{"lecture_id": "os12time2", "chunk_id": "os12time2_0000", "start": 0.0, "end": 223.12, "token_count": 599, "text": "Ja, før pause så kom det et godt spørsmål om hvorfor det tar... Hvorfor det tok lengre tid å kjøre når man brukte to CPU-er? Altså gjøre disse... ikke beregningene, men det å øke verdien med én hele tiden. Og det... Vi kan se på det en gang til. Vi kan repetere hva vi... Gjorde. Vi kompilerte sammen disse to... Oi! Nå ser dere ikke hva jeg sier. Du viser fortsatt pauseskjerm? Sorry. Da starter vi på nytt. Tilbake til... Der var hun. Da starter vi på nytt. Vi så før pause på hvordan vi kompilerte sammen disse to programmene her. Det var da et trådprogram som kjører to tråder, som hele tiden utfører én linje. Og én linje, det er bare å øke svar med én. Så når begge gjør dette her 100 millioner ganger, så bør svaret bli 200 millioner. Og vi kompilerte sammen på denne måten. Og så kjørte vi det på denne måten. Og så ser vi at svaret ble ikke 200 mill. Og det er... Det skyldes da at man ikke synkroniserer. At disse to trådene... De kjører på hver sin CPU, og de går da ut og henter inn... Og så ødelegger de for hverandre. Men det som spørsmålet gjaldt, var om jeg tok tiden på disse her. Hvis jeg timer Adatot på den måten, så ser vi at de bruker... Ja, 1 sekund. Men mitt poeng var at det at de bruker 200 % CPU, det viser at her så bruker de de to sekundene. I motsetning til... Hvis jeg eksplisitt med task-sett sier at nå skal begge trådene kjøre på samme suppe... Da... Da ser vi at... tiden var raskere. Her ble faktisk sluttresultatet riktig også. Det var altså noe av det vi skulle se på. Men at det går raskere her... Det kan nok skyldes at... At det tar mer tid å synkronisere mellom to CPU-er. Men svaret er kanskje ikke fullt så enkelt heller. For jeg testet det også. Ved å prøve å skru av den joinen som vi gjør til slutt. Men iallfall - det som kan ha en effekt, det må vi undersøke nærmere.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0001", "start": 180.0, "end": 363.72, "token_count": 579, "text": "Det var altså noe av det vi skulle se på. Men at det går raskere her... Det kan nok skyldes at... At det tar mer tid å synkronisere mellom to CPU-er. Men svaret er kanskje ikke fullt så enkelt heller. For jeg testet det også. Ved å prøve å skru av den joinen som vi gjør til slutt. Men iallfall - det som kan ha en effekt, det må vi undersøke nærmere. Og det er tema for forelesning i neste uke. Og det er cashing. For neste uke skal vi se på minne. Og det som kan ha en effekt her, som gjør at det går raskere når du kjører på samme suppo, Det er at... Ja, det kan ha med cashing å gjøre. At man mellomlagrer verdien og så gjør en endring før den er skrevet helt ut til dem. Vi kan prøve å se i neste uke om vi kan finne ut av det. For da kan vi se på hvor mange sånne cash-operasjoner som utføres. Så det kan ha en effekt når noe går raskere på samme CPU enn hvis man kjører det på to forskjellige CPU-er. Dette gikk på 0,34 sekunder, men så opp i 1 sekund her selv om du kjørte på to forskjellige CPU-er. Men akkurat den biten, den ser vi på neste gang. Men nå skal vi konsentrere oss om... ikke om timingen, men om det som kjøres... Det som skjer når vi kjører på samme SIPU og på forskjellige SIPU-er. Så vi kan gjenta det vi... det vi gjorde. Hvis jeg nå ikke tenker på tiden, bare kjører av-og-taut, så ser vi når jeg kjører dette programmet på to forskjellige SIPU-er... Så selv om dette bare er én enkel institusjon, så blir sluttresultatet forskjellig hver gang. Fordi de driver og henter ut samme verdi og overskriver hverandres resultater. Men hvis jeg kjører på... på samme suppe, så ser vi... Da blir resultatet riktig hver gang. Og det er fordi når det bare er én institusjon her, så blir dette som en atomisk operasjon. Men forskjellen er at vi låser ikke minnebussen.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0002", "start": 321.1, "end": 497.92, "token_count": 598, "text": "Så selv om dette bare er én enkel institusjon, så blir sluttresultatet forskjellig hver gang. Fordi de driver og henter ut samme verdi og overskriver hverandres resultater. Men hvis jeg kjører på... på samme suppe, så ser vi... Da blir resultatet riktig hver gang. Og det er fordi når det bare er én institusjon her, så blir dette som en atomisk operasjon. Men forskjellen er at vi låser ikke minnebussen. Men vi kan ikke ha en contex-switch som ødelegger for denne atomiske operasjonen. For da... Hvis det skjer en contex-switch, så er enten så er denne institusjonen ferdig, eller så er den ikke ferdig. Så en contex-switch vil ikke kunne ødelegge for dette. Men hvis de kjører på to forskjellige CPU-er, som vi ser her oppe... Da trenger det ikke å være kontekster som kommer midt inn i en kode. Da kommer de omtrent likt ut til dem for å hente inn verdien. Etterpå skal jeg prøve å tegne opp litt hvorfor dette skjer, og prøve å forklare enda litt mer detalj. For det er viktig å få med seg akkurat den biten her. Men før vi kommer så langt, så skal vi se på et annet eksempel. For eksempel hvor jeg har en ikke-minimal.s, men minimal-2.s. For å gjøre det litt enklere enn det jeg viste fram før pause. For der hadde jeg kode som var lagd av GCC. Men vi ser nå på... Dette er nå assembly-kode. Og... Assembly-kode og maskinkode... Vi bruker ofte de ordene om hverandre, og det er fordi én linje assemblykode, sånn som dette, det fører til én linje maskinkode. Så hvis det er enkelprosent-dax, det blir direkte oversatt til nulldeler og enere. Men det vil alltid være sånn at én assemblykodelinje, det blir én maskinkodelinje. Så dette kan man stole på, at dette er det operativsystemet ser. Derimot, hvis du har høynivåkode... Så kan det være at én linje høynivåkode kan gi flere linjer maskinkode. Eller asemblykode. Men i dette tilfellet så ser vi, i stedet for å bare øke svar med én direkte i ram, som man kan gjøre,", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0003", "start": 460.64, "end": 636.2, "token_count": 598, "text": "Så hvis det er enkelprosent-dax, det blir direkte oversatt til nulldeler og enere. Men det vil alltid være sånn at én assemblykodelinje, det blir én maskinkodelinje. Så dette kan man stole på, at dette er det operativsystemet ser. Derimot, hvis du har høynivåkode... Så kan det være at én linje høynivåkode kan gi flere linjer maskinkode. Eller asemblykode. Men i dette tilfellet så ser vi, i stedet for å bare øke svar med én direkte i ram, som man kan gjøre, så har jeg delt opp dette i tre institusjoner. Først en som henter svar og legger det i EAX. Og så en institusjon som øker EAX med én. Og så flyttes resultatet ut til svaret. Det er sånn som en kompilator kan finne på å lage kode. Det kan vi ikke være sikre på om dette skjer. Så hvis jeg nå prøver å kompilere med denne i stedet... Så jeg tar nå minimal to, som er denne koden. Og så prøver jeg å kjøre med Task-sett. Og da ser vi igjen så oppstår problemet. Igjen så blir det nå trøbbel. Og det er fordi her er det tre linjer med kode. Man henter inn eksplisitt fra RAM, så hentes det inn til AAX. Så økes den, og så legges den ut igjen. Og da kan vi få problemer med Urvis, og det er det som skjer. Hvis det kommer da en context switch før den har økt verdien, så kan den hoppe til den andre tråden, som nå henter inn svar på nytt, gjør en rekke økninger og legger tilbake resultatet. Men da i mellomtiden så er denne første prosessen, den er frosset her. Den vil øke da på... den verdien som den hentet inn, og så skrivende ut igjen. Og da blir det trøbbel. Da blir det trøbbel. Men... Hvis vi derfor i stedet bruker minimal.s... Denne, med bare én enkelinstitusjon... Så komponere på nytt. Én enkel instruksjon, så kjøre med Taset. Da vil hver eneste gang så får man riktig svar. Fordi vi ikke kan komme en context-witch inne i den operasjonen.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0004", "start": 600.0, "end": 856.28, "token_count": 596, "text": "Den vil øke da på... den verdien som den hentet inn, og så skrivende ut igjen. Og da blir det trøbbel. Da blir det trøbbel. Men... Hvis vi derfor i stedet bruker minimal.s... Denne, med bare én enkelinstitusjon... Så komponere på nytt. Én enkel instruksjon, så kjøre med Taset. Da vil hver eneste gang så får man riktig svar. Fordi vi ikke kan komme en context-witch inne i den operasjonen. Ja... Da skal jeg prøve å ta en pause... Men skal vi se... Her. Jeg tenkte jeg bare skulle prøve å forklare... hva som skjer her. Hvis vi tenker oss... Hvis vi tenker oss at dette er CPU1... Og så har vi... skal vi se... sånn... En buss som går opp til RAM her oppe. Her er han. Og det som skjer hele tiden, er at her oppe i Ramm så har vi en adresse hvor vi har en arabel som heter'svar'. Og la oss si'svar nå er kanskje 10'. Så... Det som da skjer... Vi kan ta det første eksempelet først. Hvor vi bare har én institusjon her, som heter INK-L. INK-lung. Svar av... Altså det er én institusjon som øker den verdien. Da er det opplagt ikke noe problem hvis denne her kjører helt alene. Da vil vel den bare hente... I én institusjon så øker den da verdien. Men på en eller annen måte... Den kan ikke... Den må på en eller annen måte hente inn verdien her. Så verdien vil gå på data. Det er en del av hele denne maskininstitusjonen INK med svar. Den henter inn verdien, øker med en og legger den tilbake i én enkelt operasjon. Men da er det klart... Da kan vi ha problemer her hvis... CPU2, den også gjør den samme operasjonen. Og så er jo begge de to koblet på... Dette er buss. De er koblet på den samme bussen. Og de snakker med hverandre og henter inn verdier. Men da er problemet hvis disse to CPU-ene ikke er koordinerte. Sånn som de generelt. Så vil... De vil da operere samtidig. Og hvis verdien her oppe er 10, så vil begge de to hente ned verdien 10.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0005", "start": 802.38, "end": 1016.36, "token_count": 595, "text": "CPU2, den også gjør den samme operasjonen. Og så er jo begge de to koblet på... Dette er buss. De er koblet på den samme bussen. Og de snakker med hverandre og henter inn verdier. Men da er problemet hvis disse to CPU-ene ikke er koordinerte. Sånn som de generelt. Så vil... De vil da operere samtidig. Og hvis verdien her oppe er 10, så vil begge de to hente ned verdien 10. Og de vil da måtte... Den verdien vil da lagres i et register her nede. Vi lagrer det ikke eksplisitt i registeret. Den maskininstruksjonen som gjør dette, den må lagre et register, og så må de sende verdien inn i aluen osv. Den må i hvert fall kanalisere den tieren der inn i aluen, sånn at aluen øker den med én. Og så må den sende 11 tilbake. Men da er det klart... Da får vi allerede et problem hvis de gjør dette her. Helt samtidig. Ber om den tieren. Da kommer det en tier kjørende ned der. Disse bitene sendes over bussen. En tier inn her og en tier inn der. Og så øker begge... Øker den til 11 med alu. Og så sender begge 11 tilbake. Her går det... Dette går ikke bra fordi at... Uansett hvilken som da kommer først tilbake... Uansett så vil 11 lagres her oppe. Og det som skulle ha skjedd, det er at 12 skulle ha blitt lagret. Fordi begge har lagt til. Og det er da... Det er da vi kommer inn med den smarte tingen at vi legger på en... Lokk. Der skal det stå 'lokk'. Vi legger på en lokk foran. Foran institusjonen. Og det som skjer da, er at da... La oss si den CPU1 gjør dette her først. Den lokker da hele databussen. Nå får ingen andre lov til å... endre på den variabelen. Det vil jo ikke gjelde alle. Men man sjekker at den ene variabelen der... Her skal ingen andre kunne... Den skal ingen andre kunne endre. Og det som skjer da, er at da får CPU1 i fred og ro utføre sin alun øke fra 10 til 11, sende den tilbake på bussen, og denne her går opp til 11.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0006", "start": 977.08, "end": 1194.64, "token_count": 596, "text": "Den lokker da hele databussen. Nå får ingen andre lov til å... endre på den variabelen. Det vil jo ikke gjelde alle. Men man sjekker at den ene variabelen der... Her skal ingen andre kunne... Den skal ingen andre kunne endre. Og det som skjer da, er at da får CPU1 i fred og ro utføre sin alun øke fra 10 til 11, sende den tilbake på bussen, og denne her går opp til 11. Og så, i neste omgang, når den er ferdig, og så i neste omgang, når den er ferdig, Med den ene institusjonen. Så får CPU2 utføre sin institusjon. Den hadde kanskje prøvd å gjøre det samtidig, men så fant den ut at databussen var lokket. Den var låst, så da måtte den vente litt. Og da begynner CPU2 på sin operasjon. Og den vil da, istedenfor å hente inn 10, så vil den hente inn 11. Og den får da resultatet 12, og så sendes det tilbake. Og så blir det 12 her. Og alt ble riktig. Så det går fint med... med lokk. Men så var det det som skjedde med... når vi kjører Task-sett. Så... ja. Vi kan kanskje ta... Vi tar en ny figur ved, så ser vi på Task-sett. Du vil bare ha én CPU. Én CPU her, og så har vi ramme her oppe. Og her har vi svar. Svar likt 10. Og da er det litt greiere, for hvis vi bare sier... Da skjer den operasjonen der. Det er bare én institusjon. Så da vil det hele tiden være sånn at hvis du... Hvis jeg gjør ink-svar, så henter jeg ut tallet ti. Den tar databussen inn til Alund. Alund... Får inn 10, sender 11 tilbake. Og så kommer det 11 opp her. Og dette er da én operasjon. Men så har jeg nå to prosesser, eller to tråder, som kjører samtidig på denne CPU-en. Og da vil det liksom være P1 og P2. Men gjett gitt P1 og P2. De har liksom en... Et lite område, en sånn PCB her oppe, hvor de har sine verdier lagret. Ops... Dårlig kulepenn. Der. P1 og P2 har sine verdier lagret her oppe.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0007", "start": 1147.22, "end": 1367.22, "token_count": 591, "text": "Og dette er da én operasjon. Men så har jeg nå to prosesser, eller to tråder, som kjører samtidig på denne CPU-en. Og da vil det liksom være P1 og P2. Men gjett gitt P1 og P2. De har liksom en... Et lite område, en sånn PCB her oppe, hvor de har sine verdier lagret. Ops... Dårlig kulepenn. Der. P1 og P2 har sine verdier lagret her oppe. Og når det gjør en context switch, så henter man inn de gamle verdiene. Men da er poenget her... Når vi kjører et task-sett, og vi bare har én institusjon, så da så vi at en context switch hadde ikke noe å si. For da utføres den institusjonen her ferdig, og det går bare én i operasjon. Så hver gang prosess én er inne og gjør dette her, så økes det pent fra 10 til 11, og så kanskje kommer P2 inn og skal jobbe. Men hente ut verdien 11, for P1 er jo ferdig med den. Kjøre ned til aluen og øke igjen. Da kommer den opp til 12. Og alt går fint. Men det som ble problemet, er... Hva skjer om vi bruker den koden som... Det var det andre tilfellet vi kjørte. Da var det tre instruksjoner. Og da så vi at da ble det også trøbbel for... Selv om vi kjørte Task-sett. Og da har vi to prosesser, P1 og P2, og det var litt sånn som det med den MILD-en som vi så på. Da, selv om det bare er én CPU og én buss, så får vi problemer. For da vil... La oss si vi har verdien 11 her, da. Så er det Prosess P1 som kjører, henter inn verdien 11 og legger den i AX. Og så kommer det en Context Switch. Og da ligger da verdien 11... Den vil da lagres i PCB for P1. Og den verdien 11, den ligger der, da. Og så kommer den Context Switch akkurat etter den instruksjonen der. Så starter P2 å kjøre, og den vil da begynne på koden her og hente inn verdien 11, som ligger i svar, inn i sitt register. Og så øker den den og legger ut osv.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0008", "start": 1329.82, "end": 1551.0, "token_count": 586, "text": "Og så kommer det en Context Switch. Og da ligger da verdien 11... Den vil da lagres i PCB for P1. Og den verdien 11, den ligger der, da. Og så kommer den Context Switch akkurat etter den instruksjonen der. Så starter P2 å kjøre, og den vil da begynne på koden her og hente inn verdien 11, som ligger i svar, inn i sitt register. Og så øker den den og legger ut osv. Og da vil da P2 kunne gjøre det en rekke ganger. 100 ganger, kanskje. Så den kommer opp i et svar på 111 her oppe. Og så kommer den kontekst-witch-tilbake, og så er det P1 sin tur. Men da vil jo P1 begynne å operere på sin gamle 11 som ligger der. Den legges inn i registrene, og så øker den AX-men og får 12. Og så sendes 12 ut. Og da ser vi... Da blir det totalt kaos, fordi det var tre linjer her. Men hvis jeg kjørte Task-sett... Og tvang begge prosessene til å kjøre på... på samme CPU. Så så vi at ink svar, med én enkel operasjon, så fungerte det som det skulle. Da fikk vi ikke noe trøbbel. Så hvis vi hopper tilbake hit... Gjenta den problemstillingen... Når vi kjørte en enkel institusjon sånn som dette... Så gir Tasset det samme svaret. Fordi da blir det på en måte automisk. Selv uten å bruke lokk så får vi samme svar. Derimot... Derimot hvis jeg bruker... Oi... Her. Hvis jeg bruker minimal to, med tre instruksjoner... Vi kjører Tasset... Oi. Der brukte jeg minimal én. Minimal to. Komplirer med minimal to, og så kjører Tasset. Så ser vi hver gang det blir forskjellig. Og det er fordi... Og det er fordi verdiene overskriver hverandre. Fordi det da skjer en context switch på akkurat feil feilse. Ok. Det var enda litt mer detaljer rundt Lundstaset og Sepur. Det er litt vanskelige problemstillinger, så derfor prøvde jeg å legge inn enda litt mer tid på det. Ok. Da skal vi tilbake og se på noen slider.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0009", "start": 1488.28, "end": 1714.68, "token_count": 597, "text": "Oi. Der brukte jeg minimal én. Minimal to. Komplirer med minimal to, og så kjører Tasset. Så ser vi hver gang det blir forskjellig. Og det er fordi... Og det er fordi verdiene overskriver hverandre. Fordi det da skjer en context switch på akkurat feil feilse. Ok. Det var enda litt mer detaljer rundt Lundstaset og Sepur. Det er litt vanskelige problemstillinger, så derfor prøvde jeg å legge inn enda litt mer tid på det. Ok. Da skal vi tilbake og se på noen slider. Og X86-institusjonslokk, så nå skal vi se på semaforer. Semaforer er et begrep som er mye brukt når det gjelder synkronisering. Og semaforer, de... Det er en slags teller. Så en binær semafor, altså en semafor som bare har 0 eller 1, det er akkurat som en mytex. En semafor kan ha flere verdier. Du kan f.eks. starte med Slake T. Da har man ti ressurser som man kan bruke opp før man må vente og synkronisere med andre. På en semafor har man to metoder som man bruker. Og SIGMO-S, det signaliserer nå... Nå er alt klart. Semaforer er jo et gammelt begrep som handler om flagg. At man bruker sånne tegn for flagg for å sende signaler over lange avstander. Så dette er semaforer som da brukes til å sende tegn prosesser imellom. Dijkstra, som er en nederlandsk professor som på 60-, 70-tallet... Han la grunnlag for mye av dette med synkronisering og den Dijkstra-algoritmen som vi skal se på i oppgavene. Og han fant på dette begrepet - semaforer. Hvis dette skal implementeres riktig, så må de være uninterruptable. Altså... De må være atomiske, sånn at det ikke kan komme en kontekst-switch midt inni her. Og det gjør man da ofte med hardware-støtte. Og de operasjonene man gjør... Her så ser vi at så lenge S er mindre enn lik 0, så venter man. Og så minsker man. La oss si at S i utgangspunktet er 5. Vil alle som går inn i vekt, de vil senke det nedover.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0010", "start": 1680.0, "end": 1863.68, "token_count": 590, "text": "De må være atomiske, sånn at det ikke kan komme en kontekst-switch midt inni her. Og det gjør man da ofte med hardware-støtte. Og de operasjonene man gjør... Her så ser vi at så lenge S er mindre enn lik 0, så venter man. Og så minsker man. La oss si at S i utgangspunktet er 5. Vil alle som går inn i vekt, de vil senke det nedover. Men når den når 0, da vil den ikke gå lenger ned. Da er det et signal til andre. Her må man stå på vente. Men hvis vi starter med S1, så vil en semafor se ut som en mytex. Så en binær semafor som enten er 0 eller 1, den er akkurat som en lokk eller som en mytex. Da kan man bruke semaforer akkurat som vi har gjort tidligere. Tidligere sa vi get mutex og release mutex, men her ville vi nå ta wait-s og signal-s. Men de har da den tilsvarende egenskapen. Da kan man kjøre et kritisk avsnitt inni, og da... Når man gjør wait-s, så setter man s lik 0. Det er da et signal til alle andre. At de må stå og vente. Ja, vi har sett... generelt med mutexer... Og hvis man gjør det med software, lager den type mutexer, så bruker man busy waiting. Og det er opplagt en ulempe. Operativstemme har den store fordelen at det kan styre prosesser og sette dem inn og ut av køer. Så dette er en... Dette er da en implementasjon av semafore reoperativsystemet. Og da kan... Hvis vi starter med wait, så kan en... Hvis en ressurs er opptatt og man må vente, så kan operativsystemet blokkere den prosessen og legge det i en venteliste. Det fine med det er at da tas bare prosessen ut av ready-list. Og den vil ikke måtte stå og vente med en busy waiting, altså stå med en løkke og kjøre CPU-en om og om igjen. Den vil da bare legges på vent. Og så, når andre prosesser er ferdig, og gjør en signal, så kan operativstemaet se at OK, S økes med én. Ja, da kan vi vekke opp neste prosess fra ventelisten. Den prosessen opp som har ligget og ventet.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0011", "start": 1825.8, "end": 2001.26, "token_count": 585, "text": "Det fine med det er at da tas bare prosessen ut av ready-list. Og den vil ikke måtte stå og vente med en busy waiting, altså stå med en løkke og kjøre CPU-en om og om igjen. Den vil da bare legges på vent. Og så, når andre prosesser er ferdig, og gjør en signal, så kan operativstemaet se at OK, S økes med én. Ja, da kan vi vekke opp neste prosess fra ventelisten. Den prosessen opp som har ligget og ventet. På den måten får man en veldig ryddig og effektiv måte på å synkronisere prosesser. Og det er et viktig poeng at operativsystemet legger til rette for at programmerere kan synkronisere med sånn som signal await, mens det er programmereren som må skrive kvoten som gjør det. Så operativstemme synkroniserer ikke for programmererne. Det er programmererne som må gjøre dette, men operativstemme legger til rette ved f.eks. å kunne tilby semaforer. Vi skal se veldig kort på hvordan man kan bruke semaforerkritisk avsnitt.  For dette ligner da veldig på hvordan man bruker getmytex og releasemytex. Det er det samme systemet. Men vi ser her Prosess A. Den kjører da kode som ikke er kritisk. Og når du skal inn i kritisk kode, det er skrevet her K1, K2, K3, den er kritisk, så gjør man en wait, og etterpå signal som signaliserer da... ... nå er jeg ferdig. Og da må PB... Og annen kode også gjøre det samme. Og allerede her så ser vi at når dette er overlatt til programmereren, så er det klart at programmereren fort kan gjøre feil. La oss si at programmereren glemmer å gjøre en wait-sr. Da kan begge komme inn i kritiske asyn samtidig. Så det er overlatt til programmereren å kode dette riktig. Så det kan fort bli feil. Men hvis man programmerer riktig... Så... Så kan det skje noe sånt som dette her. Du starter med B-en, og så sier den at den skal gå inn i kritisk avsnitt. Så kommer det en kontekst-switch, og da starter A-en. Og så ønsker A-en også å gå inn i kritisk avsnitt.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0012", "start": 1963.42, "end": 2126.3, "token_count": 599, "text": "Da kan begge komme inn i kritiske asyn samtidig. Så det er overlatt til programmereren å kode dette riktig. Så det kan fort bli feil. Men hvis man programmerer riktig... Så... Så kan det skje noe sånt som dette her. Du starter med B-en, og så sier den at den skal gå inn i kritisk avsnitt. Så kommer det en kontekst-switch, og da starter A-en. Og så ønsker A-en også å gå inn i kritisk avsnitt. Nå står det kontekst-switch her. Dette vil også fungere for... Fordi her brukes også den samme mekanismen at bussen stenges av når man gjør weight- og signal på den fellesvarianten. Så med en gang prosessen her gjør weight, så ser vi at operativsystemet legger den da i kø. Den tar den ut av ready-list. Og så vil den ligge der og vente. Så følges den inn, så kommer den tilbake til ProsessB. Som kjører ferdig sitt kritiske avsnitt, signaliserer:\" Nå er jeg ferdig.\" Og så fortsetter han å kjøre sine vanlige instruksjoner. Før til slutt A kommer tilbake og kjører ferdig sitt kritiske avsnitt, og signaliserer da til alle andre prosesser:\" Nå er jeg ferdig.\" Så i dette tilfellet her så brukes semafor akkurat som en mytex. Så i dette tilfellet her så er det ikke noen forskjell på en mytex og en semafor. Semaforen har bare... En semafor som er binær, som har enten verdi 0 eller 1. Det er det samme som en Mytex. Men en semafor kan også ha høyere verdi. En semafor kan f.eks. starte på 5 og så gå nedover til 0. Eller den kan starte på 1 og så kan man gå nedover til større negative verdier. Så semafor er... forskjellig fra Mytex på den måten. at den kan ha flere verdier. Vi kan også bruke semaforer til å synkronisere to prosesser. Det trenger ikke nødvendigvis ærlig et kritisk avsnitt, men det kan bare være sånn at du har en prosess B. Den må vente til en prosess A er ferdig med noe i sin kode. Da er det den programmereren som gjør dette her. Etter kodelinje A3.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0013", "start": 2089.56, "end": 2258.68, "token_count": 578, "text": "Så semafor er... forskjellig fra Mytex på den måten. at den kan ha flere verdier. Vi kan også bruke semaforer til å synkronisere to prosesser. Det trenger ikke nødvendigvis ærlig et kritisk avsnitt, men det kan bare være sånn at du har en prosess B. Den må vente til en prosess A er ferdig med noe i sin kode. Da er det den programmereren som gjør dette her. Etter kodelinje A3. Så skal Prosess A sende et signal til Prosess B. \"'Nå er jeg ferdig. Nå kan Prosess B ta over...' 'Kanskje bruke noe av det jeg har lagd.'\" Og så kjøres inn kode. Det kan oppnås med semaforer. Hvis man installerer den til null, så vil denne koden sørge for at A aldri går videre før B har kommet inn. Og igjen så kan vi se på det... Hvis B når frem først... Så da er ikke A klar, og da er det et signal S er lik 0. Og da senkes denne til minus 1. Og så kommer A fram til den er ferdig med sin kodedel. Og så sender den signal S ved at S økes det igjen. Og dermed kommer B inn. Og hvis A når det først strømmer, så er det enda enklere. Da økes S til 1. Og det er et signal. Så når B kommer litt, bare minker den seg igjen og går rett videre med sin kode. Så på den måten kan semaforer brukes til å synkronisere mellom... Mellom prosesser. Ja, jeg skal se på noen eksempler på låsemekanismer som ble brukt i Linux-hjernen. For kjernen selv. Den må hele tiden bruke låser. Fordi kjernen kjører ikke bare på én CPU. Den kan kjøre på flere CPU-er samtidig, og den kan også kontekstfixes. Kjernen består av mange tråder som jobber uavhengig av hverandre. Og dermed må de synkroniseres. Man bruker bl.a. atomiske operasjoner. Spinlocks er faktisk mye brukt på operativsystemnivå, for det er en veldig enkel metode. Man bare står og spinner på én verdi. Det er en enkel og sikker måte.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0014", "start": 2224.42, "end": 2405.38, "token_count": 596, "text": "Fordi kjernen kjører ikke bare på én CPU. Den kan kjøre på flere CPU-er samtidig, og den kan også kontekstfixes. Kjernen består av mange tråder som jobber uavhengig av hverandre. Og dermed må de synkroniseres. Man bruker bl.a. atomiske operasjoner. Spinlocks er faktisk mye brukt på operativsystemnivå, for det er en veldig enkel metode. Man bare står og spinner på én verdi. Det er en enkel og sikker måte. Men det er klart, de må da kodes sånn at den ikke bruker veldig mye tid. Semaforer brukes også i Linux-hjernen. Og så er det noen sånne read-all-right-locks, som bruker for å koordinere hvor mange som skriver og leser på. Vi så forrige gang på Java-kode, som var litt tilsvarende til de P3-trådene. Det var en saldo, så hadde vi én tråd som hele tiden økte saldoen, Hele tiden minsket saldoen. Så sa vi at når de to trådene kjørte uavhengig av hverandre, så ble det kaos. Akkurat som i den figuren hvor jeg prøvde å tegne inn hva som skjer, så kunne det når som helst komme en context witch. Og vi så også på Java-koden at én oppdatering, saldo pluss alike én, den tilsvarte flere... Java bite-kode-instruksjoner. Sånn at der kunne det komme en Context-switch midt inni det kritiske avsnittet. Og dermed, selv om vi kjørte task-sett med Java-koden, så... Så ødela trådene for hverandre. Og da tilbyr heldigvis Java monitorer. Monitorer er en del av programmeringsspråket. Og det er på en måte enklere og sikrere å bruke Semaforer eller metoder hvor du må ha get-mutex og release-mutex fordi... Fordi da programmereren ikke kan glemme å gjøre en get-mutex. Og det er fordi den synkroniserte metoden bruker en monitor som synkroniserer hele kodebiter-avgangen. Så dette gjør det enklere for programmereren. Og måten vi kan løse... Problemet vi hadde sist, er å... Én måte å gjøre det på er å synkronisere en kodeblokk.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0015", "start": 2366.5, "end": 2542.22, "token_count": 591, "text": "Semaforer eller metoder hvor du må ha get-mutex og release-mutex fordi... Fordi da programmereren ikke kan glemme å gjøre en get-mutex. Og det er fordi den synkroniserte metoden bruker en monitor som synkroniserer hele kodebiter-avgangen. Så dette gjør det enklere for programmereren. Og måten vi kan løse... Problemet vi hadde sist, er å... Én måte å gjøre det på er å synkronisere en kodeblokk. Da må vi først ha et static objekt. Jeg kaller det lokk. Dette er da låsen. Den er da felles for de to trådene. Og så, før et kritisk avsnitt, så kan vi bare si synchronized lock. Lage en kodeblokk rundt det avsnittet. Og hvis vi gjør det... Så sørger Java for resten. Da vil koden bli synkronisert. Og vi må gjøre synkronisert lokk. Det må vi gjøre for begge de kodeblokkene. Både den som øker med én, og den som minker med én. Og da vil vi se inni bite-koden... Vi så på det sist at hvis vi gir Java payments private, så kan vi se på bite-koden som genereres når vi kompilerer Java. Da får vi bite-kodet, og det er dette som Java-virtuellmaskinen ser. Og da så vi sist... Her er området hvor saldoen økes. Da henter man saldoen fra ram. Øker den med én... Nei, så legger man en konstant én på stacken. Og så i add vil da legge sammen de to verdiene øverst på stacken. Så hvis den henter inn saldo lik tid, så økes den med igjen. Og så skrives ut 11. Men da ser vi igjen... Her hentes først... GetStatic henter ut saldoen. Så hvis det kommer en kontekstvisj her, så kan det potensielt gå over til den andre tråden, som ødelegger. Akkurat på samme måte som tidligere. Men så ser vi... Når vi har lagt inn den synchronized lock-biten her, så dukker det opp en monitor enter og en monitor exit. Og da sørger Yawa i samarbeid med operativsystemet for at dette avsnittet er kritisk. Sånn at ved hjelp av samme mekanismer så låses da også bussen,", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0016", "start": 2501.58, "end": 2674.88, "token_count": 590, "text": "Så hvis det kommer en kontekstvisj her, så kan det potensielt gå over til den andre tråden, som ødelegger. Akkurat på samme måte som tidligere. Men så ser vi... Når vi har lagt inn den synchronized lock-biten her, så dukker det opp en monitor enter og en monitor exit. Og da sørger Yawa i samarbeid med operativsystemet for at dette avsnittet er kritisk. Sånn at ved hjelp av samme mekanismer så låses da også bussen, sånn at dette fungerer selv om trådene kjører på forskjellige sepuer. Bussen låses sånn at den saldoverdien... Det er ingen andre som kan hente ut den fra Aram før monitor exit kommer. Før man når monitor exit. Og på denne måten så vil man da kunne synkronisere Java-kode. Så en løsning på det... En litt annen løsning som man også kunne Og det er oppgaver om dere denne uken. Det er å lage en synchronized metode. Istedenfor å bare ta en kodeblokk, så lager du en hel metode som er synchronized. Da er det viktig at det bare er akkurat det kritiske avsnittet her. For dette tar også tid. Ja... Det ser ut som vi har brukt mye tid her, så vi skal straks gi oss. Men det er et spørsmål her til slutt... Hvorfor er det viktig at denne metoden er static? Det er vel en oppgave som også går på dette her. Jo, det er viktig at denne metoden er static, for hvis ikke så vil jo hver tråd som startes, vil ha sin egen metode. Og da hjelper det ikke at den er synkronisert, for da er den bare synkronisert med seg selv. Denne metoden må være static, sånn at det er den samme metoden for alle trådene. Hvis ikke, så fungerer det ikke. Ja, helt til slutt, message passing er en litt annen måte å synkronisere på. Og som oftest brukes veldig mye distribuerte systemer, hvor man da ikke bare har CPU-er på samme maskin, men CPU-er på samme maskin. Og forskjellige servere rundt omkring i verden. Da er det opplagt at hvis man har felles ressurser, så kan man ikke sette på lokk.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0017", "start": 2642.14, "end": 2793.94, "token_count": 507, "text": "Hvis ikke, så fungerer det ikke. Ja, helt til slutt, message passing er en litt annen måte å synkronisere på. Og som oftest brukes veldig mye distribuerte systemer, hvor man da ikke bare har CPU-er på samme maskin, men CPU-er på samme maskin. Og forskjellige servere rundt omkring i verden. Da er det opplagt at hvis man har felles ressurser, så kan man ikke sette på lokk. Det hjelper ikke å stenge Rambussen. Da må man kommunisere sånn at man sikrer at man f.eks. ikke endrer på noen fellesverdier. Så message-passing er en sånn generell måte for å kommunisere mellom prosesser på. Men den er litt mer tungvint. Da må du sende beskjeder frem og tilbake. Så det er ikke like kjapt som semaforer og montor. Ja... Jeg har et avsnitt om deadlock også, men da tenker jeg vi bare utsetter den biten om deadlock til neste uke. Og så... Så stopper vi her foreløpig. Og da er det som sagt... En masse oppgaver rundt dette her i... i oppgavene. Jeg fikk ikke gått inn på synkronisert og Java-koden, men hvis dere jobber med oppgavene, så kan dere se hvordan det gjøres. Da får dere det litt eksplisitt... Da kan dere teste ut og se hvordan Java-koden kan synkroniseres. Altså med task-sett er det forskjell om javatronene kjører på samme CPU eller ikke. Og det er... Vanligvis, hvis du ikke bruker task-sett, så settes de på hver sin CPU av operativstem. Men med task-sett så kan du se hva det er som skjer hvis de kjører på samme CPU. Og det er tross alt operativstemmen som styrer dette, så det kan jo være at de kjører på samme CPU. Men du kan ikke garantere det, med mindre du setter opp tasser. Så se på det i oppgaven.", "source": "lecture"}
