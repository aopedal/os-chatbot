{"lecture_id": "os7time1", "chunk_id": "os7time1_0000", "start": 0.0, "end": 227.8, "token_count": 599, "text": "Ja. God morgen, alle sammen. Som alltid er det veldig hyggelig å se at så mange av dere har kommet dere opp og er klar for operativstem-forløsning. Det er kjempebra. Jeg vet jo ikke hvordan det går fremover. Vi kan jo håpe det blir fysiske forelesninger. Men det er som dere vet, så er det fortsatt uklart. Men vi håper at vi etter hvert skal komme i gang. Men som dere ser på timeplanen her, så er det... Ja, så har vi kommet ganske langt. Vi er nå i uke syv, så i neste uke er det konteuke. Men ingen vanlige forelesninger. Og det er heller ikke nye oppgaver. Som det står her, er det ikke oppgaver pga. konteeksamen. Så... Så da er det ikke nye oppgaver. Men jeg tenker... Det er heller ikke lagt ut noen container og dokker, som er neste tema. Men jeg tenkte å gjøre det i løpet av uka. Kan komme i gang med oppgave fra uke ni. For de som er veldig hyppe på å komme i gang med det, så skal vi se veldig kort på hvordan dere kan starte dokkecontainere i Linux-VM-ene, sånn at dere kan komme i gang med å eksperimentere. Det var litt uklart med Ine og Rune i dag, men jeg tror etter hvert kanskje begge kommer. Så uansett... Som vanlig så legger jeg det ut etter hvert. Jeg lurer på om jeg kanskje ikke har husket å... Jeg legger det ut etter hvert. Redigere fra forrige gang... Altså... Nei. Der ser jeg vi bare har uredigerte opptak. Men det kommer jeg også til å gjøre i løpet av uka. Redigere disse og legge det ut under enkelttemaer. Så det er litt lettere å bli hvis man står fast med problemer i oppgaver f.eks. Temaet i dag er multitasking fortsatt. Vi så forrige gang på multitasking litt sånn i... Skal vi se... Hadde jeg en sist... Nei, det hadde jeg ikke. Vi kan gå tilbake til forrige gang. Ja, vi avsluttet dette med Branch Prediction. Og så så vi litt på... Operativsystemhistorie. Og så så vi på multitasking. Og for å repetere det veldig fort, så er... Hovedideen er at prosesser bytter på. Man kan bruke...", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0001", "start": 180.0, "end": 372.24, "token_count": 595, "text": "Temaet i dag er multitasking fortsatt. Vi så forrige gang på multitasking litt sånn i... Skal vi se... Hadde jeg en sist... Nei, det hadde jeg ikke. Vi kan gå tilbake til forrige gang. Ja, vi avsluttet dette med Branch Prediction. Og så så vi litt på... Operativsystemhistorie. Og så så vi på multitasking. Og for å repetere det veldig fort, så er... Hovedideen er at prosesser bytter på. Man kan bruke... Oi... Kan du dele skjermen? Betyr det at dere ikke ser skjermen min? Jeg ser, ja. Jeg ser skjermen. Ja, fint. For det jeg gjør, er å... Jo, jeg deler det vinduet som jeg ser, sånn at da må du... Ja, hvis dere ikke ser vinduet, så kanskje prøve å logge på igjen på Zoom. Kjempebra at dere svarer kjapt. De fleste ser her i hvert fall. Ok... Ja, så da ser dere her. Dette er liksom grunnideen i multitasking. Vi har tre prosesser P1, P2 og P3. Og så bytter man hele tiden på hvilken av de prosessene som kjører. Og hele tiden, det er veldig ofte. Her ser du det som millisekunder. Da kommer det en ny prosess inn og tar over CPU-en og kjører. Først kjører P1. Altså er det i løpet av et mikrosekund her, kanskje enda mindre, så skjer det en kontekst switch. P1 hives ut. P2 kommer inn. Og sånn fortsetter en evig løkke. Og det er ikke alltid at det er noen som ønsker å bruke CPU-en, selv om du bare har én CPU. De fleste prosesser vil bare stå og vente, kanskje på input og gjøre noe en gang iblant. Man har regnejobber som skal regne ut et eller annet, eller de skal rendre en video, gjøre masse operasjoner for å få ut de riktige pikslene. En skal vri bildet 50 grader, og så må man regne ut hvilke piksler som kommer ut. Da står CPU-en og jobber hele tiden. Eller en kompilator som lager maskinkode. Den bruker jeg også CPU helt tiden. Så dette er hovedideene bak multitasking. Og så begynte vi forrige gang så vidt å se på multitasking", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0002", "start": 335.58, "end": 539.98, "token_count": 589, "text": "eller de skal rendre en video, gjøre masse operasjoner for å få ut de riktige pikslene. En skal vri bildet 50 grader, og så må man regne ut hvilke piksler som kommer ut. Da står CPU-en og jobber hele tiden. Eller en kompilator som lager maskinkode. Den bruker jeg også CPU helt tiden. Så dette er hovedideene bak multitasking. Og så begynte vi forrige gang så vidt å se på multitasking i en server som har én CPU. Og da så vi at den serveren, den gjorde akkurat dette her. Hvis det kom to regnejobber som sto og regnet, så... Og så fikk de 50 % CPU-tid hver. Og det vi skal fortsette med i dag, er å se på multitasking med... Altså multicore multitasking. At du har mange CPU-er som kjører i parallell. Og da skal vi se på hvordan jobbene da blir fordelt mellom CPU-ene. Vi fortsetter omtrent der vi slapp i hvert fall. Så... Det jeg tenkte oss å se på da, var å prøve å regne på en regnejobb. Dette er et lite script, som bare står og regner tre millioner ganger så legger den sammen i pluss én. En økning med, og så legger den sammen og lager en sum. Det er ikke så viktig akkurat hva den gjør, men poenget er at et sånt program vil bruke så mye CPU som det bare kan. Helt innen står det 'bruker CPU'. Den hviler aldri 'bruker helt innen CPU'. Og da kan vi se på topp samtidig. Som står og går. Og hvis jeg nå kjører en regnejobb... Time tar tiden på regnejobben. Da ser vi at øverste linje her toppsorterer default etter hvilke prosesser som bruker mest CPU. Og øverste linje her, det vil da være toppsortering. Da ser vi ikke... Vi så ikke navnet på regnejobben, men det er fordi jeg har et litt lite toppvindu. Hvis vi drar litt lenger bort her nå... Sånn. Der kan vi se. Dette er regnejobben som står og kjører. Og den får 100 % CPU. Ved å taste én i topp så kan jeg se hvor mange CPU-er det er. Og da ser jeg denne maskinen her.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0003", "start": 504.74, "end": 676.96, "token_count": 588, "text": "Og øverste linje her, det vil da være toppsortering. Da ser vi ikke... Vi så ikke navnet på regnejobben, men det er fordi jeg har et litt lite toppvindu. Hvis vi drar litt lenger bort her nå... Sånn. Der kan vi se. Dette er regnejobben som står og kjører. Og den får 100 % CPU. Ved å taste én i topp så kan jeg se hvor mange CPU-er det er. Og da ser jeg denne maskinen her. Dette er egentlig en desktop. Min desktop som står nede på OsloMet, den har to CPU-er. Iallfall... Hvis vi skal se senere, så har den egentlig fire, eller faktisk åtte, hvis du regner med hypertrening, men jeg har skrudd av de andre CPU-ene. Så i dette tilfellet så ser dette nøyaktig ut som en CPU, ei, en desktop som har to CPU-er. I forelesningshåndtatene så... Så har jeg et tilsvarende eksempel med den gamle Macen min, som også har to CPU-er. Men i prinsippet skjer det nøyaktig det samme. For det vi kan prøve å få til her, det er hva skjer om vi nå kjører to regnejobber samtidig. Da kan jeg lage en liten løkke for i-inn 1.2. Og så inn i den løkka så kan jeg ta... Og time regnejobben. Og så kan jeg legge den i bakgrunnen. Sånn at det som vil skje nå, er at to regnejobber startes helt samtidig. Don. Og da ser vi i topp at her er det to regnejobber som starter. Og siden denne serveren har to CPU-er, så ser vi at de jobber på hver sin CPU. Det går an å se hvilken CPU som blir brukt. Nå tastes det F i topp. Da kan vi styre hvilke kolonner som brukes. Hvis man blar nedover her, så vil man se... Her er det en kolonne som heter Last Used CPU. Hvis jeg nå taster Space her, så får jeg et merke på den. Og Escape går nå tilbake. Og da... Vil jeg se... hvis jeg lager vinduet litt større... Så vil jeg se at ytterst her så kommer det en kolonne hvor det står P, og det er Last Used CPU. Så det er på en måte en statistikk på", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0004", "start": 635.48, "end": 819.18, "token_count": 598, "text": "Nå tastes det F i topp. Da kan vi styre hvilke kolonner som brukes. Hvis man blar nedover her, så vil man se... Her er det en kolonne som heter Last Used CPU. Hvis jeg nå taster Space her, så får jeg et merke på den. Og Escape går nå tilbake. Og da... Vil jeg se... hvis jeg lager vinduet litt større... Så vil jeg se at ytterst her så kommer det en kolonne hvor det står P, og det er Last Used CPU. Så det er på en måte en statistikk på hvilken CPU ble sist brukt av prosessene som listes. Hvis jeg nå starter regnejobben på nytt, så ser vi at det er... Den kjører på SUP1. Og den prosessen med den i den kjører på null. Så kan vi se det hender de bytter om, men stort sett sånn som nå, så kjører de hele tiden på samme SUP1. Så kan man spørre seg hva det er som skjer hvis jeg nå kjører tre SUPU-er? Det skjedde med to CPU-er. Kan ta det en gang til eksplosivt. Når jeg har to CPU-er, så er på en måte ikke dette multitasking, fordi de kjører på to forskjellige CPU-er. Så de kjører reelt sett samtidig. Multitasking er når de bytter på på samme CPU-er. Så dette er SMP - Simultaneous Multiprocessing. Men SMP, da kjører man samtidig på to forskjellige regneenheter. To forskjellige kjerner, eller CPU-er. Eller course. Så én core er da én regneenhet. Jeg sier ofte CPU, så da mener jeg én regneenhet. Vi kan jo ha mange cours inne på én CPU. Men sånn i... Hvis jeg sier CPU uten å spesifisere noe, Og spesielt så tenker jeg på en core, eller en enkelt rein enhet. Og det er det også OS og Topp rapporterer det som. Så da kan vi prøve å kjøre... Skal vi se... Hvor var vi? Ja, den forløkken. Én, to. Så kan vi prøve å øke den forløkken til tre. Sånn at vi kjører tre prosesser samtidig. Og da ser vi... Da får de plutselig ikke 75 %, men de får noe sånn som 67 %.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0005", "start": 780.0, "end": 947.36, "token_count": 591, "text": "Og spesielt så tenker jeg på en core, eller en enkelt rein enhet. Og det er det også OS og Topp rapporterer det som. Så da kan vi prøve å kjøre... Skal vi se... Hvor var vi? Ja, den forløkken. Én, to. Så kan vi prøve å øke den forløkken til tre. Sånn at vi kjører tre prosesser samtidig. Og da ser vi... Da får de plutselig ikke 75 %, men de får noe sånn som 67 %. Eller da to tredjedeler. Og da ser vi at her bytter... Her er det i hvert fall én av prosessene som bytter hele tiden. For noen ganger kjører begge på én, og andre ganger kjører begge på null. Og den måten å gjøre dette på, det er fair scheduling. Den som fordeler hvilke prosesser som kjører hvor. Den heter Fair Scheduler, og den prøver å gi så lik CPU-tid til alle prosesser som mulig. Her er det tre stykker som hele tiden vil ha CPU. Da fordeler den det ved at hele tiden kjører det en på hver av CPU-ene. Så bytter man på hvilken av de tredje som kjører. Det byttes ganske ofte, noen ganger i sekundene. Men ikke hele tiden, for det koster en del å bytte fra... Men på den måten så ser vi at alle de prosessene, de bruker omtrent like lang tid. Men du ser, det er litt forskjell. 25 på den ene og 26,5 på den andre og 26,7 på den tredje. Men sånn, røft sett, så prøver man å gi like mye CPU til hver. Og sånn kan vi fortsette. Vi kan prøve å se hvordan dette her ser ut på... På en maskin med fire sepur. Og det jeg skal gjøre i bakgrunnen da, det er å jukse litt. Ved å skru på noen sepur i bakgrunnen. På den Linux-maskinen så kan jeg gjøre det fra kommandolinja. Jeg må riktignok være Ruth, men jeg kan aktivere sepur. Det jeg gjorde i bakgrunnen nå... Jeg skal se på hvordan jeg gjør det senere. Det var å aktivere to til av CPU-ene, sånn at jeg skulle ha fire. Da må jeg gå inn og ut igjen med topp.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0006", "start": 905.76, "end": 1099.76, "token_count": 595, "text": "Og det jeg skal gjøre i bakgrunnen da, det er å jukse litt. Ved å skru på noen sepur i bakgrunnen. På den Linux-maskinen så kan jeg gjøre det fra kommandolinja. Jeg må riktignok være Ruth, men jeg kan aktivere sepur. Det jeg gjorde i bakgrunnen nå... Jeg skal se på hvordan jeg gjør det senere. Det var å aktivere to til av CPU-ene, sånn at jeg skulle ha fire. Da må jeg gå inn og ut igjen med topp. Hvis jeg taster én nå, så ser vi øverst her. Jeg tastet én, og da får jeg ut at nå har denne serveren her fire CPU-er. Og hvis jeg nå kjører akkurat samme med tre regnejobber, så ser vi at da kommer de tre regnejobbene i gang. Og så får de nå hver sin CPU. Hvis jeg legger inn \".Last Used CPU igjen... Så starter vi på nytt, for det var ferdige.Så ser vi... Vi ser at nå så står de på 3, 2 og 1. Vi kan vel også se at de står fast der. Stort sett... Den som slutter på 29, står på 3. Ja, 29. Den er på 3 fortsatt. 29, ja... Stort sett, hvis det ikke er noen grunn til det, så blir de stående og kjøre på den samme. Men da kan vi gjøre tilsvarende.  Hva skjer nå om vi kjører fem og kanskje seks seppuer? Nei... Vi kjører seks prosesser på denne maskinen som bare har fire seppuer. Og da ser vi at da blir det altså firedel på seks. Det blir to tredjedeler seppukapasitet på hver. Omtrent 67 %. Det varierer litt opp og ned, men sånn ca. 67 %. Og så bytter man hele tiden på prosessene. Og hvis jeg kjører 5, så får de noe sånt som... Ca. 80 % burde det bli. Men her ser vi... Man kan se det varierer litt. Øverst er det alltid én med... Men hvis du ser på totaltiden, så blir den omtrent lik til slutt. Hvis du ser på totaltiden her, så ligger det rundt sånn 21... Litt forskjelligre blir det, men i utgangspunktet så prøver operativstemme å fordele tiden likt.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0007", "start": 1059.28, "end": 1286.8, "token_count": 598, "text": "Og hvis jeg kjører 5, så får de noe sånt som... Ca. 80 % burde det bli. Men her ser vi... Man kan se det varierer litt. Øverst er det alltid én med... Men hvis du ser på totaltiden, så blir den omtrent lik til slutt. Hvis du ser på totaltiden her, så ligger det rundt sånn 21... Litt forskjelligre blir det, men i utgangspunktet så prøver operativstemme å fordele tiden likt. Ja... Det er noen spørsmål i chatten her. Funkerer ikke for meg med å taste F. Topp oppdaterer seg ikke. Hva kan være årsaken? Det er litt vanskelig å si. Men hvis man prøver å kjøre dette her på Linux-VM-en f.eks. Så skulle... Så skulle det gå. Vi kan... Vi kan prøve. Hvis jeg nå går inn som... Group 99 at OS... Nei, jeg er ikke 99. 100 er jeg. Group 100. Sånn er jeg på Linux-VM og vi kjører topp. Hvis jeg taster F der, så ser det ut som det... Så ser det ut som det fungerer. Selv om jeg nå ikke ser... Last used CPU-er... Jo, den var her. Og... Ja, her ser vi... Her er det mange... Mange CPU-er. 48 står det her. Og den er faktisk 40... eller 92. Men hver container får ikke full tilgang til CPU-ene. Det skal vi se på litt senere. Men opplegget er det samme. Her er det dokkercontainere. Så det er et nivå til, så de kan fordeles CPU-tid av dokker-enginer som styrer disse containerne. Men iallfall... Det ser ut som på... Så kan man taste F og så få opp det man ønsker. Et annet spørsmål som er... Én reinhet er én alu. Ja. Én reinhet er én alu. Og spesielt når man regner heltallsoperasjoner, så er det en alu. Men der kan det være altså én alu per core, eller reinenhet. Så hvis man har flytall, så har man gjerne en egen regneenhet som regner flytall. Og den... Det hender det er forskjell på om man har én alu og én flytallsregneenhet. Det hender det er forskjell. At man liksom har et...", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0008", "start": 1237.88, "end": 1435.8, "token_count": 589, "text": "Én reinhet er én alu. Og spesielt når man regner heltallsoperasjoner, så er det en alu. Men der kan det være altså én alu per core, eller reinenhet. Så hvis man har flytall, så har man gjerne en egen regneenhet som regner flytall. Og den... Det hender det er forskjell på om man har én alu og én flytallsregneenhet. Det hender det er forskjell. At man liksom har et... Inni en CPU at man har to ALU-er og én flytallregneenhet. Det varierer. Men når jeg snakker om det, så når jeg sier én CPU eller én core, så tenker jeg på én ALU som gjør enkeltoperasjonen. Vi kommer tilbake til det senere i dag når vi skal se på multitreading. For da deler man på å bruke den samme ALU-en innenfor en core. Men mer om det senere. Ok. Det var multitrening. Så hvis det ikke er noen spørsmål om noe rundt det... Det er en del oppgaver som må gå på akkurat dette her. Så hvis dere ikke har gjort det ennå, så må dere prøve dere på egen hånd i dag og gjøre oppgaver med multitrening. Det kan være litt vanskelig å tolke de oppgavene når vi kjører på de virtuelle maskinene. For der er det... Siden vi har en oppgave, kan vi si litt mer om det. Som vi så her, så var det veldig mange CPU-er. Her kjører jeg topp i gruppe 100. Det er ikke så mange prosesser her. Men det er alle prosessene som kjøres på den lokale containeren. Her er det inne som RUT også, så jeg kjører noen RUT-prosesser. Men LSCPU viser hvor mange... Eller viser litt info om systemet. Her vil vi se at vi har 96 CPU-er. Men! Hver enkelt VM, eller hver enkelt container, får ikke tilgang til alle CPU-ene. Det kunne i prinsippet gjort, men sånn som jeg har startet opp, så har jeg gitt hver VM tilgang til det som tilsvarer to CPU-er. Så hvis dere kjører to regnprosesser, så vil det si at de får 100 % CPU. Hvis du kjører tre, så får de bare to til.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0009", "start": 1400.08, "end": 1586.98, "token_count": 594, "text": "Her vil vi se at vi har 96 CPU-er. Men! Hver enkelt VM, eller hver enkelt container, får ikke tilgang til alle CPU-ene. Det kunne i prinsippet gjort, men sånn som jeg har startet opp, så har jeg gitt hver VM tilgang til det som tilsvarer to CPU-er. Så hvis dere kjører to regnprosesser, så vil det si at de får 100 % CPU. Hvis du kjører tre, så får de bare to til. Akkurat som på en fysisk maskin med to CPU-er. Men dette blir fordelt av Docker Engine, og den gjør det litt annerledes. Så hvis man lister hvilke prosessorer de kjører på, f.eks., så vil man se at de ligger på forskjellige prosessorer. Også hvis du kjører tre stykker, så ligger de på tre forskjellige. Det er da Dukker Engine som fordeler tiden. Vi kommer litt mer tilbake til det etter hvert også, men dette er en oppgave òg. Den er... Dere har jo ikke full oversikt siden dere ikke ser den fysiske serveren. Så den oppgaven er litt vanskelig, å se hva det er som egentlig skjer. Men det dere kan gjøre, er å bare teste ut hvor mye superhjul får jeg, hvor lang tid tar de forskjellige jobbene. Men ha det i bakhodet at dette er Litt mer komplisert enn om det var på en fysisk maskin. Ok. Da skal vi gå litt videre. Og så skal vi se på internminne og cash. Vi skal fortsatt se på mikroarkitektur og datamaskinarkitektur og multitasking. Hvordan... Multitasking foregår. Men for å forstå multitasking er det viktig å forstå hva cash er, og hvordan internminnet opererer sammen med CPU-en. Vi har sett på internminnet tidligere. I simulerings-CPU-en vår så vi hvordan vi hadde egne instruksjoner som flytter data fra registeret og ut i internminnet. Den store problemstillingen med RAM og CPU er at RAM er relativt tregt. CPU utfører instruksjoner veldig mye raskere enn de kan hentes fra RAM. Det er kanskje en faktor ti. Og hvis man ikke gjorde noe med det, så måtte CPU-ene så vente hele tiden på data. Instruksjoner må hentes fra RAM.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0010", "start": 1543.38, "end": 1729.98, "token_count": 588, "text": "I simulerings-CPU-en vår så vi hvordan vi hadde egne instruksjoner som flytter data fra registeret og ut i internminnet. Den store problemstillingen med RAM og CPU er at RAM er relativt tregt. CPU utfører instruksjoner veldig mye raskere enn de kan hentes fra RAM. Det er kanskje en faktor ti. Og hvis man ikke gjorde noe med det, så måtte CPU-ene så vente hele tiden på data. Instruksjoner må hentes fra RAM. Et program som kjøres. Alle institusjonene ligger i RAM. Og for å kjøre dem, må de hentes inn fra RAM. Og hvis det går mye saktere enn den tiden det tar ut fra en institusjon, så hoper det seg opp med institusjoner, og det går ikke så fort som Sepund egentlig kan kjøre. Og det er der cash kommer inn. Cash er egentlig fransk og betyr et hemmelig lager. Mellom ram og CPU. Og kanskje er et veldig hurtigram, så vi skal se - er det SRAM? Det er akkurat samme teknologi som det er i registrene. Så vi legger egentlig på et digert lager med ekstra registre. Men de er ikke registre i den betydning at CPU-en oppfatter dem som... De er bare mellomlagring av data fra RAM på vei inn til CPU-en og på vei ut fra CPU-en. Hele prinsippet med at det hjelper å få et hurtiglager mellom RAM og CPU, er at statistisk sett, når man utfører institusjoner, så... ... så bruker man bare en liten del av minnet. Altså... Det er en liten del av institusjonene som statistisk sett utføres om og om igjen. Og ofte er det også sånn at man bruker om og om igjen data i ramm som ligger ved siden av hverandre, f.eks. i et RAI. Så dermed er det mye tid å spare hvis man henter mange biter av gangen og mellomlagrer i cash. Vi skal se på etterpå hvordan det ser ut sånn rent fysisk. Minnepyramiden er et viktig prinsipp. Og prinsippet her er at vi har forskjellige enheter som lagrer data. Og som er koblet til en CPU. Og her er det veldig stor forskjell på hvor lang tid det tar å hente dataene.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0011", "start": 1687.46, "end": 1870.08, "token_count": 595, "text": "som ligger ved siden av hverandre, f.eks. i et RAI. Så dermed er det mye tid å spare hvis man henter mange biter av gangen og mellomlagrer i cash. Vi skal se på etterpå hvordan det ser ut sånn rent fysisk. Minnepyramiden er et viktig prinsipp. Og prinsippet her er at vi har forskjellige enheter som lagrer data. Og som er koblet til en CPU. Og her er det veldig stor forskjell på hvor lang tid det tar å hente dataene. Vi ser vi har registrene øverst i minnepyramiden. De er de raskeste. Bruker kortest tid på å hente data til aluen. For det er jo registrene som er koblet til aluen. Så der går det lynkjapt. Og så har man noen lag med cash. Her har jeg L1-cash og L2-cash. De fleste moderne CPU-er har L3-cash også i tillegg. Som da går litt saktere. Men teknologien her er den samme. Dette er S-ram. De er veldig hurtige, men det er større mengde. Vi har flere megabyte med L2-cash, og det tar da litt tid å frakte det inn til registrene. Så derfor går det litt lengre tid. Så kommer man ned til ram. 480 gigabyte. Vi kan ha 1000 gigabyte også av ram. Men hovedpoenget er at det går omtrent en faktor ti saktere å hente inn data fra ram. Så det er derfor man bruker det mellomlageret her. For å mellomlagre det som hentes fra RAM, sånn at det kommer raskere inn til registrerne. Vi skal se på hvordan det kommer raskere inn. Senere i kurset skal vi se på harddisker også. Helt eneste her er HDD disk... Hardware drive. Som er en tradisjonell disk. Og den er et proposal. Platelager med disker som fysisk snurrer rundt, sånn som CD-er. Og... her har vi SSD, Solid State Disc, som vi ser røfflig, i hvert fall når du skal hente en vilkårlig... ... en vilkårlig bite på disken. Riktignok henter du gjerne 512 av gangen. Bite på disken. Så går SSA-disk mye raskere, for her er det ikke noen fysiske plater som snurrer rundt. Det er mer som sånn minne på minnepinner.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0012", "start": 1835.8, "end": 2002.64, "token_count": 594, "text": "Og... her har vi SSD, Solid State Disc, som vi ser røfflig, i hvert fall når du skal hente en vilkårlig... ... en vilkårlig bite på disken. Riktignok henter du gjerne 512 av gangen. Bite på disken. Så går SSA-disk mye raskere, for her er det ikke noen fysiske plater som snurrer rundt. Det er mer som sånn minne på minnepinner. Men likevel så er det en Factor 1000 saktere enn RAM, så det går fortsatt veldig sakte, men det går vesentlig raskere enn fra harddisk. Ja, det er noen spørsmål om SSA-disken, om det... Ja, vi kommer tilbake til det. Senere, men det er en del andre begrensninger med SSD. Altså hvordan du kobler den opp til maskinen. Hva slags buss du har ut til SSD-en. Det har også en del å si. Men med sånn optimal tilkobling på begge, så kan det være en fakta på 1000. Men mer om det senere, når vi skal snakke om disker.  ESRAM og DERAM. CPU-registrene og cash er laget av ESRAM. ESRAM består av seks damasthistorier for hver bytt som lagres. Det var det vi bygde opp møysommelig tidligere i datamaskinarkitektur. At vi satte sammen and-er og -årer, og så lagde vi noen løkker tilbake og noen not-porter, og så klarte vi å lage en liten krets. Som lagret ett bit. 1.01-er. Men vi trengte da seks transistorer for å få det til. Mens DRAM, eller Dynamic Rum, er en mye enklere teknologi. Det består bare av én transistor og en kapasitator. En kapasitator er en bitte liten device som lagrer en liten elektrisk ladning. Så er det så enkelt at hvis den har ladning, så er den én. Hvis den ikke har ladning, så er den null. Deram er da mindre og mye billigere å lage enn SRAM. Men det største problemet er at den er ikke like hurtig. Og i tillegg må det lades opp på nytt ti ganger i sekundet. Og Deram er da, i motsetning til disker, altså flash-minne og harddisker, så forsvinner alt som er lagret i Deram.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0013", "start": 1972.72, "end": 2154.68, "token_count": 594, "text": "Så er det så enkelt at hvis den har ladning, så er den én. Hvis den ikke har ladning, så er den null. Deram er da mindre og mye billigere å lage enn SRAM. Men det største problemet er at den er ikke like hurtig. Og i tillegg må det lades opp på nytt ti ganger i sekundet. Og Deram er da, i motsetning til disker, altså flash-minne og harddisker, så forsvinner alt som er lagret i Deram. Så når du skrur på en datamaskin, så står DRAM og lades opp på nytt hele tiden for at man skal beholde den nullen eller eneren. Nullen er lett å beholde, men eneren må helt innlades. Siste versjon av DRAM er DDR5 SDRAM. Double Data Rate Generation 5 Synchronous Dynamic Gram. Det er vel ikke brukt i noen stor grad ennå. Det er det det er fire som er foreløpig det mest vanlige, som kom i 2016 eller noe sånt. Men igjen, prinsippet er det samme, men all utviklingen går da på å få ting til å gå enda litt fortere. Ellen og L2 Cash. Denne figuren viser prinsippene for cash. Hvorfor man kan få til å kjøre programmet fortere ved å bruke cash. Helt til venstre på figuren her så ser vi CPU-en. Her står det R0R1R2 etter det. Det kunne satt AXBCXX også. Det er da registrene inni CPU-en. Og disse brukes da hele tiden til å mate oss inn i alun. Den kan kverne institusjoner fortere enn RAM kan levere det. Og dermed så legger vi til dette L1 og L2-cash. Som sagt, mange har L3-cash også inne på skipen, av moderne prosessorer. Men prinsippet er det samme. Så L1-cash er litt mindre. Men vi ser her i stedet for de fire... Her er det ikke bite engang, men det er fire bit. Men la oss si det er bite som skal inn i registrene. De fire bitene får plass i registrene. Og da kunne det være at CPU-en gjør en instruksjon som sier 'hent bite nummer to' her. Opprinnelig så var CPU-en sånn at OK, bite nummer to... Da går vi ut i ram og henter bite nummer to, som er den 1.101 som ligger her oppe,", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0014", "start": 2112.2, "end": 2264.18, "token_count": 592, "text": "Så L1-cash er litt mindre. Men vi ser her i stedet for de fire... Her er det ikke bite engang, men det er fire bit. Men la oss si det er bite som skal inn i registrene. De fire bitene får plass i registrene. Og da kunne det være at CPU-en gjør en instruksjon som sier 'hent bite nummer to' her. Opprinnelig så var CPU-en sånn at OK, bite nummer to... Da går vi ut i ram og henter bite nummer to, som er den 1.101 som ligger her oppe, og så sender vi den inn igjen. Men på den tiden var det ikke noen forskjell på CPU og ram, så det fungerte greit. Men etter hvert så har CPU-en løpt ifra og blitt raskere enn ram. Og da, i stedet for å bare hente den ene biten der ute i ram, så når man da henter noe i ram, så tar man like godt med et stort område. I nærheten av den biten man skal hente. Og så legger man... Så legger man det i L2-cash. Hele den, så mye man får plass til. Og det varierer. Og cashing, det styres på Hardner-nivå. Så dette er ikke noe som operativsystemet går inn og styrer. Så vi kommer ikke til å se på sånn i detalj nøyaktig hvordan algoritmene for dette er. Det styres på hardware-nivå. Som operativstem får du ikke gjort så mye med hvordan cash virker. Men iallfall i prinsippet så virker det sånn at du tar med en stor bit av gangen, og så tar du med en litt mindre bit som får plass i LN-cash, og så, inntil CPU-en, så tar du de nærmeste bitene. Men som sagt, så er det statistisk sett, så er det veldig ofte at man trenger... Bites, eller data som ligger i nærheten av hverandre. Dette kan f.eks. være institusjoner som ligger rett etter hverandre. Og da er det ofte at man hopper fra institusjon 1 til 2 til 3 til 4 osv. Og da, hvis man gjør det, så vil jo alle de institusjonene ligge her i LNCash. Og da går det veldig kjapt å hente de over til CPU. Andre ganger så er det kanskje et stort RA som ligger i ramm.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0015", "start": 2238.88, "end": 2385.24, "token_count": 589, "text": "Bites, eller data som ligger i nærheten av hverandre. Dette kan f.eks. være institusjoner som ligger rett etter hverandre. Og da er det ofte at man hopper fra institusjon 1 til 2 til 3 til 4 osv. Og da, hvis man gjør det, så vil jo alle de institusjonene ligge her i LNCash. Og da går det veldig kjapt å hente de over til CPU. Andre ganger så er det kanskje et stort RA som ligger i ramm. De dataene du jobber med. Og da er det den samme fordelen. Jo, da... Ofte så skal du ha neste R-element. Og når du henter ut det, så går det raskt fordi du har hentet det inn i LN-cash. Og det skal vi teste ut senere når vi skal se på ramm. Hvordan er forskjell på f.eks. hvordan man indekserer en matrise. For i noen tilfeller så hopper man rundt i ramm og henter. I andre tilfeller så henter man ramm data som ligger rett etter hverandre i ramm. Og det går alltid mye raskere. Så dette er hovedprinsippet. Dette viser det man kan kalle mikroarkitekturen for L1 og L2-cash. Igjen så er det som sagt vanlig å ha en eldre cash, men i prinsippet så er den tilsvarende som level 2-cash. Her ser vi at L1-cash den har en litt spesiell arkitektur. Her står det LN Data og LN Instruksjoner. Det betyr at her er det to forskjellige veier inn til CPU-en. Det er dette som gjør at man kan si... Dette er egentlig ikke noen van Neumann-arkitektur, hvor både datainstruksjoner går på den samme bussen. Det vil si det er van Neumann-arkitektur inn hit, og så, den siste biten, så er det Harvard-arkitekturen. Hvor man da deler opp. Institusjonene kommer inn på... På én buss eller en rute inn til CPU-en. Og datakomera på en annen. Så ser vi altså at vi har en tredje bit. TLB Translation Look-Aside Buffer. Og det er... Nå skal vi komme tilbake til senere. Det er minneadressering. Det er en... Det bruker MMU.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0016", "start": 2347.52, "end": 2443.12, "token_count": 305, "text": "Det vil si det er van Neumann-arkitektur inn hit, og så, den siste biten, så er det Harvard-arkitekturen. Hvor man da deler opp. Institusjonene kommer inn på... På én buss eller en rute inn til CPU-en. Og datakomera på en annen. Så ser vi altså at vi har en tredje bit. TLB Translation Look-Aside Buffer. Og det er... Nå skal vi komme tilbake til senere. Det er minneadressering. Det er en... Det bruker MMU. Og MMU virtualiserer minneadressene, sånn at CPU-en ikke trenger å vite nøyaktig hvor i RAM enhver bite ligger. Det kommer vi tilbake til senere, men det er også veldig viktig for effektivitet at det er hurtig. Så derfor så er det en egen bit av LNCash som er satt av til TLB, eller minneadressering. Da skal vi se generelt på multitasking og multiprosessing. Men jeg ser at tiden er mye her nå, så vi trenger en pause. Så da tar vi 15 minutter pause derfra. Da starter vi 09.31. Som vanlig, still gjerne spørsmål i chatten i pausen.", "source": "lecture"}
