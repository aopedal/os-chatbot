{"lecture_id": "os8del3", "chunk_id": "os8del3_0000", "start": 0.0, "end": 173.16, "token_count": 596, "text": "Ok. Da skal vi se på hvorfor ikke en prosess kan utnytte to CPU-er. Og problemstillingen her er nå spesielt det at man tenker at OK, her har jeg en... Det kan være en regnejobb, typisk, som bruker mye CPU. Og nå vil jeg kjøre den på en svær server som har 96 CPU-er. Og da gå fantastisk fort. Men det er ikke så lett å utnytte flere parallelle CPU-er. Flere forskjellige samtidige renhentede enhenter. Og det er som regel fordi at... Én prosess er ett dataprogram som skal kjøres. Det er som vi ser på denne illustrasjonen her. Det er at det er instruksjoner etter hverandre som bare står og kjører om og om igjen. Og for det første så vet ikke operativsystemet noe om hva som foregår inni denne koden. Den ser bare instruksjoner, og den sier til CPU-e. Sett i gang, kjør disse instruksjonene. Operativsystemet kan ikke vite noe om hva som egentlig foregår her. Det er det programmereren som het. Så derfor er det veldig vanskelig å gjøre noen fordeling her. Operativsystemet kan ikke si at OK, CPU1, du gjør instruksjon 1, 2, 3, og CPU2, du gjør 4 og 5. I prinsippet kunne man gjøre det, men da måtte man flytte hele prosessen fra CPU1 og over på CPU2. Hver gang du gikk fra 3 til 4. Og det ville bare... Det ville bare ta veldig mye tid. Så her er det på en måte opplagt at disse institusjonene må kjøre på samme CPU. For hele tiden er man avhengig av hva som skjedde i forrige institusjon. Man kan ikke kjøre dette uavhengig på en annen CPU. Og det vi ser her, er en veldig enkel implementasjon av... I Bonacci-rekken først legger du én inn i AX og én inn i BX. Og så på ledd 3 så ser du legg til AX til BX. Så da blir BX 2, og AX er fortsatt 1. Og så hopper du til neste ledd. Legg til BX til AX. Da legger du 2 pluss 1 er 3, så da blir AX 3. Og så hopper du opp til 3 igjen. Og sånn fortsetter det.", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0001", "start": 146.8, "end": 314.08, "token_count": 589, "text": "Og det vi ser her, er en veldig enkel implementasjon av... I Bonacci-rekken først legger du én inn i AX og én inn i BX. Og så på ledd 3 så ser du legg til AX til BX. Så da blir BX 2, og AX er fortsatt 1. Og så hopper du til neste ledd. Legg til BX til AX. Da legger du 2 pluss 1 er 3, så da blir AX 3. Og så hopper du opp til 3 igjen. Og sånn fortsetter det. Da blir BX lik 2 pluss 3 er 5. Og så på neste så blir AX lik... Tre pluss fem er åtte, og så... og så videre. Ja. Jeg ser forresten den Fibonacci-rekken her. Den så ikke veldig riktig ut. Én, én, to, tre, fem, skulle stå der, og åtte. Det blir et problem for oppgavene. Hva er feil i denne Fibonacci-rekken? Men hovedpoenget er at man kan ikke... Utnytte to eller hundre prosessorer når du bare har ett program som kjører sånn som dette her... Det må kjøres sekvensielt. Det vi kunne få til, er hvis man som programmerer kan skrive kode som kan kjøres i parallell. Men det er opp til programmereren. Hvis programmeren kan klare å få til... Splitte opp denne koden, sånn at den kan kjøre på to steder samtidig, gjøre noen milliarder institusjoner på hvert sted, og så slå sammen resultatene. Da kan man utnytte to eller flere prosesser. Men i de fleste tilfeller så er det vanskelig. Og i et sånt tilfelle som dette her, hvor alt avhenger av forrige to-tre institusjoner, så vil det ikke være mulig å utnytte flere. Men i noen tilfeller så har man parallelliserbar kode. Og vi tenker oss et enkelt tilfelle sånn som dette her... At vi skal legge sammen en stor sum. Vi skal telle fra 1 pluss 2 pluss 3 pluss 4 opp til 2000. Nå er det klart. I akkurat i dette tilfellet så fins det en formel. Utled en formel som gir svaret her, som er 1 ganger 1 pluss 1,5, er det vel? Men det er jo ikke poenget. Poenget er at her skal vi gjøre", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0002", "start": 278.64, "end": 447.92, "token_count": 591, "text": "Og vi tenker oss et enkelt tilfelle sånn som dette her... At vi skal legge sammen en stor sum. Vi skal telle fra 1 pluss 2 pluss 3 pluss 4 opp til 2000. Nå er det klart. I akkurat i dette tilfellet så fins det en formel. Utled en formel som gir svaret her, som er 1 ganger 1 pluss 1,5, er det vel? Men det er jo ikke poenget. Poenget er at her skal vi gjøre en lang regneroperasjon. Vi skal gjøre den på denne måten. Og dette er da kode som opplagt er parallelliserbart. For da, hvis vi har en oppgave som er på denne måten her... Så kan vi f.eks. dele dette i to. Én CPU kan regne ut summen fra 1 til 1000, og en annen CPU kan regne ut summen fra 1001 til 2000. Og så, etterpå at de to prosessene er ferdig, så kan man slå sammen resultatet, og så får man totalsummen. Og dermed har man klart å parallellisere koden, og dermed kan man utnytte flere CPU-er. Hvis man bare kjører et C-program som lager denne summen her... Og overleverer det lasteren i RAM og ber operativsystemet om å kjøre, så aner ikke operativsystemet noe om hva alle disse institusjonene i denne summen gjør. Så operativsystemet selv er overhodet ikke i stand til å utnytte at det har 48. Det går bare ikke, så man kan ikke forvente at operatørsystemet skal kunne sørge for at man utnytter alle CPU-ene. Og da er det programmereren selv som må sørge for parallellisering. Og da kunne man løse dette her med to prosesser eller to tråder. Og tråder skal vi se på mye senere i detalj. Vi skal se på ja. og P-treads i C, som vi da kan sette opp for å gjøre ting i parallelt. Vi har vel egentlig delvis sett på det når vi har gjort regnejobber i parallelt også. Da er det en sånn type regnejobb. Så setter vi opp akkurat like regnejobber på fire CPU-er ved å bare starte fire bæsjscript samtidig. Det vi ikke har gjort, er at vi ikke har slått sammen ressurser.", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0003", "start": 413.84, "end": 592.96, "token_count": 539, "text": "Og tråder skal vi se på mye senere i detalj. Vi skal se på ja. og P-treads i C, som vi da kan sette opp for å gjøre ting i parallelt. Vi har vel egentlig delvis sett på det når vi har gjort regnejobber i parallelt også. Da er det en sånn type regnejobb. Så setter vi opp akkurat like regnejobber på fire CPU-er ved å bare starte fire bæsjscript samtidig. Det vi ikke har gjort, er at vi ikke har slått sammen ressurser. Men det er en liten detalj som man kan få til. Et eksempel på når dette kan være nyttig, er passordkracking. Det var en student som syntes at den passordkrakking-algoritmen gikk litt tregt. Den tok jo over to minutter på studiesesong. At den klarte å dele opp... Dele opp det problemet i åtte like biter og utnyttet da de åtte sekundene som var på PC-en. Og passord-cracking er typisk et problem som er parallelliserbart. Men hvis vi da setter i gang en skript som kjører gjennom alle de 17 000 passordene eller hva det er... Så kan ikke operativsystemet forstå dette her. At... Oi, dette her er jo parallelliserbart. Så intelligent er ikke operativsystemet. Det finnes noen kompilatorer som kan automatisk parallellisere på den måten. Så noen automatiske måter finnes det. Men stort sett så er det da programmereren som må se.  På hver CPU så kan jeg kjøre gjennom ett antall passord. Så fordeler jeg de jobbene likt. Og det er først da man kan virkelig utnytte at man har mange CPU. Og dette er viktig å kunne, for veldig ofte så kan man nå kjøre på servere som har mange CPU-er. Og da kan det være viktig å ha kode som utnytter... Hvis det er CPU-avhengig kode som man ønsker skal kjøre fort. Så dette er problemstillinger man ofte kommer ut for hvis man koder og er utvikling. Men det vi ser på, er liksom de prinsipielle delene av dette.", "source": "lecture"}
