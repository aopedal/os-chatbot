{"lecture_id": "os14del2", "chunk_id": "os14del2_0000", "start": 0.0, "end": 174.1, "token_count": 515, "text": "Det aller viktigste å ha med seg er at internmelding eller RAM, det er da bare en rekke med bite som ligger etter hverandre. Og RAM... Random Access Memory, det er random fordi det skal ta like lang tid å hente et hvilket som helst bitt. Spesielt pga. cash, så vil vi se at det tar forskjellig tid å hente forskjellig bit. Det skal vi se på i detalj i dag, i praksis. Videre så vi mye på MMU, Memory Management Unit. Og det er da en hardware-enhet som oversetter adresser. For alle prosesser har sitt eget adresseråk. Den starter fra null og går oppover. Og dette kalles da virtuelle adresser. Og de virtuelle adressene oversettes til fysiske adresser av MMU. Så inni selve prosessen tenker den bare på adresser fra null til én gigabyte. Men de oversettes til fysiske adresser i RAM.  Og da kan minneadressering nummer 1000 f.eks. Den kan ligge i 14 367 000 i ramm. Og dette gjør at operativsystemet da dynamisk kan laste inn og ut sider av ramm, og ikke minst laste inn og ut prosesser etter hvert som det kommer nye prosesser. Og dette er helt nødvendig for et moderne operativsystem. For å kunne håndtere minnene på en ordentlig måte. Så vi så mye på det, og på PageTableEnters, som var da den minste enheten som viser hvor en side ligger. Så det man gjorde, var istedenfor bare å se på bite for bite, så lagde man sider. Typisk 4K, 4000 bite. En sånn passe side, som er da den minste enheten som man tar inn og ut av, da. I tillegg så vi på TLB. Translation Look-Aside Buffer. Det er da cash for minneadressering, og som også har en stor effekt på hvor fort ting går. Heldigvis ligger stort sett minneofflag i TLB. Man får mye treff i cash, og dermed så går det veldig mye raskere enn det ellers ville gjort.", "source": "lecture"}
