{"lecture_id": "os6del5", "chunk_id": "os6del5_0000", "start": 0.0, "end": 189.08, "token_count": 589, "text": "Aller først, branch prediction. Branch prediction er en slags konsekvens av det vi så på forrige gang. At vi bruker, for det første, pipelining. Pipelining er at man deler én institusjon. Da tenker vi på en sånn institusjon. Som ADD AX til svar... Altså legge til verdien i registeret AX til svar i RAM. Denne operasjonen... I maskinkode så er det én maskininstitusjon. Men denne deles opp i mange mikroinstitusjoner. Først hentes den din, så dekodes den... Så deles den opp i små deler og utføres, for det er flere ting som skulle gjøres. Man må hente inn verdien fra RAM inn i et temporært register. Så må man legge til. Og så må det resultatet legges ut igjen, akkurat som vi gjorde i simulerings-CPU-en. Vi må på et eller annet tidspunkt ta verdien i et register og legge ut i RAM når man gjør en sånn operasjon. Alt dette brytes da ned i... Mange små mikrooperasjoner. Som typisk for Intel kan det være 14 sånne operasjoner. Pipelining, da... Når vi starter på en institusjon som har 14 deler, så venter vi ikke med å få gjort alle de 14 delene ferdig. Vi begynner på neste del. Neste institusjon... Med en gang den første institusjonen er gjort, så begynner vi på... Den første instruksjonen for den instruksjonen som kommer etter i pipeline. Sånn at i praksis så kjøres ting delvis parallelt. Og i tillegg så har man superskalaarkitektur. Hvor det faktisk virkelig går parallelt. Og da kan det være flere samtidige institusjoner som går inn... Som kommer i en pipeline delt opp i 14 biter. Men så vil da hver av de små bitene... De kan kjøres helt samtidig. Altså institusjonen som er fem institusjoner etter den første, den kan kjøres samtidig. Og dette går veldig fint hvis institusjonene er uavhengige av hverandre. Altså hvis det ikke er noen direkte sammenheng. Men i noen tilfeller så er det en sammenheng, og det viktigste til... ... som du da har i Fawlucker og Violen... Hele tiden så har man branching.", "source": "lecture"}
{"lecture_id": "os6del5", "chunk_id": "os6del5_0001", "start": 153.5, "end": 329.7, "token_count": 584, "text": "Men så vil da hver av de små bitene... De kan kjøres helt samtidig. Altså institusjonen som er fem institusjoner etter den første, den kan kjøres samtidig. Og dette går veldig fint hvis institusjonene er uavhengige av hverandre. Altså hvis det ikke er noen direkte sammenheng. Men i noen tilfeller så er det en sammenheng, og det viktigste til... ... som du da har i Fawlucker og Violen... Hele tiden så har man branching. Typiskvis hvis du har en if-test, så er det en branch. Hvis svaret er true, så går det den ene veien. Hvis det er folk, så går det den andre veien. Og det vet man ikke før man kommer dit. Det blir da plutselig et problem med en sånn branching når systemet allerede er i gang med å... Utføre neste institusjon... Det største problemet er at man kunne løst det ved å... Hvis man kom til en bransje, så bare stoppet man helt. Pipelining og superskalære... Altså å kjøre mikroinstitusjoner i reell parallellitet, med parallellitet. Altså kjøre de helt samtidig. Man kunne skru det helt av. Men da ville ting gå... Mye saktere. Så det man prøver på da, er å gjette. Man gjetter hvilken bransje som skal kjøres, og så bare sier man sånn... Ja, tidligere så har det ofte... Har disse testene blitt true når programmet ble kjørt. Så vi gjetter at det blir true igjen. Og så hiver man alle institusjonene i den bransjen som om den testen... Hvis da testen ikke slår til, og man har gjettet feil, hva skjer da? Jo, det er ikke katastrofe, for da må man rett og slett bare glemme hva som skjedde, og hoppe tilbake. Og så må man kjøre om igjen den andre bransjen. Det er klart, dette gir en masse ekstra logikk og overhead å få til dette her. Men igjen - alt er gjort for at ting skal gå raskere. Vi skal se på det i praksis, men vi kan ta med ett eksempel som gjorde at dette med pipelining og ikke minst parallellitet i mikroinstruksjoner, altså superskalaarkitektur...", "source": "lecture"}
{"lecture_id": "os6del5", "chunk_id": "os6del5_0002", "start": 283.88, "end": 487.98, "token_count": 597, "text": "glemme hva som skjedde, og hoppe tilbake. Og så må man kjøre om igjen den andre bransjen. Det er klart, dette gir en masse ekstra logikk og overhead å få til dette her. Men igjen - alt er gjort for at ting skal gå raskere. Vi skal se på det i praksis, men vi kan ta med ett eksempel som gjorde at dette med pipelining og ikke minst parallellitet i mikroinstruksjoner, altså superskalaarkitektur... og moderne CPU-er etter 2000 har, det var Meltdown og Specter, som var to sikkerhetshull som ble funnet i 2018. Det var noe så spesielt som et hardware-sikkerhetshull. Og det rammet Intel og Arm og IBM-prosessorer av alt som var av prosessorer, ble rammet. At kode blir utført i parallell. Men det var virkelig et hack. Men det utnyttet det at når man kommer til en bransje, så går man inn og kjører parallelt. Og man kan også gjøre tester. F.eks. er det hele tiden sånne tester. Har denne prosessen lov å lese data fra den andre prosessen? Dette systemet fungerer helt fint hvis systemet er sikker på at CPU utfører én og én institusjon. Men med parallellitet, med pipelining, og med at institusjoner faktisk utføres i parallell, så begynner man noen ganger å... Utføre en instruksjon som å sjekke om man har lov til å lese RAM, samtidig som en annen prosess legger noen av sine data i ram. Det dette sikkerhetsrullet utnyttet, var at man i en prosess da kunne, ved en feil, lese RAM for en annen prosess. Og det er virkelig en sikkerhetskatastrofe. F.eks. så kunne det brukes til at en prosess kunne lese passord som en annen prosess. Dette brukte de hardware-effektene sånn at for å rette opp i denne feilen, så måtte både CPU-ene endres for å sikre seg mot denne feilen, og operativsystemet. Dette er ett eksempel på hvor det er nyttig å vite litt om hva som foregår enda lenger ned. Så skjer det på operativsystemnivå, altså med kode. Men i dette tilfellet så skjedde det da altså med halvvei.", "source": "lecture"}
