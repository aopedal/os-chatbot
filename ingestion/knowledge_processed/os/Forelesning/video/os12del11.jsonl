{"lecture_id": "os12del11", "chunk_id": "os12del11_0000", "start": 0.0, "end": 204.4, "token_count": 581, "text": "Vi så før pause på hvordan vi kompilerte sammen disse to programmene her. Det var da et trådprogram som kjører to tråder, som hele tiden utfører én linje. Og én linje, det er bare å øke svar med én. Så når begge gjør dette her 100 millioner ganger, så bør svaret bli 200 millioner. Og vi kompilerte sammen på denne måten. Og så kjørte vi det på denne måten. Og så ser vi at svaret ble ikke 200 millioner. Og det er... Det skyldes da at man ikke synkroniserer. At disse to trådene... De kjører på hver sin CPU, og de går da ut og henter inn. Verdier fra ramm. Og så ødelegger de for hverandre. Men det som spørsmålet gjaldt, var om jeg tok tiden på disse her. Hvis jeg timer Adatat på den måten, så ser vi at de bruker... ja, ett sekund. Men mitt poeng var at det at det bruker 200 % CPU, det viser at her så bruker de de to sekundene imot. Hvis jeg eksplisitt med task-sett sier at nå skal begge trådene kjøre på samme superhjul... Da... Da ser vi at... tiden var raskere. Her ble faktisk sluttresultatet... riktig også. Og det var altså noe av det vi skulle se på. Men... At det går raskere her... Det kan nok skyldes at... At det tar mer tid å synkronisere mellom to CPU-er. Men svaret er kanskje ikke fullt så enkelt heller. For jeg testet det også. Ved å prøve å skru av den joinen som vi gjør til slutt. Men iallfall - det som kan ha en effekt, det må vi undersøke nærmere. Og det er tema for forelesningen neste uke. Og det er cashing. Neste uke skal vi se på minnet. Og det som kan ha en effekt her, som gjør at det går raskere når du kjører på Det er at... Ja, det kan ha med cashing å gjøre. At man mellomlagrer verdien og så gjør en endring før den er skrevet helt ut til dem. Vi kan prøve å se i neste uke om vi kan finne ut av det,", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0001", "start": 163.36, "end": 343.8, "token_count": 593, "text": "Og det er tema for forelesningen neste uke. Og det er cashing. Neste uke skal vi se på minnet. Og det som kan ha en effekt her, som gjør at det går raskere når du kjører på Det er at... Ja, det kan ha med cashing å gjøre. At man mellomlagrer verdien og så gjør en endring før den er skrevet helt ut til dem. Vi kan prøve å se i neste uke om vi kan finne ut av det, for da kan vi se på hvor mange sånne cash-operasjoner som utføres. Så det kan ha en effekt når noe går raskere på samme CPU enn hvis man kjører på to forskjellige CPU-er. Vi så her at dette gikk på 0,34 sekunder, men så opp i 1 sekund her, selv om de kjørte på to forskjellige CPU-er. Men akkurat den biten, den ser vi på neste gang. Men nå skal vi konsentrere oss om ikke om timingen, men om det som kjører... Det som skjer når vi kjører på samme SIPU og på forskjellige SIPU-er... Vi kan gjenta det vi... det vi gjorde. Hvis jeg nå ikke tenker på tiden, bare kjører av-og-taut, så ser vi når jeg kjører dette programmet på to forskjellige SIPU-er. Så selv om dette her bare er én enkel institusjon, så blir sluttresultatet forskjellig hver gang. Fordi de driver og henter ut samme verdi og overskriver hverandres resultater. Men hvis jeg kjører på... på samme suppe, så ser vi... Da blir resultatet riktig hver gang. Og det er fordi når det bare er én institusjon her, så blir dette som en atomisk operasjon. Men forskjellen er at vi låser ikke minnebussen. Men vi kan ikke ha en contex-switch som ødelegger for denne atomiske operasjonen. For da... Hvis det skjer en contex-switch, så er enten så er denne institusjonen ferdig, eller så er den ikke ferdig. Så en contex-switch vil ikke kunne ødelegge for dette. Men hvis de kjører på to forskjellige CPU-er, som vi ser her... Da trenger det ikke å være kontekster som kommer midt inn i en kode. Da kommer de omtrent likt ut til ram for å hente inn verdien.", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0002", "start": 304.0, "end": 478.96, "token_count": 598, "text": "Men vi kan ikke ha en contex-switch som ødelegger for denne atomiske operasjonen. For da... Hvis det skjer en contex-switch, så er enten så er denne institusjonen ferdig, eller så er den ikke ferdig. Så en contex-switch vil ikke kunne ødelegge for dette. Men hvis de kjører på to forskjellige CPU-er, som vi ser her... Da trenger det ikke å være kontekster som kommer midt inn i en kode. Da kommer de omtrent likt ut til ram for å hente inn verdien. Etterpå skal jeg prøve å tegne opp litt hvorfor dette skjer, og prøve å forklare enda litt mer i detalj. For det er viktig å få med seg akkurat den biten her. Men før vi kommer så langt, så skal vi se på et annet... Et annet eksempel hvor jeg har en ikke-minimal.s, men minimal-2.s. For å gjøre det litt enklere enn det jeg viste fram før pause. For der hadde jeg kode som var lagd av GCC. Men vi ser nå på... Dette er nå assembly-kode. Og assembly-kode og maskinkode... Jeg bruker ofte de ordene om hverandre, og det er fordi én linje assemblykode, sånn som dette, det fører til én linje maskinkode. Så hvis det er enkelprosent dax, det blir direkte oversatt til nulldeler og enere. Men det vil alltid være sånn at én assemblykodelinje, det blir én maskinkodelinje. Så dette kan man stole på at dette er det operativsystemet ser. Derimot, hvis du har høynivåkode, Så kan det være at én linje høynivåkode kan gi flere linjer maskinkode eller asemblykode. Men i dette tilfellet så ser vi, i stedet for å bare øke svar med én direkte i ramm, som man kan gjøre, så har jeg delt opp dette i tre institusjoner. Først en som henter svar og legger det i EAX. Og så en institusjon som øker EAX med én. Og så flyttes resultatet ut til svaret. Det er sånn som en kompilator kan finne på å lage kode. Det kan vi ikke være sikre på om dette skjer. Så hvis jeg nå prøver å kompilere med denne i stedet... Så jeg tar nå minimal... Ikke tre, men minimal to.", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0003", "start": 436.2, "end": 575.98, "token_count": 451, "text": "som man kan gjøre, så har jeg delt opp dette i tre institusjoner. Først en som henter svar og legger det i EAX. Og så en institusjon som øker EAX med én. Og så flyttes resultatet ut til svaret. Det er sånn som en kompilator kan finne på å lage kode. Det kan vi ikke være sikre på om dette skjer. Så hvis jeg nå prøver å kompilere med denne i stedet... Så jeg tar nå minimal... Ikke tre, men minimal to. Og så prøver jeg å kjøre med Task-sett. Og da ser vi igjen så oppstår problemet. Igjen så blir det nå trøbbel. Og det er fordi her er det tre linjer med kode. Man henter inn eksplisitt fra RAM, så hentes det inn til AAX. Så økes den, og så legges den ut igjen. Og da kan vi få problemet med Yrvis, og det er det som skjer. Hvis det kommer da en contact switch før den har øket verdien, så kan den hoppe til den andre tråden, som nå henter inn svar på nytt, gjør en rekke økninger og legger tilbake resultatet. Men da, i mellomtiden, så er denne første prosessen frosset her. Den vil øke da på... den verdien som den hentet inn, og så skrive den ut igjen. Og da blir det trøbbel. Da blir det trøbbel. Men hvis vi derfor i stedet bruker minimal.s, denne, med bare én enkelinstitusjon... Så komponere på nytt. Én enkelinstitusjon, så kjøre med Taset. Da vil hver eneste gang så får man riktig svar. Fordi det ikke kan komme en kontekst-witch inne i den operasjonen.", "source": "lecture"}
