{"lecture_id": "os10del7", "chunk_id": "os10del7_0000", "start": 0.0, "end": 109.76, "token_count": 292, "text": "Her er det arm-arkitektur, så det kan være interessant å se på... Hvis man tar KSC på sum.c, men med den aksjonen minus stor S. Sånn. Da får jeg en sum.s. Som inneholder... Som inneholder da... arm-instruksjoner. Og vi ser at dette er ganske forskjellig fra de X86-instruksjonene vi er vant til. Men noen av de heter de samme, sånn som AD. Men her er det AD med tre argumenter og... Ja... Elder og størr... Jeg kjenner ikke de institusjonene. Men det vi ser, er at det er en helt annen type institusjoner. Men prinsippene er de samme. Her har vi en Compere, f.eks. Og vi har løkker som hopper rundt. Så hvis man studerte disse maskininstitusjonene, så vil du se at dette er det summeprogrammet Som er tall fra 1 pluss 2 pluss 3 pluss 4. I prinsippet fungerer maskinkoden på samme måte, men det er andre institusjoner. Så de vil se helt forskjellige ut. Og disse institusjonene her... Hvis man kopierer dem over", "source": "lecture"}
{"lecture_id": "os10del7", "chunk_id": "os10del7_0001", "start": 90.0, "end": 119.98, "token_count": 116, "text": "Som er tall fra 1 pluss 2 pluss 3 pluss 4. I prinsippet fungerer maskinkoden på samme måte, men det er andre institusjoner. Så de vil se helt forskjellige ut. Og disse institusjonene her... Hvis man kopierer dem over til en X86-maskin, så fungerer det opplagt ikke i det hele tatt. Fordi disse institusjonene er totalt uforståelige for en X86-maskin.", "source": "lecture"}
{"lecture_id": "linux11del6", "chunk_id": "linux11del6_0000", "start": 0.0, "end": 99.56, "token_count": 286, "text": "Da skal vi se på Windows PowerShell. Windows PowerShell kom i 2006. Og det er da både et kommandolinjeverktøy og et skriftspråk for Windows. Som vi skal se, så er du veldig kraftig inspirert av Linux-versell. Det er mange ting som ligner, og mange konstruksjoner som er like. Linus har noe sånn Dev.0. Helt tilsvarende Dev.0, har man også i Foreshell. Og det er en rekke andre likheter. Pipes og omdirigering, f.eks. Er helt likt som på Linus. Siden Windows 2008 server og Windows 7, så har Foreshell vært installert sånn default. Men det er foreløpig ikke helt default. På samme måte som Linus-skjellet, så er PowerShell bygd opp av mange små programmer, eller commandlets, som gir en veldig fleksibel måte å løse oppgaver på. Siste versjon er 7,0, men all beskrift har fortsatt en else.pc1. Selv om det var opprinnelig, så var det PowerShell... Men da PowerShell versjon 2 kom, fortsatte man med PC1 Extension. Og det har man fortsatt.", "source": "lecture"}
{"lecture_id": "linux11del6", "chunk_id": "linux11del6_0001", "start": 71.4, "end": 159.4, "token_count": 293, "text": "som gir en veldig fleksibel måte å løse oppgaver på. Siste versjon er 7,0, men all beskrift har fortsatt en else.pc1. Selv om det var opprinnelig, så var det PowerShell... Men da PowerShell versjon 2 kom, fortsatte man med PC1 Extension. Og det har man fortsatt. Et veldig viktig prinsipp i PowerShell er at alt er objekter. I utgangspunktet er Windows objektorientert, skrevet i C pluss pluss. Og alt i Windows er i utgangspunktet objekter. I tillegg er konfigurasjonen i Windows ikke basert på tekstfiller, Men på binære filer og databaser, som Registry, som er en stor binær database. Dermed kan man ikke, som vi er vant til fra Linus, trekke ut all informasjon fra tekstfiler. Man må også kommunisere med disse binære databasene. Og da er det en veldig effektiv måte å gjøre det på. Det er å bruke den samme objektorienteringen. Derfor er også Portial objektorientert. Vi har sett med Linux at der sendes strømmer av tekst mellom kommandoer med pipes og omdirigerer.", "source": "lecture"}
{"lecture_id": "linux11del6", "chunk_id": "linux11del6_0002", "start": 139.66, "end": 225.04, "token_count": 298, "text": "Og da er det en veldig effektiv måte å gjøre det på. Det er å bruke den samme objektorienteringen. Derfor er også Portial objektorientert. Vi har sett med Linux at der sendes strømmer av tekst mellom kommandoer med pipes og omdirigerer. Og det er et veldig kraftig verktøy. PowerShell, derimot, sender ikke tekst, men det sender hele objekter mellom sine command lets ved hjelp av pipes. Og det er, som vi skal se, ganske genialt. For det gjør at PowerShell blir enda kraftigere enn Linux selv. For når man har objekter, så kan man på en helt annen måte spørre objektet om hvilke egenskaper du har som objekt. Og så kan man bruke disse egenskapene når man skriver skrift. Og da slipper man veldig mange av de problemene man har i Linux selv, med syntaksfeil og finne ut hvilken informasjon man skal gjøre, og drive og parse tekst. Plukke ut riktige biter av tekst. Det kan være tunget i Linus, men med Vinos PowerShell så er det mye enklere. Det finnes fire typer kommandoer i PowerShell.", "source": "lecture"}
{"lecture_id": "linux11del6", "chunk_id": "linux11del6_0003", "start": 199.44, "end": 289.18, "token_count": 298, "text": "med syntaksfeil og finne ut hvilken informasjon man skal gjøre, og drive og parse tekst. Plukke ut riktige biter av tekst. Det kan være tunget i Linus, men med Vinos PowerShell så er det mye enklere. Det finnes fire typer kommandoer i PowerShell. Commandlets er den viktigste. Det tilsvarer helt bæsj-shell-biltits. Kommandoer som pwd, som er en del av skjellet. I PowerShell heter det get location. Og echo, som i PowerShell heter write output. De er bygd inn i skjellet. Og det samme er command lets. Men i PowerShell så er command lets det aller vanligste. Stort sett alle kommandoer er command lets. I tillegg så har vi noen applications. Og det er eksisterende Windows-programmer, sånn som Ping og IP-konfig. Og de finnes fortsatt. Og det er programmer som ligger da på disk. Akkurat som bind.mv, f.eks. i Linus. I Linus er bind og user-bind der har de de aller fleste kommandoene. Så har vi skript. Tekstfilet med nc.pc-en er et post-it-skript. Det tilsvarer bæsj-skript som vi har drevet med.", "source": "lecture"}
{"lecture_id": "linux11del6", "chunk_id": "linux11del6_0004", "start": 270.0, "end": 384.24, "token_count": 298, "text": "Akkurat som bind.mv, f.eks. i Linus. I Linus er bind og user-bind der har de de aller fleste kommandoene. Så har vi skript. Tekstfilet med nc.pc-en er et post-it-skript. Det tilsvarer bæsj-skript som vi har drevet med. I tillegg har det funksjoner som ligner veldig på funksjoner i bæsj-hegg. Hello World-program har verdens korteste Hello World-program. For man trenger ikke å skrive ekko. Man kan bare ha en fil som inneholder strengen Hello Work. Når man kjører den, så vil den da skrive ut Hello Work. Da lager man bare en fil, hello.cn. Så gjør man det etterpå. Så kjører man den på den måten, og så får du ut Hello World. For å få lov til å kjøre et skritt... Så må du sette execution policy. For i utgangspunktet så er execution policy satt sånn at det ikke er lov å kjøre påskjøttskript. Så det vi anbefaler å gjøre, er å sette execution policy til remote signed. Da betyr det at da kan du kjøre alle script som du lager selv, på din maskin.", "source": "lecture"}
{"lecture_id": "linux11del6", "chunk_id": "linux11del6_0005", "start": 360.0, "end": 445.0, "token_count": 289, "text": "Så må du sette execution policy. For i utgangspunktet så er execution policy satt sånn at det ikke er lov å kjøre påskjøttskript. Så det vi anbefaler å gjøre, er å sette execution policy til remote signed. Da betyr det at da kan du kjøre alle script som du lager selv, på din maskin. Men så kan du også kjøre script som er signert av en trusted publisher. Det er noen man stoler på, som Michaelson stoler på, som har lagd script. De kan du laste ned og fortsatt kjøre. Dette sikrer at hacker f.eks. ikke laster ned skumle PowerShell-script, og så kjører de lokalt på din maskin. For da har denne excision policyen sørget for at de ikke blir kjørt. Så lenge de ikke kommer fra en annen trøstet porters. For å få til dette, så må du ha administratorrettigheter for å sette det. Jeg har nevnt at det er mange likheter med vers, og det er også gjort eksplisitt ved at man har laget aliaser for en rekke kommandelets. På høyre side der, så står det 'kommandlets'. Vi ser", "source": "lecture"}
{"lecture_id": "linux11del6", "chunk_id": "linux11del6_0006", "start": 420.0, "end": 509.72, "token_count": 299, "text": "For å få til dette, så må du ha administratorrettigheter for å sette det. Jeg har nevnt at det er mange likheter med vers, og det er også gjort eksplisitt ved at man har laget aliaser for en rekke kommandelets. På høyre side der, så står det 'kommandlets'. Vi ser opplegget med kommandlets er at det står et verb først, og så hva man skal gjøre. Get content, set location, copy item osv. Men så har man lagd alias som gjør akkurat det samme på Linux. Eller man har lagd alias som har samme navn som Linux-kommandoer som tilsvarer disse kommandonettene. Og dette betyr at hvis du er vant til dette, kan du sette deg ned og så kan du kjøre alle de kjære kommandoene som Cat, CD, CP, LS, MV. Og det gjør det veldig praktisk å gå imellom PowerShell og Linus. Da kan man faktisk ta en del bæsjskrift på Linux og bare kopiere rett over, og de vil da kjøre i PowerShell. Et par andre likheter som vi skal se på, er som jeg har sagt, pipes of redirection. Dette ser ut som en standard linuskommando.", "source": "lecture"}
{"lecture_id": "linux11del6", "chunk_id": "linux11del6_0007", "start": 488.02, "end": 597.96, "token_count": 299, "text": "Da kan man faktisk ta en del bæsjskrift på Linux og bare kopiere rett over, og de vil da kjøre i PowerShell. Et par andre likheter som vi skal se på, er som jeg har sagt, pipes of redirection. Dette ser ut som en standard linuskommando. Den kan du kjøre på Forcel også, og den gjør omtrent det samme som i Forcel. Nei, den gjør omtrent det samme som i Linux Sheet. Men det vi skal se, er at faktisk output fra LS det er egentlig ikke i utgangspunktet bare tekst. Det er en hel... Det er et helt objekt. Men likevel så kan man gjøre det på den måten. Variabler håndteres på samme måte som i Linux. Den eneste forskjellen er at der har man alltid et dollartegn foran variablen. Sånn som i POP, f.eks. I tillegg er ikke PowerCel som var på Syntax. Det spiller ingen rolle. Og som sagt, så trenger man ikke å skrive ekko. Bare skriv dollar hver, så skrives verdien av variabelen ut. Ok. Da har vi sett litt på Powercel på en mer teoretisk måte. Men nå skal vi se på Powercel i praksis.", "source": "lecture"}
{"lecture_id": "os2del4", "chunk_id": "os2del4_0000", "start": 0.0, "end": 106.4, "token_count": 300, "text": "CMOS skal se litt om teknologien, men vi skal ikke gå så nøye inn på det. Vi skal se mer på logikken. Men CMOS er en halvlederteknologi. Og er den som er brukt i så å si alt som er av halvledere. Og den består av to typer transistorer. NMOS og PMOS. Ja, og den forskjellen på de er at den ene har hull, og den andre har altså positive hull, og den andre har elektroner. Men som sagt, vi skal ikke gå inn i tekniske detaljer her, vi skal se mer på logikken. Og logikken er ganske enkel. Dette er en NMOS-transistor. Og den har en sannhetstabell som vi ser her, som er ganske enkel. Den er sånn at her står det X. Og så ser vi her streker her. Dette er ledninger. Hvis jeg ser 10 nanometer teknologi, så er disse ledningene av den størrelsesorden. Så det er bare noen atomer, noen silisium... I dette tilfellet er det kobberledninger, så det er bare noen kobberatomers bredde på disse ledningene. Så er det inni her som halvlederen ligger. Her er silisium.", "source": "lecture"}
{"lecture_id": "os2del4", "chunk_id": "os2del4_0001", "start": 85.6, "end": 178.04, "token_count": 293, "text": "Så det er bare noen atomer, noen silisium... I dette tilfellet er det kobberledninger, så det er bare noen kobberatomers bredde på disse ledningene. Så er det inni her som halvlederen ligger. Her er silisium. Som er lagd på en sånn måte at hvis det er en spenning... Vi kan starte med den første. Hvis det er null her, betyr det at det er null spenning. Det kommer strøm inn på toppen, og strøm ut i bunnen her. Hvis du har spenning null inn, så er den bryteren av. Da er det ingen kobling mellom toppen og bunnen. Men hvis du setter på en spenning, f.eks. 5 volt inn her, over den transistoren, så skrur man på denne bryteren. En transistor er egentlig bare en bryter. Da går det strøm igjen. Det er egentlig hele greia. Med den type brytere kan man bygge CPU-er som gjør akkurat den logikken man ønsker. Men hvordan, det skal vi se på i detalj. Pemos er broren til NMOS. Bortsett fra at den virker helt motsatt.", "source": "lecture"}
{"lecture_id": "os2del4", "chunk_id": "os2del4_0002", "start": 150.0, "end": 218.12, "token_count": 215, "text": "Da går det strøm igjen. Det er egentlig hele greia. Med den type brytere kan man bygge CPU-er som gjør akkurat den logikken man ønsker. Men hvordan, det skal vi se på i detalj. Pemos er broren til NMOS. Bortsett fra at den virker helt motsatt. Logisk sett så hadde man ikke trengt å ha denne. Det er mer av ingeniørmessige årsaker. Man får mye mindre effekttap med denne måten å gjøre det på, å bygge logiske porter av PMOS og NMOS. Men iallfall, en PMOS-transistor, den virker på en motsatt måte. Hvis det kommer null inn her, null spenning, så er... Da går det strøm igjennom. Hvis det kommer en ener inn, så er den av. Så den virker helt motsatt av en Moss.", "source": "lecture"}
{"lecture_id": "linux7del11", "chunk_id": "linux7del11_0000", "start": 0.02, "end": 130.7, "token_count": 276, "text": "Dokkerhub nevnte vi. Jeg kunne kanskje bare gå inn og se kjapt på hvordan det ser ut.  Ja, nå har jeg gått inn på Dokkerhaug, og her ligger det da imager som kan lastes ned. Det vi lastet ned var Ubuntu. Hvis jeg går på Explore her, så vil man se at det er et uttall. Her er det. Vi har tre millioner forskjellige imager av forskjellige typer, som er plasset opp. Her ser vi databaser, Replication Services, brukere for operating systems. Her har vi buntet som vi nettopp blåste ned. Alpine, SentOS, Debian osv. En rekke imager. Så får man en Debian-versjon som man... Så kan man også selv laste opp imager til Dockerup. Det er et stort men, og det er sånn sikkerhetsmessig... Sånn som Ubuntu følger opp sine egne imager. Men det er et generelt problem med sikkerhet og... Om man vet hva et image egentlig inneholder. Sikkerhetsmessig er det litt mer tvilsomt enn om man installerer systemer og applikasjoner.", "source": "lecture"}
{"lecture_id": "linux7del11", "chunk_id": "linux7del11_0001", "start": 99.42, "end": 169.0, "token_count": 145, "text": "Sånn som Ubuntu følger opp sine egne imager. Men det er et generelt problem med sikkerhet og... Om man vet hva et image egentlig inneholder. Sikkerhetsmessig er det litt mer tvilsomt enn om man installerer systemer og applikasjoner. I mitt stegs er det generelt sånn at man kan velge hvilken versjon man vil bruke på en enkel måte. Så jeg sa at vi fikk Ubunti 1804. Hvis du vil eksplisitt ha Ubunti 1404, så kan du legge på den som en sånn...", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0000", "start": 0.0, "end": 152.44, "token_count": 285, "text": "Da har jeg satt på recording igjen, så forelesningen blir tatt opp. Multiple choice-obligatoriske oppgaver. Så... Det er forhåpentligvis et relativt enkelt spørsmål som dere kan prøve å svare på. Fra deg vi snakket om i første time. Ine, er du der? Ja. Du er der. Flott. Har det vært noen spørsmål i chatten som jeg ikke har fått med meg? Det har vært spørsmål til meg direkte, men da er jeg svart på det. Ja, flott. Er det noen som er noen viktige spørsmål som du tenker mange kan lure på? Ja, litt sånn i forhold til... Kanskje noen eksempler på hyperthreading og sånt noe. F.eks. om det er litt eksempler på det. I forhold til det, kanskje. Og så kanskje greit... Det har vært tidligere noen spørsmål i forhold til det med når man skal sjekke at det vil være litt antall kjerner man får opp. For seg selv og for systemet er jo ikke alltid helt bestemt. Nei. Ja, det er et godt spørsmål.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0001", "start": 128.98, "end": 225.08, "token_count": 282, "text": "Og så kanskje greit... Det har vært tidligere noen spørsmål i forhold til det med når man skal sjekke at det vil være litt antall kjerner man får opp. For seg selv og for systemet er jo ikke alltid helt bestemt. Nei. Ja, det er et godt spørsmål. Og det kan jo være litt forvirrende. Ja, jeg kan... Etterpå... Jeg tenkte å få litt tid til å se på dokkekonteinere. Så jeg kunne si litt om de VM-ene og den... For det er en oppgave med hypertrening hvor du skal se på din egen VM. Jeg har fått spørsmål om det tidligere, men det er sikkert greit å... ja, kanskje vise litt om det, eller noe sånt noe. Ja, når det gjelder hypertrening... Ja, så... Jeg viste to eksempler på hypertrening sist, og det er kanskje det... de viktigste eksemplene. Og det vi så på, var regnejobber. Altså den rein eller... Eller bæsjskilt som bare heter regn. Hvis vi kjører det på to Sonyer", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0002", "start": 195.06, "end": 276.88, "token_count": 292, "text": "Ja, når det gjelder hypertrening... Ja, så... Jeg viste to eksempler på hypertrening sist, og det er kanskje det... de viktigste eksemplene. Og det vi så på, var regnejobber. Altså den rein eller... Eller bæsjskilt som bare heter regn. Hvis vi kjører det på to Sonyer og regnejobber på en hypertreding-tjernet, så så vi at det tar nesten dobbelt så lang tid. For de må da bytte på å bruke alum. Men samtidig kjørte vi en annen prosess. En rammeprosess som hele tiden skrev til et r-øyet ramm. Og den så vi kunne i noen tilfeller kjøre nesten dobbelt så fort. Altså at det gikk like fort om man hadde to sånne prosesser inne på samme kjerne. Så hvis én sånn prosess kjører alene, så klarer den ikke å utnytte alle ressursene. Og dermed så kan to sånne kjøre omtrent like fort som om de var alene på den kjernen. For mer normale programmer så ligger ofte svaret sånt et sted i midten der.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0003", "start": 250.4, "end": 344.42, "token_count": 298, "text": "Altså at det gikk like fort om man hadde to sånne prosesser inne på samme kjerne. Så hvis én sånn prosess kjører alene, så klarer den ikke å utnytte alle ressursene. Og dermed så kan to sånne kjøre omtrent like fort som om de var alene på den kjernen. For mer normale programmer så ligger ofte svaret sånt et sted i midten der. Men det var også et... Ja, jeg kan ta det. Og et annet spørsmål kan vi ta etterpå. Men nå kan vi stoppe pollingene. Og se de fleste har svart. Og det ser veldig bra ut. Ser du den nå, Ine? 70... Ser du Poll...? Nei, det ser du ikke. Share results. Sånn. Nå ser jeg, ja. Flott. Sharing Poll Results. Ja. Det er et svar som skilte seg veldig ut der, og det er kjempebra, for det er det riktige svaret. 82 % av svarte. Veldig bra. til å gi begrensede tidsintervall til brukerprosessene. Det er en hardware-timer i CPU-en som slår inn hvert hundredels sekund. Når det skjer, så switcher...", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0004", "start": 317.4, "end": 404.14, "token_count": 297, "text": "Det er et svar som skilte seg veldig ut der, og det er kjempebra, for det er det riktige svaret. 82 % av svarte. Veldig bra. til å gi begrensede tidsintervall til brukerprosessene. Det er en hardware-timer i CPU-en som slår inn hvert hundredels sekund. Når det skjer, så switcher... Modusbit for CPU-en switcher over til kernel mode, kernel modus, og operativsystemet tar over. Så velger operativsystemet hvilken prosess som skal kjøre videre. Switcher til brukermodus og... Setter i gang den prosessen. Så kan en stå og eksklusivt bruke CPU-en i use mode, så den kan gjøre omtrent alle instruksjoner, som move og add osv. Men der noen få den ikke får lov til å gjøre, sånn som f.eks. holdt. Den får ikke lov til å stoppe maskinen. Og dermed så har CPU-en kontroll. Jeg kan se på de andre som overlater timesharingen til hardware og alle rytmer.... Det er litt sannhet i det også, siden hardware er med ved modus bit osv. Og en hardware-timer som sender signaler, får et intervju...", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0005", "start": 376.98, "end": 482.04, "token_count": 291, "text": "Den får ikke lov til å stoppe maskinen. Og dermed så har CPU-en kontroll. Jeg kan se på de andre som overlater timesharingen til hardware og alle rytmer.... Det er litt sannhet i det også, siden hardware er med ved modus bit osv. Og en hardware-timer som sender signaler, får et intervju... Men selve algoritmene er det operativsystemet som styrer. Den hardware-timeren gir kontrollen til operativsystemet, og derfra tar operativsystemet kontroll. Det andre svaret virker også ganske riktig. Og så venter de prosessen til at prosessen skal gjøre gi opp, og gir da cpd-en til neste prosess i readylist. Ja, det er ikke sånn... Det er ikke helt feil. Hvis en prosess skal gjøre input-output-operasjoner og ikke trenger cpd-en lenger, så vil operativsystemet gi over. Men det er ikke det som er hovedmekanismen. Og hovedmekanismen er at den deler inn tiden i likeintervaller, og på den måten gir hver prosess en liten bit av tid, når den måtte trenge det. Det er en mulig løsning, og det var noe lignende som det", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0006", "start": 446.8, "end": 559.82, "token_count": 290, "text": "Men det er ikke det som er hovedmekanismen. Og hovedmekanismen er at den deler inn tiden i likeintervaller, og på den måten gir hver prosess en liten bit av tid, når den måtte trenge det. Det er en mulig løsning, og det var noe lignende som det som Windows 95 hadde opprinnelig som multitasking. Altså at den bare hadde en sånn liste, og så sa den... OK, nå skal Prosess A få 100 sekunder. Kjør det 100 sekunder, og så gi tilbake kontrollen til meg. Men da var det fortsatt i cornal mode. Sånn at da kunne prosessen gjøre holdt eller ødelegge for systemet. Så dette her ville... Hvis du bare gir hver prosess lov til å stå i kjøre og starte, så ville det fungere helt greit helt til det var en bug i et program. Eller et program som var ondsidet med hensikt, og som prøvde å ta over og få mest mulig CPU til seg. Men hvis alle prosesser oppførte seg OK, og ikke krasjet systemet, så ville et sånt opplegg ha fungert. Men det er nettopp det med bug.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0007", "start": 532.64, "end": 646.32, "token_count": 297, "text": "Eller et program som var ondsidet med hensikt, og som prøvde å ta over og få mest mulig CPU til seg. Men hvis alle prosesser oppførte seg OK, og ikke krasjet systemet, så ville et sånt opplegg ha fungert. Men det er nettopp det med bug. Vil aldri systemet gå ned. Men hvis du hadde et opplegg som dette her, som gjorde at alle prosesser kunne kjøre kurlemode og gjøre hva du ville, da kunne man risikere at hver gang det var et bug i et brukerprogram, så kunne systemet gå ned. Og sånn var det tidligere. Som på Windows på slutten av 80-tallet. Og da gikk systemet ned. Med denne måten gjør at operativstemaet har full kontroll, og systemet blir mye sikrere. Ok. Da skal vi fortsette med systemkall. Og det var et godt spørsmål i pausen om at man kan switche fra... Da kan man gjøre en institusjon som switcher. For i kernel-mode så har man allmakt. Men fra user-mode så kan man ikke switche til kernel-mode. Men det switcher jo til kernel-mode. Men den switchen foregår i det øyeblikket at...", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0008", "start": 622.64, "end": 722.28, "token_count": 288, "text": "Da kan man gjøre en institusjon som switcher. For i kernel-mode så har man allmakt. Men fra user-mode så kan man ikke switche til kernel-mode. Men det switcher jo til kernel-mode. Men den switchen foregår i det øyeblikket at... ... at timeren går på, sender et signal, og så switches det til kernel-mode. Operativsystemet inn og tar over. Men det som jeg mente med at man ikke kan switche fra use-to-mode til curner-mode, det er... Det finnes ingen instruksjon, sånn som det står her... Det finnes ingen instruksjon switch-to-cerner-mode som en vanlig brukerprosess kan utføre. For hvis den fantes, så kunne den bare i prosessen gjøre searche curner-mode, og så vips, så var den i curner-mode og kunne gjøre hva den ville. Så hva da når et brukerprogram skal gjøre noe som... Som skal gjøre instruksjoner som ikke kan utføres fra use mode? Hvordan kan da brukerprogrammet få til det?  Og det kan f.eks. være sånn som å lese noe fra disk. Sånn generelt så har jo operativsystemet full kontroll på disken.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0009", "start": 682.64, "end": 800.7, "token_count": 297, "text": "Så hva da når et brukerprogram skal gjøre noe som... Som skal gjøre instruksjoner som ikke kan utføres fra use mode? Hvordan kan da brukerprogrammet få til det?  Og det kan f.eks. være sånn som å lese noe fra disk. Sånn generelt så har jo operativsystemet full kontroll på disken. Men hvordan kan da et brukerprogram lese noe fra disken når den må da utføre operasjoner som bare kan gjøres i kernel mode? Jo, der da systemcall kommer inn. Og det er rett og slett... Et brukerkode som ber kjernen om hjelp ved hjelp av SystemColl. SystemColl er egentlig bare et API mot operativsystemkjernen. Det er et sett med operasjoner som en vanlig brukerprogram fra YSIMOD kan be operativsystemkjernen om å gjøre. På samme måte som du har et API... Et Application Programming Interface mot moduler og programmer av alle mulige typer. Da er det liksom alle de operasjonene som det er mulig å få utført med dette programmet eller denne metoden. Ja, så... Men vi har et dilemma her hvis vi skal... Hvis vi skal gjøre noe som krever current mode. Det kunne jo være sånn at man...", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0010", "start": 773.06, "end": 857.92, "token_count": 287, "text": "av alle mulige typer. Da er det liksom alle de operasjonene som det er mulig å få utført med dette programmet eller denne metoden. Ja, så... Men vi har et dilemma her hvis vi skal... Hvis vi skal gjøre noe som krever current mode. Det kunne jo være sånn at man... At brukerprogrammet kunne sette modusbytt til kernel mode, og så... Og så utføre det man trengte, og så skulle det switches tilbake. Men da får du igjen problemet. Hvis du kan gjøre switch til kernel mode, så kan brukerprosessen ta over og stoppe systemet. Så igjen må vi ha hjelp fra Harvey, og da er det en spesiell intensjon som heter Trap. At den switcher til curl-mode og hopper til kode for et systemkall i én og samme operasjon. Og det betyr at fra use-mode så kan du ikke da først hoppe til curl-mode, og så love å si... Ja, etterpå... Jeg lover. Jeg skal gjøre systemkall etterpå. Men dette må gjøres i én og samme operasjon. Og da, for å få til noe i én og samme operasjon, så må man ha én", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0011", "start": 843.3, "end": 932.96, "token_count": 281, "text": "og så love å si... Ja, etterpå... Jeg lover. Jeg skal gjøre systemkall etterpå. Men dette må gjøres i én og samme operasjon. Og da, for å få til noe i én og samme operasjon, så må man ha én Så igjen så får man hjelp fra Hardware for å få til systemkall. Her er en oversikt over hvordan et systemkall foregår. Og da ser vi på venstre side her, så er vi i brukerminnet.  Og på høyre så har vi privilegert-minnet. Og her er det vanlig brukerkode som kjører YSEMOD, Institusjon 1, 2, 3 osv., og så skal det gjøres et systemcall. Og det er systemcall nummer tre i API-et. Og sånn ser det ut i Lynix-API-et. Så er det systemcall nummerert når det var her. Det finnes mange hundre systemkall. Men det er noen få som gjøres veldig ofte. Og tredje systemkall, Sister Read, det er akkurat det jeg også leser fra disk. Og det kan man ikke gjøre i Use and Mold.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0012", "start": 914.92, "end": 1007.72, "token_count": 289, "text": "Det finnes mange hundre systemkall. Men det er noen få som gjøres veldig ofte. Og tredje systemkall, Sister Read, det er akkurat det jeg også leser fra disk. Og det kan man ikke gjøre i Use and Mold. Og det som skjer da, er at her kommer det et systemkall Trap 3. Da... En viktig del av systemkallet er den institusjonen trap. For den switcher da til... Den switcher modus bit til curl mode samtidig som den hopper inn i en branching-tabell her og hopper til første kodelinje i det systemkallet. Så da, i én institusjon, så switchers modus bit, og... Den første institusjonen for dette systemkallet legges inn i... ... inn i institusjonsregisteret. Det er den neste institusjonen som skal gjøres. Det må vi hele tiden tenke på. Vi har i utgangspunktet bare én CPU som vi ser på, og det er bare én av gangen som kan gjøre institusjoner. Så dermed må man ha en sånn hardwarehjelp fra Trap for å kunne både hoppe inn, Og på denne måten så får man full kontroll.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0013", "start": 981.84, "end": 1078.0, "token_count": 287, "text": "Det må vi hele tiden tenke på. Vi har i utgangspunktet bare én CPU som vi ser på, og det er bare én av gangen som kan gjøre institusjoner. Så dermed må man ha en sånn hardwarehjelp fra Trap for å kunne både hoppe inn, Og på denne måten så får man full kontroll. Wymbranching-tabell, det er rett og slett bare en tabell som peker på de forskjellige systemkallene. Du ser det går en pil fra systemkall 3. Her ligger da adressen til der de rammet som første institusjon i dette systemkallet ligger. Ja, dette er en illustrasjon fra Tanbaum på systemcall. Her er det litt mer... Litt flere detaljer, men ideen er den samme. Vi har vanlige instruksjoner her. Én, to, tre. Og så kaller man rid. Med å få riktige verdier inn i forskjellige registre osv. Men så er det da the trap to cornal. Da hopper man inn i kjernekodet, utfører systemkallet, og så hopper man tilbake igjen. Men det er klart, det er masse som må holdes orden på her.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0014", "start": 1059.68, "end": 1149.44, "token_count": 293, "text": "Med å få riktige verdier inn i forskjellige registre osv. Men så er det da the trap to cornal. Da hopper man inn i kjernekodet, utfører systemkallet, og så hopper man tilbake igjen. Men det er klart, det er masse som må holdes orden på her. At man må hoppe tilbake til riktig sted i use mode osv. Så det er en ganske kompleks operasjon. Men det viktige prinsippet, det er... Og at man da både switcher i modusbytt og hopper til systemkallkoden. I én og samme institusjon. Her er noen eksempler på systemkall. Vi så et av de tidligere, var Fork. Og det er typisk noe som er systemkall. Altså at man... Fork brukes i Linux til å... Og sette i gang en ny prosess. Det kan ikke et vanlig brukerprogram gjøre. Der må operativsystemet inn og styre. Ja... Vi skal bruke det litt senere når vi skal forke og snakke med Child. Men dette er igjen sånn prosessmanagement. Så har vi sånn som File Management, som vi har sett på med Open, Close, Read...", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0015", "start": 1127.48, "end": 1229.04, "token_count": 291, "text": "Der må operativsystemet inn og styre. Ja... Vi skal bruke det litt senere når vi skal forke og snakke med Child. Men dette er igjen sånn prosessmanagement. Så har vi sånn som File Management, som vi har sett på med Open, Close, Read... Det er greit å skrive til og fra filer. Disken og filsystemet, det er det operativsystemet som kontrollerer. Og her er det klart, det her må vi bruke systemcall for å oppnå det. Igjen så kunne vi hatt vanlige brukerprosesser som styrte dette fra jus imot. Men da kunne man risikere å krasje hele disken. For andre brukere osv. Så er det sånn som Directory og System Management, med MKDIR og LinkMount... Vi ser sånn som MKDIR. Det er en del av de Shell-kommandoene som faktisk heter det samme som systemkall. Og i C så er alle disse systemkallene implementert. Skrive- se-programmer som direkte utfører systemcall mot Linux-kjernen. Ja, her er en del sånn diverse, sånn som Kill, for eksempel, som opplagt trengs et systemcall for å gjøre.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0016", "start": 1202.02, "end": 1314.36, "token_count": 299, "text": "Og i C så er alle disse systemkallene implementert. Skrive- se-programmer som direkte utfører systemcall mot Linux-kjernen. Ja, her er en del sånn diverse, sånn som Kill, for eksempel, som opplagt trengs et systemcall for å gjøre. Det kan heller ikke en brukerprosess gjøre mot f.eks. andre brukere. Ja, her er noen Windows-systemcall. Jeg har satt opp en masse systemcall for Unix og Windows. Og da... Dette er bare for å illustrere at alle moderne operativsystemer har en tilsvarende mekanisme med systemcall. Men ofte er ting ganske forskjellig, sånn som Windows 32. De har rett og slett en create-prosess. Det er da et systemkall som lager en ny prosess. Men akkurat som Linux har read, så har Windows' operativstemme read file for å lese data fra en fil. Men i prinsippet så virker Windows og andre operativstemmer på nøyaktig samme måte, at det må gjøre systemkall for å... Vanlige brukerprosesser må gjøre systemcall når de skal gjøre kjerneoperasjoner. Altså alt som har med å snakke med hardware,", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0017", "start": 1289.8, "end": 1388.28, "token_count": 282, "text": "Men i prinsippet så virker Windows og andre operativstemmer på nøyaktig samme måte, at det må gjøre systemkall for å... Vanlige brukerprosesser må gjøre systemcall når de skal gjøre kjerneoperasjoner. Altså alt som har med å snakke med hardware, og alt som har med å styre prosesser. Det er typisk kjernevirksomhet som man er nødt til å gjøre systemcall for å få utført. Da skal vi se litt spesifikt på Linux-sheduling. Og i den simuleringen av å lage vaffelrør og forelese så er det denne scheduling-algoritmen som jeg tar utgangspunkt i. Men det finnes mange andre scheduling-algoritmer. Windows har en annen. Den som er i nyere Linux-kjerner... Er en litt annen kjerne... En litt annen scheduler. Skedulerer, eller tidsfordeler. Og den heter Completely Fair Scheduler, CFS. Den tok over for den som var i Linnis 2.6-kjernen, som var i mange 10-15 år. Og det var fordi at den ikke alltid var helt fair. Det var noen da i...", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0018", "start": 1366.68, "end": 1463.96, "token_count": 295, "text": "Skedulerer, eller tidsfordeler. Og den heter Completely Fair Scheduler, CFS. Den tok over for den som var i Linnis 2.6-kjernen, som var i mange 10-15 år. Og det var fordi at den ikke alltid var helt fair. Det var noen da i... En Linux-kjerneutviklergruppe som kom opp med et forslag til en ny scheduler. Så etter mye testing og feiling og prøving, erstattet den den gamle scheduleren. Det er en O1-scheduler, som betyr at den skalerer sånn at det går like raskt om det er 200 prosesser, eller om det er 10 prosesser som skal scheduleres. Det er det jernmannen forbinder med ordet scheduling. Det er å fordele ressurser blant en rekke enheter som trenger disse ressursene. Så scheduling kan brukes i mange tilfeller, men dette er da CPU-scheduling som operativsystemet utfører, som vi ser på nå. I Linux 2.6-scheduling så deles tiden inn i epoker. Og da... Hver prosess som skal kjøre, tildeles et time-countum. Og dette time-countumet er da målt i jiffis, eller tics.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0019", "start": 1441.36, "end": 1539.36, "token_count": 284, "text": "som vi ser på nå. I Linux 2.6-scheduling så deles tiden inn i epoker. Og da... Hver prosess som skal kjøre, tildeles et time-countum. Og dette time-countumet er da målt i jiffis, eller tics. Og det er disse hundredelssekundene, eller ti millisekunder, som vi snakker om. Det er liksom det minste tidsintervallet. Hver gang timeren slår, så går det ett tics. Vi har vel sett på det så vidt... I Proxtat så er det en sånn liste over tics. Da kan man f.eks. se at siste sekund så har man kjørt 80 tics i user mode og 2 tics i curl mode med denne prosessen. Da betyr det at denne prosessen har hatt CPU-en omtrent hele tiden. Det er den viktige minste tidsenheten. Men så kommer det en epoke... Det er da en annen og større tidsenhet. Man gir da hver prosess et time-kantum. F.eks. så kan en prosess få 20 enheter med tid i form av tics. Så da gir man en prosess 20 tics.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0020", "start": 1515.88, "end": 1603.96, "token_count": 292, "text": "Men så kommer det en epoke... Det er da en annen og større tidsenhet. Man gir da hver prosess et time-kantum. F.eks. så kan en prosess få 20 enheter med tid i form av tics. Så da gir man en prosess 20 tics. Så kan da operativstemme prioritere, altså gi en annen enhet... Nei, gi en annen prosess - 40-tics. Og da betyr det at da vil den som får 40-tics, kjøre i snitt dobbelt så lenge som den andre. Og det skal vi se på senere, hvordan vi kan gjøre med nice-kommandoen i Linux. Etter at alle prosessene har fått tildelt sitt time-kontum, altså sin tids... Én liten bit med tid, så kjører operativstemme Rown-Robin scheduling. Det betyr at... Rown-Robin, det betyr at man sitter rundt et bord, og så får alle litt tid. Men da er det ikke sånn at bare hver prosess får etikk. Man avbryter det ikke hele tiden. Dette er fordi det kan være effektivt og ikke... Ikke ha for mange avbrudd.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0021", "start": 1582.12, "end": 1670.88, "token_count": 298, "text": "og så får alle litt tid. Men da er det ikke sånn at bare hver prosess får etikk. Man avbryter det ikke hele tiden. Dette er fordi det kan være effektivt og ikke... Ikke ha for mange avbrudd. For det er litt overhead med en context switch, altså å switche over til en annen prosess. Så dette systemet sørger for at da, hvis det ikke skjer noe spesielt, altså hvis det ikke kommer noen interrupter, så vil den prosessen som er tildelt 20-tics, den vil fullføre de 20-ticsene i denne epoken. ... litt fred og ro til å kjøre ferdig. Det blir jo noen sånn 0,2 sekunder... 20 hundredeler, så kjører den. Og så etterpå kommer kanskje den prosessen som har fått ti tics. Så kanskje ikke er flere som har lyst til å kjøre i den epoken. Og da starter en ny epoke. Og så fortsetter det sånn. Dermed kan operativsteamet avgjøre prioritering av de forskjellige prosessene. Så dette er en måte å dele inn tiden på på en litt mer dynamisk måte enn å bare gi annenhver tics", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0022", "start": 1650.74, "end": 1739.48, "token_count": 275, "text": "Og da starter en ny epoke. Og så fortsetter det sånn. Dermed kan operativsteamet avgjøre prioritering av de forskjellige prosessene. Så dette er en måte å dele inn tiden på på en litt mer dynamisk måte enn å bare gi annenhver tics til hver eneste prosess. Den måten ville ha gitt litt mye overhet. Så må vi også huske på at timeticsene er definert av operativsystemet. Man har testet ut i noen skeduer... Eller i 26-kjernen... Kan man sette 1 ms eller 100 ms? Men da oppfører systemet seg litt forskjellig. Etter hvert timertick, så sjekkes det om den prosessen som kjører, har flere tics igjen. Altså om telleren til prosessen er større enn null. Da kaller man ikke skeduleren. Da bare fortsetter den å kjøre til den er ferdig med sin epoke. Altså da typisk med sine 20 tics. Og så er epoken over når alle prosesser har brukt opp sin tid. Og da kommer tida null for alle prosesser.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0023", "start": 1719.68, "end": 1814.56, "token_count": 300, "text": "Da kaller man ikke skeduleren. Da bare fortsetter den å kjøre til den er ferdig med sin epoke. Altså da typisk med sine 20 tics. Og så er epoken over når alle prosesser har brukt opp sin tid. Og da kommer tida null for alle prosesser. Og da starter man på nytt, og så deler scheduleren ut tics til alle prosesser som ønsker å... Og det er da en variabel som kalles priority, eller prioritet. Og den bestemmer da hvor mye seputid prosessene skal få. Og en prosess kan faktisk senke sin egen prioritet. Den kan be om lavere prioritet. I Linux gjør man det med commando nice. Og da får den prosessen mindre prioritet. Være så fair som bare mulig. Alle som ønsker CPU, tildeles omtrent like mye mange TIX. Og det er dette vi ser som vi så på i forrige uke, da vi kjørte fire og åtte prosesser på samme CPU. Det operativsystemet gjør, er å tildele TIX. Og den tildeler da i utgangspunktet like mange TIX til hver av prosessene. Time-kontum vil da kunne variere, sånn statistisk.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0024", "start": 1791.8, "end": 1878.96, "token_count": 293, "text": "da vi kjørte fire og åtte prosesser på samme CPU. Det operativsystemet gjør, er å tildele TIX. Og den tildeler da i utgangspunktet like mange TIX til hver av prosessene. Time-kontum vil da kunne variere, sånn statistisk. For dette er en dynamisk skedulering. For hver epoke så deles det ut nye tics. Og her er en sånn statistikk på... I Linux-kjerne 2.4 så var gjennomsnittlig time-kontum på 210 millisekunder. Altså så man måler og ser hvor langt det er time-kontum når du kjører en masse prosesser på... Og i 2006 var det omtrent 100 millisekunder. Hva var en epoke igjen? Jo, en epoke, det er liksom... Det er ikke en fast tid, men det er... Ved starten av en epoke, så har operativsystemet, så sjekker den en ready-liste. En liste over alle prosesser som har lyst til å brukes i pund. Det kan jo være noen som ligger i vektstilling eller venter på input og upput eller av en eller annen grunn ikke ønsker å kjøre.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0025", "start": 1858.74, "end": 1943.2, "token_count": 290, "text": "Ved starten av en epoke, så har operativsystemet, så sjekker den en ready-liste. En liste over alle prosesser som har lyst til å brukes i pund. Det kan jo være noen som ligger i vektstilling eller venter på input og upput eller av en eller annen grunn ikke ønsker å kjøre. Men alle prosesser som ønsker å kjøre, de blir da tildelt et time-kontum. Da kan det være at Prosess A får 30 tics, Prosess B får 20 tics, Prosess C får 10 tics. Og så setter man i gang med å kjøre. Den defineres av det tidsrommet 30 pluss 20 pluss 10. Og hvis ikke noe spesielt skjer, så kjøres de 60 ticsene, og så starter man på nytt igjen. Men da kan det være litt avhengig av om prosessen faktisk har brukt opp sine tics. Så kan operativstyret dynamisk tildele tics etter hvor mange man har brukt. Hvis man ikke bruker noe særlig med tics, så får man flere neste gang, sånn at man får høyere prioritet. Det er en del oppgaver denne uken.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0026", "start": 1918.76, "end": 1998.96, "token_count": 292, "text": "om prosessen faktisk har brukt opp sine tics. Så kan operativstyret dynamisk tildele tics etter hvor mange man har brukt. Hvis man ikke bruker noe særlig med tics, så får man flere neste gang, sånn at man får høyere prioritet. Det er en del oppgaver denne uken. Og så kan man også se på den vaffelrøreskreduleringen. Der bruker jeg akkurat dette her. At vi har en counter for hver prosess. Og så prioriterer de forskjellige. Vaffelprosessen og forelesningsprosessen har litt forskjellig prioritet. Hvis det kommer et time-it-itch, så kan det være den samme prosessen fortsetter litt til. Og det er for å gjøre det mer effektivt. For at det ikke skal gå bort for mye tid til context-switching. Alle operativsystemer har en eller annen form for prioritet på prosesser. Og i 2.6-hjernen så er det 140 forskjellige prioritetsklasser. Og hver sånn klasse tilsvarer et antall tillegg til tics i starten av en epoke. Og det scheduleren gjør, er at når den kommer inn,", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0027", "start": 1975.56, "end": 2059.32, "token_count": 292, "text": "Alle operativsystemer har en eller annen form for prioritet på prosesser. Og i 2.6-hjernen så er det 140 forskjellige prioritetsklasser. Og hver sånn klasse tilsvarer et antall tillegg til tics i starten av en epoke. Og det scheduleren gjør, er at når den kommer inn, så velger den prosessen som har høyest prioritet. Og så kjører den til den har brukt opp alle sine tillegg til tics, eller gir fra seg CPU-en. Og deretter kalles scheduleren på nytt. Og det er et viktig poeng, det der med at en eller gir fra seg CPU-en. Fordi... Det gjør at en prosess er veldig høyt prioritert. Og det kan typisk være sånne interaktive prosesser, sånn som en teksteditor. Den bruker veldig lite CPU, men akkurat når det kommer inn tasten F fra brukeren, så er det veldig viktig at den prosessen svarer kjapt. Og en teksteditor bruker vanligvis veldig lite CPU. Så den vil hele tiden få dynamisk høyere prioritet. Den vil komme veldig høyt opp. Men det som skjer da...", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0028", "start": 2032.96, "end": 2120.98, "token_count": 296, "text": "Den bruker veldig lite CPU, men akkurat når det kommer inn tasten F fra brukeren, så er det veldig viktig at den prosessen svarer kjapt. Og en teksteditor bruker vanligvis veldig lite CPU. Så den vil hele tiden få dynamisk høyere prioritet. Den vil komme veldig høyt opp. Men det som skjer da... Hvis en teksteditor får utdelt 120 tics, kommer veldig høyt opp... Så med en gang den har prosessert den ene bokstaven sin, så vil den overgis. Den vil stoppe og si at den ikke trenger CPU lenger. Dermed vil den beholde den høye prioriteten. Kanskje få enda et tics som kommer opp i 121. Sånn at neste gang når den kommer inn, så vil den alltid komme inn med en gang. Med en gang det kommer et interrupt, for når brukeren tasser F, så sendes et interrupt. Og da vil scheduleren... Den vil merke det, med et spesielt bit, som vi skal se på neste slide. Men scheduleren vil merke det, og teksteditorprosessen vil hoppe inn. Derimot, en regneprosess, sånn som den dot-regn, som...", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0029", "start": 2099.64, "end": 2174.32, "token_count": 292, "text": "så sendes et interrupt. Og da vil scheduleren... Den vil merke det, med et spesielt bit, som vi skal se på neste slide. Men scheduleren vil merke det, og teksteditorprosessen vil hoppe inn. Derimot, en regneprosess, sånn som den dot-regn, som... Den vil da hver gang i epoken bruke opp absolutt alle ticsene sine. Så den kommer kanskje ned til slutt til ti tics. Hver gang er det bare den som kjører. Da er det ti tics i epoken. Og den kjører da om og om igjen. Men den vil da... Hvis du hele tiden bruker opp ticsene, så vil du gå ned i prioritet. Men så lenge det ikke er noen andre som ønsker å kjøre, så er det helt greit å være nede i prioritet. For da får du likevel kjøre hele tiden. Men da vil interaktive prosesser bygges opp en høy prioritet og vil alltid komme raskt inn. Men de bruker likevel ikke mye CPU. Alle typer prosesser, både de som bruker mye CPU og ønsker å bruke mye CPU, og de som er interaktive og ikke bruker mye,", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0030", "start": 2157.04, "end": 2232.04, "token_count": 283, "text": "Men da vil interaktive prosesser bygges opp en høy prioritet og vil alltid komme raskt inn. Men de bruker likevel ikke mye CPU. Alle typer prosesser, både de som bruker mye CPU og ønsker å bruke mye CPU, og de som er interaktive og ikke bruker mye, de vil da kunne samkjøre innenfor samme system, uten at taxidirektoren vil oppleves som ekstremt treig, bare fordi det er en reinejobb som står og kjører. Og det er denne need reshed. Det står altså trenger reschedulering. Og det skjer hvis det i løpet av epoken kommer inn et interrupt, Det er en sånn 01-bit i CPU-en. Og hvis dette bitet blir satt, så vil scheduleren kjøres etter neste time-tick. Hvis det var en prosess som hadde la oss si 20 tic, så ville bare scheduleren gå inn og kontrollere om det har skjedd noen interrupts. Nei, det har ikke det. Ok, da bare kjører samme prosess videre. Og da kjøres scheduleren på nytt. Og da kan en gå inn og say...", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0031", "start": 2208.64, "end": 2295.76, "token_count": 287, "text": "Hvis det var en prosess som hadde la oss si 20 tic, så ville bare scheduleren gå inn og kontrollere om det har skjedd noen interrupts. Nei, det har ikke det. Ok, da bare kjører samme prosess videre. Og da kjøres scheduleren på nytt. Og da kan en gå inn og say... Ok, da gir jeg den prosessen som har høyest prioritet, den får nå kjøre. Og typisk er det da interaktive prosesser som har bygd seg opp høy prioritet ved å ikke bruke CPU-en. Du får liksom goodwill. Når jeg kommer inn, så bruker jeg omtrent ikke CPU. Og det er akkurat sånn scheduleren bygger opp systemet. Noe tilsvarende må alle andre schedulere gjøre også. Dette er en veldig viktig mekanisme når du skal kjøre både interaktive prosesser og regneprosesser samtidig på det samme systemet. Hvis vi ikke hadde sånn, så måtte man vente helt til den CPU-intensive prosessen var ferdig med sin del. Og hvis jeg tok flere tidels sekunder, så ville det oppleves som veldig tregt for en interaktiv prosess.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0032", "start": 2272.92, "end": 2378.96, "token_count": 284, "text": "på det samme systemet. Hvis vi ikke hadde sånn, så måtte man vente helt til den CPU-intensive prosessen var ferdig med sin del. Og hvis jeg tok flere tidels sekunder, så ville det oppleves som veldig tregt for en interaktiv prosess. Ok. Dette var de viktige prinsippene bak schedulering. For de to viktigste prinsippene var user mode og curl mode, og i tillegg systemkall og trap. Disse begrepene må dere ha greie på. Det er det viktigste når det gjelder operativsystemskedulering. Så tenkte jeg å kunne si litt om denne simuleringen som jeg snakket om. Skal vi se... Her. Skedulering av... Samtidig forelesning og vaffelrørlaging. Ja, dere kan jo i fred og ro kose dere med denne videoen. Litt popkorn og cola og så videre. Så kan dere se da hvordan et operativsystem virker i praksis. Det jeg har prøvd å gjøre her, er altså å lage et operativsystem som bruker dette med poker fra Linux26-kjernen. Stort sett opererer på samme måte.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0033", "start": 2355.68, "end": 2442.4, "token_count": 293, "text": "Litt popkorn og cola og så videre. Så kan dere se da hvordan et operativsystem virker i praksis. Det jeg har prøvd å gjøre her, er altså å lage et operativsystem som bruker dette med poker fra Linux26-kjernen. Stort sett opererer på samme måte. Og da vil dere se i videoen at jeg har på en bandyhjelm. Eller en sykkelhjelm. Iallfall en hjelm. Og hovedpoenget med den er at den hjelmen, det er modusbyttet. Så dere kan se... Når timeren går av, så tar jeg på meg hjelmen. Og dette skal da skje automatisk. Det er på en måte hardware som vi gjør. En gang jeg sier 'Den piper', så skal hjelmen komme på av seg selv. Det er vanskelig å være operativsystem, så det er ikke alt jeg klarer å få det helt til. Men det er utgangspunktet. Så det er da et ytre interrupt. Og så i tillegg så har vi noen... Ja, dette er da institusjoner, operativsystem... Kanskje dette er kjernen. Så jeg starter opp med å lese ReadyList over prosesser", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0034", "start": 2417.3, "end": 2502.1, "token_count": 282, "text": "så det er ikke alt jeg klarer å få det helt til. Men det er utgangspunktet. Så det er da et ytre interrupt. Og så i tillegg så har vi noen... Ja, dette er da institusjoner, operativsystem... Kanskje dette er kjernen. Så jeg starter opp med å lese ReadyList over prosesser som jeg ønsker skal kjøre. Og så... Og så er det da to prosesser. Du kan hoppe til det. Vaffelprosess og Forelesningsprosess. Og disse to prosessene, det er da to programmer som jeg ønsker å kjøre. Og vaffelprosessen... Det er omtrent sånn som jeg lager vafler. Selv om jeg ikke skriver ned assembly-kode for det. Blander 100 gram sukker og mel og visper. Og så sjekker jeg om det er blandet. Det er da en typisk compare-oppgave. JMPNB - jump not blandet. Da hopper jeg tilbake. Og så fortsetter det sånn. Men så kommer det et viktig poeng i denne sammenheng. Og det er når jeg skal hente melk... Det tilsvarer på en måte at jeg skal...", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0035", "start": 2480.22, "end": 2570.72, "token_count": 295, "text": "om det er blandet. Det er da en typisk compare-oppgave. JMPNB - jump not blandet. Da hopper jeg tilbake. Og så fortsetter det sånn. Men så kommer det et viktig poeng i denne sammenheng. Og det er når jeg skal hente melk... Det tilsvarer på en måte at jeg skal... Nå trenger jeg melk til røra, og det ligger på disk. Og da må jeg gjøre et systemkall. For det å hente melk, det må jeg få hjelp av operativsystemkjernen til å gjøre. Og da er jeg et vanlig program som opererer uten hjelm. Og så når jeg da gjør et systemkall... Da kommer hjelmen på, for da må jeg be Operativsteam Kjernen om hjelp. Og så ber kjernen... Den setter i gang den prosessen. Eller da hopper vi tilbake til kjernekode et eller annet sted her. Jo, her er det... Legg melk i buffer. Sett need rechard, osv. Eva, som mange av dere kjenner fra diskrematematikk, som er melkemannen i dette opplegget... Kan du si spoiler alert? At det fungerer ikke helt optimalt?", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0036", "start": 2541.24, "end": 2634.68, "token_count": 281, "text": "Eller da hopper vi tilbake til kjernekode et eller annet sted her. Jo, her er det... Legg melk i buffer. Sett need rechard, osv. Eva, som mange av dere kjenner fra diskrematematikk, som er melkemannen i dette opplegget... Kan du si spoiler alert? At det fungerer ikke helt optimalt? For tanken er at... Dette med å hente melk skal ta veldig lang tid. Men det har jeg ikke formidlet godt nok. Og Eva står på døra med melken med en gang. Da blir det litt forviklinger. Dere får se. Men... Og hovedpoenget er da at... En vanlig brukerprosess må be om hjelp fra operativstemme, og da tar den på en måte frivillig på seg hjelmen og kommer over i køllen mot. Mens så vil det hvert minutt så skjer det et timertick. For jeg har en hardware timer. Hvert minutt så ringer den. Da kommer hjelmen automatisk rett på. Her er en time-off-call. Det er da på en måte... Det er den interrupt-rutinen som man hopper til når det kommer", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0037", "start": 2605.36, "end": 2699.16, "token_count": 295, "text": "Mens så vil det hvert minutt så skjer det et timertick. For jeg har en hardware timer. Hvert minutt så ringer den. Da kommer hjelmen automatisk rett på. Her er en time-off-call. Det er da på en måte... Det er den interrupt-rutinen som man hopper til når det kommer en time-off-call. Da sjekkes det om kontra null. Summen av alle er null. Det startes en ny epoke. Hvis ikke, så... Hvis den ene contoen er null, så flyttes den fra readylist. Så gjør man et kall til scheduler. Så kommer scheduleren inn, og da velger den en av de to prosessene som skal kjøre. Men hvis det ikke har skjedd noe spesielt, så er det bare den prosessen som står og kjører. Som fortsetter, sånn at man unngår kontekst-switch. Hvis ikke, så må man sette i gang et kontekst-switch. Og da må jeg liksom... Enten så switcher man da til vaffellaging. Eller så switcher man til forelesningsprosessen. Og forelesningsprosessen, det er... Det er denne prosessen her, hvor jeg har dagens faktum og snakker om Linux.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0038", "start": 2678.54, "end": 2760.04, "token_count": 298, "text": "Hvis ikke, så må man sette i gang et kontekst-switch. Og da må jeg liksom... Enten så switcher man da til vaffellaging. Eller så switcher man til forelesningsprosessen. Og forelesningsprosessen, det er... Det er denne prosessen her, hvor jeg har dagens faktum og snakker om Linux. Og utviklingen av Linux, og Linus Thorvalds bor på en hybel i Helsinki, osv.... Det er da altså operasjoner som... Jeg som hardware ønsker å få utført disse to prosessene her samtidig. Og så ønsker jeg at de ikke skal ødelegge for hverandre. Og da har jeg da den tredje prosessen, som er operativ stemkjernen, som sørger for at disse to samkjører på en riktig måte. Og det er sånn jeg gjør det. Den ligger ganske så tett opp til Linux 26-kjernen med poker. Relativt realistisk simulering. Så... Men den ligger som sagt her. Ja, dere har også å se på OSEGG. Det er liksom høydepunktet. Her vil dere se hvorfor det er viktig å ha på seg hjelm når man skal knuse egg.", "source": "lecture"}
{"lecture_id": "os8time2", "chunk_id": "os8time2_0039", "start": 2735.04, "end": 2925.82, "token_count": 297, "text": "Relativt realistisk simulering. Så... Men den ligger som sagt her. Ja, dere har også å se på OSEGG. Det er liksom høydepunktet. Her vil dere se hvorfor det er viktig å ha på seg hjelm når man skal knuse egg. For å knuse egg er opplagt noe som du må gjøre med et systemkall. Det kan ikke en vanlig brukerprosess gjøre. Så jeg håper dere får... Det skal jeg også ha litt fornøyelse av å se på dette her. Men samtidig så er det veldig seriøst. Det er akkurat sånn... Eller det er veldig tett opptil hvordan operativsystemet utfører sin kjernevirksomhet. Bruke hjelm når man klekker egg? Nei, når man knuser egg. Det er da man må bruke hjelm. Ok. Da tenker jeg vi tar en pause der, så er det lab etterpå. Det er vanskelig å forstå hvordan det er å være gravid. Hvordan var det å jobbe på sykehuset i Storbritannia? Hvordan var det å jobbe på sykehuset i Storbritannia? ... og det er veldig vanskelig å forstå hvordan det er å leve i en slik situasjon.", "source": "lecture"}
{"lecture_id": "os12del1", "chunk_id": "os12del1_0000", "start": 0.0, "end": 97.72, "token_count": 282, "text": "Som vi ser, så har vi ikke så mange uker igjen med kursinnhold. Det blir... Det er muligens at vi kommer til å fortsette... Vi skal se på det i løpet av dagen. Tirsdag 27. Jeg tror det er litt kort... Det er bare én forelesning til internminene og så disker og filsystemer. Så det er mulig det forlenges inn til tirsdag 27. Men det kommer ikke til å bli så veldig mye mer på den praktiske delen. Jeg annonserte Dokkerhub før påske, men i hvert fall utsatte det. Og det er uansett ikke veldig mye mer vi skal snakke om dokker. Eller ekstra stoff om dokker. Men det kommer en runde til med Powershell, Windows Powershell. Der var det en digital forelesning som ble lagt ut i påsken. Og så kommer det en til i løpet av morgendagen. Og det er en praktisk del om å skrive påvarsellsskript og å bruke påvarsell fra kommandolinje. En ting som er fint med Powershell, er at den ligner veldig på Linux på bæsj selv.", "source": "lecture"}
{"lecture_id": "os12del1", "chunk_id": "os12del1_0001", "start": 72.04, "end": 127.5, "token_count": 164, "text": "Og så kommer det en til i løpet av morgendagen. Og det er en praktisk del om å skrive påvarsellsskript og å bruke påvarsell fra kommandolinje. En ting som er fint med Powershell, er at den ligner veldig på Linux på bæsj selv. Så det er inspirert av det. Sånn at veldig mange kommandoene kan du faktisk bruke direkte. Sånn som CP og MV og mange andre kommandoer. Sånn at man i noen tilfeller kan ta Shell-script og bare paste inn og kjøre som Powershell-script. Så det er... Vi har også mange oppgaver denne uken som går på det med få og se.", "source": "lecture"}
{"lecture_id": "os6del10", "chunk_id": "os6del10_0000", "start": 0.0, "end": 101.48, "token_count": 300, "text": "Unix operativstemmer. Det er på en måte en helt annen verden. Men opprinnelig, sånn på 80-tallet, så var Unix på en måte der Linux var for ti år siden. At det var nytt og spennende og åpen kildekode og brukt på universiteter og så videre. Så utviklet det seg til kommersielle 64-bit. Da var det firmaer som IBM, Sun, HP, Silicon Graphics og andre som bygde egne Unix operativsystemer. Da var det typiske at IBM hadde egen hardware med helt egne institusjoner osv., og så hadde de et eget operativsystem. Så hadde Sun spark-prosessorer og også sitt eget operativsystem. De hadde mange forskjellige operativsystem og konkurrerte med hverandre. Det endte etter hvert med at Linux tok over rollen til alle disse her. Og nå er det veldig få av den type Unix-operativsystem som eksisterer. Det aller meste som kjører ute i serverrom, er Linux- eller Windows-servere. Det var disse frie Unix-klonene som etter hvert tok over. Som da var åpen kildekode-varianter av de store kommersielle Unix-systemene som var lukkede. Der var også lukket kildekode.", "source": "lecture"}
{"lecture_id": "os6del10", "chunk_id": "os6del10_0001", "start": 77.84, "end": 163.7, "token_count": 237, "text": "Det aller meste som kjører ute i serverrom, er Linux- eller Windows-servere. Det var disse frie Unix-klonene som etter hvert tok over. Som da var åpen kildekode-varianter av de store kommersielle Unix-systemene som var lukkede. Der var også lukket kildekode. Spesielt da Linux er åpen kildekode og har tatt over veldig mye av det som er i serververdenen. Spesielt sånn HP, high performance computing, så er alle... De tusen raskeste high-performance-computerne er bygd på Linux. Ja, MacOS er også delvis bygd på Linux. Det vil si den Mac-kjernen Darwin, den bygger delvis på FreeBSD. Så sånn sett så kan du si at Mac har noe av Unix i seg. Og vi kan også se at f.eks. hos AMX, så kan du bare kjøre et vanlig skjell. Så det er ganske tett integrert med Linux. Ikke så veldig stort forsøk.", "source": "lecture"}
{"lecture_id": "os13del18", "chunk_id": "os13del18_0000", "start": 0.0, "end": 104.2, "token_count": 300, "text": "Paging gjør da at man deler inn programmer, prog1 og prog2, i sider på denne måten her. Og så har man... Og så har man fysisk ram som ligger imellom her. Da kan det være at ikke alle sidene i disse to programmene ligger i ram. Kanskje være page 3 fra program 1 og page 0 fra program 1 og page 4 fra program 2. De andre vil da ligge på disken. Disse sidene ligger da på swap-området på disken. Det er typisk noe tilfelle hvor man får problemer hvor det ikke er plass til alle programmene i RAM samtidig. Da sliter man, hvor da begynner... Da kaller man det swapping. Hvis du har en fysisk disk, vil du kunne høre at den disken kjører og kjører. For hele tiden flyttes ting inn og ut av minnet fra disken. Og det går ekstremt tregt. Og det er da ting virkelig går sakte på en maskin. Ja... Oi, jeg ser vi har mye tid for å avslutte der. Det er algoritmer som bestemmer hvilke sider som skal ligge i ramm, og det er da en del av operativsystemet som gjør paging.", "source": "lecture"}
{"lecture_id": "os13del18", "chunk_id": "os13del18_0001", "start": 78.2, "end": 145.0, "token_count": 213, "text": "Og det er da ting virkelig går sakte på en maskin. Ja... Oi, jeg ser vi har mye tid for å avslutte der. Det er algoritmer som bestemmer hvilke sider som skal ligge i ramm, og det er da en del av operativsystemet som gjør paging. Det typiske som skjer, er at du får en pagefault. Det er da man adresserer noe... En adresse som ikke ligger i ramm, men som ligger ute på disk. Og det tar veldig lang tid, for da må... Da må man fysisk ut på disken, hente det inn i RAM, og så varsle alt. Så typisk vil da en prosess, den vil da scheduleres ut mens man venter på denne siden. Men de algoritmene som da bestemmer hvilke sider skal ligge inne, og hvilke skal ligge på disk, det er pitching-algoritmer.", "source": "lecture"}
{"lecture_id": "linux4del10", "chunk_id": "linux4del10_0000", "start": 0.0, "end": 108.68, "token_count": 290, "text": "Skript og argumenter Argumenter blir lagret i spesielle variabler når de kjøres. Så hvis vi f.eks. kjører et skript argscript.chell med argumentene fil 1, fil 2 og fil 3, så ser vi at første argument, fil 1, det blir lagret i en variabel dollar 1. Andre argument, fil 2, blir lagret i dollar 2. Jeg tror man kan ha opptil ni argumenter på den måten her. I tillegg blir alle argumentene samlet. Det blir lagret i denne strengen her. Og antall argumenter ligger i en spesiell streng dollar-hash-tegn. Så dollar-stjerne gir hele strengen, og dollar-hashtag gir antall argumenter. Så da kan vi se på... Vi kan skrive det skriptet. La oss si jeg kaller det Arigdotcel. Så kan jeg prøve å... Ja, det som man ofte gjør, er å legge inn en test. Typisk noe sånt som hvis antall argumenter er mindre enn én. Og si at du er nødt til å ha med argumenter. Da kan man kjøre en sånn test, og så kan man si... Gi en melding. Gi et argument.", "source": "lecture"}
{"lecture_id": "linux4del10", "chunk_id": "linux4del10_0001", "start": 74.96, "end": 182.94, "token_count": 296, "text": "er å legge inn en test. Typisk noe sånt som hvis antall argumenter er mindre enn én. Og si at du er nødt til å ha med argumenter. Da kan man kjøre en sånn test, og så kan man si... Gi en melding. Gi et argument. Og så kan man ta exit. Kan du kjøre exit sånn som det? Men for å vise også hvordan exit-verdier virker, kan vi si... Exit 3. Sånn. Og så kan vi prøve å kjøre dette skriptet. Hvis jeg nå kjører det med et argument, fil 1, så skjer det ingenting. Da kan man gå inn og behandle det argumentet. Men hvis jeg kjører uten argument nå, så ser vi at vi får en feilmelding i ett argument. Så vil vi også kunne se at dollarspørsmålstegn... Det inneholder den exit-verdien. Så det tretallet der kommer nå ut her som exit-verdi. Så det er det dollar-spørsmålstegn inneholder. Vanligvis, hvis jeg bare hadde gjort exit her... Vi kan se hva som skjer da. Da skal en standard exit-verdi, det skal vel være... Null. Ja, og da ser vi at det gir standard exit verdi null.", "source": "lecture"}
{"lecture_id": "linux4del10", "chunk_id": "linux4del10_0002", "start": 160.32, "end": 277.48, "token_count": 296, "text": "Så det er det dollar-spørsmålstegn inneholder. Vanligvis, hvis jeg bare hadde gjort exit her... Vi kan se hva som skjer da. Da skal en standard exit-verdi, det skal vel være... Null. Ja, og da ser vi at det gir standard exit verdi null. Så følger det an i en feilmelding, så er det vanlig å gi et tall. Så exit 1 er en standard error. Ok. Så kan vi prøve, når man først har fått inn minst ett argument, så kan man prøve å behandle argumentene. En måte å gjøre det på er da for arg... Vi ønsker å løpe gjennom alle argumentene. Og Dollar stjerne gir alle argumentene. Så for hvert argument nå, så kan vi f.eks. skrive det ut. Sånn. Det skal vi da skrive ut. Hvis vi nå prøver å kjøre det... Legger til et par argumenter, fil 1 og fil 2, så får vi ut argumentene. Så skal vi fylle på med flere argumenter på den måten her. Så kan vi også skrive ut... La oss si... Antall argumenter. Hvis du husker hva det var, så er det dollar, hashtag og sånn.", "source": "lecture"}
{"lecture_id": "linux4del10", "chunk_id": "linux4del10_0003", "start": 244.12, "end": 294.72, "token_count": 126, "text": "Legger til et par argumenter, fil 1 og fil 2, så får vi ut argumentene. Så skal vi fylle på med flere argumenter på den måten her. Så kan vi også skrive ut... La oss si... Antall argumenter. Hvis du husker hva det var, så er det dollar, hashtag og sånn. Hvis jeg kjører den sammen nå, så ser vi at du får et antall argumenter lik tre. Og på denne måten så kan man styre alt som har med argumenter å gjøre, til script.", "source": "lecture"}
{"lecture_id": "os4del2", "chunk_id": "os4del2_0000", "start": 0.0, "end": 93.6, "token_count": 296, "text": "I dag skal vi se på maskinkode og assembly og C-C-programmering. Det vi holdt på med i... Eller aller først så skal vi ta en ekstra titt på simuleringsmaskinen. For det er et par ting der som vi skal gjøre, som vi ikke så så nøye på forrige gang. Så vi tar en liten rekapitulering av det vi holdt på med sist, med den simulerte maskinen. Men det vi skal gjøre videre i dag, er å se hvordan den maskinkoden og ensemble-koden som vi har i simuleringen, faktisk er mer eller mindre nøyaktig den samme som man har i X86-arkitekturen. Det er én maskinarkitektur som er den mest vanlige, som de aller fleste PC-er og servere kjører på, er Exo-86. Så det er én helt spesiell arkitektur, hvor det er definert maskininstitusjoner, akkurat som vi definerer maskininstitusjoner i den simulerte maskinen. Og det er den som lager maskinen, som bare definerer sånn skal institusjonene se ut. Ad skal være institusjon nummer fire. For andre arkitekturer vil dette være forskjellig.", "source": "lecture"}
{"lecture_id": "os4del2", "chunk_id": "os4del2_0001", "start": 70.66, "end": 130.28, "token_count": 217, "text": "Så det er én helt spesiell arkitektur, hvor det er definert maskininstitusjoner, akkurat som vi definerer maskininstitusjoner i den simulerte maskinen. Og det er den som lager maskinen, som bare definerer sånn skal institusjonene se ut. Ad skal være institusjon nummer fire. For andre arkitekturer vil dette være forskjellig. Forskjellig nummerering på instruksjoner, og de kan være litt forskjellige. Et annet eksempel er ARM, som er maskinarkitekturen som er brukt av alle prosessorene som sitter i mobiler. Så ARM er det som det er laget mest av av CPU-er. 100 mrd. eller noe sånt. Det er ekstremt mange CPU-er. ARM har andre institusjoner enn X86 og X86 har andre institusjoner enn vår.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0000", "start": 0.0, "end": 103.8, "token_count": 295, "text": "Ja. God morgen, alle sammen. Som alltid er det veldig hyggelig å se at så mange av dere har kommet dere opp og er klar for operativstem-forløsning. Det er kjempebra. Jeg vet jo ikke hvordan det går fremover. Vi kan jo håpe det blir fysiske forelesninger. Men det er som dere vet, så er det fortsatt uklart. Men vi håper at vi etter hvert skal komme i gang. Men som dere ser på timeplanen her, så er det... Ja, så har vi kommet ganske langt. Vi er nå i uke syv, så i neste uke er det konteuke. Men ingen vanlige forelesninger. Og det er heller ikke nye oppgaver. Som det står her, er det ikke oppgaver pga. konteeksamen. Så... Så da er det ikke nye oppgaver. Men jeg tenker... Det er heller ikke lagt ut noen container og dokker, som er neste tema. Men jeg tenkte å gjøre det i løpet av uka. Kan komme i gang med oppgave fra uke ni. For de som er veldig hyppe på å komme i gang med det, så skal vi se veldig kort på hvordan dere kan starte dokkecontainere", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0001", "start": 78.44, "end": 185.92, "token_count": 283, "text": "Men jeg tenker... Det er heller ikke lagt ut noen container og dokker, som er neste tema. Men jeg tenkte å gjøre det i løpet av uka. Kan komme i gang med oppgave fra uke ni. For de som er veldig hyppe på å komme i gang med det, så skal vi se veldig kort på hvordan dere kan starte dokkecontainere i Linux-VM-ene, sånn at dere kan komme i gang med å eksperimentere. Det var litt uklart med Ine og Rune i dag, men jeg tror etter hvert kanskje begge kommer. Så uansett... Som vanlig så legger jeg det ut etter hvert. Jeg lurer på om jeg kanskje ikke har husket å... Jeg legger det ut etter hvert. Redigere fra forrige gang... Altså... Nei. Der ser jeg vi bare har uredigerte opptak. Men det kommer jeg også til å gjøre i løpet av uka. Redigere disse og legge det ut under enkelttemaer. Så det er litt lettere å bli hvis man står fast med problemer i oppgaver f.eks. Temaet i dag er multitasking fortsatt.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0002", "start": 160.88, "end": 269.84, "token_count": 292, "text": "Men det kommer jeg også til å gjøre i løpet av uka. Redigere disse og legge det ut under enkelttemaer. Så det er litt lettere å bli hvis man står fast med problemer i oppgaver f.eks. Temaet i dag er multitasking fortsatt. Vi så forrige gang på multitasking litt sånn i... Skal vi se... Hadde jeg en sist... Nei, det hadde jeg ikke. Vi kan gå tilbake til forrige gang. Ja, vi avsluttet dette med Branch Prediction. Og så så vi litt på... Operativsystemhistorie. Og så så vi på multitasking. Og for å repetere det veldig fort, så er... Hovedideen er at prosesser bytter på. Man kan bruke... Oi... Kan du dele skjermen? Betyr det at dere ikke ser skjermen min? Jeg ser, ja. Jeg ser skjermen. Ja, fint. For det jeg gjør, er å... Jo, jeg deler det vinduet som jeg ser, sånn at da må du... Ja, hvis dere ikke ser vinduet, så kanskje prøve å logge på igjen på Zoom. Kjempebra at dere svarer kjapt. De fleste ser her i hvert fall.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0003", "start": 240.0, "end": 323.32, "token_count": 288, "text": "Jeg ser, ja. Jeg ser skjermen. Ja, fint. For det jeg gjør, er å... Jo, jeg deler det vinduet som jeg ser, sånn at da må du... Ja, hvis dere ikke ser vinduet, så kanskje prøve å logge på igjen på Zoom. Kjempebra at dere svarer kjapt. De fleste ser her i hvert fall. Ok... Ja, så da ser dere her. Dette er liksom grunnideen i multitasking. Vi har tre prosesser P1, P2 og P3. Og så bytter man hele tiden på hvilken av de prosessene som kjører. Og hele tiden, det er veldig ofte. Her ser du det som millisekunder. Da kommer det en ny prosess inn og tar over CPU-en og kjører. Først kjører P1. Altså er det i løpet av et mikrosekund her, kanskje enda mindre, så skjer det en kontekst switch. P1 hives ut. P2 kommer inn. Og sånn fortsetter en evig løkke. Og det er ikke alltid at det er noen som ønsker å bruke CPU-en, selv om du bare har én CPU.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0004", "start": 305.32, "end": 385.48, "token_count": 286, "text": "Først kjører P1. Altså er det i løpet av et mikrosekund her, kanskje enda mindre, så skjer det en kontekst switch. P1 hives ut. P2 kommer inn. Og sånn fortsetter en evig løkke. Og det er ikke alltid at det er noen som ønsker å bruke CPU-en, selv om du bare har én CPU. De fleste prosesser vil bare stå og vente, kanskje på input og gjøre noe en gang iblant. Man har regnejobber som skal regne ut et eller annet, eller de skal rendre en video, gjøre masse operasjoner for å få ut de riktige pikslene. En skal vri bildet 50 grader, og så må man regne ut hvilke piksler som kommer ut. Da står CPU-en og jobber hele tiden. Eller en kompilator som lager maskinkode. Den bruker jeg også CPU helt tiden. Så dette er hovedideene bak multitasking. Og så begynte vi forrige gang så vidt å se på multitasking i en server som har én CPU. Og da så vi at den serveren, den gjorde akkurat dette her.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0005", "start": 360.0, "end": 465.2, "token_count": 291, "text": "Den bruker jeg også CPU helt tiden. Så dette er hovedideene bak multitasking. Og så begynte vi forrige gang så vidt å se på multitasking i en server som har én CPU. Og da så vi at den serveren, den gjorde akkurat dette her. Hvis det kom to regnejobber som sto og regnet, så... Og så fikk de 50 % CPU-tid hver. Og det vi skal fortsette med i dag, er å se på multitasking med... Altså multicore multitasking. At du har mange CPU-er som kjører i parallell. Og da skal vi se på hvordan jobbene da blir fordelt mellom CPU-ene. Vi fortsetter omtrent der vi slapp i hvert fall. Så... Det jeg tenkte oss å se på da, var å prøve å regne på en regnejobb. Dette er et lite script, som bare står og regner tre millioner ganger så legger den sammen i pluss én. En økning med, og så legger den sammen og lager en sum. Det er ikke så viktig akkurat hva den gjør, men poenget er at et sånt program vil bruke så mye CPU som det bare kan.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0006", "start": 444.2, "end": 539.98, "token_count": 288, "text": "tre millioner ganger så legger den sammen i pluss én. En økning med, og så legger den sammen og lager en sum. Det er ikke så viktig akkurat hva den gjør, men poenget er at et sånt program vil bruke så mye CPU som det bare kan. Helt innen står det 'bruker CPU'. Den hviler aldri 'bruker helt innen CPU'. Og da kan vi se på topp samtidig. Som står og går. Og hvis jeg nå kjører en regnejobb... Time tar tiden på regnejobben. Da ser vi at øverste linje her toppsorterer default etter hvilke prosesser som bruker mest CPU. Og øverste linje her, det vil da være toppsortering. Da ser vi ikke... Vi så ikke navnet på regnejobben, men det er fordi jeg har et litt lite toppvindu. Hvis vi drar litt lenger bort her nå... Sånn. Der kan vi se. Dette er regnejobben som står og kjører. Og den får 100 % CPU. Ved å taste én i topp så kan jeg se hvor mange CPU-er det er. Og da ser jeg denne maskinen her.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0007", "start": 521.5, "end": 599.98, "token_count": 300, "text": "Hvis vi drar litt lenger bort her nå... Sånn. Der kan vi se. Dette er regnejobben som står og kjører. Og den får 100 % CPU. Ved å taste én i topp så kan jeg se hvor mange CPU-er det er. Og da ser jeg denne maskinen her. Dette er egentlig en desktop. Min desktop som står nede på OsloMet, den har to CPU-er. Iallfall... Hvis vi skal se senere, så har den egentlig fire, eller faktisk åtte, hvis du regner med hypertrening, men jeg har skrudd av de andre CPU-ene. Så i dette tilfellet så ser dette nøyaktig ut som en CPU, ei, en desktop som har to CPU-er. I forelesningshåndtatene så... Så har jeg et tilsvarende eksempel med den gamle Macen min, som også har to CPU-er. Men i prinsippet skjer det nøyaktig det samme. For det vi kan prøve å få til her, det er hva skjer om vi nå kjører to regnejobber samtidig. Da kan jeg lage en liten løkke for i-inn 1.2. Og så inn i den løkka så kan jeg ta...", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0008", "start": 581.38, "end": 672.76, "token_count": 293, "text": "For det vi kan prøve å få til her, det er hva skjer om vi nå kjører to regnejobber samtidig. Da kan jeg lage en liten løkke for i-inn 1.2. Og så inn i den løkka så kan jeg ta... Og time regnejobben. Og så kan jeg legge den i bakgrunnen. Sånn at det som vil skje nå, er at to regnejobber startes helt samtidig. Don. Og da ser vi i topp at her er det to regnejobber som starter. Og siden denne serveren har to CPU-er, så ser vi at de jobber på hver sin CPU. Det går an å se hvilken CPU som blir brukt. Nå tastes det F i topp. Da kan vi styre hvilke kolonner som brukes. Hvis man blar nedover her, så vil man se... Her er det en kolonne som heter Last Used CPU. Hvis jeg nå taster Space her, så får jeg et merke på den. Og Escape går nå tilbake. Og da... Vil jeg se... hvis jeg lager vinduet litt større... Så vil jeg se at ytterst her så kommer det en kolonne hvor det står P, og det er Last Used CPU.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0009", "start": 649.46, "end": 739.24, "token_count": 299, "text": "Hvis jeg nå taster Space her, så får jeg et merke på den. Og Escape går nå tilbake. Og da... Vil jeg se... hvis jeg lager vinduet litt større... Så vil jeg se at ytterst her så kommer det en kolonne hvor det står P, og det er Last Used CPU. Så det er på en måte en statistikk på hvilken CPU ble sist brukt av prosessene som listes. Hvis jeg nå starter regnejobben på nytt, så ser vi at det er... Den kjører på SUP1. Og den prosessen med den i den kjører på null. Så kan vi se det hender de bytter om, men stort sett sånn som nå, så kjører de hele tiden på samme SUP1. Så kan man spørre seg hva det er som skjer hvis jeg nå kjører tre SUPU-er? Det skjedde med to CPU-er. Kan ta det en gang til eksplosivt. Når jeg har to CPU-er, så er på en måte ikke dette multitasking, fordi de kjører på to forskjellige CPU-er. Så de kjører reelt sett samtidig. Multitasking er når de bytter på på samme CPU-er.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0010", "start": 720.0, "end": 802.92, "token_count": 298, "text": "Det skjedde med to CPU-er. Kan ta det en gang til eksplosivt. Når jeg har to CPU-er, så er på en måte ikke dette multitasking, fordi de kjører på to forskjellige CPU-er. Så de kjører reelt sett samtidig. Multitasking er når de bytter på på samme CPU-er. Så dette er SMP - Simultaneous Multiprocessing. Men SMP, da kjører man samtidig på to forskjellige regneenheter. To forskjellige kjerner, eller CPU-er. Eller course. Så én core er da én regneenhet. Jeg sier ofte CPU, så da mener jeg én regneenhet. Vi kan jo ha mange cours inne på én CPU. Men sånn i... Hvis jeg sier CPU uten å spesifisere noe, Og spesielt så tenker jeg på en core, eller en enkelt rein enhet. Og det er det også OS og Topp rapporterer det som. Så da kan vi prøve å kjøre... Skal vi se... Hvor var vi? Ja, den forløkken. Én, to. Så kan vi prøve å øke den forløkken til tre.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0011", "start": 785.84, "end": 862.56, "token_count": 289, "text": "Og det er det også OS og Topp rapporterer det som. Så da kan vi prøve å kjøre... Skal vi se... Hvor var vi? Ja, den forløkken. Én, to. Så kan vi prøve å øke den forløkken til tre. Sånn at vi kjører tre prosesser samtidig. Og da ser vi... Da får de plutselig ikke 75 %, men de får noe sånn som 67 %. Eller da to tredjedeler. Og da ser vi at her bytter... Her er det i hvert fall én av prosessene som bytter hele tiden. For noen ganger kjører begge på én, og andre ganger kjører begge på null. Og den måten å gjøre dette på, det er fair scheduling. Den som fordeler hvilke prosesser som kjører hvor. Den heter Fair Scheduler, og den prøver å gi så lik CPU-tid til alle prosesser som mulig. Her er det tre stykker som hele tiden vil ha CPU. Da fordeler den det ved at hele tiden kjører det en på hver av CPU-ene. Så bytter man på hvilken av de tredje som kjører.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0012", "start": 844.56, "end": 925.44, "token_count": 287, "text": "Den heter Fair Scheduler, og den prøver å gi så lik CPU-tid til alle prosesser som mulig. Her er det tre stykker som hele tiden vil ha CPU. Da fordeler den det ved at hele tiden kjører det en på hver av CPU-ene. Så bytter man på hvilken av de tredje som kjører. Det byttes ganske ofte, noen ganger i sekundene. Men ikke hele tiden, for det koster en del å bytte fra... Men på den måten så ser vi at alle de prosessene, de bruker omtrent like lang tid. Men du ser, det er litt forskjell. 25 på den ene og 26,5 på den andre og 26,7 på den tredje. Men sånn, røft sett, så prøver man å gi like mye CPU til hver. Og sånn kan vi fortsette. Vi kan prøve å se hvordan dette her ser ut på... På en maskin med fire sepur. Og det jeg skal gjøre i bakgrunnen da, det er å jukse litt. Ved å skru på noen sepur i bakgrunnen. På den Linux-maskinen så kan jeg gjøre det fra kommandolinja.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0013", "start": 900.0, "end": 998.96, "token_count": 293, "text": "På en maskin med fire sepur. Og det jeg skal gjøre i bakgrunnen da, det er å jukse litt. Ved å skru på noen sepur i bakgrunnen. På den Linux-maskinen så kan jeg gjøre det fra kommandolinja. Jeg må riktignok være Ruth, men jeg kan aktivere sepur. Det jeg gjorde i bakgrunnen nå... Jeg skal se på hvordan jeg gjør det senere. Det var å aktivere to til av CPU-ene, sånn at jeg skulle ha fire. Da må jeg gå inn og ut igjen med topp. Hvis jeg taster én nå, så ser vi øverst her. Jeg tastet én, og da får jeg ut at nå har denne serveren her fire CPU-er. Og hvis jeg nå kjører akkurat samme med tre regnejobber, så ser vi at da kommer de tre regnejobbene i gang. Og så får de nå hver sin CPU. Hvis jeg legger inn \".Last Used CPU igjen... Så starter vi på nytt, for det var ferdige.Så ser vi... Vi ser at nå så står de på 3, 2 og 1. Vi kan vel også se at de står fast der. Stort sett...", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0014", "start": 976.72, "end": 1072.64, "token_count": 283, "text": "Hvis jeg legger inn \".Last Used CPU igjen... Så starter vi på nytt, for det var ferdige.Så ser vi... Vi ser at nå så står de på 3, 2 og 1. Vi kan vel også se at de står fast der. Stort sett... Den som slutter på 29, står på 3. Ja, 29. Den er på 3 fortsatt. 29, ja... Stort sett, hvis det ikke er noen grunn til det, så blir de stående og kjøre på den samme. Men da kan vi gjøre tilsvarende.  Hva skjer nå om vi kjører fem og kanskje seks seppuer? Nei... Vi kjører seks prosesser på denne maskinen som bare har fire seppuer. Og da ser vi at da blir det altså firedel på seks. Det blir to tredjedeler seppukapasitet på hver. Omtrent 67 %. Det varierer litt opp og ned, men sånn ca. 67 %. Og så bytter man hele tiden på prosessene. Og hvis jeg kjører 5, så får de noe sånt som... Ca. 80 % burde det bli. Men her ser vi...", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0015", "start": 1041.94, "end": 1153.76, "token_count": 298, "text": "Det blir to tredjedeler seppukapasitet på hver. Omtrent 67 %. Det varierer litt opp og ned, men sånn ca. 67 %. Og så bytter man hele tiden på prosessene. Og hvis jeg kjører 5, så får de noe sånt som... Ca. 80 % burde det bli. Men her ser vi... Man kan se det varierer litt. Øverst er det alltid én med... Men hvis du ser på totaltiden, så blir den omtrent lik til slutt. Hvis du ser på totaltiden her, så ligger det rundt sånn 21... Litt forskjelligre blir det, men i utgangspunktet så prøver operativstemme å fordele tiden likt. Ja... Det er noen spørsmål i chatten her. Funkerer ikke for meg med å taste F. Topp oppdaterer seg ikke. Hva kan være årsaken? Det er litt vanskelig å si. Men hvis man prøver å kjøre dette her på Linux-VM-en f.eks. Så skulle... Så skulle det gå. Vi kan... Vi kan prøve. Hvis jeg nå går inn som... Group 99 at OS... Nei, jeg er ikke 99. 100 er jeg.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0016", "start": 1114.96, "end": 1237.88, "token_count": 300, "text": "Det er litt vanskelig å si. Men hvis man prøver å kjøre dette her på Linux-VM-en f.eks. Så skulle... Så skulle det gå. Vi kan... Vi kan prøve. Hvis jeg nå går inn som... Group 99 at OS... Nei, jeg er ikke 99. 100 er jeg. Group 100. Sånn er jeg på Linux-VM og vi kjører topp. Hvis jeg taster F der, så ser det ut som det... Så ser det ut som det fungerer. Selv om jeg nå ikke ser... Last used CPU-er... Jo, den var her. Og... Ja, her ser vi... Her er det mange... Mange CPU-er. 48 står det her. Og den er faktisk 40... eller 92. Men hver container får ikke full tilgang til CPU-ene. Det skal vi se på litt senere. Men opplegget er det samme. Her er det dokkercontainere. Så det er et nivå til, så de kan fordeles CPU-tid av dokker-enginer som styrer disse containerne. Men iallfall... Det ser ut som på... Så kan man taste F og så få opp det man ønsker. Et annet spørsmål som er... Én reinhet er én alu. Ja.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0017", "start": 1208.42, "end": 1311.44, "token_count": 299, "text": "Så det er et nivå til, så de kan fordeles CPU-tid av dokker-enginer som styrer disse containerne. Men iallfall... Det ser ut som på... Så kan man taste F og så få opp det man ønsker. Et annet spørsmål som er... Én reinhet er én alu. Ja. Én reinhet er én alu. Og spesielt når man regner heltallsoperasjoner, så er det en alu. Men der kan det være altså én alu per core, eller reinenhet. Så hvis man har flytall, så har man gjerne en egen regneenhet som regner flytall. Og den... Det hender det er forskjell på om man har én alu og én flytallsregneenhet. Det hender det er forskjell. At man liksom har et... Inni en CPU at man har to ALU-er og én flytallregneenhet. Det varierer. Men når jeg snakker om det, så når jeg sier én CPU eller én core, så tenker jeg på én ALU som gjør enkeltoperasjonen. Vi kommer tilbake til det senere i dag når vi skal se på multitreading.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0018", "start": 1293.72, "end": 1391.64, "token_count": 297, "text": "Det varierer. Men når jeg snakker om det, så når jeg sier én CPU eller én core, så tenker jeg på én ALU som gjør enkeltoperasjonen. Vi kommer tilbake til det senere i dag når vi skal se på multitreading. For da deler man på å bruke den samme ALU-en innenfor en core. Men mer om det senere. Ok. Det var multitrening. Så hvis det ikke er noen spørsmål om noe rundt det... Det er en del oppgaver som må gå på akkurat dette her. Så hvis dere ikke har gjort det ennå, så må dere prøve dere på egen hånd i dag og gjøre oppgaver med multitrening. Det kan være litt vanskelig å tolke de oppgavene når vi kjører på de virtuelle maskinene. For der er det... Siden vi har en oppgave, kan vi si litt mer om det. Som vi så her, så var det veldig mange CPU-er. Her kjører jeg topp i gruppe 100. Det er ikke så mange prosesser her. Men det er alle prosessene som kjøres på den lokale containeren. Her er det inne som RUT også, så jeg kjører noen RUT-prosesser.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0019", "start": 1361.6, "end": 1460.38, "token_count": 291, "text": "Som vi så her, så var det veldig mange CPU-er. Her kjører jeg topp i gruppe 100. Det er ikke så mange prosesser her. Men det er alle prosessene som kjøres på den lokale containeren. Her er det inne som RUT også, så jeg kjører noen RUT-prosesser. Men LSCPU viser hvor mange... Eller viser litt info om systemet. Her vil vi se at vi har 96 CPU-er. Men! Hver enkelt VM, eller hver enkelt container, får ikke tilgang til alle CPU-ene. Det kunne i prinsippet gjort, men sånn som jeg har startet opp, så har jeg gitt hver VM tilgang til det som tilsvarer to CPU-er. Så hvis dere kjører to regnprosesser, så vil det si at de får 100 % CPU. Hvis du kjører tre, så får de bare to til. Akkurat som på en fysisk maskin med to CPU-er. Men dette blir fordelt av Docker Engine, og den gjør det litt annerledes. Så hvis man lister hvilke prosessorer de kjører på, f.eks., så vil man se at de ligger på forskjellige prosessorer.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0020", "start": 1437.0, "end": 1526.96, "token_count": 299, "text": "Akkurat som på en fysisk maskin med to CPU-er. Men dette blir fordelt av Docker Engine, og den gjør det litt annerledes. Så hvis man lister hvilke prosessorer de kjører på, f.eks., så vil man se at de ligger på forskjellige prosessorer. Også hvis du kjører tre stykker, så ligger de på tre forskjellige. Det er da Dukker Engine som fordeler tiden. Vi kommer litt mer tilbake til det etter hvert også, men dette er en oppgave òg. Den er... Dere har jo ikke full oversikt siden dere ikke ser den fysiske serveren. Så den oppgaven er litt vanskelig, å se hva det er som egentlig skjer. Men det dere kan gjøre, er å bare teste ut hvor mye superhjul får jeg, hvor lang tid tar de forskjellige jobbene. Men ha det i bakhodet at dette er Litt mer komplisert enn om det var på en fysisk maskin. Ok. Da skal vi gå litt videre. Og så skal vi se på internminne og cash. Vi skal fortsatt se på mikroarkitektur og datamaskinarkitektur og multitasking. Hvordan...", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0021", "start": 1497.0, "end": 1600.76, "token_count": 300, "text": "Litt mer komplisert enn om det var på en fysisk maskin. Ok. Da skal vi gå litt videre. Og så skal vi se på internminne og cash. Vi skal fortsatt se på mikroarkitektur og datamaskinarkitektur og multitasking. Hvordan... Multitasking foregår. Men for å forstå multitasking er det viktig å forstå hva cash er, og hvordan internminnet opererer sammen med CPU-en. Vi har sett på internminnet tidligere. I simulerings-CPU-en vår så vi hvordan vi hadde egne instruksjoner som flytter data fra registeret og ut i internminnet. Den store problemstillingen med RAM og CPU er at RAM er relativt tregt. CPU utfører instruksjoner veldig mye raskere enn de kan hentes fra RAM. Det er kanskje en faktor ti. Og hvis man ikke gjorde noe med det, så måtte CPU-ene så vente hele tiden på data. Instruksjoner må hentes fra RAM. Et program som kjøres. Alle institusjonene ligger i RAM. Og for å kjøre dem, må de hentes inn fra RAM. Og hvis det går mye saktere enn den tiden det tar ut fra en institusjon,", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0022", "start": 1584.76, "end": 1676.96, "token_count": 295, "text": "Instruksjoner må hentes fra RAM. Et program som kjøres. Alle institusjonene ligger i RAM. Og for å kjøre dem, må de hentes inn fra RAM. Og hvis det går mye saktere enn den tiden det tar ut fra en institusjon, så hoper det seg opp med institusjoner, og det går ikke så fort som Sepund egentlig kan kjøre. Og det er der cash kommer inn. Cash er egentlig fransk og betyr et hemmelig lager. Mellom ram og CPU. Og kanskje er et veldig hurtigram, så vi skal se - er det SRAM? Det er akkurat samme teknologi som det er i registrene. Så vi legger egentlig på et digert lager med ekstra registre. Men de er ikke registre i den betydning at CPU-en oppfatter dem som... De er bare mellomlagring av data fra RAM på vei inn til CPU-en og på vei ut fra CPU-en. Hele prinsippet med at det hjelper å få et hurtiglager mellom RAM og CPU, er at statistisk sett, når man utfører institusjoner, så... ... så bruker man bare en liten del av minnet. Altså...", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0023", "start": 1653.36, "end": 1744.6, "token_count": 285, "text": "og på vei ut fra CPU-en. Hele prinsippet med at det hjelper å få et hurtiglager mellom RAM og CPU, er at statistisk sett, når man utfører institusjoner, så... ... så bruker man bare en liten del av minnet. Altså... Det er en liten del av institusjonene som statistisk sett utføres om og om igjen. Og ofte er det også sånn at man bruker om og om igjen data i ramm som ligger ved siden av hverandre, f.eks. i et RAI. Så dermed er det mye tid å spare hvis man henter mange biter av gangen og mellomlagrer i cash. Vi skal se på etterpå hvordan det ser ut sånn rent fysisk. Minnepyramiden er et viktig prinsipp. Og prinsippet her er at vi har forskjellige enheter som lagrer data. Og som er koblet til en CPU. Og her er det veldig stor forskjell på hvor lang tid det tar å hente dataene. Vi ser vi har registrene øverst i minnepyramiden. De er de raskeste. Bruker kortest tid på å hente data til aluen.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0024", "start": 1721.78, "end": 1802.24, "token_count": 293, "text": "Og som er koblet til en CPU. Og her er det veldig stor forskjell på hvor lang tid det tar å hente dataene. Vi ser vi har registrene øverst i minnepyramiden. De er de raskeste. Bruker kortest tid på å hente data til aluen. For det er jo registrene som er koblet til aluen. Så der går det lynkjapt. Og så har man noen lag med cash. Her har jeg L1-cash og L2-cash. De fleste moderne CPU-er har L3-cash også i tillegg. Som da går litt saktere. Men teknologien her er den samme. Dette er S-ram. De er veldig hurtige, men det er større mengde. Vi har flere megabyte med L2-cash, og det tar da litt tid å frakte det inn til registrene. Så derfor går det litt lengre tid. Så kommer man ned til ram. 480 gigabyte. Vi kan ha 1000 gigabyte også av ram. Men hovedpoenget er at det går omtrent en faktor ti saktere å hente inn data fra ram. Så det er derfor man bruker det mellomlageret her. For å mellomlagre det som hentes fra RAM,", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0025", "start": 1783.26, "end": 1870.08, "token_count": 286, "text": "Så kommer man ned til ram. 480 gigabyte. Vi kan ha 1000 gigabyte også av ram. Men hovedpoenget er at det går omtrent en faktor ti saktere å hente inn data fra ram. Så det er derfor man bruker det mellomlageret her. For å mellomlagre det som hentes fra RAM, sånn at det kommer raskere inn til registrerne. Vi skal se på hvordan det kommer raskere inn. Senere i kurset skal vi se på harddisker også. Helt eneste her er HDD disk... Hardware drive. Som er en tradisjonell disk. Og den er et proposal. Platelager med disker som fysisk snurrer rundt, sånn som CD-er. Og... her har vi SSD, Solid State Disc, som vi ser røfflig, i hvert fall når du skal hente en vilkårlig... ... en vilkårlig bite på disken. Riktignok henter du gjerne 512 av gangen. Bite på disken. Så går SSA-disk mye raskere, for her er det ikke noen fysiske plater som snurrer rundt. Det er mer som sånn minne på minnepinner.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0026", "start": 1842.96, "end": 1925.92, "token_count": 300, "text": "som vi ser røfflig, i hvert fall når du skal hente en vilkårlig... ... en vilkårlig bite på disken. Riktignok henter du gjerne 512 av gangen. Bite på disken. Så går SSA-disk mye raskere, for her er det ikke noen fysiske plater som snurrer rundt. Det er mer som sånn minne på minnepinner. Men likevel så er det en Factor 1000 saktere enn RAM, så det går fortsatt veldig sakte, men det går vesentlig raskere enn fra harddisk. Ja, det er noen spørsmål om SSA-disken, om det... Ja, vi kommer tilbake til det. Senere, men det er en del andre begrensninger med SSD. Altså hvordan du kobler den opp til maskinen. Hva slags buss du har ut til SSD-en. Det har også en del å si. Men med sånn optimal tilkobling på begge, så kan det være en fakta på 1000. Men mer om det senere, når vi skal snakke om disker.  ESRAM og DERAM. CPU-registrene og cash er laget av ESRAM. ESRAM består av seks damasthistorier for hver bytt som lagres.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0027", "start": 1901.68, "end": 1983.16, "token_count": 287, "text": "Men med sånn optimal tilkobling på begge, så kan det være en fakta på 1000. Men mer om det senere, når vi skal snakke om disker.  ESRAM og DERAM. CPU-registrene og cash er laget av ESRAM. ESRAM består av seks damasthistorier for hver bytt som lagres. Det var det vi bygde opp møysommelig tidligere i datamaskinarkitektur. At vi satte sammen and-er og -årer, og så lagde vi noen løkker tilbake og noen not-porter, og så klarte vi å lage en liten krets. Som lagret ett bit. 1.01-er. Men vi trengte da seks transistorer for å få det til. Mens DRAM, eller Dynamic Rum, er en mye enklere teknologi. Det består bare av én transistor og en kapasitator. En kapasitator er en bitte liten device som lagrer en liten elektrisk ladning. Så er det så enkelt at hvis den har ladning, så er den én. Hvis den ikke har ladning, så er den null. Deram er da mindre og mye billigere å lage enn SRAM.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0028", "start": 1966.0, "end": 2043.26, "token_count": 289, "text": "En kapasitator er en bitte liten device som lagrer en liten elektrisk ladning. Så er det så enkelt at hvis den har ladning, så er den én. Hvis den ikke har ladning, så er den null. Deram er da mindre og mye billigere å lage enn SRAM. Men det største problemet er at den er ikke like hurtig. Og i tillegg må det lades opp på nytt ti ganger i sekundet. Og Deram er da, i motsetning til disker, altså flash-minne og harddisker, så forsvinner alt som er lagret i Deram. Så når du skrur på en datamaskin, så står DRAM og lades opp på nytt hele tiden for at man skal beholde den nullen eller eneren. Nullen er lett å beholde, men eneren må helt innlades. Siste versjon av DRAM er DDR5 SDRAM. Double Data Rate Generation 5 Synchronous Dynamic Gram. Det er vel ikke brukt i noen stor grad ennå. Det er det det er fire som er foreløpig det mest vanlige, som kom i 2016 eller noe sånt. Men igjen, prinsippet er det samme,", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0029", "start": 2023.6, "end": 2122.48, "token_count": 292, "text": "Double Data Rate Generation 5 Synchronous Dynamic Gram. Det er vel ikke brukt i noen stor grad ennå. Det er det det er fire som er foreløpig det mest vanlige, som kom i 2016 eller noe sånt. Men igjen, prinsippet er det samme, men all utviklingen går da på å få ting til å gå enda litt fortere. Ellen og L2 Cash. Denne figuren viser prinsippene for cash. Hvorfor man kan få til å kjøre programmet fortere ved å bruke cash. Helt til venstre på figuren her så ser vi CPU-en. Her står det R0R1R2 etter det. Det kunne satt AXBCXX også. Det er da registrene inni CPU-en. Og disse brukes da hele tiden til å mate oss inn i alun. Den kan kverne institusjoner fortere enn RAM kan levere det. Og dermed så legger vi til dette L1 og L2-cash. Som sagt, mange har L3-cash også inne på skipen, av moderne prosessorer. Men prinsippet er det samme. Så L1-cash er litt mindre. Men vi ser her i stedet for de fire... Her er det ikke bite engang, men det er fire bit.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0030", "start": 2103.56, "end": 2189.48, "token_count": 300, "text": "Som sagt, mange har L3-cash også inne på skipen, av moderne prosessorer. Men prinsippet er det samme. Så L1-cash er litt mindre. Men vi ser her i stedet for de fire... Her er det ikke bite engang, men det er fire bit. Men la oss si det er bite som skal inn i registrene. De fire bitene får plass i registrene. Og da kunne det være at CPU-en gjør en instruksjon som sier 'hent bite nummer to' her. Opprinnelig så var CPU-en sånn at OK, bite nummer to... Da går vi ut i ram og henter bite nummer to, som er den 1.101 som ligger her oppe, og så sender vi den inn igjen. Men på den tiden var det ikke noen forskjell på CPU og ram, så det fungerte greit. Men etter hvert så har CPU-en løpt ifra og blitt raskere enn ram. Og da, i stedet for å bare hente den ene biten der ute i ram, så når man da henter noe i ram, så tar man like godt med et stort område. I nærheten av den biten man skal hente. Og så legger man... Så legger man det i L2-cash.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0031", "start": 2168.24, "end": 2242.2, "token_count": 287, "text": "Og da, i stedet for å bare hente den ene biten der ute i ram, så når man da henter noe i ram, så tar man like godt med et stort område. I nærheten av den biten man skal hente. Og så legger man... Så legger man det i L2-cash. Hele den, så mye man får plass til. Og det varierer. Og cashing, det styres på Hardner-nivå. Så dette er ikke noe som operativsystemet går inn og styrer. Så vi kommer ikke til å se på sånn i detalj nøyaktig hvordan algoritmene for dette er. Det styres på hardware-nivå. Som operativstem får du ikke gjort så mye med hvordan cash virker. Men iallfall i prinsippet så virker det sånn at du tar med en stor bit av gangen, og så tar du med en litt mindre bit som får plass i LN-cash, og så, inntil CPU-en, så tar du de nærmeste bitene. Men som sagt, så er det statistisk sett, så er det veldig ofte at man trenger... Bites, eller data som ligger i nærheten av hverandre.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0032", "start": 2221.84, "end": 2286.76, "token_count": 290, "text": "og så tar du med en litt mindre bit som får plass i LN-cash, og så, inntil CPU-en, så tar du de nærmeste bitene. Men som sagt, så er det statistisk sett, så er det veldig ofte at man trenger... Bites, eller data som ligger i nærheten av hverandre. Dette kan f.eks. være institusjoner som ligger rett etter hverandre. Og da er det ofte at man hopper fra institusjon 1 til 2 til 3 til 4 osv. Og da, hvis man gjør det, så vil jo alle de institusjonene ligge her i LNCash. Og da går det veldig kjapt å hente de over til CPU. Andre ganger så er det kanskje et stort RA som ligger i ramm. De dataene du jobber med. Og da er det den samme fordelen. Jo, da... Ofte så skal du ha neste R-element. Og når du henter ut det, så går det raskt fordi du har hentet det inn i LN-cash. Og det skal vi teste ut senere når vi skal se på ramm. Hvordan er forskjell på f.eks. hvordan man indekserer en matrise.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0033", "start": 2268.88, "end": 2343.96, "token_count": 285, "text": "Ofte så skal du ha neste R-element. Og når du henter ut det, så går det raskt fordi du har hentet det inn i LN-cash. Og det skal vi teste ut senere når vi skal se på ramm. Hvordan er forskjell på f.eks. hvordan man indekserer en matrise. For i noen tilfeller så hopper man rundt i ramm og henter. I andre tilfeller så henter man ramm data som ligger rett etter hverandre i ramm. Og det går alltid mye raskere. Så dette er hovedprinsippet. Dette viser det man kan kalle mikroarkitekturen for L1 og L2-cash. Igjen så er det som sagt vanlig å ha en eldre cash, men i prinsippet så er den tilsvarende som level 2-cash. Her ser vi at L1-cash den har en litt spesiell arkitektur. Her står det LN Data og LN Instruksjoner. Det betyr at her er det to forskjellige veier inn til CPU-en. Det er dette som gjør at man kan si... Dette er egentlig ikke noen van Neumann-arkitektur,", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0034", "start": 2322.04, "end": 2401.72, "token_count": 300, "text": "Her ser vi at L1-cash den har en litt spesiell arkitektur. Her står det LN Data og LN Instruksjoner. Det betyr at her er det to forskjellige veier inn til CPU-en. Det er dette som gjør at man kan si... Dette er egentlig ikke noen van Neumann-arkitektur, hvor både datainstruksjoner går på den samme bussen. Det vil si det er van Neumann-arkitektur inn hit, og så, den siste biten, så er det Harvard-arkitekturen. Hvor man da deler opp. Institusjonene kommer inn på... På én buss eller en rute inn til CPU-en. Og datakomera på en annen. Så ser vi altså at vi har en tredje bit. TLB Translation Look-Aside Buffer. Og det er... Nå skal vi komme tilbake til senere. Det er minneadressering. Det er en... Det bruker MMU. Og MMU virtualiserer minneadressene, sånn at CPU-en ikke trenger å vite nøyaktig hvor i RAM enhver bite ligger. Det kommer vi tilbake til senere, men det er også veldig viktig for effektivitet at det er hurtig.", "source": "lecture"}
{"lecture_id": "os7time1", "chunk_id": "os7time1_0035", "start": 2385.24, "end": 2443.12, "token_count": 169, "text": "Og MMU virtualiserer minneadressene, sånn at CPU-en ikke trenger å vite nøyaktig hvor i RAM enhver bite ligger. Det kommer vi tilbake til senere, men det er også veldig viktig for effektivitet at det er hurtig. Så derfor så er det en egen bit av LNCash som er satt av til TLB, eller minneadressering. Da skal vi se generelt på multitasking og multiprosessing. Men jeg ser at tiden er mye her nå, så vi trenger en pause. Så da tar vi 15 minutter pause derfra. Da starter vi 09.31. Som vanlig, still gjerne spørsmål i chatten i pausen.", "source": "lecture"}
{"lecture_id": "os13del12", "chunk_id": "os13del12_0000", "start": 0.0, "end": 105.04, "token_count": 300, "text": "Ja, jeg tenkte jeg kunne vise det i praksis, men bare først skissere hva som skjer her. Dette er en simulering jeg lagde en gang. Så det er et C pluss pluss-prosjekt. Og da lagde jeg et bibliotek som gjorde noen beregninger. Genererte noen tilfeldige tall og regnet ut standard og vik osv. Det jeg gjorde da, var at jeg lagde et C++-library. Altså mitt eget bibliotek. Og det G++ er en C++-kompilator. Så det jeg gjorde da først, var å kompilere kildekoden til biblioteket. Og da lages det kalktools.o og roundtools.o. Og så er ar en kommando for å lage et bibliotek. Og det biblioteket jeg lagde, er libtools.a. Og så hadde jeg en simulering som jeg kompilerte. Akkurat tilsvarende som vi gjorde tidligere. Lage maskinkode. Og så til slutt så denne operasjonen her nede... Den lager en eksekverbar fil-sim ved å lime sammen alle programmene. Og her er det også noen kommandoer som gjør at man limer inn det biblioteket her oppe.", "source": "lecture"}
{"lecture_id": "os13del12", "chunk_id": "os13del12_0001", "start": 79.52, "end": 199.4, "token_count": 297, "text": "Akkurat tilsvarende som vi gjorde tidligere. Lage maskinkode. Og så til slutt så denne operasjonen her nede... Den lager en eksekverbar fil-sim ved å lime sammen alle programmene. Og her er det også noen kommandoer som gjør at man limer inn det biblioteket her oppe. Så i praksis det jeg gjorde, var at jeg laget mitt eget lille bibliotek her. Og så, den siste operasjonen, linket det sammen. Og all koden var det her inne. Og så kan den lastes inn og kjøres. Så vi kan... Vi kan se på hvordan det ser ut i praksis. Så her under 'Tools' så har jeg da de verktøyene. For eksempel 'Calc Tools'. Det er da en metode som regner ut varians. Og så har jeg en... Bare et lite program som... Skal vi se... Sånn, kanskje. Dette er et lite skript som kompilerer. Så først kompileres de to programmene, og så lager jeg et bibliotek. ved å eksplisitt kjøre det. Sånn. Nå har jeg lagd en bibliotekfil. Og den... Jeg tar den her.", "source": "lecture"}
{"lecture_id": "os13del12", "chunk_id": "os13del12_0002", "start": 166.68, "end": 300.88, "token_count": 282, "text": "Dette er et lite skript som kompilerer. Så først kompileres de to programmene, og så lager jeg et bibliotek. ved å eksplisitt kjøre det. Sånn. Nå har jeg lagd en bibliotekfil. Og den... Jeg tar den her. Libtools.a. Det er selve bibliotekfilen som en nå skal bruke når jeg skal kjøre. Så... da kan jeg gå til selve simuleringen. Her har jeg også et lite program som kompilerer. Den komplerer selve simuleringen og noen andre hjelpeprogram. Og så her linkes det sammen til en simulering. Så jeg skal gjøre det her. Jeg skriver bæsj minus 6, for da får jeg se eksplisitt hva som skjer. Nå har jeg lagd en simulering. 27 000 bites. Og så kan den simuleringen kjøre. Lastes den inn i minnet, inkludert biblioteksfilene? Så skal jeg prøve å gjøre det samme på en litt annen måte. Det jeg skal gjøre da, er... Nå har jeg en... S-Tools.  Den her har jeg i de samme bibliotekene,", "source": "lecture"}
{"lecture_id": "os13del12", "chunk_id": "os13del12_0003", "start": 270.0, "end": 391.08, "token_count": 290, "text": "Lastes den inn i minnet, inkludert biblioteksfilene? Så skal jeg prøve å gjøre det samme på en litt annen måte. Det jeg skal gjøre da, er... Nå har jeg en... S-Tools.  Den her har jeg i de samme bibliotekene, men her skal jeg vise hvordan man lager et dynamisk bibliotek. Det er veldig mye av det samme. Det ligner veldig, men du ser... Dynamisk bibliotek under Linux så heter de.so. I Windows heter det DLL. Dynamical Linkable... Ja, hva er det det heter...? DLL... Dynamical Linked Library heter det. Så hvis jeg kjører dette, så lager jeg da et dynamisk bibliotek. libstools.so. Så... da kan jeg... gå hit, hvor jeg har det dynam... Det dynamiske. Og så kan jeg... Complere med det dynamiske biblioteket. Og da ser det veldig likt ut. Jeg legger på en minus L-tools der. Og så er det nå klart til at jeg kan kjøre den simuleringen i stedet. Akkurat den går litt fortere. Det er ikke noen forskjell i koden. Det er bare en løkke som er mindre her.", "source": "lecture"}
{"lecture_id": "os13del12", "chunk_id": "os13del12_0004", "start": 369.72, "end": 462.74, "token_count": 289, "text": "Jeg legger på en minus L-tools der. Og så er det nå klart til at jeg kan kjøre den simuleringen i stedet. Akkurat den går litt fortere. Det er ikke noen forskjell i koden. Det er bare en løkke som er mindre her. Det ser jo veldig likt ut når jeg kjører, men det som er en viktig forskjell her, er at når... I det andre tilfellet her, når jeg starter denne her som bruker et dynamisk bibliotek, så lastes det biblioteket inn når jeg kjører det. Og det kan også... Da kunne jeg også lage andre simuleringer. Som bruker akkurat det samme biblioteket. Vi kan se at det er en liten forskjell. Hvis jeg nå tar LS minus L på SIM, så ser vi at den er på 26.68. Mens den første simuleringen, den er på 27.88. Så du ser her, det er en forskjell på én kilobite. I dette tilfellet er det en statisk lenke. Så da er all koden fra biblioteket ligger fysisk inne i den kjørbare filen. Mens her så lastes den kjørbare...", "source": "lecture"}
{"lecture_id": "os13del12", "chunk_id": "os13del12_0005", "start": 441.46, "end": 490.0, "token_count": 164, "text": "Så du ser her, det er en forskjell på én kilobite. I dette tilfellet er det en statisk lenke. Så da er all koden fra biblioteket ligger fysisk inne i den kjørbare filen. Mens her så lastes den kjørbare... Det dynamiske biblioteket lastes dynamisk. Og dermed ser vi at koden er litt mindre. Så hvis vi går tilbake til slidene... I det andre tilfellet hadde jeg et dynamisk bibliotek som ble lastet inn når jeg kjørte koden. I det første tilfellet så lå alt inni her. Og dermed så var den 1K søre den koden.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0000", "start": 0.0, "end": 132.92, "token_count": 288, "text": "Ja... Da starter vi igjen. Det var noen spørsmål i pausen, så jeg tenkte jeg skulle prøve å tegne og forklare litt mer før vi ser mer på... Men det var én kommentar til, kanskje, først. Jo... Det ble spurt om... Kode, hva den betydde. Ja, jeg har lagt til litt her. Kode betyr åtte bytes. Men f.eks. long betyr fire bytes. Da ville jeg skrevet noe sånt. Da settes det av 4 bit i ramm til denne variabelen, som vil da være en 32-bitsvariabel. Så det typisk Jesus gjør, er når man bruker int, så er det long, og da settes det av 4 bit til variabelen. Dette vil også kompilere og kjøre. Det jeg ønsket generelt, var å bruke 8 byte til disse variablene. Hvis du bruker en long og du får tall som er større enn det som er plass til en long, så kan du få problemer. Ok. Men da skal jeg prøve å si litt om ram og CPU. Helt klart. Skal vi se... Hvis jeg klarer å... Jo, hvis vi tenker oss...", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0001", "start": 98.68, "end": 223.88, "token_count": 299, "text": "Hvis du bruker en long og du får tall som er større enn det som er plass til en long, så kan du få problemer. Ok. Men da skal jeg prøve å si litt om ram og CPU. Helt klart. Skal vi se... Hvis jeg klarer å... Jo, hvis vi tenker oss... ... at denne boksen er CPU-en. Håper det ser OK nå. Så inni CPU-en ligger da de registrene. CX osv. Og de er registre sånn som jeg hadde i simuleringen. I simuleringen så var registerstørrelsen 4-bit. Her er AX egentlig enda lengre. Den er på 32-bit. Nei, forresten. Den er 16-bit. EAX er på 32-bit. Så da er det bare lengre ray av bitt, sånn som dette her. Og med nuller og enere. Og så inni CPU-en så har vi da en alu. Og da har vi sett tidligere at vi... Det som skjer inni CPU-en, er at du har en kanal fra registrene. Som går inn i aluen. Og så kommer resultatet etter at aluen har gjort beregninger. Den kommer tilbake til registrene. Så her kan vi sitte og regne og holde på.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0002", "start": 198.84, "end": 326.36, "token_count": 300, "text": "Og da har vi sett tidligere at vi... Det som skjer inni CPU-en, er at du har en kanal fra registrene. Som går inn i aluen. Og så kommer resultatet etter at aluen har gjort beregninger. Den kommer tilbake til registrene. Så her kan vi sitte og regne og holde på. F.eks. de Fibonacci-tallene. De regnes ut lokalt inne i SEPUN. Men så begynner vi å gjøre instruksjoner sånn som Move. Hadde en institusjon sånn som move%eax-til-svar i den koden som vi kjørte nå nettopp... Så betyr det, flytt resultatet av det vi hadde, til ram. Så dette er ram. Det skal vi studere senere i detalj. Men RAM er egentlig bare et svært reim med bites. Så her er det - skal vi se - åtte bit. Så dette er da adresse null i RAM. Dette er adressen i RAM. Det vi holder på med når vi sier'move prosent EAX' til svar, det er at vi ønsker å legge verdien av EAX fra CPU-en også ut i RAM. Så kan det òg godt være at... Hvis så... La oss si den svaret er 'long', da.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0003", "start": 300.0, "end": 409.84, "token_count": 297, "text": "Dette er adressen i RAM. Det vi holder på med når vi sier'move prosent EAX' til svar, det er at vi ønsker å legge verdien av EAX fra CPU-en også ut i RAM. Så kan det òg godt være at... Hvis så... La oss si den svaret er 'long', da. Hvis jeg har definert en variabel som long... Så er den på fire bite. Og da betyr det at det settes av fire bite i ram. Og dette her er da de fire bitene til svar. Og det vi så i koden, det var noe sånt som minus fire prosents RDB eller noe i den stillingen her. Det er et register som ligger i CPU, men det inneholder et tall. Så dette er en adresse, og den adressen kan f.eks. være til rammelinje nummer 3757. Og den minus 4 betyr at det er den adressen minus 4. Så dette her... Når du ser det i et assemblerprogram, så... Peker det til et eller annet sted i ram. Og den inneholder da en adresse, som er den adressen her. Hvilket nummer... Hvilket bite i ram som skal legges der. Så det som skjer med den institusjonen her,", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0004", "start": 385.36, "end": 494.6, "token_count": 297, "text": "Så dette her... Når du ser det i et assemblerprogram, så... Peker det til et eller annet sted i ram. Og den inneholder da en adresse, som er den adressen her. Hvilket nummer... Hvilket bite i ram som skal legges der. Så det som skjer med den institusjonen her, det er at man tar de verdiene som lå i AX, og så legger man ut her. Det er EAX, så den EAX inneholder 32-bit. Så de 32-bitene får da plass i det som er satt av i ramm til de 32-bitene. Og når man skriver kode, int... Hvis man skriver kode sånn som dette her... Int svar er lik 42. Så det er... Det kompulatoren gjør da, som vi kan gjøre direkte i Assembly, er å finne en plass her i ram, og så skrive inn ener og nullere som tilsvarer 42, sånn at du lagrer dataene. Men når vi da gjør operasjoner sånn som add, så... Så opererer da add på registrene. En add-operasjon kan også operere på en variabel og et register samtidig. Så vi kan f.eks. si add % eax til svar.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0005", "start": 458.56, "end": 567.88, "token_count": 289, "text": "og så skrive inn ener og nullere som tilsvarer 42, sånn at du lagrer dataene. Men når vi da gjør operasjoner sånn som add, så... Så opererer da add på registrene. En add-operasjon kan også operere på en variabel og et register samtidig. Så vi kan f.eks. si add % eax til svar. Så hvis jeg gjør en sånn... Hvis jeg gjør en sånn operasjon, så sier jeg ta det tallet som ligger i eax. Et tall 10 som ligger der, og legg til svar. Og så ligger det allerede 32 her i svar. Og så ligger det kanskje... Her ligger det 10 i det eksempelet vi hadde. Denne maskininstitusjonen her, den vil nå utføre operasjonen at den tar det tallet 10 og legger til 32, sånn at etter den institusjonen Så står det 42 her. Men det er klart at dette er hardware-kodet, altså denne institusjonen, på en sånn måte at først må verdien 32 som ligger her, den må sendes på databussen fra RAM til CPU. Her er databuss.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0006", "start": 531.08, "end": 637.72, "token_count": 292, "text": "at den tar det tallet 10 og legger til 32, sånn at etter den institusjonen Så står det 42 her. Men det er klart at dette er hardware-kodet, altså denne institusjonen, på en sånn måte at først må verdien 32 som ligger her, den må sendes på databussen fra RAM til CPU. Her er databuss. Og det skjer da bak kulissene når man utfører en sånn operasjon som dette. Men det er på en måte hardware-kodet på forhånd, at når den institusjonen er der utføres, så tar man først 32 og legger inn her i et register. Og så legges det da tallet sammen med AX gjennom aluen. Det tallet 32 må sendes inn til Alun. Det går via registeret. Så lagres det ut igjen i... Mellomlagres resultatet. Så lempes det ut via datobussen ut hit, sånn at 42 lagres. Nøyaktig hva som skjer ved en institusjon, det er brent inn i kretskortet... Det er forhåndsbestemt hvordan dette skjer. Det eneste vi som programmerere vet, og ens operativsystem vet,", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0007", "start": 612.86, "end": 744.3, "token_count": 297, "text": "Så lempes det ut via datobussen ut hit, sånn at 42 lagres. Nøyaktig hva som skjer ved en institusjon, det er brent inn i kretskortet... Det er forhåndsbestemt hvordan dette skjer. Det eneste vi som programmerere vet, og ens operativsystem vet, er at resultatet blir sånn som det. Dette vet kompulatoren om, så den kan i stedet for å lage instruksjoner som da går inn og ut av databussen, som tar tid, så prøver den å optimalisere og gjøre mest mulig med registeret her inne. Ut på databusen og ut til ham. Så sånn røftelig er det... Det fungerer. Så nå skal vi se litt mer på Assembly. Vi skal se på en if-test. Og kanskje vi kan prøve å også lage den sånn fra scratch. Skal vi se... Se om jeg klarer å komme inn her. Oi. Der, ja. Må bare legge av litt. Ja, da skal jeg lage en liten if-test. Men vi kan se på... Jo, jeg har en if-main her. Jeg skal nå prøve å lage en liten rutine som utgjør en if-test.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0008", "start": 705.1, "end": 825.64, "token_count": 279, "text": "Oi. Der, ja. Må bare legge av litt. Ja, da skal jeg lage en liten if-test. Men vi kan se på... Jo, jeg har en if-main her. Jeg skal nå prøve å lage en liten rutine som utgjør en if-test. Det jeg tenkte å prøve på, var å skrive den fra scratch i Assembly. Se litt mer i detalj hva som foregår. Eller ta det bare sånn. Step for step. Så da kan jeg prøve å starte å lage den If-testen. Ja, jeg kan kalle den min If fra skillen fra de andre. Det jeg trenger å vite, er at det skal være en ekstern funksjon-if-test, så det navnet må jeg ha. Da begynner jeg fra scratch. Det jeg trenger å si, er at det er en global if-test. Det definerer den funksjonen jeg skal lage. At den heter det. Så C kan få tak i den. Så er det en label-if-test. Det er en slags standard måte å starte en... Den koden jeg skal lage... Vi kan se. Jeg har en... Den koden ser sånn ut. Jeg kan ta med den...", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0009", "start": 793.2, "end": 904.96, "token_count": 286, "text": "Det definerer den funksjonen jeg skal lage. At den heter det. Så C kan få tak i den. Så er det en label-if-test. Det er en slags standard måte å starte en... Den koden jeg skal lage... Vi kan se. Jeg har en... Den koden ser sånn ut. Jeg kan ta med den... Dette her ønsker jeg nå å lage. Så jeg kan kanskje ta med den inn i... Sånn at de ser hva vi skal lage. Skal vi kommentere det... Sånn. Så tanken her er bare å illustrere hvordan man kan lage en if-test. Vi har lagd en foreløkke. Om jeg får løkka, så kan de også lage en vile. Det blir omtrent det samme. Så vet vi omtrent hvordan alt som er av kode, lages i maskinkode. OK. Det vi kan starte med, det er altså... Nå skal vi prøve å få dette til å virke. Det er å ha et lite dataavsnitt. Og der har jeg en variabel som jeg kaller svar. Det er den svar her oppe som er 32. Da kan jeg si... Ja, jeg kan bruke kode igjen.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0010", "start": 878.52, "end": 988.92, "token_count": 300, "text": "OK. Det vi kan starte med, det er altså... Nå skal vi prøve å få dette til å virke. Det er å ha et lite dataavsnitt. Og der har jeg en variabel som jeg kaller svar. Det er den svar her oppe som er 32. Da kan jeg si... Ja, jeg kan bruke kode igjen. Sette av 64 bit, 8 bytes, til en kode som... Ja... Som inneholder tallet 32. Det definerer den. Og så kan jeg... Bare for å se at dette her virker, så kan jeg bare teste først. Flytt tallet én til rax, og så returner. Da vil jo denne assembly-koden her nå, den gjør da ingenting. Den skal bare returnere én. Jeg tenker bare jeg gjør det her nå, først for å se om alt funker. Det kan være smart sånn at etterpå, når jeg skriver mer kode, så kan jeg være sikker på Da skal jeg lime den sammen med Ifmain. Den skal sammen med Ifmain sånn. Ja, der fikk jeg en warning... Ja, det er bare en warning. Jeg tror det er bare et ligneskift. Men vi kan se om den kjører. Ja, den kaller if-test, og så returnerer den svaret.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0011", "start": 964.84, "end": 1071.48, "token_count": 292, "text": "Den skal sammen med Ifmain sånn. Ja, der fikk jeg en warning... Ja, det er bare en warning. Jeg tror det er bare et ligneskift. Men vi kan se om den kjører. Ja, den kaller if-test, og så returnerer den svaret. Så det var en god start. Jeg lurer på om den... Ja, det var ikke noe linjeskift her, så jeg tror da... Var det med et linjeskift, så ville den ikke gi den ordningen. Ok. Men nå skal jeg prøve å lage kode som lager en if-test, da. For vi har en variabel svar her, som vi tenker oss er et eller annet tall. Og så skal vi... Den skal... Hvis svaret er sånn... Så skal den returnere 1, og ellers skal den returnere 0. Og da... Ja, hva skal vi gjøre da? Jo, vi kan starte med... Det er jo 42 som er liksom... Tallet vi skal sammenligne med. Så vi kan starte med å legge 42 i en... I et register. Da kan vi bare velge hvilket register vi vil. La oss si jeg bruker RBX. Og så skal jeg nå... ... sammenligne svaret med dette tallet.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0012", "start": 1037.88, "end": 1162.28, "token_count": 288, "text": "Tallet vi skal sammenligne med. Så vi kan starte med å legge 42 i en... I et register. Da kan vi bare velge hvilket register vi vil. La oss si jeg bruker RBX. Og så skal jeg nå... ... sammenligne svaret med dette tallet. Kanskje jeg skal... Nei, sånn. De tabbene er litt... Jeg håper det er litt på egen hånd, jeg. Jeg skal nå sammenligne RBEX og svar. Det kan rett og slett skrives sånn. En variabel kan bare skrives direkte sånn. Dette er en instruksjon som skal sammenligne de bitene som ligger her ute, i svaret svar, som da tilsvarer den der. Så jeg sammenligner nå 42 med svar. Og så... så skal jeg hoppe. Så da vil jeg hoppe hvis den er større igjen. JG, det er 'jump greater than'. Da kan jeg hoppe til et sted hvor det står... Eller en linje hvor det er 'greater'. Da husker vi fra simuleringen at da var det en sånn bransjekontroll. Og den bransjekontrollen styrte dette her med hopping.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0013", "start": 1140.0, "end": 1225.52, "token_count": 300, "text": "JG, det er 'jump greater than'. Da kan jeg hoppe til et sted hvor det står... Eller en linje hvor det er 'greater'. Da husker vi fra simuleringen at da var det en sånn bransjekontroll. Og den bransjekontrollen styrte dette her med hopping. Men da må jeg ha et eller annet sted... Så må jeg ha en linje hvor det står 'greater'. Så her har jeg da en label som heter Grater. Og så vet jeg... Hvis jeg hopper til Grater, da er den større enn 42, da skal jeg returnere 1. Og det kan jeg jo få til ved at jeg tar tallet 1... Alltid ha en dollar foran jeg skal skrive tall. Jeg tar tallet 1, og så legger jeg det i RAX. For RAX, det er det som returnerer. Sluttverdien. Så da er på en måte den biten riktig. Men så må jeg jo prøve å se hva det er som skjer hvis... Altså, jeg skal ha den elsker-en også. Hvis svarer 42, da skal jeg returnere igjen. Jo, men det jeg rett og slett kan gjøre da, er å bare gå inn etter jumpgrater.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0014", "start": 1208.2, "end": 1313.24, "token_count": 292, "text": "Men så må jeg jo prøve å se hva det er som skjer hvis... Altså, jeg skal ha den elsker-en også. Hvis svarer 42, da skal jeg returnere igjen. Jo, men det jeg rett og slett kan gjøre da, er å bare gå inn etter jumpgrater. For hvis... Hvis testen slår til, og den er greater, så hopper den til greater. Hvis ikke, så vil den fortsette å bare utføre kode nedover her. For vi vet at når den ikke hopper, så utføres bare neste kodelinje. Neste kodelinje kan jo da være å putte null i prosent rx. For da har vi fått til den elskeren. Men da blir det dumt. Hvis jeg nå hopper... Hvis jeg ikke gjør noe mer nå... Vi kan prøve å kompilere, så kan vi se hva som skjer. Men det må jeg ha lenger ned her. Så må jeg ha en return. Og så return sånn. Og det som skjer her nå, det er da... Verdi returneres i prosent av x. Eller ea, ikke sant. Sånn. Vi kan se... Vi kan prøve å se hva som skjer når jeg kjører dette her.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0015", "start": 1273.04, "end": 1395.52, "token_count": 293, "text": "Men det må jeg ha lenger ned her. Så må jeg ha en return. Og så return sånn. Og det som skjer her nå, det er da... Verdi returneres i prosent av x. Eller ea, ikke sant. Sånn. Vi kan se... Vi kan prøve å se hva som skjer når jeg kjører dette her. I dette tilfellet, når jeg har svaret er 32... Så skal den jo helst returnere null. Så vi kan prøve å komplere og se hva den returnerer. Da kompilerer jeg en sånn. Men den returneres av lik én. Så det var ikke helt riktig, den koden jeg skrev. Men hva var det som var galt? Du har ikke fjernet den første returen... Kjempebra! Dette her skulle jo ikke med. Så da returnerte han den. Det var derfor den ble retur 1. Veldig bra observert. Da ser vi en. Og så ser vi kanskje for null nå. Nei. Det er fortsatt... Får jeg svar 1? Hva gikk galt i If-testen min nå? Fordi at... Jeg kom jo hit, og så sammenligner jeg... \".Jump greater\". Nei, den skal ikke slå til.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0016", "start": 1363.38, "end": 1473.7, "token_count": 299, "text": "Og så ser vi kanskje for null nå. Nei. Det er fortsatt... Får jeg svar 1? Hva gikk galt i If-testen min nå? Fordi at... Jeg kom jo hit, og så sammenligner jeg... \".Jump greater\". Nei, den skal ikke slå til. Og dermed så skal jeg jo flytte 0 over rx. Nei, den er ikke lik, fordi at jeg sammenligner 42 og 32. Altså, i sammenligningen her så sammenligner jeg RBX og svar, og svar er 32. Ja, om jeg bytter plass i Compere, er det noen som foreslår? Nei, det hjelper ikke. Men det er noe med logikken her som ikke stemmer helt. For det som skjer nå, er at hvis jeg ikke hopper, så går jeg hit. Ja, nettopp. Den går gjennom linje for linje. Så... Det som skjer, jeg hopper ikke her fordi den ikke er større. Og så går jeg hit, legger null i RX. Men så fortsetter den bare å gå ned til greater. Så hvis jeg ikke gjør noe annet, så... Så fortsetter man å kjøre linje for linje, akkurat som den simuleringen.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0017", "start": 1453.92, "end": 1543.38, "token_count": 292, "text": "Det som skjer, jeg hopper ikke her fordi den ikke er større. Og så går jeg hit, legger null i RX. Men så fortsetter den bare å gå ned til greater. Så hvis jeg ikke gjør noe annet, så... Så fortsetter man å kjøre linje for linje, akkurat som den simuleringen. Og da går den til greater, og så flytter den én til rax, og så går den til return. Så hvordan skal jeg fikse det? Jo, det jeg må gjøre da, er at her må jeg jo legge inn... Her må jeg legge inn en jump, for jeg flytter null til rax, og da er jeg egentlig ferdig. Så jeg kunne lagt inn en return her, men... Jeg kan gjøre det eksplosivt og så si... OK, her vil jeg hoppe til Return. Sånn, da. Jump Return. Hvis jeg kommer hit, legger jeg null, og så hopper jeg over greater, sånn at ikke den blir satt. Og det er akkurat det en iftest gjør. Det funker. Ja... Og da ser vi... Nå returneres svarlig knull. Ja, det var en som foreslo \".Jump to return\". Helt riktig.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0018", "start": 1516.76, "end": 1629.02, "token_count": 283, "text": "Hvis jeg kommer hit, legger jeg null, og så hopper jeg over greater, sånn at ikke den blir satt. Og det er akkurat det en iftest gjør. Det funker. Ja... Og da ser vi... Nå returneres svarlig knull. Ja, det var en som foreslo \".Jump to return\". Helt riktig. Det var akkurat det jeg må gjøre. Og det som dere må sitte igjen med av dette her, er at... Her ser vi hvordan en kompilator må tenke, hvordan en kompilator da kan oversette. Her har vi en branching. Her er det en test som utføres. Og det kan alltid oversettes med denne type sammenligninger og jump statement. Det er spørsmål om man kan ha return to steder. Jeg er ikke sikker på... Jeg kan teste. Da burde det i så fall gå å gjøre sånn. Ja, ser ut som det går fint. Ja. Det går det an å gjøre. Denne vil utføre det samme, for den returnerer da direkte. Men da må jeg bare dobbeltsjekke. Funker det nå? Hvis svar er større enn 42. Altså hvis svar er 52.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0019", "start": 1600.54, "end": 1704.68, "token_count": 294, "text": "Ja, ser ut som det går fint. Ja. Det går det an å gjøre. Denne vil utføre det samme, for den returnerer da direkte. Men da må jeg bare dobbeltsjekke. Funker det nå? Hvis svar er større enn 42. Altså hvis svar er 52. Da må jeg kompulere på nytt og også kjøre. Ja, det ser ut til å funke fint. Og det er liksom... det er poenget. Nå var svar 52, og JG hopp hvis hun er større. Og da hopper han til greater, og så flytter han Mooby inn her. Så kunne jeg teste JG, om den faktisk funker. Hvis tallet er 42, så skal den jo ikke hoppe til 1 her oppe. Da skal den returnere 0. Så vi kan prøve det til slutt. Ja, da stemmer det. Den returnerer 0. Så den... Den fungerer som den skulle. Her ser vi hvordan man kan skrive en assemblerkode. Og dette vil egentlig si at man skriver maskinkode. For her er assembleren... Den gcc-en når den lager maskinkode av denne. Så bare oversetter den linje for linje.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0020", "start": 1680.0, "end": 1783.8, "token_count": 298, "text": "Den fungerer som den skulle. Her ser vi hvordan man kan skrive en assemblerkode. Og dette vil egentlig si at man skriver maskinkode. For her er assembleren... Den gcc-en når den lager maskinkode av denne. Så bare oversetter den linje for linje. Move er institusjon nummer 112. Så skriver den 112. Og så rbx. Og så kodestøyen, akkurat som i simuleringen jeg har sett på tidligere. Compare blir en linje, dette blir en linje, move blir en linje osv. Så dette blir linje for linje. Det var spørsmål hvilken verdi som reduseres når det bare står rett? Og det er... Rax returneres alltid. Og det er en slags sånn avtale med c-funksjoner. Jeg forventer å få returverdien i RAX. Nei, jeg kan ikke returnere noe som ikke er RAX. Men hvis jeg har en funksjon som... Nei, så jeg må legge den returverdien i RAX. Hvis du holder en funksjon, så har du andre rutiner. Da tar funksjonen imot variabler. Hvis du har en funksjon som har to int-variabler,", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0021", "start": 1749.74, "end": 1849.88, "token_count": 295, "text": "Nei, jeg kan ikke returnere noe som ikke er RAX. Men hvis jeg har en funksjon som... Nei, så jeg må legge den returverdien i RAX. Hvis du holder en funksjon, så har du andre rutiner. Da tar funksjonen imot variabler. Hvis du har en funksjon som har to int-variabler, men da legges de... Jeg husker ikke hva konvensjonen er, men da kan det være sånn at de innkomne variablene legges i rax og rbx. Så hele tiden må man ha konvensjoner, sånn at man vet hva funksjonene skal. Når du først har det, så kan man skrive kode som dette her og sende variabler frem og tilbake til funksjonen. Men det som er viktig her, er at vi nå på en måte har en idé om hvordan enhver sånn konstruksjon som dette her, en foreløpige eller en if-test... Hvordan den produseres i markinen. Spørsmål om... Jo, om returverdien, hvorfor det står int i... I maine. Altså, det er en int maine. Men maine har også en returverdi, så det...", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0022", "start": 1822.18, "end": 1941.9, "token_count": 292, "text": "Hvordan den produseres i markinen. Spørsmål om... Jo, om returverdien, hvorfor det står int i... I maine. Altså, det er en int maine. Men maine har også en returverdi, så det... Her kan maine returnere tall. Og det er derfor du har en int-verdi på maine. Hvis jeg nå kompilerer den her... Også kjører add-og-topp... Så vil jeg da se at... Da kan jeg lese ut returverdien fra det jeg kjørte programmet. Så den leverer et heltall, og på den måten kan program levere en feilkode når det kjøres. Så hvis jeg er i Linux her, så er feilkoden... Da får jeg ut akkurat den feilkodete i meg. Ok. Da skal vi til slutt se på noen slides og komme veldig raskt innom pipelining. Kanskje vi ser litt mer på det neste gang, men... Vi kan iallfall starte. Først skal jeg si litt om forenklinger ved den CPU-simuleringen vi hadde. Den simulerte CPU-en vi hadde, den virker i prinsipp som alle mer komplekse og moderne CPU-er.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0023", "start": 1907.32, "end": 2009.8, "token_count": 297, "text": "Kanskje vi ser litt mer på det neste gang, men... Vi kan iallfall starte. Først skal jeg si litt om forenklinger ved den CPU-simuleringen vi hadde. Den simulerte CPU-en vi hadde, den virker i prinsipp som alle mer komplekse og moderne CPU-er. Det er klart... Den simulerte CPU-en vi hadde, den virker i prinsipp som Men den har en rekke forenklinger. Det er vel heller de moderne CPU-ene som er mer komplekse, og de er blitt lagd mer komplekse for at de skal være raskere. I prinsippet så virker de på samme måte. For det første så bruker institusjoner mer tid enn én CPU-sykkel på å utføres. Og det er fordi at det er... De operasjonene er mer komplekse enn i vår enkle CPU, så det tar mer tid. F.eks. så hentes typisk først hver institusjon inn fra RAM, og så deles den opp i flere biter. F.eks. hvis en institusjon leser fra RAM eller skriver til RAM, så er det egne deler av institusjonen. Så en X86-institusjon deles generelt opp i små biter, eller mikro...", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0024", "start": 1991.52, "end": 2081.76, "token_count": 298, "text": "og så deles den opp i flere biter. F.eks. hvis en institusjon leser fra RAM eller skriver til RAM, så er det egne deler av institusjonen. Så en X86-institusjon deles generelt opp i små biter, eller mikro... Vi skal se litt på det snart. Men aller først, det som er veldig viktig å ha med videre, det er at vi har en CPU-ulykke, akkurat som med den i simuleringen. Så lenge maskinen ikke blir skrudd av, så utfører den instruksjoner. En NOP-instruksjon, Novo Operation, som ikke gjør noen ting, bare står og slår i lufta. Så dette er gangen for enhver CPU. Først henter man denne instruksjonen den skal kjøres. Og så øker programkontoen, og så utføres den instruksjonen. Instruksjoner kan være sånne som hopper i koden, men hvis det ikke er noe hopp i koden, så utføres bare... Så økes PC bare med én, og så fortsetter den å kjøre. Men CPU er også koblet til annen hardware, som tastatur og nettverkskort osv.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0025", "start": 2062.52, "end": 2150.12, "token_count": 300, "text": "Instruksjoner kan være sånne som hopper i koden, men hvis det ikke er noe hopp i koden, så utføres bare... Så økes PC bare med én, og så fortsetter den å kjøre. Men CPU er også koblet til annen hardware, som tastatur og nettverkskort osv. Så når som helst så kan CPU-en bli avbrutt av et interrupt. Det skal vi se på senere. Da må CPU-en stoppe i de operasjonene den gjør. Og så må den behandle interruptet. Så må CPUN stoppe opp og gjøre institusjoner som tar imot det tegnet, sånn at det kan skrives ut til skjermen. Den type avbrudd er det ikke CPUN som styrer, for det er avbrudd som kommer utenfra, så de kan komme når som helst. Pipelining. Jeg nevnte at en i institusjonen deles opp i flere biter. Man klarer ikke å gjøre den på én klokkesyklus. Det er rett og slett for mange operasjoner som skal gjennomføres, så man har funnet ut at det er bedre å dele opp instruksjonene i små biter enn å ha en veldig lang syklus.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0026", "start": 2130.0, "end": 2207.8, "token_count": 280, "text": "Man klarer ikke å gjøre den på én klokkesyklus. Det er rett og slett for mange operasjoner som skal gjennomføres, så man har funnet ut at det er bedre å dele opp instruksjonene i små biter enn å ha en veldig lang syklus. Så i de aller første mikkelprosessorene var det bare én syklus, sånn som i vår simulering. Snart med to sykler, altså fetch og execute. Først hente instruksjonen, og så utføre den. Etter hvert ble det en standard som hadde de viktigste operasjonene. Fetch, decode, execute rights. Fetch, hente instruksjonen. Decode er instruksjonsdekoderen som da finner ut hvilke knapper skal man trykke på i alle datapapp for å utføre instruksjonen. Og det må dekodes. Og så kommer execute. Det er virkelig å utføre instruksjonen. Hvis det er å legge sammen to tall, så skjer dette inni ALU. Og så skrive resultatet deres. Det er jo ikke alltid alle deler som utføres.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0027", "start": 2190.0, "end": 2275.68, "token_count": 286, "text": "Og det må dekodes. Og så kommer execute. Det er virkelig å utføre instruksjonen. Hvis det er å legge sammen to tall, så skjer dette inni ALU. Og så skrive resultatet deres. Det er jo ikke alltid alle deler som utføres. Men med dette kan dere tenke dere én måte å dele opp instruksjonene på. Men Moderne Sepur har enda flere stages enn dette her. 14 stages. Eller 14 deler, da... er vanlig. Og da deles da det som vi har tenkt på som én institusjon... En ad, f.eks. Det deles da opp i 14 små biter. Som på en måte er detaljer av den institusjonen som skal utføres. Og alt dette... Denne inndelingen gjøres for at alt skal gå fortere. Det man kan gjøre når man har delt opp når man har den type pipelining, det er at institusjoner kan gjøres samtidig. Det vi kan tenke hvis vi har 'fetch' og 'execute'. Hvis vi bare har to stages. To stadier er det vel på norsk. Så har vi første stadiet å hente institusjonen.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0028", "start": 2250.0, "end": 2347.8, "token_count": 293, "text": "Det man kan gjøre når man har delt opp når man har den type pipelining, det er at institusjoner kan gjøres samtidig. Det vi kan tenke hvis vi har 'fetch' og 'execute'. Hvis vi bare har to stages. To stadier er det vel på norsk. Så har vi første stadiet å hente institusjonen. Og andre er å utføre. Da kan vi tenke oss at OK... Men når vi er i gang med å utføre den første institusjonen, så kan neste institusjon hentes av fetch. For da slipper vi å vente på at den hentes. Og det er akkurat det som er pipelining. Man gjør operasjoner samtidig. Så hvis vi har fire stadier, så kan vi tenke oss at uten... Den blå er en institusjon, den røde er en annen. Så går klokka bortover sånn. I vår simulering gjør vi én institusjon på hvert klokkesyklus. Men hvis vi har en CPU som må ha fire sykler for å utføre en institusjon, så ser vi at den første - fetch, decode, execute også right. Men pipelining vil si at man gjør to operasjoner samtidig.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0029", "start": 2320.08, "end": 2415.6, "token_count": 293, "text": "I vår simulering gjør vi én institusjon på hvert klokkesyklus. Men hvis vi har en CPU som må ha fire sykler for å utføre en institusjon, så ser vi at den første - fetch, decode, execute også right. Men pipelining vil si at man gjør to operasjoner samtidig. Man begynner på den neste institusjonen før den første er ferdig. Så da får vi denne rekkefølgen istedenfor åtteklokkesykler. Så blir vi da ferdig på fem. For da henter vi først den første institusjonen, og så på neste syklus så dekodes den første institusjonen. Men samtidig så hentes neste. Og det er opplagt at da går ting raskere. Ja, her ser vi noen sånne mikroarkitekturer for Intel. Som jeg sa, de aller første... 8086 var en av de første CPU-ene for PC-er. Da var det en pipeline med to steg, eller to stages. Så ser vi at den har økt en del oppover. 54 plater hadde enormt mange stages. Men så har man gått litt tilbake. Og i de mer moderne er det 14 stages som er vanlige.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0030", "start": 2394.08, "end": 2495.38, "token_count": 297, "text": "Da var det en pipeline med to steg, eller to stages. Så ser vi at den har økt en del oppover. 54 plater hadde enormt mange stages. Men så har man gått litt tilbake. Og i de mer moderne er det 14 stages som er vanlige. Så dette er pipelining. Det gjør at vi gjør på en måte én og én instruksjon, men at man tjusstarter. Så kommer et litt annet prinsipp, og det er superskalararkitektur. Her utnyttes både pipelining, det samme prinsippet, men også i en superskalararkitektur så gjøres ting faktisk i parallell. Så sa vi at man har... La oss si du har åtte institusjoner etter hverandre. Det er de åtte neste som skal gjøres, eller seks institusjoner, som i dette tilfellet. Seks institusjoner etter hverandre. Så da er det kanskje én institusjon som er ad, og én er move. Og de er av litt forskjellig type. Og da gjør man faktisk de instruksjonene i den grad det er mulig, i parallell. Og her kan dere kanskje skimte at det står alu.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0031", "start": 2476.4, "end": 2561.28, "token_count": 288, "text": "Så da er det kanskje én institusjon som er ad, og én er move. Og de er av litt forskjellig type. Og da gjør man faktisk de instruksjonene i den grad det er mulig, i parallell. Og her kan dere kanskje skimte at det står alu. Her er det to aluer, og så er det en load her, og så er det en alu her borte med jump osv. Så det som skjer da, er at man... Først så deler man alle de seks institusjonene inn i mikroinstitusjoner. Så hver av de har kanskje 14 mikroinstitusjoner, med fetch-delen her oppe. På den måten at de seks institusjonene hvis mulig utføres i parallell på helt uavhengige små aluer her, som jobber parallelt med å regne og lagre. Og at dette er selvfølgelig bare for å få ting til å gå fortere. For da kan man få til å... Man kan utføre instruksjoner i løpet av en syklus, eller kanskje enda raskere, ved at man gjør ting i parallell inne i CPU-en.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0032", "start": 2541.52, "end": 2619.42, "token_count": 293, "text": "Og at dette er selvfølgelig bare for å få ting til å gå fortere. For da kan man få til å... Man kan utføre instruksjoner i løpet av en syklus, eller kanskje enda raskere, ved at man gjør ting i parallell inne i CPU-en. Dette må ikke forveksles med det vi skal se på senere med multitasking, for da har vi helt fullstendig store CPU-er som jobber helt uavhengig av hverandre. Men her deles institusjonene, sekvensielle institusjoner som kommer etter hverandre, opp i små biter. Og så utføres de i parallell. Så her kan det være institusjon 1 som holder på, samtidig med at institusjon 3 holdt på her borte. Det er klart, alle institusjoner kan ikke utføres i parallell. Altså, noen er avhengige av hverandre. Men det er et samarbeid mellom kompilatoren og CPU-en. Så prøver man å gjøre så mye som bare mulig parallelt. En skalær prosessor. Det norske ordet kan kanskje diskuteres. Jeg lurer på om kanskje skalar er bedre?", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0033", "start": 2596.36, "end": 2680.04, "token_count": 288, "text": "Men det er et samarbeid mellom kompilatoren og CPU-en. Så prøver man å gjøre så mye som bare mulig parallelt. En skalær prosessor. Det norske ordet kan kanskje diskuteres. Jeg lurer på om kanskje skalar er bedre? En skalar i motsetning til en vektor er noe som ikke er i parallell. Men i hvert fall en skalar prosessor utfører institusjoner én og én. De superskalære prosessorene, som egentlig er alle prosessorer etter år 2000, de er superskalære. De har flere parallelle enheter som utfører mikrooperasjoner. De kan ha flere aluer og FPU-er, sånn at de kan jobbe med helt forskjellige institusjoner på én gang, og kjøre de faktisk samtidig. Men det bryr man seg egentlig vanligvis ikke så mye om som operativsystem, for man ser ikke dette. CPU-en sørger alltid for at den logikken... Den kan til og med utføre operasjoner auto-warder i en annen rekkefølge enn det sekvensielle programmet tilsier.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0034", "start": 2656.6, "end": 2769.86, "token_count": 292, "text": "Men det bryr man seg egentlig vanligvis ikke så mye om som operativsystem, for man ser ikke dette. CPU-en sørger alltid for at den logikken... Den kan til og med utføre operasjoner auto-warder i en annen rekkefølge enn det sekvensielle programmet tilsier. Men da hender det man må gå tilbake og rette opp hvis noe går galt. Her ser vi Intel Core 2, som er en relativt moderne SPU-arkitektur. Den deler da institusjonene opp i mange småbiter. Og så ser vi her nede, så har vi da i parallell flere aluer. Her er en alu-branch og SSE-alu, og så har vi store-address. Store-data, load-address. Så for hver... Samtidig kan det kjøres i parallell. Dette gir da mye større ytelse på prosessoren. Man får da prosessoren til å yte litt ekstra ved at tingene gjøres parallelt. Men det er en grense for hvor mye du kan parallellisere. Utover det er det veldig vanskelig å få til parallellisering. Det er ikke alltid det virker, det er avhengig av koden.", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0035", "start": 2740.68, "end": 2849.98, "token_count": 291, "text": "Man får da prosessoren til å yte litt ekstra ved at tingene gjøres parallelt. Men det er en grense for hvor mye du kan parallellisere. Utover det er det veldig vanskelig å få til parallellisering. Det er ikke alltid det virker, det er avhengig av koden. Så det er et samarbeid mellom kompulatoren og CPU-en å få til den optimale kjøringen av en énprosess. Og det er... Det gjøres ved de to metodene, pipelining og parallellitet, eller superskalær. OK, jeg tenkte å begynne å se på bransjeprediction. For det er et sånt eksempel på hvordan pipelining kan faktisk ha innflytelse på det å kjøre programmer. Men jeg ser klokka er såpass mye nå, så jeg lurer på om vi bare utsetter den bransjeprediction-delen til neste gang. Og så stopper vi der. Med mindre det er noen spørsmål... noen som har noen de lurer på? Nei, still uansett gjerne spørsmål i chatten. Og så vil vi nå som vanlig, som alltid, så åpne jeg...", "source": "lecture"}
{"lecture_id": "os5time2", "chunk_id": "os5time2_0036", "start": 2816.16, "end": 2889.4, "token_count": 159, "text": "Og så stopper vi der. Med mindre det er noen spørsmål... noen som har noen de lurer på? Nei, still uansett gjerne spørsmål i chatten. Og så vil vi nå som vanlig, som alltid, så åpne jeg... Breakout rooms. Så kommer jeg og Ine og... Håper Rune er her også. Rune, er du her? Ja, Rune er her, ser jeg. Da lager jeg tre breakout-room, så må dere komme og spørre i de rommene. Still også gjerne spørsmål i chatten her ute, så kan vi... Men da stopper vi der, og så lager jeg Breakout Rooms.", "source": "lecture"}
{"lecture_id": "linux1del9", "chunk_id": "linux1del9_0000", "start": 0.0, "end": 88.68, "token_count": 297, "text": "Litt om oppgaver. Generelt når det gjelder oppgaver, så... Når man skal dokumentere at man har gjort en oppgave, så holder det lenge å bare copy og paste tekst fra de kommandoene du har gjort. Hvis du f.eks. har gjort... Ja, la oss si youname minus a. Du skal vise at du har gjort det. Så kan du ta den... Den teksten som står her. Og så bare... copy og så peise ned et dokument. Og så levere det. Så det holder lenge som dokumentasjon. Litt generelt om oppgavene denne uken. Det er bl.a. en oppgave hvor du skal bruke topp. Og topp, det er elkommandoen jeg har skrevet nå. Det er en kommando som viser fortløpende prosesser som står og kjører. Den stopper man med å tasse Q. Q, så kommer jeg ut igjen. Kontroll-L, så får jeg en clear screen. Men så skal man i den oppgaven også gjøre en kommando som heter PSAOX. Hvis du gjør den, så kommer det en masse linjer. Det er alle prosessene som står og kjører. Og da skal man i oppgaven også bruke grep.", "source": "lecture"}
{"lecture_id": "linux1del9", "chunk_id": "linux1del9_0001", "start": 69.34, "end": 155.4, "token_count": 285, "text": "Kontroll-L, så får jeg en clear screen. Men så skal man i den oppgaven også gjøre en kommando som heter PSAOX. Hvis du gjør den, så kommer det en masse linjer. Det er alle prosessene som står og kjører. Og da skal man i oppgaven også bruke grep. Og da setter man først en pipe. Dette er en pipe som sender nå alle dataene som kommer ut, alle linjene fra PSAUX. Det sendes nå videre til et annet program som heter GREP. Og i det GREP-programmet så kan jeg f.eks. grepe på tekst. Og f.eks. så kan jeg grepe på linjen eller på teksten 3.18329. Både linjer i PSA og X hvor dette brukernavnet står. På den måten. Og så går videre av oppgaven ut på at du skal lage et skript som gjør dette her. Og til slutt så skal skriptet virke på en sånn måte... Skripte PS-user. Det skal virke på en sånn måte at hvis du skriver f.eks..ps-user og så S318... Som et argument. Det som kommer da etter skriptet S318.", "source": "lecture"}
{"lecture_id": "linux1del9", "chunk_id": "linux1del9_0002", "start": 133.56, "end": 209.98, "token_count": 285, "text": "som gjør dette her. Og til slutt så skal skriptet virke på en sånn måte... Skripte PS-user. Det skal virke på en sånn måte at hvis du skriver f.eks..ps-user og så S318... Som et argument. Det som kommer da etter skriptet S318. Jeg kan legge på 318329. Det som kommer etter skriptet, det er argumentet. Og når jeg kjører det, da, så skal jeg i praksis gjøre det som står her oppe. Og det som må skje inni skriptet da, det er at S318329, det må legges på en måte bakerst i den kommandolinjen der. Og det kan man gjøre ved å bruke en spesiell variabel som heter dollar... dollar 1. Det første argumentet til skript, det vil legges internt i skriptet i en variabel som heter dollar 1. Så dermed så kan man inni skriptet bruke den verdien. Det skal vi snakke om senere, men prøv å få det til nå, sånn at du kan kjøre det skriptet her med vilkårlige kommandoer.", "source": "lecture"}
{"lecture_id": "linux1del9", "chunk_id": "linux1del9_0003", "start": 188.38, "end": 225.0, "token_count": 145, "text": "Det første argumentet til skript, det vil legges internt i skriptet i en variabel som heter dollar 1. Så dermed så kan man inni skriptet bruke den verdien. Det skal vi snakke om senere, men prøv å få det til nå, sånn at du kan kjøre det skriptet her med vilkårlige kommandoer. Nei, vi vil kåre argumenter. For eksempel kan jeg i stedet sag... Og da skrives ut alle linjer som inneholder Ruth. I stedet for alle med 3.18,329.", "source": "lecture"}
{"lecture_id": "os5del9", "chunk_id": "os5del9_0000", "start": 0.0, "end": 67.76, "token_count": 200, "text": "Det ble spurt om kode, hva den betydde. Og ja, jeg har lagt i litt her. Kode betyr åtte bytes. Men f.eks. long betyr fire bytes. Så da ville jeg skrevet noe sånt. Og det går an å skrive det òg. Da settes det av fire bytes i ramm. Til denne variabelen, som vil være en 32-bitsvariabel. Så det typisk GCC gjør, er når man bruker int, så er det long. Og da settes det av 4 byte til variabelen. Dette vil også kompilere og kjøre. Men det jeg ønsket generelt, var å bruke 8 byte til disse variablene. Hvis du bruker en long og du får tall som er større enn det som er plass til en long, så kan du få problemer.", "source": "lecture"}
{"lecture_id": "linux6del5", "chunk_id": "linux6del5_0000", "start": 0.0, "end": 115.04, "token_count": 285, "text": "Noe som er litt praktisk, og som er spesielt hvis man skal automatisere, er å kunne logge inn på andre Linux-servere uten å taste passord. Så jeg skal prøve å demonstrere hvordan man kan gjøre det til en annen bruker på StuddSSH. Så nå har jeg en testbruker på StuddSSH, S318329. Og da kan jeg jo logge meg inn på StudSSO. Det var feil... Da kan jeg logge meg inn med passordet til brukeren. På denne måten. For det første er det tungvint å skrive passord hver gang. For det andre så er det faktisk et sikkerhetsproblem. Hvis du har passord, så kan det gjettes. Så hvis jeg nå går tilbake, så fins det en metode for å sette opp passordløs tilkobling. Og da må man lage et nøkkelpar. Og det gjør man med kommandoen SSHIJEN. Denne kommandoen genererer da et nytt nøkkelpar. Og du blir spurt hvor du vil legge disse nøklene. Dette er den private nøkkelen som må passes veldig godt på. Og da kan du svare bare default.", "source": "lecture"}
{"lecture_id": "linux6del5", "chunk_id": "linux6del5_0001", "start": 90.0, "end": 191.58, "token_count": 294, "text": "Og det gjør man med kommandoen SSHIJEN. Denne kommandoen genererer da et nytt nøkkelpar. Og du blir spurt hvor du vil legge disse nøklene. Dette er den private nøkkelen som må passes veldig godt på. Og da kan du svare bare default. Jeg har allerede lagd en sånn nøkkel, så... Hvis du har en nøkkel fra før, så er det bedre å bruke den nøkkelen og ikke skrive over, for da forsvinner de rettighetene du hadde tidligere. Så jeg kan svare nei her. Så gjør du dette første gang, så svarer du ja. Det som skjer når vi kjører den kommandoen, er at i en mappe som heter.so, så lages det da to filer. id.rsa, som er den private nøkkelen, og id.rsa.pub, som er den offentlige nøkkelen. Og poenget med dette er at id.rsa er en privat nøkkel som på en måte beviser at du er deg. Mens den offentlige nøkkelen, som ligger da... Og ser sånn ut. Den skal du da legge inn dit du ønsker å kunne logge deg inn uten passord.", "source": "lecture"}
{"lecture_id": "linux6del5", "chunk_id": "linux6del5_0002", "start": 160.32, "end": 268.86, "token_count": 295, "text": "Og poenget med dette er at id.rsa er en privat nøkkel som på en måte beviser at du er deg. Mens den offentlige nøkkelen, som ligger da... Og ser sånn ut. Den skal du da legge inn dit du ønsker å kunne logge deg inn uten passord. Og da vil systemet i den andre enden forstå at når du bruker din private nøkkel for å dekryptere en hemmelig melding, så vil den andre enden forstå at du har rettigheter. Det som skal skje, er at hele denne nøkkelen skal kopieres over til StudieSSH. Men da er det lagd en kommando som gjør hele dette her. Og den heter SSH-copy-ID. Så det du kan gjøre, er i stedet for den SSH-kommandoen som du vanligvis bruker for å logge deg inn på StudieSSH, så kan du i stedet si SSH-copy... copy-ID. Og da kommer det informasjon, og så må du bruke det vanlige passordet som du logger deg inn med SSH. Og hvis du skriver det passordet riktig, så vil dette skje at du får beskjed om å prøve å logge deg inn på denne maskinen med SSH.", "source": "lecture"}
{"lecture_id": "linux6del5", "chunk_id": "linux6del5_0003", "start": 240.0, "end": 359.0, "token_count": 294, "text": "Og da kommer det informasjon, og så må du bruke det vanlige passordet som du logger deg inn med SSH. Og hvis du skriver det passordet riktig, så vil dette skje at du får beskjed om å prøve å logge deg inn på denne maskinen med SSH. Så skal jeg prøve med den innloggingen her. Og det som nå skal skje, er dette at jeg kommer rett inn uten å skrive noe passord. Og dermed kan jeg enkelt gå frem og tilbake. Hvis jeg skal eksplisitt kunne gå med SSH herfra, fra studie-SSH inn på Linux-VM, så må jeg gjøre det samme her. Og så lage en SSH kiy-gen og så SSH copy-id over til Linux. Så det går an. Men... Med ctrl-d så kan jeg gå tilbake igjen. Og da kan jeg enkelt gå frem og tilbake uten å skrive passord. Det man også kan gjøre, er å utføre kommandoer på motsatt side. Hvis jeg ønsker å utføre hostname på study SSO, så kan jeg bare skrive kommandoen etter SSO-linjen. Og så utføres nå hostname på study SSO. Og hvis jeg vil gjøre mer...", "source": "lecture"}
{"lecture_id": "linux6del5", "chunk_id": "linux6del5_0004", "start": 330.0, "end": 435.64, "token_count": 299, "text": "Det man også kan gjøre, er å utføre kommandoer på motsatt side. Hvis jeg ønsker å utføre hostname på study SSO, så kan jeg bare skrive kommandoen etter SSO-linjen. Og så utføres nå hostname på study SSO. Og hvis jeg vil gjøre mer... Omfattende operasjoner med... Det kan til og med være first host, name og så u-name i USA. Så kan jeg sende med hele kommandoer på den måten. Og da utføres de kommandoene på studiesesong. Når man setter opp passordløs innlogging på denne måten her, så er det veldig viktig å tenke over hva dette innebærer. F.eks. hvis du er i en gruppe på OSVM-en din hvor flere brukere har tilgang, så er det klart at med en gang du setter opp passordløs tilkobling til StudieSSH, så vil også de andre brukerne som har tilgang til en felles OSVM, også få muligheten til å logge inn på StudieSSH. Så hvis dette er tilfellet, så er det, med mindre det ikke har noe... Noe liggende av verdi på StudieSOS, så er det best å unngå å sette opp", "source": "lecture"}
{"lecture_id": "linux6del5", "chunk_id": "linux6del5_0005", "start": 407.6, "end": 467.56, "token_count": 197, "text": "så vil også de andre brukerne som har tilgang til en felles OSVM, også få muligheten til å logge inn på StudieSSH. Så hvis dette er tilfellet, så er det, med mindre det ikke har noe... Noe liggende av verdi på StudieSOS, så er det best å unngå å sette opp passordløs innlogging den veien, fra Linux-VM til StudieSOS. Men det som er trygt, er å sette opp det samme, passordløs innlogging fra StudieSOS til Linux-VM. For da... Det eneste det betyr, er at du som bruker på Studieshow, får tilgang til VM uten å taste passord. Det vil da også gjelde de andre som er på samme gruppe, men de vil da komme fra sin konto på Studieshow.", "source": "lecture"}
{"lecture_id": "os2del20", "chunk_id": "os2del20_0000", "start": 0.0, "end": 107.92, "token_count": 298, "text": "Sånn. Her er den virtuelle Windows-maskinen. Og så har jeg lastet ned det verktøyet som... Det sto vel en link i forrige ukes oppgaver. Så kan jeg kjøre det. Den sier no default printer. Det er OK. Men sånn ser dette verktøyet ut. Men det funker som det skal. Så dere får noen oppgaver denne uken, hvor dere skal laste ned noen komponenter og sette det sammen. Men helt til slutt i dag kan jeg vise noen enkle ting, hvordan man bruker det. Dette er en And-gate. Hvis man klikker på den, og så klikker uti kanalen her, så ser du at du får opp en port. Og så blir dere bedt om å gjøre noen oppgaver hvor dere skal sette sammen sånne porter. I dette verktøyet kan man logisk sette sammen porter, sånn at de virker sånn som de vil virke. Og lager det med halvledere. Så da er det noen sånne input man trenger. F.eks. her oppe står det en interaktiv input. Så hvis jeg klikker på den og plasserer den ut her... Dette er en bryter som kan skrus på som null og én.", "source": "lecture"}
{"lecture_id": "os2del20", "chunk_id": "os2del20_0001", "start": 83.08, "end": 171.08, "token_count": 292, "text": "I dette verktøyet kan man logisk sette sammen porter, sånn at de virker sånn som de vil virke. Og lager det med halvledere. Så da er det noen sånne input man trenger. F.eks. her oppe står det en interaktiv input. Så hvis jeg klikker på den og plasserer den ut her... Dette er en bryter som kan skrus på som null og én. Og så ønsker jeg deg å putte den inn i en an-port. Og da er det en liten blyant oppi hjørnet her, wiring tool. For å koble sammen inputen der til add-porten. Og da venstreklikker jeg sånn, så har jeg koblet de to sammen. Så kan jeg gjøre det tilsvarende. Jeg ønsker å ha en input til. Da gjør jeg tilsvarende. Hvis man er litt forsiktig, så får man rette og fine linjer. Litt skjev. Sånn. Da har jeg to input. Og så ønsker jeg å se hva som blir output her. Her oppe har jeg et lite leddlys. Rødt, det kan vi tenke oss at betyr én. Mens hvitt eller ingenting, det er null.", "source": "lecture"}
{"lecture_id": "os2del20", "chunk_id": "os2del20_0002", "start": 150.0, "end": 234.52, "token_count": 300, "text": "Litt skjev. Sånn. Da har jeg to input. Og så ønsker jeg å se hva som blir output her. Her oppe har jeg et lite leddlys. Rødt, det kan vi tenke oss at betyr én. Mens hvitt eller ingenting, det er null. Og nå har jeg lagd en liten krets. Og så... I utgangspunktet så... Så kan vi prøve å kjøre den kretsen. Og da, for å kjøre kretsen, så trenger jeg å bruke den hånden der, altså peke. For det jeg kan gjøre da, er at jeg kan skru på en ener. Da ser vi det kommer en ener inn i anden, og nå setter jeg på en ener til. Så kommer det to ener. Da burde det jo komme en null ut, men da må vi først kjøre kretsen. Du ser her. Hvis vi trykker på run nå, så begynner kretsen å kjøre. Da virker kretsen, og da ser vi at av én og én, det gir en ener ut. Så hvis jeg nå skrur av... Hvis jeg sender null inn i en annen port, så får jeg null ut. Hvis jeg sender to nuller, så får jeg også en null.", "source": "lecture"}
{"lecture_id": "os2del20", "chunk_id": "os2del20_0003", "start": 210.0, "end": 308.16, "token_count": 297, "text": "Hvis vi trykker på run nå, så begynner kretsen å kjøre. Da virker kretsen, og da ser vi at av én og én, det gir en ener ut. Så hvis jeg nå skrur av... Hvis jeg sender null inn i en annen port, så får jeg null ut. Hvis jeg sender to nuller, så får jeg også en null. Uansett, hvis jeg har en null inn i en annen port, så kommer det null ut. Så på denne måten så... Så kan man da bygge kretser, og så kan man teste det. Og det som... Jo, dets... Det som dere skal gjøre i oppgavene, det er vel å legge inn... Skal vi se om jeg får til det. Legge inn makroer. Skal vi se. Sånn, ja. Nå trykker jeg på en bed makro her oppe. Det betyr legge inn en liten boks. I oppgaveteksten står det at dere skal legge inn en full lader, f.eks. Det var den som vi bygde. Da har jeg lastet ned den til desktopen her. Sånn at jeg har full lader her. Og da ser vi... Da får vi en liten boks som er kodet inn", "source": "lecture"}
{"lecture_id": "os2del20", "chunk_id": "os2del20_0004", "start": 287.16, "end": 370.28, "token_count": 294, "text": "I oppgaveteksten står det at dere skal legge inn en full lader, f.eks. Det var den som vi bygde. Da har jeg lastet ned den til desktopen her. Sånn at jeg har full lader her. Og da ser vi... Da får vi en liten boks som er kodet inn med akkurat den logikken som vi så på. Og nå kan dere med de metodene her... Altså hvis dere ønsker å ha input til sett, så kan dere legge på en liten boks her, en null sånn, og så lage en wire herfra dit. Og så fortsette sånn. Da kan dere... F.eks. skal dere sette sammen to sånne, for å kunne legge sammen to tall. Dette er da teknikken man bruker for å gjøre det. Hvis jeg peker på den og høyre-klikker, så kan jeg se inne i boksen og se hva det er som foregår her. Da ser vi... Dette er hele logikken i boksen. X, Y, Z. Dette ser jo enklere ut enn det vi... Men her er det gjort noen enda mer smarte forenklinger. Dette er vel en exor-port. Vi bruker noen andre porter.", "source": "lecture"}
{"lecture_id": "os2del20", "chunk_id": "os2del20_0005", "start": 347.2, "end": 442.84, "token_count": 290, "text": "og se hva det er som foregår her. Da ser vi... Dette er hele logikken i boksen. X, Y, Z. Dette ser jo enklere ut enn det vi... Men her er det gjort noen enda mer smarte forenklinger. Dette er vel en exor-port. Vi bruker noen andre porter. Du kan uttrykke dette hver and or og not, men dette er en enda mer effektiv måte. Dette er den mest effektive måten å kode en fullader på, med and or og not-porter. Dvs. dette er en exor, som igjen er and or-porter. Dermed kan man lage dette med X, Y og Z inn, og riktig C og S ut. Og hovedpoenget er da... Da kan man legge inn flere sånne. Sånne makroer som dette her. Legge inn to og tre boksere av den typen. Og så sette det sammen og få en krets som da legger sammen... Sånn, ja. Man må klikke på kanvasen for å få ut det. Det man da må gjøre etter hvert, er liksom ta wire mente derfra. Det skal jo opp i Z. Så kan man kable det på den måten der.", "source": "lecture"}
{"lecture_id": "os2del20", "chunk_id": "os2del20_0006", "start": 414.64, "end": 485.98, "token_count": 211, "text": "Og så sette det sammen og få en krets som da legger sammen... Sånn, ja. Man må klikke på kanvasen for å få ut det. Det man da må gjøre etter hvert, er liksom ta wire mente derfra. Det skal jo opp i Z. Så kan man kable det på den måten der. Sette sammen boksene, og vips, så har man settes sammen. En operasjon, en liten bit av NCPU, som er den biten som legger sammen tall. Det vi skal se på senere, er en hel datamaskin som er bygd på denne måten her. Det var en oppgave vi hadde tidligere i datamaskinarkitektur. Da bygde alle stuntene en hel datamaskin som opererer i prinsippet akkurat som en datamaskin. Men som er simulert med and or-rapporter på denne matten.", "source": "lecture"}
{"lecture_id": "os5del4", "chunk_id": "os5del4_0000", "start": 0.0, "end": 104.56, "token_count": 288, "text": "Det var den funksjonen... Sumfunksjonen. Denne. Og... Det vi så på sist, var at vi ba GCC om å lage assemblekode for den. Så så vi hvordan den så ut. Vi kan repetere det. Jeg ba... GCC om da å lage assemblerkode. Og den skulle da bli sum funksjon dos bes. Og den så ut som noe sånt som dette her. Så fant vi ut... Hvis vi går inn og ser i detalj, så ligner den veldig på den maskinkoden vi hadde i simuleringen. Bortsett fra denne skriver nå ut til minnene. Vi ser deg hele tiden. Men i prinsippet ligner koden veldig. Lager løkker på samme måte. Men det vi skulle se på nå, var hva skjer med denne funksjonen hvis jeg ber om lag så effektiv kode som bare mulig? Jo, da kan vi prøve å se hva som skjer, da. Da får jeg en ny assembly-kode. Og denne er da lagd av GCC for å være mest mulig effektiv. Og da ser vi ganske overraskende at her var det ikke veldig mye kode. Noen som klarer å se hva denne koden her gjør.", "source": "lecture"}
{"lecture_id": "os5del4", "chunk_id": "os5del4_0001", "start": 80.2, "end": 178.96, "token_count": 293, "text": "Da får jeg en ny assembly-kode. Og denne er da lagd av GCC for å være mest mulig effektiv. Og da ser vi ganske overraskende at her var det ikke veldig mye kode. Noen som klarer å se hva denne koden her gjør. Den skal jo regne ut en hel sum, men det er veldig få instruksjoner her. Og det som da viser seg, er at kompilatoren er faktisk da så smart... Det er klart at den ser vel uansett hva som skjer med input og output i denne metoden. Uansett når denne kjøres, så vil du regne ut en sum 1 pluss 2 pluss 3 som blir 6. Så den gjør da faktisk den optimale optimaliseringen. Den regner ut hele løkka, og så kommer den fram til at svaret blir seks. Så svarer 6 ut i AX, og så returnerer det. Så det er morsomt nok. Så er det den optimale... Den optimale versjonen av dette... Av denne løkka her. Det er jo bare å returnere tallet 6. Det virker jo litt overraskende, men det er helt logisk. GCC går nå inn for å lage...", "source": "lecture"}
{"lecture_id": "os5del4", "chunk_id": "os5del4_0002", "start": 153.56, "end": 209.0, "token_count": 173, "text": "Så det er morsomt nok. Så er det den optimale... Den optimale versjonen av dette... Av denne løkka her. Det er jo bare å returnere tallet 6. Det virker jo litt overraskende, men det er helt logisk. GCC går nå inn for å lage... Den hurtigst mulige versjonen av denne koden. Og det er da faktisk bare å returnere tallet seks. Med en gang du får et input her, eller det kan skje andre ting, så er det klart, da kan man ikke optimalisere på den måten. Så hvis vi la til et input, så ville du sett at det fortsatt var en løkke, men at programmet da stort sett bare brukte registeret.", "source": "lecture"}
{"lecture_id": "os1del8", "chunk_id": "os1del8_0000", "start": 0.0, "end": 104.28, "token_count": 299, "text": "Vesentlige mål for kurset. Det første mest praktiske er å kunne lære å bruke kommandolinje og skrive systemskript. Vi bruker mest Linux og dokker, men også noe Windows-skript i. Så det er den første praktiske delen. Den andre er, som jeg sa, å lære hvordan en datamaskin virker på alle nivåer. Og helt opp til operativstemme og applikasjonene som sitter på toppen av operativstemme. Det ble spurt om pensumlitteratur, og svaret var at to compendier dekker pensum. De ligger ute, de som er fra i fjor, men blir fortløpende oppdatert. Anbefalt støttelitteratur. Tan Baum. Det er en veldig god bok. Men den er veldig omfattende og stor og dyr. Så jeg vil ikke forlange at dere alle skal gå og kjøpe og lese hele den. Men spesielt for de som liker dette kurset og er interessert, så er det en veldig... Veldig dyptpløyende og god bok. Men den er nok i overkant omfattende. Den er kanskje på 1000 sider. Overkant omfattende for et kurs som dette her.", "source": "lecture"}
{"lecture_id": "linux4del1", "chunk_id": "linux4del1_0000", "start": 0.0, "end": 82.48, "token_count": 283, "text": "Vi skal se noe litt mer systematisk på vertsskripting, eller skjellprogrammering. Og vi kan lage mange forskjellige typer skript. Sånn som vi allerede har gjort, så kan ny skript lage nye kommandoer. Så er det vanlig å lage oppstartsprogrammer, programmer som gjør systemarbeid, og som setter opp ting og får systemet til å... Og virke som det skal. Så kan vi lage installasjonsprogrammer som installerer andre programmer. Så er det også vanlig å lage demons. Såkalte demons. Så det er prosesser som alltid står og går i bakgrunnen og utfører en eller annen tjeneste. Hvis vi setter inn et program... Mitt prog. Et script. Men sånn og bak her, så vil det stå og kjøre i bakgrunnen. Stort sett vil den faktisk også fortsette å kjøre etter at den har logget ut, sånn som andre systemprosesser. Men det er ikke helt riktig, spesielt hvis det skriver noe til output, til fil eller til skjerm, så kan man risikere at det stopper.", "source": "lecture"}
{"lecture_id": "linux4del1", "chunk_id": "linux4del1_0001", "start": 56.06, "end": 142.2, "token_count": 298, "text": "Men sånn og bak her, så vil det stå og kjøre i bakgrunnen. Stort sett vil den faktisk også fortsette å kjøre etter at den har logget ut, sånn som andre systemprosesser. Men det er ikke helt riktig, spesielt hvis det skriver noe til output, til fil eller til skjerm, så kan man risikere at det stopper. Det skal vi se på senere, bl.a. så kan man bruke screen for å beholde en prosess. Når du skriver et skript, så er det viktig å ikke skrive hele skriptet med en gang. Prøv å begynne med et lite skjelett, og så test typisk ut i kommandoen først. Få de kommandoene du skal kjøre til, og virke. Og så putter du det inn i skriptet bit for bit. Og så utvider du med en detalj i gangen og tester for hver gang. Det kan også være smart å bare ta copy og paste ut i kommandovinduet når du skal teste. Dette er litt forskjellig fra andre programmer, nettopp fordi syntaksen i et chellscript er litt kryptisk. Og det er veldig mange småfeil som kan oppstå, så test hele veien.", "source": "lecture"}
{"lecture_id": "linux4del1", "chunk_id": "linux4del1_0002", "start": 120.0, "end": 194.98, "token_count": 274, "text": "Det kan også være smart å bare ta copy og paste ut i kommandovinduet når du skal teste. Dette er litt forskjellig fra andre programmer, nettopp fordi syntaksen i et chellscript er litt kryptisk. Og det er veldig mange småfeil som kan oppstå, så test hele veien. Ellers så er det et par tips til debugging. Hvis man kjører mitt script med på denne måten, Med bæsj minus X så vil det vises hvert step i skriptet når det kjøres. Altså det vil vise hva som skjer. Og det kan være veldig nyttig hvis det er en feil, for da kan du se... Oi, her. Denne variabelen ble ikke tatt inn, så derfor ble det feil. Eller så er den gamle, gode måten å legge inn noen ekkord, har nå kommet hit. Det går an å legge inn når du skal finne feil. Så igjen, ta én bit av gangen og fullfør det, og så legger du på neste bit. Ikke skriv masse kode og så begynne å kjøre. Da blir det mye feilsøkel.", "source": "lecture"}
{"lecture_id": "os2del9", "chunk_id": "os2del9_0000", "start": 0.0, "end": 77.64, "token_count": 300, "text": "Ja, nå har vi startet med en sannhetstabell. Og så har vi skrevet ned et logisk uttrykk for den sannhetstabellen. Og da kan vi begynne å tegne krets. Og når vi har tegnet en krets, så kan vi bare sende inn til Intel og be dem om å brenne denne kretsen, og så får vi hardware som er akkurat som vi ønsker det. Men først må vi tegne kretsen. Det er ganske enkelt, for da har vi ledninger A og B som kommer inn her. Som man setter spenning over. Og så, når man har et uttrykk som det her, A ganger B pluss A ganger B, så tenker vi oss først... OK, først må jeg ha A ganger B. Og A ganger B, da trenger jeg en anport. Og den har jeg her. Så da kommer A ganger B ut her på høyre side. Så trenger jeg å legge til, eller... Legge til med en år, som vi skal se... Jeg trenger å legge til dette uttrykket. Not A ganger not B. Og da kan jeg bare sette på to not-porter her oppe av. For da kommer det en kabel her med A.", "source": "lecture"}
{"lecture_id": "os2del9", "chunk_id": "os2del9_0001", "start": 55.76, "end": 134.72, "token_count": 300, "text": "Så trenger jeg å legge til, eller... Legge til med en år, som vi skal se... Jeg trenger å legge til dette uttrykket. Not A ganger not B. Og da kan jeg bare sette på to not-porter her oppe av. For da kommer det en kabel her med A. Så går den inn i not-port. Da kommer ikke A ut på andre siden. Og så kommer ikke B her. Og de sendes inn i en port. Så da blir det ikke A ganger ikke B som kommer ut her. Så her står det en pluss, det er en år. Så da er det bare å ta de to, a ganger b, og ikke a ganger ikke b, og legge inn i årporten. Og vips, så har vi kretsen vi ønsker. Og hvis vi har flere ledd her, så er det bare å legge dem inn i samme årport. Eller man kan også ha flere årporter. Og hvis man har a, b og c, a ganger b ganger c, så kan man også legge det inn i n-porten. Og på denne måten kan man skrive ned hardware. For enhver logisk krets. Og så... Før man da... Før man da sender inn til brenning av kretser,", "source": "lecture"}
{"lecture_id": "os2del9", "chunk_id": "os2del9_0002", "start": 110.1, "end": 138.44, "token_count": 89, "text": "Og hvis man har a, b og c, a ganger b ganger c, så kan man også legge det inn i n-porten. Og på denne måten kan man skrive ned hardware. For enhver logisk krets. Og så... Før man da... Før man da sender inn til brenning av kretser, så ønsker man gjerne å foren...", "source": "lecture"}
{"lecture_id": "os3del6", "chunk_id": "os3del6_0000", "start": 0.0, "end": 72.88, "token_count": 278, "text": "Dette er det første forsøket vårt på å lagre en bit. Så det jeg skal gjøre nå, er å prøve å feile og så utvikle en konstruksjon som kan lagre en bit. Og q er da liksom det jeg lager. Den lagrede enheten. Så i dette tilfellet, i denne kretsen her, så lagrer vi en ener. Og vi ser også, vi har satt det opp på en litt sånn lur måte, Så kommer en null inn her, og så går den enere ut. Og så ser vi at vi har koblet output fra denne outporten til input på den som står under. Og da ser vi for en litt lur krets som det kommer en ener inn her. Og da vil det gå en null ut, og så går en null inn der, og så kommer det en ener ut. Så her har vi konstruert en krets som inneholder en ener. Men hva er problemet, er spørsmålet. Jo, problemet her er at det er vel og bra at vi har den eneren, men dette er en lukket krets, så der vil det bare bli stående en ener for evig og alltid.", "source": "lecture"}
{"lecture_id": "os3del6", "chunk_id": "os3del6_0001", "start": 52.68, "end": 78.96, "token_count": 104, "text": "Så her har vi konstruert en krets som inneholder en ener. Men hva er problemet, er spørsmålet. Jo, problemet her er at det er vel og bra at vi har den eneren, men dette er en lukket krets, så der vil det bare bli stående en ener for evig og alltid. Så på en eller annen måte må vi kunne endre på denne verdien. Og da kommer neste forsøk.", "source": "lecture"}
{"lecture_id": "linux8del5", "chunk_id": "linux8del5_0000", "start": 0.02, "end": 110.4, "token_count": 300, "text": "Og hva er forskjellen på image og container? Generelt, container er da den kjørende enheten. Imaget er filen som inneholder alkohol. Men vi kan starte en container. Dere container run. Og så så vi sist at minus it, det er for interaktivt å tette y. Det er for å starte opp en terminal. Og så kan vi si at i den... Nå bare laster jeg ned punktet. Og så ønsker jeg å kjøre et bæsjvindu når den starter opp. Og da ser vi... Nå hentes det et image fra... Ikke fra GitHub, men fra Dokkeraup. Da ble det lastet ned, og så ser vi at nå fikk vi opp et prompt der. Og det betyr at nå er jeg inne i dokker-imaget. Inne i dokker-konteineren. Så nå er dette en konteiner, for det er et image som da er startet opp. Så en instanse har jeg nå fått opp. Og jeg kan starte flere instanser av det samme imaget. Så... Hvis jeg tar PVD her, så vil jeg se at jeg er inni et Linux filsystem. Jeg kan ta... og se hva slags distribusjon det er. Og vi ser at dette er 18.04.", "source": "lecture"}
{"lecture_id": "linux8del5", "chunk_id": "linux8del5_0001", "start": 79.42, "end": 191.4, "token_count": 284, "text": "Så en instanse har jeg nå fått opp. Og jeg kan starte flere instanser av det samme imaget. Så... Hvis jeg tar PVD her, så vil jeg se at jeg er inni et Linux filsystem. Jeg kan ta... og se hva slags distribusjon det er. Og vi ser at dette er 18.04. Og så så vi sist at... Hvordan er det hvis jeg tar Exit nå? Så vil... Vi kan prøve det. Så vil containeren stoppe. Hvis jeg nå tar dokkecontainer PS, så ser vi at vi har en... Ingen container som kjører. Men PS-A, da vil jeg se at jeg har en container som... Det ble gjort exit på for tolv sekunder siden. Men da er det mulig å starte den på nytt. Så da kan jeg si... Dokker, konteiner start. Så konteiner i den. Så ser vi at da starter konteineren. Og der har vi en konteiner som kjører i syv sekunder. Eller som har kjørt i syv sekunder. Konteineren er liksom selve instansen. Og imaget er det imaget som instansen er startet fra.", "source": "lecture"}
{"lecture_id": "linux8del5", "chunk_id": "linux8del5_0002", "start": 159.04, "end": 339.68, "token_count": 298, "text": "Så ser vi at da starter konteineren. Og der har vi en konteiner som kjører i syv sekunder. Eller som har kjørt i syv sekunder. Konteineren er liksom selve instansen. Og imaget er det imaget som instansen er startet fra. Men nå er vi på en måte ute av konteineren igjen. Vi så også sist på hvordan vi kan koble oss til. Og det kan vi gjøre med... Det er et par materiører på her. Den beste måten er kanskje å bruke eksekut. For da kan man si at man ønsker å eksekutere på... I denne konteineren så ønsker jeg å kjøre bæsj. Så... Ops. Kanskje jeg ikke trenger IT her. Prøve IT her, da. Nei, da må jeg sjekke ut hvordan det var i brukt eksekutt. Skal vi se. Dette her burde virke. Sånn. Ja. Jeg lurer på hva jeg gjorde feil sist, men skal vi se. Det var bare rekkefølgen på IT. Jeg måtte ha... IT må komme etter eksigens. Sånn. Så da har jeg koblet meg inn i konteineren igjen.", "source": "lecture"}
{"lecture_id": "linux8del5", "chunk_id": "linux8del5_0003", "start": 270.0, "end": 366.0, "token_count": 164, "text": "Skal vi se. Dette her burde virke. Sånn. Ja. Jeg lurer på hva jeg gjorde feil sist, men skal vi se. Det var bare rekkefølgen på IT. Jeg måtte ha... IT må komme etter eksigens. Sånn. Så da har jeg koblet meg inn i konteineren igjen. Da kan jeg se til meg at jeg har history, så jeg kan bla tilbake her. Og så er det en annen måte å gå ut av konteineren på. Det er kontroll P, kontroll Q. Da kommer jeg ut, og da vil jeg se at jeg fortsatt... System PS. Så står den fortsatt der og kjører.", "source": "lecture"}
{"lecture_id": "linux7del7", "chunk_id": "linux7del7_0000", "start": 0.0, "end": 126.68, "token_count": 294, "text": "Ja, da skal vi ta oss og kjøre en Hello World. Ja, jeg kan jo ta oss og... Med disse slidene så kan jeg ta og... Kjøre det i et vindu her. Skal jeg ta og i stedet... Det kan sikkert være fint for dere å ha slidene oppe, men jeg kan da dele... Et dokkervindu med dere i stedet. Sånn. Jeg kan kanskje vise hvordan det er tenkt at dere skal gjøre det, hvis dere ikke har gjort det allerede. Er inne på desktopen min, som står nede på bordet mitt. Og så går jeg inn som jeg bruker OS70. Bare logger inn på den som vanlig. Jeg er nettopp logget inn, så jeg trengte ikke... Ja, generelt så må man bruke sudo for å kjøre dokker. Som jeg snakket om tidligere, dette er VM-er. Man trenger ikke være like bekymret for å kjøre ting som Ruud. Hvis noe galt skjer, så går det an å bygge VM-ene på nytt. Sånn. Men i hvert fall nå har jeg et Ruud-skjell. For de som er interessert, så kan du se at her ligger en dokker.so.", "source": "lecture"}
{"lecture_id": "linux7del7", "chunk_id": "linux7del7_0001", "start": 102.84, "end": 249.88, "token_count": 296, "text": "Man trenger ikke være like bekymret for å kjøre ting som Ruud. Hvis noe galt skjer, så går det an å bygge VM-ene på nytt. Sånn. Men i hvert fall nå har jeg et Ruud-skjell. For de som er interessert, så kan du se at her ligger en dokker.so. Jeg installerte dokker på VM-en her. Det eneste jeg gjorde, var å kjøre det. Det installerer sertifikat og noe greier, og så henter det ned dokker fra dokker.com. Det som er installert, er dokker. Når man har gjort det, så kan man begynne å kjøre containere. Vi kan starte med dokker. Også Hello World. Det er en... En bitte liten dokker hello world. Da ser vi den starter oss oppover, men da har den kjørt en liten container. Vi kan kanskje gå tilbake til slidene og se på hva som egentlig skjer her, når jeg kjører denne hello world. Etter hvert skal vi kjøre litt mer avanserte ting. Man kan f.eks. kjøre Ubuntu, og da starter opp tilsvarende en hel Ubuntu-server. Så ser vi den kommandoen der, var det jeg kjørte.", "source": "lecture"}
{"lecture_id": "linux7del7", "chunk_id": "linux7del7_0002", "start": 204.56, "end": 322.76, "token_count": 241, "text": "når jeg kjører denne hello world. Etter hvert skal vi kjøre litt mer avanserte ting. Man kan f.eks. kjøre Ubuntu, og da starter opp tilsvarende en hel Ubuntu-server. Så ser vi den kommandoen der, var det jeg kjørte. Men hva var det som egentlig hendte, da? Jo, når jeg kjører docker-rund, så er det egentlig flere kommandoer som skjer. Man kan gjøre de eksplisitt, men det er bare både docker-bild... Så man kjører egentlig de tre kommandoene der. Og pull, dvs. at den går ut i dockerhub, som er et repository. Altså et lager av forskjellige docker-images. I vårt tilfelle henter vi bare en liten hello world. Som vi ser her, kan vi hente Så lastes det imaget ned fra Dokkerov hit. Og så det neste... Det var pull. Og så rund. Da kjøres... Da kjøres det imaget som en kontakt.", "source": "lecture"}
{"lecture_id": "linux12del10", "chunk_id": "linux12del10_0000", "start": 0.0, "end": 113.88, "token_count": 282, "text": "Så skal vi se på... ja, et par kommandoer som er veldig nyttige. Som vi har tilsvarende i Linux. Og det er spesielt sort object og select object. De har mange egenskaper, men kanskje det mest nyttige er å sortere på bokstaver og tall. Men også da... belgutt fra en liste. Så vi kan prøve først å bruke LS. Så kan jeg sende det til sort. Vi kan skrive det fullt ut først. Sort object på den måten. Men så trenger vi å sortere et eller annet. Vi må si hva vi vil sortere på. Da kunne jeg, som vanlig, så kunne jeg sende LS til Game eller get members. Eksplosives, get member. Da får vi alle propper til det. Og så kan vi se... OK, length, den vil vi prøve. Så da tar jeg sort over objects. Og så ønsker jeg å sortere på lengde. Da ser vi... Vi får en sortert liste med hvor lengden står. Så kunne vi også ta med... Her kan man legge på opsjoner. Hvis jeg taster minus D her og tapp, så ser vi om vi får descending...", "source": "lecture"}
{"lecture_id": "linux12del10", "chunk_id": "linux12del10_0001", "start": 90.0, "end": 210.78, "token_count": 288, "text": "Og så ønsker jeg å sortere på lengde. Da ser vi... Vi får en sortert liste med hvor lengden står. Så kunne vi også ta med... Her kan man legge på opsjoner. Hvis jeg taster minus D her og tapp, så ser vi om vi får descending... Ja, det er eneste opsjon som begynner på D, men generelt så kan man... Her ønsker jeg det sending. Det betyr rett og slett at vi sorterer i synkende verdier. Sånn som dette objektet her, har en default utskriftsmetode. Ofte kan det være greit å kunne skrive det ut på andre måter. Det man generelt kan gjøre da, er å sende output til format table. Da kan man skrive ut sin egen liste over hva man ønsker å ha med. La oss si jeg ønsker å ha med name og lengd på den måten. Så da får jeg ut en formatert tabell med navnet først og lengden etterpå. Da kan man plukke ut nøyaktig det man ønsker, og få en grei overskrift. Dette kan forkortes til FT. FT... Så får man en sånn overskrift.  Ja. Noen ganger så...", "source": "lecture"}
{"lecture_id": "linux12del10", "chunk_id": "linux12del10_0002", "start": 170.36, "end": 292.96, "token_count": 292, "text": "Så da får jeg ut en formatert tabell med navnet først og lengden etterpå. Da kan man plukke ut nøyaktig det man ønsker, og få en grei overskrift. Dette kan forkortes til FT. FT... Så får man en sånn overskrift.  Ja. Noen ganger så... Du vil jo en sånn liste kunne bli ganske lang. La oss si jeg går opp hit. Og så skriver jeg ut den tilsvarende listen. Ja. Nå ble det ikke gjort noe lenger, det er bare fordi jeg tok LS. Men la oss si jeg tar nå LS minus R. Den er veldig nyttig. Da går man nedover. Der fikk jeg en masse filer. Da er det et par ting vi kan gjøre her. Vi så noe rødt over skjermen. Vi kan luke bort feilmeldinger. Så vi kan ta feilmeldinger og sende til null. Ikke se alle, men plukke ut... Ja, la oss si de fem første. Og det er her select object kommer inn. Da kan vi si select object. Og så kan vi si first... Jeg ønsker bare de første fem. På den måten. Så vil jeg da plukke ut de fem største objektene.", "source": "lecture"}
{"lecture_id": "linux12del10", "chunk_id": "linux12del10_0003", "start": 263.1, "end": 375.26, "token_count": 294, "text": "Ikke se alle, men plukke ut... Ja, la oss si de fem første. Og det er her select object kommer inn. Da kan vi si select object. Og så kan vi si first... Jeg ønsker bare de første fem. På den måten. Så vil jeg da plukke ut de fem største objektene. Og da ser vi... Da har vi veldig kjapt med en kommandolinje funnet et veldig kraftig verktøy, nemlig en metode å finne alle filer... Eller å finne de fem største filene som ligger i denne mappen. Den tar litt lengre tid, men den leter nå gjennom alle mapper på C-kolon, og så plukker den ut... Den sorterer da alle objektene etter lengde. Og så, etter at den har sortert, så velger den de første fem. Og så skriver den ut. Filosofien her er den samme som vi har sett i Linux. Men på en måte så er dette enda kraftigere, fordi vi har objekter som pipes imellom her. Det tar nok litt lengre tid og krever litt mer ressurser, men det er veldig fleksibelt når man skal programmere. Så dermed har jeg på kort tid fått ut", "source": "lecture"}
{"lecture_id": "linux12del10", "chunk_id": "linux12del10_0004", "start": 353.1, "end": 460.26, "token_count": 291, "text": "Men på en måte så er dette enda kraftigere, fordi vi har objekter som pipes imellom her. Det tar nok litt lengre tid og krever litt mer ressurser, men det er veldig fleksibelt når man skal programmere. Så dermed har jeg på kort tid fått ut de fem største fillene på disken. Ja... Vi snakker om tid. Ofte så kan det være nyttig å så måle... måletid. Og da er det en kommando som heter measure... Skal vi se... Measure command. Den tar da tiden på én kommando. Så man skriver mesh command. Starter med curl point S og avslutter med curl point S. Og da kan jeg generelt ta tiden på hvor langt de kommandoer bruker. Så det kunne jeg brukt for å sammenligne hastigheter av forskjellige skrift i Windows. Og da får vi ut en lang liste, og dette er et slags... Dette er et tidsobjekt. Men det vi ønsker å se her nå, er at dette tok 22 sekunder. Her kommer det ut en skrift. Her kommer det ut en utskrift. Men det vi vet fra PowerShell, er at egentlig så er nok dette her et objekt.", "source": "lecture"}
{"lecture_id": "linux12del10", "chunk_id": "linux12del10_0005", "start": 440.2, "end": 476.02, "token_count": 113, "text": "Dette er et tidsobjekt. Men det vi ønsker å se her nå, er at dette tok 22 sekunder. Her kommer det ut en skrift. Her kommer det ut en utskrift. Men det vi vet fra PowerShell, er at egentlig så er nok dette her et objekt. Og det er da et objekt som man kan plukke ut og trekke ut sekunder osv. Og det har også metoder. Og det skal vi se generelt på nå. Det er på tide.", "source": "lecture"}
{"lecture_id": "os7del10", "chunk_id": "os7del10_0000", "start": 0.0, "end": 72.0, "token_count": 225, "text": "Så et lite spørsmål til alle. Man må jo til og med regne litt. Med papir og blyant, hvis man ikke har en kalkulator eller er god i hoderegning. Spørsmålet etrer hvis en 100 % CPU-avhengig prosess bruker 18 sekunder på én enkelt CPU, hvor lang tid bruker da fem slike prosesser på en server med fire CPU-er? Og dette vil da være tilsvarende... Ja, 18 var kanskje ikke helt riktig. Men jeg tenkte å teste ut med denne prosessen her, som tar omtrent 18 sekunder. Så problemstillingen er... Jeg kjører én enkelt prosess, og den bruker 18 sekunder. Men hvor lang tid tar det hvis jeg da starter opp med en forløkke? Starter opp og kjører fem sånne jobber. Ja, jeg ser vi har fått inn en del svar allerede.", "source": "lecture"}
{"lecture_id": "os6del12", "chunk_id": "os6del12_0000", "start": 0.0, "end": 88.96, "token_count": 288, "text": "Så det kan se ut noe sånt som dette her. Her har vi tre prosesser, P1, P2 og P3, som kjører etter hverandre. Og her så ser vi tiden i millisekunder. Altså millisekunder, det er et tusendels sekund. Så vi ser... En typisk tid P1 kjører, er i ti millisekunder. Altså et hundredels sekund. Men på et hundredels sekund kan jo én prosess som står og kjører, den kan gjøre millioner, for ikke å si milliarder, av institusjoner. Millioner av institusjoner kan den gjøre. Og da får operativstemme, får dette til å se ut som om alle disse tre prosessene kjører samtidig. Men i virkeligheten, når du bare har én CPU, Så P1 kjører i 10 mil eller sekunder. Så kommer det en context switch. Det er ganske omfattende. Da må OS lagre alt om... ... om denne prosessen her. Husker det er et levende liv som leves. Så alt som eksisterer om prosess 1, det må lagres. Alle verdier i registeret, f.eks.", "source": "lecture"}
{"lecture_id": "os6del12", "chunk_id": "os6del12_0001", "start": 60.0, "end": 156.06, "token_count": 300, "text": "Så P1 kjører i 10 mil eller sekunder. Så kommer det en context switch. Det er ganske omfattende. Da må OS lagre alt om... ... om denne prosessen her. Husker det er et levende liv som leves. Så alt som eksisterer om prosess 1, det må lagres. Alle verdier i registeret, f.eks. Alt den har i ramm, er allerede lagret i ramm, men all kontekst, all info om den prosessen, det må lagres. Og så må all konteksten til P2 lastres inn. F.eks. hvilke verdier registerene hadde når P2 stoppet sist. Og sånn fortsetter det. Man bytter med kontekst-switcher hele veien. Og så kommer P1 inn igjen. Og så bytter de om å kjøre på denne nå. PCB er prosesskontrollblokk. Det er en blokk i ramm som inneholder all den informasjonen som trengs om en prosess. CPU-registeret, f.eks., peker etter stack-prosess-tilstand. Om den venter på noe, f.eks. Alle prosesser har en PID. Eier, prioritet, osv.. Det er masse informasjon som må lagres om hver enkelt prosess.", "source": "lecture"}
{"lecture_id": "os6del12", "chunk_id": "os6del12_0002", "start": 133.9, "end": 230.58, "token_count": 289, "text": "om en prosess. CPU-registeret, f.eks., peker etter stack-prosess-tilstand. Om den venter på noe, f.eks. Alle prosesser har en PID. Eier, prioritet, osv.. Det er masse informasjon som må lagres om hver enkelt prosess. Den operasjonen som operativstemme gjør for å bytte om på prosesser, kalles generelt cheduling. CPU-cheduling er å fordele CPU-tid mellom prosessene. Det kalles ofte også timesharing. Om scheduleren skal kalles. For at ting skal gå fortere, så er det ikke alltid at man gjør et bytte. Hvis vi går tilbake her... Hvis P2 er ferdig... Hvis verken P1 eller P3 ønsker å brukes i PU-en, så kan det være at P2 bare fortsetter. For å få kontekstswitch-tiden til å gjøres så raskt som mulig, er det noen ganger man bare sjekker... Ok, ingen andre ønsker å kjøre. Da bare fortsetter P2. Men det er det da. Skeduleren, som er en del av operativsystemet, den avgjør hvilken prosess som skal velges når den blir kalt.", "source": "lecture"}
{"lecture_id": "os6del12", "chunk_id": "os6del12_0003", "start": 212.7, "end": 301.08, "token_count": 284, "text": "er det noen ganger man bare sjekker... Ok, ingen andre ønsker å kjøre. Da bare fortsetter P2. Men det er det da. Skeduleren, som er en del av operativsystemet, den avgjør hvilken prosess som skal velges når den blir kalt. Og dette, som vi har sett, det å switche fra én prosess til en annen... All informasjonen må da først lagres for P1 og så hentes inn for P2. Så dette tar tid, og det er litt overhead å gjøre denne context-switchen. Her ser vi alt som skjer i en context-switch hvis vi tenker oss at prosess 1 kjører, og så switcher vi til prosess 2. Og da vil jo... Prosess én vil jo bruke CPU-en. Og midt inni en operasjon så kan det være at AX er lik fem. Neste institusjon som skal utføres, kan kanskje være at AX skal legges ut i en variabel. Og da er det klart... Verdien på AX, den må da lagres for prosessen. Så det er en ganske komplisert prosess enn contact stetch. Og informasjon som må lagres av prosessen.", "source": "lecture"}
{"lecture_id": "os6del12", "chunk_id": "os6del12_0004", "start": 281.52, "end": 373.48, "token_count": 281, "text": "at AX skal legges ut i en variabel. Og da er det klart... Verdien på AX, den må da lagres for prosessen. Så det er en ganske komplisert prosess enn contact stetch. Og informasjon som må lagres av prosessen. Men all denne informasjonen for prosess 1 lages da i RAM i PCB1. Neste prosess som skjer, er at PCB2 må lastes inn. All informasjon fra PCB2 må da lastes inn i alle områder som beskriver den kjørende prosessen. Operativstemme ordner ikke alt dette her. Sånn som å laste inn alle verdier av institusjoner. Det blir litt vanskelig, for du må jo bruke registrene for å kjøre programmet. Hvis operativstemmen skulle gjøre det, så ville operativstemmen også endre registerverdiene. Så der er det hardwareoperasjoner som kommer inn, som på én smell bare legger inn alle verdiene fra et lager. Så kan man hoppe til neste instruksjon. Et eller annet sted står det lagret PC - program counter. Og det siste som skjer etter at all informasjon er lagt til,", "source": "lecture"}
{"lecture_id": "os6del12", "chunk_id": "os6del12_0005", "start": 346.24, "end": 378.0, "token_count": 100, "text": "Så der er det hardwareoperasjoner som kommer inn, som på én smell bare legger inn alle verdiene fra et lager. Så kan man hoppe til neste instruksjon. Et eller annet sted står det lagret PC - program counter. Og det siste som skjer etter at all informasjon er lagt til, er at da hopper man til programconteren som kjører neste instruksjon.", "source": "lecture"}
{"lecture_id": "linux3del2", "chunk_id": "linux3del2_0000", "start": 0.0, "end": 94.16, "token_count": 283, "text": "Globale variabler. Vi så hvordan vi kunne definere lokale variabler. Sånn som Oslic Linux. Men disse variablene er lokale. Så vi kan lage en lokal variabel til. Altså kalle den local, sånn som det.  Og nå skal jeg gjøre variabelen OS til global. Og det kan jeg gjøre med kommandoen Eksport. Hvis jeg gjør Eksport OS, så vil nå variabelen Dollar OS, den vil være global. Og da må man spørre seg hva betyr global i denne sammenhengen? Jo, det betyr at hvis man fra dette skjellet starter et nytt program, Den vil sendes med til dette programmet. Derav navnet Eksport. Så det ville kanskje vært mer naturlig å kalle det for en eksportvariabel. Men det er litt sånn som... Hvis man fra et hovedprogram gjør et kall til en metode, så må man eksplisitt sende med som parametere de variablene man ønsker at metoden skal bruke. Så det er den samme tankegangen. Vi kan se hvordan det funker. Hvis jeg nå skriver ut OS i dette skjellet,", "source": "lecture"}
{"lecture_id": "linux3del2", "chunk_id": "linux3del2_0001", "start": 67.68, "end": 149.52, "token_count": 284, "text": "Men det er litt sånn som... Hvis man fra et hovedprogram gjør et kall til en metode, så må man eksplisitt sende med som parametere de variablene man ønsker at metoden skal bruke. Så det er den samme tankegangen. Vi kan se hvordan det funker. Hvis jeg nå skriver ut OS i dette skjellet, så kommer det naturligvis ut for den... er jo definert her. Og det samme gjelder lokalt. Men hvis jeg nå starter et nytt skjell... Hvis jeg skriver bæsj inn her, så starter et nytt skjell. Vi kan også se det med PS. Der ser jeg at jeg har det skjellet som jeg kjører i nå. Så starter jeg et nytt shell. Hvis jeg nå skriver PS, så ser vi at da har jeg to bæsjell som står og kjører. Og det nye, det som vises nå, det er 97.75. Og hvis jeg nå prøver å skrive ut den lokale variabelen, som jeg definerte, dollarlook, så ser vi. Her er det ikke noen variabel. Nå har det startet opp et nytt skjell,", "source": "lecture"}
{"lecture_id": "linux3del2", "chunk_id": "linux3del2_0002", "start": 125.6, "end": 225.16, "token_count": 298, "text": "Og det nye, det som vises nå, det er 97.75. Og hvis jeg nå prøver å skrive ut den lokale variabelen, som jeg definerte, dollarlook, så ser vi. Her er det ikke noen variabel. Nå har det startet opp et nytt skjell, og siden den er lokal, så blir den ikke sendt med til skjellet. Derimot, OS, som jeg har eksportert og gjort global, den er fortsatt definert i dette skjellet. Hvis jeg nå går ut igjen av skjellet med Exit, så kan man se at... Hvis jeg tar PS nå, så ser jeg at... Nei, hvilken var det... Det var den her, 97,75. Den prosessen er nå borte, og dermed er vi tilbake i det opprinnelige skjellet. Og her er den lokale variabelen definert, akkurat som den globale. Her er begge to definert. Generelt så kan man liste alle globale... Variabler med eksport... Legg på en mål her, for det er mange variabler. Så da ser vi alt som er deklarert av globale variabler. Og helt til slutt her så ser vi den definisjonen der som vi lagde,", "source": "lecture"}
{"lecture_id": "linux3del2", "chunk_id": "linux3del2_0003", "start": 197.94, "end": 305.76, "token_count": 299, "text": "Her er begge to definert. Generelt så kan man liste alle globale... Variabler med eksport... Legg på en mål her, for det er mange variabler. Så da ser vi alt som er deklarert av globale variabler. Og helt til slutt her så ser vi den definisjonen der som vi lagde, en global OS-variabel. Noen variabler som brukes ofte, og som er definert som... Det globale, det er sånn som Path. Og det er litt av poenget. Man kan sende med disse variablene til kommandoer eller programmer som man starter opp, som trenger en sånn variabel. Et annet eksempel er ClassPath. Nå er ikke det definert her. Men typisk så setter man en ClassPath hvis man skal kjøre Java. Når man starter opp Yawa da, og man har satt glass PAF, så vil den globale variabelen bli sendt med til Yawa, sånn at den kan bruke den. I tillegg så kan man... Jeg viste hvordan man gjorde OS global. Man kan også direkte eksportere en variabel. Det er ganske vanlig å bruke store bokstaver. Så vi kan si noe sånt. Da har jeg lagd direkte en global variabel dollar globe.", "source": "lecture"}
{"lecture_id": "linux3del2", "chunk_id": "linux3del2_0004", "start": 277.68, "end": 328.36, "token_count": 150, "text": "I tillegg så kan man... Jeg viste hvordan man gjorde OS global. Man kan også direkte eksportere en variabel. Det er ganske vanlig å bruke store bokstaver. Så vi kan si noe sånt. Da har jeg lagd direkte en global variabel dollar globe. Så hvis jeg skriver ut den, så... Ja, jeg skal ikke utføre den, men jeg skal skrive den ut. Da ser vi at den variabelen er definert. Det jeg gjorde her oppe, var at jeg skrev dollar globe, og da trodde selv at jeg prøvde å utføre kommandoen globe. Men den kommandoen fins ikke.", "source": "lecture"}
{"lecture_id": "os4del17", "chunk_id": "os4del17_0000", "start": 0.0, "end": 106.24, "token_count": 285, "text": "Vi kan se på... denne, ja. Dette er da et assembly-program som jeg har skrevet. Det er egentlig bare å sette seg ned med en taxidoor og skrive assembly-kode. Den gjør akkurat det samme som den... sum-metoden. Så det jeg prøver å etterligne... Egentlig ikke den. Det er den funk... Sum-funksjonen. Denne. Det jeg gjør nå, er at jeg prøver å skrive et assembly-program som kan erstatte denne funksjonen her. Så skal vi også se at den kan erstatte den funksjonen, sånn at jeg kan kompilere det inn. Og den erstatter da direkte denne funksjonen. Kanskje vi kan gjøre det først? Så kan vi se... Vi kan se veldig kjapt her. Hvis dere ser godt etter, så er dette et program som ligner helt på programmet fra simuleringen. Den eneste forskjellen er at her hadde... Her hadde vi så maks i løkka, så kalte vel kanskje den for R0. Men det er fire registre, akkurat som vi i simuleringen brukte R0, R1, R2, R3 og R4.", "source": "lecture"}
{"lecture_id": "os4del17", "chunk_id": "os4del17_0001", "start": 83.76, "end": 178.96, "token_count": 290, "text": "programmet fra simuleringen. Den eneste forskjellen er at her hadde... Her hadde vi så maks i løkka, så kalte vel kanskje den for R0. Men det er fire registre, akkurat som vi i simuleringen brukte R0, R1, R2, R3 og R4. Så denne skal gjøre den løkka, og så skal den sende resultatet tilbake til main. Vi kan se på hvordan det fungerer i praksis først, sånn at vi vet hvor vi er. Så det jeg skal gjøre nå, er densummain.c. I stedet for å kompilere den sammen med dette C-programmet, så vil jeg nå kompilere den sammen med as.s. Og det kan jeg gjøre på samme måte. Jeg kan si jeg vil ha med Summain. Og så vil jeg sende ut en eksekverbar kode, som er sum. Hvis jeg gjør det, og så kjører den, så ser vi... Ja, vi får tallet seks. Men man er på en måte ikke helt overbevist om at det er denne koden her som kjører. Og da kan vi jo teste det veldig raskt ved å si at det tallet der er en maks.", "source": "lecture"}
{"lecture_id": "os4del17", "chunk_id": "os4del17_0002", "start": 165.52, "end": 249.68, "token_count": 295, "text": "Ja, vi får tallet seks. Men man er på en måte ikke helt overbevist om at det er denne koden her som kjører. Og da kan vi jo teste det veldig raskt ved å si at det tallet der er en maks. Som man sammenligner med. Skal se litt nøyere på koden etterpå. Men jeg kan i hvert fall save den der. Og så prøve å kompilere på nytt. Og så kjøre det. Og da ser vi... Jo, det ser ut til å virke, dette her. Det er den assembly-koden som nå utfører denne løkken her. Og da har jeg hele clouet at... Jeg som programmerer kan nå velge å si at... Nei, jeg stoler ikke på GCC. GCC lager ikke bra nok kode. Jeg vil skrive denne koden i stedet. Og så skriver jeg denne koden, som jeg håper er mer effektiv enn koden som GCC lager. Men fra vårt ståsted så er det viktigste å se hvordan henger dette her sammen? Altså hvordan går man fra Høyre... Sånn her - til maskinkode. Og det vanligvis er det da kompilatoren som gjør den jobben.", "source": "lecture"}
{"lecture_id": "os4del17", "chunk_id": "os4del17_0003", "start": 224.0, "end": 322.42, "token_count": 291, "text": "som jeg håper er mer effektiv enn koden som GCC lager. Men fra vårt ståsted så er det viktigste å se hvordan henger dette her sammen? Altså hvordan går man fra Høyre... Sånn her - til maskinkode. Og det vanligvis er det da kompilatoren som gjør den jobben. Den kompilerer da symfunksjon.c og lager eksekverbar kode. Men i stedet nå så kan vi... Vi kan gjøre sånn også - kompilere as.s, og så lage eksekverbar kode som jeg kan kalle as. Og så kan jeg kompilere den sammen med... SumMain, var det jeg kalte den. Og så kan jeg kalle den Main. Og så kan jeg lime sammen de to bitene, AS og Main, og lagre det som en kjørbar filsum. Og så kan jeg kjøre det igjen. Og da ser vi... Nå er dette på en måte to uavhengige biter. Så jeg kan gå inn her og endre tilbake. Endre den til 3, sånn at summen skal bli 10. Da trenger jeg ikke kompilere sum main på nytt, men jeg må kompilere...", "source": "lecture"}
{"lecture_id": "os4del17", "chunk_id": "os4del17_0004", "start": 303.1, "end": 349.0, "token_count": 182, "text": "Og da ser vi... Nå er dette på en måte to uavhengige biter. Så jeg kan gå inn her og endre tilbake. Endre den til 3, sånn at summen skal bli 10. Da trenger jeg ikke kompilere sum main på nytt, men jeg må kompilere... Assemblykoden. Den må jeg kompilere på nytt, og så må jeg linke den sammen med main. Til en ny eksekuerbar kode. Og så må jeg kjøre den. Så jeg kunne gjort det etter én operasjon, men dette var bare for å illustrere at nå er det denne koden jeg kompilerer, og bare denne. Og det er uavhengig av meg. Og det gjorde jeg ved denne operasjonen.", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0000", "start": 0.0, "end": 99.28, "token_count": 295, "text": "Vi så til sist før pausen at vi trengte MMU. Vi trengte en veldig hurtig hardware bit som oversetter virtuelle adresser. Alle programmer bruker virtuelle adresser. De oversettes da til fysiske adresser. Det kunne vært nyttig å se til også. Hvis vi skulle lagd det her, så betyr det at da... Hvis vi skulle brukt et virtuelt adresserom, så betyr det at de adressene som vi sender ut her på AddressOuts, de er da virtuelle. Så da kunne det være sånn at når vi sender ut adresse nummer 8, så har vi system som sier at OK, egentlig så... Egentlig skal den peke til adresse nummer 108 i fysisk ramme. Og da måtte man her, imellom adresse out og ramme, så måtte man ha en egen enhet. Og det er det som er MMU-en. En egen enhet som da lynraskt oversetter... Akkurat som resten av CPU-en med tilsvarende logikk oversetter denne adressen fra 8 til 108. Det vil måtte være en boks inni her. Denne CPU-en har fysisk adressering, så her kan du ikke bruke virtuelt adresserom.", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0001", "start": 75.24, "end": 169.76, "token_count": 289, "text": "En egen enhet som da lynraskt oversetter... Akkurat som resten av CPU-en med tilsvarende logikk oversetter denne adressen fra 8 til 108. Det vil måtte være en boks inni her. Denne CPU-en har fysisk adressering, så her kan du ikke bruke virtuelt adresserom. Men alle moderne CPU-er bruker et virtuelt adresserom. Så da har man en MMU i denne biten av databussen. Så det er det vi kommer til nå, men først skal vi se på noen andre... Ja, vi ser litt på mer praktisk bruk. Og vi skal se på hvordan vi kan kompilere hva som skjer når vi kompilerer programmer, og lovder dem. For det er jo det som i prinsippet skjer hele tiden. Man har kode som kompileres, og så får vi kjørbar kode.  Og så må det legges inn i interminet og kjøres. Og det er det vi ser på denne sliden her. Så vi starter her oppe med kildekode, og så kompilerer vi. Og det er da typisk når vi har gjort det med C-programmer, så har vi skrevet GCC minus C, og så kode.c.", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0002", "start": 151.72, "end": 231.16, "token_count": 298, "text": "Og så må det legges inn i interminet og kjøres. Og det er det vi ser på denne sliden her. Så vi starter her oppe med kildekode, og så kompilerer vi. Og det er da typisk når vi har gjort det med C-programmer, så har vi skrevet GCC minus C, og så kode.c. Og da har vi ofte lagt på en minus O, og så kalt det noe. RUN, f.eks. Og den røde vil da være maskinkode. Og da har vi gjort den oversettelsen. Kompilatoren har oversatt kildekoden til maskinkode. Og her er det da maskinkode med nulldøgnere. Vi har sett at vi kan se på den maskinkoden ved å be om å få assembly-kode. Men det er da en én-til-én mellom assembly-koden og maskinkoden. Dette er maskinkode som sier nøyaktig hvilke instruksjoner som skal utføres. Men det vi ikke har sett på tidligere, er at inni her så er det relative adresser. Ethvert program sånn som dette her starter med et minnerom fra 0 til 4G. Fra 0 til maks. Og de adressene vil da være relative,", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0003", "start": 207.6, "end": 292.8, "token_count": 292, "text": "Dette er maskinkode som sier nøyaktig hvilke instruksjoner som skal utføres. Men det vi ikke har sett på tidligere, er at inni her så er det relative adresser. Ethvert program sånn som dette her starter med et minnerom fra 0 til 4G. Fra 0 til maks. Og de adressene vil da være relative, for de vil ikke være de fysiske adressene som ligger her ute i rommet. Men så før vi får ferdig maskinkoden som kan kjøres, så har vi sett tidligere at vi har lagt til én linje med linking. Vi kan gjøre hele dette her i en operasjon, men det vi typisk da har gjort, er at vi f.eks. så har vi kompliert to biter. Vi har kompliert én main og én... Vi hadde en sånn sum-funksjon. Den kompilerte vi i to forskjellige programmer. I linkingen så limes de to programmene til ett virkende system. Det som vi ikke så på, var at her i kildekoden så hadde vi f.eks. sånn Include STDIO. Altså for å kunne skrive print. Og det var da et systembibliotek som da linkes inn...", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0004", "start": 270.76, "end": 353.24, "token_count": 292, "text": "I linkingen så limes de to programmene til ett virkende system. Det som vi ikke så på, var at her i kildekoden så hadde vi f.eks. sånn Include STDIO. Altså for å kunne skrive print. Og det var da et systembibliotek som da linkes inn... Da er det kode her fra systembiblioteket for å printe ut. Det linkes sammen med... Maskinkoden som er lagd av kildekoden av programmet. Så alt dette limes sammen til én stor maskinkode. Og så, når programmet skal kjøres, så må det lastes inn i ram. Og det ser vi. Her er denne koden tatt og lastet inn i ram. Og det er en maskinkode som da kan kjøres. CPU-en setter i gang her på adresse 0, og så kjører den nedover. En sinus AX her, og det er typisk et sånt systembibliotek... Man ønsker i kildekoden å regne ut sinus AX, og i stedet for å skrive kode som regner ut det fra scratch, så bruker man et eller annet mattebibliotek som man linker inn herfra. Så kan man kjøre sinus AX. Og det kan man statisk linke inn.", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0005", "start": 332.68, "end": 412.24, "token_count": 289, "text": "Man ønsker i kildekoden å regne ut sinus AX, og i stedet for å skrive kode som regner ut det fra scratch, så bruker man et eller annet mattebibliotek som man linker inn herfra. Så kan man kjøre sinus AX. Og det kan man statisk linke inn. Man kan ta den sinus AX-koden og hive rett inn i maskinkoden. Men også ha såkalt dynamisk bibliotek. Og da vil man ha kode som ikke engang i utgangspunktet lastes inn. Så når man begynner å kjøre denne maskinkoden, så kan det være at man akkurat i dette tilfellet ikke regner ut SinusX. Og da trenger man ikke den koden. Hvis det viser seg når du kjører dette programmet, så ønsker man å regne ut SinusX. Da har man en dynamisk link. Da laster operativsystemet inn dette biblioteket her med maskinkode som regner ut CNS og X og andre funksjoner. Laster inn den, og så hopper koden til riktig sted her. Regner ut CNS og X og returnerer. Og fordelen med dette med å ha et sånt dynamisk bibliotek er at da kan jo", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0006", "start": 387.6, "end": 472.2, "token_count": 286, "text": "Da laster operativsystemet inn dette biblioteket her med maskinkode som regner ut CNS og X og andre funksjoner. Laster inn den, og så hopper koden til riktig sted her. Regner ut CNS og X og returnerer. Og fordelen med dette med å ha et sånt dynamisk bibliotek er at da kan jo flere programmer bruke den samme dynamiske koden. Dette er der shared memory. Vi ser det er program 2. Det ønsker også å regne ut sinus X. Og da, i stedet for at sinus X-koden er kopiert både i maskinkoden her oppe og i program 2, så peker begge til denne del L-en, til dette dynamiske biblioteket. Og på den måten så kan det da regne ut sinus X. Men vi ser med en gang. Vi begynner å se på dette her... Jo, vi skal løfte inn maskinkode inn i ramm. Så begynner vi å tenke sånn... Disse adressene her... Jo, vi kunne jo hatt sånn at... La oss si dette er adresse 1000. Så kunne vi hatt sånn at... Ok, da legger vi til 1000 på alle disse her.", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0007", "start": 450.92, "end": 536.72, "token_count": 286, "text": "Jo, vi skal løfte inn maskinkode inn i ramm. Så begynner vi å tenke sånn... Disse adressene her... Jo, vi kunne jo hatt sånn at... La oss si dette er adresse 1000. Så kunne vi hatt sånn at... Ok, da legger vi til 1000 på alle disse her. Da må alle adressene som er her inne, oversettes. Da må vi legge til 1000. Lime de fast her. Men problemet med det er at da må denne maskinkoden her forever ligge akkurat der. Og den dynamiske her må forever ligge akkurat der. Men hva om vi ønsker å legge inn nye programmer? Jo, da må de legges ut i resten av RAM. Men til slutt går RAM full, og man har ikke plass til flere. Og da må man begynne å ta programmer ut. Og da ville det vært tungvint. Alle programmer til enhver tid skulle vite hvor de lå, og alle måtte vite de fysiske adressene. Og denne oversettelsen her er veldig tungvint og veldig lite dynamisk. Så det man har kommet opp med da, er en metode med virtuelt minne. Hvor alle adressene her...", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0008", "start": 507.6, "end": 592.0, "token_count": 246, "text": "Alle programmer til enhver tid skulle vite hvor de lå, og alle måtte vite de fysiske adressene. Og denne oversettelsen her er veldig tungvint og veldig lite dynamisk. Så det man har kommet opp med da, er en metode med virtuelt minne. Hvor alle adressene her... Etter at det er lagt inn, så har man en tabell som viser hvor alle de forskjellige programmene ligger. Sånn at når det er kode her som spør om ram-adresse 48, så vet det systemet, MMU-en, vet hvor ram-adresse 48 for akkurat denne kodebiten her ligger. Hvilken fysisk adresse det er. Den må alltid kunne oversettes. På denne måten så er det veldig enkelt å flytte programmer inn og ut, for da bare oppdaterer MMU. Pagetabellene blir oppdatert når man flytter programmer inn og ut, og det muliggjør å ha en veldig dynamisk organisering av prosessene som ligger i rammen.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0000", "start": 0.02, "end": 89.0, "token_count": 285, "text": "Det vi avslutter med, var å vise at operativsystemet forenkler. Hardware er fryktelig komplekst. Så én viktig hovedoppgave for operativsystemet er å forenkle grensesnittet fra brukerprogrammer mot Hardware. Men det er en annen oppgave også som er veldig viktig, og det er å... Mellom de forskjellige programmene og mellom de forskjellige brukerne. Det er en annen viktig hovedside. Her er et forsøk på en OUS-definisjon. Det er at et operativsystem er programvarer hvis hensikt er to ting. A. Gi applikasjonsprogrammer og brukere enhetlige, enklere og mer abstrakt adgang til maskinens ressurser. Så det er det vi så på med forrige med beautiful and ugly interface. De som skriver et applikasjonsprogram, skal ikke behøve å ta hensyn til detaljene ned i Hardware. Det fikser operativ systemet. Så det er én viktig del. Men så er det altså del B. Administrere ressurser, slik at prosesser og brukere ikke ødelegger for hverandre.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0001", "start": 70.52, "end": 175.16, "token_count": 298, "text": "De som skriver et applikasjonsprogram, skal ikke behøve å ta hensyn til detaljene ned i Hardware. Det fikser operativ systemet. Så det er én viktig del. Men så er det altså del B. Administrere ressurser, slik at prosesser og brukere ikke ødelegger for hverandre. Hvis en prosess gjør en eller annen jobb og får noe inn i minnet som den skal ta vare på og bruke senere, kan ikke en annen prosess komme inn og skrive over eller ødelegge noe av det den har. Den andre brukeren bruker. En prosess tar over all CPU på maskinen. Det vil også gå dårlig hvis ikke operativstemmen sørger for å fordele CPU-tip. Eller som det står i eksemplene her, et filsystem. Som brukes til å gi alle brukere og prosesser atskilt adgang til å lagre på disken. Da må opplagt ikke de kunne overskrive for hverandre. Prinsippskisse av Linux. Tidligere hadde vi et enkelt grensesnitt, og vi hadde operativsystemkjerne og hardware. Men dette er på en måte en litt mer detaljert skisse, med Linux som eksempel.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0002", "start": 150.0, "end": 248.44, "token_count": 287, "text": "Prinsippskisse av Linux. Tidligere hadde vi et enkelt grensesnitt, og vi hadde operativsystemkjerne og hardware. Men dette er på en måte en litt mer detaljert skisse, med Linux som eksempel. Skal si at det er litt forskjellig fra Windows. I begge tilfeller så har vi en operativsystemkjerne. Og det er... Når jeg sier OS, så tenker jeg ofte på OS-kjernen. Men det er ikke noen sånn helt klare definisjoner der. Hva som hører til OS-kjernen, og hva som ikke hører til OS-kjernen. Grovt sett så kan vi si at operativsystemkjernen er den som kjører i corner mode. Men så kan en da ha systembiblioteker og systemprogrammer som kjører på toppen. Og det er det vi ser litt her. Hvis vi starter nederst, så ser vi at vi har hardware her nede. AMD X86 osv. Hardware kan være veldig forskjellig, men operativsystemkjernen styrer da denne hardwaren. Men så ser vi... Her har vi et systemkaldt grensesnitt. Dette er virkelig da et API... Application Programming Interface.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0003", "start": 222.96, "end": 307.88, "token_count": 290, "text": "Hvis vi starter nederst, så ser vi at vi har hardware her nede. AMD X86 osv. Hardware kan være veldig forskjellig, men operativsystemkjernen styrer da denne hardwaren. Men så ser vi... Her har vi et systemkaldt grensesnitt. Dette er virkelig da et API... Application Programming Interface. Dere er kanskje kjent med API-er fra forskjellige softwareløsninger. Men da er det typisk at du har inn mot en klasse eller en softwarepakke, så har du et gitt antall kall som du kan gjøre. Et helt klart definert grensesnitt. Og nøyaktig det samme er det når det gjelder operativstyrer. Da har man et systemkall-grensesnitt. Så det er bare et begrenset antall systemkall som vanlige programmer kan gjøre for å snakke med operativsystemkjernen. Basert på de systemkallene, og eksempel open-close, dette er om filer, eller ri, det er et annet systemkall, da kan en applikasjon her oppe be systemet om at det leser. En fil fra disken. Da vil ikke applikasjonen styre disken direkte.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0004", "start": 283.04, "end": 384.2, "token_count": 298, "text": "Basert på de systemkallene, og eksempel open-close, dette er om filer, eller ri, det er et annet systemkall, da kan en applikasjon her oppe be systemet om at det leser. En fil fra disken. Da vil ikke applikasjonen styre disken direkte. Den kan bare gjøre systemkall til operativstemkjernen. Dette er helt essensielt når det gjelder operativstemmer. At vi har dette grensesnittet. Men så ser vi også at vi har sånne... Her er et bibliotek, et systembibliotek. Det kan være math.ho. En nettverksoppkobling fra denne applikasjonen til en annen et annet sted. Det er typisk systembiblioteker. I noen tilfeller kan man si at det er en del av operativsystemet, men det er ikke en del av kjernen. Forskjellen er hvis det er et systembibliotek. Hvis det snakker gjennom systemkall til Da er det ikke en del av kjernen. Da er det mer en system, software, som sitter på toppen. Men som mange vil betrakte som en del av operativsystemet. Det er derfor det står... Det er en 19 stiplet linje her.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0005", "start": 353.34, "end": 449.92, "token_count": 293, "text": "Forskjellen er hvis det er et systembibliotek. Hvis det snakker gjennom systemkall til Da er det ikke en del av kjernen. Da er det mer en system, software, som sitter på toppen. Men som mange vil betrakte som en del av operativsystemet. Det er derfor det står... Det er en 19 stiplet linje her. Her står det GNU slash Linux. Og GNU... Det er en liten stiplet linje her. Jeg ser... jeg ser... har ikke skrevet hva Gnu er, men Gnu, det er en sånn rekkurs i forkortelse. Gnus, not Unix. Vanligvis når man opptaler Linux, så sier man bare Linux. Men det egentlig riktige navnet for Linux er GnuLinux. Gnu, det er resten av systemet. Linux er egentlig bare Linux-kjernen. Men hvis du skal styre en maskin, eller ikke minst styre applikasjoner, så trenger du mer enn akkurat kjernen. Så Gnu er alle disse verktøyene sånn som det står her. Compulator f.eks., GCC, som er det aller viktigste. Alle disse verktøyene er da bygd opp på toppen av Linux.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0006", "start": 435.16, "end": 525.16, "token_count": 296, "text": "så trenger du mer enn akkurat kjernen. Så Gnu er alle disse verktøyene sånn som det står her. Compulator f.eks., GCC, som er det aller viktigste. Alle disse verktøyene er da bygd opp på toppen av Linux. Og når du i dagligtallet snakker om et operativsystem, så tenker man ofte på at så tar man også med den biten. Hvis du f.eks. snakker om et vindusoperativsystem, så har du absolutt også med alle disse verktøyene. Også vindusgrensesnittet. Og der er det en stor forskjell. I vindus så er det Gui. Vindusgrensesnittet, grafiske brukerinterface, det er en del av vinduskjernen. Mens vi ser her på Linux, så er all grafikk... Det er brukerprogramvare som sitter på toppen av operativstømkjernen og bare snakker med kjernen gjennom grensesnitt. Vi kommer tilbake til disse tingene, men dette er... Én vesentlig forskjell på Windows og Linux. Men hovedideen som dere må huske å sitte tilbake igjen med i dag, det er operativsystemet kjernen.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0007", "start": 501.94, "end": 587.48, "token_count": 299, "text": "og bare snakker med kjernen gjennom grensesnitt. Vi kommer tilbake til disse tingene, men dette er... Én vesentlig forskjell på Windows og Linux. Men hovedideen som dere må huske å sitte tilbake igjen med i dag, det er operativsystemet kjernen. Det er det helt essensielle av operativsystemet. Det kjører i curl-mode. Det har lov til å gjøre absolutt alt av endringer. Da kan det også gjøre feil og ødelegge systemet, få det til å gå ned osv. Mens resten av apparativsystemet, det snakker med kjernen gjennom et API. Gjennom systemkall. Og da er det opplagt mye sikrere. Det er ikke så lett for en applikasjon her oppe da å få hele systemet til å gå ned. For det får rett og slett ikke lov til å gjøre alt det vil. Da skal vi bruke litt tid på å snakke om et veldig sentralt begrep, nemlig... Hvis man leser diverse operativstemmebøker, som jeg har gjort, så finner man også diverse definisjoner på prosess. Det enkleste er bare at en prosess er et program som kjører.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0008", "start": 562.74, "end": 674.12, "token_count": 289, "text": "Da skal vi bruke litt tid på å snakke om et veldig sentralt begrep, nemlig... Hvis man leser diverse operativstemmebøker, som jeg har gjort, så finner man også diverse definisjoner på prosess. Det enkleste er bare at en prosess er et program som kjører. En annen er arbeidsoppgavene en prosessor gjør på et program. Litt mer spesifikt, men fortsatt relativt enkelt. Det som er litt mer å oppfatte, er at en prosess er delt inn i tre deler. For det første er det et kjørbart program. Men så er det også programmets data, variable filer osv. Men også den konteksten programmet er i. Den tilstanden. For eksempel om... Oi, unnskyld. Om den venter på noe, eller om... Eller om den bruker CPU-en, eller... Hva er det problemet med lynet? Hva slags prioritet den har, hvilke prosessorregistre den bruker, osv. Det er liksom selve tilstanden til prosessoren. Eller høytsvevende definisjon, nemlig et programs ånd eller sjel. Og dette er...", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0009", "start": 638.86, "end": 769.2, "token_count": 299, "text": "Hva er det problemet med lynet? Hva slags prioritet den har, hvilke prosessorregistre den bruker, osv. Det er liksom selve tilstanden til prosessoren. Eller høytsvevende definisjon, nemlig et programs ånd eller sjel. Og dette er... Når jeg så den definisjonen, så prøvde jeg å trekke dette litt lenger. Så det jeg har prøvd å gjøre, er å lage en analogi til hva en prosess er. Og da skal vi se... Da skal jeg dele et annet vindu med dere. Og så skal vi prøve å se på den analogien. Skal vi se hvis jeg klarer å finne igjen det vinduet. Der, ja. Sånn. Her... Her ser vi... Forhåpentlig ser dere også dette her. Program eller kode. Hvis jeg sier at... Jo... Vi har sagt at en prosess er et program som kjører. Men hva med... Hva om programmet eller koden som vi kjører, er DNA? Altså godt å si et menneskes DNA. Hva er da prosessen? Jeg ser Marius har et spørsmål. Jeg kan ta det etterpå. Men kom gjerne med forslag i chatten.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0010", "start": 731.44, "end": 861.74, "token_count": 286, "text": "Men hva med... Hva om programmet eller koden som vi kjører, er DNA? Altså godt å si et menneskes DNA. Hva er da prosessen? Jeg ser Marius har et spørsmål. Jeg kan ta det etterpå. Men kom gjerne med forslag i chatten. Vanligvis har vi altså vanlige programmer som kjører. Det er koden. Og så har vi da prosesser som kjører på en datamaskin. Men hva kan da en prosess være, hvis det er DNA som er koden? Forslag - enzymer, proteiner? Ja, det er godt forslag. Det er ikke nødvendigvis min analogi er helt perfekt, men det tenker jeg kanskje er litt... Det som er problemet med DNA, er at den både er hardware og prosessen i seg selv. Fordi du på en måte... DNA er kode som bestemmer hvordan alt blir. Menneske... Ja... Det kom masse forslag her. Veldig bra. Men det er med programmet. Og mennesket, da tenker jeg mer at det er kanskje... Er litt mer sånn hardware. Blod som pumpes rundt i kroppen. Ja, absolutt. Nervesignaler.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0011", "start": 827.52, "end": 959.0, "token_count": 289, "text": "Menneske... Ja... Det kom masse forslag her. Veldig bra. Men det er med programmet. Og mennesket, da tenker jeg mer at det er kanskje... Er litt mer sånn hardware. Blod som pumpes rundt i kroppen. Ja, absolutt. Nervesignaler. Bevisstheten. Ja, det begynner å nærme dere. Men det er faktisk... Noe helt spesifikt som jeg er ute etter. Men vi har jo sånn som hardware, da. Lurer på hva det er også. Og da tror jeg kanskje kan være med på mennesker, sjel og ånd. Question does not compute. Men hvis jeg prøver å stille spørsmål på en litt annen måte, da. Hvordan... Hvis du ser på deg selv... Eller se på meg, da. Jeg har et DNA. Og det er jo egentlig bare en kjempelang streng med kode. Så den prosessen at mitt DNA kjører... Det DNA-et kjøres. Hva kan det kalles? Eller for din del, at ditt DNA kjøres. Det var masse forslag her. Noen som har flere ideer? Hvordan... Hvordan er det relatert til deg?", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0012", "start": 919.84, "end": 1064.84, "token_count": 299, "text": "Så den prosessen at mitt DNA kjører... Det DNA-et kjøres. Hva kan det kalles? Eller for din del, at ditt DNA kjøres. Det var masse forslag her. Noen som har flere ideer? Hvordan... Hvordan er det relatert til deg? Ja, gener - igjen gener. Det er selve DNA. Så... hjerte, ja, da er du inne på noe. For det er liksom det at... at det utføres. Men hva er selve prosessen? At man lever, ja. Det... Veldig bra. Der Mohammed kom med at man lever. Så det jeg vil si, er at selve prosessen for DNA-et er livet. Altså det som et menneske... Helt fra... Helt fra man blir født til man dør. Med prosesser også. Man har jo... Man har jo sånt som kill eller kontroll C. Det vil jo være drap eller død, ikke sant? Jeg ser chatten her om dette er fag i filosofi. Ja, absolutt. Prosesser skal vi snakke om hele tiden. Og det er veldig viktig at dette er mye mer enn bare et program som kjører. Og det er tanken med denne analogien, at hver gang dere hører ordet prosess,", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0013", "start": 1044.52, "end": 1159.56, "token_count": 263, "text": "Jeg ser chatten her om dette er fag i filosofi. Ja, absolutt. Prosesser skal vi snakke om hele tiden. Og det er veldig viktig at dette er mye mer enn bare et program som kjører. Og det er tanken med denne analogien, at hver gang dere hører ordet prosess, så skal dere da ikke bare tenke på det programmet som kjører, men dere skal tenke på at dette er hele livet for akkurat den koden som kjører. Hva kan hardware være da? Der igjen blir det litt vanskelige organer. Det var bra, var den som foreslo. Men jeg tenker at Hardware også er sånn noe mer enn bare mennesket selv, ikke sant? For det kan jo ha sånn som hus, mat, bygninger osv. Fordi at DNA på en måte opererer... DNA opererer over hele verden. Så...  Control-C er close... Det er jo copy-vinduet sitt. Det er faktisk sant. Men hvis du kjører en Linux-prosess og du skal stoppe den, så hvis du tasser control-C, så blir den drept.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0014", "start": 1133.64, "end": 1244.12, "token_count": 294, "text": " Control-C er close... Det er jo copy-vinduet sitt. Det er faktisk sant. Men hvis du kjører en Linux-prosess og du skal stoppe den, så hvis du tasser control-C, så blir den drept. Men vi har et par andre viktige ting her. Hva med... Eller for å sette det motsatt... Hva kan man si at staten eller lovverket... Hva er det i denne analogen? Analogien. App i OS, ja. Andreas, supert. OS, operativsystemet, det er liksom staten eller lovverket, som da sørger for at prosesser ikke ødelegger for hverandre. For da er det sånn at hvis en av dere går inn i nabohybelen til en annen student, så kan ikke vi bare gå inn der og ta hva som helst. Og akkurat det er det operativsystemet sørger for. Det sørger for at de prosessene som kjører her på jorda, ikke her på jorda... Operativsystemet sørger for at prosessene i en datamaskin ikke ødelegger for hverandre. Og de kontrollerer at de deler på godene sånn som de skal. Og det samme kan man da si om operativsystemet.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0015", "start": 1223.12, "end": 1328.12, "token_count": 299, "text": "Det sørger for at de prosessene som kjører her på jorda, ikke her på jorda... Operativsystemet sørger for at prosessene i en datamaskin ikke ødelegger for hverandre. Og de kontrollerer at de deler på godene sånn som de skal. Og det samme kan man da si om operativsystemet. Det er en slags sånn overordnet sjef. Et politi kunne også kanskje vært. Som overholder lovverket. Politi. Som passer av prosessene, ikke ødelegger for andre. Så kan man også spørre seg om hva med Rut eller administrator? Hvem er dette i den analogien? Brian kommer en gang til med... veldig bra. Sjelden noen sier det så fort. Men det er Gud. Administrator har all makt. Og det er en del. Regjeringen Kongen, ja, det er også litt det samme. Men Gud er kanskje enda bedre. Dere har sikkert opplevd en del Ruth-eller-administratorer som føler seg som Gud. Men i denne analogien så er de det. For de er også en prosess. Det ble en litt omfattende diskusjon når vi skal diskutere om Gud også har DNA osv.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0016", "start": 1307.52, "end": 1394.88, "token_count": 288, "text": "Men Gud er kanskje enda bedre. Dere har sikkert opplevd en del Ruth-eller-administratorer som føler seg som Gud. Men i denne analogien så er de det. For de er også en prosess. Det ble en litt omfattende diskusjon når vi skal diskutere om Gud også har DNA osv. Men det er på en måte en prosess som styrer de andre prosessene. Og en Gud kan jo da bare si OK, denne prosessen her, den gjør så mye galt. Så Rutel-administrator er på en måte en sånn... Er allmektig på toppen og styrer alle prosessene. OK. Jeg vet ikke om denne analogien er helt perfekt. Men det som er viktig med den, er at fra nå av, når dere tenker på en prosess, så må dere ta med alle de bitene som... Denne analogien viser at en prosess omfatter, da. For eksempel så skal vi senere se på hva som... At vi kan... Eller at operativsystemet... For å dele på godene, så driver operativsystemet hele tiden og stopper prosesser. Og hvis du stopper en prosess, så er det...", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0017", "start": 1369.56, "end": 1479.56, "token_count": 298, "text": "Denne analogien viser at en prosess omfatter, da. For eksempel så skal vi senere se på hva som... At vi kan... Eller at operativsystemet... For å dele på godene, så driver operativsystemet hele tiden og stopper prosesser. Og hvis du stopper en prosess, så er det... Det er på en måte et drap, men det er mer sånn at du... Setter hele prosessen på hvile. Men da er det ikke bare å si at nå skal ikke du kjøre mer. Da må du også ta vare på alt det den prosessen hadde. Alle oppkoblinger, alt som ligger i registeret, internminnet. Alt det må lagres. Og på en måte fryses. Og det er mer sånn som... Hvor mennesker fryses ned og tines opp 100 år senere. Det er akkurat det operativsystemet gjør hele tiden. Det fryses ned en prosess i ett hundredels sekund. Men da må alt om prosessen også lagres, nøyaktig som når man skal vekke opp et menneske igjen. Naturlover går under ruteadministrator. Ja, det... Jo, du kan nok si det, men kanskje... Jo, men naturlover er vel litt mer sånn som hvordan hardware virker.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0018", "start": 1444.66, "end": 1541.32, "token_count": 295, "text": "Men da må alt om prosessen også lagres, nøyaktig som når man skal vekke opp et menneske igjen. Naturlover går under ruteadministrator. Ja, det... Jo, du kan nok si det, men kanskje... Jo, men naturlover er vel litt mer sånn som hvordan hardware virker. Altså... For når du har program som skal kjøre på en datamaskin, så er det på en måte gitt av naturlover hvis du gjør den institusjonen. Det skjer det og det. Så det er kanskje litt mer sånn. Men... Ja, det er som sagt, det er ikke alt som klaffer 100 % med denne analogien. Men det som er viktig, er at dere har med det som... Odeta oppsummerer veldig fint at prosessen er livsløpet av programmet. Og absolutt, det er det. For hvis du har et program... Så har det en funksjon som det skal gjøre. La oss si det er et enkelt program som skal regne ut en sum fra 1 til 100. Og da er hele livsløpet til programmet at det starter, og så kjører det nøyaktig sånn som DNA-et tilsier, nemlig at det skal legge sammen alle disse tallene.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0019", "start": 1519.56, "end": 1623.28, "token_count": 285, "text": "Så har det en funksjon som det skal gjøre. La oss si det er et enkelt program som skal regne ut en sum fra 1 til 100. Og da er hele livsløpet til programmet at det starter, og så kjører det nøyaktig sånn som DNA-et tilsier, nemlig at det skal legge sammen alle disse tallene. Det bruker da hardware, det bruker da alle ressursene. Og så gjennom livsløpet til prosessen. Og så utføres nøyaktig det det skal, som beskrevet i DNA-et, eller i koden. Så kommer det fram til et resultat, og så gir det videre til noen andre. Absolutt. Prosessen er hele livsløpet til et program. Men hva med CPU? Spør Floyd her. Jo, det blir mer sånn. CPU er da en del av hardware-et som... Men i denne analogien er det kanskje litt mer sånn at hjernen er CPU-en? Det blir litt komplisert, for DNA er også oppskriften på hjernen. Men så vil kanskje si mer at hjernen er CPU. Vi kan ta med det også. Men... ja. Nå begynner analogien å bli litt vanskelig.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0020", "start": 1579.56, "end": 1697.84, "token_count": 292, "text": "Men i denne analogien er det kanskje litt mer sånn at hjernen er CPU-en? Det blir litt komplisert, for DNA er også oppskriften på hjernen. Men så vil kanskje si mer at hjernen er CPU. Vi kan ta med det også. Men... ja. Nå begynner analogien å bli litt vanskelig. Så den er ikke perfekt, men prøv å huske å ta med dette videre. OK. Da skal jeg... Da stopper vi den analogien. Men husk dette videre. Når vi senere snakker om prosesser. OK. Da skal vi se... Da må jeg dele riktig screen... Sånn. Da ser dere forhåpentligvis eksempler på prosesser. Det er riktig. Ja, flott. Her ser vi utskrift fra topp i Linux. Og det viser da alle de prosessene som står her og kjører. Og hvor lenge de har levd, eller det jeg vil si da, hvor lenge de har kjørt, mye tid de har brukt, mye CPU de bruker osv. Det ser veldig likt ut på Windows. Akkurat det samme med ID-er osv. Så dette er sånt som vi skal se på senere i detalj.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0021", "start": 1676.2, "end": 1766.04, "token_count": 299, "text": "som står her og kjører. Og hvor lenge de har levd, eller det jeg vil si da, hvor lenge de har kjørt, mye tid de har brukt, mye CPU de bruker osv. Det ser veldig likt ut på Windows. Akkurat det samme med ID-er osv. Så dette er sånt som vi skal se på senere i detalj. Et annet prinsipp som er viktig når det gjelder operativsystemer, er abstraksjon og hierarkier. Det er nemlig det at man har bokser på høynivå. Der har man oversikten. Dette kan være hele operativsystemet, kanskje. Så tar man ut en del av operativsystemet som kanskje har med scheduler. Så går man enda lenger ned og ser på detaljene inni her. Dette er ekstremt viktig. Det vet dere fra objektorientert programmering. Man lager moduler som gjør akkurat det man skal. Og så bygger man opp hierarkier av denne type systemer. Ikke mens hardware, som vi skal begynne å se på nå, så er det veldig bygd opp. Om man sier OK, dette er en liten boks som gjør sånn og sånn,", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0022", "start": 1744.38, "end": 1857.34, "token_count": 299, "text": "Man lager moduler som gjør akkurat det man skal. Og så bygger man opp hierarkier av denne type systemer. Ikke mens hardware, som vi skal begynne å se på nå, så er det veldig bygd opp. Om man sier OK, dette er en liten boks som gjør sånn og sånn, så bygger vi et stort hele av masse små bokser. Et Linux-eksempel på hierarki, det er hvis man gjør en kommando sånn som dette. Det er en kommando som bare skriver ut litt tekst som ligger i den filen på skjermen. For å få til det, så gjøres det da en rekke systemcall. Og dette er da systemcall som er API-et til Linux-kjernen. For eksempel så gjør man open, read, close og en mengde andre systemcall. Med kommandoen strace, strace, så hvis man utfører den...  Så får man se alle de systemkallene som gjøres. Her er det listet opp. Kjør en kommando. Read filen. Vi ser det er en rekke systemkall som under huden på... Da har vi en applikasjonsprogram. De snakker med operativsystemet gjennom systemcall når de skal gjøre", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0023", "start": 1821.88, "end": 1932.44, "token_count": 289, "text": "Så får man se alle de systemkallene som gjøres. Her er det listet opp. Kjør en kommando. Read filen. Vi ser det er en rekke systemkall som under huden på... Da har vi en applikasjonsprogram. De snakker med operativsystemet gjennom systemcall når de skal gjøre noe spesifikt med hardware. OK. Da har vi en timinutterstide igjen, så skal vi ta en kort introduksjon til datamaskinarkitektur. Det er det vi skal jobbe med de neste ukene. Da har vi så vidt sett litt på hva operativsystemer og prosesser osv. er. For å kunne forstå det helt i detalj, hvordan operativsystemet virker, så trenger man også å forstå hardware. Man får forstå hvordan CPU og ram fungerer, for å forstå hvordan operativsystemet, Og hardware, det bygger i bunn og grunn på digitalteknikk. Alt i en datamaskin er representert ved nuller og enere. Og det er ganske enkelt representert sånn at null, det er ingen spenning. Og en ener er f.eks. fem volts spenning i forhold til jord.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0024", "start": 1903.24, "end": 2008.8, "token_count": 296, "text": "Og hardware, det bygger i bunn og grunn på digitalteknikk. Alt i en datamaskin er representert ved nuller og enere. Og det er ganske enkelt representert sånn at null, det er ingen spenning. Og en ener er f.eks. fem volts spenning i forhold til jord. Og dermed, med en gang man har nuller og enere, så kan man representere tall med nuller og enere, binære tall. F.eks. så kan du da sette 32-bitt ved siden av hverandre med nuller og enere. Da får man et heltall, en integer, og da kan man representere tall opp til 32. Eller omtrent 4 milliarder. I en datamaskin så er alt tall. Og utgangspunktet er da nuller og enere. Dette er typisk sånn som man har i en standard CPU. At du har null er representert med ingen spenning. Fem volt betyr da her er det spenning. Og det er null. Ja, dere vet sikkert at... eller man sier at alle datamaskiner er drevet binært. Det er riktig, men det er ikke opplagt at man skulle bruke det binære tallsystemet.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0025", "start": 1989.34, "end": 2078.38, "token_count": 297, "text": "Fem volt betyr da her er det spenning. Og det er null. Ja, dere vet sikkert at... eller man sier at alle datamaskiner er drevet binært. Det er riktig, men det er ikke opplagt at man skulle bruke det binære tallsystemet. Det var en del forskjell på å bruke desimale tall. Det kunne man oppnå ved å si at null er null volt. Én volt. Og så representere alt med desimaltall. Men det viser seg at det blir veldig komplisert i praksis å få til. Sånn at etter hvert så har alle datamaskiner benyttet det binære tallsystemet, fordi det er veldig enkelt å skille mellom null og én. Men ut fra binære tall, så kan man representere alt. Sånn som her. 0101 er fem. En ener pluss en firer, det blir en femmer. Så kan man representere bokstaver. F.eks. bokstaven P er bokstaven nummer 80. Da har du bokstaver. Så kan man representere piksler i grafikk. Og fargen til piksler. Dermed har du alt som er en datamaskin.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0026", "start": 2059.7, "end": 2150.16, "token_count": 293, "text": "Så kan man representere bokstaver. F.eks. bokstaven P er bokstaven nummer 80. Da har du bokstaver. Så kan man representere piksler i grafikk. Og fargen til piksler. Dermed har du alt som er en datamaskin. Og alt kan da representeres ved nulleregnere. Datamaskinarkitektur går da ut på å manipulere på disse nullene og enerne, sånn at man får gjort nøyaktig det man ønsker å gjøre. Så alt er tall. Og her ser vi da konkret hvordan et binært tall kan se ut. Og her ser vi sånne ledninger. Og det er ikke tull, det er virkelig ledninger. Du måler spenningsforskjeller i forhold til jord. Hvis det er null her, så betyr det at det er faktisk en null. Og fem volt her, det betyr en ener. Og sånn får vi tallet ti. Det er ener her. To en-toer. Ingen firere og en åtter. Og det blir til sammen tallet ti. Datamaskin trenger man ikke bare å representere tall, man må kunne lagre f.eks. 32-bit.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0027", "start": 2122.44, "end": 2210.02, "token_count": 273, "text": "Og fem volt her, det betyr en ener. Og sånn får vi tallet ti. Det er ener her. To en-toer. Ingen firere og en åtter. Og det blir til sammen tallet ti. Datamaskin trenger man ikke bare å representere tall, man må kunne lagre f.eks. 32-bit. Men man må kunne utføre alle mulige logiske og matematiske operasjoner på samlinger av bit. Som f.eks. addere, subtrahere, multiplisere, dividere, sammenligne, skifte operasjoner og en rekke andre operasjoner. Men disse er faktisk de viktigste. Og de fleste programmer kan man utføre bare ved å... Dette er maskininstruksjoner som vi skal se på i stor detalj. Men hvordan kan man lage én sånn enkel operasjon? Hvordan kan man få til det? Hvordan kan man få til å lage logiske operasjoner rent fysisk? Jo, det kan gjøres med logiske kretser. Bygge de logiske kretsene sånn teoretisk. Tenke seg hvordan bør dette se ut.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0028", "start": 2183.4, "end": 2275.46, "token_count": 293, "text": "Men hvordan kan man lage én sånn enkel operasjon? Hvordan kan man få til det? Hvordan kan man få til å lage logiske operasjoner rent fysisk? Jo, det kan gjøres med logiske kretser. Bygge de logiske kretsene sånn teoretisk. Tenke seg hvordan bør dette se ut. Og etterpå så kan man da bygge de logiske kretsene fysiske som integrerte kretser. Som fysiske integrerte kretser. Logiske kretser, det er kretser som da utfører binær logikk eller binær algebra. kan utføres med såkalte and or not-operasjoner. Så da kan man... Alt man ønsker å få til, kan man få til ved disse operasjonene. Og da gjør man ganske enkelt sånn at man bygger disse tre logiske operatorene i hardware, og dermed så kan man få til hva man vil. Av både addisjon og divisjon og... Alle operasjoner det er mulig å få til. Hvis man setter sammen de riktige logiske operasjonene and or not. På en helt spesiell måte. Man må finne ut nøyaktig hvordan man skal sette det sammen.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0029", "start": 2253.64, "end": 2352.24, "token_count": 289, "text": "i hardware, og dermed så kan man få til hva man vil. Av både addisjon og divisjon og... Alle operasjoner det er mulig å få til. Hvis man setter sammen de riktige logiske operasjonene and or not. På en helt spesiell måte. Man må finne ut nøyaktig hvordan man skal sette det sammen. De fysiske implementasjonene av and or not, av disse operasjonene, det kalles porter. Som er logikken i det. Så må vi se litt på den fysiske utførelsen av de. For i de aller første datamaskinene så brukte man radiorør. Som man brukte for å implementere and-or-not-porter. Men de radiooverrørene har en fysisk størrelse som er... De er store. Så dermed bitte små... Det som i dag er bitte små... Små datamaskiner. Fylte da opp store saler. Det trengte enormt mye plass. Men... Det var en veldig stor oppdagelse i forrige århundre. Kvantemekanikken. Nemlig hvordan verden virker helt nede på mikronivå. På atomnivå. Og denne teknologien, det gjorde...", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0030", "start": 2328.28, "end": 2424.48, "token_count": 285, "text": "Det trengte enormt mye plass. Men... Det var en veldig stor oppdagelse i forrige århundre. Kvantemekanikken. Nemlig hvordan verden virker helt nede på mikronivå. På atomnivå. Og denne teknologien, det gjorde... Da ble det mulig å lage transistoren, som var helt grunnleggende for datamaskinen. Det som var fantastisk med transistoren, var at man kunne lage and or not-porter som var ekstremt små. Sånn at man kan få i dag mange milliarder av dem på en kvadratcentimeter. Det er hele grunnlaget for datamaskinen. Og de er så små at ledningene er sånn... Et hårstrå er 100 000 nanometer. Du kan tenke deg hvor ekstremt små de er. Det man da bruker disse transitionordene til, det er å lage en liten logisk port, sånn som dette her. Dette er AND-porten. Den fungerer sånn at... Du har input A og B, nuller og enere. Så her kommer A inn som en... La oss si det kommer en null inn her, og B er en null.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0031", "start": 2394.48, "end": 2479.84, "token_count": 298, "text": "Det man da bruker disse transitionordene til, det er å lage en liten logisk port, sånn som dette her. Dette er AND-porten. Den fungerer sånn at... Du har input A og B, nuller og enere. Så her kommer A inn som en... La oss si det kommer en null inn her, og B er en null. Og da kommer A prikk B, eller A and B, som de av dere som har diskré matematikk. Dere er kanskje vant til det. Men hvis det kommer to nuller inn, så kommer det en null ut. Og tilsvarende, hvis det kommer null og én eller én og null inn, så kommer det også en null ut. Og det er bare i tilfelle 1-1 kommer inn, så kommer det en ener ut. Dette er da en byggescene, en port. Det tar veldig kjapt. De andre er år, som har en litt annen virkemåte. Og not, som er rett og slett sånn at hvis det kommer en null inn, så kommer det en ener ut. Hvis det kommer en ener inn, så kommer det null ut. Hvis du kobler på en spenning null her, så vil det komme en spenning én ut i den andre enden.", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0032", "start": 2460.08, "end": 2542.12, "token_count": 300, "text": "De andre er år, som har en litt annen virkemåte. Og not, som er rett og slett sånn at hvis det kommer en null inn, så kommer det en ener ut. Hvis det kommer en ener inn, så kommer det null ut. Hvis du kobler på en spenning null her, så vil det komme en spenning én ut i den andre enden. Det som er helt fantastisk, er at bare ved hjelp av de tre portene, så kan man lage en vilkårlig logikk. Og få til alle mulige logiske kretser. Sånn som dette her er eksempel på. Her setter vi sammen en and og en overport. Og så får vi ut et resultat. Og det som vi skal se på i neste uke, er hvordan man generelt kan lage en stor, kompleks sak av sånne and over-porter. Og så kan man f.eks. få til det at man starter med to binære tall. Kanskje 32 bits binære tall, til og med. Og så setter man sammen en masse and over-porter på en sånn måte at... I andre enden kommer det som kommer ut da, er summen av de to tallene. Og det er veldig langt fra opplagt hvordan man kan sette sammen de,", "source": "lecture"}
{"lecture_id": "os1b", "chunk_id": "os1b_0033", "start": 2524.06, "end": 2585.98, "token_count": 232, "text": "Kanskje 32 bits binære tall, til og med. Og så setter man sammen en masse and over-porter på en sånn måte at... I andre enden kommer det som kommer ut da, er summen av de to tallene. Og det er veldig langt fra opplagt hvordan man kan sette sammen de, men ved hjelp av binær logikk, så kan man få til å sette sammen en smørja masse and or and not-porter på en sånn måte at hvis man sender to binære tall inn i denne svære boksen med and or and not-porter, så kommer det alltid ut summen i den andre enden. Og sånn er generelt en datamaskin bygget opp. Og vi skal faktisk i ganske stor detalj bygge opp en virtuell sånn maskin. Eller jeg skal vise dere en sånn bygning som dere skal teste ut. Og så skal vi kjøre programmer på den maskinen for å se helt nøyaktig hvordan den ser ut.", "source": "lecture"}
{"lecture_id": "os12del9", "chunk_id": "os12del9_0000", "start": 0.0, "end": 23.0, "token_count": 78, "text": "Et spørsmål i chatten her... Tessanset funker også hvis det er snakk om prosess på forskjellige CPU-er. Ja, den låser også minnebussen, sånn at da er det ingen andre som heller kan endre på den verdien i ramm. Hvor lokkvariabelen er lagret.", "source": "lecture"}
{"lecture_id": "linux2del3", "chunk_id": "linux2del3_0000", "start": 0.0, "end": 82.72, "token_count": 296, "text": "En liten oppsummering om Linux-selskript. Ja, det er som om vi har sett en samling av kommandolinjer. Han kan også ha if-tester og forlocker osv., men i utgangspunktet skal man bare samle kommandolinjer som man har testet ut der, inn i en tekstinstruktor, og så blir det et skript. Og det er program som utføres linje for linje. Det kompileres ikke. Så det betyr at hvis du har en syntaksfeil et godt stykke ned i skriptet, så vil skriptet kjøre helt til det kommer ned dit, og så vil det feile der nede. Fordeler med det er at det er veldig raskt å lage. Og så er det veldig tett opp mot kommandolinjen, sånn at det løsner til å teste ut det du skal gjøre, og så bare putte inn et skript når det virker. For små oppgaver som skal gjøres, og som ligger tett inntil operativsystemet. Det er mange negative sider også. Det er f.eks. veldig langsomt i forhold til komplisert kode. Vi skal teste litt etter hvert. Det mangler avanserte datastrukturer.", "source": "lecture"}
{"lecture_id": "linux2del3", "chunk_id": "linux2del3_0001", "start": 52.48, "end": 137.6, "token_count": 281, "text": "sånn at det løsner til å teste ut det du skal gjøre, og så bare putte inn et skript når det virker. For små oppgaver som skal gjøres, og som ligger tett inntil operativsystemet. Det er mange negative sider også. Det er f.eks. veldig langsomt i forhold til komplisert kode. Vi skal teste litt etter hvert. Det mangler avanserte datastrukturer. Vi skal se at man kan bruke RI, f.eks. Men det også er litt tungvint. Og litt krypt. Generert er syntaksen til Shellscript ganske kryptisk, og dermed blir scriptene vanskelige å lese for andre. Hvis du har prøvd å se på noen litt større Shellscript, så finner du fort ut det. I tillegg blir det vanskelig å feilsøke å debugge. Det er også generelt et problem. Så det brukes først og fremst for små, enkle oppgaver. Å automatisere oppgaver hvor man skal bruke operativstemme til å utføre et eller annet, så er det veldig enkelt og praktisk å kunne automatisere jobber med Shellscript.", "source": "lecture"}
{"lecture_id": "linux2del3", "chunk_id": "linux2del3_0002", "start": 110.72, "end": 187.76, "token_count": 279, "text": "å debugge. Det er også generelt et problem. Så det brukes først og fremst for små, enkle oppgaver. Å automatisere oppgaver hvor man skal bruke operativstemme til å utføre et eller annet, så er det veldig enkelt og praktisk å kunne automatisere jobber med Shellscript. En meget nyttig måte å teste ut bæsjscript på, er å bruke minus-x-parameteren. Da kjører du et script sånn som dette her. I tilfelle heter det mitt script. Da legger man på minus X som opsjon. Og da får man se hva som skjer, hvordan hver eneste linje i skriptet utføres. Og spesielt hvis noe går galt i skriptet, så du får bare en eller annen sær feilmelding, så kan det være veldig nyttig å legge på den minus X, og så kjøre det på den måten der. I stedet for å kjøre det med frikslash minus skript, så kjører du med bæsj minus X, Da ser du nøyaktig hva som skjer i hver linje i koden når den kjøres.", "source": "lecture"}
{"lecture_id": "os12del12", "chunk_id": "os12del12_0000", "start": 0.0, "end": 135.44, "token_count": 289, "text": "Hvis vi tenker oss at dette er CPU1... Og så har vi... skal vi se... sånn... En buss som går opp til Ramm her oppe. Her er Ramm. Og det som skjer hele tiden, er at her oppe i Ramm så har vi en adresse hvor vi har en variabel som heter'svar'. Og la oss si'svar nå er kanskje 10'. Så... Vi kan ta det første eksempelet først. Hvor vi bare har én institusjon her, som heter INK-L. INK-lung. Svar av... prosent. Altså det er én institusjon som øker den verdien. Da er det opplagt ikke noe problem hvis denne her kjører helt alene. Da vil vanligvis bare hente... I én institusjon så øker den da verdien. Men på en eller annen måte... Den kan ikke... Den må på en eller annen måte hente inn verdien her. Så verdien vil gå... På databussen, ned hit... Det er da en del av hele denne maskininstitusjonen INK med svar. Den henter inn verdien, øker med én, og legger den tilbake. I én enkeltoperasjon.", "source": "lecture"}
{"lecture_id": "os12del12", "chunk_id": "os12del12_0001", "start": 120.0, "end": 234.36, "token_count": 295, "text": "På databussen, ned hit... Det er da en del av hele denne maskininstitusjonen INK med svar. Den henter inn verdien, øker med én, og legger den tilbake. I én enkeltoperasjon. Men da er det klart, da kan vi ha problemer her hvis... CPU2, den også... gjør den samme operasjonen. Og så er jo begge de to koblet på... Dette er buss. De er koblet på den samme bussen. Og de snakker med hverandre om og henter inn verdier. Men da er problemet hvis disse to CPU-ene ikke er koordinerte. De vil da operere samtidig. Og hvis verdien her oppe er 10, så vil begge de to hente ned verdien 10. Og den verdien vil da lagres i et register her nede. Vi lagrer det ikke eksplisitt i registeret. Den maskininstruksjonen som gjør dette, den må lagre et register, og så må de sende verdien inn i aluen osv. Den må i hvert fall kanalisere den tieren der inn i aluen, sånn at aluen øker den med én. Og så må den sende 11 tilbake.", "source": "lecture"}
{"lecture_id": "os12del12", "chunk_id": "os12del12_0002", "start": 214.88, "end": 311.8, "token_count": 294, "text": "den må lagre et register, og så må de sende verdien inn i aluen osv. Den må i hvert fall kanalisere den tieren der inn i aluen, sånn at aluen øker den med én. Og så må den sende 11 tilbake. Men da er det klart... Da får vi allerede et problem hvis de gjør dette her. Helt samtidig. Ber om den tieren. Da kommer det en tier kjørende ned der. Disse bitene sendes over bussen. En tier inn her og en tier inn der. Og så øker begge... Øker den til 11 med alu. Og så sender begge 11 tilbake. Her går det... Dette går ikke bra fordi at... Uansett hvilken som da kommer først tilbake... Uansett så vil 11 lagres her oppe. Og det som skulle ha skjedd, det er at 12 skulle ha blitt lagret. Fordi begge har lagt til. Og det er da... Det er da vi kommer inn med den smarte tingen at vi legger på Lokk... Det skulle stå lokk. Jeg vil legge på en lokk foran. Foran institusjonen. Og det som skjer da, er at da...", "source": "lecture"}
{"lecture_id": "os12del12", "chunk_id": "os12del12_0003", "start": 290.7, "end": 380.8, "token_count": 291, "text": "Fordi begge har lagt til. Og det er da... Det er da vi kommer inn med den smarte tingen at vi legger på Lokk... Det skulle stå lokk. Jeg vil legge på en lokk foran. Foran institusjonen. Og det som skjer da, er at da... La oss si den CPU1 gjør dette her først. Den lokker da hele databussen. Nå får ingen andre lov til å... endre på den variabelen. Det ville jo ikke gjelde. Men man sjekker at den ene variabelen der... Her skal ingen andre kunne... Den skal ingen andre kunne endre. Og det som skjer da, er at da får CPU1 i fred og ro utføre sin alun, øker fra 10 til 11, sender den tilbake på bussen, og denne her går opp til 11. Og så, i neste omgang, når den... Når den er ferdig med den ene institusjonen, så får CPU2 utføre sin institusjon. Den hadde kanskje prøvd å gjøre det samtidig, men så fant den ut at nei, databussen var lokket. Den var låst, så da måtte den vente litt. Og da begynner CPU2 på sin operasjon.", "source": "lecture"}
{"lecture_id": "os12del12", "chunk_id": "os12del12_0004", "start": 363.36, "end": 396.96, "token_count": 134, "text": "så får CPU2 utføre sin institusjon. Den hadde kanskje prøvd å gjøre det samtidig, men så fant den ut at nei, databussen var lokket. Den var låst, så da måtte den vente litt. Og da begynner CPU2 på sin operasjon. Og den vil da, istedenfor å hente inn 10, så vil den hente inn 11. Og den får da resultatet 12, og så sendes det tilbake. Og så ble det tolv her. Og alt ble riktig. Så det går fint med...", "source": "lecture"}
{"lecture_id": "linux7del18", "chunk_id": "linux7del18_0000", "start": 0.0, "end": 172.34, "token_count": 294, "text": "Neste step er da attaching og executing. Altså hvordan man... Sette opp en container som står og kjører i bakgrunnen. Og hvordan man kan gå inn på den og endre den. Så det vi kan... Det vi kan prøve å få til, er å gjøre det tilsvarende med en ubundte server. Da er det et par måter å koble seg til konteinere som står og kjører på. En er attach og en annen er execute. Da er vi egentlig rett over på neste... på del fem. Del fem er vel den vi hadde tenkt å... Det er det vi hadde tenkt å få til i dag. Ja. Vi kan også prøve å installere Ubuntet, som vi er litt mer kjent med. Hvordan vi kan starte opp Ubuntu og koble oss inn og ut. Da skal jeg først... stoppe EngineX. Jeg bare tok kontroll-C, så stoppet den. Hvis jeg nå prøver å laste websiden, så vil den være borte. For vi kan prøve å... Så kan jeg prøve å starte en... ubundne konteinere. Minus D. Den betyr... Legg den i bakgrunnen. Jeg tar minus IT også. Som et skjell.", "source": "lecture"}
{"lecture_id": "linux7del18", "chunk_id": "linux7del18_0001", "start": 106.24, "end": 286.74, "token_count": 288, "text": "Hvis jeg nå prøver å laste websiden, så vil den være borte. For vi kan prøve å... Så kan jeg prøve å starte en... ubundne konteinere. Minus D. Den betyr... Legg den i bakgrunnen. Jeg tar minus IT også. Som et skjell. Og starte den opp. Men vi ser nå at jeg hadde opsjonen minus D, så nå er jeg fortsatt i Linux-VM. Da må jeg prøve å liste containere. Da ser vi Dock in container PS. En konteiner som står og kjører. Men så må vi prøve å klare å koble oss til den konteineren. Vi setter PS minus A, så ser vi. Da får jeg opp alle. Den eneste som har satt oss opp, det er den siste... Én måte å koble seg til en konteiner på, det er å bruke Execute. Exec-it. Lage en kobling, og så skal vi se. Den konteineren vi kjører, den har den i den der. Bruker den konteineren i den. Da ser vi. Nå er jeg inne i Ubuntu-konteineren. Her kan jeg gjøre hva jeg vil. Og hvis jeg nå ønsker å...", "source": "lecture"}
{"lecture_id": "linux7del18", "chunk_id": "linux7del18_0002", "start": 250.04, "end": 388.02, "token_count": 284, "text": "Exec-it. Lage en kobling, og så skal vi se. Den konteineren vi kjører, den har den i den der. Bruker den konteineren i den. Da ser vi. Nå er jeg inne i Ubuntu-konteineren. Her kan jeg gjøre hva jeg vil. Og hvis jeg nå ønsker å... Lage en webserver av denne konteineren, så kan jeg... Det fungerer. For å installere Apache 2 nå, så er det akkurat sånn som man kan gjøre i Linux-VM. Jeg installerer Appgetinstallapache2. Eller som jeg gjorde det nå, Appinstallapache2. Ja. Det som skjer nå, er at dette gjøres lokalt i imaget. Imaget vil nå endre seg. Hvis du lister størrelsen på imaget, så vil du se at dette er litt større enn det originale buntimaget som vi la. Det er ikke så rart, for alt jeg gjør nå, vil gjøre at dette imaget blir forskjellig fra... Da trenger det litt mer plass på å... Det trenger litt mer plass for å lagre all den informasjonen. I det tilfellet her så starter ikke Apache med en gang, men man kan ta...", "source": "lecture"}
{"lecture_id": "linux7del18", "chunk_id": "linux7del18_0003", "start": 345.98, "end": 478.96, "token_count": 292, "text": "så vil du se at dette er litt større enn det originale buntimaget som vi la. Det er ikke så rart, for alt jeg gjør nå, vil gjøre at dette imaget blir forskjellig fra... Da trenger det litt mer plass på å... Det trenger litt mer plass for å lagre all den informasjonen. I det tilfellet her så starter ikke Apache med en gang, men man kan ta... Apache 2, og så start. Gjør jeg det, så vil jeg nå starte en Apache webserie. Og da... Så ser jeg at i den dokkeinstansen her nå, så kjører jeg Apache. Så er det en måte... Hvis jeg tar... Exit nå, så vil... Så vil hele containeren stoppe. Men det man kan gjøre, er å ta kommandosekvensen kontroll P, kontroll Q. Jeg gjør nå kontroll P, kontroll Q, mens jeg holder kontroll inne. Da ser vi jeg går ut og... Ut av containeren igjen. Konteineren med Ubunter på, den står fortsatt og kjører. Men... Så nå kjører det en konteiner... Nei. Nå kjører det en BEPS-server på port 80 inni denne konteineren.", "source": "lecture"}
{"lecture_id": "linux7del18", "chunk_id": "linux7del18_0004", "start": 441.84, "end": 502.48, "token_count": 119, "text": "Da ser vi jeg går ut og... Ut av containeren igjen. Konteineren med Ubunter på, den står fortsatt og kjører. Men... Så nå kjører det en konteiner... Nei. Nå kjører det en BEPS-server på port 80 inni denne konteineren. Det første jeg skulle starte, var å lage en port forwarding, som jeg gjorde på den andre containeren. Da er det mulig jeg må starte den opp på nytt for å få til port.", "source": "lecture"}
{"lecture_id": "linux7del13", "chunk_id": "linux7del13_0000", "start": 0.0, "end": 170.74, "token_count": 293, "text": "Så kan vi beskrive en melding. Vi kjører den, så ser vi. Den finner ikke Alpine lokalt, altså imaget. Og laster ned. Og så kjører det, og så kommer det fra alpine her. Hvis jeg gjør det en gang til, så går det mye fortere. Det kommer fra alpine med en gang. Så kan jeg ta igjen og liste... Liste images. Ja, det var litt rart. Det hadde jeg forventet å ligge noen... Vi kan liste konteinere. Konteiner... LS. Og da ser vi... Jeg kan prøve å holde det i den formen, sånn at dere ser. Vi lister en konteiner. Det første som står, er ID-en. Det er på en måte også navnet til konteineren. Og så ser vi image. Det er de tre imagene vi har lastet ned. Status på alle sammen er... exit, altså at vi har kjørt dem ferdig. Ja, det er vel stort sett det vi trenger for å kjøre containere. Etter hvert skal vi se hvordan man... Hvordan man kobler seg til konteinere som kjører. Det vi har gjort nå hele tiden, er å... Vi har startet konteinere,", "source": "lecture"}
{"lecture_id": "linux7del13", "chunk_id": "linux7del13_0001", "start": 126.08, "end": 186.0, "token_count": 146, "text": "Status på alle sammen er... exit, altså at vi har kjørt dem ferdig. Ja, det er vel stort sett det vi trenger for å kjøre containere. Etter hvert skal vi se hvordan man... Hvordan man kobler seg til konteinere som kjører. Det vi har gjort nå hele tiden, er å... Vi har startet konteinere, og så har vi stoppet igjen. Da ligger imaget der fortsatt, men konteineren selv er stoppet. Det er akkurat som om man starter en prosess og kjører. Det er ikke verre. Det er bare en kill på den.", "source": "lecture"}
{"lecture_id": "linux3del11", "chunk_id": "linux3del11_0000", "start": 0.0, "end": 102.68, "token_count": 288, "text": "Vi skal nå se på et eksempel hvor vi bruker Source til å kjøre et skript. Og da fungerer det litt annerledes enn hva som er default når man kjører skript. Først skal jeg lage et lite skript. En måte å gjøre det på, er å catte rett til skriptet. La oss si jeg kaller det skriptet change, for det skal skifte... Jeg skal skifte mappe. Så jeg kan skrive skriftet sånn. Det jeg skal gjøre, er å gå til user bind. Så skal jeg skrive et p-dor til det. Når man skriver et skrift på denne måten her, så kan man taste kontroll-d. Da skrives alt til filen. Sånn. Da har jeg et lite skritt. Så kan jeg endre filmodus på det også. Sånn at det kan kjøres. Ja... Nei, nå kjører Change. Så vil man jo skifte sted man står, til Usebin. Men hvis jeg tar Peder over til det, så ser vi at nei, det er ikke tilfellet. Det er tilsvarende som vi har sett på i oppgaver tidligere.", "source": "lecture"}
{"lecture_id": "linux3del11", "chunk_id": "linux3del11_0001", "start": 74.02, "end": 163.12, "token_count": 289, "text": "Ja... Nei, nå kjører Change. Så vil man jo skifte sted man står, til Usebin. Men hvis jeg tar Peder over til det, så ser vi at nei, det er ikke tilfellet. Det er tilsvarende som vi har sett på i oppgaver tidligere. Det som egentlig skjer når man kjører et script sånn som det her, er at det startes opp et nytt skjell, og inni det skjellet så skifter man posisjon. Og så tar man Peder over til det, og da får man ut denne utskriften. Men etter det er ferdig, så skjer det en exit. Man avslutter skjellet og går ut av det. Og alt som er gjort inni det skjellet, er da glemt. Det kan minne litt om hva som skjer hvis man kjører skritter sånn. Da ser man at eksplosivt så starter da bindbæsj. Man kan gjøre veldig eksplosivt sånn. Et nytt skjell som kjører det som står inn i change. Og det som står inn i change, er dette her. CDUCB. Pad over til det, da kommer den ut.", "source": "lecture"}
{"lecture_id": "linux3del11", "chunk_id": "linux3del11_0002", "start": 139.8, "end": 233.68, "token_count": 289, "text": "Da ser man at eksplosivt så starter da bindbæsj. Man kan gjøre veldig eksplosivt sånn. Et nytt skjell som kjører det som står inn i change. Og det som står inn i change, er dette her. CDUCB. Pad over til det, da kommer den ut. Hvis jeg nå gjør PAD over til det, så er jeg fortsatt der jeg var. Og da finnes det en egen kommando, source, som gjør dette på en annen måte. Så hvis jeg bruker kommandoen source til å kjøre change, Det betyr ta alle kommandoene i Script to Change og kjør de rett ut i skjellet her, direkte. Det blir sånn. Og da ser vi. Da skifter jeg også posisjonen her i dette skjellet. Så det å gjøre Sort Change, det er omtrent det samme som å bare ta copy og paste av alle linjene. Og da ser vi... Da endres mappen, sånn at jeg kommer dit jeg skal. En helt lik måte å gjøre dette på er å sette en prikk foran. Det er den korte versjonen. Hvis jeg tar prikk-change, så skjer det samme.", "source": "lecture"}
{"lecture_id": "linux3del11", "chunk_id": "linux3del11_0003", "start": 206.36, "end": 241.24, "token_count": 99, "text": "å bare ta copy og paste av alle linjene. Og da ser vi... Da endres mappen, sånn at jeg kommer dit jeg skal. En helt lik måte å gjøre dette på er å sette en prikk foran. Det er den korte versjonen. Hvis jeg tar prikk-change, så skjer det samme. Det betyr også bare 'paste alle kommandoene ut i dette skjellet'. Takk.", "source": "lecture"}
{"lecture_id": "linux5del4", "chunk_id": "linux5del4_0000", "start": 0.0, "end": 89.8, "token_count": 298, "text": "SED er en enkel, liten kommando som kan brukes til å bytte ut forekomster av ord. F.eks. hvis jeg skriver en linje 'ekko, test og test' på denne måten her. Og så ønsker jeg å bytte ut ordet 'test' med... la oss si 'fisk'. Da kan jeg starte med deg. Da er syntaksen på denne måten. At man har tre slasher sånn, og så er det man ønsker å bytte ut. Test kommer først, så det man ønsker å bytte til. Fisk kommer etterpå. Da ser vi at det er bare den første testen, det første ordet, som nå blir byttet ut med fisk. For å få til litt forskjellige effekter kan man se manualsidene for SED delt på nettet. Her legger man på en G. Det er da en opsjon. Som betyr globalt, og det betyr bytt ut alle forekomster av test. Og dermed ser vi at det blir fisk og fisk. Sånn at den andre forekomsten også blir byttet ut. Ja, nå over til SORT, som er en annen og kanskje enda nyttigere kommando, som kan brukes til å sortere filer, linje for linje.", "source": "lecture"}
{"lecture_id": "linux5del4", "chunk_id": "linux5del4_0001", "start": 65.08, "end": 164.88, "token_count": 298, "text": "Og dermed ser vi at det blir fisk og fisk. Sånn at den andre forekomsten også blir byttet ut. Ja, nå over til SORT, som er en annen og kanskje enda nyttigere kommando, som kan brukes til å sortere filer, linje for linje. Og da har jeg en liten eksempelfil her med oversikt over eiere av forskjellige biler til forskjellige priser. Så jeg skal prøve å sortere denne filen. Og først skal vi se hvordan Sort fungerer default. Sort biler. Den vil da sortere alfabetisk på første... På første ord i linjen. Den starter av på første ord, og sorterer hvis første ord er likt, så går den videre til neste osv. Og da ser vi at da blir det sortert på H foran K foran S. Alfabetisk sortering. Så kan man plukke ut den kolonnen man ønsker å sortere på. Hvis jeg i stedet ønsker å sortere på linje 2, så kan jeg ta sort minus 2. Og da vil jeg sortere på bilnavn. Og da ser vi... Da kommer Berlingo før BMW. Det er BE. Og elbil kommer til sist.", "source": "lecture"}
{"lecture_id": "linux5del4", "chunk_id": "linux5del4_0002", "start": 138.8, "end": 224.12, "token_count": 287, "text": "Så kan man plukke ut den kolonnen man ønsker å sortere på. Hvis jeg i stedet ønsker å sortere på linje 2, så kan jeg ta sort minus 2. Og da vil jeg sortere på bilnavn. Og da ser vi... Da kommer Berlingo før BMW. Det er BE. Og elbil kommer til sist. Så kan jeg tenke... OK, nå ønsker jeg å sortere på prisen til slutt. Da kan jeg sortere på kolonne 3. Men da ser det litt rart ut, for 150 000 kommer foran 500 000. Så det ser ikke sortert ut. Og det er fordi den sorterer da ikke numerisk, men på første siffer. Altså én kommer foran fem som kommer foran ni. For å få til å sortere numerisk, så må man legge på en opsjon minus N. Hvis jeg da sorterer numerisk, så ser vi at 90 000 kommer foran 150 000 foran 500 000. Man kan også sortere den andre veien. Default er at At minst kommer først, akkurat som alfabetisk. Men man kan legge på en R for reverse, og så får man da største tall først.", "source": "lecture"}
{"lecture_id": "linux5del4", "chunk_id": "linux5del4_0003", "start": 198.44, "end": 251.12, "token_count": 152, "text": "Hvis jeg da sorterer numerisk, så ser vi at 90 000 kommer foran 150 000 foran 500 000. Man kan også sortere den andre veien. Default er at At minst kommer først, akkurat som alfabetisk. Men man kan legge på en R for reverse, og så får man da største tall først. Så den siste kommandoen betyr da å sortere kolonne tre nummerisk og reverse, sånn at den største kommer først. Og så kan man, hvis man ønsker å få dette ut i en fil i stedet, så kan man skrive det til sortert på den måten.", "source": "lecture"}
{"lecture_id": "linux7del3", "chunk_id": "linux7del3_0000", "start": 0.0, "end": 67.0, "token_count": 176, "text": "Ja. Her ser vi et bilde av noe som ser ut som ekte containere. Og en del av... Eller kanskje den viktigste ideen er at det er avhengighet eller dependencies, som det står på disse slidene. F.eks. så vil det generelt være vanskelig å ta et programsystem og kjøre på en... Hvis du går fra Linux-servere til Windows-servere, så er det umulig. Men det er også vanskelig å gjøre det fra å gå fra Red Hat til Ubuntu f.eks. Men det fine med dere er at hele den biten der kan enkelt testes ut ved at man kjører containere. Start opp en Ubuntu-konteiner og en RedDat-konteiner, og så kan man teste ut og kjøre koden.", "source": "lecture"}
{"lecture_id": "os13del10", "chunk_id": "os13del10_0000", "start": 0.0, "end": 119.68, "token_count": 295, "text": "Vi snakket om ramme og registre for å lagre adresser før pause. Og det var et godt spørsmål om å presisere disse registrene. Og da tenker jeg vi kan gå tilbake til det bildet... Det bildet viser her nede hvordan ram er koblet til CPU-en. Dette utgjør totalt sett adressebussen. I vår veldig enkle CPU så hadde vi registeret med fire bit. Men dette er det samme om du har la oss si 64 bit. Med 64 sånne koblinger mellom CPU-en. Datapath er en del av CPU-en, mens RAM er det vi snakker om nå - internmine. Og da ser vi uansett hvordan vi... Når vi skal snakke med RAM, så må vi spesifisere adressen. Og her er det fire bit som spesifiserer adressen. ... register inn i bussen på adresselinjene. Og hvis man da kobler rn, hvor det står tallet 1, inn i 'adresse out', så betyr det skriv til byte nummer 1 i ram. Står det 80 rn, så skriver man til byte nummer 8, osv. Så på den måten så trenger man både et register som kobler til adressen,", "source": "lecture"}
{"lecture_id": "os13del10", "chunk_id": "os13del10_0001", "start": 97.28, "end": 195.46, "token_count": 296, "text": "Og hvis man da kobler rn, hvor det står tallet 1, inn i 'adresse out', så betyr det skriv til byte nummer 1 i ram. Står det 80 rn, så skriver man til byte nummer 8, osv. Så på den måten så trenger man både et register som kobler til adressen, Ett som kobles til dataene. Og de trenger ikke nødvendigvis være like store. 64-bit kan være litt overkill på rammeadresse fordi ramme ikke er så stort. Så da kan man f.eks. velge å bruke et 48-bitsregister til akkurat disse adressene, og så kan man sende 64-bits... Med data. Altså man sender det registeret. Så hvis man skal... Hvis man f.eks. skal sende tallet 8 til adresse 4, da... Så på denne CPU-en her, så må du da ha ett register med tallet 8. Og så må det kobles til Data Out. Og så må du ha et annet register. Med tallet 4 kobles det til AdresseOut. Og så trykker du på skriveknappen, og så skrives det til Ramm. Så alle tall som kommer fra CPU-en på en eller annen måte,", "source": "lecture"}
{"lecture_id": "os13del10", "chunk_id": "os13del10_0002", "start": 176.72, "end": 213.5, "token_count": 138, "text": "Og så må det kobles til Data Out. Og så må du ha et annet register. Med tallet 4 kobles det til AdresseOut. Og så trykker du på skriveknappen, og så skrives det til Ramm. Så alle tall som kommer fra CPU-en på en eller annen måte, det må lagres i registeret. Og når vi skulle programmere dette, så måtte vi f.eks. skrive kode som inneholdt tallet 3, og så la vi det et register. Og så pekte det på en adresse. Så sånn fungerte det hele veien.", "source": "lecture"}
{"lecture_id": "os14del10", "chunk_id": "os14del10_0000", "start": 0.0, "end": 94.2, "token_count": 281, "text": "Og vi skal se på noe som virker ganske rart i utgangspunktet. Jeg starter ut med et lite og enkelt program. Det eneste som ikke er så enkelt, er at det er veldig mange nuller her. Skulle kanskje brukt den definerte med ganger og så videre. Sånn som vi gjorde i det andre programmet. Men hvis jeg holder på de nullene her... Så ser vi at her er det... Bortsett fra 24 først her, så er det ni nuller. Så det er 1024 millioner. Så dette er da én milliard eller én giga. Så det jeg prøver å definere her nå, er et... Eller det jeg definerer her, er et... Og så ser vi at jeg har en enkel, liten forløkke. Den er enkel, og den går ikke helt opp, men den går til 10 millioner. Så vi ser at jeg bruker da en hundredel av det store r-øyet. Eller går opp til en hundredel. Så ser vi. Dette ser litt rart ut foreløpig, men... Bare tenk på det som en institusjon som vi ikke bruker.", "source": "lecture"}
{"lecture_id": "os14del10", "chunk_id": "os14del10_0001", "start": 70.08, "end": 160.8, "token_count": 275, "text": "men den går til 10 millioner. Så vi ser at jeg bruker da en hundredel av det store r-øyet. Eller går opp til en hundredel. Så ser vi. Dette ser litt rart ut foreløpig, men... Bare tenk på det som en institusjon som vi ikke bruker. Vi setter J lik I ganger 100. Så den J-en går helt opp til maks her oppe. Men i første omgang, det jeg gjør, er at jeg setter nå hvert Ri lik I. Så jeg begynner med Ri av 0 og setter ned lik 0, Ri av 1 lik 1, Ri av 2 lik 2 osv. oppover. Og det er jo... Ja. Hva som skjer når man bruker ramm. Hvis vi gjorde sånn som vi gjorde før pause... At vi så på topp osv., så ville vi da sett at etter hvert som man brukte det jeg er i, så ville det komme inn i ress osv. Men nå skal jeg bare kompilere programmet. Det heter MDC. Og så ta tiden på... Og vi ser, til tross for at det skriver til... Hva er det...", "source": "lecture"}
{"lecture_id": "os14del10", "chunk_id": "os14del10_0002", "start": 127.3, "end": 217.2, "token_count": 275, "text": "At vi så på topp osv., så ville vi da sett at etter hvert som man brukte det jeg er i, så ville det komme inn i ress osv. Men nå skal jeg bare kompilere programmet. Det heter MDC. Og så ta tiden på... Og vi ser, til tross for at det skriver til... Hva er det... 1 million RI-elementer? Nei, 10 millioner. Så går det på 0,02 sekunder. Selv om vi sier ram er tregt, så går det veldig fort. Mye raskere enn til disk. Og det er bare det at registeret er enda raskere. Ekstremt rask. Men i hvert fall... Dette går fort. Så skal jeg gjøre det som er litt spesielt. Nå skal jeg endre I til J her. Det er den eneste endringen jeg gjør. Jeg setter... Byttet nå I ut med J. Det vil si at jeg gjør akkurat like mange instruksjoner. For det er ti millioner ganger som jeg løper gjennom her. Så eneste forskjellen er at det første jeg gjør, er RA0 lik 0.", "source": "lecture"}
{"lecture_id": "os14del10", "chunk_id": "os14del10_0003", "start": 197.8, "end": 302.76, "token_count": 299, "text": "Byttet nå I ut med J. Det vil si at jeg gjør akkurat like mange instruksjoner. For det er ti millioner ganger som jeg løper gjennom her. Så eneste forskjellen er at det første jeg gjør, er RA0 lik 0. Og så det neste jeg gjør, er RA av... Når I er lik 1, så vil J bli 100. Så neste institusjon er RA100 lik 1. Og så RA200 lik 2 osv. Men jeg gjør dette da ti millioner ganger. Så i utgangspunktet... I hvert fall hvis ram var ram, så burde dette ta... Akkurat like lang tid. Men vi ser dette tar enormt mye lengre tid. Det tar 1,5 sekunder i stedet for 0,19. Altså... Dette er faktisk nesten en faktor 100. Så hvordan kan det ha seg? Og at det kan skyldes... veldig stor forskjell i effektivitet. Vi gjør det samme antall institusjoner. Ti millioner ganger så skriver vi noe til et RI i RAM. Fyller opp program med tall ti millioner ganger. Helt det samme hver gang. Vel, vi har snakket med om cash.", "source": "lecture"}
{"lecture_id": "os14del10", "chunk_id": "os14del10_0004", "start": 270.0, "end": 402.3, "token_count": 290, "text": "Og at det kan skyldes... veldig stor forskjell i effektivitet. Vi gjør det samme antall institusjoner. Ti millioner ganger så skriver vi noe til et RI i RAM. Fyller opp program med tall ti millioner ganger. Helt det samme hver gang. Vel, vi har snakket med om cash. Og dette er absolutt noe som har med cash å gjøre. Og... Ja, det er et forslag at det er på grunn av r-øyet. Ja, det er pga. r-øyet. Og vi må prøve å tenke oss... Hva er det som... Hva er det egentlig som skjer her? Dette... Dette er et viktig poeng, så jeg tenker vi kan bruke litt tid på det. Kanskje jeg skal prøve å tegne... Tegne opp hva som skjer. Øyeblikk... Oi, hvor var den? Vi har et r-øy vi kaller r-øy her. Og det... Og da er det et viktig poeng at dette R-øyet ligger i ramm. Og det ville da settes av plass til på adresser etter hverandre. Dette vil da være logiske eller virtuelle adresser.", "source": "lecture"}
{"lecture_id": "os14del10", "chunk_id": "os14del10_0005", "start": 368.36, "end": 505.62, "token_count": 300, "text": "Og det... Og da er det et viktig poeng at dette R-øyet ligger i ramm. Og det ville da settes av plass til på adresser etter hverandre. Dette vil da være logiske eller virtuelle adresser. Men de ville mappes over, avbildes på fysisk R-øye i ramm, og da ligger de etter hverandre. Og det vi gjorde i første programmet... Det var å legge inn sånn... 0, 1, 2, 3, 4, 5 osv. Nedover sånn. Og da ser vi... Kanskje vi kom ned til 100 her nå, da. Eller vi kom egentlig mye lenger. Vi kom ned til... Vi kan ta med masse nuller der. Vi kommer ned til plass nummer 10 millioner. Kjempesvoltære. Men likevel så må vi huske på at dette var bare én av de 100 sånne som vi hadde bortover. Hvis vi tenker at dette er... At Ramm bare fortsetter sånn, ned dit, o... ned dit, og så videre. Så hadde vi da... Her oppe hadde vi 10 millioner og 1. Og her så hadde vi plassnummer 20 millioner. Den lå her nede.", "source": "lecture"}
{"lecture_id": "os14del10", "chunk_id": "os14del10_0006", "start": 470.72, "end": 585.0, "token_count": 288, "text": "som vi hadde bortover. Hvis vi tenker at dette er... At Ramm bare fortsetter sånn, ned dit, o... ned dit, og så videre. Så hadde vi da... Her oppe hadde vi 10 millioner og 1. Og her så hadde vi plassnummer 20 millioner. Den lå her nede. Og så hadde vi 100 sånne bortover. For vi har 100 ganger så mye som 10 millioner. Så det vi gjorde i det første programmet, det var bare å fylle opp det r-et der. Det var prog 1. Men så... Hva gjorde vi i prog 2? Jo, da så vi at vi fikk en faktor 100. Jeg prøver å skrive Prog2 med rødt der. Så i Prog2 så la vi fortsatt J lik 1. Så la vi fortsatt 0 inn her. Men så begynte vi å gå inn og legge inn her i 100. Så la vi 1. Og så lenger ned her. 200. Så la vi to. Og så fortsetter vi sånn nedover. Men da begynte vi å legge inn her også. Når vi kom opp i over ti... Over ti millioner.", "source": "lecture"}
{"lecture_id": "os14del10", "chunk_id": "os14del10_0007", "start": 552.22, "end": 677.16, "token_count": 298, "text": "Men så begynte vi å gå inn og legge inn her i 100. Så la vi 1. Og så lenger ned her. 200. Så la vi to. Og så fortsetter vi sånn nedover. Men da begynte vi å legge inn her også. Når vi kom opp i over ti... Over ti millioner. Kanskje vi fikk da... Ja, her nede. Så la vi inn... I 20 millioner så la vi vel inn noe sånt som 200 millioner. Men håpepoenget er at vi legger da over alt i ramm. Nå fyller vi ut hele det herreiet. Og så legger vi i den andre kjøringen. Altså når jeg hadde Prog 2, var Array av J. Det var prog 2. Krog 1 var array av i, ligg i... Array av jilliki. Da bare la vi nedover her. Array av jodligi, da økes... Det er da prog 2. Da økes jod med 100 for hver gang, sånn at vi legger... Vi legger data utover i hele æreøyet, og totalt sett så var... Hele dette var på 4G. Så et svært æreøy. Men da kom vi til løsningen på dette.", "source": "lecture"}
{"lecture_id": "os14del10", "chunk_id": "os14del10_0008", "start": 653.24, "end": 758.44, "token_count": 294, "text": "Da økes jod med 100 for hver gang, sånn at vi legger... Vi legger data utover i hele æreøyet, og totalt sett så var... Hele dette var på 4G. Så et svært æreøy. Men da kom vi til løsningen på dette. Ja, det er noen som kommer med et forslag her. Du må ut i ramma og hente en... Ja, det er riktig. Eller riktignok... Nå skriver vi til ramm. Sånn at vi må skrive ut til ramm. Men... Ja, og da... Når du legger inn tall på alle plassene, kan du legge inn flere tall før den må ut igjen. Jo, men problemet... Da... Jeg er ikke helt sikker på det. Jeg forstår deg riktig, men... En skulle på en måte tro at det var... For å si det på en annen måte... Hvis dette var ramm i ordets rette betydning, random access memory, så skal det gå like raskt å skrive noe hit som å skrive noe dit. Eller hvor som helst i ramm. Du er inne på noe der når du sier hvis du går... Hvis du legger inn tall på alle plassene på en gang...", "source": "lecture"}
{"lecture_id": "os14del10", "chunk_id": "os14del10_0009", "start": 729.2, "end": 827.5, "token_count": 294, "text": "For å si det på en annen måte... Hvis dette var ramm i ordets rette betydning, random access memory, så skal det gå like raskt å skrive noe hit som å skrive noe dit. Eller hvor som helst i ramm. Du er inne på noe der når du sier hvis du går... Hvis du legger inn tall på alle plassene på en gang... Må systemet kanskje flushe cashen? Ja, men det er akkurat dette som er... Akkurat det er poenget. Cashen må flushes. Altså... Når du legger alle etter hverandre på denne måten her, så det systemet vil gjøre da... Den vil ikke skrive én og én bite ut. Den vil ikke legge hver bite på ram ut på bussen og så skrive. Den vil ta hele... Litt avhengig av hvor stor LN cash er. Kanskje det er plass til 200 bite i LN cash. Så tar den hele den biten her. Og legger ut i LN cash. Da skriver den ikke bare én og én bite, men den kan ta hele biten etter hverandre, for den biten skal ligge på samme sted i ram. Og da kan man ta hele biter og skrive ut.", "source": "lecture"}
{"lecture_id": "os14del10", "chunk_id": "os14del10_0010", "start": 802.82, "end": 881.0, "token_count": 287, "text": "Og legger ut i LN cash. Da skriver den ikke bare én og én bite, men den kan ta hele biten etter hverandre, for den biten skal ligge på samme sted i ram. Og da kan man ta hele biter og skrive ut. Eller hvis man leser, så leser man da ikke én bite, men man leser fra ram. Først fyller man opp hele El3Cash, så El2Cash, og så El1Cash. Når de ligger etter hverandre, så kan de i sin helhet legges ut i LNCash. Og dermed så kan du ta mange hundre biter av gangen. Og som vi ser, så går det 100 ganger så fort. Derimot, når... ... vi prøver å kjøre program 2, så ser vi... Disse er spredt med 100 bite imellom. Så kanskje det er bare noen få bites som da treffer med hver gang LNCash kjøres. Noen flere treffer med L2, enda flere med L3, men du får ikke plass til alt. Så dette vil ta veldig mye lengre tid. Og vi ser det tar nesten 100 ganger så lang tid med Prog2.", "source": "lecture"}
{"lecture_id": "os2del3", "chunk_id": "os2del3_0000", "start": 0.0, "end": 87.2, "token_count": 282, "text": "Transistoren. Transistoren er grunnlaget for dette her. Altså for det å kunne, i det hele tatt, lage en datamaskin. De aller første datamaskinene hadde transistorrør som lagde disse logiske portene. Men problemet med det var at de transistorrørene var store. Så datamaskinene ble helt ekstremt store. Så det som la grunnlaget for CPU-en, var halvledertransistoren. Og det var det Shockley Bardin og Bratt Tane, som fikk nobelprisen i fysikk for dette, som konstruerte det. Mange argumenterer for at det er kanskje den aller viktigste oppdagelsen i forrige runde. Og det sier ikke lite, fordi den var da grunnlaget for alt som har med datamaskiner å gjøre. Og det som er så spesielt med halvledertransistoren, det er at den er ekstremt liten, det er mulig å konstruere den ekstremt liten, helt nedi nanometer. Og ved hjelp av disse bitte små halvlederbitene, så kan man lage logiske ands.", "source": "lecture"}
{"lecture_id": "os2del3", "chunk_id": "os2del3_0001", "start": 67.8, "end": 164.56, "token_count": 282, "text": "Og det som er så spesielt med halvledertransistoren, det er at den er ekstremt liten, det er mulig å konstruere den ekstremt liten, helt nedi nanometer. Og ved hjelp av disse bitte små halvlederbitene, så kan man lage logiske ands. Og ikke bare logiske, men faktisk fysiske porter som utfører logikken. Og man har teknologi helt nede i fem nanometer, og da er vi som komponenter av størrelsen fem nanometer, og det er ekstremt lite. Et hårstrå til sammenligning er 100 000 nanometer. Denne teknologien gjør at det er mulig å pakke sammen ekstremt mange små transistorer på et lite område. Og der har det vært en fantastisk utvikling fra 70-tallet, hvor de første kommersielle CPU-ene kom, sånn som i det diagrammet, Intel 404 her nede. Vi hadde noen tusen transistorer, men så har vi økt til i dag hvor det er, når dere ser på skallen her, 20 milliarder transistorer på de største CPU-ene.", "source": "lecture"}
{"lecture_id": "os2del3", "chunk_id": "os2del3_0002", "start": 137.82, "end": 248.42, "token_count": 296, "text": "hvor de første kommersielle CPU-ene kom, sånn som i det diagrammet, Intel 404 her nede. Vi hadde noen tusen transistorer, men så har vi økt til i dag hvor det er, når dere ser på skallen her, 20 milliarder transistorer på de største CPU-ene. Det er et ekstremt antall. Så er det noe som heter Mores lov. Det er egentlig ikke en lov, men det er bare empirisk at man har vist at sånn ca. annethvert år Det har funka ganske bra fra 70-tallet og så helt opp til i dag. Hvis den oppførselen er sånn at den går som to i x-hallet, blir det vel, Det ville være en ganske rett strek når du bruker loggplott. Så dette er faktisk en dobling. Da kan man spørre seg hvordan i all verden... For det første er det en teknologisk bragd å få til. Og man har begynt å nærme seg slutten for hva som er mulig. For det andre så skyldes ikke dette bare at CPU-ene går raskere og kan utføre mer arbeid. En stor del av de ekstra transistorene de siste årene har kommet pga. cash.", "source": "lecture"}
{"lecture_id": "os2del3", "chunk_id": "os2del3_0003", "start": 227.2, "end": 340.02, "token_count": 297, "text": "Og man har begynt å nærme seg slutten for hva som er mulig. For det andre så skyldes ikke dette bare at CPU-ene går raskere og kan utføre mer arbeid. En stor del av de ekstra transistorene de siste årene har kommet pga. cash. Men det som har vært viktig for utviklingen, er at jo mindre transistorer du har, jo hurtigere kan operasjonene kjøres. Klokkefrekvensen har også økt hele veien. Her er noen tall på det. Den hadde 2300 transistorer. Den har 7,2 milliarder transistorer. Det er en økning på en faktor, en million. Hvis man ser tilsvarende på klokkefrekvenser, så har ikke de økt like mye. Denne Intel hadde 500 kHz, eller en halv megahertz. I dag er det typisk fire gigahertz klokkefrekvens. Så det betyr en økning på 8000 omtrent. Og da betyr det at siden 1970 så går ting minst 8000 ganger raskere i en CPU. Det er gjort en masse andre forbedelser. Men den største faktoren er at klokkefrekvensen har økt.", "source": "lecture"}
{"lecture_id": "os2del3", "chunk_id": "os2del3_0004", "start": 312.24, "end": 413.76, "token_count": 289, "text": "Så det betyr en økning på 8000 omtrent. Og da betyr det at siden 1970 så går ting minst 8000 ganger raskere i en CPU. Det er gjort en masse andre forbedelser. Men den største faktoren er at klokkefrekvensen har økt. Den teknologien man har nå er ganske imponerende. Man kan få 100 mill. transistorer inn på 1 m2, det er helt vanvittige tall. Og man fortsetter nedover. TSMC, som er en halvlederprodusent... Det er verdens største halvlederprodusent, som f.eks. IMD har outsourcet sin produksjon til. Intel har også noe der, men Intel produserer det meste selv av CPU-er og silisiumbrikker. Men de har kommet ned fem nanometer, og de jobber også med to og tre nanometer. Etter hvert er det ikke mulig å gå lenger ned. Radius til et silisiumatom er på 0,1 nanometer. Det vil ha en diameter på 0,2. Hvis du får fem silisiumatomer ved siden av hverandre, så vil det ta kanskje 1 nanometer.", "source": "lecture"}
{"lecture_id": "os2del3", "chunk_id": "os2del3_0005", "start": 390.0, "end": 472.24, "token_count": 283, "text": "Etter hvert er det ikke mulig å gå lenger ned. Radius til et silisiumatom er på 0,1 nanometer. Det vil ha en diameter på 0,2. Hvis du får fem silisiumatomer ved siden av hverandre, så vil det ta kanskje 1 nanometer. Stort lenger ned enn det kan man ikke gå. Man kan ikke bygge fysiske komponenter. For da må man begynne med kvantemekanikk. Og effekter som kvantemekanisk tunnelering har faktisk noe å si, og det skaper problemer for disse silikonprodusentene, halvledderprodusentene. Så de fysiske grensene nærmer seg, så man kan ikke nå lage enda mindre og enda raskere CPU-er. Og som jeg nevnte, CPU-frekvensen er ikke klar. Den var oppe i 3 GHz i 2005 omtrent, og der har det stått stabilt. Det man i stedet har gjort, er å putte på mer cash. Som vi skal snakke mye om senere. Putte på mer cash og lage flere CPU-er innpå samme brikke.", "source": "lecture"}
{"lecture_id": "os2del3", "chunk_id": "os2del3_0006", "start": 450.0, "end": 491.92, "token_count": 150, "text": "Den var oppe i 3 GHz i 2005 omtrent, og der har det stått stabilt. Det man i stedet har gjort, er å putte på mer cash. Som vi skal snakke mye om senere. Putte på mer cash og lage flere CPU-er innpå samme brikke. Altså multicore computing. Vi har noen servere som har kanskje 64... Tidligere hadde alle én, så var det vanlig med to og sånne fire. Så måten man får servere til å bli mer effektive på nå, er først og fremst å ha flere CPU-er.", "source": "lecture"}
{"lecture_id": "linux5del9", "chunk_id": "linux5del9_0000", "start": 0.0, "end": 106.52, "token_count": 297, "text": "Denne teknikken kan man da bruke til f.eks. å gå gjennom passordfilen og se på hvert element i passordfilen med den samme vile read line-tankegangen. Da kan vi først se på første linje i passordfilen, så ser vi hvordan den ser ut. Den ser sånn ut. Da kan vi tenke oss at vi sender passordfilen til denne konstruksjonen her. Hvis vi nå sender inn passordfilen, så går vi gjennom den linje for linje. Rid linje leser da hele, men det man også kan gjøre, er å lage en variabel for hver kolonne som man leser inn. Så det første ordet i passordfilen er brukernavn. Så jeg kan kalle det BR-navn. Og så kommer det en X. Og så kommer en UID. Og så kommer en gruppe-ID. Så kommer navn på brukeren. Så kommer home-mappen, og til slutt Shell. Da vil hver av de elementene der leses. Linje for linje, så vil brukernavn tilhørende brukernavn X-til-X, UiD-til-UiD osv. Så kan han da f.eks. her, og vi trenger ikke å skrive ut linje,", "source": "lecture"}
{"lecture_id": "linux5del9", "chunk_id": "linux5del9_0001", "start": 86.46, "end": 190.4, "token_count": 290, "text": "Da vil hver av de elementene der leses. Linje for linje, så vil brukernavn tilhørende brukernavn X-til-X, UiD-til-UiD osv. Så kan han da f.eks. her, og vi trenger ikke å skrive ut linje, men vi kan skrive ut brukernavn. BR-navn. BR-navn. Og så kan vi skrive UID dollar UID. Hvis det er de to vi ønsker å få ut. Så kan vi prøve å kjøre det her. Det vil ikke fungere helt med en gang. Der ser vi at vi fikk ut en masse informasjon. Og det vi ser er problemet her, er at brukernavn er hele linjen. Og det er fordi default, så splitter did på mellomrom. Men her har vi kolon. Og da kan vi bruke IFS igjen. Vi kan si OK, vi ønsker ikke å splitte på kolon. Er det på mellomrom? Vi ønsker å splitte på kolon. Så jeg kan sette IFS. Den definerer løya splitt-opp-på-kolon. Da kan vi prøve å kjøre igjen. Og da ser vi for hver linje i postofilen, så får vi brukernavn og UID.", "source": "lecture"}
{"lecture_id": "linux5del9", "chunk_id": "linux5del9_0002", "start": 162.56, "end": 208.94, "token_count": 136, "text": "Vi kan si OK, vi ønsker ikke å splitte på kolon. Er det på mellomrom? Vi ønsker å splitte på kolon. Så jeg kan sette IFS. Den definerer løya splitt-opp-på-kolon. Da kan vi prøve å kjøre igjen. Og da ser vi for hver linje i postofilen, så får vi brukernavn og UID. Så hvis vi tar på det de første linjene... Så ser vi brukernavn og rute, UID 0, osv. nedover. Takk for møtet. Ha det bra!", "source": "lecture"}
{"lecture_id": "os2del10", "chunk_id": "os2del10_0000", "start": 0.0, "end": 111.92, "token_count": 293, "text": "Det man... Bare for å vise litt om forenkling, så kan vi se på en krets. For det første, hva blir den bolske funksjonen for denne her? Jo, her ser vi at vi har to enere. Så den bolske funksjonen for dette her må bli ikke A ganger B pluss A ganger B. Ja, vi kan jo ta det her. Ikke A ganger B. Det er det første uttrykket her. Pluss A ganger B, siden dette også skal gi en ener. Dette logiske uttrykket vil alltid oppfylle sannhetstabellen, fordi det gir ener i de to tilfellene og null i de to andre. Her har jeg tegnet opp denne kretsen ved å tegne den rett frem. Men det vi skal se på nå, er hvordan kan man forenkle denne kretsen. Igjen så blir dette mer sånn ingeniørmessig. Kretsen virker som den skal, men man kan spare enormt med porter hvis man forenkler kretser. Sympatisk... Ikke sympatisk, men systematisk måte. Og det er at man først forenkler, og så brenner man kretsen. Jeg ser det kommer en spoiler-alert her i chatten.", "source": "lecture"}
{"lecture_id": "os2del10", "chunk_id": "os2del10_0001", "start": 80.96, "end": 141.0, "token_count": 167, "text": "men man kan spare enormt med porter hvis man forenkler kretser. Sympatisk... Ikke sympatisk, men systematisk måte. Og det er at man først forenkler, og så brenner man kretsen. Jeg ser det kommer en spoiler-alert her i chatten. F ligg B. Det er faktisk helt riktig. Og det ser jo litt utrolig ut. Så skal vi se på hvordan man kan generelt forenkle det, og i dette tilfellet vise at F er faktisk lik B. En liten spoiler-alert. Så prøv å se på dette i pausen. Hvorfor er egentlig... Hvorfor er dette riktig, at F er lik B?", "source": "lecture"}
{"lecture_id": "linux5del1", "chunk_id": "linux5del1_0000", "start": 0.0, "end": 107.8, "token_count": 298, "text": "Vi skal nå se på passordkryptering på en Linux-server, og hva som skjer når vi logger inn på en Linux-server. Ja, vi vet at all info om innlogging ligger i en fil som heter etterpassword. I hvert fall all info som brukernavn og bruker-id osv. Hjemmemappe. Default selv. Men passordet ligger ikke her. Tidligere så lå i stedet for den X-en, så lå det en såkalt passordhersj. En kryptert form av passordet. Av sikkerhetsgrunner så ligger det nå ikke lenger i passord, sånn at det kan ses av alle. Men default, så ligger en... Passordhersen ligger i etshadow. Men den har ikke en vanlig bruker lov til å se på, så da må man være sudobruker for å ha ut rettigheter. Nå hadde jeg nettopp tastet ut passordet, ellers måtte jeg taste passordet direkte. Her ser vi en lang streng, som er en såkalt hers. Det er generert med en hersingalgoritme, en krypteringsalgoritme, som ut ifra passordet lager denne hersen. Og det som skjer når du logger inn, er at man taster inn passordet,", "source": "lecture"}
{"lecture_id": "linux5del1", "chunk_id": "linux5del1_0001", "start": 80.28, "end": 178.0, "token_count": 294, "text": "Her ser vi en lang streng, som er en såkalt hers. Det er generert med en hersingalgoritme, en krypteringsalgoritme, som ut ifra passordet lager denne hersen. Og det som skjer når du logger inn, er at man taster inn passordet, og så har man en algoritme som lager denne hersen, og så sammenligner man med det som ligger i Etch Shadow. Hvis det er det samme, så får du lov å logge. Vi kan se litt på de forskjellige hersingmetodene. Tidligere brukte man Dess, som er en relativt dårlig algoritme. Så brukte man MD5. Det brukes fortsatt i en del sammenhenger. Men det var noen mangler ved MD5, sånn at den litt lettere kunne knekkes i noen tilfeller. Så... I de senere årene har man gått over til Sja. Sja-256 og Sja-512. Dette er da antall bitt som er brukt i krypteringen. Jo flere bitt, jo vanskeligere er det å knekke. Og vi så på vårt eksempel at... Det sto en dollar seks først her i hashen. Og det betyr...", "source": "lecture"}
{"lecture_id": "linux5del1", "chunk_id": "linux5del1_0002", "start": 150.0, "end": 244.18, "token_count": 280, "text": "I de senere årene har man gått over til Sja. Sja-256 og Sja-512. Dette er da antall bitt som er brukt i krypteringen. Jo flere bitt, jo vanskeligere er det å knekke. Og vi så på vårt eksempel at... Det sto en dollar seks først her i hashen. Og det betyr... At dette var sja512. Så det som skjer når vi krypterer passordet, det er at man... Eller når vi logger inn, så er det første som skjer, at man taster en passord. Og så vil loggenstillet kryptere passordet med en krypteringsalgoritme. Så får vi en lang hastereng. Så sjekkes den mot EtsShadow. Hvis den da er lik, så får du logge inn. Poenget er at det er vanskelig å gå den andre veien. Eller i praksis umulig å gå den andre veien herfra og tilbake og finne ut passordet. Tidligere lå dette passordet i Klarteks, så alle kunne se det for alle brukere. Det har man sluttet med, for det er mulig...", "source": "lecture"}
{"lecture_id": "linux5del1", "chunk_id": "linux5del1_0003", "start": 219.74, "end": 298.4, "token_count": 289, "text": "Poenget er at det er vanskelig å gå den andre veien. Eller i praksis umulig å gå den andre veien herfra og tilbake og finne ut passordet. Tidligere lå dette passordet i Klarteks, så alle kunne se det for alle brukere. Det har man sluttet med, for det er mulig... Selv om det er umulig å gå denne veien, så er det mulig å bruke en såkalt brute force-metode for å knekke passord. Og det man gjør da, er at man sender inn en rekke forslag på passord. Man gjetter rett og slett. Typisk å gå gjennom alle bokstaver i alfabetet. Eventuelt noe som er smartere, Bruk en ordbok, gå gjennom alle ordene i ordboken. Kjøre krypteringsalgoritmen som brukes når man logger inn. Og så sjekke mot hashen her. Er det den samme, gjør man det for en million forskjellige passord. Og så plutselig får man en match, og da vet man passordet. Så på den måten kan det være mulig ut fra hasher å finne passordord.", "source": "lecture"}
{"lecture_id": "linux5del1", "chunk_id": "linux5del1_0004", "start": 279.6, "end": 389.96, "token_count": 294, "text": "Og så sjekke mot hashen her. Er det den samme, gjør man det for en million forskjellige passord. Og så plutselig får man en match, og da vet man passordet. Så på den måten kan det være mulig ut fra hasher å finne passordord. Selv om det ikke er passord i klartekst, så kan man da klare å finne det ut ved Brute Force. Vi skal se nå på hvordan vi kan... Hvordan vi kan klare det. Ja... Vi så her at den passordstrengen lå i Shadow. Eller i dette tilfellet åtte tegn her mellom... Etter dollar nummer to... Mellom dollar nummer to og dollar nummer tre. Der er det en streng. Og det er et såkalt salt. Og vi så at vi brukte sja5. Og det er mulig fra kommandolinja, og så... Med kommandoen MK-password. Hvis man da bruker... Hvis man da spesifiserer hvilken algoritme det er, minus M... I vårt tilfelle så var det A512. Og så, hvis man i tillegg spesifiserer saltet, som var dette... Mellom andre og tredje dollartegn.", "source": "lecture"}
{"lecture_id": "linux5del1", "chunk_id": "linux5del1_0005", "start": 365.16, "end": 453.52, "token_count": 283, "text": "Hvis man da bruker... Hvis man da spesifiserer hvilken algoritme det er, minus M... I vårt tilfelle så var det A512. Og så, hvis man i tillegg spesifiserer saltet, som var dette... Mellom andre og tredje dollartegn. Så kan man kjøre passordalgoritmen. Hvis jeg nå taster inn mitt passord på denne serveren, så vil du se at da kommer ut i andre enden... Jo, faktisk, da får vi til en match. Det er ikke så lett å se, men du ser de begynner på H6, CV, KIUD og sånn. Og så ser vi slutten. Den er også akkurat den samme som her. Dette skjer ved innlogging. Jeg taster inn passordet. Og så kjører skjellet denne kommandoen. Og så får du ut denne strengen og tester den. Er det det samme som i Shadow? Hvis det er det, så får jeg lov å logge. Denne metoden kan da brukes til å lage en brute force-passordknekker. Og det er det dere skal gjøre i første oppgave. Denne uka.", "source": "lecture"}
{"lecture_id": "linux6del4", "chunk_id": "linux6del4_0000", "start": 0.0, "end": 94.3, "token_count": 288, "text": "Rettighetsprinsippene på et Linux-system er relativt enkle. En vanlig bruker har stort sett bare lov til å gjøre endringer på sitt eget hjemmeområde. Så her, inne på homegroup100, her kan brukeren gjøre omtrent som han eller hun vil. Fjerne filer, lage filer, mapper osv. Men med en gang en vanlig bruker prøver å gå... Ned på ROOT-filsystemet og f.eks. fjerne Etcete Password. Så får man permission denied. ROOT derimot... Administratorbrukeren, den har alle rettigheter. Og kan fjerne alt som er av mapper og filer for alle brukere. Legge til grupper, endre på grupperettigheter, endre på filerettigheter. Nei... Egentlig absolutt alle mulige rettigheter. Så derfor er det ikke... Man bør helst unngå å jobbe for mye i et rutskjell. Man kan få et rutskjell ved å gjøre sudoveisu. Skal vi se... Nå må jeg ta riktig passord. Sånn. Der er jeg i RUT. Og jeg kan da gjøre også alt mulig galt.", "source": "lecture"}
{"lecture_id": "linux6del4", "chunk_id": "linux6del4_0001", "start": 70.12, "end": 161.2, "token_count": 288, "text": "Man bør helst unngå å jobbe for mye i et rutskjell. Man kan få et rutskjell ved å gjøre sudoveisu. Skal vi se... Nå må jeg ta riktig passord. Sånn. Der er jeg i RUT. Og jeg kan da gjøre også alt mulig galt. Så problemet med å jobbe i et rutskjell på denne måten er at det er fortere å glemme at man har allmektig power. Man kan gjøre hva som helst, og da kan man fort også en feil slette ting. Så det beste er å jobbe som vanlig bruker, og så gjøre kommandoer med sudo, sånn som aduser. Men passordet huskes, så det er ikke så vanskelig og så mye ekstra jobb å taste ned passordet noen ganger ved å være sudobruker. Fordelene er at når man gjør vanlige ting, risikerer man ikke å ødelegge systemet. Og i tillegg, hvis det er et system som mange bruker, så kan man da se... Hvilken brukers som gjorde sudo, sånn at man kan se hvem som har gjort hva i ettertid, ut ifra loggfiler.", "source": "lecture"}
{"lecture_id": "linux6del4", "chunk_id": "linux6del4_0002", "start": 136.9, "end": 214.22, "token_count": 290, "text": "Fordelene er at når man gjør vanlige ting, risikerer man ikke å ødelegge systemet. Og i tillegg, hvis det er et system som mange bruker, så kan man da se... Hvilken brukers som gjorde sudo, sånn at man kan se hvem som har gjort hva i ettertid, ut ifra loggfiler. Men det kan legges til at tidligere så var det et veldig strengt skille mellom ruteuser og vanlige brukere. For da opererte man gjerne med servere som sto og gikk i årevis, og som ble drift. Og som hadde den rette tilstanden, og som da aldri skulle endres. Etter hvert som man har begynt med virtuelle maskiner, som kan bygges med nytt hvis noe går galt, og i enda større grad dokkecontainere, som veldig raskt kan bygges på nytt, så er det ikke så kritisk om man er root user og ødelegger systemet. For da er filosofien mer at jo, hvis noe går galt, så kan man bygge et helt nytt system. Og dermed er det ikke så kritisk. Om man sommer ut gjør en feil.", "source": "lecture"}
{"lecture_id": "os6del14", "chunk_id": "os6del14_0000", "start": 0.0, "end": 100.72, "token_count": 278, "text": "Ok. Nå... Vi kan rydde opp litt her. Nå er jeg inne på én server. Og så skal jeg bare kjøre en liten regnejobb. Jeg har et program som heter Adatot. Som er CPU-avhengig, og som bare står og bruker CPU. Samtidig kan jeg her kjøre topp, og da ser vi... Topp viser nå øverst en linje med det programmet som kjører. Der ser vi... Det var ferdig. Vi kan også ta tiden på programmet. Jeg starter på nytt, og da ser vi... Øverst her så er det en prosess som står og kjører, og den ser vi bruker 100 %. Hvis jeg taster tallet én i topp, så ser vi at det kommer fram én CPU her oppe. Og her er det bare CPU0. Så dette er en server som bare har én enkelt CPU. Det er det nesten umulig å få tak i. Alle dagens servere eller CPU-er har minst to CPU-er. Men jeg har bare skrudd av de andre for å vise denne demoen her. Så det man kan gjøre, det er å kjøre...", "source": "lecture"}
{"lecture_id": "os6del14", "chunk_id": "os6del14_0001", "start": 70.84, "end": 168.4, "token_count": 294, "text": "Og her er det bare CPU0. Så dette er en server som bare har én enkelt CPU. Det er det nesten umulig å få tak i. Alle dagens servere eller CPU-er har minst to CPU-er. Men jeg har bare skrudd av de andre for å vise denne demoen her. Så det man kan gjøre, det er å kjøre... Prøv å se hva som skjer. Hvis jeg kjører nå to regneoppgaver samtidig... Da legger jeg henne i bakgrunnen sånn. To stykker. Og da ser vi. Her er det nå to prosesser som heter alt. Vi ser de deler nå likt på CPU-en. Disse to her. Her er det en rad som sier CPU. Og her ser vi. Bær av de får 50 %. Hvis jeg nå starter en til, så ser vi at da kommer den inn også. Men da får hver av de 33 %. Da deler de likt på den ene CPU-en. Sånn fungerer multitasking når man bare har én CPU. De deler da på CPU-en, og de kjører halvparten hver. Men de kjører da ca. ett hundredels sekund hver, og så bytter de på hvem som kjører.", "source": "lecture"}
{"lecture_id": "os6del14", "chunk_id": "os6del14_0002", "start": 144.68, "end": 236.5, "token_count": 290, "text": "Da deler de likt på den ene CPU-en. Sånn fungerer multitasking når man bare har én CPU. De deler da på CPU-en, og de kjører halvparten hver. Men de kjører da ca. ett hundredels sekund hver, og så bytter de på hvem som kjører. Og hele tiden så bytter operativstemmet frem og tilbake mellom de to prosessene. Så skal vi veldig kort se på hva som... Hva skjer hvis jeg nå starter opp én CPU til på denne serveren? Jeg kan vise senere hvordan jeg kan gjøre det. Men nå startet jeg opp én server til. Nei, én CPU til. Så hvis jeg nå taster én, så ser vi at jo, her dukker det opp to CPU-er. Så nå har denne serveren tilgang til to CPU-er. Og hva skjer da hvis jeg starter to programmer samtidig? Jo, da ser vi her oppe... Så ser vi at nå jobber disse prosessene på hver sin CPU. Den får 100 % på den ene CPU-en, og den får 100 % på den andre. Men da vil det bli sånn at hvis jeg nå starter tre prosesser av den typen,", "source": "lecture"}
{"lecture_id": "os6del14", "chunk_id": "os6del14_0003", "start": 215.36, "end": 310.78, "token_count": 296, "text": "Jo, da ser vi her oppe... Så ser vi at nå jobber disse prosessene på hver sin CPU. Den får 100 % på den ene CPU-en, og den får 100 % på den andre. Men da vil det bli sånn at hvis jeg nå starter tre prosesser av den typen, Så får de ca. 67 % hver. Der fordeler de CPU-tiden seg imellom på den måten. Og det går også an å se nøyaktig hvordan det skjer. Skal vi se om jeg er rask nok til å få til det. La oss si jeg starter tre prosesser her. Jeg taster F, så kan jeg gå inn i Topp. Jeg tastet nå F, og så kan jeg gå ned og finne Last Use CPU. Så Space på den, og så Escape. Så ser vi helt ytterst her, så har vi fått et nytt felt hvor det står 100. Nå var jeg litt sein. Jeg kan starte på nytt. Starter nå tre... prosesser. Helt til høyre her, så ser vi en null og en ener. Og da ser vi at de bytter på. Noen ganger så kjører begge på CPU1 og én på CPU0, og så andre ganger så kjører begge på CPU0.", "source": "lecture"}
{"lecture_id": "os6del14", "chunk_id": "os6del14_0004", "start": 293.98, "end": 379.48, "token_count": 294, "text": "Starter nå tre... prosesser. Helt til høyre her, så ser vi en null og en ener. Og da ser vi at de bytter på. Noen ganger så kjører begge på CPU1 og én på CPU0, og så andre ganger så kjører begge på CPU0. Så typisk så kjøres da én prosess på hver av CPU-ene, og så vil den tredje prosessen bytte mellom. Nei, det er ikke helt riktig, fordi... Operativstemme har en scheduler som kalles Fair Scheduler. Så når tre prosesser kjøres på denne måten her... Det som i praksis skjer, er at alle tre bytter likt, sånn at hver prosess får da ca. to tredjedeler CPU-tid, hvor den har tilgang til CPU-en. Og på den måten så får de i snitt så får de 67 % CPU-tid. Ok. Men da tenker jeg dere er passe slitne. Da skal vi slutte der. Men det er noen oppgaver denne uken som går ut på dette her. Av at dere skal kjøre CPU-avhengige prosesser. Nå kjørte jeg et CV-program. Man kan også kjøre programmer sånn som regn her.", "source": "lecture"}
{"lecture_id": "os6del14", "chunk_id": "os6del14_0005", "start": 356.5, "end": 457.58, "token_count": 294, "text": "Da skal vi slutte der. Men det er noen oppgaver denne uken som går ut på dette her. Av at dere skal kjøre CPU-avhengige prosesser. Nå kjørte jeg et CV-program. Man kan også kjøre programmer sånn som regn her. Det er det regneprogrammet jeg viste. Det vil oppføre seg på akkurat samme måte. Så får de hver sin CPU. Legger jeg på det tredje regnprogrammet, så får det i snitt 67 % CPU hver. Fordi operativsystemene da bytter om på hvilken CPU de bruker. Sånn teoretisk så vi i dag mest på operativsystemer hvordan de kjører på én CPU. Å kunne gå inn og fordele prosesser på de forskjellige CPU-ene. Som vi så vidt så på her. Så i oppgaven denne uken så skal dere teste ut dette her. Både på study SSO og kjøre regnejobber. Men også på... Også på de Linux-VM-ene. Og der er det litt annerledes. Hvis dere gjør topp der og taster én, så vil dere se at dere har noe sånt som 96 CPU-er. Det dere faktisk da ser, er", "source": "lecture"}
{"lecture_id": "os6del14", "chunk_id": "os6del14_0006", "start": 432.8, "end": 521.4, "token_count": 290, "text": "Men også på... Også på de Linux-VM-ene. Og der er det litt annerledes. Hvis dere gjør topp der og taster én, så vil dere se at dere har noe sånt som 96 CPU-er. Det dere faktisk da ser, er den underliggende serveren. Men de containerne dere har, er satt opp sånn at de bare får tilgang på to CPU-er. Eller i snitt så får de så mye CPU-tilgang. Så det er... Det er da begrenset på en annen måte. Og ikke sånn som med fysiske servere, hvor du har fire CPU-er, og de er de du har. Men med virtuelle maskiner og med containere, så kan man når man setter det i gang, så kan man tildele et antall CPU-er. Og med Docky-containere, så er det sånn... Der blir det ikke direkte tildelt, men der blir man tildelt en prosentdel. Så de dere har, er tildelt sånn at de får i snitt to CPU-er. Mens på Studies SO har hver VM fire sepur som man kan kjøre på. Men dette er sånt som dere kan teste ut i oppgavene denne uken.", "source": "lecture"}
{"lecture_id": "os4del5", "chunk_id": "os4del5_0000", "start": 0.0, "end": 58.0, "token_count": 176, "text": "Et annet spørsmål er de ledningene som går mellom boksene i bussen. Det er et godt spørsmål. Ja, det er ikke det man kaller... Det er ikke det man vanligvis kaller databussen. Men det som man vanligvis kaller databussen, er dataene som går til RAM. Og det skal vi komme litt innpå etterpå. Det som er databussen, vil i vårt tilfelle være de fire linjene her og de fire linjene her. Addresse out og data out. Og det er da en buss som går mellom CPU-en og RAM. Disse linjene internt, det er mer... Du kunne kalle det busser òg, men det er interne linjer i CPU-en.", "source": "lecture"}
{"lecture_id": "linux8del4", "chunk_id": "linux8del4_0000", "start": 0.0, "end": 95.94, "token_count": 169, "text": "Hva er forskjellen på image og konteiner? Når du starter opp imaget, så har du en instanse av imaget som kjører. Det er en virtuell maskin. Det kaller du en VM. Tilsvarende er det for containere. Du har et image som du starter opp. Med en gang du har startet det imaget og har et image som kjører, så er det en container. Det er kanskje ikke helt presist svar. Du kan jo liste konteinere. Og da... og da... er på en måte det en konteiner... Når den er stoppet, så er den fortsatt en konteiner. Det er da en instanse som er frosset ned, på en måte.", "source": "lecture"}
{"lecture_id": "os1del15", "chunk_id": "os1del15_0000", "start": 0.0, "end": 139.2, "token_count": 292, "text": "Her ser vi, forhåpentligvis ser dere også dette her, program eller kode. Hvis jeg sier at... Jo, vi har sagt at en prosess er et program som kjører. Men hva med... Hva om programmet eller koden som vi kjører, er DNA? Altså... Hva er da prosessen? Jeg ser Marius har et spørsmål, jeg kan ta det etterpå. Vanlige programmer som kjører. Det er koden. Og så har vi da prosesser som kjører på en datamaskin. Men hva kan da en prosess være hvis det er DNA som er koden? Ja, forslag... Enzymer, proteiner... Ja, det er godt forslag. Det er helt perfekt, men det tenker jeg kanskje er litt... Det blir jo ikke på en måte hardware. Det som er problemet med DNA, er at den både er hardware og prosessen i seg selv. Fordi du på en måte... DNA er kode som bestemmer hvordan alt blir. Menneske... ja. Det kom masse forslag her. Veldig bra. Alt som er programmert i DNA. Ja, jo, men det er med programmet. Og menneske, da tenker jeg mer at det kanskje er litt mer sånn hardware.", "source": "lecture"}
{"lecture_id": "os1del15", "chunk_id": "os1del15_0001", "start": 112.32, "end": 245.14, "token_count": 298, "text": "Menneske... ja. Det kom masse forslag her. Veldig bra. Alt som er programmert i DNA. Ja, jo, men det er med programmet. Og menneske, da tenker jeg mer at det kanskje er litt mer sånn hardware. Blod som pumpes rundt i kroppen. Ja, absolutt. Nervesignaler. Bevisstheten. Ja, det begynner å nærme dere. Men det er noe helt spesifikt som jeg er ute etter. Vi har jo sånn som hardware, da. Lurer på hva det er også. Og da tror jeg kanskje jeg kan være med på mennesker. Sjel og ånd. Men hvis jeg prøver å stille spørsmålet på en litt annen måte, da... Hvordan... Hvis du ser på deg selv... Eller se på meg, da. Jeg har et DNA. Og det er jo egentlig bare en kjempelang streng med kode. Så... Den prosessen at mitt DNA kjører, at det i det hele tatt, det DNA-et kjøres, hva kan det kalles? Eller for din del, at ditt DNA kjøres. Det var masse forslag her. Noen som har flere ideer? Hvordan er det relatert til deg?", "source": "lecture"}
{"lecture_id": "os1del15", "chunk_id": "os1del15_0002", "start": 200.68, "end": 340.0, "token_count": 289, "text": "Og det er jo egentlig bare en kjempelang streng med kode. Så... Den prosessen at mitt DNA kjører, at det i det hele tatt, det DNA-et kjøres, hva kan det kalles? Eller for din del, at ditt DNA kjøres. Det var masse forslag her. Noen som har flere ideer? Hvordan er det relatert til deg? Ja, gener - igjen gener. Det er selve DNA. Så... Hjerte, ja, da er du inne på noe. For det er liksom det at... at det utføres. Men hva er selve prosessen? At man lever, ja. Veldig bra. Mohammed kom med at man lever. Det jeg vil si, er at selve prosessen for DNA-et er livet. Altså det som et menneske... Helt fra man blir født til man dør. Og akkurat sånn er det med prosesser også. Man har jo sånn som kill eller kontroll C. Det vil jo være drap. Eller død, ikke sant. Jeg ser i chatten her om dette er fag i filosofi. Ja, absolutt! Det er veldig viktig å liksom... Prosesser skal vi snakke om hele tiden.", "source": "lecture"}
{"lecture_id": "os1del15", "chunk_id": "os1del15_0003", "start": 310.0, "end": 432.72, "token_count": 290, "text": "Man har jo sånn som kill eller kontroll C. Det vil jo være drap. Eller død, ikke sant. Jeg ser i chatten her om dette er fag i filosofi. Ja, absolutt! Det er veldig viktig å liksom... Prosesser skal vi snakke om hele tiden. Og det er veldig viktig at dette er mye mer enn bare et program som kjører. Og det er tanken med denne analogien, at hver gang dere hører ordet prosess, så skal dere da ikke bare tenke på det programmet som kjører, men dere skal tenke på at dette er hele livet for akkurat den koden som kjører. Hva kan hardware være, da? Der igjen blir det litt vanskelig... Organer, det var bra, var den som foreslo. Men jeg tenker at hardware også er sånn noe mer enn bare mennesket selv, ikke sant? For det kan jo ha sånn som hus, mat... Bygninger osv. Fordi at DNA på en måte opererer... DNA opererer over hele verden. Så... Kontroll C er close... Det er jo copy-og-do-s. Det er faktisk sant. Men hvis du kjører en Linux-prosess og du skal stoppe den,", "source": "lecture"}
{"lecture_id": "os1del15", "chunk_id": "os1del15_0004", "start": 390.02, "end": 515.36, "token_count": 275, "text": "Bygninger osv. Fordi at DNA på en måte opererer... DNA opererer over hele verden. Så... Kontroll C er close... Det er jo copy-og-do-s. Det er faktisk sant. Men hvis du kjører en Linux-prosess og du skal stoppe den, så hvis du tasser kontroll C, så blir den drept. Ja, så kill-kontroll C er drap, men vi har et par andre viktige ting her. Hva med... Eller for å sette det motsatt... Hva kan man si at staten eller lovverket... Lovverket... Hva er det i denne analogen? Analogien? Andreas, supert. OS, operativsystemet, det er liksom staten eller lovverket, som da sørger for at prosesser ikke ødelegger for hverandre. For da er det sånn at hvis en av dere går inn i nabohybelen til en annen student, så kan ikke vi bare gå inn der og ta hva som helst. Og akkurat det er det operativsystemet sørger for. Det sørger for at de prosessene som kjører her på jorda, ikke er på jorda,", "source": "lecture"}
{"lecture_id": "os1del15", "chunk_id": "os1del15_0005", "start": 493.8, "end": 594.28, "token_count": 278, "text": "For da er det sånn at hvis en av dere går inn i nabohybelen til en annen student, så kan ikke vi bare gå inn der og ta hva som helst. Og akkurat det er det operativsystemet sørger for. Det sørger for at de prosessene som kjører her på jorda, ikke er på jorda, operativsystemet sørger for at prosessene i en datamaskin ikke ødelegger for hverandre. De kontrollerer at de deler på godene sånn som det skal. Det samme kan man da si om operativsystemet. Det er en slags sånn overordnet sjef. Politi kunne også... Kanskje vært. Som overholder lovverket. Kan ta med det òg. Politi. Som passer av prosessene, ikke ødelegger for andre. Så kan man også spørre seg om hva med Rut eller administrator? Hvem er dette i den analogien? Brian kommer en gang til med... veldig bra. Sjelden noen sier det så fort. Men det er Gud. Administrator har all makt. Og det er en del regjering i Kongen, ja. Det er også litt det samme.", "source": "lecture"}
{"lecture_id": "os1del15", "chunk_id": "os1del15_0006", "start": 570.0, "end": 670.74, "token_count": 296, "text": "Hvem er dette i den analogien? Brian kommer en gang til med... veldig bra. Sjelden noen sier det så fort. Men det er Gud. Administrator har all makt. Og det er en del regjering i Kongen, ja. Det er også litt det samme. Men Gud er kanskje enda bedre. Dere har sikkert opplevd en del Ruth. Men i denne analogien så er det det. For de er også en prosess. Det blir en litt omfattende diskusjon når vi skal diskutere om Gud også har DNA osv. Men det er en prosess som styrer de andre prosessene. En Gud kan jo da bare si OK, denne prosessen her gjør så mye galt, så den bare stopper vi. Så Rutel Administrator er på en måte en sånn... Er allmektig på toppen og styrer alle prosessene. OK. Jeg vet ikke om denne analogien er helt perfekt. Men det som er viktig med den, er at fra nå av, når dere tenker på en prosess, så må dere ta med alle de bitene som... Denne analogien... Viser at en prosess omfatter, da. For eksempel så skal vi senere se på hva som... At vi kan...", "source": "lecture"}
{"lecture_id": "os1del15", "chunk_id": "os1del15_0007", "start": 641.78, "end": 731.2, "token_count": 277, "text": "OK. Jeg vet ikke om denne analogien er helt perfekt. Men det som er viktig med den, er at fra nå av, når dere tenker på en prosess, så må dere ta med alle de bitene som... Denne analogien... Viser at en prosess omfatter, da. For eksempel så skal vi senere se på hva som... At vi kan... Eller at operativsystemet... For å dele på godene, så driver operativsystemet hele tiden og stopper prosesser. Og hvis du stopper en prosess, så er det... Det er på en måte et drap, men det er mer sånn at du setter hele prosessen på hvile. Da må du også ta vare på alt det den prosessen hadde. Alle oppkoblinger, alt som ligger i registeret, internminnet. Alt det må lagres og på en måte fryses. Og det er mer sånn som... Dere har sikkert sett science fiction-filmer Og så tines opp 100 år senere. Og det er akkurat det operativsystemet gjør hele tiden. Her er det snakk om et hundredels sekund. Det fryses ned en prosess i et hundredels sekund.", "source": "lecture"}
{"lecture_id": "os1del15", "chunk_id": "os1del15_0008", "start": 706.08, "end": 833.84, "token_count": 290, "text": "Og det er mer sånn som... Dere har sikkert sett science fiction-filmer Og så tines opp 100 år senere. Og det er akkurat det operativsystemet gjør hele tiden. Her er det snakk om et hundredels sekund. Det fryses ned en prosess i et hundredels sekund. Men da må alt om prosessen også lagres, nøyaktig som når man skal vekke opp et menneske. Naturlover går under Ruteadministrator. Jo, du kan nok si det. Men kanskje... Men det er som sagt... Det er ikke alt som klaffer 100 % med denne analogien. Men det som er viktig, er at dere har med det som... Odeta oppsummerer veldig fint at prosessen er livsløpet av programmet. Og absolutt, det er det. For hvis du har et program, så har du en eller annen funksjon som du skal gjøre. som skal regne ut en sum fra 1 til 100. Da er hele livsløpet til programmet at det starter, og så kjører det nøyaktig sånn som DNA-et tilsier. Nemlig at det skal legge sammen alle disse tallene. Det bruker da hardware. Det bruker da alle ressursene.", "source": "lecture"}
{"lecture_id": "os1del15", "chunk_id": "os1del15_0009", "start": 810.0, "end": 917.0, "token_count": 298, "text": "som skal regne ut en sum fra 1 til 100. Da er hele livsløpet til programmet at det starter, og så kjører det nøyaktig sånn som DNA-et tilsier. Nemlig at det skal legge sammen alle disse tallene. Det bruker da hardware. Det bruker da alle ressursene. Og så gjennom livsløpet til prosessen så utføres nøyaktig det det skal, som beskrevet. I DNA-et, eller i koden. Så kommer det fram til et resultat, og så gir det videre til noen andre. Så absolutt. Prosessen er hele livsløpet til et program. Men hva med CPU? Spør Floyd her. Jo, det blir mer sånn. CPU er da en del av hardwareet som mennesket lever på. Men i denne analogien er det kanskje litt mer sånn at hjernen er CPU-en. Altså at du... Det blir litt komplisert, for DNA er også oppskriften på hjernen. Men så vil jeg kanskje si mer at CPU er... At hjernen er CPU. Vi kan ta med det også. Men... ja. Nå begynner analogien å bli litt vanskelig. Så den er ikke perfekt, men prøv å huske å ta med dette her videre.", "source": "lecture"}
{"lecture_id": "os12del3", "chunk_id": "os12del3_0000", "start": 0.0, "end": 78.56, "token_count": 291, "text": "Ja... Det er et godt spørsmål i chatten om... ... uke 14 er obligatorisk. Det var fint du spurte om, for det... Nei, uke 14 er ikke obligatorisk. Så Oblig3... Det kommer en mappe for å levere Oblig3 i dag. Og alt som skal inngå i Oblig3, det er akkurat til og med uke 12. Altså fra før påske. Så som det står her i uke 12... Det er de siste som skal være med i opplegg 3-innlevering. Så derfor er det... Jeg har kanskje ikke skrevet noe om det, men vi... Jo, her står det en kommentar om dette. Innleveringene er ikke obligatoriske, så de som har merket opplegg, bare betrakt de viktigste oppgavene å få med seg for å forberede seg til eksamen. Altså det som er mest eksamensrelevant. Så når det står oblig her, sånn som her, så betyr det ikke at det skal være med i noen oblig-innlevering. Men det skal... Det er det som er det viktigste. Og jeg snakket med studenter og studenter om det.", "source": "lecture"}
{"lecture_id": "os12del3", "chunk_id": "os12del3_0001", "start": 55.38, "end": 119.0, "token_count": 229, "text": "for å forberede seg til eksamen. Altså det som er mest eksamensrelevant. Så når det står oblig her, sånn som her, så betyr det ikke at det skal være med i noen oblig-innlevering. Men det skal... Det er det som er det viktigste. Og jeg snakket med studenter og studenter om det. Det kan godt være at vi kan få til... Vi kan legge opp en innlevering, sånn at dere kan... Sånn frivillig levere inn og få tilbake... Tilbakemeldinger på det som er 'obliger'. Hvis det er noe interesse for det, si gjerne ifra, så kan vi prøve å få til en sånn ordning, så dere får tilbakemelding på samme måte som dere har fått på de virkelig obligatoriske oppgavene. Men altså - opp til altså oppgaver til og med uke tolv er obligatoriske.", "source": "lecture"}
{"lecture_id": "os8del1", "chunk_id": "os8del1_0000", "start": 0.0, "end": 90.8, "token_count": 295, "text": "Forrige uke var det... Komte uke, så jeg håper at... Mange av dere klarte å ta inn det tapte hvis dere lå litt tilbake. For det har vært ganske... Ganske intenst, egentlig, de første ukene. Vi har på en måte kommet litt lenger enn vi var i fjor. Så det kommer nok... Det er en hard periode nå i dette kurset. Mye roligere etter påske, sånn... Vi har bare satt opp undervisning fram til uke 16. Det er mulig vi da får ganske mye tid til å se på tidligere eksamensoppgaver og så fordøye det stoffet vi har lært. Så da blir det litt mindre trykk mot slutten av kurset. Men her vi er nå, så har vi begynt med en container. Der ligger det en forelesning ute. Jeg hadde i hvert fall tenkt å dele den opp i litt mer deler, sånn at dere kan se på enkeltdeler. Men det er en ganske sakte, rolig, systematisk måte å begynne i praksis med containere, spesielt med dokkercontainere, Og kjøre de på de VM-ene som dere har.", "source": "lecture"}
{"lecture_id": "os8del1", "chunk_id": "os8del1_0001", "start": 70.8, "end": 166.72, "token_count": 298, "text": "sånn at dere kan se på enkeltdeler. Men det er en ganske sakte, rolig, systematisk måte å begynne i praksis med containere, spesielt med dokkercontainere, Og kjøre de på de VM-ene som dere har. Så dokker er noe vi skal jobbe mye med de neste ukene. Jeg får se hvor langt vi kommer i dag. Men jeg tenkte kanskje å bruke litt tid på å se på de første oppgavene denne uken, som går nettopp på dette her, med å kjøre Hello World på dokker og starte opp. Og så, i løpet av dagen, komme frem til det å kunne starte opp en dokkecontainer som kjører en webserver på Linux-VM-en deres. Tidligere så har dere kjørt en webserver direkte på Linux-VM, men nå skal dere kjøre en dokkecontainer inni Linux-VM som kjører en webserver. Så det er en del ting der som kan være litt forvirrende. Jeg skal prøve å sette av litt tid mot slutten i dag, og så kan vi gå inn og se på de oppgavene og se hvordan det er tenkt det skal være. Men ellers så er hovedfokus i dag på scheduling", "source": "lecture"}
{"lecture_id": "os8del1", "chunk_id": "os8del1_0002", "start": 141.44, "end": 245.04, "token_count": 286, "text": "som kjører en webserver. Så det er en del ting der som kan være litt forvirrende. Jeg skal prøve å sette av litt tid mot slutten i dag, og så kan vi gå inn og se på de oppgavene og se hvordan det er tenkt det skal være. Men ellers så er hovedfokus i dag på scheduling og hvordan et operativsystem egentlig virker.  Altså hele det store bildet av operativsystemet, hvordan det styrer alle prosesser som kjører på en maskin. Vi har sett en del i praksis sånn som... Med multitasking og multitredding som vi holdt på med forrige gang... Hvordan operativsystemet da fordeler prosesser på... Og så hvordan et operativsystem deler inn tiden og lar én og én prosess kjøre. Men det er en del problemstillinger som vi ikke har sett på, spesielt hvordan man i praksis kan få til dette her. For der er det en del tilfeller hvor operativsystemet er nødt til å ha hjelp Og ha egne instruksjoner for å kunne kontrollere prosessene. Hvis vi tenker tilbake på dette med prosess, som er et levende liv,", "source": "lecture"}
{"lecture_id": "os8del1", "chunk_id": "os8del1_0003", "start": 217.64, "end": 311.52, "token_count": 292, "text": "spesielt hvordan man i praksis kan få til dette her. For der er det en del tilfeller hvor operativsystemet er nødt til å ha hjelp Og ha egne instruksjoner for å kunne kontrollere prosessene. Hvis vi tenker tilbake på dette med prosess, som er et levende liv, så tenker vi oss nå at vi har tusenvis av levende liv innenfor en datamaskin. Og så skal operatørsystemet nå holde orden på alle de tusen. Enkelte liv, altså prosesser, må fryses helt. Alt må lagres. Og så må man sette i gang andre prosesser. Og samtidig så må man sørge for at de ikke ødelegger for hverandre. Og det er de problemstillingene vi skal se på i dag. Så ser vi at det også står vaffelrøre på programmet i dag. Og det er da en simulering som jeg har lagd av hvordan... Rett og slett hvordan et operativsystem virker. Og det... Et operativsystem kan kjøre to prosesser samtidig på samme CPU. Og det er det jeg har illustrert med den vaffelrøre-videoen som ligger ute.", "source": "lecture"}
{"lecture_id": "os8del1", "chunk_id": "os8del1_0004", "start": 284.8, "end": 372.98, "token_count": 293, "text": "Og det er da en simulering som jeg har lagd av hvordan... Rett og slett hvordan et operativsystem virker. Og det... Et operativsystem kan kjøre to prosesser samtidig på samme CPU. Og det er det jeg har illustrert med den vaffelrøre-videoen som ligger ute. Her så er jeg da... Jeg er på en måte... Jeg er en CPU. Og så tenker jeg at jeg skal både holde forelesning og lage vaffelrøre samtidig. Og da må jeg jo switche mellom de to oppgavene. Og da har jeg prøvd å gjøre det på en veldig systematisk måte, nemlig med å kjøre et operativsystem som styrer de to prosessene, som kjører da på meg. Og operativsystemet kjører også da på meg. Og da... Ja, vi kan komme litt mer tilbake til det på slutten. Kanskje vi setter av litt tid også, sånn at vi kan se på den. Men det er altså en... Skal vi se... For de som syns forelesningen blir kjedelig, så kan dere hoppe og så se på den videoen. Ja. Da ønsker jeg velkommen til denne.", "source": "lecture"}
{"lecture_id": "os8del1", "chunk_id": "os8del1_0005", "start": 345.28, "end": 434.9, "token_count": 289, "text": "Og da... Ja, vi kan komme litt mer tilbake til det på slutten. Kanskje vi setter av litt tid også, sånn at vi kan se på den. Men det er altså en... Skal vi se... For de som syns forelesningen blir kjedelig, så kan dere hoppe og så se på den videoen. Ja. Da ønsker jeg velkommen til denne. Vi skal ikke kjøre denne her, men dere ser jeg har et operativstem. Og så lager jeg vafler og holder forelesning samtidig. Dette ligger veldig tett opp til scheduleren i versjon 2.6 i Linux-kjernen. Så det er en litt eldre kjerne. I dag ser scheduleren litt annerledes ut. Men hovedideen er å få vist prinsippene. Så... Men vi kommer tilbake til det mot slutten av forelesningen. Først skal vi se på noen av de tingene som er viktige. For i det hele tatt å få til dette her. Og da er det spesielt prosessormodus. Og så er det trap og systemcall. Det er også en viktig ingrediens i det å lage et operativsystem. Aller først skal vi se på litt...", "source": "lecture"}
{"lecture_id": "os8del1", "chunk_id": "os8del1_0006", "start": 411.64, "end": 447.0, "token_count": 102, "text": "For i det hele tatt å få til dette her. Og da er det spesielt prosessormodus. Og så er det trap og systemcall. Det er også en viktig ingrediens i det å lage et operativsystem. Aller først skal vi se på litt... Noe som egentlig henger mer sammen med det vi holdt på med forrige gang med multitasking. Én prosess ikke kan utnytte tosepur.", "source": "lecture"}
{"lecture_id": "linux8del9", "chunk_id": "linux8del9_0000", "start": 0.0, "end": 114.42, "token_count": 297, "text": "Så nå har vi på en måte fått et veldig kraftig verktøy. Vi ser her nå... Jeg kan stoppe den her. B5. Det var faktisk flere med B5. Eksplisitt stoppe en sånn, da. Nå stopper jeg den... Da ser vi... Ved å bygge denne konteineren med følgende dokkefil, så har vi nå en konteiner som tar det innholdet vi ønsker, installerer Apache 2 og kjører den ned i forgrunnen. Det vi gjorde, var bare å bygge den sånn. Nå er denne ferdigbygd. Her har vi en fiks ferdig oppskrift, så nå er det bare for den som ønsker det å starte konteineren på den måten her. Og vips... På omtrent no time så har vi da en kjørende konteiner. Og da sier vi at nå er det veldig mye lettere å starte en til som kjører på 80-82. Sånn som det. Eller tre sykler, for den saks skyld. Hvis jeg nå går til 8082, så ser vi... Der har jeg også en container som kjører. 8083. Har jeg en annen webserver osv.?", "source": "lecture"}
{"lecture_id": "linux8del9", "chunk_id": "linux8del9_0001", "start": 81.68, "end": 131.96, "token_count": 145, "text": "Og da sier vi at nå er det veldig mye lettere å starte en til som kjører på 80-82. Sånn som det. Eller tre sykler, for den saks skyld. Hvis jeg nå går til 8082, så ser vi... Der har jeg også en container som kjører. 8083. Har jeg en annen webserver osv.? 84. Den hadde jeg ikke startet. Så vi ser på det. På denne måten at jeg er ekstremt hurtig å starte å kjøre konteinere. Nå har jeg tre konteinere som står og kjører.", "source": "lecture"}
{"lecture_id": "os12del8", "chunk_id": "os12del8_0000", "start": 0.0, "end": 93.8, "token_count": 297, "text": "Så i praksis så brukes som oftest hardwaystøttede løsninger. Og en sånn hardwaystøttet løsning kan lages hvis man har en institusjon som f.eks. TestAndSet TSL. Det er da en institusjon som gjør begge de to operasjonene som vi snakket om på forrige slide. Å teste verdien og endre den, i én og samme institusjon. Det er viktig at det er én og samme institusjon, for det gjør at det ikke kan komme en kontekst-switch mens dens institusjon utføres. En TestAnset vil i tillegg låse minnebussen, bussen ut av ramm, sånn at ikke andre CPU-er kan lese verdien. Da kan man implementere GetMuteX på følgende måte... Man har da Wile test-and-set lock. Og denne operasjonen, det er bare da én institusjon. Og midt inni den institusjonen så kan det ikke komme en context switch. Og siden den i tillegg låser minnebussen, så er man da bombesikker på at bare denne prosessen kommer inn i kritiske avsnitt av gangen. En perfekt løsning.", "source": "lecture"}
{"lecture_id": "os12del8", "chunk_id": "os12del8_0001", "start": 68.44, "end": 163.36, "token_count": 285, "text": "Og denne operasjonen, det er bare da én institusjon. Og midt inni den institusjonen så kan det ikke komme en context switch. Og siden den i tillegg låser minnebussen, så er man da bombesikker på at bare denne prosessen kommer inn i kritiske avsnitt av gangen. En perfekt løsning. Vi så forrige gang på X86-institusjonen LOC. Og det... Den LOC-institusjonen, den utføres før en kritisk institusjon. Den koden vi hadde sist, var at vi først hadde LOC, og så hadde vi en ad, eller en ink.  Og den gjør at man låser av minnebussen, sånn at ingen andre CPU-er heller får endre den verdien... Den minneadressen som man bruker. Alle andre minneadresser kan brukes, men ikke akkurat den. Så det sikrer da at institusjonen etterlokker. Den vil være den eneste som kan endre på den variabelen som kommer etter lock-instruksjonen. Og dette sørger da for at det kritiske avsnittet fullføres uten at noen andre tråder kommer inn.", "source": "lecture"}
{"lecture_id": "os12del8", "chunk_id": "os12del8_0002", "start": 139.0, "end": 203.92, "token_count": 231, "text": "Så det sikrer da at institusjonen etterlokker. Den vil være den eneste som kan endre på den variabelen som kommer etter lock-instruksjonen. Og dette sørger da for at det kritiske avsnittet fullføres uten at noen andre tråder kommer inn. Men det er klart, dette fungerer bare hvis det kritiske avsnittet kun er én enkel institusjon. Men det kan det ofte være. Man kunne i prinsippet bruke en sånn lock-instruksjon til å lage En Mutex, men da bruker man heller Test-and-Set-institusjonen. Og Test-and-Set-institusjonen er også en X86-institusjon. Hvis man skal lese om dette, så kan man slå opp i Intels X86-manual. Der står det om hvordan denne lokkinstitusjonen låser av... Låser av bussen og hindrer at noen andre endrer på verdi.", "source": "lecture"}
{"lecture_id": "os1del10", "chunk_id": "os1del10_0000", "start": 0.0, "end": 65.02, "token_count": 211, "text": "Nyttepersoner, jeg viste frem studentassistentene. I tillegg har vi Taiba, som jobber med Linux-drift. Her på vårt institutt. På Institutt for informatikk. Og hun styrer spesielt med Linux-drift. Stud.SSH, for eksempel. Eller gjerne allerede nå, skal logge dere inn på. Der vet jeg det har vært en del trøbbel med studiesesong. Så det er egentlig fint om vi kan teste ut i laben. Det vil jo da være oppgaven til neste uke, men test gjerne ut allerede nå om dere klarer å logge inn på studiesesong, om det er noen problemer rundt det. Hvis det er store problemer med det, så skal vi prøve å sette opp disse virtuelle maskinene litt tidligere. Jeg kan bruke dem allerede nå de første ukene.", "source": "lecture"}
{"lecture_id": "os1del3", "chunk_id": "os1del3_0000", "start": 0.0, "end": 95.96, "token_count": 296, "text": "Når vi er inne på forelesninger, så ser vi her også ligger det emneevalueringer. Og det pleier instituttlederen min å si at det må jeg alltid si fra om og fortelle om. Og det kan være nyttig å lese for dere sånn fra hva studentene sa i fjor. Så her står det litt om tilbakemelding fra emneevalueringen. Og det som ja, kanskje mange sier, er at... Vi kan jo se sånn som her. 54 % mener at pensumet er for stort eller litt for stort. Så dette kurset er nok litt omfattende. Men samtidig så tenker jeg at man... Det er mye matnyttig. Det er også en del tilbakemeldinger på at de søker på sommerjobb eller jobb, for den saks skyld. At de sitter igjen med mye som er konkret og matnyttig fra dette kurset. Så derfor har nok kurset blitt relativt omfattende. Men det er jo ikke alt som er like viktig. Så det som er viktig, er at dere sitter igjen med... De vesentlige delene av kurset. Og det er ikke nødvendigvis så omfattende.", "source": "lecture"}
{"lecture_id": "os11del7", "chunk_id": "os11del7_0000", "start": 0.0, "end": 82.32, "token_count": 285, "text": "Hva er meningen med tråder hvis det ikke har så mye å si hvordan prosessene kjøres? Jeg antar tanken er da... Sånn som Java. Java på Linux hvis den ikke tar hensyn til prioriteten. Vel, det... Vanligvis så har alle tråder samme prioritet. Og det fungerer i de aller fleste tilfeller helt greit. Fordi operativsystemet er så bra til å skredulere. De fordeler ressurser, og som vi har sett, er operativsystemet veldig bra til å gi respons til prosesser som ønskerespons fra et tastetrykk, f.eks. Så får den lynraskt den responsen. Så hovedgrunnen til at man ikke har tatt så nøye på implementering av prioritet sånn som i Java, er at operativsystemet gjør den jobben. Veldig bra. Og det er likevel mange fordeler. En av de største er at prosessen slipper å vente. Du kan ha en tråd som står og venter på input-upput. Og ikke minst så kan du utnytte flere CPU-er. Hvis du har en server med 48 CPU-er, så er det helt strålende", "source": "lecture"}
{"lecture_id": "os11del7", "chunk_id": "os11del7_0001", "start": 66.56, "end": 89.72, "token_count": 97, "text": "En av de største er at prosessen slipper å vente. Du kan ha en tråd som står og venter på input-upput. Og ikke minst så kan du utnytte flere CPU-er. Hvis du har en server med 48 CPU-er, så er det helt strålende å kunne sette i gang 48 tråder som jobber i parallell på dem og utnytter ressursene.", "source": "lecture"}
{"lecture_id": "linux7del2", "chunk_id": "linux7del2_0000", "start": 0.0, "end": 109.54, "token_count": 291, "text": "Men vi skal se på hva er... Hva er dere? Ja. Igjen tar vi utgangspunkt i... Dette er Prakmas utgangspunkt, med at man har en developer som sitter her oppe øverst i diagrammet og skal skrive kode, som så skal bygges og kjøres. Og da, som sagt, i motsetning til å ha store releaser, som er hvert halvår eller festival hver måned, så releases fortløpende kode fra developeren. Og kjører gjennom hele kjeden her. Inkludert automatiske tester. Og da gjør det å bruke containere... Det gjør dette mye enklere. Det er det som kanskje muliggjør dette i det hele tatt. Derfor er det en sentral del i Continues Delivery. Ideen med konteinere i det hele tatt er den samme som på konteinerskip. At man skal lage en enhet, en liten server, som passer sammen. Her oppe er det dokker. Konteinerne er bygd sånn at de lett kan stables oppå hverandre. Det er også ideen med dokker i dataverden. Man kan få en liten enhet og sette den til å kjøre hvor som helst.", "source": "lecture"}
{"lecture_id": "linux7del2", "chunk_id": "linux7del2_0001", "start": 80.24, "end": 187.22, "token_count": 292, "text": "At man skal lage en enhet, en liten server, som passer sammen. Her oppe er det dokker. Konteinerne er bygd sånn at de lett kan stables oppå hverandre. Det er også ideen med dokker i dataverden. Man kan få en liten enhet og sette den til å kjøre hvor som helst. I motsetning til tidligere tider, hvor man hadde store servere som kjørte i maskinrom. De var veldig vanskelig å endre på. Og ikke minst var det vanskelig for utviklere å utvikle kode som fungerte, på mange forskjellige typer servere. Nå er alt det forenklet enormt ved hjelp av Datagym. Vi kommer nok litt mer til å se på bakgrunnen for dere litt mer teoretisk etter hvert. Hvordan den kan brukes. Det er en del begreper her. Det vi skal konsentrere oss om, er Docker Engine. Som på en måte er den installasjonen vi har gjort på Linux-VM-ene. Vi har allerede installert dokker, så for dere skal det bare være å logge inn på Linux-VM. Da kan dere bare kjøre dokker. Det skal vi se på i første praktiske del.", "source": "lecture"}
{"lecture_id": "linux7del2", "chunk_id": "linux7del2_0002", "start": 158.16, "end": 243.98, "token_count": 242, "text": "Det vi skal konsentrere oss om, er Docker Engine. Som på en måte er den installasjonen vi har gjort på Linux-VM-ene. Vi har allerede installert dokker, så for dere skal det bare være å logge inn på Linux-VM. Da kan dere bare kjøre dokker. Det skal vi se på i første praktiske del. I tillegg har man dokkerhub. Det er etter hvert veldig viktig. Det skal vi se mer på i neste uke. Det er litt sånn som github, hvor man kan laste ned kode til prosjekter. På dokkerhub kan man laste ned hele servere og hele systemer som dokker-images. Og så kan man kjøre det. Det er det som skjer når man kjører dokker Hello World, som er det første vi skal gjøre. Da lastes det ned et lite image. Og så kjøres det på lokalmaskin. Så er det dokkemaskin og dokke-composed. Det er begreper som vi ikke kommer Styre litt større systemer.", "source": "lecture"}
{"lecture_id": "linux6del12", "chunk_id": "linux6del12_0000", "start": 0.0, "end": 89.96, "token_count": 291, "text": "Det kan være at man ønsker å få skriptkjørt regelmessig. For eksempel så kan jeg lage et scriptsync.shell hvor jeg bruker en rsync-kommando. Rsync minus a, og ikke minus r, som det er på SEP. Denne rsync-kommandoen tar kopi av min mappe på OS100. Og legger den på lokalt på dette systemet. I tillegg ser vi at jeg legger til en liten linje, backup tatt og hvilken dato tidspunktet ble tatt på, til en loggfil. Og da kunne jeg ønske at du kunne kjøre den med emnet mellomrom, f.eks. hver natt. Og til dette så kan man bruke kron. Kron er en egen bakgrunn. En bakgrunnsprosess, en demon som står og går, og som styrer såkalte kronjobber, som kjøres i kronologisk orden med jevne mellomrom. For å legge inn en sånn jobb i kron, så bruker man en kommando som heter krontab. Krontab minus e for edit, da får man opp en fil som man kan editere. Og nederst i den så ser vi at jeg allerede har lagt inn...", "source": "lecture"}
{"lecture_id": "linux6del12", "chunk_id": "linux6del12_0001", "start": 64.08, "end": 158.04, "token_count": 285, "text": "og som styrer såkalte kronjobber, som kjøres i kronologisk orden med jevne mellomrom. For å legge inn en sånn jobb i kron, så bruker man en kommando som heter krontab. Krontab minus e for edit, da får man opp en fil som man kan editere. Og nederst i den så ser vi at jeg allerede har lagt inn... Sync.shell. Her i Krontab så kan man ikke bruke Tilde, så man må bruke full path til skript man kjører. Disse stjernene i starten, det er en kode for hvor ofte et skript skal kjøres. Hvis jeg f.eks. setter inn 5 her på den første, så er det... Det er minutt. Så denne vil... Dette vil si at denne jobben vil kjøres hver gang antall minutter er fem. Altså det vil da bli fem år tolv, fem år vett, fem år to osv. Hvis jeg setter på én for time her, så vil det da kjøre på tidspunktet 01.00. Hvis jeg bare har stjerner, så ville default kjøre hvert eneste minutt hele døgnet.", "source": "lecture"}
{"lecture_id": "linux6del12", "chunk_id": "linux6del12_0002", "start": 133.8, "end": 235.76, "token_count": 295, "text": "Altså det vil da bli fem år tolv, fem år vett, fem år to osv. Hvis jeg setter på én for time her, så vil det da kjøre på tidspunktet 01.00. Hvis jeg bare har stjerner, så ville default kjøre hvert eneste minutt hele døgnet. Så kan man også sette på day of month, altså hvilken dag, osv. Det som kanskje er enklest er måten å finne ut det på hvis man har en spesiell tidspunkt eller antall ganger om dagen osv. I notatene står det en link til en webside som man lett kan få til hvilken som helst frekvens på å kjøre dette skriptet. Vi kan teste dette skriptet nå. Nå har jeg satt opp frekvens hvert minutt. Når man saver den filen, så ser man at man kommer opp krontab. Og da kan jeg ta en tale minus F på... Kanskje se på klokkeslettet først. Nå er det 3.3.13. Da tror jeg det snart skal skrives en ny. Den loggen het sync.log. Nå har jeg en tale på den, og der så vi at 33.32...", "source": "lecture"}
{"lecture_id": "linux6del12", "chunk_id": "linux6del12_0003", "start": 210.0, "end": 316.04, "token_count": 274, "text": "Og da kan jeg ta en tale minus F på... Kanskje se på klokkeslettet først. Nå er det 3.3.13. Da tror jeg det snart skal skrives en ny. Den loggen het sync.log. Nå har jeg en tale på den, og der så vi at 33.32... Så ble en ny backup tatt. Og da kan vi også prøve å se... Hvis jeg nå lager en ny fil her... På OS100, så skal kronjobben gå, og så skal den snart legge til ny fyll. Den går da hvert minutt. Så den har ennå ikke gått. 34,11. Da betyr det at om ja, 15 sekunder omtrent, så vil kronejobben gå enda en gang. Dette er jo kanskje litt høy frekvens, så... Men man kunne godt sette opp en gang hver time. Der så vi. Og så kan vi se om den har gjort det den skulle, nemlig å oppdatere. Ja, det ser vi at jeg har fått til. Da har jeg fått over ny fil. Og på denne måten kan man sette opp et backup-system.", "source": "lecture"}
{"lecture_id": "os13del16", "chunk_id": "os13del16_0000", "start": 0.0, "end": 95.32, "token_count": 294, "text": "TelB, Translation Look-Aside Buffer, det er en viktig bit. Og i CPU-en så har vi L1 og L2 Cash for ramm. Men da snakker vi hele tiden om kode og variabler. Men vi har det samme for MMU, fordi MMU må gå så raskt. Så har man TLB, som er en cashbit spesielt for MMU-adressene. Og som et eksempel, da... Hvis man har en prosess som bruker 100 MB, så vil det gi 4 kB med sider. Nei, så vil det med 4 kB sider... Altså med 1 lik 12. Så har vi 4 kB størrelse på sidene. Det vil bety omtrent 25 000 sider, så vi ser det blir fort veldig mange... En sånn topp-L blir fort veldig stor. En 4 GB-prosess har 1 mill. sider i MMU. Og da får man ikke plass til å lagre dette inne i CPU-en. Der er det bare et begrenset antall registre. Så dermed så vil MMU være med også da... Den vil i utgangspunktet ligge i ramm, men så vil du ha noe i cash. TLB-en er da den innerste delen av cashen", "source": "lecture"}
{"lecture_id": "os13del16", "chunk_id": "os13del16_0001", "start": 73.12, "end": 160.32, "token_count": 288, "text": "Og da får man ikke plass til å lagre dette inne i CPU-en. Der er det bare et begrenset antall registre. Så dermed så vil MMU være med også da... Den vil i utgangspunktet ligge i ramm, men så vil du ha noe i cash. TLB-en er da den innerste delen av cashen som de... som er raskest å treffe. Så TLB er... er da hurtigcash for MEU. Og den vil da bare inneholde en bitte liten del av pagedabellen, men heldigvis er det ofte den som treffes på. Akkurat som med annen type cash. Bruker man ofte de samme sidene om og om igjen, sånn at da treffer man ofte på den oversettelsen. Hvis man ber om en adresse som ikke ligger i TLB, så får man en såkalt TLB-miss eller en soft-miss. Det tar vesentlig lengre tid enn om den ligger i TLB, for da må man ut lenger ut i cash, eventuelt helt ut i ramm for å hente denne siden. Dette er bare noen eksempler på sånn typisk TLB-ytelse. Størrelse... En cash-linje...", "source": "lecture"}
{"lecture_id": "os13del16", "chunk_id": "os13del16_0002", "start": 139.88, "end": 216.2, "token_count": 281, "text": "Det tar vesentlig lengre tid enn om den ligger i TLB, for da må man ut lenger ut i cash, eventuelt helt ut i ramm for å hente denne siden. Dette er bare noen eksempler på sånn typisk TLB-ytelse. Størrelse... En cash-linje... Det er der en bit av cash... Altså den minste biten av cash er typisk på 64 bytes. Og TLB-er kan være sånn mellom 16 000 og 4000 linjer. Eller mellom 1 og 256 kilobytes. Så det er relativt... Men det som er viktig, oppslagstiden er ekstremt hurtig. Dere kan gå i underkant av en klokkesykkel og slå opp. Det er hardware-kablet, så man gjør ikke noen instruksjoner og regner noe. Man kabler adressene direkte. Hvis det er en TLBM-miss, så kan det fort gå mange klokkesykler for å hente den, avhengig av om den er i cash eller i ram. Det som er veldig fint med dette, er at TLB-misfrekvensen statistisk er veldig liten.", "source": "lecture"}
{"lecture_id": "os13del16", "chunk_id": "os13del16_0003", "start": 197.4, "end": 269.0, "token_count": 292, "text": "Man kabler adressene direkte. Hvis det er en TLBM-miss, så kan det fort gå mange klokkesykler for å hente den, avhengig av om den er i cash eller i ram. Det som er veldig fint med dette, er at TLB-misfrekvensen statistisk er veldig liten. Stort sett så bruker man de samme adressene om og om igjen, og de ligger da i TLB. Så noe sånt som dette her kan det se ut. Vi har sett tidligere at vi har level 2-cash også level 3-cash inne på prosessoren. Og så har vi Ram her ute. Så tidligere har vi sett at vi har... LN-cash for data og for instruksjoner. Sånn at når... Ofte så henter man de samme instruksjonene, de samme dataene, om og om igjen, og det ligger veldig nære CPU-en, og dermed går det tigangs så raskt som om man skulle hente det ut til dem. Helt det samme er det for MMU. Og da har vi en telbeg LN-cash her inne. Og dette er telbn som vi snakker om. Her ligger hurtigoppslagene for...", "source": "lecture"}
{"lecture_id": "os13del16", "chunk_id": "os13del16_0004", "start": 250.0, "end": 283.0, "token_count": 135, "text": "de samme dataene, om og om igjen, og det ligger veldig nære CPU-en, og dermed går det tigangs så raskt som om man skulle hente det ut til dem. Helt det samme er det for MMU. Og da har vi en telbeg LN-cash her inne. Og dette er telbn som vi snakker om. Her ligger hurtigoppslagene for... Så 99 % av tilfellene så treffer man på et LB, og da går oversettelsen fra virtuelt minne til fysisk minne veldig raskt.", "source": "lecture"}
{"lecture_id": "linux8del2", "chunk_id": "linux8del2_0000", "start": 0.0, "end": 94.84, "token_count": 279, "text": "Jo, for det første så gjør det det enkelt å sette opp og kopiere et helt driftsmiljø. Hvis man har en applikasjon som man skal utvikle, så kan man sette opp hele det miljøet med nøyaktig riktige versjoner av kompulator, bibliotek osv.. Den som skriver koden, kan da enkelt teste ut koden, at den virker som den skal, i en kopi av det miljøet som faktisk skal kjøre koden. Man kan ikke teste i produksjon direkte, for da kan du risikere å stoppe hele produksjonsmiljøet. Men samtidig er det... veldig oppsiktsvekkende. Når en utvikler testekoden sin, så kjøres den i et miljø som ikke er helt lik driftsmiljøet. Da blir det mye vanskeligere å teste, og det blir en mye større prosess å committe kode. Og få den til å kjøre. Vi har ikke sett så mye på det, men vi skal se litt mer på... Og det kanskje allerede neste uke. Virtuelle maskiner og VM-er.", "source": "lecture"}
{"lecture_id": "linux8del2", "chunk_id": "linux8del2_0001", "start": 60.0, "end": 154.2, "token_count": 300, "text": "Når en utvikler testekoden sin, så kjøres den i et miljø som ikke er helt lik driftsmiljøet. Da blir det mye vanskeligere å teste, og det blir en mye større prosess å committe kode. Og få den til å kjøre. Vi har ikke sett så mye på det, men vi skal se litt mer på... Og det kanskje allerede neste uke. Virtuelle maskiner og VM-er. Men dere har jo fått virtuelle maskiner som dere kjører, Linux-VM-er. Og mange av dere har også installert Windows-VM-er med version-boks. Og det er på en måte en annen måte å sette opp et helt stort miljø, som kan være nøyaktig likt driftsmiljøet. Da må du ha for hver maskin, for hver virkuell maskin, så må du ha hele operativsystemet. Og det er veldig omfattende. Det er digert i forhold til containere. Containere er små og raske å starte og stoppe. Og det skyldes rett og slett at hvis du kjører ti Linux-containere på én maskin, sånn som... Oppgaven denne og forrige uke går ut på.", "source": "lecture"}
{"lecture_id": "linux8del2", "chunk_id": "linux8del2_0002", "start": 128.3, "end": 226.02, "token_count": 294, "text": "Det er digert i forhold til containere. Containere er små og raske å starte og stoppe. Og det skyldes rett og slett at hvis du kjører ti Linux-containere på én maskin, sånn som... Oppgaven denne og forrige uke går ut på. Så bruker alle de ti konteinerne det samme underliggende operativsystemet. Da sparer man masse ressurser i forhold til om man skulle kjøre ti virtuelle maskiner. For da ville hver enkelt virtuelle maskin ha hele Ubuntu-operativsystemet, hvis man brukte Ubuntu. Og det krever veldig mye mer ressurser å... Både minne og... Se spesielt til minne. En annen grunn til, eller kanskje en av de viktigste grunnene til at dokker har blitt så populært og så mye brukt, er at det er en viktig del av continuous delivery og continuous development. Historisk så var det sånn at for ca. 20 år siden, rundt år 2000, så ble alt drift... Da hadde man serverrom hvor fysiske servere hadde applikasjoner som så kjørte. Da kunne det være både webservere og databaser på samme fysiske server.", "source": "lecture"}
{"lecture_id": "linux8del2", "chunk_id": "linux8del2_0003", "start": 193.84, "end": 291.34, "token_count": 287, "text": "er at det er en viktig del av continuous delivery og continuous development. Historisk så var det sånn at for ca. 20 år siden, rundt år 2000, så ble alt drift... Da hadde man serverrom hvor fysiske servere hadde applikasjoner som så kjørte. Da kunne det være både webservere og databaser på samme fysiske server. Men felles for alle var at det var veldig tungt å drifte. Hvis man skulle oppgradere eller vedlikeholde, så var det en stor prosess. Så kom man med oppdateringer en gang i halvåret, maks en gang i måneden. Kanskje noen kom en gang i året med oppdateringer av applikasjoner. Fordi det var en stor prosess å sette det opp og teste osv. Og ikke minst å kopiere driftsmiljøet og gjøre reelle tester av programmene. Men så kom... Nå har det kommet en revolusjon med DevOps, som er et tettere samarbeid mellom Development Operations. Altså mellom de som utvikler og de som drifter programvåret. For 20 år siden var det sånn at de var to helt atskilte miljøer", "source": "lecture"}
{"lecture_id": "linux8del2", "chunk_id": "linux8del2_0004", "start": 270.02, "end": 359.56, "token_count": 297, "text": "Nå har det kommet en revolusjon med DevOps, som er et tettere samarbeid mellom Development Operations. Altså mellom de som utvikler og de som drifter programvåret. For 20 år siden var det sånn at de var to helt atskilte miljøer som samarbeidet veldig lite. Programmererne var fornøyd når de hadde fått ferdig koden, og så sendte den til drift, som så skulle drifte. Men det førte med seg en enorm rekke med problemer når man deployer, setter i gang nye systemer og skal gjøre det. Og dermed så kom det et nytt mantra, som var på at man skulle kunne committe kode mye oftere. Ti ganger om dagen var liksom det første målet som man hadde. Og for 20 år siden så var det nærmest utenkelig. Men i dag så er dette hverdagen i veldig mange bedrifter, og spesielt store, moderne bedrifter som Google og Facebook osv. De bruker dette hele tiden. At hver gang en utvikler... lager noe nytt, så blir det automatisk, i veldig stor grad automatisk testet i driftsmiljø. Men da er det i driftsmiljø.", "source": "lecture"}
{"lecture_id": "linux8del2", "chunk_id": "linux8del2_0005", "start": 335.76, "end": 460.0, "token_count": 298, "text": "og spesielt store, moderne bedrifter som Google og Facebook osv. De bruker dette hele tiden. At hver gang en utvikler... lager noe nytt, så blir det automatisk, i veldig stor grad automatisk testet i driftsmiljø. Men da er det i driftsmiljø. Kua er også en del av det. Alt foregår automatisk. Docker, eller containere, er en veldig viktig del av hele det løpet med å levere kode kontinuerlig. Det er å sette opp store, komplekse systemer med kubernetis. Kubernetis er en måte å orkestrere eller sette opp komplekse systemer ved hjelp av dokker og konteinere. I en kubernetis kalles det pods. Det er et system av én eller flere dokkerkonteinere som kjører innen Dette ble også mye brukt, eller nærmest eksplodert, i bruk av containere. Og spesielt Kubernetes. Et eksempel på dette, som jeg nevnte sist, er finn.no. Og neste slide er hentet fra en bloggpost fra en som jobber i Finn. Vi ser at det er et ganske... Det er et ganske komplekst system som de har i Finn.", "source": "lecture"}
{"lecture_id": "linux8del2", "chunk_id": "linux8del2_0006", "start": 420.0, "end": 526.76, "token_count": 285, "text": "Dette ble også mye brukt, eller nærmest eksplodert, i bruk av containere. Og spesielt Kubernetes. Et eksempel på dette, som jeg nevnte sist, er finn.no. Og neste slide er hentet fra en bloggpost fra en som jobber i Finn. Vi ser at det er et ganske... Det er et ganske komplekst system som de har i Finn. De bruker en rekke forskjellige verktøy. Vi ser nederst her infrastrukturen, hvor de bruker både cloud, men også open sack lokalt. Men det som er kjernen i det hele, som vi ser her, Utviklerne som sitter her oppe og bruker alle disse verktøyene. Den typiske strømmen er at de committer til Github. Og så både testes og kjøres konen deres i dockercontainere. Og alt dette her er da typisk orkestrert med kybernetis. Allerede i dag så er det ganske vanlig å komme ut i bedrifter som bruker dere, og det kommer helt sikkert til å øke kontinuerlig. Så det var den lange forklaringen på hvorfor vi snakker om dere.", "source": "lecture"}
{"lecture_id": "linux8del2", "chunk_id": "linux8del2_0007", "start": 499.64, "end": 538.0, "token_count": 114, "text": "Og alt dette her er da typisk orkestrert med kybernetis. Allerede i dag så er det ganske vanlig å komme ut i bedrifter som bruker dere, og det kommer helt sikkert til å øke kontinuerlig. Så det var den lange forklaringen på hvorfor vi snakker om dere. Men det er generelt fornuftig å stille den type spørsmål. Hvorfor holder vi på med akkurat det vi gjør?", "source": "lecture"}
{"lecture_id": "os1del13", "chunk_id": "os1del13_0000", "start": 0.0, "end": 88.86, "token_count": 285, "text": "Det vi avslutter med, var å vise at operativsystemet forenkler. Hardware er fryktelig komplekst. Så én viktig hovedoppgave for systemet, er å forenkle grensesnittet fra brukerprogrammer mot Hardware. Men det er en annen oppgave også som er veldig viktig, og det er å... Mellom de forskjellige programmene og mellom de forskjellige brukerne. Det er en annen viktig hovedside. Her er et forsøk på en OUS-definisjon. Det er at et operativsystem er programvarer hvis hensikt er to ting. A. Gi applikasjonsprogrammer og brukere enhetlige, enklere og mer abstrakt adgang til maskinens ressurser. Så det er det vi så på med forrige med beautiful and ugly interface. De som skriver et applikasjonsprogram, skal ikke behøve å ta hensyn til detaljene ned i Hardware. Det fikser operativ systemet. Så det er én viktig del. Men så er det altså del B. Administrer ressurser, slik at prosesser og brukere ikke ødelegger for hverandre.", "source": "lecture"}
{"lecture_id": "os1del13", "chunk_id": "os1del13_0001", "start": 73.22, "end": 178.96, "token_count": 300, "text": "skal ikke behøve å ta hensyn til detaljene ned i Hardware. Det fikser operativ systemet. Så det er én viktig del. Men så er det altså del B. Administrer ressurser, slik at prosesser og brukere ikke ødelegger for hverandre. Hvis en prosess gjør en eller annen jobb og får noe inn i minnet som den skal ta vare på og bruke senere, kan ikke en annen prosess komme inn og skrive over eller ødelegge noe av det den har. Den andre brukeren bruker. En prosess tar over all CPU på maskinen. Det vil også gå dårlig hvis ikke operativstemmen sørger for å fordele CPU-tip. Eller som det står i eksemplene her, et filsystem. Som brukes til å gi alle brukere og prosesser atskilt adgang til å lagre på disken. Da må opplagt ikke de kunne overskrive for hverandre. Prinsippskisse av Linux. Tidligere hadde vi et enkelt grensesnitt, og vi hadde operativsystemkjerne og hardware. Men dette er på en måte en litt mer detaljert skisse, med Linux som eksempel. Skal si at det er litt forskjellig fra Windows.", "source": "lecture"}
{"lecture_id": "os1del13", "chunk_id": "os1del13_0002", "start": 150.0, "end": 248.64, "token_count": 283, "text": "Prinsippskisse av Linux. Tidligere hadde vi et enkelt grensesnitt, og vi hadde operativsystemkjerne og hardware. Men dette er på en måte en litt mer detaljert skisse, med Linux som eksempel. Skal si at det er litt forskjellig fra Windows. I begge tilfeller har vi en operativsystemkjerne. Og det er... Når jeg sier OS, så tenker jeg ofte på OS-kjernen. Men det er ikke noen sånn helt klare definisjoner der. Hva som hører til OS-kjernen, og hva som ikke hører til OS-kjernen. Grovt sett så kan vi si at operativsystemkjernen er den som kjører i corner mode. Men så kan den ha systembiblioteker og systemprogrammer som kjører på toppen. Og det er det vi ser litt her. Hvis vi starter nederst, ser vi at vi har hardware her nede. AMD X86 osv. Hardware kan være veldig forskjellig, men operativsystemkjernen styrer denne hardwaren. Men så ser vi... Her har vi et systemkaldt grensesnitt. Dette er virkelig da et API... Application Programming Interface.", "source": "lecture"}
{"lecture_id": "os1del13", "chunk_id": "os1del13_0003", "start": 222.96, "end": 311.52, "token_count": 298, "text": "Hvis vi starter nederst, ser vi at vi har hardware her nede. AMD X86 osv. Hardware kan være veldig forskjellig, men operativsystemkjernen styrer denne hardwaren. Men så ser vi... Her har vi et systemkaldt grensesnitt. Dette er virkelig da et API... Application Programming Interface. Dere er kanskje kjent med API-er fra forskjellige softwareløsninger. Men det er typisk at du inn mot en klasse eller en softwarepakke, så har du et gitt antall kall som du kan gjøre. Et helt klart definert grensesnitt. Og nøyaktig det samme er det når det gjelder operativstyrer. Da har man et systemkall-grensesnitt. Så det er bare et begrenset antall systemkall som vanlige programmer kan gjøre for å snakke med operativsystemkjernen. Basert på de systemkallene, og eksempel open-close, dette er om filer, eller ri, det er et annet systemkall, da kan en applikasjon her oppe be systemet om at det leser. Da vil ikke applikasjonen her oppe styre disken direkte. Den kan bare gjøre systemkall til operativstemkjernen.", "source": "lecture"}
{"lecture_id": "os1del13", "chunk_id": "os1del13_0004", "start": 283.04, "end": 377.68, "token_count": 287, "text": "Basert på de systemkallene, og eksempel open-close, dette er om filer, eller ri, det er et annet systemkall, da kan en applikasjon her oppe be systemet om at det leser. Da vil ikke applikasjonen her oppe styre disken direkte. Den kan bare gjøre systemkall til operativstemkjernen. Dette er helt essensielt når det gjelder operativstemmer. At vi har dette grensesnittet. Men så ser vi også at vi har sånne... Her er et bibliotek, et systembibliotek. Det kan være math.ho. Det kan være en funksjon. En nettverksoppkobling fra denne applikasjonen til en annen et annet sted. Det er typisk systembiblioteker. I noen tilfeller kan man si at det er en del av operativsystemet, men det er ikke en del av operativsystemkjernen. Forskjellen er hvis det er et systembibliotek. Hvis det snakker gjennom systemkall til Da er det ikke en del av kjernen. Da er det mer en system, software, som sitter på toppen. Men som mange vil betrakte som en del av operativsystemet.", "source": "lecture"}
{"lecture_id": "os1del13", "chunk_id": "os1del13_0005", "start": 349.98, "end": 442.44, "token_count": 281, "text": "men det er ikke en del av operativsystemkjernen. Forskjellen er hvis det er et systembibliotek. Hvis det snakker gjennom systemkall til Da er det ikke en del av kjernen. Da er det mer en system, software, som sitter på toppen. Men som mange vil betrakte som en del av operativsystemet. Det er derfor det står... Det er en 19 stiplet linje her. Her står det GNU slash Linux. Og GNU... Det er en liten stiplet linje her. Jeg ser... jeg ser... har ikke skrevet hva Gnu er, men Gnu, det er en sånn rekkurs i forkortelse. Gnus, not Unix. Vanligvis når man opptaler Linux, så sier man bare Linux. Men det egentlig riktige navnet for Linux er GnuLinux. Gnu, det er resten av systemet. Linux er egentlig bare Linux-kjernen. Men hvis du skal styre en maskin, eller ikke minst styre applikasjoner, så trenger du mer enn akkurat kjernen. Så Gnu er alle disse verktøyene sånn som det står her. Compulator f.eks., GCC,", "source": "lecture"}
{"lecture_id": "os1del13", "chunk_id": "os1del13_0006", "start": 420.0, "end": 508.76, "token_count": 296, "text": "Gnu, det er resten av systemet. Linux er egentlig bare Linux-kjernen. Men hvis du skal styre en maskin, eller ikke minst styre applikasjoner, så trenger du mer enn akkurat kjernen. Så Gnu er alle disse verktøyene sånn som det står her. Compulator f.eks., GCC, som er det aller viktigste. Alle disse verktøyene er da bygd opp på toppen av Linux. Og når du i dagligtallet snakker om et operativsystem, så tenker man ofte på at så tar man også med den biten. Hvis du f.eks. snakker om et vindusoperativsystem, så har du absolutt også med alle disse verktøyene. Også vindusgrensesnittet. Og der er det en stor forskjell. I vindus så er det Gui. Vindusgrensesnittet, grafiske brukerinterface, det er en del av vinduskjernen. Mens vi ser her på Linux, så er all grafikk... Det er brukerprogramvare som sitter på toppen av operativstømkjernen og bare snakker med kjernen gjennom grensesnitt. Vi kommer tilbake til disse tingene, men dette er...", "source": "lecture"}
{"lecture_id": "os1del13", "chunk_id": "os1del13_0007", "start": 489.82, "end": 561.62, "token_count": 255, "text": "Mens vi ser her på Linux, så er all grafikk... Det er brukerprogramvare som sitter på toppen av operativstømkjernen og bare snakker med kjernen gjennom grensesnitt. Vi kommer tilbake til disse tingene, men dette er... Én vesentlig forskjell på Windows og Linux. Men hovedideen som dere må huske å sitte tilbake igjen med i dag, det er operativsystemet kjernen. Det er det helt essensielle av operativsystemet. Det kjører i curl-mode. Det har lov til å gjøre absolutt alt av endringer. Da kan det også gjøre feil og ødelegge systemet, få det til å gå ned osv. Mens resten av operativsystemet, det snakker med kjernen gjennom et API. Gjennom systemkall. Og da er det opplagt mye sikrere. Det er ikke så lett for en applikasjon her oppe da å få hele systemet til å gå ned. Det får rett og slett ikke lov til å gjøre alt det vil.", "source": "lecture"}
{"lecture_id": "os4del15", "chunk_id": "os4del15_0000", "start": 0.0, "end": 104.2, "token_count": 299, "text": "Foreløpig så kan jeg på en måte ikke... Jeg kan ikke kompilere denne biten alene, for alt henger sammen. Men det som går an å gjøre, er å dele opp seerprogrammet, sånn at vi har én bit som... Som utfører summen, og en annen bit som er main. Så da ser det... Skal vi se hvis jeg finner den funksjonen... Jeg tror det er en som heter Sumfunksjon. Sånn, ja. Sumfunksjon, den inneholder da bare denne funksjonen. Og det går da an å kompilere det for seg. Og så kan man i tillegg ha... En main som kaller denne funksjonen. Så her har vi en extern int sum i den sum main. Og den kaller da sum. Kattens sum er to m-er, for ikke å blande. Sum kaller funksjon sum, og så skriver den ut hva den gjør. Og dette er mulig å gjøre i C. Og her har jeg gjort det eksplisitt, fordi vi da etterpå skal kunne gå inn og se på maskinkode for denne summen. Hvis vi ser på den samlede maskinkoden for hele sum, så er det mye mer oversiktlig,", "source": "lecture"}
{"lecture_id": "os4del15", "chunk_id": "os4del15_0001", "start": 85.36, "end": 173.64, "token_count": 294, "text": "Og dette er mulig å gjøre i C. Og her har jeg gjort det eksplisitt, fordi vi da etterpå skal kunne gå inn og se på maskinkode for denne summen. Hvis vi ser på den samlede maskinkoden for hele sum, så er det mye mer oversiktlig, for da inkluderer det main og all kommunikasjon med operativsystemet osv. Men da kan vi se hvordan vi kan kompilere dette. Og én måte å kompilere det på er å kompilere alt sammen. Sum main og sum funksjon. Og så kalle det gjensum. Og på samme måte så får vi da et program som vi kan kjøre. Men det som er fint for oss nå, og som generelt er fint, er at man kan f.eks. ha samme main, og så gjør man bare endringer her i sum.  Det hadde vært fint å kunne kompilere de uavhengig av hverandre. Og så skjøte de sammen etterpå. Og det er mulig. Jeg kan først kompilere main. Men da må jeg legge... Hvis jeg legger på en... Hvis jeg legger på en opsjon minus c, så betyr det bare kompiler.", "source": "lecture"}
{"lecture_id": "os4del15", "chunk_id": "os4del15_0002", "start": 149.76, "end": 255.16, "token_count": 300, "text": " Det hadde vært fint å kunne kompilere de uavhengig av hverandre. Og så skjøte de sammen etterpå. Og det er mulig. Jeg kan først kompilere main. Men da må jeg legge... Hvis jeg legger på en... Hvis jeg legger på en opsjon minus c, så betyr det bare kompiler. Og ikke... Ikke load systembiblioteket. Biblioteker og alt annet som trengs for å få en ferdig kjørbar kode. Bare kompler akkurat den koden inni her. Og så kan jeg kanskje kalle den for... La oss si... Main er vel et naturlig navn på den. Jeg kaller den Main. Det jeg fikk nå, var et eksekverbar kode som heter Main, som inneholder bare den biten. Samme med... Med den symfunksjonen her borte. Den ønsker jeg å kompilere i en annen bit. Og så kan jeg kalle den for eksempel Funk. Sånn. Og da gir dette maskinkode som inneholder bare... Så for å lage en eksekverbar kode der totalt sett, så må jeg legge sammen... Den operasjonen jeg gjør nå, er å linke programmet.", "source": "lecture"}
{"lecture_id": "os4del15", "chunk_id": "os4del15_0003", "start": 222.6, "end": 314.38, "token_count": 245, "text": "Og så kan jeg kalle den for eksempel Funk. Sånn. Og da gir dette maskinkode som inneholder bare... Så for å lage en eksekverbar kode der totalt sett, så må jeg legge sammen... Den operasjonen jeg gjør nå, er å linke programmet. Og da oppfører Jesus seg som en linker. Jeg linker nå main og funk sammen. Og så får jeg ut et... En kjørbar fil som heter SUM. Så kjører jeg den, og så ser vi at det fungerer. Så i praksis er det samme operasjonene jeg gjorde her oppe da jeg kompilerte hele programmet og kjørte det. Men jeg har delt dem opp nå i to biter. Så hvis vi ser på sum, det eksekverbare programmet, ser vi det er 8672 bytes. Enn summen av disse to. Det er fordi det da er linke til biblioteker inn i den ferdige, eksekverbare koden. Og så er den da klar til å kjøre.", "source": "lecture"}
{"lecture_id": "linux2del5", "chunk_id": "linux2del5_0000", "start": 0.0, "end": 83.72, "token_count": 289, "text": "Vi skal nå se mer på mapper og manipulere mapper med filbehandling. I Linux så er det aller meste mapper og filer. Så det er veldig nyttig å kunne manipulere på de. Flytte rundt og lage de filstrukturene man ønsker, enten fra kommandolinjen eller i et skript. Så vi tar utgangspunktet i mappen min. Som jeg står i nå. Hvis jeg lister mapper her, så ser vi her to mapper, dir1 og dir2. Det er en nyttig kommando for å se på mappestrukturen, eller trestrukturen, som heter tree. Hvis jeg kjører tree her, så ser vi at jeg får en oversikt. Da ser jeg at under dir1 så er det en mappe ved ww. Da kan jeg liste dir1, så ser jeg... Ja, her ligger det en mappe. Den er spesielt fin hvis det er relativt oversiktlige trestrukturer. Hvis de er kjempestore, så er de ikke så enkle å se. Men i dette tilfellet så får vi en fin oversikt med tre. Det jeg først skal prøve å gjøre, er å flytte dyr 1 med alt under ned til dyr 2.", "source": "lecture"}
{"lecture_id": "linux2del5", "chunk_id": "linux2del5_0001", "start": 60.0, "end": 139.98, "token_count": 297, "text": "Den er spesielt fin hvis det er relativt oversiktlige trestrukturer. Hvis de er kjempestore, så er de ikke så enkle å se. Men i dette tilfellet så får vi en fin oversikt med tre. Det jeg først skal prøve å gjøre, er å flytte dyr 1 med alt under ned til dyr 2. For å flytte på mapper så bruker jeg MV eller Move. Det er alltid det jeg ønsker å flytte, som i dette tilfellet er dir1. Og jeg ønsker å flytte dir1 til dir2, som er andre argument. Så hvis jeg gjennomfører den og ser på trestrukturen, så ser vi at da har jeg oppnådd det jeg ønsket, nemlig å flytte dir1 med undermoppe ned til dir2. Så da får jeg denne mappestrukturen. Så kan jeg flytte dir1 tilbake igjen, Så ønsker jeg å flytte den hit, til min, hvor jeg står. Og da må jeg bruke prikk, eller kan bruke prikk. Det er mappen som jeg står i. Så hvis jeg flytter tilbake sånn, så har jeg fått den opprinnelige trestrukturen jeg hadde.", "source": "lecture"}
{"lecture_id": "linux2del5", "chunk_id": "linux2del5_0002", "start": 120.0, "end": 193.88, "token_count": 283, "text": "Så ønsker jeg å flytte den hit, til min, hvor jeg står. Og da må jeg bruke prikk, eller kan bruke prikk. Det er mappen som jeg står i. Så hvis jeg flytter tilbake sånn, så har jeg fått den opprinnelige trestrukturen jeg hadde. Så skal jeg prøve å se... Hva skjer hvis de to ikke finnes? Hvis jeg flytter de to til katt... I praksis er dir 2 katt i stedet. Hva skjer nå? Jo, da kan jeg prøve å bla tilbake med kontroll og R, og så finne den forrige MV-kommandoen. Det var ikke den. Men et takt til tilbake. Nei, ikke den heller, men den var det jeg gjorde tidligere. Flyttet dir 1 til dir 2. Så hvis jeg utfører den kommandoen nå, hva skjer når ikke dir 2 finnes? Jo, den kjører den kommandoen, og det som skjer da, er at da, i stedet for å flytte dir1 til dir2, så endres da bare navnet på dir1 til dir2.", "source": "lecture"}
{"lecture_id": "linux2del5", "chunk_id": "linux2del5_0003", "start": 177.52, "end": 268.32, "token_count": 295, "text": "hva skjer når ikke dir 2 finnes? Jo, den kjører den kommandoen, og det som skjer da, er at da, i stedet for å flytte dir1 til dir2, så endres da bare navnet på dir1 til dir2. Så det er klart, hvis du gjør sånne operasjoner i et skript, så må man tenke gjennom og være klar over alle muligheter. Altså hva skjer hvis dir2 finnes fra før, og hva skjer hvis den ikke finnes fra før. Da skal vi se på en litt annen problemstilling, hvor vi i stedet for å flytte, så skal vi kopiere mapper. Da kan jeg prøve å lage den samme strukturen igjen hvis jeg flytter dyr 2 til dyr 1. Og så renamer jeg katt til dyr 2. Så skulle jeg ha en lik... Filstruktur. Eller mappestruktur. Så... Ja, for å få litt mer innhold, så kan jeg lage en... Lage en fil med kommand og touch i mappe 1. Eller dire 1. Sånn som det. Og så ønsker jeg nå å ikke flytte, men å lage en kopi.", "source": "lecture"}
{"lecture_id": "linux2del5", "chunk_id": "linux2del5_0004", "start": 240.0, "end": 312.2, "token_count": 281, "text": "Filstruktur. Eller mappestruktur. Så... Ja, for å få litt mer innhold, så kan jeg lage en... Lage en fil med kommand og touch i mappe 1. Eller dire 1. Sånn som det. Og så ønsker jeg nå å ikke flytte, men å lage en kopi. Jeg ønsker å ta en kopi av hele det. Sånn som det. Så ønsker jeg nå å ikke flytte, men å lage en kopi. Med innhold og legge inn i deal 2. Da kan jeg ikke bruke MV, for da flyttes alt. Jeg ønsker en kopi. Og jeg kan heller ikke bare ta CP, for da får jeg ikke med innhold. Så hvis jeg skal ha med hele trestrukturen, så må jeg legge til opsjonen minus R for rekkerskyv. Så da tar jeg en rekkerskyv-kopi av deal 1 og ønsker å legge kopien i deal 2. Hvis jeg nå taster 3, så får jeg se at jo, da har jeg oppnådd det jeg ønsket. Jeg har fått en kopi av hele denne mappestrukturen inn i DIRL2.", "source": "lecture"}
{"lecture_id": "linux2del5", "chunk_id": "linux2del5_0005", "start": 290.2, "end": 388.2, "token_count": 294, "text": "så må jeg legge til opsjonen minus R for rekkerskyv. Så da tar jeg en rekkerskyv-kopi av deal 1 og ønsker å legge kopien i deal 2. Hvis jeg nå taster 3, så får jeg se at jo, da har jeg oppnådd det jeg ønsket. Jeg har fått en kopi av hele denne mappestrukturen inn i DIRL2. Så kan jeg igjen prøve å se hva ville skjedd her hvis DIRL2 ikke fantes. Og da kan jeg jo først... For å få samme mappestruktur kan jeg slette DIRL1 igjen. Da sletter jeg den. Da er vi tilbake der vi var. Men så må jeg ta DIRR2 og så endre navn til katt, f.eks. Og så prøve å se hva som skjer hvis jeg nå gjør en kopi. Hva skjer nå hvis jeg gjør CP minus R dire n dir 2? Akkurat som sist. Ja, det fungerer iallfall. Og det som jeg ser jeg gjør nå, det er at jeg får en nøyaktig kopi av hele dire 1, som kalles dire 2. Og disse kommandoene med re 1 og cd...", "source": "lecture"}
{"lecture_id": "linux2del5", "chunk_id": "linux2del5_0006", "start": 360.0, "end": 400.56, "token_count": 117, "text": "Hva skjer nå hvis jeg gjør CP minus R dire n dir 2? Akkurat som sist. Ja, det fungerer iallfall. Og det som jeg ser jeg gjør nå, det er at jeg får en nøyaktig kopi av hele dire 1, som kalles dire 2. Og disse kommandoene med re 1 og cd... Lekeskiv på CP. Og på RM. De er det veldig nyttig å kunne når du skal manipulere på Linux-filsystem.", "source": "lecture"}
{"lecture_id": "os3bdel3", "chunk_id": "os3bdel3_0000", "start": 0.0, "end": 82.72, "token_count": 270, "text": "D-vippe. Dette er altså en D-vippe, som er den endelige lagringsenheten for nullarenere i en CPU. Og den er satt sammen av to D-låser, eller latcher. Og måten vi har gjort det på, er at vi har én slave som hele tiden står og leser fra master. Og master er den som tar input utenfra. Så ser vi den stiplede linjen her. Det er de to lertsene som da er slått sammen til en D-vippe. Og det som er hele clouet med denne måten å gjøre det på, er at vi har en klokke som vi skrur av og på systematisk hele tiden med en viss frekvens. Og det er dette som er den berømte CPU-klokka. Som moderne CPU-er, fra en type sin frekvens mellom 1 og 3, ofte 4 GHz. Men noe særlig høyere enn det kommer man ikke pga. fysiske begrensninger. Da blir det altfor mye varmeutvikling. Derfor vet man at hvis man overklokker CPU-er,", "source": "lecture"}
{"lecture_id": "os3bdel3", "chunk_id": "os3bdel3_0001", "start": 60.0, "end": 149.96, "token_count": 296, "text": "Som moderne CPU-er, fra en type sin frekvens mellom 1 og 3, ofte 4 GHz. Men noe særlig høyere enn det kommer man ikke pga. fysiske begrensninger. Da blir det altfor mye varmeutvikling. Derfor vet man at hvis man overklokker CPU-er, så må man begynne med vannavkjøling, og i ekstreme tilfeller med flytende luft osv. Men det er da mye mer effektivt, og i stedet for å ha høyere frekvens, så lager man flere sepur og fordeler dem, sånn at man da har maskiner som har fire, åtte, og i servere 30 og 60 sånne sepur. Så helt uavhengige enheter som regner hver for seg. Men vi skal se på hvorfor dette her virker. Og i de simuleringene som vi gjorde i fjor med studenter på rekke osv.... Så det jeg gjorde da, var at jeg var klokke. Og det jeg gjorde da, var at jeg hvert andre sekund omtrent så løftet jeg armen opp, og da er celik én, og da er det slavene som virker.", "source": "lecture"}
{"lecture_id": "os3bdel3", "chunk_id": "os3bdel3_0002", "start": 125.68, "end": 214.84, "token_count": 297, "text": "Og i de simuleringene som vi gjorde i fjor med studenter på rekke osv.... Så det jeg gjorde da, var at jeg var klokke. Og det jeg gjorde da, var at jeg hvert andre sekund omtrent så løftet jeg armen opp, og da er celik én, og da er det slavene som virker. Og så tok jeg armen ned. Og da blir det en ener som er sendt til master. Og hele clouet er at disse her virker annenhver gang. Og her har jeg satt opp systematisk, og vi ser på hver av de to fastene. Så i en CPU så deles tiden inn i små klokketall. Den går av og på hele tiden. Når klokken sender inn en null, da skal alle beregninger ferdigstilles. Det kretsen gjør, sånn som AD-er osv., det skal gjøres ferdig, og så lagres det hos Master. Den lagringen må være ferdig før klokken switcher til. Når klokka er null her, kan vi tenke oss at dette er et register vi skal lagre noe i. Så har vi kanskje en addisjon eller en subtraksjon eller et eller annet", "source": "lecture"}
{"lecture_id": "os3bdel3", "chunk_id": "os3bdel3_0003", "start": 193.84, "end": 263.96, "token_count": 270, "text": "det skal gjøres ferdig, og så lagres det hos Master. Den lagringen må være ferdig før klokken switcher til. Når klokka er null her, kan vi tenke oss at dette er et register vi skal lagre noe i. Så har vi kanskje en addisjon eller en subtraksjon eller et eller annet som pågår, og det tar tid. De må strømme fysisk, strømme gjennom den kretsen for å komme til et svar. Og da, når klokka er null, så leser Master det som kommer inn. Kanskje sluttsvaret på den summen, dette bittet, blir da null. Og da lagres det hos Master. Da er det viktig at før klokka ringer, før klokka skifter fra null til én, så må alle disse operasjonene være ferdige. Det er det som gjør at noen komplekse operasjoner, som å dividere f.eks., det tar mer enn en klokkesyklus, og da må det tas med i beregningen at den blir ikke ferdig på én klokkesykkel.", "source": "lecture"}
{"lecture_id": "os3bdel3", "chunk_id": "os3bdel3_0004", "start": 245.52, "end": 321.0, "token_count": 283, "text": "så må alle disse operasjonene være ferdige. Det er det som gjør at noen komplekse operasjoner, som å dividere f.eks., det tar mer enn en klokkesyklus, og da må det tas med i beregningen at den blir ikke ferdig på én klokkesykkel. En addisjon kan typisk være ferdig på én klokkesyklus, og da kommer resultatet inn med en gang. Og dette må være ferdig før klokka switcher over til 1. For da skrus lesingen fra master av. Og da, når klokka switcher 1, så ser vi at da er det Slaven som begynner å lese. Og da er det smarte her at da leser Slaven verdien fra master. Men da er master skrudd av, så da har slaven god tid på å lese denne verdien. Og da er den sikker på at denne verdien er den endelige verdien. I dette tilfellet får vi en null her hos Slaven. Og det er denne som er verdien som registeret inneholder. Og helt tilsvarende med alle andre masterslavepar, som totalt sett utgjør en vippe.", "source": "lecture"}
{"lecture_id": "os3bdel3", "chunk_id": "os3bdel3_0005", "start": 297.14, "end": 371.6, "token_count": 244, "text": "Og da er den sikker på at denne verdien er den endelige verdien. I dette tilfellet får vi en null her hos Slaven. Og det er denne som er verdien som registeret inneholder. Og helt tilsvarende med alle andre masterslavepar, som totalt sett utgjør en vippe. Så vi ser her når klokken slår én, Slaven leser hver informaster og lagrer den. Men jeg begynner med en gang å sende ut dette resultatet, som er det gjeldende resultatet, ut i kretsen, som er koblet til utgang for nyberegninger. Og på denne måten så går klokka av og på. Og for hver sånn klokkesyklus så utføres det da én beregning. Og denne CPU-klokken er helt essensiell for å synkronisere dataene. For hver tid på klokken kan man utføre et nytt sett av beregninger. Det kan f.eks. hver dag å utføre en maskininstitusjon.", "source": "lecture"}
{"lecture_id": "linux7del9", "chunk_id": "linux7del9_0000", "start": 0.0, "end": 130.78, "token_count": 295, "text": "Sånn. Jeg startet med å kjøre Docker Container and Hello World. Men da kan jeg prøve å kjøre et helt OS. Hvis jeg skriver minus IT, i er for interaktivt. T er for at den skal sette opp en TTI eller en terminal. Noen av oppgavene senere kjører de alpine, som er en sånn mini... Liten Linux-installasjon. Jeg kan starte Ubuntu her, så vi er litt mer vant til det. Så må jeg starte et bæsjvindu også, for å kunne få kontakt med... Da er den ute på Lockerup og henter ned et Ubuntu-image. Uansett hva slags Linux-OS jeg har eller hvilken distribusjon jeg har lokalt, så vil det imaget sørge for at dette ser helt ut som Ubuntu på alle måter. Så har jeg fått opp et... Her har jeg fått opp et prompt som... Som Ruth. Jeg er Ruth. Det pleier man å være i de imagene. Nå ser vi at vi har et fullt filsystem her. Og dette ser ut som en... Eller, det er en... I praksis så er dette en Ubuntu-installasjon. Jeg prøver en liste prosesser, så ser vi at det er veldig lite prosesser som kjører.", "source": "lecture"}
{"lecture_id": "linux7del9", "chunk_id": "linux7del9_0001", "start": 97.08, "end": 209.86, "token_count": 298, "text": "Det pleier man å være i de imagene. Nå ser vi at vi har et fullt filsystem her. Og dette ser ut som en... Eller, det er en... I praksis så er dette en Ubuntu-installasjon. Jeg prøver en liste prosesser, så ser vi at det er veldig lite prosesser som kjører. Det er en av de tingene som er gjort med dokkecontainere, at man skiller det helt fra resten av apparativsystemet. Så det eneste vi ser i dokkecontaineren, er de prosessene som vi kjører selv. Så kan vi som med andre... Som med andre containere... Nei, med andre servere. Så kan man logge ut. Enten med kontroll D eller med exit. Den store forskjellen nå, hvis jeg kjører exit her, så er faktisk hele den containeren som jeg startet opp og kjørte, lukket ned. Sånn generelt så kan jeg kjøre dokkecontainer-PS. Da viser jeg alle konteinere som kjører. Nå er det ingen konteinere som kjører. Men hvis jeg legger på AS... Ja, jeg ser det blir... Jeg har et veldig stort vindu for å få med alt, så da er det kanskje vanskelig for dere.", "source": "lecture"}
{"lecture_id": "linux7del9", "chunk_id": "linux7del9_0002", "start": 180.0, "end": 299.0, "token_count": 296, "text": "Sånn generelt så kan jeg kjøre dokkecontainer-PS. Da viser jeg alle konteinere som kjører. Nå er det ingen konteinere som kjører. Men hvis jeg legger på AS... Ja, jeg ser det blir... Jeg har et veldig stort vindu for å få med alt, så da er det kanskje vanskelig for dere. Vanskelig for dere å se. Klarer du å se dette? Det er helt på grensen om det går. Poenget er at dette er en listing av alle de tre konteinerne som jeg har startet. Ingen av de kjører. Status er... exited. Hovedpoenget er når du starter og kjører en konteiner... Da stopper den igjen etterpå. Så fjerner du hele konteineren. Jeg kan prøve å starte på nytt. Nå gikk det mye fortere. Den kommandoen her startet og stoppet... en hel server, kan du si. Med fysisk server tar det mange minutter. Med en VM tar det fort iallfall et halvt minutt. Men med... ja, jeg ser... jeg ikke timer. Jeg tenkte å prøve å ta tiden på denne her. Med dere så går det veldig fort. Jeg ser det...", "source": "lecture"}
{"lecture_id": "linux7del9", "chunk_id": "linux7del9_0003", "start": 270.0, "end": 305.0, "token_count": 97, "text": "Den kommandoen her startet og stoppet... en hel server, kan du si. Med fysisk server tar det mange minutter. Med en VM tar det fort iallfall et halvt minutt. Men med... ja, jeg ser... jeg ikke timer. Jeg tenkte å prøve å ta tiden på denne her. Med dere så går det veldig fort. Jeg ser det... Det startes opp på under fem sekunder.", "source": "lecture"}
{"lecture_id": "os10del1", "chunk_id": "os10del1_0000", "start": 0.0, "end": 101.48, "token_count": 293, "text": "Temaet i dag er plattformavhengighet og treads. Plattformavhengighet er ganske morsomt, og det er veldig sånn konkret. Vi skal bare se på hvordan tar det seg ut når man kopierer programmer mellom forskjellige plattformer. Stort sett så skal vi se det praktisk an. Jeg har en litt større demo. Og jeg kopierer masse programmer og masse plattformer. Og plattformer er typisk et gitt operativsystem på en gitt type CPU. Linux på Intel eller Windows på AMD, f.eks. Det er én plattform. Og plattformuavhengige programmer skal man kunne kopiere fra én plattform til en annen, og så skal de kunne kjøre uten videre. Spesielt så skal vi se på javatråder i dag. Men vi skal ha en generell innledning, sånn teoretisk, om tråder og hva det er. Og så skal vi som vanlig gjøre en del praktisk. Etter hvert så kommer vi til Petrads i C også. Det er da det samme prinsippet bak Petrads tråder. Det er planen. Jeg tenkte aller først å se litt på det som er på en måte litt...", "source": "lecture"}
{"lecture_id": "os10del1", "chunk_id": "os10del1_0001", "start": 73.24, "end": 171.84, "token_count": 298, "text": "Og så skal vi som vanlig gjøre en del praktisk. Etter hvert så kommer vi til Petrads i C også. Det er da det samme prinsippet bak Petrads tråder. Det er planen. Jeg tenkte aller først å se litt på det som er på en måte litt... Eldre notater som er fra et eksperiment som vi kjørte for noen år siden. I prinsippet så ligner det på det vi skal gjøre nå. Men det kan være greit å få en litt bredere forståelse for... En litt bredere forståelse for plattformavhengighet. Men kanskje aller først det vi holdt på med sist. Da så vi på... Ja, det siste vi så på, var systemkall. Det første vi så på sist, var systemkall. Og hvordan det i praksis ser ut når man måler tiden på programmer... Det finnes en god del instruksjoner i curl-mode, spesielt med systemcall. En default, hvis det ikke er noe spesielt som skjer, hvis du bare regner f.eks., så kjøres alt i use-mode. Det kan vi se med time, og vi kunne også se det i prock. Så så vi på prioritet, og spesielt på NICE hvordan man da kan prioritere", "source": "lecture"}
{"lecture_id": "os10del1", "chunk_id": "os10del1_0002", "start": 150.0, "end": 230.68, "token_count": 294, "text": "Det finnes en god del instruksjoner i curl-mode, spesielt med systemcall. En default, hvis det ikke er noe spesielt som skjer, hvis du bare regner f.eks., så kjøres alt i use-mode. Det kan vi se med time, og vi kunne også se det i prock. Så så vi på prioritet, og spesielt på NICE hvordan man da kan prioritere ved å tildele TIX til prosesser. Og NICE kunne gjøre sånn at man var... Vær veldig snill med andre. Og tildelte... Bare si 'Jeg vil ha veldig få tics'. Det kan f.eks. være nyttig sånn... Når jeg editerer videoer på laptopen min, så den har åtte super U-er, men det er veldig tungt når jeg kjører 16 sånne videoredigeringsjobber i parallell. Da kan det være nyttig å sette 'nice' på de, for da fungerer laptopen. Og de prosessene som står og heltingen skal jobbe, de bare tar seg CPU-tid når ingen andre ber om det. Og da fungerer systemet fortsatt bra. Og det er egentlig hele filosofien til operativsystemet.", "source": "lecture"}
{"lecture_id": "os10del1", "chunk_id": "os10del1_0003", "start": 205.56, "end": 258.0, "token_count": 181, "text": "Da kan det være nyttig å sette 'nice' på de, for da fungerer laptopen. Og de prosessene som står og heltingen skal jobbe, de bare tar seg CPU-tid når ingen andre ber om det. Og da fungerer systemet fortsatt bra. Og det er egentlig hele filosofien til operativsystemet. At alle prosesser som kjører, de skal få CPU-tid når de trenger det. Så så vi altså litt på prosessforløp. Som vi begynner å bli ganske gode på nå. Hva som skjer med prosesser i et system. Og til slutt på OS-arkitektur. Hvordan selve arkitekturen av et operativstemmeprogramme.", "source": "lecture"}
{"lecture_id": "os8del12", "chunk_id": "os8del12_0000", "start": 0.02, "end": 92.8, "token_count": 300, "text": "Alle operativstemaer har en eller annen form for prioritet på prosesser. Og i 260-hjernen så er det 140 forskjellige prioritetsklasser. Og hver sånn klasse tilsvarer et antall tildelte tics i starten av en epoke. Og det scheduleren gjør, er at når den kommer inn, så velger den prosessen som har høyest prioritet. Eller gi fra seg CPU-en. Og deretter kalles kjedelvern på nytt. Og det er et viktig poeng, det der med at en eller gir fra seg CPU-en. Fordi det gjør at en prosess er veldig høyt prioritert. Og det kan typisk være sånne interaktive prosesser, som en teksteditor. Den bruker veldig lite CPU. Akkurat når det kommer inn tasten F fra brukeren, så er det veldig viktig at den prosessen svarer kjapt. Og en tekstredaktor bruker vanligvis veldig lite CPU, så den vil hele tiden få dynamisk høyere prioritet. Den vil komme veldig høyt opp. Men det som skjer da... Hvis en tekstredaktor har 100 og får... Utdelt 120 tics kommer veldig høyt opp.", "source": "lecture"}
{"lecture_id": "os8del12", "chunk_id": "os8del12_0001", "start": 70.64, "end": 153.52, "token_count": 296, "text": "Og en tekstredaktor bruker vanligvis veldig lite CPU, så den vil hele tiden få dynamisk høyere prioritet. Den vil komme veldig høyt opp. Men det som skjer da... Hvis en tekstredaktor har 100 og får... Utdelt 120 tics kommer veldig høyt opp. Så med en gang den har prosessert den ene bokstaven sin, så vil den overgi seg. Den vil stoppe og si at nei, nå trenger jeg ikke CPU lenger. Og dermed så vil den beholde den høye prioriteten. Kanskje få enda et tics som kommer opp i 121. Sånn at neste gang når den kommer inn, så vil den alltid komme inn med en gang. Med en gang det kommer. For når brukeren tasser F, så sendes et interrupt. Og da vil scheduleren merke det med et spesielt bit, som vi skal se på neste slide. Men scheduleren vil merke det, og teksteditorprosessen vil hoppe inn. Derimot en regneprosess, sånn som den.regn... Hver gang i epoken vil den bruke opp absolutt alle ticsene sine. Så den kommer kanskje ned til slutt til ti tics.", "source": "lecture"}
{"lecture_id": "os8del12", "chunk_id": "os8del12_0002", "start": 135.4, "end": 208.34, "token_count": 299, "text": "Men scheduleren vil merke det, og teksteditorprosessen vil hoppe inn. Derimot en regneprosess, sånn som den.regn... Hver gang i epoken vil den bruke opp absolutt alle ticsene sine. Så den kommer kanskje ned til slutt til ti tics. Hver gang er det bare den som kjører. Da er det ti tics i epoken. Og den kjører da om og om igjen. Hvis du hele tiden bruker opp ticsene, så vil det gå ned i prioritet. Men så lenge det ikke er noen andre som ønsker å kjøre, så er det helt greit. For da får du likevel kjøre hele tiden. Men da vil interaktive prosesser... De vil etter hvert bygges opp en høy prioritet og vil alltid komme raskt inn. Men de bruker likevel like mye CPU, så på den måten kan alle typer prosesser, både de som bruker mye CPU og ønsker å bruke mye CPU, og de som er interaktive og ikke bruker mye, de vil da kunne samkjøre innenfor samme system uten at taxidirektoren vil oppleves som ekstremt treg, bare fordi det er en regnejobb som står.", "source": "lecture"}
{"lecture_id": "linux5del2", "chunk_id": "linux5del2_0000", "start": 0.0, "end": 101.84, "token_count": 290, "text": "Passordkrakking. Hvis man har tilgang til Shadow Film på Linux, som vi har sett, og dermed tilgang til hashtringene, så kan man ved en Brute Force-metode finne ut hvilke passord som passer til hvilken konto. Og man har tilsvarende passordhasher på Windows. Der også har man fått bedre og bedre algoritmer. På Minus lagres hersteringen i en såkalt SAM-datapasse. Og den er opplagt også. Det er veldig viktig at den ikke blir kjent, for da kan alle som kjenner disse hersene, prøve å gjette på passord. Og da bruker man programmer som kjører gjennom f.eks. ordbøker. Eller eventuelt alle mulige kombinasjoner. Men her på OsloMet, på Studio SSO, så ser det ut som du logger inn på en Linux-server. Og for fem-seks år siden så lå også passordhersen i shadowfilen. Men det gjør det ikke lenger. Når du logger på nå, så sendes denne forespørselen til en... En database sentralt og en AD Active Directory-database. Og så er det der autentiseringen foregår.", "source": "lecture"}
{"lecture_id": "linux5del2", "chunk_id": "linux5del2_0001", "start": 75.52, "end": 168.04, "token_count": 291, "text": "Og for fem-seks år siden så lå også passordhersen i shadowfilen. Men det gjør det ikke lenger. Når du logger på nå, så sendes denne forespørselen til en... En database sentralt og en AD Active Directory-database. Og så er det der autentiseringen foregår. Men på samme måte. På den måten sikrer man seg at man bare har herser ett sted på Oslomet. Tidligere var det to, men det var da en ulempe sånn sikkerhetsmessig. Jo færre steder de hersene er, jo bedre er det. Vi skal se litt på hvordan man kan cracke sånne passord med brute force. Ved virkelig brute force kan man gå gjennom alle mulige kombinasjoner. Da kan man tenke seg hvis det f.eks. er 52 tegn, små og store bokstaver, og titall, så har du 62 kombinasjoner. Hvis du da har 8 tegn i passorden... Så vil det bli åtte opphøyd i 62, som er to ganger ti fjortende. Eller 218 billioner mulige kombinasjoner. Og hvis man har en veldig kraftig GPU-server,", "source": "lecture"}
{"lecture_id": "linux5del2", "chunk_id": "linux5del2_0002", "start": 141.28, "end": 234.28, "token_count": 297, "text": "og titall, så har du 62 kombinasjoner. Hvis du da har 8 tegn i passorden... Så vil det bli åtte opphøyd i 62, som er to ganger ti fjortende. Eller 218 billioner mulige kombinasjoner. Og hvis man har en veldig kraftig GPU-server, så vil det ta noe sånt som sju år å regne én million hash i sekundet.  Og brute-force et sånt passord. Så når du har så mange som 62 tegn og en lengde på 8 bit... Nei, på 8 tegn. Så... så tar det uforholdsmessig lang tid å knekke et passord av den type. Men det er derfor man da må velge enda lengre passord. Så... og... Man blir oppfordret til å bruke spesialtegn. Og hvis du gjør det, så ser du... Hvis du har en lengde på ti passordtegn, og så bruker du 94 tegn til å skrive passord med, alle sånne spesialtegn, så er det oppe i 1,7 millioner år før du kan cracke et sånt passord ved Web Route Force. Og dermed blir det... med lange passord.", "source": "lecture"}
{"lecture_id": "linux5del2", "chunk_id": "linux5del2_0003", "start": 210.52, "end": 303.4, "token_count": 286, "text": "Og hvis du gjør det, så ser du... Hvis du har en lengde på ti passordtegn, og så bruker du 94 tegn til å skrive passord med, alle sånne spesialtegn, så er det oppe i 1,7 millioner år før du kan cracke et sånt passord ved Web Route Force. Og dermed blir det... med lange passord. Så blir det i praksis umulig å bruke et brute force-angrep. Men det er også derfor det er så veldig farlig å bruke ord fra ordbok i et passord. For når man gjør det, så kan man kjøre brute force bare gjennom ordboken. Og f.eks. det å teste ut én million ord, det kan man gjøre på et sekund. Har du et ord som står ordrett i en ordbok, så er sjansen stor for at passordet ditt kan bli avslørt av en passordknekke-algoritme som dette her. Men det er klart... For i det hele tatt å få det til, så må man først ha... En hash. Altså, man må ha din hash. Men noen ganger så blir den type hasher avslørt,", "source": "lecture"}
{"lecture_id": "linux5del2", "chunk_id": "linux5del2_0004", "start": 279.88, "end": 366.7, "token_count": 280, "text": "av en passordknekke-algoritme som dette her. Men det er klart... For i det hele tatt å få det til, så må man først ha... En hash. Altså, man må ha din hash. Men noen ganger så blir den type hasher avslørt, og da kan man så kverne passordkrakk i algoritmen på dette til man finner passord. Noe helt annet som vi skal se på senere, er SSO-skanning. Da prøver man også å gjette passord for å komme seg inn på SSO-servere, men da gjetter man bare ett av gangen, hvert tredje sekund maks. Men det må dere være obs på på VM-ene dere har med Public IP. Med en gang dere f.eks. lager et nytt brukernavn med passord der, så... Hvis dere har lagret dårlig passord, så blir man hacket med en gang fordi en mengde brutt force-angrep på public IP-er. Sånn ca. hvert tredje sekund tikker det inn et nytt forslag til passord. Hvis du bruker test-test, så blir du typisk hacka i løpet av få minutter.", "source": "lecture"}
{"lecture_id": "linux5del2", "chunk_id": "linux5del2_0005", "start": 336.96, "end": 374.68, "token_count": 112, "text": "så... Hvis dere har lagret dårlig passord, så blir man hacket med en gang fordi en mengde brutt force-angrep på public IP-er. Sånn ca. hvert tredje sekund tikker det inn et nytt forslag til passord. Hvis du bruker test-test, så blir du typisk hacka i løpet av få minutter. Det er veldig viktig å sette gode passord på brukerne dere etter hvert skal lage.", "source": "lecture"}
{"lecture_id": "os7del14", "chunk_id": "os7del14_0000", "start": 0.0, "end": 98.12, "token_count": 286, "text": "Ja, hyperthreading er opprinnelig en markedsføringsterminologi som Intel innførte. Det er altså Intels varemerke hyperthreading. Som vi ser her nede, så er den generelle betegnelsen SMT. Simultaneous Multithreading. Så når AMD bruker det samme prinsippet, så kaller de det for SMT. Men vi ser først på Intel og Hyperthreading. Hyperthreading består i at én single core CPU, dvs. én CPU som har én enkelt alu, én regneenhet, én kjerne, kan inneholde to prosesser samtidig. Litt av innholdet i CPU-ene er da duplisert, spesielt registre. For det kan ikke lastes ut. Men dette foregår da på hardware-nivå. Så operativsystemet opplever dette som to selvstendige prosessorer. Det lister det i topp som to selvstendige prosessorer. Men det som skjer i virkeligheten, er at når OS fordeler prosesser til denne prosessoren som er hypertraining, så settes det i gang. Men de to prosessene deler da Alun, som er på denne CPU-en.", "source": "lecture"}
{"lecture_id": "os7del14", "chunk_id": "os7del14_0001", "start": 72.64, "end": 163.4, "token_count": 295, "text": "Det lister det i topp som to selvstendige prosessorer. Men det som skjer i virkeligheten, er at når OS fordeler prosesser til denne prosessoren som er hypertraining, så settes det i gang. Men de to prosessene deler da Alun, som er på denne CPU-en. Og da er det Hardware som switcher kjøpt imellom de to prosessene. Og dette skjer i løpet av nanosekunder, altså ekstremt hurtig. Og dette er ikke i nærheten av det som skjer når man gjør Context Switch med OS. Det tar veldig mye lengre tid. Og denne teknologien er da lagd fordi man har sett at... Selv om man har pipelining og mikrooperasjoner som utføres i parallell på superskalare CPU-er. Til tross for det, så vil det hele tiden være litt hardware-ressurser som ikke blir brukt. F.eks. at alun ikke blir utnyttet fullstendig. Og det er typisk, for selv med cash må man noen ganger vente på... Resultater eller vente på noe fra RAM eller fra andre devices. Denne ventetiden utnyttes av å lynhurtig switche frem og tilbake", "source": "lecture"}
{"lecture_id": "os7del14", "chunk_id": "os7del14_0002", "start": 139.36, "end": 214.0, "token_count": 251, "text": "som ikke blir brukt. F.eks. at alun ikke blir utnyttet fullstendig. Og det er typisk, for selv med cash må man noen ganger vente på... Resultater eller vente på noe fra RAM eller fra andre devices. Denne ventetiden utnyttes av å lynhurtig switche frem og tilbake mellom de to prosessene som kjører. Det er dette som er hypertrening. Det typiske er at de har egne registre for hver prosess, men deler felles ALU. Etterpå skal vi kjøre noen tester, og da vil vi se at... Det går saktere når man har hypertrening, fordi de må dele på alle. Og som jeg nevnte, hypertrening styres og har det vel. Så OS vet egentlig ikke noe om dette her. Ja, de vet litt om det, men den er ikke med og styrer. Den bare gir prosesser til CPU-en, og så utfører CPU-en disse lynhurtige switchene mellom de to. I tillegg til prosessen om Kjell.", "source": "lecture"}
{"lecture_id": "os7del7", "chunk_id": "os7del7_0000", "start": 0.0, "end": 80.44, "token_count": 280, "text": "ESRAM og DRAM. CPU-registrene og cash er laget av ESRAM. ESRAM består av seks damasthistorier for hver bytte som lagres. Det var det vi bygde opp møysommelig tidligere i datamaskinarkitektur. At vi satte sammen and-er og -årer, og så laget vi noen løkker tilbake og noen not-porter, og så klarte vi å lage en liten krets. Som lagret ett bit. 1.01-er. Men vi trengte da seks transistorer for å få det til. Mens DRAM, eller Dynamic Rum, er en mye enklere teknologi. Det besto bare av én transistor og en kapasitator. Kapasitator er en bitte liten device som lagrer en liten elektrisk ladning. Og da er det så enkelt at hvis den har ladning, så er den én. Hvis den ikke har ladning, så er den null. Deram er da mindre og mye billigere å lage enn SRAM. Men det største problemet er at den er ikke like hurtig. Og i tillegg må det lades opp på nytt ti ganger i sekundet.", "source": "lecture"}
{"lecture_id": "os7del7", "chunk_id": "os7del7_0001", "start": 63.88, "end": 138.0, "token_count": 254, "text": "Hvis den ikke har ladning, så er den null. Deram er da mindre og mye billigere å lage enn SRAM. Men det største problemet er at den er ikke like hurtig. Og i tillegg må det lades opp på nytt ti ganger i sekundet. Og Deram er da, i motsetning til disker, altså flash-minne og harddisker, så forsvinner alt som er lagret. Det forsvinner når du skrur av strømmen. Så når du skrur på en datamaskin, så står DRAM og lades opp på nytt hele tiden for at man skal beholde den nullen eller eneren. Nullen er lett å beholde, men eneren må helt innlades. Siste versjon av DRAM er DDR5 SDRAM. Det er det det er fire som er foreløpig det mest vanlige, som kom i 2016 eller noe sånt. Igjen, prinsippet er det samme, men all utviklingen går da på å få ting til å gå enda litt fortere.", "source": "lecture"}
{"lecture_id": "os5del6", "chunk_id": "os5del6_0000", "start": 0.0, "end": 113.72, "token_count": 294, "text": "Jo... Her har jeg skrevet... Assembly-kode, som kanskje er den raskeste til å utføre akkurat dette her. Vi kan se på dette. Dette er kode som en assembly-programmerer skriver. Man kan sette seg ned og skrive assembly-kode for X86, og så kan man inkludere der. Da er det assembleren som lager maskinkoden av denne her. Og maskinkode, stort sett så oversettes den linje for linje. Når jeg skriver... så oversettes det av assembleren til maskinkode ved at move oversettes til det nummeret move har i instruksjonssettet. Det som er forskjellig fra forrige gang, som kommer i tillegg, det er her nede. Så ser vi at vi har et datafelt. Og dette er måten man legger variabler i ram på. Så denne linjen her, den sier lag en variabelsvar og legg i ram. Det betyr lag 1... eller lagre 64 bit. Så denne vil lage 8 byte som inneholder denne variabelen. Og den vil inneholde tallet 32. Og så kan vi se... Så det første jeg egentlig trenger, er å definere funksjonen én linje.", "source": "lecture"}
{"lecture_id": "os5del6", "chunk_id": "os5del6_0001", "start": 90.0, "end": 190.0, "token_count": 289, "text": "Det betyr lag 1... eller lagre 64 bit. Så denne vil lage 8 byte som inneholder denne variabelen. Og den vil inneholde tallet 32. Og så kan vi se... Så det første jeg egentlig trenger, er å definere funksjonen én linje. Så den global gjør at jeg kan bruke denne funksjonen fra main. Skal gjøre det etterpå. Én linje. Det er en standard start av funksjonen. Og så det jeg gjør først, er... Nå! Den dataen her nede betyr at jeg allerede har lagd tallet 32 i... Nei, her har jeg lagd tallet 10 i memoar. Så det første jeg gjør, er å flytte memoar til RBX. Og så legger jeg til RBX til svar, altså til svar som da ligger i ramm. Så denne ad-operasjonen her, den utføres på et register og et tall i ramm. Så det som utføres her nå, det er at i tallet 10 ligger RBX. Så flytter jeg svaret ut i rax. Når jeg returnerer, returneres verdien i rax.", "source": "lecture"}
{"lecture_id": "os5del6", "chunk_id": "os5del6_0002", "start": 160.88, "end": 277.8, "token_count": 283, "text": "Så denne ad-operasjonen her, den utføres på et register og et tall i ramm. Så det som utføres her nå, det er at i tallet 10 ligger RBX. Så flytter jeg svaret ut i rax. Når jeg returnerer, returneres verdien i rax. Det er et spørsmål om du kan gjenta hva... Ja, supert. Ja, kode betyr at det skal være... At det skal settes av 64 bit. Det er 32 bit, og kode er 64 bit. Så den sier rett og slett... Sett av 64 bit, eller av 8 bytes, til denne variabelen. Jeg tror hvis... Jeg husker ikke helt hvis man... Det er mulig det er.long, tror jeg det står, hvis du skal sette av 32 bit. Så det er det kode betyr. Ja... Og hvorfor er det et sånt tegn? Det er bare en kommentar. Ok. Men det vi skal se på nå, er... Først kan vi se på hvordan vi kan kjøre denne her. Så den kan jeg da kjøre ved å skjøtte den sammen med én linje main. Og enl.s, sånn.", "source": "lecture"}
{"lecture_id": "os5del6", "chunk_id": "os5del6_0003", "start": 246.52, "end": 299.96, "token_count": 137, "text": "Ja... Og hvorfor er det et sånt tegn? Det er bare en kommentar. Ok. Men det vi skal se på nå, er... Først kan vi se på hvordan vi kan kjøre denne her. Så den kan jeg da kjøre ved å skjøtte den sammen med én linje main. Og enl.s, sånn. Og så kjøre add-og-dots, og da ser vi at den funker som det skal. Så hvis jeg her nå starter med 22 i stedet, så... Vi får sjekke at vi faktisk... Ja, så svarer den...", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0000", "start": 0.0, "end": 107.48, "token_count": 293, "text": "Der har jeg startet å ta opp. Som sagt - er det spørsmål, så inn i chatten. Så bare spør. Det er lov å skru på lyden og spørre også. Ingen gjør det, men det er lov. Men etter forelesning i hvert fall så vil det som vanlig være break-out rooms, Og studentassistentene. OK. Da skal vi se litt på dagens planer. Ja. For det første så kan dere se at jeg har endret litt på opplegget. Så... Nå er vi her. Så i forrige uke, uke tolv, så var det da den... Siste runden med digitale forelesninger. Så jeg fant ut at det pensumet vi har, er stort nok. Det har vært mange tilbakemeldinger på det. Så jeg har tenkt å ikke legge inn noe mer stoff rundt dokker. Og rundt det praktiske. Så i stedet tenkte jeg å bruke litt mer tid på... De siste delene om internminne og disker og filsystemer. Og da vil det tilsvarende være oppgaver, men da vil det bare være oppgaver om disse temaene her. Og ikke i tillegg, da, om Linux og PowerShell,", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0001", "start": 82.78, "end": 170.4, "token_count": 277, "text": "Og rundt det praktiske. Så i stedet tenkte jeg å bruke litt mer tid på... De siste delene om internminne og disker og filsystemer. Og da vil det tilsvarende være oppgaver, men da vil det bare være oppgaver om disse temaene her. Og ikke i tillegg, da, om Linux og PowerShell, sånn som det er pride å være. Så de siste tre ukene blir da litt roligere. De siste to ukene blir litt roligere sånn sett. Så det kommer til å være veldig god tid til å jobbe med dette fram til eksamen, som er lenge til. Det er vel 11.6, eller noe sånt, hvis jeg ikke husker helt feil. Og da tenker jeg også å prøve å få til en prøveeksamen en eller annen dag. Hvor mange uker med forelesning er det igjen? Jo, sånn... Som du ser her, så er vi nå her på tirsdag 13. april. Så tirsdag 27. blir siste forelesning. Mulig den ikke blir så lang heller. Men i hvert fall denne uken er den siste.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0002", "start": 145.38, "end": 250.08, "token_count": 294, "text": "Hvor mange uker med forelesning er det igjen? Jo, sånn... Som du ser her, så er vi nå her på tirsdag 13. april. Så tirsdag 27. blir siste forelesning. Mulig den ikke blir så lang heller. Men i hvert fall denne uken er den siste. Mens... Jo, mens eksamen er juni her, så jeg tenkte på et eller annet tidspunkt i morgen... Og da i form av en... en inspera-prøveeksamen. Sånn at dere får testet ut nøyaktig hvordan denne typen eksamen er. Og det... skal vi se... det jeg pleier å gjøre, er å bruke konteeksamen fra året før. Så jeg kommer nok til å gjøre det. Kanskje med noen tillegg. Ja... Det får vi se på. Hvis det er noen som... Har noen gode ideer om når det passer best med prøveeksamen. Typisk i forhold til andre fag osv. Det er akkurat samme obligatoriske innleveringer, prosjektinnleveringer osv. Kolliderer med mange andre. Så kom gjerne med forslag til det. Hvis ikke så kommer jeg med et forslag etter hvert. Ja...", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0003", "start": 226.32, "end": 319.76, "token_count": 295, "text": "Typisk i forhold til andre fag osv. Det er akkurat samme obligatoriske innleveringer, prosjektinnleveringer osv. Kolliderer med mange andre. Så kom gjerne med forslag til det. Hvis ikke så kommer jeg med et forslag etter hvert. Ja... Så... Forrige gang så holdt vi på med mutex og semaforer og synkronisering. Så... Et siste tema som er relatert til det, er deadlock. Det fikk vi ikke snakket om forrige gang, så vi skal starte med... Og snakka om det i dag. Så litt om deadlock i starten. Men så etter hvert så er... Vi får se hvor langt vi kommer. Men fullt fokus er da fra på internminne, eller ramm. Og det er et veldig viktig tema. Kanskje spesielt viktig for... Når man kjører programmer og ting går sakte, da er det... Men hvis ting virkelig går sakte og henger, og man har problemer, da er det stort sett ramm som er problemet. Rett og slett at man har for lite ramm. Så det er helt nødvendig. Og vi skal se en del på dette teoretisk først.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0004", "start": 300.0, "end": 431.4, "token_count": 293, "text": "Men hvis ting virkelig går sakte og henger, og man har problemer, da er det stort sett ramm som er problemet. Rett og slett at man har for lite ramm. Så det er helt nødvendig. Og vi skal se en del på dette teoretisk først. Men som atter så kommer vi til å ha en del praktiske demoer. Og forskjellige systemer. Men det kommer jo enda mer tilbake til neste gang, hvor vi skal se på en del veldig spesielle effekter med minnebruk. Hvor ting plutselig går mye saktere, hvor man gjør små endringer. Og det er da typisk pga. cash og andre rammerelaterte grunner. Og det... Vi skal starte litt generelt om ramme og adresserom osv. Og så skal vi se på MMU og paging, som er en veldig viktig bit av alt som har med interne min å gjøre. Og etter hvert noen praktiske eksempler. Ja, så da tenker jeg vi hopper... Til deadlock. Vi skal først på synkronisering. Vi har hele tiden... Det vil si, aller først så så vi på det å multitasking, å parallellisere.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0005", "start": 377.4, "end": 498.0, "token_count": 294, "text": "Og etter hvert noen praktiske eksempler. Ja, så da tenker jeg vi hopper... Til deadlock. Vi skal først på synkronisering. Vi har hele tiden... Det vil si, aller først så så vi på det å multitasking, å parallellisere. Få ting til å gå fort i parallell. Og stort sett så går det veldig fint. Det er bare å kjøre på i parallell så sant det er mulig å parallellisere koden. Men så kom vi til noen tilfeller hvor man må serialisere koden. Rett og slett ødeleggende at kode kjører i parallell. Og det er da typisk hvis man har en felles ressurs som to eller flere tråder jobber opp mot. Da kan de ødelegge for hverandre. Så et system må være tread safe. Det betyr at man ikke må ha tråder som ødelegger for hverandre. Og da må man serialisere og synkronisere. Og vi så forrige gang på forskjellige typer... Serialisering og forskjellige metoder for å gjøre det, bl.a. Mutex og semaforer, monitorer... Dette er teknologier og egentlig tilbud fra operativsystemet", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0006", "start": 471.76, "end": 566.24, "token_count": 286, "text": "Og da må man serialisere og synkronisere. Og vi så forrige gang på forskjellige typer... Serialisering og forskjellige metoder for å gjøre det, bl.a. Mutex og semaforer, monitorer... Dette er teknologier og egentlig tilbud fra operativsystemet til programmereren for å hjelpe til å serialisere. De er bare litt forskjellige, hverandre. I prinsippet så er det samme ting de oppnår. Monitorer, sånn som vi så på i Java, de er enklere å forholde seg til. Det var én enkel metode som man kunne legge rundt en hel blokk, som den synkroniserte metoden. Så den ville da synkronisere hele systemet på en veldig enkel måte. Mens med å bruke mutexer direkte og også semaforer er litt mer komplisert. Så dette er på en måte forskjellige tilbud fra prioritetsstemme til programmerere for å kunne serialisere. Men når man serialiserer på denne måten med mutexer og tvinger prosesser til å vente på hverandre, så får man et problem med at deadlock kan oppstå.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0007", "start": 540.0, "end": 646.56, "token_count": 298, "text": "Så dette er på en måte forskjellige tilbud fra prioritetsstemme til programmerere for å kunne serialisere. Men når man serialiserer på denne måten med mutexer og tvinger prosesser til å vente på hverandre, så får man et problem med at deadlock kan oppstå. Klare kriterier må være tilfredsstilt for at deadlock skal oppstå. Hvis man klarer å unngå alle disse tre kriteriene, kan man si at ok, da unngår jeg deadlock. Men samtidig så er dette gjerne noe man ønsker å få til i et program. Og da må man kode sånn at deadlock ikke oppstår. Det første kriteriet er at man må ha en eller annen form for mutex. Altså, man må ha ressurser som ikke kan deles. Hvis alle ressurser kan deles hele tiden, uten noe problem, så vil ikke deadlock også. Så må man også ha et kriterium at en prosess kan beholde sin ressurs mens den venter på andre. Og også at en prosess ikke kan tvinges til å gi opp sin ressurs. Hvis disse kriteriene er oppfylt, så kan deadlock oppstå. Og vi kan få deadlock ved sirkulær venting. Vi skal se hva det betyr.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0008", "start": 622.64, "end": 717.74, "token_count": 296, "text": "mens den venter på andre. Og også at en prosess ikke kan tvinges til å gi opp sin ressurs. Hvis disse kriteriene er oppfylt, så kan deadlock oppstå. Og vi kan få deadlock ved sirkulær venting. Vi skal se hva det betyr. Ja... Her er et enkelt eksempel på deadlock.  Hvor man generelt kan få deadlock hvis to eller flere prosesser venter på hverandre. Og i det eksempelet her så ser vi at vi kjører prosess A og prosess B. Og de gjør sånn at de skal vente S1 for å vente på en ressurs, og single S1 her nede for å avgi den ressursen. Men da kan vi få et... Et dødlagt problem. Hvis både prosess A og prosess B ønsker å få tak i ressurs S1 og S2, og prosess A sånn tilfeldigvis, så gjør prosess A først en wait på S1, mens prosess B gjør wait på S2. Og så, mens den venter på S1, så ønsker den også å vente på S2. Den vil også ha den ressursen. Og samtidig gjør... Prosess B, det samme, wait på S-en.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0009", "start": 700.82, "end": 774.4, "token_count": 274, "text": "så gjør prosess A først en wait på S1, mens prosess B gjør wait på S2. Og så, mens den venter på S1, så ønsker den også å vente på S2. Den vil også ha den ressursen. Og samtidig gjør... Prosess B, det samme, wait på S-en. Og da vil vi få en låst situasjon. Da ser vi gjerne på eksempel 2 her. Da vil vi få en låst situasjon, hvor prosess A venter på at prosess B skal release S2. For den har vi fått tak i SO. Den har nøkkelen her til SO. Og så venter den på den. Og tilsvarende venter Prosess B på at Prosess A skal release essay. Kanskje de står her med en sånn... Med busy waiting. Står og spinner og venter og venter. Og dette kalte seg en deadlock. Den vil aldri løse seg opp. Eksempel igjen er jo kanskje enklere. Prosess 1 venter på P2. P2 venter på P3, og P3 venter på P1. De bare venter på hverandre.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0010", "start": 759.72, "end": 826.48, "token_count": 290, "text": "Og dette kalte seg en deadlock. Den vil aldri løse seg opp. Eksempel igjen er jo kanskje enklere. Prosess 1 venter på P2. P2 venter på P3, og P3 venter på P1. De bare venter på hverandre. Det kan være en semafor som dette her, men det kunne også være sånn som vi så på forrige gang, at prosess 2 skal være ferdig med noe i koden før prosess 3 går videre, osv. Og dette er sånt som kan oppstå i den virkelige verden også. Jeg husker veldig godt at jeg var ute og kjørte bil, og så kom jeg i et kryss hvor man har vikeplikt fra høyre. Og da hadde jeg tidligere snakket om dette på forelesning, at jo, hvis kommer det et kryss med fire biler som skal inn, og det var vanlig vikerplikt, så... Og da var det sånn at jeg ventet på den som sto ved siden av fra høyre. Den ventet på den som sto ved siden av fra høyre igjen, osv. Rundt hele krysset. Så alle sto og ventet på hverandre.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0011", "start": 812.4, "end": 901.92, "token_count": 298, "text": "og det var vanlig vikerplikt, så... Og da var det sånn at jeg ventet på den som sto ved siden av fra høyre. Den ventet på den som sto ved siden av fra høyre igjen, osv. Rundt hele krysset. Så alle sto og ventet på hverandre. Og jeg var den eneste, kanskje av bilistene, som jublet... Yes! Deadlock! Og løp hjem og fortalte om det til kona. De andre tenkte kanskje ikke så nøye over det, men akkurat denne situasjonen er det som skjer i programmer. Hvor de venter på hverandre, og så kan en deadlock-situasjon som det oppstå. Dining philosophers problem, det er et veldig kjent problem. Hvor deadlock da kan oppstå. Og dette er kjent fordi at det blir ofte brukt som et eksempelproblem. Så man trenger da... Eller man bruker semaforer og mutex osv. Og så skal man programmere disse filosofene til å siste å spise spagetti. Og tenke. Men så må man gjøre det på en sånn måte at man skal programmere Og man unngår deadlock. Problemet, hvis dere kan se her, så er det...", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0012", "start": 882.6, "end": 967.3, "token_count": 300, "text": "Og så skal man programmere disse filosofene til å siste å spise spagetti. Og tenke. Men så må man gjøre det på en sånn måte at man skal programmere Og man unngår deadlock. Problemet, hvis dere kan se her, så er det... Den tegningen skal forestille et bord med fem porsjoner med spagetti. Og så ligger det mellom hver tallerken en gaffel. Og da tenker vi oss at det er fem filosofer som sitter rundt her og skal spise. Og dette må da programmeres som filosofprosesser. Og de oppførte seg sånn at noen ganger så sitter de og tenker... Typisk bare står og spinner uten gafler. Men så er det noen ressurser de deler på, og det er gaflene. Hvis det sitter en øverst her ved bordet, så har han da to gafler som han kan ta. Og systemet er sånn at for å spise så må man ha to gafler. Og da er det typisk sånn... Jo, det er programmer, dette her, så de må da ta opp gafler én av gangen. Og da må de med mutexer og så videre sjekke at gaflene er ledige.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0013", "start": 945.72, "end": 1027.54, "token_count": 296, "text": "Og systemet er sånn at for å spise så må man ha to gafler. Og da er det typisk sånn... Jo, det er programmer, dette her, så de må da ta opp gafler én av gangen. Og da må de med mutexer og så videre sjekke at gaflene er ledige. Så må de plukke opp først én gaffel, og så en til. Og så, når de kommer i gang, så kan de starte med å spise. Og da må de programmere sånn at det er random tidsbruk. Altså de kan sitte og tenke en stund. Og så bestemmer de seg om å begynne å spise. Og så begynner de å spise. Problemstillingen er da å programmere dette sånn at alle sitter og spiser. Alle sitter sånn og spiser. Og så... Jo, programmet må være sånn at de når som helst kan ta en gaffel  At de når som helst kan ta en gaffel og spise, og så må dette flyte. Og dette må gjelde i alle situasjoner. Og da kan det være sånn at dette fungerer veldig fint lenge, og så plutselig kommer du til deadlock.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0014", "start": 1012.68, "end": 1089.66, "token_count": 292, "text": " At de når som helst kan ta en gaffel og spise, og så må dette flyte. Og dette må gjelde i alle situasjoner. Og da kan det være sånn at dette fungerer veldig fint lenge, og så plutselig kommer du til deadlock. Og et eksempel på deadlock da, det vil typisk være at... Jo, tenk om... Hvis vi tenker oss disse fem trådene, kjører på én CPU, så vil du gjøre én ting av gangen. I og for seg så kan akkurat det samme skje hvis vi kjører på fem forskjellige CPU-er. Men i hvert fall hvis man tenker seg at alle samtidig kommer til det steget at de har tatt én gaffel opp. Og så sitter de og holder på den ressursen. Og så gjør alle de andre det samme. For alle tar opp høyre gaffel, og så venter de på at venstre gaffel skal bli ledig. Men hvis man ikke programmerer med høyre, Ja. Det er kommentar her med selvkjørende biler. Ja, og da vil du virkelig få en deadlock. Ja, det er kommentar her med selvkjørende biler.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0015", "start": 1062.04, "end": 1155.36, "token_count": 298, "text": "For alle tar opp høyre gaffel, og så venter de på at venstre gaffel skal bli ledig. Men hvis man ikke programmerer med høyre, Ja. Det er kommentar her med selvkjørende biler. Ja, og da vil du virkelig få en deadlock. Ja, det er kommentar her med selvkjørende biler. Ja, og da vil du virkelig få en deadlock. Når selvkjørende biler blir så avanserte at de kjører ut i trafikken, så er absolutt det noe man må ta hensyn til og få til en deadlock-løsning. Og ja, en mulig løsning kan kanskje være at man... Ja, nei, det er ikke noe... Hvis du tenker på det med selvkjørende biler... Det er et godt eksempel. Det er ikke så enkelt å finne ut hvem som skal kjøre. Det må kanskje være noe sånn at en starter å begynne å kjøre, og så detekterer, men da vil den andre si at... ja. Rangerer man prioritet? Jo, det kunne være en mulighet. Alle biler har en prioritet, så må de snakke sammen... Eller da må de vite hvem som skal kjøre først.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0016", "start": 1131.86, "end": 1227.86, "token_count": 293, "text": "Det må kanskje være noe sånn at en starter å begynne å kjøre, og så detekterer, men da vil den andre si at... ja. Rangerer man prioritet? Jo, det kunne være en mulighet. Alle biler har en prioritet, så må de snakke sammen... Eller da må de vite hvem som skal kjøre først. Men det var et veldig godt eksempel på en virkelig deadlock som kan oppstå, Rent praktisk må kunne løses. Ja. Men kunstig intelligens... Jo, det blir jo en kunstig intelligens, men det er ikke så lett å lære det heller. Kunstig intelligens lærer ofte av tidligere data. Men det er klart. Dette er virkelig... Det er jo kunstig intelligens. Men hovedpoenget her er at dette er noe som... Med en gang man deler på ressurser og prøver å synkronisere seg imellom. Og det er ikke så lett å unngå deadlock, men det er usedvanlig viktig å unngå det. Jeg har kommet med mange gode forslag her. Trafikklys? Jo, det er jo en dag. Men at man har... Man legger inn det i alle kryss.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0017", "start": 1200.14, "end": 1306.82, "token_count": 292, "text": "Og det er ikke så lett å unngå deadlock, men det er usedvanlig viktig å unngå det. Jeg har kommet med mange gode forslag her. Trafikklys? Jo, det er jo en dag. Men at man har... Man legger inn det i alle kryss. Man kan jo på en måte lage software-trafikklys som alle indirekte vet om. OK, men... Ja, så dette er jo deadlock-problemstillingen. Mulige løsninger for deadlock. Ja... Den første og viktigste løsningen er å prøve å forhindre det. F.eks. internt i operativstemkjernen er det utrolig viktig at deadlock forhindres, sånn at prosesser ikke står og venter på hverandre. Og da må man skrive kode som gjør da at det aldri oppstår deadlock. Og det kan være litt vanskelig å programmere, Du må ofte teste det ut, men da kan det være sånn at deadlock oppstår bare i ekstremt sjeldne tilfeller. Og så oppdager man ikke før det skjer i kjørende kode. For vanlige brukerprosesser så er det vanskelig for operativsystemet å garantere at det ikke skjer en deadlock. ", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0018", "start": 1281.86, "end": 1362.46, "token_count": 280, "text": "Du må ofte teste det ut, men da kan det være sånn at deadlock oppstår bare i ekstremt sjeldne tilfeller. Og så oppdager man ikke før det skjer i kjørende kode. For vanlige brukerprosesser så er det vanskelig for operativsystemet å garantere at det ikke skjer en deadlock.  La oss si at operativsystemet tilbyr semaforer med mate and signal. Men hvis to programmer bruker det på denne måten her, så skjer det en deadlock. Og da er det vanskelig for operativsystemet å gjøre noe med det. Så metode to er altså å løse opp en deadlock, men det er generelt vanskelig, for ofte så holder en prosess på en ressurs av en eller annen... Av en grunn. Det er ikke bare tilfeldig at den har tatt den gaffelen. Den skal ha den. Så det er generelt vanskelig å løse opp deadlocker etter at det har skjedd. Så en vanlig måte å håndtere deadlockproblemer på er å stikke hodet i sanden, som strutser gjør. Og det er ofte sånn operativsystemet gjør.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0019", "start": 1342.74, "end": 1437.0, "token_count": 298, "text": "Den skal ha den. Så det er generelt vanskelig å løse opp deadlocker etter at det har skjedd. Så en vanlig måte å håndtere deadlockproblemer på er å stikke hodet i sanden, som strutser gjør. Og det er ofte sånn operativsystemet gjør. Hvis det er brukerdeadlock, så ignorerer operativsystemet det problemet. OK. Da var vi ferdige med deadlock og skedulering og synkronisering og hele den biten. Så nå skal vi starte å se på internmin. Internmin og cash. Vi har vært borti både internmin og cash tidligere. Men vi skal nå se spesifikt på det som spesielt har med ramme å gjøre. Ikke så mye på cash, men vi skal se hvordan ram oppfører seg, og hva som skjer når programmer lager store r-er og bruker store mengder ramm. Og hvordan organiseringen av ramm, ikke minst... hva som skjer når programmer lager store r-er og bruker store mengder ramm.  Hvordan organiseringen av ramm, ikke minst hvordan det skjer i operativsystem. Og jevnt så skjer det i nært samarbeid med hardware.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0020", "start": 1414.14, "end": 1515.74, "token_count": 300, "text": "og hva som skjer når programmer lager store r-er og bruker store mengder ramm. Og hvordan organiseringen av ramm, ikke minst... hva som skjer når programmer lager store r-er og bruker store mengder ramm.  Hvordan organiseringen av ramm, ikke minst hvordan det skjer i operativsystem. Og jevnt så skjer det i nært samarbeid med hardware. Det er mange hardware-spesifikke instruksjoner og konstruksjoner, ikke minst MMU, som er lagd i hardware for at... Det å bruke ramm skal gå fort. Og veldig mye av dette skyldes at ramm i utgangspunktet er relativt tregt. Cash er mye raskere, eller S-ram er mye raskere enn D-ram. Kanskje noen faktorer ti ganger. Så det har vi sett på tidligere... For at man skal hurtigere kunne snakke med Ra. Men utgangspunktet RAM - Random Access Memory... Det høres ut som et litt rart begrep. Random Access. Men hovedpoenget med begrepet Random Access er at det er minnet hvor det går like fort å hente et hvert bite. Uavhengig av hvor det ligger.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0021", "start": 1487.54, "end": 1573.22, "token_count": 285, "text": "Men utgangspunktet RAM - Random Access Memory... Det høres ut som et litt rart begrep. Random Access. Men hovedpoenget med begrepet Random Access er at det er minnet hvor det går like fort å hente et hvert bite. Uavhengig av hvor det ligger. Hvis du skal hente byte nr. 1000 med ram eller random access, så betyr det at det går like fort å hente byte nr. 1000 som det går å hente byte nr. 1000-1000. Uansett hvor det ligger i ram, så går det like fort å hente det. Og det er i og for seg riktig for en standard konstruksjon av ram, I praksis så vil det ta forskjellig tid å hente en gitt bite. F.eks. en variabel svar som man har i et C-program. Hvis man skal gå ut i RAM og hente den, så vil det være forskjellig hvor lang tid det tar. Og det er først og fremst da pga. cash. For hvis du nylig har hentet den verdien, så vil den ligge i cash. Og cash er hurtigminne, og da går det hurtigere å hente.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0022", "start": 1555.82, "end": 1626.86, "token_count": 286, "text": "så vil det være forskjellig hvor lang tid det tar. Og det er først og fremst da pga. cash. For hvis du nylig har hentet den verdien, så vil den ligge i cash. Og cash er hurtigminne, og da går det hurtigere å hente. Sånn sett er det ikke random access i forhold til om du henter en variable eller en bite som ikke har vært i minnet på lang tid. Da vil det gå raskt å hente det. Et annet tilfelle vi har hvor det er forskjell på tiden, det er med såkalt nummanoder. Eller så er det servere som har mange CPU-er. Altså sånn titalls CPU-er. Sånn som noen av de vi har sett på, med 48 CPU-er. Eller sånn som den serveren som dokkecontainerne kjører i, Linux-VM-ene, som vi kaller dem, den har 60 CPU-er eller noe sånt. Den, den er da... Den har da et system av numa-noder. Og det betyr at det er en slags cluster av CPU-er, kanskje seks eller åtte av gangen, som tilhører spesielle noder.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0023", "start": 1605.1, "end": 1689.26, "token_count": 289, "text": "Linux-VM-ene, som vi kaller dem, den har 60 CPU-er eller noe sånt. Den, den er da... Den har da et system av numa-noder. Og det betyr at det er en slags cluster av CPU-er, kanskje seks eller åtte av gangen, som tilhører spesielle noder. Som ligger nærmere de nodene. Rent og slett fysisk nærmere, sånn at de har raskere aksess. De har en egen minibuss ut dit. Så NVE Superbude kan hente da bites fra hele ramm, men i noen tilfeller vil det ta lengre tid, fordi de ikke sitter på den nummadoden som de selv hører til. Og da vil heller ikke RAN være helt random aksess. Det går like lang tid å hente hver bite. Og dette er veldig forskjellig fra harddisker, som vi skal se på senere. Iallfall spinnende, tradisjonelle harddisker. Der er det avhengig av hvor lesehodet til harddisken står, osv. På hvor lang tid det tar å hente en gitt del av minnet. Ok. Men som vi har sett tidligere...", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0024", "start": 1670.88, "end": 1759.6, "token_count": 283, "text": "Iallfall spinnende, tradisjonelle harddisker. Der er det avhengig av hvor lesehodet til harddisken står, osv. På hvor lang tid det tar å hente en gitt del av minnet. Ok. Men som vi har sett tidligere... Register og cash er laget av S-ram, static-ram. Det består av seks temas historier. Jeg har sett på konstruksjonen av det tidligere. Det er ekstremt hurtig, og det er statisk. Det trenger ikke å oppfriskes. Ram eller internmine, derimot, det er laget av D-ram, dynamic-ram. Og det er en mye enklere konstruksjon. Det består bare av én transistor, og så er det én kondensator. En kondensator er da et lite element som kan holde på ladning. Så det holder på statisk ladning. Litt sånn som en ballong som du gnir på, så får du statisk ladning. En kondensator kan da holde en liten ladning, og det vil da være en én eller null. Men denne ladningen må oppfriskes ca. ti ganger i sekundet.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0025", "start": 1732.5, "end": 1821.18, "token_count": 291, "text": "Så det holder på statisk ladning. Litt sånn som en ballong som du gnir på, så får du statisk ladning. En kondensator kan da holde en liten ladning, og det vil da være en én eller null. Men denne ladningen må oppfriskes ca. ti ganger i sekundet. Så da må man ha en liten loop som går og oppfrisker alle verdiene i RAM hele tiden. Så det betyr jo opplagt at hvis man skrur av en maskin, så forsvinner alt som er i RAM. Ingenting av det som er i RAM. Selvfølgelig ikke det i registeret heller. Men... Så det betyr at alt som skal lagres permanent, det må lagres på disk. På harddisker, der ligger det permanent. Ja... Tidligere så var det ikke vanlig å synkronisere deRam. Men... Ja, for kanskje sånn 15-20 år siden, så... Så ble det vanlig å synkronisere det ram, sånn at lesing og skriving var synkronisert med en ekstern klokke. Sånn som det alltid har vært i CPU-en. Der har vi en klokke.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0026", "start": 1805.18, "end": 1896.18, "token_count": 292, "text": "Men... Ja, for kanskje sånn 15-20 år siden, så... Så ble det vanlig å synkronisere det ram, sånn at lesing og skriving var synkronisert med en ekstern klokke. Sånn som det alltid har vært i CPU-en. Der har vi en klokke. Men det er også en klokke ut mot databussen, sånn at man synkroniserer lesing og skriving. Og da finnes det forskjellige versjoner av ram. Alle nyeste er DDR5. DDR4 var den forrige. DDR står for Double Data Rate. Så alt dette er hesteram, men det har vært versjoner som har kommet, som har vært mer og mer effektive. Og den typiske forskjellen er at de har høyere klokkefrekvens på databussen, sånn at de raskere kan overføre data. Den har vi også sett på videre. Dette er det veldig viktig å ha med seg. Vi starter helt innerst her med registeret. Og her inne... Registrene er ekstremt hurtige. Og så er det altså med avstanden. Registrene ligger inne i CPU-en,", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0027", "start": 1869.58, "end": 1959.54, "token_count": 297, "text": "Den har vi også sett på videre. Dette er det veldig viktig å ha med seg. Vi starter helt innerst her med registeret. Og her inne... Registrene er ekstremt hurtige. Og så er det altså med avstanden. Registrene ligger inne i CPU-en, og man kan kopiere mellom registrene. På mindre enn et nanosekund, altså typisk på én eller to klokkesykler, så kan man kopiere mellom registrene. Mens LNCash, det er da fortsatt SRAM. Det er på en måte samme teknologi, men det ligger litt lenger ut, så det tar litt lengre tid. Og så kommer du enda lenger ut til L2Cash. Eltre Cash er gjerne hakke utenfor der igjen også, men noen flere nanosekunder. Og der ser vi at det er en faktum på minst ti inn til registrene. Det er denne forskjevnen som gjør at cash er så viktig. Man klarer rett og slett ikke å få inn data fort nok til CPU-en uten å bruke cash. Så kommer et hakk ut til disker. Solid State-disker. Skal se mer på det senere. De har Random Access på samme måte som RAM.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0028", "start": 1936.02, "end": 2028.86, "token_count": 285, "text": "Det er denne forskjevnen som gjør at cash er så viktig. Man klarer rett og slett ikke å få inn data fort nok til CPU-en uten å bruke cash. Så kommer et hakk ut til disker. Solid State-disker. Skal se mer på det senere. De har Random Access på samme måte som RAM. At du kan ta like lang tid å hente en hvilken som helst bite. Men det går mye saktere. Det er en fakta på i hvert fall 1000 i forhold til RAM. Og så har du kanskje grovt sett en fakta på 1000 til igjen ut til fysiske harddisker som spinner rundt. Så der går det veldig mye saktere. Her nede. Adresse 0. Her er det 8-bit som utgjør én bite. Og så er det adresse 1 osv. oppover. Og her ser du 42. Dette er 2 i 32. Så dette er 4 giga med adresser. Og dermed har du 4 gigabyte med... Med ram i dette R-øyet. Så det er viktig å huske. Det er bare ett stort R-øy som programmerer,", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0029", "start": 2002.3, "end": 2107.5, "token_count": 295, "text": "Og her ser du 42. Dette er 2 i 32. Så dette er 4 giga med adresser. Og dermed har du 4 gigabyte med... Med ram i dette R-øyet. Så det er viktig å huske. Det er bare ett stort R-øy som programmerer, så kan vi tenke på det. Ett stort R-øy med bites som ligger etter hverandre. Så har vi sett tidligere hvordan f.eks. vi har lagret en 64-bit... Som trenger fire bite. Og da setter man typisk av de fire bitene etter hverandre til en variabel. Det er en litt sånn teknikalitet. Men i virkeligheten så er det bare bite som ligger etter hverandre i et svært ærøy. Adresserommet... Vi trenger da å kunne adressere alle bitene som ligger der. Og disse adressene må da kunne lagres i registeret. Og det har vi sett på tidligere, at vi har brukt move f.eks. for å flytte noe fra ram og inn i de interne registrene i CPU-en. Og da har vi brukt registeret sånn som prosent-rsp, som er da en peker... Prosent-rsp peker til toppen av stacken.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0030", "start": 2084.54, "end": 2198.5, "token_count": 287, "text": "Og det har vi sett på tidligere, at vi har brukt move f.eks. for å flytte noe fra ram og inn i de interne registrene i CPU-en. Og da har vi brukt registeret sånn som prosent-rsp, som er da en peker... Prosent-rsp peker til toppen av stacken. Det er et tilspørsmål i chatten her. GDDR... Ja, det er vel sånn GPU-ram... Det er jeg ikke sikker på. Men det er det. Det høres veldig sånn ut at det er grafikkram. Jeg kan sjekke ut det i pausen. Jo, et annet eksempel på adresserom, det er sånn som IP-adresser. Da har vi alle adresser fra 00 til 255, 255, 255, 255. Alle IP4-adresser må ligge innenfor dette adresserommet. Det var derfor man måtte begynne med IPv6, fordi det var til slutt ikke nok adresser i adresserommet. Samme problemstillingene har man i internminet. Generelt så er det veldig enkelt adresserom for internminet. Det går bare fra null til maks. Men så trenger man å...", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0031", "start": 2175.78, "end": 2280.42, "token_count": 295, "text": "Det var derfor man måtte begynne med IPv6, fordi det var til slutt ikke nok adresser i adresserommet. Samme problemstillingene har man i internminet. Generelt så er det veldig enkelt adresserom for internminet. Det går bare fra null til maks. Men så trenger man å... Så trenger man å ha et register for å lagre en adresse. Til å begynne med hadde man 16-bits CPU-er. Og da hadde du en registerstørrelse på 16 bit. Hvis du da skulle lagre alle adressene, så er det bare plass til to i 16-adresser. Og det er 64K. Og derfor er det mange sånne gamle computere... Kommodorer, 64, osv. For da hadde de et adresserom som var på 64 000. Og der kunne man lagre 64 kilobyte, og det var punktet. Etter hvert så fikk man 32-bitsregisteret. Og da hadde man to i 32. Det er 4G. Det var også et sånt problem... Det var med 32-bits CPU-er. Hvis man kjørte Linux og hadde mer enn 4 GB ram, så fikk man straks et problem.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0032", "start": 2255.74, "end": 2364.86, "token_count": 295, "text": "Og da hadde man to i 32. Det er 4G. Det var også et sånt problem... Det var med 32-bits CPU-er. Hvis man kjørte Linux og hadde mer enn 4 GB ram, så fikk man straks et problem. Mange av de CPU-ene støttet ikke det å bruke 4G-ram. Så etter hvert kom det 64-bits-registeret, og da har man mer enn nok. Størrelse på adresserommet. Selv to opphøyde 48 gir 256 terabyte. Så det er mer enn nok for rammedelen. Så da er det ikke noe problem med antall bit i registrene. Men generelt så må du da kunne ha et register som kan lagre alle adressene i IRA. Ja... Virtuelt adresserom... Vi deler da... Vi har et fysisk adresserom. Det er liksom alle adressene fra null til maks. Men generelt så er det ikke plass i alle programmer i internminnet på en gang. Hvis du har veldig mange programmer, så må de til en viss grad lastes. Og i tillegg, som vi skal se, så er det veldig nyttig å kunne ha et virtuelt adresserom, for at man da dynamisk kan velge", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0033", "start": 2338.18, "end": 2435.98, "token_count": 290, "text": "Men generelt så er det ikke plass i alle programmer i internminnet på en gang. Hvis du har veldig mange programmer, så må de til en viss grad lastes. Og i tillegg, som vi skal se, så er det veldig nyttig å kunne ha et virtuelt adresserom, for at man da dynamisk kan velge hvilke biter av et program som er med. Sånn man organiserer det, er at hvert enkelt program får et adresserom fra null til maks, f.eks. til 4G hvis det er Og hver prosess lokalt tror at den har tilgang til alt dette minnet. Den har et kjempesvært adresserom. Men i virkeligheten så ligger noe av dette minnet i ramm, og andre ligger på disken. Eller andre deler er ikke i bruk i det hele tatt. Så disse logiske adressene... De brukes overalt hvor programmet refererer til nå. F.eks. en sånn institusjon som dette er - move1023 til AL. Det sier move det som ligger i minneadresse 1023, inn i registeret AL. Men 1023 er da den virtuelle adressen. Det er ikke den faktisk fysiske adressen.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0034", "start": 2409.58, "end": 2504.38, "token_count": 290, "text": "De brukes overalt hvor programmet refererer til nå. F.eks. en sånn institusjon som dette er - move1023 til AL. Det sier move det som ligger i minneadresse 1023, inn i registeret AL. Men 1023 er da den virtuelle adressen. Det er ikke den faktisk fysiske adressen. Opprinnelig, i de aller første datamaskinene, så var det... Så brukte man ikke et virtuelt adresserom, og da var 1023 Byte nummer 1023 i RAM. Men nå har vi et system hvor alle disse adressene hele tiden oversettes til fysiske adresser. Og dette gjøres da av MMU, som vi skal se på i detalj. Memory Management Unit. Og... Siden dette gjøres om ikke ved hver institusjon, så hver eneste gang man adresserer RAM i det hele tatt, så må denne oversettelsen gjennomføres. Og det betyr at det må gå ekstremt raskt, for dette skjer hele tiden. Så alle programmer som snakker med minnet, de må få sin virtuelle adresse oversatt til den fysiske. Og det skjer om og om igjen, og da har man ikke...", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0035", "start": 2477.86, "end": 2581.5, "token_count": 298, "text": "så må denne oversettelsen gjennomføres. Og det betyr at det må gå ekstremt raskt, for dette skjer hele tiden. Så alle programmer som snakker med minnet, de må få sin virtuelle adresse oversatt til den fysiske. Og det skjer om og om igjen, og da har man ikke... Da har man ikke noe tid til å bruke CPU-sykler på å få dette til, så dette må nærmest lagres i... Eller, det må lages i hardware. Og det er nettopp det MMU er. Det er hardware som oversetter fra virtuelle adresser til fysiske adresser. Men jeg ser vi trenger en pause nå, så da skal vi se på... Nøyaktig hvordan det gjøres etter pause. Vi skal ha et par... Et par eksempler på minnebruk også. Men så skal vi... Så skal vi se på nøyaktig hvordan MMU virker. Ja... Jeg ser Ina har kommet opp med et godt svar her. Det er typisk sånt som brukes i GPU-er, som er da prosessoren som prosesserer grafikk. Og GPU-er har typisk veldig mange uavhengige kjerner. De har små kjerner med relativt lite ramte hver,", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0036", "start": 2548.98, "end": 2654.92, "token_count": 285, "text": "Ja... Jeg ser Ina har kommet opp med et godt svar her. Det er typisk sånt som brukes i GPU-er, som er da prosessoren som prosesserer grafikk. Og GPU-er har typisk veldig mange uavhengige kjerner. De har små kjerner med relativt lite ramte hver, men de kan kanskje ha 4096 uavhengige kjerner som kan jobbe i parallell. Og det er opplagt nyttig når man jobber på grafikkenheter. Hvis man skal vri om på et 3D-bilde med enormt mange bits, så kan de operasjonene da gjøres i parallell. 4096 operasjoner gjøres helt samtidig. Det tilsvarer parallelle CPU-er, men de er mindre, og så gjør de akkurat denne operasjonen. Som er spesifisert for dem. Og GDDR er da den type ramme som GPU-ene bruker. Altså de grafiske prosessorenhetene. Ok. Men da tar vi en pause der. 9.19. Vi kan starte igjen... Hva blir det? 9.35. Så starter vi igjen. Da skal vi se på...", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0037", "start": 2623.26, "end": 2661.54, "token_count": 93, "text": "Og GDDR er da den type ramme som GPU-ene bruker. Altså de grafiske prosessorenhetene. Ok. Men da tar vi en pause der. 9.19. Vi kan starte igjen... Hva blir det? 9.35. Så starter vi igjen. Da skal vi se på... Ja, det viktigste etter pause ble å se på hvordan MMU fungerer.", "source": "lecture"}
{"lecture_id": "os13del19", "chunk_id": "os13del19_0000", "start": 0.0, "end": 64.16, "token_count": 188, "text": "Ja, først er det spørsmål om R32 fra starten av den designerte startadressen. Ja... Jeg antar du spørsmålet gjelder... den her. Low 32, det vil være når... Helt konkret, når man kompilerer, så vil kompilatoren lage minneadresser. Det er det logiske adresserommet, og det logiske adresserommet start på null. Love 32 er en logisk eller virtuell adresse innen det adresserommet som Programmet 1 tror han er ene hersker over. Programmet vet ikke når det blir lovd ut, om dette blir fysiske adresser eller ikke. Men det betyr ikke noe at programmet gjør det, for dette sørger MMU for. Det blir oversatt til i dette tilfellet 134.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0000", "start": 0.0, "end": 128.72, "token_count": 285, "text": "Så nå er opptak startet. Skal vi se... Dette er planen for i dag. Vi skal snakke mer om internminne. Forrige gang så snakket vi ganske mye teoretisk om internminne, om hvordan MMU virker spesielt. I dag skal vi se... I større grad på det praktiske. Vi skal kjøre ganske mange forskjellige eksempler på minnebruk og hva som skjer når man kjører programmer som bruker mye minne. Og også hvordan man kan se på detaljene av minnebruken i topp. Skal vi se... Som dere ser, så er det... Vi nærmer oss slutten med stormskritt. Neste uke er siste forelesning. Det kommer til å være om disker og filsystemer. Vi håper å få begynt på det i dag. Så ser vi også at vi har rotet litt ned med mengden stoff her. De siste to ukene så er det ikke digitale forelesninger i tillegg, som det har vært tidligere, med Linux-shell og med power-shell. Så de to siste ukene blir litt roligere, og dere kan også se at det er litt færre oppgaver.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0001", "start": 103.98, "end": 198.54, "token_count": 276, "text": "Så ser vi også at vi har rotet litt ned med mengden stoff her. De siste to ukene så er det ikke digitale forelesninger i tillegg, som det har vært tidligere, med Linux-shell og med power-shell. Så de to siste ukene blir litt roligere, og dere kan også se at det er litt færre oppgaver. Det kommer nok én til om disker, eventuelt så kommer de neste uke. Litt avhengig av hvor langt vi kommer. Men oppgavene går ut på å teste ut noe av det jeg skal se på nå i dag, på Linux-VM. Er tilgjengelig i chatten, så still gjerne spørsmål i chatten. Du kan gjerne stille til alle. Men det går også an å stille direkte til Ine, så kan hun svare direkte. Eventuelt så kan vi ta det i pausen. Ja, hvor var jeg? Jo, neste uke er siste runde. Det kommer noen flere disk-oppgaver de siste ukene. Det er ikke noen oblig 4. Oblig 3 var den siste. Men oppgavene som er merket med oblig, er ment som", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0002", "start": 162.28, "end": 259.88, "token_count": 299, "text": "så kan hun svare direkte. Eventuelt så kan vi ta det i pausen. Ja, hvor var jeg? Jo, neste uke er siste runde. Det kommer noen flere disk-oppgaver de siste ukene. Det er ikke noen oblig 4. Oblig 3 var den siste. Men oppgavene som er merket med oblig, er ment som de som det er viktigst å få med seg i forhold til pensum og i forhold til eksamen. Ordinære forelesning, men jeg tenker å få til en prøveeksamen. Kanskje jeg kan få til to også, for jeg har... I hvert fall så har jeg... Det som var prøveeksamen i fjor, det har jeg på en måte... Et opptak av hvor jeg går gjennom alle oppgavene én for én. Så det kan være en fin test. En prøveeksamentest. Hvor dere da... Dere får en full eksamensoppgave og så går dere gjennom den på egen hånd. Og så kan dere i ettertid, hvis det er noen spørsmål dere står fast ved, så kan dere gå inn og se på hvordan jeg mente den skulle løses. Tilsvarende kommer dere til å bli for prøveeksamen.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0003", "start": 240.0, "end": 349.8, "token_count": 285, "text": "Dere får en full eksamensoppgave og så går dere gjennom den på egen hånd. Og så kan dere i ettertid, hvis det er noen spørsmål dere står fast ved, så kan dere gå inn og se på hvordan jeg mente den skulle løses. Tilsvarende kommer dere til å bli for prøveeksamen. Da kan vi først ha en prøveeksamen, og så, dagen etter eller litt senere, så går vi gjennom den prøveeksamen i plenum. Altså felles. Kanskje det til og med kunne være fysisk... Nå tør jeg i hvert fall ikke å love noe. Det har vært mye kanskje tidligere. Så hvis det ikke er noen spørsmål til noe rundt kurset, så begynner vi med dagens pensum. Ja... Jeg går hakket tilbake. Før vi begynner... Det kan være lurt å ta en liten kikk på det vi holdt på med sist. Spesielt internminedelen. Det aller viktigste å ha med seg, er at internmelding eller RAM det er da bare en rekke med bite som ligger etter hverandre. Og RAM... Random Access Memory...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0004", "start": 300.0, "end": 415.02, "token_count": 281, "text": "Ja... Jeg går hakket tilbake. Før vi begynner... Det kan være lurt å ta en liten kikk på det vi holdt på med sist. Spesielt internminedelen. Det aller viktigste å ha med seg, er at internmelding eller RAM det er da bare en rekke med bite som ligger etter hverandre. Og RAM... Random Access Memory... Det er random fordi det skal ta like lang tid å hente et hvilket som helst bitt. I så syst at det er ikke helt sant, spesielt pga.... ... cash, så vi ser at det tar forskjellig tid å hente forskjellig bit. Det skal vi se på i detalj i dag, i praksis. Videre så vi mye på MMU, Memory Management Unit. Og det er da en hardware-enhet som oversetter adresser. For alle prosesser har sitt eget adresserom. Den starter fra null og går oppover. Og dette kalles da virtuelle adresser. Og de virtuelle adressene oversettes til fysiske adresser av MMU. Så inni selve prosessen tenker den bare på adresser fra 0 til 1 GB. Men de oversettes til fysiske adresser i RAM.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0005", "start": 390.0, "end": 485.36, "token_count": 292, "text": "Og dette kalles da virtuelle adresser. Og de virtuelle adressene oversettes til fysiske adresser av MMU. Så inni selve prosessen tenker den bare på adresser fra 0 til 1 GB. Men de oversettes til fysiske adresser i RAM. Og da kan minneadressering nummer 1000, for eksempel, den kan... Den ligger i 14 367 millioner i ram. Og dette gjør at operativsystemet da dynamisk kan laste inn og ut sider av ram, og ikke minst laste inn og ut prosesser etter hvert som det kommer nye prosesser. Og dette er helt nødvendig for et moderne operativsystem for å kunne håndtere minnet på en ordentlig måte. Så vi så mye på det. Page table entres... Som var da den minste enheten som viser hvor en side ligger. Så det man gjorde, var istedenfor bare å se på bite for bite, så lagde man sider. Typisk 4K, 4000 bite. En sånn passe side, som er da den minste enheten som man tar inn og ut av. I tillegg så så vi på TLB fra en slite. Det er da cash for minneadressering,", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0006", "start": 458.44, "end": 562.44, "token_count": 294, "text": "Så det man gjorde, var istedenfor bare å se på bite for bite, så lagde man sider. Typisk 4K, 4000 bite. En sånn passe side, som er da den minste enheten som man tar inn og ut av. I tillegg så så vi på TLB fra en slite. Det er da cash for minneadressering, og som også har en stor effekt på hvor fort ting går. Heldigvis ligger stort sett minneofflag i TLB. Man får mye treffe-cash, og dermed så går det veldig mye raskere enn det ellers ville gjort. Da kan vi hoppe til dagens program, og da fortsetter vi der vi sluttet. Der. Dynamisk allokering. Som dere sikkert har prøvd selv, så kan man be om mer ram mens man kjører et program. Altså, man kan deklarere alt som er av variabler osv. i starten av programmet. Og så bare bruke det. Men man kan også, sånn som Java... Det man typisk gjør, er å ha statements om dette her. PCB er en ny prosess midt inn i programmet. Og da vet jo ikke operativsystemet eller noen andre om at dette her kommer til å skje.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0007", "start": 540.0, "end": 629.82, "token_count": 297, "text": "Og så bare bruke det. Men man kan også, sånn som Java... Det man typisk gjør, er å ha statements om dette her. PCB er en ny prosess midt inn i programmet. Og da vet jo ikke operativsystemet eller noen andre om at dette her kommer til å skje. F.eks. så kan man gi input underveis til et RA hvor langt det skal være. Og da må det lages underfly. Det må sette seg plass i minnet. Da er det veldig fint å ha paging, for da kan operativsømme sette av nye sider til denne prosessen dynamisk. Og da får prosessen, når den gjør noe sånt som dette, page for page med minne. Det kan jo være en sånn... Det kan jo være... Dette krever... Mange megabyte med minne og lag et nytt objekt, så... Men da får prosessen tillagt så mange sider som den trenger. I CAs C pluss pluss så må man... Når man allokerer minnet på den måten her... Vi skal se et seeksempel etterpå. Så må man etterpå slette sånne objekter som er i bruk. Hvis man hele tiden allokerer mer og mer minne uten å frigjøre det...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0008", "start": 610.76, "end": 688.8, "token_count": 300, "text": "I CAs C pluss pluss så må man... Når man allokerer minnet på den måten her... Vi skal se et seeksempel etterpå. Så må man etterpå slette sånne objekter som er i bruk. Hvis man hele tiden allokerer mer og mer minne uten å frigjøre det... Så får man det som man kaller en minnelekkasje. Det er et vanlig problem i programmering, altså i store servere osv. Det er et eller annet som gjør at når du kjører programmet lenger og lenger, så bruker det mer og mer minne. Og så går det tregere og tregere. Og det er en typisk minnelekkasje. Det vil bare si at man allokerer mer og mer minne. Som ikke blir frigjort. Så det må programmereren sørge for, at man frigjør mine hele tiden. Det er en av de store fordelene med mange nyere programmeringsspråk, sånn som Java. Dere tenker kanskje ikke på Java som supernytt, men i forhold til COC pluss pluss så er det relativt nytt. Og det utfører da denne oppryddingen automatisk. Såkalt garbage collection.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0009", "start": 668.18, "end": 768.6, "token_count": 293, "text": "Det er en av de store fordelene med mange nyere programmeringsspråk, sånn som Java. Dere tenker kanskje ikke på Java som supernytt, men i forhold til COC pluss pluss så er det relativt nytt. Og det utfører da denne oppryddingen automatisk. Såkalt garbage collection. Som skjer hele tiden bak kulissene. Så hvis dere har et RAI eller noen objekter som ikke brukes lenger, så fjernes det fra minnet, sånn at minnet blir frigjort til andre programmer eller andre variabler i samme program. Den delen av ramm som dynamisk kan øke og minke i størrelse, det kalles heap. Forrige gang så vi et minnekart i Linux, der dere hadde én del som var heapen. Her legges alt som er av ri og sånn, som øker og minsker i størrelse. Mens vi har stacken også. Den inneholder f.eks. alt som har med å hoppe til og fra metoder å gjøre. En organisering av ramm som operativstemme sørger for. Ok. Da... Før vi ser på noen minnebegreper, så skal vi se litt sånn i praksis på...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0010", "start": 735.58, "end": 854.26, "token_count": 289, "text": "Mens vi har stacken også. Den inneholder f.eks. alt som har med å hoppe til og fra metoder å gjøre. En organisering av ramm som operativstemme sørger for. Ok. Da... Før vi ser på noen minnebegreper, så skal vi se litt sånn i praksis på... Vi skal se litt i praksis på ramm og kjøring av ramm. Se et konkret eksempel på litt av det jeg snakket om her med dynamisk allokering. Hvis jeg klarer å finne det... Der, ja. Her har jeg et lite oppsett for å kjøre en demo. Det jeg skal se på, er et se-program. Men det vi aller først ser her, er at vi definerer et stort RA. Og da har jeg definert et tall S, som er 1024 ganger 1024. Dette er bare fordi jeg skal få én megabyte, eller det er et int RA. Så én int er fire bytes. Derfor blir dette fire mer. Dette er da et RA som tar... Hvis størrelsen er 4 MB... Før vi gjør det, så kan du... Altså... Det første vi skal gjøre, er bare å se på hva som skjer", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0011", "start": 833.96, "end": 912.56, "token_count": 288, "text": "Så én int er fire bytes. Derfor blir dette fire mer. Dette er da et RA som tar... Hvis størrelsen er 4 MB... Før vi gjør det, så kan du... Altså... Det første vi skal gjøre, er bare å se på hva som skjer når vi deklarerer dette RA-et, og så begynne å kjøre. Og så ser vi nedover i programmet her... Så ser vi at det stopper ved første linje og skriver ut størrelse kolon. Og Scanf leser inn den variabelen. Så... Det programmet vil skrive størrelse, og så vil det stoppe der. Etterpå skal vi se hvordan vi da kan lese inn størrelsen på et RAI, og så allokere det med Mallock. Men vi ser først bare på starten, og da trenger vi bare å bry oss om de tre første linjene her. Så kanskje det vi kan gjøre aller først, er også bare å lage et bitte lite RAI med én bite. For det vi skal se på nå, er hvordan... Hvordan ser det ut i topp når vi kjører dette programmet? Og programmet heter RES, så jeg kompilerer det sånn.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0012", "start": 885.16, "end": 985.52, "token_count": 293, "text": "og da trenger vi bare å bry oss om de tre første linjene her. Så kanskje det vi kan gjøre aller først, er også bare å lage et bitte lite RAI med én bite. For det vi skal se på nå, er hvordan... Hvordan ser det ut i topp når vi kjører dette programmet? Og programmet heter RES, så jeg kompilerer det sånn. Og så kjører jeg det med Adopt Out. Da ser vi jeg blir bedt om størrelse. Men det jeg ønsker å gjøre nå, er å se på det i topp. Den sier Topp minus P... For nå ønsker jeg å se på akkurat... bare topp for dette programmet. Når jeg gjør Topp minus P, kan jeg spesifisere hvilken payday jeg vil se på. Og så i tillegg payday of adots. Jeg kan gjøre det eksplosivt. Dermed kan jeg starte Topp på den måten her. Og så får jeg se bare info om Adolthout. Det er denne infoen her om minnene som vi skal se på nå. Tidligere har vi sett på Payday og Priority og Nice osv. Men nå skal vi se på de tre bitene der - Hvirt, Dress og Sjel. ", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0013", "start": 964.28, "end": 1063.2, "token_count": 299, "text": "Og så får jeg se bare info om Adolthout. Det er denne infoen her om minnene som vi skal se på nå. Tidligere har vi sett på Payday og Priority og Nice osv. Men nå skal vi se på de tre bitene der - Hvirt, Dress og Sjel.  Og kortversjonen er at hvitt, det er på en måte det virtuelle adresserommet. Det er så mye som er definert for denne prosessen. Altså så mye ram. Og ram her er definert i K. Så dette betyr at det er 4516 K med virtuelt adresserom. Så det er det som det lages plass til for hele prosessen. Alt den inneholder. Og så kommer det en kolonne som heter Ress. Der ser vi det er 748K. Og Ress, det er det som er resident. Altså det som ligger i Ramm nå, og som er i bruk. Her i Hvirt så ligger alt, men det er ikke alt som er i bruk. Og det kommer ikke nødvendigvis i bruk. Det spørs hvordan programmet kjøres. Men hvis mer tas inn i RAM, så skal vi se... Da vil RS øke. Men det vi først kan se, er... VIRT gir 4516 K.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0014", "start": 1038.84, "end": 1139.78, "token_count": 277, "text": "Her i Hvirt så ligger alt, men det er ikke alt som er i bruk. Og det kommer ikke nødvendigvis i bruk. Det spørs hvordan programmet kjøres. Men hvis mer tas inn i RAM, så skal vi se... Da vil RS øke. Men det vi først kan se, er... VIRT gir 4516 K. Og så kan vi prøve å se... Ja... Da kan vi prøve å lage det R-et. Men denne gangen lage en 4MB RA. Så da stopper jeg programmet igjen, og så går jeg inn her, og så bruker jeg den opprinnelige S-faktoren. Og da... For å se hva som skjer, så kan jeg regne litt her nede. Jeg kan regne ut 1024 ganger 1024. Ja, det blir omtrent én million, men det jeg egentlig er interessert i, det er hvor mye vil... Hvor mye vil VIRT øke når jeg legger på et R-øy? Da må jeg kanskje ta med og... Skal vi se hva vi hadde her. Vi hadde VIRT er lik 4516. Sånn. Og så skal jeg nå øke...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0015", "start": 1110.16, "end": 1221.82, "token_count": 293, "text": "det er hvor mye vil... Hvor mye vil VIRT øke når jeg legger på et R-øy? Da må jeg kanskje ta med og... Skal vi se hva vi hadde her. Vi hadde VIRT er lik 4516. Sånn. Og så skal jeg nå øke... Nå burde jo den VIRT-adresserommet øke med fire ganger 1024 ganger 1024. Og det vil si... Den burde da øke med fire ganger 1024. Eller... Ja, jeg kan skrive det. Fire ganger 1024. For det er K vi snakker om. Da burde det komme 8612 K. Så skal vi se hva som skjer her, da, om vi får til det. Jeg kompilerer nå på nytt med det store re-eiet med 1 mill. integer. Så må jeg starte Topp på nytt for å få med den riktige add-out. Og da ser vi... Jo, det fungerer faktisk akkurat. Da står det 8612 her, som er da... ... det opprinnelige adresserommet vi hadde. Så har vi i tillegg definert fire... Hva blir det? Fire megabyte. Og det er da fire ganger 1024 K.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0016", "start": 1193.4, "end": 1297.88, "token_count": 283, "text": "Og da ser vi... Jo, det fungerer faktisk akkurat. Da står det 8612 her, som er da... ... det opprinnelige adresserommet vi hadde. Så har vi i tillegg definert fire... Hva blir det? Fire megabyte. Og det er da fire ganger 1024 K. Den størrelsen der i hvitt. Men vi ser... Så det passet akkurat med teorien. Men vi ser... Ress her er fortsatt 748. Så kan man spørre seg hvorfor... Hvorfor ble ikke den endret? Jo, det er fordi... Hvis vi ser i koden her, så har vi bare kommet hit. Ikke begynt å bruke det static-eriet i det hele tatt. Så etter hvert som man begynner å bruke det, så vil da res kunne øke. Men i stedet for å bruke det, så skal vi se nå på hvordan vi kan legge til statisk minne. Så nå glemmer vi den... Da glemmer vi den første. Og så... skal vi se på statusen min. Det er ett spørsmål i chatten her. Kjempebra. Stopp og spør. Vi...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0017", "start": 1273.78, "end": 1393.12, "token_count": 279, "text": "vi kan legge til statisk minne. Så nå glemmer vi den... Da glemmer vi den første. Og så... skal vi se på statusen min. Det er ett spørsmål i chatten her. Kjempebra. Stopp og spør. Vi... Spørsmålet va. Hvorfor ble det fire ganger 1024? Jo, da må vi for det første vite at... En jente er fire bite. Så for det første så ble... En jente er fire bite. Og så i tillegg... Så dette... Dette teller jo opp antall elementer. 1024 ganger 1024. Det er én mega. Men det vil også si at når vi regner i K, så er dette 1024 K. 1024 bite, det er 1 K. Så dermed ble totalstørrelsen på dette ærøyet, dette her, det ble fire ganger 1024 K. Eller fire ganger 1024 ganger 1024 bite. Så derfor ble det fire ganger 1024. Så... fire ganger 1024... Ganger 1024 er lik 4096 K. Så det er det som var de fire ganger 1024 her nede.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0018", "start": 1355.48, "end": 1471.32, "token_count": 292, "text": "Eller fire ganger 1024 ganger 1024 bite. Så derfor ble det fire ganger 1024. Så... fire ganger 1024... Ganger 1024 er lik 4096 K. Så det er det som var de fire ganger 1024 her nede. Ok. Da skal vi gå tilbake. Nå skrur jeg av det er-eiet her. Et like stort RI dynamisk. Da stopper jeg Adataut igjen. Sånn. Og så ser vi... Ja, da kan vi egentlig bare kompilere det programmet her. Og starte det. Så kan vi gå og se på topp hva som skjer. Da har vi igjen... Så er det 4516. Det er da... det vi starter med i utgangspunktet. Og så kan vi jo prøve å regne ut... Vi kan prøve oss å lage nå ett r-e som er like stort. Som har så mange elementer. Og når vi ser i koden her... Scanf, den leser inn... Med prosent d, så leser den inn et heltall. Det som skjer i programmet når jeg skriver inn noe her, det blir lest inn, skriver ut lager interrøy med det antallet elementer.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0019", "start": 1449.68, "end": 1538.96, "token_count": 290, "text": "Som har så mange elementer. Og når vi ser i koden her... Scanf, den leser inn... Med prosent d, så leser den inn et heltall. Det som skjer i programmet når jeg skriver inn noe her, det blir lest inn, skriver ut lager interrøy med det antallet elementer. Og her er det en kommando mallock. Mallock er opplagt en... Må opplagt gjøre et kall til kjernen, et systemkall, for å be operativstemme om å allokere minner. Og da ser vi... Det jeg sender med, er size. Det er den størrelsen i det tallet jeg sender inn, ganger size of int. Size of int pleier å være 4. Det kan også i prinsippet endres. Men dette gir da... størrelsen i bite som jeg ønsker å lokkere til her. Jeg ser det er en liten stjerne her. Jeg skal ikke gå for mye inn på det, men dette er da en... ... en adresse. Når du definerer et r-øye, så definerer du adressen til første punkt i r-øyet i minnet. Så det er da en minneadresse. Men etterpå bruker vi r-øye,", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0020", "start": 1520.64, "end": 1596.4, "token_count": 280, "text": "Jeg skal ikke gå for mye inn på det, men dette er da en... ... en adresse. Når du definerer et r-øye, så definerer du adressen til første punkt i r-øyet i minnet. Så det er da en minneadresse. Men etterpå bruker vi r-øye, akkurat som med Java. Nå står det 'klar til å bruke r-øyet'. Og så har jeg en løkke her hvor jeg går gjennom alle elementene og skriver til det. Og så stopper jeg bare med å vente på å avslutte. Men da ser vi... Her går jeg i gang og faktisk bruker R-øyet. Og det skal vi se på hvordan det funker i S. Men aller først... Vi har virtuelt 4516. Og så sier jeg... OK, jeg ønsker et så stort ære. Og da så vi... Da spratt den der opp til 8616. Litt mer enn forrige gang, hvis du husker det regnestykket der. 8-6-12. Det ser ut som det er 4K som bør brukes av ramm til å administrere et eller annet rundt...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0021", "start": 1572.92, "end": 1658.92, "token_count": 298, "text": "Og da så vi... Da spratt den der opp til 8616. Litt mer enn forrige gang, hvis du husker det regnestykket der. 8-6-12. Det ser ut som det er 4K som bør brukes av ramm til å administrere et eller annet rundt... Sannsynligvis bruker Mallock noe ekstra ram i tillegg til akkurat det som settes av til Herøye. Men foreløpig er det bare i Virt. Det er bare den biten som har endret seg. Men nå klarte jeg å bruke r-øyet, så da kan jeg sende med hva som helst. Den bare leses, egentlig bare for at det skal stoppe. Så begynner jeg å bruke r-øyet, og da så vi at det tok lite grann tid. Og så spratt den opp i 5384. Og da jeg så at det var kanskje noe sånt som... Hva var det som sto her? 700 og noe. Det ble ikke helt riktig... Altså, eller... riktig... Det skulle blitt noe sånt som 700 pluss 1466. Men vi ser at det ble en del mer. Og det er tydeligvis en del mer som hentes inn i RAM og brukes aktivt.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0022", "start": 1630.04, "end": 1727.72, "token_count": 288, "text": "Og da jeg så at det var kanskje noe sånt som... Hva var det som sto her? 700 og noe. Det ble ikke helt riktig... Altså, eller... riktig... Det skulle blitt noe sånt som 700 pluss 1466. Men vi ser at det ble en del mer. Og det er tydeligvis en del mer som hentes inn i RAM og brukes aktivt. Men vi ser i hvert fall... Med en gang man da bruker dette her, så kommer det i bruk som i RAM. Registreres i MMU osv. og da... Og når man kjører programmer og kanskje har mine problemer, så er det veldig viktig å se hvite forskjeller på dette her. Du kan ha et kjempestort virt, men så lenge det ikke er i bruk i RES, så er det ikke tungt for systemet. Så det er den viktige forskjellen på de to målene her. Veldig kort til slutt om SHR, eller Shared. Det er da minnet som deles med andre programmer. F.eks. så kan det være dynamisk bibliotek. Stort sett så fins det noen dynamiske bibliotek som brukes. F.eks. C-bibliotek som da deles.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0023", "start": 1700.64, "end": 1834.3, "token_count": 292, "text": "Veldig kort til slutt om SHR, eller Shared. Det er da minnet som deles med andre programmer. F.eks. så kan det være dynamisk bibliotek. Stort sett så fins det noen dynamiske bibliotek som brukes. F.eks. C-bibliotek som da deles. Det så vi på sist, at vi kunne lage statisk bibliotek. Det var litt om... Det var litt mer om ram. Vi kan gå videre og se litt mer på noen praktiske eksempler. Da kan vi hoppe hit. Her tenkte jeg å kjøre en Vram-test. Dette er også en av oppgavene denne uken. Å kjøre et Ram... Ram SMP. Hvis vi kjører det uten argumenter, sånn som dette er, så ser vi at vi får bare litt info om programmet. Men vi ser vi trenger å ha en minus-b id. Sånn generelt når... Hvis opsjoner står i parenteser, så er det opsjoner man kan velge å la ikke ta dem med, men opsjoner som ikke står i parenteser, Så vi ser her... For å få dette til å kjøre, må vi bruke den minus B. Og minus B1... Den gjør da en test hvor man skriver til ramm.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0024", "start": 1808.44, "end": 1903.56, "token_count": 278, "text": "Hvis opsjoner står i parenteser, så er det opsjoner man kan velge å la ikke ta dem med, men opsjoner som ikke står i parenteser, Så vi ser her... For å få dette til å kjøre, må vi bruke den minus B. Og minus B1... Den gjør da en test hvor man skriver til ramm. Vi kan teste og lese etterpå. Så dette er da min Linus-desktop som står nede på Oslo Nett. Som jeg kjører denne testen i. Det er at vi... Typisk det Ramspeed gjør, er å skrive til ram akkurat på samme måte som vi gjorde i det forrige programmet. Vi har et svært array, og så skriver vi bite for bite til det arrayet. Det er noe sånt som 8 gigabyte med ram som skrives. Størrelsen på blokkene som skrives. I førstelinja her så skriver man bare 1 kB av gangen. Altså man har en løkke som går gjennom... Da blir det 250 bite, sånn at det blir 1 kB totalt. Og så skrives det veldig hurtig til ramm.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0025", "start": 1880.64, "end": 1965.6, "token_count": 293, "text": "Størrelsen på blokkene som skrives. I førstelinja her så skriver man bare 1 kB av gangen. Altså man har en løkke som går gjennom... Da blir det 250 bite, sånn at det blir 1 kB totalt. Og så skrives det veldig hurtig til ramm. Og så måles hastigheten. Det går veldig fort. 26 000 MB per sekund. 27, eller 30 gigabyte i sekundet. Så... Det går unna. Hvis du skal streame noe, for eksempel, så kan du... Ja... Du kan streame kanskje 4 megabit per sekund, og det er bare bit. Dette er en bite, og så er det giga. Så det er 30 gigabyte per sekund. Veldig hurtig. Men litt av poenget her med denne testen er at vi ser at det går veldig hurtig til å begynne med. Men så begynner det å gå litt saktere. Her er det 29 000, så går den ned til 28 000, 27 000 her... 25 000. Og så dropper det enda mer. Og her nede så ser vi at vi er nede i en fjerdedel", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0026", "start": 1948.88, "end": 2036.96, "token_count": 299, "text": "Men så begynner det å gå litt saktere. Her er det 29 000, så går den ned til 28 000, 27 000 her... 25 000. Og så dropper det enda mer. Og her nede så ser vi at vi er nede i en fjerdedel av denne opprinnelige hastigheten. Og dette er da pga. cash. Dette er cash-størrelsene. Fordi når vi skriver en liten blokk, så får den plass i LN-cash. Og hvis vi skriver en litt større blokk, så får den plass i L2-cash. Og så må vi kanskje ut i L3-cash her ute. Men det vi trenger å vite da, er hvor stor er cash på denne maskinen her. Det jeg gjorde nå, var kommandoen LSCPU. Og den gir cash-størrelsene. Og da ser vi... LN-cash er 32K for data og instruksjoner. Det er data. I er instruksjoner. Og dette vil jo være typisk... Her skriver vi, så dette vil typisk være data. Så da har vi 32K i LN og 256K i L2. Så da kan vi prøve å se om det er noen forskjell på...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0027", "start": 2014.56, "end": 2104.04, "token_count": 283, "text": "Det er data. I er instruksjoner. Og dette vil jo være typisk... Her skriver vi, så dette vil typisk være data. Så da har vi 32K i LN og 256K i L2. Så da kan vi prøve å se om det er noen forskjell på... Er det noen stor forskjell ved 32K og 256K? Det er ikke så veldig stor forskjell. Vi kan se at det begynner å droppe litt ved 32K, for da må den over på L2. Men det ser ut som... Når du skriver de store mengdene her, Det er veldig effektivt. Så vi kan kanskje se det faller litt her. Og så... Men så begynner det å bli større enn L2. Nå i dag faller det litt i hastighet. Men så ser vi her mellom 4 og 8. Der begynner det å bli en stor forskjell. Og det... Da ser vi... Da begynner vi å komme over 8K. Her har vi 8K-blokk. Da ser vi at hastigheten har blitt halvert. Og det er da fordi da får ikke de blokkene plass i...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0028", "start": 2080.32, "end": 2175.88, "token_count": 287, "text": "Der begynner det å bli en stor forskjell. Og det... Da ser vi... Da begynner vi å komme over 8K. Her har vi 8K-blokk. Da ser vi at hastigheten har blitt halvert. Og det er da fordi da får ikke de blokkene plass i... Ikke engang i L3. Så da må du begynne å lese direkte fra disken... Nei, direkte fra ram, og da begynner man å komme ned på det som du kan kalle den ekte rammehastigheten. Altså at du må helt ut i ram og hente dataene. Da faller hastigheten med i hvert fall en faktor på 4. Muligens enda mer hvis vi hadde skrevet enda større blokker. Så vi kan prøve å lese også. Minus B2. Da leser vi fra ram. Enda fortere. Men vi ser igjen så vi får 1 KB. Den er kanskje for liten igjen til at det skal gå fort nok. Når det kommer opp i 2, så ser vi det kommer opp i 60 GB per stykke. Men igjen så ser vi den samme effekten. Det faller litt...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0029", "start": 2150.64, "end": 2257.36, "token_count": 276, "text": "Enda fortere. Men vi ser igjen så vi får 1 KB. Den er kanskje for liten igjen til at det skal gå fort nok. Når det kommer opp i 2, så ser vi det kommer opp i 60 GB per stykke. Men igjen så ser vi den samme effekten. Det faller litt... ... litt etter 32K, eller den cash-størrelsen. Veldig mye etter 8K. Her faller det fra 50 og ned til 20 omtrent. Så der er det en stor faktor. OK. Da... tenkte jeg vi kan se på noen flere... Minnekommandor. Kan gå til laptopen min, og så kan jeg prøve å se på \"-free\". Hvis jeg bare taster -free, så får jeg ut en del minneinfo. Stort sett så kan du se dette i toppen også, men her får vi konsentrert oss om minnet. Dette er i... Dette er i utgangspunktet K. Så jeg kan be om free minus M. Så kan jeg be om free minus G. For å se i gigabyte. Så vi kan kanskje først se på den siste her. Free minus G.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0030", "start": 2228.96, "end": 2323.4, "token_count": 295, "text": "Stort sett så kan du se dette i toppen også, men her får vi konsentrert oss om minnet. Dette er i... Dette er i utgangspunktet K. Så jeg kan be om free minus M. Så kan jeg be om free minus G. For å se i gigabyte. Så vi kan kanskje først se på den siste her. Free minus G. Her får vi de store tollene. 31 betyr at det er... 31, eller det er vel rundt av. Denne laptopen har 32 gigabyte internt inne. Og det er det vi ser her totalt. Og så ser vi... Used er tre. Så hvis vi går opp her og ser på megabytes, så ser du at det er 32 000 megabytes og 3000 er used. 3500 er brukt. Så det bestyrer at du bruker ca. 3 GB. Så det betyr igjen at det er veldig mye som er ledig. Og... Men... Så ser vi... Ja, og skjer. Det er også da delt i libraries, som ikke er... Som er fordelt mellom flere prosesser. Men her er det en bit som er interessant. Bufcash. Vi ser at det er 4G. Den kan ofte være enda større.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0031", "start": 2296.84, "end": 2386.58, "token_count": 284, "text": "Og... Men... Så ser vi... Ja, og skjer. Det er også da delt i libraries, som ikke er... Som er fordelt mellom flere prosesser. Men her er det en bit som er interessant. Bufcash. Vi ser at det er 4G. Den kan ofte være enda større. Det har ikke noe med L1 og L2Cash å gjøre. Det er filcash. Så... så dette er filcash. Og det som skjer da, er når Linux ser at her er det masse minne, mange gigabyte med minne, som er ledig. Som ikke brukes av noen prosesser. Da tar Linux operativstemkjernen og cacher filer. Fra filsystemet. Så når man da leser inn filer, så lagres det i RAM i et område som er da satt av av operativsystemet. Sånn at etterpå, når man leser fra en fil... Så i stedet for å bruke veldig lang tid på å lese på disken, så leser man direkte fra RAM. Da går det 100 000 ganger så fort. Så dette er en veldig effektiv måte å bruke RAM på for å få systemer til å gå fortere.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0032", "start": 2370.12, "end": 2459.24, "token_count": 285, "text": "Sånn at etterpå, når man leser fra en fil... Så i stedet for å bruke veldig lang tid på å lese på disken, så leser man direkte fra RAM. Da går det 100 000 ganger så fort. Så dette er en veldig effektiv måte å bruke RAM på for å få systemer til å gå fortere. Men så kan det være at man smører opp et svært RA som trenger masse ram. Da vil man se at Bufcash-andelen vil gå ned. Hvis programmet bruker opp alt ram, så droppes Fillcash. Vi kan... Vi har sett mange ganger på topp.  Vi ser her, så... rapporterer TopIG. Og den størrelsen man rapporterer på, den kan endres ved å taste... Ved å taste E. Skal vi se om jeg får til det. Jo, der. Nå var det... Nå er det oppe i terabyte. Petabyte. Det er litt stort. Men... Hvis jeg taster E én gang, så blir det... Nå ser vi det står M, bortsett fra de som er veldig store. Nå så ser vi det står G. Og da ser vi... Det er et par programmer her som er...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0033", "start": 2434.64, "end": 2521.68, "token_count": 283, "text": "Nå er det oppe i terabyte. Petabyte. Det er litt stort. Men... Hvis jeg taster E én gang, så blir det... Nå ser vi det står M, bortsett fra de som er veldig store. Nå så ser vi det står G. Og da ser vi... Det er et par programmer her som er... Kjempestore. OBS. Det er det systemet som... sørger for alle vinduene og streamer og tar opp osv. Den har... Virt på 47 G. Så da ville det vært et problem hvis alle de sidene skulle inn samtidig. Tilsvarende Zoom, som jeg også kjører, den har 6 G. Men heldigvis så brukes ikke alle de sidene her samtidig. Det er liksom alt som er mulig å gjøre i det programmet, OBS, det er definert i de sidene. Men det er ikke i bruk. Vi ser bare 0,6 G er i bruk nå. Og tilsvarende for Zoom - 1,2 G er i bruk. Så det er de som bruker det meste av ram. Så hvis jeg taler stor E, så ser vi at jeg får samme effekten her oppe.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0034", "start": 2502.64, "end": 2605.12, "token_count": 282, "text": "Men det er ikke i bruk. Vi ser bare 0,6 G er i bruk nå. Og tilsvarende for Zoom - 1,2 G er i bruk. Så det er de som bruker det meste av ram. Så hvis jeg taler stor E, så ser vi at jeg får samme effekten her oppe. Nå står det GIB. Og da får jeg ut noe av det samme som jeg fikk med fri. Det står 31 GIB her. Og \".used\": 3,4. Og 4 giga er brukt av feel cash, eller buffer cash. Så på denne måten kan man kontrollere og se hva som er i bruk av minne. Og så er det viktig å huske at det feltet her, det som er resident, det som faktisk er i ramm, og som MMU har definert alle sider for... Som er den viktigste delen. Men da ser jeg... Klokka er 9.17, så vi trenger en pause. Jeg ser det er noen spørsmål i chatten. Ja, vi kan godt ta de før vi går til pause. Et spørsmål til når vi kjørte... Ops... her... når vi kjørte dette programmet...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0035", "start": 2566.96, "end": 2693.0, "token_count": 291, "text": "Men da ser jeg... Klokka er 9.17, så vi trenger en pause. Jeg ser det er noen spørsmål i chatten. Ja, vi kan godt ta de før vi går til pause. Et spørsmål til når vi kjørte... Ops... her... når vi kjørte dette programmet... Hvordan hvitt kan være 4516 før man har sagt hva størrelsen per eske er? Det er et godt spørsmål. Men vi kan da se på... Bare selve programmet. Og vi ser... Det er i utgangspunktet ganske stort. Så hvis jeg... Skal vi se... Her har jeg ikke noe. Nei. Her er det helt tomt. Så hvis jeg nå kjører programmet før jeg begynner å... Så spørsmålet er hvordan kan det være 4500 K før vi i det hele tatt begynner å kjøre? Og da kan vi jo først se på det jeg prøvde å gjøre. Vi ser på størrelsen på A.out. Og vi ser... Størrelsen på A.out er i utgangspunktet 8,3 K. Sånn at... Sånn at det begynner å kjøre, så er det ikke så rart at...", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0036", "start": 2669.2, "end": 2778.32, "token_count": 293, "text": "Vi ser på størrelsen på A.out. Og vi ser... Størrelsen på A.out er i utgangspunktet 8,3 K. Sånn at... Sånn at det begynner å kjøre, så er det ikke så rart at... ... at det virtuelle adresserommet er 4516. Skulle nesten tro det var større, siden det er 8K her oppe. For her har jeg jo ikke begynt å definere noe ennå. Men i hvert fall... Uten at jeg kan si detalj om hver eneste bite der, så er hovedpoenget at Adopt-Out er et stort program. Det linker sammen en masse biblioteker osv., bl.a. for å kunne skrive ut. Og selv om man selv bare... Hello world ic... tar mange kilobite med plass. Så alt dette er all infrastrukturen som skal til for å sette opp et program i det hele tatt. Den biten vil også ta mye ram, og det er utgangspunktet. Men så ser vi etterpå. Det vi gjorde, var når vi legger på 4K. Så ser vi i et RA, så blir den biten bare skjøtet direkte på det eksisterende. OK. Da tar vi en pause.", "source": "lecture"}
{"lecture_id": "os14time1", "chunk_id": "os14time1_0037", "start": 2753.34, "end": 2802.2, "token_count": 139, "text": "Den biten vil også ta mye ram, og det er utgangspunktet. Men så ser vi etterpå. Det vi gjorde, var når vi legger på 4K. Så ser vi i et RA, så blir den biten bare skjøtet direkte på det eksisterende. OK. Da tar vi en pause. Og da tenker jeg vi kan starte igjen... 9.21. Vi kan starte da blir det 9.36. Da tar vi et kvarters pause der. Kom gjerne med spørsmål i chatten i pausen også. Da stopper jeg recordingen.", "source": "lecture"}
{"lecture_id": "linux5del14", "chunk_id": "linux5del14_0000", "start": 0.0, "end": 100.36, "token_count": 298, "text": "Det kan være nyttig å deklarere funksjoner eller metoder i skjellskript. Vi skal først se på hvordan vi kan definere en funksjon direkte i skjellet. Og en funksjon må defineres med parenteser på denne måten. Og videre er syntaksen at det skal komme en krøllparentes, og så skal det i kommandoen. La oss si jeg bare skriver ut hosename, og så kommandoen who. Så avslutter jeg funksjonen. Da har jeg definert en funksjon, og da kan jeg utføre funksjonen ved å taste users på den måten. Da ser vi at da utføres først hosename, og så who. Hvor det bare er jeg som er innlogget. Så kan vi se... Sånn kan man definere en funksjon på én linje. La oss si jeg prøver å legge med én... ... en kommando til. Sånn. Så kan jeg igjen kjøre users. Og da ser vi at jeg har utvidet den funksjonsdefinisjonen. Sånn kan man lage små funksjoner i skjellet og kjøre dem. Men så kan man da også bruke dem i skript.", "source": "lecture"}
{"lecture_id": "linux5del14", "chunk_id": "linux5del14_0001", "start": 76.52, "end": 163.6, "token_count": 290, "text": "... en kommando til. Sånn. Så kan jeg igjen kjøre users. Og da ser vi at jeg har utvidet den funksjonsdefinisjonen. Sånn kan man lage små funksjoner i skjellet og kjøre dem. Men så kan man da også bruke dem i skript. Bare se kort på et eksempelskript fra forelesningsnotatene. Og det starter da med å deklarere en funksjon find user.  Først her skriver vi ut hvilke argumenter vi sender med til hovedprogrammet. Hovedprogrammet kommer lenger nede. Men man deklarerer funksjonene først. Og så deklarerer vi en lokal funksjon vi bruker her. Den vil ikke kunne ses av hovedprogrammet. Og så setter jeg bruker lik dollar én. I hovedprogrammet skal vi sende med én variabel til finduser. Og den variabelen kommer da som dollar 1, akkurat som til hovedskriptet. Men dette er da ikke dollar 1 i hovedskriptet. Og så gjør jeg funksjonaliteten til finduser. Jeg greper på å bruke rettspassord.", "source": "lecture"}
{"lecture_id": "linux5del14", "chunk_id": "linux5del14_0002", "start": 142.24, "end": 230.22, "token_count": 293, "text": "I hovedprogrammet skal vi sende med én variabel til finduser. Og den variabelen kommer da som dollar 1, akkurat som til hovedskriptet. Men dette er da ikke dollar 1 i hovedskriptet. Og så gjør jeg funksjonaliteten til finduser. Jeg greper på å bruke rettspassord. Og hvis dette blir noe, hvis det er et funn, så returnerer jeg null. Alt OK. Returneres 1. Så det er funksjonen. Så kan vi se på hovedprogrammet. Vi bruker da den funksjonen. Det løper først igjennom alle argumentene i... Som sendes med når programmet kjøres, altså hovedprogrammet. For hvert av de argumentene så kaller det fine user, dollar user. Det blir da dollar én i funksjonen, som vi definerte oppe. Og så ser vi at det er funksjonen returnere null eller én. Og returverdien finnes som vanlig i dollarspørsmålstegn. Hvis den er null, så betyr det at da finnes user, og hovedprogrammet leverer dollarfunn, skriver ut at den er funnet.", "source": "lecture"}
{"lecture_id": "linux5del14", "chunk_id": "linux5del14_0003", "start": 206.46, "end": 298.94, "token_count": 294, "text": "Og så ser vi at det er funksjonen returnere null eller én. Og returverdien finnes som vanlig i dollarspørsmålstegn. Hvis den er null, så betyr det at da finnes user, og hovedprogrammet leverer dollarfunn, skriver ut at den er funnet. Vi ser dollar-funn. Den er definert her. Og den er global, siden den ikke er definert som lokal. Så dermed kan vi skrive ut funn her i hovedprogrammet. Hvis ikke, så skriver man ut at Yzer ikke finnes. Så da kan vi se hvordan det ser ut når vi kjører dette. Hvis vi starter Yzer.shell, og la oss si jeg ønsker å finne route og... Rut og... la oss si Bind, som er to brukere. Da ser vi... Først skrives ut argumentene til skriftet. Det er Rute og Bind. Men det som skjer i hoveddelen, det er at man løper gjennom de to argumentene. Så først så leter man etter Rute, og da sendes argumentet Rute med til funksjonen. Så da får vi den funksjonen her. Får da argumentet Ruth, som i dag blir bruker.", "source": "lecture"}
{"lecture_id": "linux5del14", "chunk_id": "linux5del14_0004", "start": 281.22, "end": 355.84, "token_count": 219, "text": "det er at man løper gjennom de to argumentene. Så først så leter man etter Rute, og da sendes argumentet Rute med til funksjonen. Så da får vi den funksjonen her. Får da argumentet Ruth, som i dag blir bruker. Og så gjør man den funn på brukeren. Og siden den finnes, returneres null. Og Ruth finnes, og så skriver hovedprogrammet... Det skriver ut det funnet. Så går man videre til neste argument, som er bind, og så sendes det til funksjonen. Returnerer funksjonverdien. Hvis man prøver noe som ikke finnes, ruter, så returneres verdien at ruter ikke finnes. For da returneres 1. Så dette er da et eksempel på hvordan man kan bruke en funksjon i et hovedprogram. Det er programmet eneste bøk.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0000", "start": 0.02, "end": 106.76, "token_count": 299, "text": "Nå starter jeg recording. Det jeg tar opp nå, det tar jeg opp i OBS Studio, sånn at dere vil ikke høre den... Dette blir nå tatt opp fra Zoom, men jeg tar opp i bakgrunnen. Og det opptaket har jeg testet før. Det blir i hvert fall bra. Så jeg tar det nå opp, men min er gjerne på opptak. Så jeg ikke glemmer det. Da skal vi starte med å se på dagens tema. Som alltid, spør i chatten underveis hvis det er noe dere lurer på. Eller enda bedre, spesielt hvis det er noe skikkelig kritisk. Dere ikke ser noen ting, eller lyden er borte, eller... Og rop ut. Ja... Fra forrige... Fra forrige uke så... Nei, dette er neste uke. Her. Her har jeg lagt ut en del demoer. Det tok litt tid denne gangen, men de har kommet sånn... Det mangler vel kanskje én liten video her. Men tanken er at når dere jobber med oppgavene, så kan dere se på disse videoene, altså Uke fire-oppgaver. Gjerne begynn på oppgavene og så gå til videoene hvis det er noe dere lurer på.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0001", "start": 90.0, "end": 193.72, "token_count": 288, "text": "Det mangler vel kanskje én liten video her. Men tanken er at når dere jobber med oppgavene, så kan dere se på disse videoene, altså Uke fire-oppgaver. Gjerne begynn på oppgavene og så gå til videoene hvis det er noe dere lurer på. Tilsvarende så har jeg lagt ut tema for neste uke innen Linux. Og de kommer jeg til å legge ut dette temaet. Ja, så i tillegg, eller av praktisk art, så... Ser vi at Oblig1 kommer her, og den har innleveringsfrist fredag 5.2. Men det er viktig at det kun er uke 4 som er inkludert i obligen. Så oppgavene til neste uke, uke 5, de er... De skal leveres først i Oblig2 her nede. Så når du er ferdig med ukesoppgaven denne uken, så kan du levere inn Oblig1. Og som sagt, alle må levere inn som en OS-gruppe i Kanas. Men nå til dagens tema, som er maskinkode og assembly. I dag skal vi se på maskinkode og assembly og C-programmering. Det vi holdt på med i...", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0002", "start": 153.76, "end": 255.8, "token_count": 284, "text": "Så når du er ferdig med ukesoppgaven denne uken, så kan du levere inn Oblig1. Og som sagt, alle må levere inn som en OS-gruppe i Kanas. Men nå til dagens tema, som er maskinkode og assembly. I dag skal vi se på maskinkode og assembly og C-programmering. Det vi holdt på med i... Eller aller først så skal vi ta en ekstra titt på simuleringsmaskinen. For det er et par ting der som vi skal gjøre, som vi ikke så så nøye på forrige gang. Så vi tar en liten rekapitulering av det vi holdt på med sist, med den simulerte maskinen. Men det vi skal gjøre videre i dag, er å se hvordan den maskinkoden og ensemble-koden som vi har i simuleringen, faktisk er mer eller mindre nøyaktig den samme som man har i X86-arkitekturen. Det er én maskinarkitektur som er den mest vanlige, som de aller fleste PC-er og servere kjører på, er X86. Så det er én helt spesiell arkitektur, hvor det er definert maskininstitusjoner,", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0003", "start": 230.88, "end": 318.28, "token_count": 300, "text": "mer eller mindre nøyaktig den samme som man har i X86-arkitekturen. Det er én maskinarkitektur som er den mest vanlige, som de aller fleste PC-er og servere kjører på, er X86. Så det er én helt spesiell arkitektur, hvor det er definert maskininstitusjoner, akkurat som vi definerer maskininstitusjoner i den simulerte maskinen. Og det er den som lager maskinen, som bare definerer sånn skal institusjonene se ut. Ad skal være institusjon nummer fire. For andre arkitekturer vil dette være forskjellig. Forskjellig nummerering på instruksjoner, og de kan være litt forskjellige. Et annet eksempel er ARM, som er maskinarkitekturen som er brukt av alle prosessorene som sitter i mobiler. Så ARM er det som det er laget mest av av CPU-er. 100 mrd. eller noe sånt. Det er ekstremt mange CPU-er. Arm har andre institusjoner enn X86. Og X86 har andre institusjoner enn vår simulering. Men da skal vi aller først gå tilbake til vår simulering. Her.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0004", "start": 290.44, "end": 412.28, "token_count": 292, "text": "Så ARM er det som det er laget mest av av CPU-er. 100 mrd. eller noe sånt. Det er ekstremt mange CPU-er. Arm har andre institusjoner enn X86. Og X86 har andre institusjoner enn vår simulering. Men da skal vi aller først gå tilbake til vår simulering. Her. Og så skal vi starte på den. Litt øyeblikk... Sånn. Der starter simuleringen, og så åpner jeg opp... Selve maskinen. Ja, og da ser vi at... her. Og inni her, som vi har sett tidligere, så sitter alle maskininstruksjonene. Så når vi skal la denne maskinen kjøre, så kan vi f.eks. steppe gjennom. Da ser vi... Her gjorde vi den første instruksjonen, som var å legge tallet 3, som er de to siste bitene i denne instruksjonen. Den ble lagd i R0, som var det bit nummer tre... Eller nummer fem og seks, blir det. Der er det to nuller. De to der. Det står for R0. De to siste bitene er det tretallet som legges inn i R0.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0005", "start": 384.2, "end": 464.24, "token_count": 285, "text": "som var å legge tallet 3, som er de to siste bitene i denne instruksjonen. Den ble lagd i R0, som var det bit nummer tre... Eller nummer fem og seks, blir det. Der er det to nuller. De to der. Det står for R0. De to siste bitene er det tretallet som legges inn i R0. Og de fire første bitene, det er et tall som sier at nå... Og så skal vi gjøre institusjon nummer to. Og alt dette med hvordan de bitene er satt sammen, og hva som skjer når de gjøres, det er definert av maskinarkitekturen. Og den maskinarkitekturen er på en måte brent inn her. I instruksjonsdekoderen og i Datapath. Inni Datapath er alt som skjer av beregninger osv. Og vi ser i denne maskinen så ligger institusjonene i rom. Og da er det ledninger som går fra rom og inn i institusjonsdekoderen. Og det er ledninger som sender alle disse åtte bitene som en institusjon gjør. Inn til institusjonsdekoderen.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0006", "start": 446.14, "end": 531.96, "token_count": 297, "text": "Og vi ser i denne maskinen så ligger institusjonene i rom. Og da er det ledninger som går fra rom og inn i institusjonsdekoderen. Og det er ledninger som sender alle disse åtte bitene som en institusjon gjør. Inn til institusjonsdekoderen. Så oversetter institusjonsdekoderen denne koden til alle de bitene som må trykkes på. Alle de rette bitene som må trykkes på for at Datapath skal gjøre nøyaktig. Senere så skal vi se at... Ja, for... Eller vi har sett tidligere at andre institusjoner her nede, det er sånn som den. Det er en ad-institusjon. Og ad har et annet nummer. Den er 0100, som den er nummer fire. At når det kommer en ID-instruksjon, så oversettes disse åtte tallene her. Eller dvs. UPP-koden her er det som definerer hvilken instruksjon det er. De oversettes, så og så trykker man på de riktige knappene på Datapath, sånn at Alun legger sammen to tall. I tillegg kommer da de andre som sier hvilke registre man skal lagre i.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0007", "start": 513.9, "end": 592.54, "token_count": 288, "text": "Eller dvs. UPP-koden her er det som definerer hvilken instruksjon det er. De oversettes, så og så trykker man på de riktige knappene på Datapath, sånn at Alun legger sammen to tall. I tillegg kommer da de andre som sier hvilke registre man skal lagre i. De sier hvilket register skal jeg da legge seg i. Sånn som R0 pluss R1, og så resultatet legges i R0. Så alt dette er styrt av maskininstitusjonene. Og dette er nok det samme som i X86, bare at akkurat enkelttallene er annerledes. Nummereringen av institusjonene er annerledes. Men i prinsippet er alt akkurat det samme. Det er et spørsmål om... Hvis man skulle lagt inn 4, er ikke det med... Nei, det er et godt spørsmål fordi at vi har sett på... Vi kan gå tilbake, så kan vi se på... Instruksjonene til denne maskinen. Det hadde vi om på slutten forrige gang. Vi håpet kanskje litt raskt over det. Men her hadde vi...", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0008", "start": 566.14, "end": 655.06, "token_count": 288, "text": "Nei, det er et godt spørsmål fordi at vi har sett på... Vi kan gå tilbake, så kan vi se på... Instruksjonene til denne maskinen. Det hadde vi om på slutten forrige gang. Vi håpet kanskje litt raskt over det. Men her hadde vi... Så over på instruksjonene, hvordan de var definert. Og det jeg tenker... Den som spør referert til, er det ikke mulig å legge inn fire? Og nei, det er faktisk ikke mulig, fordi at vi ser... Her er det en institusjon som heter Move-e. Den kan brukes til å legge inn tall. Men så ser vi at den har to operander. Den første operanden er hvilket... Den andre operanden er selve tallet. Der er det bare satt av to bit til dette tallet. Dermed er det største tallet man kan legge inn, tre. Så for å legge inn fire til register, hva kan man gjøre da? Det er faktisk en oppgave, den siste oppgaven i dag, vi går ut på akkurat det, en utfordring. Jo, da kan man trikse det til ved at man først legger inn et tretall.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0009", "start": 637.58, "end": 737.94, "token_count": 292, "text": "Så for å legge inn fire til register, hva kan man gjøre da? Det er faktisk en oppgave, den siste oppgaven i dag, vi går ut på akkurat det, en utfordring. Jo, da kan man trikse det til ved at man først legger inn et tretall. Og så adderer man, og så får man et firetall. Men det er riktig, man kan ikke legge firetall rett inn. På andre arkitekturer så er dette fikset ved at man har flere bits. Sånn at et tall... Her er det kanskje da plass til 32 biter Som man kan legge inn. Dette er en veldig minimalistisk arkitektur. Men det finnes en del tilsvarende CPU-er for veldig enkle embedded systemer. Sånn vaskemaskin her, f.eks. Den første Intel... Eller en av de aller første Intel-integrerte kretsene, Intel 404, den hadde bare fire bit. Og det er størrelsesorden det denne her har også. Ca. 2000 transistorer totalt sett. Tilbake til simuleringen. Og et annet spørsmål er de ledningene som går mellom boksene på bussen.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0010", "start": 712.48, "end": 824.42, "token_count": 298, "text": "den hadde bare fire bit. Og det er størrelsesorden det denne her har også. Ca. 2000 transistorer totalt sett. Tilbake til simuleringen. Og et annet spørsmål er de ledningene som går mellom boksene på bussen. Ja, det er et godt spørsmål. Det er ikke det man vanligvis kaller databussen. Men det som man vanligvis kaller databussen, er dataene som går til RAM. Og det skal vi komme litt innpå etterpå. Så det som er databussen, vil i vårt tilfelle er de fire linjene her og de fire linjene her. Addresse out og data out. Og det er da en buss som går mellom CPU-en. Disse linjene internt, det er mer... Du kunne kalle det busser òg, men det er interne linjer i CPUD. Enda et spørsmål. Og det er kjempebra. Kommer flere spørsmål, så tar vi så mange vi rekker. Neste spørsmål var om Harvard-arkitektur. Og det er... Og det er et litt vanskelig spørsmål i denne sammenhengen. For det vi vet, er for Neumann-arkitekturen...", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0011", "start": 793.62, "end": 895.08, "token_count": 293, "text": "Kommer flere spørsmål, så tar vi så mange vi rekker. Neste spørsmål var om Harvard-arkitektur. Og det er... Og det er et litt vanskelig spørsmål i denne sammenhengen. For det vi vet, er for Neumann-arkitekturen... Den er sånn at både instruksjoner og data sendes gjennom den samme bussen. Så det betyr at hvis dette hadde hatt en von Neumann-arkitektur, så skulle programmet som ligger her, det skulle ha ligget i RAM. Og maskinen skulle da lese inn institusjonene, og så utføre de institusjonene. Og samtidig, når den skulle skrive data, så skulle de gå ut disse kanalene til RAM. Så derfor ligger denne nærmere Harvard-arkitekturen. Og det er rett og slett fordi bussen, eller dataene fra institusjonene, følger en annen vei enn dataene fra variablene som lagres i ramm. Altså dataene som lagres i ramm. De har én buss. Og så er det en annen buss eller en annen kanal som går mellom institusjonene.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0012", "start": 866.14, "end": 963.14, "token_count": 294, "text": "Og det er rett og slett fordi bussen, eller dataene fra institusjonene, følger en annen vei enn dataene fra variablene som lagres i ramm. Altså dataene som lagres i ramm. De har én buss. Og så er det en annen buss eller en annen kanal som går mellom institusjonene. Så derfor kan man si at dette er en hardware-arkitektur. OK. Da skal vi se veldig raskt på dette med bransjekontroll. Bransjekontroll er de kablene som går bort hit. Så ser vi her er det statusregister og load PC osv. Og det er ekstremt viktig for at man ikke bare skal fortsette ned. Nedover hele tiden. Og det går an å se at det skjer noe her... Jeg skal ikke gå inn i altfor mye detalj, men jeg kan legge på en liten kabel her på den bransjekontrolledningen. Og da vil vi se at når det blir et hopp i koden, så vil denne bransjekontrollen her sende en ener. Vi kan prøve å se på det først. Vi kjører litt nedover i koden.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0013", "start": 939.8, "end": 1025.06, "token_count": 287, "text": "en liten kabel her på den bransjekontrolledningen. Og da vil vi se at når det blir et hopp i koden, så vil denne bransjekontrollen her sende en ener. Vi kan prøve å se på det først. Vi kjører litt nedover i koden. Hvis man følger med på den bransjekontrollen, den er null hele veien. Og så går vi nedover. Og så kommer vi et valg, og da ser vi. Her lyser det opp i bransjekontrollen. Og det er den forrige compere-instruksjonen. Den har slått til. Jump not equal. Og da kommer jump not equal etterpå. Og den institusjonen gjør at det sendes en ener her. Her er et statusregister, et register som ligger inni her. Og det har lagret resultatet fra forrige operasjon. Vi gjør en compare først, og etterpå sjekker vi om vi skal hoppe. Og da er det basert på det som er lagret i statusregisteret. Så sendes det en ener. Og det betyr, hvis jeg går opp her til den PC-en som er program counter,", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0014", "start": 1002.86, "end": 1094.76, "token_count": 284, "text": "Og det har lagret resultatet fra forrige operasjon. Vi gjør en compare først, og etterpå sjekker vi om vi skal hoppe. Og da er det basert på det som er lagret i statusregisteret. Så sendes det en ener. Og det betyr, hvis jeg går opp her til den PC-en som er program counter, den teller vanligvis bare nedover i instruksjoner. Sånn at den starter på null. Program counteren starter på null her oppe. Så blir den én, så blir den to, og så videre. Men akkurat her når det kommer et hopp, så vil program counteren settes til... Den verdien som man skal hoppe til. Og den ligger inne i institusjonen. Man skal hoppe da til linje nummer fire. Og da utfører maskinen et hopp. Og sånn... Og dette fører til at man ikke bare går rett gjennom programmet, men at man gjør en branch. Da skal vi se på... Da skal vi se på Ramm. Det vi skal prøve å gjøre nå, er altså å endre eller legge til en institusjon, sånn at maskinen skriver til Ramm.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0015", "start": 1068.98, "end": 1170.42, "token_count": 282, "text": "men at man gjør en branch. Da skal vi se på... Da skal vi se på Ramm. Det vi skal prøve å gjøre nå, er altså å endre eller legge til en institusjon, sånn at maskinen skriver til Ramm. Da kan jeg legge programmet her, og så kan vi gå inn og... se på... Skal vi prøve... Vi kan lukke den av. Jeg må ha riktig peker, så skal vi prøve å komme inn i ramme der. Her er altså ramme. Dette er et ekstremt lite ramme, 16 ganger 4. Vanligvis er ramme på milliarder av bytes. Kan ha gigabyte med ramme. En bitte liten ram. Det er bare plass til 16 bites. Og det er ikke bites engang, det er 4 bites. Så dette er... På en måte var halve bites. Hvis vi åpner den, så ser vi at dette her er bare 4 bits som er lagret for hver linje. Og det er totalt 16 linjer. Så kan vi legge merke til at her ligger det nå... Hva ligger her...? 2, 4, 8.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0016", "start": 1149.9, "end": 1241.34, "token_count": 298, "text": "Hvis vi åpner den, så ser vi at dette her er bare 4 bits som er lagret for hver linje. Og det er totalt 16 linjer. Så kan vi legge merke til at her ligger det nå... Hva ligger her...? 2, 4, 8. Så det vi skal prøve å gjøre nå, er å legge resultatet fra beregningen inn i ramm. For det er det som vanligvis skjer i en beregning. Til å begynne med så skjer alle beregningene inni registrene lokalt i maskinen. Og så, til slutt, så skriver man resultatet ut i ramm. For å gjøre det, så trenger man da en instruksjon som gjør akkurat det. Da må vi gå tilbake hit, og så må vi se at... Jo, her er det to instruksjoner som vi ikke har brukt - load og store. Og store, den gjør akkurat det. Den lagrer resultater i ramm. Og så ser vi at denne instruksjonen er sånn at første operande er... Det er Destination Register, og andre er Source register. Så det betyr at vi må angi til slutt hvilket... Eller det tallet i et register.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0017", "start": 1212.96, "end": 1308.66, "token_count": 293, "text": "Og store, den gjør akkurat det. Den lagrer resultater i ramm. Og så ser vi at denne instruksjonen er sånn at første operande er... Det er Destination Register, og andre er Source register. Så det betyr at vi må angi til slutt hvilket... Eller det tallet i et register. Eller et av registrene, så må vi ha adressen til dit vi skal legge det. Og da kan jeg f.eks. si at i R0, der ligger tallet 3. Så da kan jeg legge inn R av 3. Ut i ramm. Og så la oss si... I R1 så ligger vel tallet 1. Så jeg kan velge Destination Register. Det er som 1. Ja, nå sa jeg feil. R av denne, det er jo det som legges ut. Og den skal jo være R3, som resultatet vårt ligger i. Så jeg må ta R3. Og så legge ut i en gitt adresse. Og det viktigste er store. Det er 1010. Vi bruker litt tid på dette, for dette her er... Dette er hvordan man programmerer en maskin direkte i maskinkode. Heldigvis så slipper vi å gjøre det med Exo86.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0018", "start": 1286.14, "end": 1392.18, "token_count": 294, "text": "Og så legge ut i en gitt adresse. Og det viktigste er store. Det er 1010. Vi bruker litt tid på dette, for dette her er... Dette er hvordan man programmerer en maskin direkte i maskinkode. Heldigvis så slipper vi å gjøre det med Exo86. Da har vi compulatorer som fikser den jobben, men nå skal vi prøve å gjøre det. Det er da altså Store. Og da må jeg gå inn i R-rommet her oppe. Nå er jeg over i Rom, så nå er det Instrukt maskininstruksjonene. Så tenker jeg nå at nå kan jeg legge til en maskininstrukt 2. Oi... Vi ser ikke. Supert. Bra du sier ifra. Ja, da går jeg... litt tilbake. Det jeg skal prøve å gjøre nå, er å legge til en... En institusjon som lagrer sluttresultatet, som ligger i R3, inn i ramm. Går jeg nå ned til institusjon nummer åtte, altså etter den siste jumpen... For i dag fortsetter programmet bare nedover. Og så må jeg her... må jeg skrive inn riktig institusjon. Og det var vel...", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0019", "start": 1365.06, "end": 1463.7, "token_count": 296, "text": "En institusjon som lagrer sluttresultatet, som ligger i R3, inn i ramm. Går jeg nå ned til institusjon nummer åtte, altså etter den siste jumpen... For i dag fortsetter programmet bare nedover. Og så må jeg her... må jeg skrive inn riktig institusjon. Og det var vel... Institusjonen var 1.01.0 for Store. Skal jeg passe på å gå tilbake... Sånn. Så må jeg gå inn her. Og skrive 1,0, 1,0. Og så ønsker jeg å lagre det som ligger i R3. Og det var... Da skulle jeg skrive 3 der. For det betyr legg verdien av register 3 i denne adressen. Adressen er nå 0,0. Men la oss si jeg bruker R1. Altså det tallet som ligger i R1. Sånn. Har jeg programmert en linje, så må jeg i denne editoren gå ett hakk ned, og så er det lagret. Ok. Da kan jeg prøve å kjøre, og så prøver jeg å se i Ramm etterpå om dette fungerer som det skal. Så da fortsetter jeg å kjøre programmet.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0020", "start": 1436.14, "end": 1535.76, "token_count": 281, "text": "Sånn. Har jeg programmert en linje, så må jeg i denne editoren gå ett hakk ned, og så er det lagret. Ok. Da kan jeg prøve å kjøre, og så prøver jeg å se i Ramm etterpå om dette fungerer som det skal. Så da fortsetter jeg å kjøre programmet. Hva betyr R1 her? R1 er da... Det er da adressen i ram. Det er den linjen i ram som resultatet skal lagres i. Så etter kjøringen så er vel R1 lik 1, og da skal resultatet lagres i rammelinje nummer 1. Nå kjører vi sakte gjennom. Nå har vi fått ut tallet 6 i R3. Og så ser vi... Nå hopper vi ikke. Nå lyste det ikke her. Så vi hopper ikke, og nå utføres da ram-operasjonen. Og det den skal gjøre... Nå er den ferdig. Det er... Den skulle legge resultatet, det som ligger i R3, altså tallet 6, i... Iram på adresse 1 sin RR1. Da må vi bare gå inn og sjekke.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0021", "start": 1509.38, "end": 1616.12, "token_count": 284, "text": "Så vi hopper ikke, og nå utføres da ram-operasjonen. Og det den skal gjøre... Nå er den ferdig. Det er... Den skulle legge resultatet, det som ligger i R3, altså tallet 6, i... Iram på adresse 1 sin RR1. Da må vi bare gå inn og sjekke. Iram, har dette skjedd? Hvis vi er heldige, så har vi fått til det. Skal vi se. Oi. Ja, faktisk så har vi fått dette til å virke. For vi ser... Dette er adresse 0. Men dette er adresse 1. Og her har vi lagret tallet 6, som var sluttresultatet. Og det er nøyaktig slik det virker på X86 også. F.eks. lagre en integersum, som resultatet 6 skal legges i, eller integer S, som vi vel brukte... Så er det en kobling sånn at S ligger på en spesiell adresse. En eller annen adresse i RAM. Her ser vi at S ligger i adresse 1. Så det vi gjorde akkurat nå, var å programmere maskinkode som lagret sluttresultatet i RAM.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0022", "start": 1594.12, "end": 1693.22, "token_count": 286, "text": "eller integer S, som vi vel brukte... Så er det en kobling sånn at S ligger på en spesiell adresse. En eller annen adresse i RAM. Her ser vi at S ligger i adresse 1. Så det vi gjorde akkurat nå, var å programmere maskinkode som lagret sluttresultatet i RAM. På adresse 1. Og det gjøres hele tiden i vanlig kode. Kan man lagre ting på adresse 0 også? Ja. Hvis jeg ønsket å lagre noe i adresse 0, så måtte jeg bare endret på den maskinkoden her nede på kode 8. Og da hadde det ikke vært så lett egentlig å... Da kunne jeg ikke bare brukt én institusjon, for det jeg da måtte gjort først, var å ta en move-i-institusjon, legge tallet null i r1. Før denne institusjonen. Eller så kunne jeg beholdt institusjonen, for da ville jeg... Hvis jeg før dette la inn tallet null i r1 med move-in, move-i, og så etterpå utført... Så vil jeg oppnå akkurat det og lagre resultatet på adresse 0. Ja... Så...", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0023", "start": 1663.38, "end": 1764.9, "token_count": 293, "text": "Før denne institusjonen. Eller så kunne jeg beholdt institusjonen, for da ville jeg... Hvis jeg før dette la inn tallet null i r1 med move-in, move-i, og så etterpå utført... Så vil jeg oppnå akkurat det og lagre resultatet på adresse 0. Ja... Så... Så det betyr at på denne måten så kan man programmere CPU-en. Og dette skjer da om og om igjen inni programmer. Og det vi skal se på sånn konkret nå, er hvordan vi... Hvordan dette helt tilsvarende skjer når vi kompilerer C-programmer og får ut maskinkode. Vi tar oss tid til et par spørsmål til. Så det var en oppsummering her. Vi brukte bare verdien til R1, som altså var 1, som referanse til en adresse vi skulle lagre. Helt riktig. F.eks. om R1 hadde vært lik 2, så hadde vi lagret adresse 2 i RAM. Det er helt riktig, og dette er veldig viktig, så det må vi ha med videre. For hele tiden refererer vi til RAM. Så vi kan vise et eksempel på det. F.eks. hvis jeg...", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0024", "start": 1745.82, "end": 1847.78, "token_count": 287, "text": "F.eks. om R1 hadde vært lik 2, så hadde vi lagret adresse 2 i RAM. Det er helt riktig, og dette er veldig viktig, så det må vi ha med videre. For hele tiden refererer vi til RAM. Så vi kan vise et eksempel på det. F.eks. hvis jeg... Det heter R3 på begge. Da betyr de... Legg svaret som ligger i R3, i adressen som har samme nummer som R3. Så det vil da være... Hvis jeg lagrer den... Nå bør tallet 6 da lagres på adresse nummer 6. Klikker gjennom fra starten av nå. Altså klikker raskt igjennom. Vi kan jo følge med her. Så ser vi... Der kommer først tre. Så blir svaret seks. Og der... Nå skal vi da legge... Det den skal gjøre, er å legge svaret seks inn i adresse nummer seks. Og da kan vi gå inn i RAM, og så kan vi se... Har det det som har skjedd...? Ja, da ser vi her nede. På adresse 6 så ligger nå resultatet som også er tallet 6.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0025", "start": 1818.02, "end": 1981.3, "token_count": 295, "text": "Det den skal gjøre, er å legge svaret seks inn i adresse nummer seks. Og da kan vi gå inn i RAM, og så kan vi se... Har det det som har skjedd...? Ja, da ser vi her nede. På adresse 6 så ligger nå resultatet som også er tallet 6. Så nøyaktig på den måten så er det maskinkode aksesserer RAM. Det er en ny remse med adresser, som er adresser til én og én byte. Ok. Da... Da avslutter vi den... den delen. Og det vi skal se på nå, det er da... Vi kan begynne så vidt. Hvordan dette ser ut i en X86-maskin når vi kjører Linux-programmer. Da skal jeg gå inn på Studies SO. Sånn som... oi... Det så ikke så bra ut. Jo, det var bare en feilstavelse. Studies og så, skal vi gå med på. Og alle C-programmer. For å kunne få til å skrive ut noe, så trenger vi det Standard-in-out. Std.io. Dette er et bibliotek som vi inkluderer. Og så har alle C-program det. Jeg har en maine, altså en hovedfunksjon eller hovedmetode.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0026", "start": 1946.16, "end": 2052.42, "token_count": 300, "text": "Og alle C-programmer. For å kunne få til å skrive ut noe, så trenger vi det Standard-in-out. Std.io. Dette er et bibliotek som vi inkluderer. Og så har alle C-program det. Jeg har en maine, altså en hovedfunksjon eller hovedmetode. Og i praksis så kan man kjøre alt inn i maine. Og i dette enkle programmet så er det eneste som jeg gjør, er å skrive 'Tellow World' med funksjon printf. Og for å få dette her til å kjøre, så må vi kopulere. Og da gjør vi den operasjonen om å oversette... Fra høydenivåkode til maskinkode. Så for å kjøre dette programmet så bruker jeg kompulatoren GCC. En standard Linux-kompulator. Og det som skjer da, er at det lages... En exequerware-fil med maskinkode som heter Adapt. Og når jeg kjører den, så skrives Hello World ut. Da må vi vite at... Eller vi kan se på AdOtOnt, og vi ser den er ganske stor. Den er på 8600 bytes. Så dette er tydeligvis mye mer enn bare akkurat kode for å skrive ut den.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0027", "start": 2036.14, "end": 2132.5, "token_count": 295, "text": "Da må vi vite at... Eller vi kan se på AdOtOnt, og vi ser den er ganske stor. Den er på 8600 bytes. Så dette er tydeligvis mye mer enn bare akkurat kode for å skrive ut den. Og det er bl.a. fordi det inkluderes et bibliotek her oppe. Så den inneholder masse kommunikasjon med operativsystemet, f.eks. Man kan også, som vi skal gjøre etter hvert... Man kan også kalle dette noe annet enn Adapt. La oss si jeg ønsker å kalle det Hello. Da får jeg en Feel Hello, som er nøyaktig den samme som Adapt. Og så, når jeg skal kjøre det, så kjører jeg det med Hello. Så dette skal vi gjøre en masse nå. Vi skal lage... Og kompilere det... Men det vi skal studere, er at i bakgrunnen så lages det maskinkode. Og vi skal se på hvordan denne maskinkoden, som da faktisk lages når vi kompilerer C-programmer på en Linux-maskin, den er så å si identisk med den maskinkoden som vi lagde til simulering. Men nå ser jeg vi trenger en liten pause her. Da tar vi pause til 9.30.", "source": "lecture"}
{"lecture_id": "os4time1", "chunk_id": "os4time1_0028", "start": 2105.88, "end": 2138.74, "token_count": 88, "text": "Og vi skal se på hvordan denne maskinkoden, som da faktisk lages når vi kompilerer C-programmer på en Linux-maskin, den er så å si identisk med den maskinkoden som vi lagde til simulering. Men nå ser jeg vi trenger en liten pause her. Da tar vi pause til 9.30. Still gjerne spørsmål i pausen.", "source": "lecture"}
{"lecture_id": "os9del14", "chunk_id": "os9del14_0000", "start": 0.0, "end": 102.1, "token_count": 295, "text": "I prinsippet er det mye som ligner, men det er noen forskjeller. Her igjen er denne nederste boksen kjernen. Vi kjører gysemål her oppe med brukerapplikasjoner. Alt dette kjører gysemål og ber da operatismeskjernen om hjelp. Gjennom API-et, gjennom systemkallet. Så er det med liten skrift ntoscornal.xe. Den vil du finne på en Windows-maskin, og det er da hele dette programmet her. Det er ntoscornal.xe. Windows har også en såkalt monolittisk kjerne. Det vil si at du har én stor kodeenhet, hvor i prinsippet man kan... Her borte fra deviser og filsystemer kan det ødelegge for grafikken. Og det er forskjellig fra såkalt mikrokjerne... Hvor du da har en veldig liten mikrokjerne... Og da typisk disse delene er helt uavhengige... Og snakker med hverandre via signaler. Altså det kommuniserer med mikrokjernen. Mens i monolittiske kjerner, som både Linux og Linux er, så kan alle deler av kjernen snakke med alle deler av kjernen.", "source": "lecture"}
{"lecture_id": "os9del14", "chunk_id": "os9del14_0001", "start": 77.48, "end": 178.9, "token_count": 294, "text": "Og da typisk disse delene er helt uavhengige... Og snakker med hverandre via signaler. Altså det kommuniserer med mikrokjernen. Mens i monolittiske kjerner, som både Linux og Linux er, så kan alle deler av kjernen snakke med alle deler av kjernen. Det betyr også at kompleksiteten blir veldig stor, og det øker sjansen for feil. En viktig forskjell på Windows og Linux er at grafikken er en del av... Det er noen forskjeller på det. Det er tatt ut i noen sølveversjoner. Men sånn tradisjonelt er alt med grafikk en del av Windows-kjernen. Sånn er det ikke i Linux. Som vi ser her, har vi ikke noen direkte del av kjernen som styrer med grafikk. Det som skjer der, er at grafikk kjøres i use mode. X-vindussystemet kjøres i user space. Det gjør også at det ikke er like effektivt. Spesielt har det tradisjonelt vært en del problemer med spill på Linux. Iallfall tradisjonelt, nettopp pga. pilene der. I tillegg ser vi at den har en del mikrokerner her.", "source": "lecture"}
{"lecture_id": "os9del14", "chunk_id": "os9del14_0002", "start": 156.7, "end": 235.96, "token_count": 209, "text": "Det gjør også at det ikke er like effektivt. Spesielt har det tradisjonelt vært en del problemer med spill på Linux. Iallfall tradisjonelt, nettopp pga. pilene der. I tillegg ser vi at den har en del mikrokerner her. Som styrer alle disse underdelene. Sånn som power management, object manager, fyllsystem osv. Men det er ikke en sånn ekte microcanal i... I den forstand at den bare kommuniserer med signaler med de andre modulene. Men det er en liten del av kjernen som styrer alt det andre. Som skal gjøre at kjernen her får et uniformt grensesnitt mot hardware. Så hvis man endrer hardware her nede, så tar hal det av seg. Sånn at kernel får det samme grensesnittet. Uansett hva slags hardware som ligger under.", "source": "lecture"}
{"lecture_id": "os12del7", "chunk_id": "os12del7_0000", "start": 0.0, "end": 102.92, "token_count": 292, "text": "Ja... Vi har allerede sett på Lock på X86-institusjonen Lock. Og som vi skal se senere, så trenger man... For å lage en effektiv løsning, så trenger man hjelp fra hardware. Men det går også an å lage software-løsninger som, selv om de kjører på... Selv om det kan komme en kontekst-witch som sørger for en Mutex. Hvis vi ønsker en software-løsning, da ønsker vi oss gjerne å ha to funksjoner eller metoder sånn som dette... GetMutex og releaseMutex. Og getMutex... Den metoden ønsker vi skal hente en lokk. Og så sier vi denne nøkkelen. Ingen andre må ta den. Ingen andre kan ta den. Så da kan jeg utføre mitt Kritiske avsnitt. Og så, etterpå, så kan jeg gi fra meg nøkkelen. Og dette virker jo enkelt og greit. Så da burde man egentlig ha løst hele problemet. Men vi skal se at det er ikke så enkelt som man skulle tro. Så dette er første forsøk på å lage en software music. De andre forsøkene er det oppgaver om denne uken.", "source": "lecture"}
{"lecture_id": "os12del7", "chunk_id": "os12del7_0001", "start": 75.64, "end": 173.32, "token_count": 288, "text": "Og dette virker jo enkelt og greit. Så da burde man egentlig ha løst hele problemet. Men vi skal se at det er ikke så enkelt som man skulle tro. Så dette er første forsøk på å lage en software music. De andre forsøkene er det oppgaver om denne uken. Så se på de oppgavene senere. Men vi skal se på dette første forsøket, som er liksom det... Enkleste man kan få til, og som tilsvarer det å lage... Vi kan lage en mail-lok. Vi hadde et eksempel hvor vi lagde en fil. Og så sjekker alle andre prosesser om den filen finnes. Dette er egentlig det tilsvarende, men vi får det samme problemet. Så vi tenker oss at vi har en static boolin-lok. Det er da en felles variabel som er true eller false. Og den er static i betydning... Av at to eller flere prosesser kan aksessere den. Så nå skal vi som programmerere ha kode som sikrer denne lokken. Og da kan vi gjøre det på denne måten her. Vi kan si... Getmutex-lokk. Den kan være sånn at...", "source": "lecture"}
{"lecture_id": "os12del7", "chunk_id": "os12del7_0002", "start": 142.68, "end": 246.7, "token_count": 299, "text": "Det er da en felles variabel som er true eller false. Og den er static i betydning... Av at to eller flere prosesser kan aksessere den. Så nå skal vi som programmerere ha kode som sikrer denne lokken. Og da kan vi gjøre det på denne måten her. Vi kan si... Getmutex-lokk. Den kan være sånn at... Dette er en litt spesiell konstruksjon, men den funker i Java, f.eks. Og det er vile lock, og så kommer det bare to parenteser. Og de to parentesene, de er... De gjør ingenting. Det er faktisk en maskininstitusjon som gjør ingenting. Og den heter NOP, No Operation. Så vile lock, og så ingenting. Det den gjør, det er at den bare tester om og om igjen. Om lock er true. Ja. Den tester om og om igjen om lock er true eller false. Og hvis lock er true, så går den inn i løkka og gjør ingenting. Og det den da gjør, er at den hele tiden sjekker om lock er true. Så den står her og gang på gang tester om er lock true, er lock true. Hele tiden, hvis lokket er truet, så står den og venter.", "source": "lecture"}
{"lecture_id": "os12del7", "chunk_id": "os12del7_0003", "start": 222.58, "end": 305.3, "token_count": 291, "text": "Og hvis lock er true, så går den inn i løkka og gjør ingenting. Og det den da gjør, er at den hele tiden sjekker om lock er true. Så den står her og gang på gang tester om er lock true, er lock true. Hele tiden, hvis lokket er truet, så står den og venter. Og da er det klart... Der vil den stå evig. Med mindre det er andre prosesser som aksesserer denne lokken og setter den til Folds. Så hvis ingen andre har satt denne til Folds før, så vil den første prosessen som gjør GetMuteX, den vil gå inn... Lokket er Folds, så da hopper den over denne her. Og da er det trygt, for da kan den gå inn i sitt kritisk avsnitt. For den har nå gått inn, satt locklig true... Akkurat som å skru på en lås. Det er som om man går inn på et toalett og vrir på låsen, for da er det et signal til alle andre. Da er det rødt. Ingen kan komme inn her. Så da er det safe. Så hvis en annen prosess kommer inn og også prøver å gjøre", "source": "lecture"}
{"lecture_id": "os12del7", "chunk_id": "os12del7_0004", "start": 280.16, "end": 359.2, "token_count": 295, "text": "Akkurat som å skru på en lås. Det er som om man går inn på et toalett og vrir på låsen, for da er det et signal til alle andre. Da er det rødt. Ingen kan komme inn her. Så da er det safe. Så hvis en annen prosess kommer inn og også prøver å gjøre get mutex før det kritiske avsnittet, så vil den komme inn og så se... Oi, lokk er på. OK, da må jeg stå her og vente. Og den står da og venter helt til den første prosessen som kom inn, har gjort released mutex. For hvis vi husker det man... Først gjør man get mutex, henter låsen, så kritisk avsnitt, og så release mutex. Så når da... Prosess nummer to. Er ferdig med sett kritiske avsnitt, så vil den release mye av teksten, og det gjør den ved å sette locklick-fots. Og da vil de som måtte stå her og vente i en løkke, de vil da komme inn i kritiske avsnitt, og så vil de sette locklick, tror jeg. Så dette ser ut som det perfekte opplegg. Men her er det et problem.", "source": "lecture"}
{"lecture_id": "os12del7", "chunk_id": "os12del7_0005", "start": 335.32, "end": 443.44, "token_count": 287, "text": "så vil den release mye av teksten, og det gjør den ved å sette locklick-fots. Og da vil de som måtte stå her og vente i en løkke, de vil da komme inn i kritiske avsnitt, og så vil de sette locklick, tror jeg. Så dette ser ut som det perfekte opplegg. Men her er det et problem. Jeg har stilt et spørsmål her. Dette burde sikre at to prosesser ikke er i kritisk asyl samtidig. Men vi kan få et problem her, og det er hvis... Hva skjer hvis det kommer en context switch? Vi tenker at disse kjører på samme CPU. Hva om det kommer en kontekst-witch rett etter at denne prosessen har testet om... Om lock er false. Hvis vi antar at lock er false... Og så vil det jo... En sånn veiløkke... En sånn test består av flere deler. Første del må hente inn verdien og legge et register. Truly Falls-register er typisk 0 eller 1. Og så må den, etter at den har hentet den inn, gjøre en compare. Sammenligne den verdien med 0, f.eks.", "source": "lecture"}
{"lecture_id": "os12del7", "chunk_id": "os12del7_0006", "start": 410.2, "end": 500.36, "token_count": 281, "text": "Og så vil det jo... En sånn veiløkke... En sånn test består av flere deler. Første del må hente inn verdien og legge et register. Truly Falls-register er typisk 0 eller 1. Og så må den, etter at den har hentet den inn, gjøre en compare. Sammenligne den verdien med 0, f.eks. Og så må den etter den compare hoppe, avhengig av verdien. Men det der utføres i minst to institusjoner. Så hva skjer om det kommer en context switch nøyaktig etter at den har hentet inn verdien, og sett at den er falsk? Jo, da fryser selv den prosessen. Det neste den vil gjøre, er å sette lock-click-through og gå inn i kreditskapsnitt. Men når den første prosessen som kommer inn, fryser, Da er jo lock fortsatt false. Så den prosess nummer to... Den vil enkelt og greit bare hoppe over den løkka. Lock er false. Og så vil den sette locklik, tror jeg. Men da er det for sent. For da er P1 allerede inne i kritiske avsnitt.", "source": "lecture"}
{"lecture_id": "os12del7", "chunk_id": "os12del7_0007", "start": 480.0, "end": 562.12, "token_count": 284, "text": "Da er jo lock fortsatt false. Så den prosess nummer to... Den vil enkelt og greit bare hoppe over den løkka. Lock er false. Og så vil den sette locklik, tror jeg. Men da er det for sent. For da er P1 allerede inne i kritiske avsnitt. Og så kommer P2 etter, og den går også inn i kritiske avsnitt. Og da er vi tilbake i de gamle problemene. Så kan begge to kjøre kritiske avsnitt samtidig. Så derfor så fungerer rett og slett ikke denne software-løsningen. Den vil fungere stort sett, bortsett fra hvis det kommer et kritisk avsnitt nøyaktig etter wild lock. Nøyaktig etter at verdien er hentet inn til registrene, men rett før den hopper på grunnlag av denne verdien. Er ikke denne god nok? Og i øvingsoppgavene så kommer det et par andre nye forsøk som er litt bedre. Og til slutt så kommer man fram til Peterson-algoritmen, som kom en gang på 80-tallet, som er en perfekt software-mytex-løsning.", "source": "lecture"}
{"lecture_id": "os12del7", "chunk_id": "os12del7_0008", "start": 540.0, "end": 632.58, "token_count": 266, "text": "Er ikke denne god nok? Og i øvingsoppgavene så kommer det et par andre nye forsøk som er litt bedre. Og til slutt så kommer man fram til Peterson-algoritmen, som kom en gang på 80-tallet, som er en perfekt software-mytex-løsning. Men den er litt tungvint, og du trenger litt kode. Men den kan. Det kan man bruke. Men i praksis, sånn som med operativstemme og sånn som med Java-tråder osv., så bruker man metoder hvor man får hjelp fra Harvay. Og det sikrer i tillegg at man lokker databussen. Så de metodene er da enda bedre. I de softwareløsningene som vi har sett på, de krever litt kode. Og i tillegg så bruker de alle sammen bussy waiting. Bussy waiting er dette her med at man står og venter. Og da bruker man CPU-en. Man gjør NOP-institusjoner om og om igjen. Og det er en litt effektiv måte å vente på. Det kalles da generelt 'bussy waiting'.", "source": "lecture"}
{"lecture_id": "os3bdel5", "chunk_id": "os3bdel5_0000", "start": 0.0, "end": 96.0, "token_count": 284, "text": "Von Neumann-arkitektur. Den aller vanligste datamaskinarkitekturen som brukes, ble definert av en matematiker som het John von Neumann. Han var virkelig et universalgeni og hadde... Sto bak veldig mye av konstruksjonen av en moderne datamaskin. Det vi har sett på nå, det er først og fremst aluen. Så dette er den sentrale beregningsenheten. I tillegg har vi registeret. Når man gjør beregninger, så kobler man registrene til input på aluen. Og så kommer man andre registeret til outputs, og så gjøres det beregninger. Og dette gjøres om og om igjen. Vi har en kontrollenhet som styrer alt dette. I tillegg så har man main memory, secondary memory, main memory, det er RAM, internminne. Og internminne går ut til en buss, en databuss, som sender data inn til kontrollenheten. Altså kommer data ut igjen til RAM. Og det som er spesielt med von Neumann-arkitektur, er at her i RAM så ligger De institusjonene som kontrollerer hva som skal gjøres.", "source": "lecture"}
{"lecture_id": "os3bdel5", "chunk_id": "os3bdel5_0001", "start": 68.68, "end": 162.66, "token_count": 280, "text": "internminne. Og internminne går ut til en buss, en databuss, som sender data inn til kontrollenheten. Altså kommer data ut igjen til RAM. Og det som er spesielt med von Neumann-arkitektur, er at her i RAM så ligger De institusjonene som kontrollerer hva som skal gjøres. Og i tillegg så ligger data. Det er typisk variabler. Hvis du har en variabel i et program, så vil den variabelen lagres. Og så gjør du beregninger, og så lagrer du dataene i den variabelen. De ligger da i ramm, og da må hele tiden trafikken gå inn og ut til Søppel. Og det som er spesielt med von Neumann-arkitekturen, er at samme buss brukes til både instruksjoner og data. I den såkalte Harvard... Hva heter den? Hardford... Arkitekturen. Harvard. Universitetet Harvard. Arkitekturen. Så er det litt annerledes, for da er det to busser. Én buss som sender institusjoner, og en atskilt buss som sender data.", "source": "lecture"}
{"lecture_id": "os3bdel5", "chunk_id": "os3bdel5_0002", "start": 131.56, "end": 230.8, "token_count": 293, "text": "I den såkalte Harvard... Hva heter den? Hardford... Arkitekturen. Harvard. Universitetet Harvard. Arkitekturen. Så er det litt annerledes, for da er det to busser. Én buss som sender institusjoner, og en atskilt buss som sender data. I virkeligheten, i moderne arkitektur, så brukes egentlig en slags blanding. Der har man Cash, som vi skal se på senere. Og LNCash, det har to... Én for data og én for instruksjoner. Så det er en sannhet med modifikasjoner, at alle bruker von Neumann-arkitektur, men i hovedsak så ligner det på denne arkitekturen. I tillegg så har man secondary memory, det er disk, og så har man en rekke forskjellige enheter som kommuniserer med dette. Men CPU og main memory er liksom hovedbiten som vi skal se på nå. De delene van Normann-arkitekturen består av, er som vi så på forrige figur, det er Ramm, så er det Alu, og så er det en kontrollenhet som henter inn instruksjoner fra Ramm.", "source": "lecture"}
{"lecture_id": "os3bdel5", "chunk_id": "os3bdel5_0003", "start": 205.72, "end": 274.0, "token_count": 213, "text": "Men CPU og main memory er liksom hovedbiten som vi skal se på nå. De delene van Normann-arkitekturen består av, er som vi så på forrige figur, det er Ramm, så er det Alu, og så er det en kontrollenhet som henter inn instruksjoner fra Ramm. Så dekodes instruksjonene og sender signaler til Aluen, sånn at riktige operasjoner blir utført. Sånn at Alun gjør en ad i det ene tilfellet og en sammenligning i det andre osv. Så er det registeret som vi har slitt med i dag og lagd. Det er det et internlager som lagrer alle instruksjonene og lagrer alle dataene som kommer ut av Alun. I tillegg så har vi InputUpput, som... Og kommuniserer med utenverdenen.", "source": "lecture"}
{"lecture_id": "os1del6", "chunk_id": "os1del6_0000", "start": 0.0, "end": 95.84, "token_count": 300, "text": "Jeg har pratet lenge, har ikke presentert meg ennå. Dere ser kanskje navnet mitt også, men jeg heter Hårek Haugerud. Jeg pleide å sitte i P35, men nå har jeg flyttet opp til AI-laben, siden jeg jobber en del med de som jobber der. Så jeg sitter fysisk i P52. Det vil si, så langt har jeg hjemmekontor, men når jeg... Jeg kommer tilbake til campus og CT i P52. Det jeg kanskje ikke har gjort så klart hittil, er at kurset består av to uavhengige deler. Den ene er operativsystemer, OS. Og denne delen er mer teoretisk om hvordan et operativsystem er bygd opp. og kjente operativsystemer er bygd opp. Og hvordan alt dette her henger sammen helt fra grunnen. Og vi bruker en god del tid på også å se på hardware, datamaskinarkitektur. For målet er at dere, etter å ha tatt kurset, skal på en måte vite alt som skjer i en datamaskin. Helt nede fra 0 volt, 5 volt, spenninger... Bitte små, de aller minste delene i datamaskinen.", "source": "lecture"}
{"lecture_id": "os1del6", "chunk_id": "os1del6_0001", "start": 69.08, "end": 154.88, "token_count": 291, "text": "Og vi bruker en god del tid på også å se på hardware, datamaskinarkitektur. For målet er at dere, etter å ha tatt kurset, skal på en måte vite alt som skjer i en datamaskin. Helt nede fra 0 volt, 5 volt, spenninger... Bitte små, de aller minste delene i datamaskinen. Helt opp til operativsystemet og dokker og virtuelle maskiner og alt som skjer på toppen. Så tradisjonelt så er operativsystemet veldig spesifikt om schedulere og minnebruk og CPU-er og hvordan alt dette styres. Det jeg har prøvd å legge inn... Etter hvert er det også å ta med hva som skjer på litt høyere nivå. Spesielt det som vi har gjort med de siste årene, er å se på dokker. Altså se på konteinere, og bruke og kjøre og lage konteinere. Og også har vi sett på virtuelle maskiner. Sånn at dere... Når dere går ut i arbeidslivet og begynner å bruke dette her, Så vet dere hva en container er, og dere vet hva operatørsystemet er,", "source": "lecture"}
{"lecture_id": "os1del6", "chunk_id": "os1del6_0002", "start": 134.26, "end": 222.32, "token_count": 299, "text": "Altså se på konteinere, og bruke og kjøre og lage konteinere. Og også har vi sett på virtuelle maskiner. Sånn at dere... Når dere går ut i arbeidslivet og begynner å bruke dette her, Så vet dere hva en container er, og dere vet hva operatørsystemet er, og hvordan ting henger sammen. Så dette er en slags sånn... For å si det veldig fint, en dannelsesreise innen data. Dere skal kjenne til hvordan alt henger sammen. Og det er ikke nødvendigvis noe som dere får veldig nytt for akkurat der og da. Men jeg håper dere skal sitte med en dypere og grundigere forståelse av hvordan alt henger sammen. Sånn at når dere møter på et problem som ikke jeg vet om, og som ikke dere vet om eksisterer engang, som kanskje kommer i fremtiden, så har dere en dypere forståelse. Og da er det alltid lettere å takle problemer og forstå hva som skjer der oppe. Men sånn i praksis, hvis du er utvikler og jobber som konsulent, så tenker du ikke hele tiden på hva som skjer i operativsystemet.", "source": "lecture"}
{"lecture_id": "os1del6", "chunk_id": "os1del6_0003", "start": 199.1, "end": 289.92, "token_count": 294, "text": "som kanskje kommer i fremtiden, så har dere en dypere forståelse. Og da er det alltid lettere å takle problemer og forstå hva som skjer der oppe. Men sånn i praksis, hvis du er utvikler og jobber som konsulent, så tenker du ikke hele tiden på hva som skjer i operativsystemet. Men noen ganger så blir det plutselig viktig å vite hva som foregår. Så det er den første delen, den mer teoretiske delen. Den andre delen er mer praktisk bruk av operativsystem. Det vi først og fremst jobber med, er kommandolinje. Spesielt Linux-kommandolinje. Men vi kommer også til å drive noe med vindus og PowerShell. Og skrive PowerShell-skript. I Linux-delen kommer vi til å skrive såkalte Bæsj-skript. Linux-kommandolinjeskript, som egentlig består av bare å sette sammen kommandoer til et systematisk... Dette blir små systemskritt som brukes til å styre operativstemme og til å snakke med operativstemme. Jeg nevner også dokker her. Vi kommer til å holde på noen uker med dokker.", "source": "lecture"}
{"lecture_id": "os1del6", "chunk_id": "os1del6_0004", "start": 266.0, "end": 363.0, "token_count": 285, "text": "bare å sette sammen kommandoer til et systematisk... Dette blir små systemskritt som brukes til å styre operativstemme og til å snakke med operativstemme. Jeg nevner også dokker her. Vi kommer til å holde på noen uker med dokker. Det som er nytt av året, er at... Jo, tidligere så har alle... Dere har blitt delt inn i grupper, og da har hver studentgruppe en virtuell maskin. VM som dere logger inn på. Nytt av året er at serverne har blitt så gamle og dårlige som kjørte disse, så de har begynt å bryte sammen. Derfor har vi lagd et nytt system. Og i år så ser dette ut på samme måte, Som ved litt ekstra detaljer ser ut som selvstendige virtuelle maskiner. Så dere får da tilgang til en sånn dockingcontainer som har en offentlig IP. Og som dere kan installere og kjøre f.eks. webservere på osv. Og som dere kan bruke og teste og eksperimentere med sånn som dere vil. Så dokker kommer vi til å bruke og jobbe en god del med. I den praktiske del.", "source": "lecture"}
{"lecture_id": "os14del7", "chunk_id": "os14del7_0000", "start": 0.0, "end": 98.72, "token_count": 290, "text": "Vi ser her så... rapporterer TopIG. Og den størrelsen man rapporterer på, den kan endres ved å taste... Ved å taste E. Skal vi se om jeg får til det. Jo, der. Nå var det... Nå er det oppe i terabyte. Petabyte. Det er litt stort. Men... Nå ser vi det står M, bortsett fra de som er veldig store. Nå så ser vi det står i G. Og da ser vi... Det er et par programmer der som er kjempestore. OBS, det er det systemet som sørger for alle vinduene og streamer og tar opp osv. Så da ville det vært et problem hvis alle de sidene skulle inn samtidig. Tilsvarende Zoom, som jeg også kjører, den har 6G. Men heldigvis så brukes ikke alle de sidene her samtidig. Det er liksom alt som er mulig å gjøre i det programmet, OBS... Det er definert i de sidene. Men det er alt som er mulig å gjøre i det programmet. Det er ikke i bruk. Vi ser bare 0,6 G er i bruk nå. Og tilsvarende for Zoom - 1,2 G er i bruk.", "source": "lecture"}
{"lecture_id": "os14del7", "chunk_id": "os14del7_0001", "start": 79.78, "end": 154.0, "token_count": 246, "text": "Det er liksom alt som er mulig å gjøre i det programmet, OBS... Det er definert i de sidene. Men det er alt som er mulig å gjøre i det programmet. Det er ikke i bruk. Vi ser bare 0,6 G er i bruk nå. Og tilsvarende for Zoom - 1,2 G er i bruk. Så det er de som bruker det meste av ramm. Så hvis jeg tar oss ut stor E, så ser vi om jeg får samme effekten her oppe. Nå står det GIB. Og da får jeg ut noe av det samme som jeg fikk med fri. Det står 31 GIB her. Og 4 giga er brukt av feelcash, eller buffercash. Så på denne måten kan man kontrollere og se hva som er i bruk av minne. Og så er det viktig å huske at det feltet her, det som er resident, det som faktisk er i ramm, og som MMU har definert alle sidene for... Det er den viktigste delen.", "source": "lecture"}
{"lecture_id": "linux3del4", "chunk_id": "linux3del4_0000", "start": 0.0, "end": 87.48, "token_count": 290, "text": "Prosesser... Vi skal se litt nærmere på prosesser. Det som er viktig når det gjelder prosesser, først og fremst, er å kunne liste dem. Generelt så lister man prosesser med PS. Men PS uten argumenter vil bare liste prosesser i det lokale skjellet. Så her listes bare det bæsjcellet som jeg står og kjører i. Hvis man føyer på AUX... Mange andre argumenter man også kan bruke, men AOX vil vise alle prosesser som kjører på systemet. Da legger jeg på en mål, for det er veldig mange. Med PSAOX kan du bla deg gjennom absolutt alle prosesser. Typisk så vil det da kanskje grepe på PS. Så ser vi at da får vi ut alle som har noe med PS å gjøre,inkludert... Den som selv kjørte. Så nå skriver jeg PS, og så ser jeg at jeg har to jobber som kjører. Men det kan være nyttig å se på prosesser som kjører. Jeg skal bruke et eksempel, og jeg har et script som heter run.shell. Og det scriptet gjør, er... Her er det en foreløkke som går fra 1 til 600.", "source": "lecture"}
{"lecture_id": "linux3del4", "chunk_id": "linux3del4_0001", "start": 65.46, "end": 140.0, "token_count": 286, "text": "Så nå skriver jeg PS, og så ser jeg at jeg har to jobber som kjører. Men det kan være nyttig å se på prosesser som kjører. Jeg skal bruke et eksempel, og jeg har et script som heter run.shell. Og det scriptet gjør, er... Her er det en foreløkke som går fra 1 til 600. Så sover scriptet i ett sekund. Så dette scriptet her vil da stå i ti minutter og kjøre før det avslutter. Så dette er typisk et skjell som vi kan starte opp i bakgrunnen. Aller først, hvis jeg bare kjører script sånn som dette her, så ser vi at da får jeg ikke tilbake terminalpromptet. Og det er fordi da starter scriptet å kjøre, og så vil det kjøre helt til det avslutter. Så da kan jeg stoppe det med Controll-C, og så kan jeg i stedet starte det med et AND-tegn til slutt, en alfakrøll. Og da... Ikke en alfakrøll, en AND. Og da, hvis jeg legger den bak, så vil skriptet kjøre i bakgrunnen.", "source": "lecture"}
{"lecture_id": "linux3del4", "chunk_id": "linux3del4_0002", "start": 120.0, "end": 198.14, "token_count": 296, "text": "Så da kan jeg stoppe det med Controll-C, og så kan jeg i stedet starte det med et AND-tegn til slutt, en alfakrøll. Og da... Ikke en alfakrøll, en AND. Og da, hvis jeg legger den bak, så vil skriptet kjøre i bakgrunnen. Nå ser vi jeg fikk opp 10.58, og det betyr... 10.518. Og det betyr at det er en prosess... Med denne paydayen som kjører i bakgrunnen. Det ser vi også tydelig her. 10518 står og kjører her. Vi får med også den slip-funksjonen, for den kjøres gang på gang. Så hvis jeg ønsker å stoppe den prosessen for den når den kjører i ti minutter, så kan jeg bruke kill til å stoppe den. Da tar jeg kill, og så må jeg si prosess-idéen. Så har jeg stoppet den jobben, og den er borte. Så kan det være noen tilfeller hvor du f.eks. er inne på study SSO, og så kanskje du editerer, eller et eller annet... Og så av en eller annen grunn så henger den editeringsjobben.", "source": "lecture"}
{"lecture_id": "linux3del4", "chunk_id": "linux3del4_0003", "start": 180.02, "end": 265.2, "token_count": 298, "text": "Så har jeg stoppet den jobben, og den er borte. Så kan det være noen tilfeller hvor du f.eks. er inne på study SSO, og så kanskje du editerer, eller et eller annet... Og så av en eller annen grunn så henger den editeringsjobben. Den fryser, og du må drepe jobben. Og det man kan gjøre da, er... Hvis alt henger, så kan man gå inn og logge seg inn på nytt. På en Linux-maskin så er det enkelt. Er jeg nå inne på samme maskin i et annet skjell? Men PCR vil jo naturlig nok ikke vise annet enn det som er det lokale skjellet. Så for å finne den jobben som som så gikk, den gjedd-jobben, så kan jeg ta PSAUX, liste alle prosesser, og så kan jeg greppe på gjedd. er denne gjedd-jobben. Så fra dette vinduet kan jeg drepe den jobben. Og så kan jeg gå tilbake til mitt skjell, og da ser vi... Her kommer det opp.... Nå har vi sendt et signal til den prosessen og fått den drept. Så hvis jeg nå gjør PS, så ser vi at prosessen er borte.", "source": "lecture"}
{"lecture_id": "linux3del4", "chunk_id": "linux3del4_0004", "start": 241.64, "end": 310.2, "token_count": 223, "text": "Så fra dette vinduet kan jeg drepe den jobben. Og så kan jeg gå tilbake til mitt skjell, og da ser vi... Her kommer det opp.... Nå har vi sendt et signal til den prosessen og fått den drept. Så hvis jeg nå gjør PS, så ser vi at prosessen er borte. En annen ting som kan være nyttig, det er... Og ta tiden på prosesser. Her ser vi den tilsvarende prosessen som bare går i en løkke tre ganger. Rundt tre... Og den vil da vare ca. tre sekunder. Men det jeg kan gjøre da, er at jeg kan ta tiden på denne prosessen. Eller hvilke som helst andre. Og da får jeg nøyaktig tid på hvor lang tid den tok. Tok de tre sekundene den skulle, så brukte den litt tid til på å starte opp. Så dermed ble det 3,003 sekunder som den brukte.", "source": "lecture"}
{"lecture_id": "linux11del9", "chunk_id": "linux11del9_0000", "start": 0.0, "end": 101.04, "token_count": 295, "text": "OK. Da skal vi se litt på flere likheter med bæsj. Vi kan bare prøve å gjøre en liten sesjon. F.eks. så kan jeg bruke MK-dyr og lage en mappe-dyr. Så ser vi om han får litt output, så ting ser litt annerledes ut. Men jeg kan gå til den mappen, og så kan jeg si ekko... Så kan jeg pipe det til en fil.tekst her. Da bør du se at jeg har en fil her. Så kan jeg bruke CAT. Til å vise filen. Men det er ikke alt som funker. F.eks. hvis jeg prøver touch for å lage en tom fil, så... så virker det ikke den. En... da er det en kommando som heter... Det jeg gjør nå, er at akkurat som på Linux, så kan jeg lete tilbake i tidligere kommandoer med kontroll-r. Jeg kan gjøre det en gang til. Nå lette jeg for å finne 'new item'. 'New item', det tilsvarer touch. Hvis jeg nå taster... Så utføres commando new item, og da lager jeg en tom fil, på samme måte som touch. Så nå har jeg to filer her.", "source": "lecture"}
{"lecture_id": "linux11del9", "chunk_id": "linux11del9_0001", "start": 78.78, "end": 177.12, "token_count": 299, "text": "Jeg kan gjøre det en gang til. Nå lette jeg for å finne 'new item'. 'New item', det tilsvarer touch. Hvis jeg nå taster... Så utføres commando new item, og da lager jeg en tom fil, på samme måte som touch. Så nå har jeg to filer her. For å gjenta det jeg gjorde... Hvis man taster kontroll R, så ser vi det kommer en back-eye search. Og det jeg gjorde da videre, var å taste inn item. Og da, hvis jeg taster kontroll R på nytt, så akkurat som i linjeskjellet, så får jeg... Så leter jeg meg tilbake i gamle kommandoer. Det er også veldig nyttig. Så det aller meste kan gjøres. F.eks. skal jeg, som jeg også nevnte, skrive LS og sort. Hadde kanskje ikke så stor effekt der, men tilsvarende kan jeg videresette. Denne til en fil. Sort.tekster. Og da ser vi at det får en... en fil som inneholder den teksten her. Det ser litt annerledes ut enn i et Linux-skjell, men stort sett så kan man gjøre veldig mye av det samme.", "source": "lecture"}
{"lecture_id": "linux11del9", "chunk_id": "linux11del9_0002", "start": 153.92, "end": 188.02, "token_count": 79, "text": "Sort.tekster. Og da ser vi at det får en... en fil som inneholder den teksten her. Det ser litt annerledes ut enn i et Linux-skjell, men stort sett så kan man gjøre veldig mye av det samme. Og man kan overføre hele program fra... Og kjøre det i Popshake.", "source": "lecture"}
{"lecture_id": "os5del16", "chunk_id": "os5del16_0000", "start": 0.0, "end": 111.0, "token_count": 300, "text": "Ja, her ser vi noen sånne mikroarkitekturer for Intel. Som jeg sa, de aller første... 8086 var en av de første CPU-ene for PC-er. Da var det en pipeline med to stages. Så ser vi at den har økt en del oppover. Så har man gått litt tilbake. Og i det mer moderne så er det 14 stages som er vanlige. Så dette er pipelining. Det gjør at vi gjør på en måte én og én institusjon, men at man tjuvstarter på neste institusjon før den første er ferdig. Så kommer et litt annet prinsipp. Og det er superskalararkitektur. Og her utnyttes både pipelining, det samme prinsippet, men også, så i en superskalararkitektur, så gjøres ting faktisk i parallell. Og det gjøres da ved at man har... La oss si du har åtte instruksjoner etter hverandre. ... seks institusjoner etter hverandre. Da er det kanskje én institusjon som er ad, og én er remove. De er av litt forskjellig type. Da gjør man faktisk de institusjonene, i den grad det er mulig, i parallell.", "source": "lecture"}
{"lecture_id": "os5del16", "chunk_id": "os5del16_0001", "start": 90.0, "end": 179.96, "token_count": 289, "text": "... seks institusjoner etter hverandre. Da er det kanskje én institusjon som er ad, og én er remove. De er av litt forskjellig type. Da gjør man faktisk de institusjonene, i den grad det er mulig, i parallell. Her kan dere kanskje skimte at det står alu. Her er det to aluer, og så er det en load. Og så er det en alu her borte, med jump osv. Så det som skjer da, er at man... Først så deler man alle de seks institusjonene inn i mikroinstitusjoner. Så hver av de har kanskje 14 mikroinstitusjoner, med fetch-delen her oppe. Og så sender man det til en scheduler. På den måten at de seks institusjonene... Hvis mulig utføres de parallelt på helt uavhengige små aluer her som jobber parallelt med å regne og lagre. Og alt dette er da selvfølgelig bare for å få ting til å gå fortere. For da kan man få til å utføre instruksjoner i løpet av en syklus. Eller kanskje enda raskere. Ved at man...", "source": "lecture"}
{"lecture_id": "os5del16", "chunk_id": "os5del16_0002", "start": 158.0, "end": 245.88, "token_count": 293, "text": "som jobber parallelt med å regne og lagre. Og alt dette er da selvfølgelig bare for å få ting til å gå fortere. For da kan man få til å utføre instruksjoner i løpet av en syklus. Eller kanskje enda raskere. Ved at man... Gjør ting i parallell inne i CPU-en. Dette må ikke forveksles med det vi skal se på senere med multitasking, for da har vi fullstendig store CPU-er som jobber uavhengig av hverandre. Men her deles institusjonene, sekvensielle institusjoner, som kommer etter hverandre, opp i små biter. Og så utføres de i parallell. Så her kan det være institusjon 1 som holder på, Alle instruksjoner kan ikke utføres i parallell. Noen er avhengige av hverandre. Men det er et samarbeid mellom kompilatoren og CPU-en. Så prøver man å gjøre så mye som bare mulig parallelt. Jeg skal lære prosessord. Det norske ordet kan kanskje diskuteres... En skalar i motsetning til en vektor. Det er noe som ikke er i parallell.", "source": "lecture"}
{"lecture_id": "os5del16", "chunk_id": "os5del16_0003", "start": 219.6, "end": 312.4, "token_count": 294, "text": "Men det er et samarbeid mellom kompilatoren og CPU-en. Så prøver man å gjøre så mye som bare mulig parallelt. Jeg skal lære prosessord. Det norske ordet kan kanskje diskuteres... En skalar i motsetning til en vektor. Det er noe som ikke er i parallell. Men iallfall en skalar prosessor. Det utfører institusjonene én og én. De superskalære prosessorene, som egentlig er alle prosessorer etter år 2000, de er superskalære. De har da flere parallelle enheter som utfører mikrooperasjoner. Sånn at de kan jobbe med helt forskjellige institusjoner på én gang, og kjøre de faktisk samtidig. Men det bryr man seg egentlig vanligvis ikke så mye om som operativstem, for man ser ikke dette. CPU-en sørger alltid for at den logikken i koden utføres som den skal. Den kan til og med utføre operasjoner auto-order i en annen rekkefølge. Men da hender det man må gå tilbake og rette opp hvis noe går galt. Her ser vi Intel Core 2,", "source": "lecture"}
{"lecture_id": "os5del16", "chunk_id": "os5del16_0004", "start": 289.28, "end": 389.92, "token_count": 294, "text": "CPU-en sørger alltid for at den logikken i koden utføres som den skal. Den kan til og med utføre operasjoner auto-order i en annen rekkefølge. Men da hender det man må gå tilbake og rette opp hvis noe går galt. Her ser vi Intel Core 2, som er en relativt moderne SPU-arkitektur. Her ser vi at den har en masse lag. Den deler instruksjonene opp i mange småbiter. Og så ser vi... Her nede så har vi da i parallell flere aluer. Her er en alu-branch og SSE-alu, og så har vi store address... Store data, load address. Så for hver... Hver institusjon kan da deles opp i biter, sånn at det er en pipeline, og samtidig så kan det kjøres i parallell. Det gir da mye større ytelse på prosessoren. Man får da prosessoren til å yte litt ekstra ved at tingene gjøres parallelt. Men det er en grense for hvor mye du kan parallellisere. Sånn som åtte instruksjoner... Utover det er det veldig vanskelig å få til parallellisering. Det er ikke alltid det virker.", "source": "lecture"}
{"lecture_id": "os5del16", "chunk_id": "os5del16_0005", "start": 365.62, "end": 411.8, "token_count": 134, "text": "Man får da prosessoren til å yte litt ekstra ved at tingene gjøres parallelt. Men det er en grense for hvor mye du kan parallellisere. Sånn som åtte instruksjoner... Utover det er det veldig vanskelig å få til parallellisering. Det er ikke alltid det virker. Det er et samarbeid mellom kompulatoren og CPU-en å få til den optimale kjøringen av en prosess. Det gjøres ved de to metodene pipelining og parallellitet, eller superskalær CPU.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0000", "start": 0.0, "end": 97.66, "token_count": 290, "text": "Før pausen så vi på Nice, og vi kan fortsette å se på det. Der har vi Nice Vindu, og de jobbene står fortsatt og kjører. Jeg stilte noen spørsmål før pause, og det var i hvert fall... Christian hadde godt svar på begge deler. Nemlig... Så lenge det ikke er noen andre jobber som bruker SUPU, så vil jo ikke nice-verdien ha noe å si. Fordi da er det ingen andre som trenger SUPU. Og når det ikke er noen andre der, så trenger man ikke å være nice med de heller. Så dermed så kjører de med 100 % hele tiden. Men jeg spurte da også neste spørsmål... Hvordan kan man prøve å kjøre førerprosesser? Nei, hvordan kan man vise effekten? Da foreslo Christian å kjøre flere prosesser på samme CPU. Og bruke TASSET med ulike nice-verdier. Det er også et veldig godt forslag, for da vil du kunne se den effekten. En annen måte å se den samme effekten på, er jo å fylle hele serveren. Med regnejobber. Og... det... ja...", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0001", "start": 75.94, "end": 173.66, "token_count": 282, "text": "Og bruke TASSET med ulike nice-verdier. Det er også et veldig godt forslag, for da vil du kunne se den effekten. En annen måte å se den samme effekten på, er jo å fylle hele serveren. Med regnejobber. Og... det... ja... Da vil du få den samme effekten, men da begynner serveren å fryse. Jeg kjører dette på laptopen min, og her kjører jeg også OBS, Studio og Zoom. Så jeg tror jeg foretrekker det forslaget til Christian, og så teste ut det. Hovedpoenget var at hvis man ser på Last Used CPU... Hvis jeg tar med den kolonnen... Så ser vi at... Ja, det er definitivt noen som flytter seg litt. Når jeg sa på én og to, så sa vi OBS og Zoom som også bruker mye. De kjører faktisk noen ganger på samme CPU. Men de kjører da typisk på andre CPU-er enn regnejobbene. Og dermed så vil ikke regnejobbene trenge å være nice. Men det kan likevel være fint å ha. Hvis du f.eks. skal kjøre", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0002", "start": 150.0, "end": 256.2, "token_count": 292, "text": "De kjører faktisk noen ganger på samme CPU. Men de kjører da typisk på andre CPU-er enn regnejobbene. Og dermed så vil ikke regnejobbene trenge å være nice. Men det kan likevel være fint å ha. Hvis du f.eks. skal kjøre masse videoer, sånn som jeg gjør noen ganger, da kan det være nyttig å ha på Nice. At ikke systemet fryser når jeg kjører 18 forskjellige videojobber som står og karner og rendrer videoer. Det er veldig tungt. Når jeg har sett på Nice, så vil de være nice med andre jobber. Sånn at systemet ikke blir så tungt. Men først og fremst så ser vi på dette for å se hvordan prioritering fungerer. Da skal vi prøve å teste ut Christians forslag med å bruke Task Set. Nå står jo de jobbene der og hopper frem og tilbake. Så vi kan ta... kanskje og drepe regnejobbene først. Og så kan jeg i stedet si Task Set. La oss si vi setter de på prosessor 3. Så kan jeg ta nice minus 1,19 på regnjobben... regn.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0003", "start": 220.4, "end": 348.82, "token_count": 282, "text": "Nå står jo de jobbene der og hopper frem og tilbake. Så vi kan ta... kanskje og drepe regnejobbene først. Og så kan jeg i stedet si Task Set. La oss si vi setter de på prosessor 3. Så kan jeg ta nice minus 1,19 på regnjobben... regn. Sånn. Og da skal vi se om vi ser... Skulle gjerne hatt med Last Use To Poo... Og en litt større. Der. Da ser vi den ene jobben som jeg ba om, så står den på tre. Men hva om jeg nå... setter en jobb til der? Og så gir jeg den en bitte litt nice en. Ja, jeg får en effekt, men effekten er så stor at jeg nesten ikke så regnejobben. Men her nede kommer da den andre regnejobben. Den som har nice19, den kjører nå nesten ikke noe CPU. Den har 1,7 %, mens denne som er ganske... bare lite grann nice. Den får det aller meste. Hvis jeg nå kjører en default uten å bruke nice i det hele tatt, så vil den få enda litt mer. Da ser vi...", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0004", "start": 314.62, "end": 425.46, "token_count": 283, "text": "Den som har nice19, den kjører nå nesten ikke noe CPU. Den har 1,7 %, mens denne som er ganske... bare lite grann nice. Den får det aller meste. Hvis jeg nå kjører en default uten å bruke nice i det hele tatt, så vil den få enda litt mer. Da ser vi... Da kommer zoom-obs høyere, men her har vi nå regnejobbene. Og den jobben som har nice null, sånn standard, den får 55 %. Du ser den er litt nice med den andre regnejobben. Og vi gir litt mindre. Mens den som er 19, den er supernice. Så på denne måten fungerer nice. Men vi hadde et annet problem før pause også. Jeg prøvde å sette nice til 18 på en som hadde nice verdi 19. La oss si... Jeg er lei av at denne her... Nei, hva var det den var... Denne her har så lav nice-verdi, så jeg skal prøve å renaise. La oss si til pluss fem. Men da får jeg permisjonen her, og som en påpekte i chatten... Kanskje det ikke er lov. Og det ser vi også at...", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0005", "start": 390.0, "end": 502.06, "token_count": 300, "text": "La oss si... Jeg er lei av at denne her... Nei, hva var det den var... Denne her har så lav nice-verdi, så jeg skal prøve å renaise. La oss si til pluss fem. Men da får jeg permisjonen her, og som en påpekte i chatten... Kanskje det ikke er lov. Og det ser vi også at... I man-sidene så står det at... Skal vi se om vi finner det... Ja...... så en vanlig bruker kan bare øke nice-verdiene. Så hvis du først har sagt at du skal være nice, så kan du ikke gå tilbake til det. Så det er derfor man får permission denied. Mens som sagt så kan Ruth sette nice verdier. Så jeg gjør det med sudo. Sudo re-nice, den setter da nice-verdien til 5. Det er egentlig litt rart. Skulle tro man kunne sette den til 0, men sånn er det. Og med sudo så kan jeg også da sette nice-verdien til noe negativt. Den der har nå minus 5. Men det ser faktisk ikke ut som den... Likevel for noe mer slippu? Jo, i forhold til regnejobbene... Så ser vi nå for den som har minus 5 her...", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0006", "start": 470.26, "end": 589.26, "token_count": 298, "text": "Og med sudo så kan jeg også da sette nice-verdien til noe negativt. Den der har nå minus 5. Men det ser faktisk ikke ut som den... Likevel for noe mer slippu? Jo, i forhold til regnejobbene... Så ser vi nå for den som har minus 5 her... Den får 63 %, mens de andre regneobnene er 2016. Dette gir da en prioritet som er enda høyere enn 0, som er default. Og vi snakket om 140 prioritetsklasser. Det er disse 40 fra nice verdi minus 20, som er det høyeste, Det er de 40 prioritetsklassene som er for vanlige gyserprosesser. Vanlige brukerprosesser. Men i tillegg har man 100 prioritetsklasser som er for realtime-prioritering. Og det types av kjerneprosesser som skal gå veldig fort. Og her står det RT, og ikke noen nice-verdi. Det betyr at den hører til de 100 prosessene som har Migration og watchdog... Det er typisk noen systemprosesser. De har en annen prioritetsklasse. RealTime er typisk en... Generelt som en prosess som må kunne utføres innen en viss frist.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0007", "start": 567.08, "end": 675.74, "token_count": 282, "text": "Det betyr at den hører til de 100 prosessene som har Migration og watchdog... Det er typisk noen systemprosesser. De har en annen prioritetsklasse. RealTime er typisk en... Generelt som en prosess som må kunne utføres innen en viss frist. Du kan ha en realtime-prosess som i løpet av et hundredeles sekund må bli ferdig. Så det er en annen prioritetsklasse. Så de går over disse jusprosessene. De har da 40 prioritetsklasser. Og med Nice og Re-Nice kan man flytte seg opp og ned i de prioritetsklassene. Yes... Det tror jeg var det meste om Nice. Så... Da skal vi gå tilbake til sleidene. Dette var hvordan man kan endre på prioritet på et Linux-system. Prioritet i Windows... På helt samme måte så kan man prioritere jobber i Windows. Windows har også dynamisk prioritet, som endres på noe av den samme måten. Med admin-rettigheter... Hvis man administrerer to vinduer, så kan man endre prioriteten fra Task Manager. Men man kan ikke gjøre det som vanlig bruker, sånn som i Linux.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0008", "start": 644.2, "end": 763.18, "token_count": 299, "text": "På helt samme måte så kan man prioritere jobber i Windows. Windows har også dynamisk prioritet, som endres på noe av den samme måten. Med admin-rettigheter... Hvis man administrerer to vinduer, så kan man endre prioriteten fra Task Manager. Men man kan ikke gjøre det som vanlig bruker, sånn som i Linux. Hvis man tester ut det, vil man se at det er veldig hard prioritering. Det er enorme forskjeller når du gjør disse prioritetene. Den vil dynamisk prioritere prosesser etter mye av de samme prinsippene. Skal vi se lite grann på prosessforløpet? Vi har jo vært mye inne på dette her, tilsvarende som i den vaffelsimuleringen. Jo, et par ting... noen begreper som vi kan ta med. Et prosessforløp så starter det som en ny prosess. Det er sånn alle prosesser starter. Og så legges det i reddelist. I vaffelsimuleringen så var forelesning og vaffelprosessen helt inne i reddelist og ønsket å kjøre. En dispatcher er den delen av skredderen som velger hvilken prosess som skal kjøre. Dispatcheren setter i gang og kjører prosessen.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0009", "start": 732.08, "end": 829.78, "token_count": 292, "text": "Det er sånn alle prosesser starter. Og så legges det i reddelist. I vaffelsimuleringen så var forelesning og vaffelprosessen helt inne i reddelist og ønsket å kjøre. En dispatcher er den delen av skredderen som velger hvilken prosess som skal kjøre. Dispatcheren setter i gang og kjører prosessen. Når den er i rødningstilstand, kan den få et interrupt. Det typiske interruptet er timer interrupt. Hvert hundrede sekund vil man kunne bli avbrutt. Man kan velge å gi flere tics til samme prosess, sånn at den kjører litt lenger enn minste tidsenhet. Men så kan man også få IO. Det er sånn man venter på melkemannen. Eller noe fra disk, eller noe som tar lang tid. Så blir den tatt ut fra rønning og satt i en waiting-kø. Da er den heller ikke i ready-list. Etter de prosessene som er klare til å kjøre. Det er de som får tid. Det var også derfor de to jobbene som var nicet, fikk stå i rønning hele tiden. Fordi det ikke var noen andre i ready-list på den CPU-en.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0010", "start": 805.76, "end": 909.82, "token_count": 296, "text": "Da er den heller ikke i ready-list. Etter de prosessene som er klare til å kjøre. Det er de som får tid. Det var også derfor de to jobbene som var nicet, fikk stå i rønning hele tiden. Fordi det ikke var noen andre i ready-list på den CPU-en. Dette er én CPU. Dette er en enkel CPU. Hvis vi har flere CPU-er, så vil vi ha én kø for CPU-en. Jeg har en liten demo av dette her også, som ligger på... ... kan jeg eventuelt se i Freero, som ligger på kurssiden. Det er en liten demo som viser hele det forløpet. Med at du har prosesser som står i redelist. Som tar jobber fra readylist og ut til running. Igjen så er denne simuleringen her, eller denne illustrasjonen, den har bare én CPU. Så da er det bare én readylist. Men med en gang du har flere CPU-er, så kan kjernetråder også kjøres på mange CPU-er samtidig. Så dermed kan du få en enda mer... En effektiv utnyttelse av de CPU-ene du har. Og brukerprogrammet vil da kunne kjøre hele tiden.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0011", "start": 887.56, "end": 999.02, "token_count": 283, "text": "Men med en gang du har flere CPU-er, så kan kjernetråder også kjøres på mange CPU-er samtidig. Så dermed kan du få en enda mer... En effektiv utnyttelse av de CPU-ene du har. Og brukerprogrammet vil da kunne kjøre hele tiden. Så kan scheduler kjøre på en annen CPU, og så skritulere dette. Men dette bildet er tenkt én CPU som snart kjører. Og da ser vi her... En som måtte vente, og da kommer han tilbake i Redelist når han er ferdig med å vente. Det er herfra at scheduleren og ledddispatcheren fra Redelist hele tiden plukker jobber. Ja... Det var vel egentlig det meste om den prosess... Prosessforløpet... Vi så et par nye sheddling-begreper. En queuer er den delen av scheduleren som legger i kø og beregner prioriteten skal få dynamisk. Dispatcher er den delen som velger prosesser fra redelist. Den velger ut hvilken av de som skal kjøre. Og det kan være en ganske komplisert affære hvis du har hundrevis av prosesser.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0012", "start": 977.16, "end": 1084.78, "token_count": 285, "text": "og beregner prioriteten skal få dynamisk. Dispatcher er den delen som velger prosesser fra redelist. Den velger ut hvilken av de som skal kjøre. Og det kan være en ganske komplisert affære hvis du har hundrevis av prosesser. Det gjorde altså at den 2.6-kjerneskeduleren som vi har sett på, ble oppgradert til en skeduleren som heter Completely Fair Scheduler - CFS. Bedre og bedre schedulere. Nå skal vi se litt på dette med å lage nye prosesser. I alle OS må man ha en eller annen mekanisme for å lage prosesser. I Unix og nå i Linux så er det en litt spesiell måte å... Så er det en litt spesiell måte å starte opp prosesser på. Prosesser lages f.eks. ved systemoppstart. Da er det en første prosess inngitt. Den aller første prosessen som starter opp. Man kan også lage prosesser. Hvis du har en kjørende prosess, så kan den utføre et systemkall og så starte en ny prosess. Som ber om at en prosess startes. F.eks. hvis du er i en bærsell,", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0013", "start": 1062.44, "end": 1152.28, "token_count": 292, "text": "Da er det en første prosess inngitt. Den aller første prosessen som starter opp. Man kan også lage prosesser. Hvis du har en kjørende prosess, så kan den utføre et systemkall og så starte en ny prosess. Som ber om at en prosess startes. F.eks. hvis du er i en bærsell, og så vil du starte enda en bærsell, skriver du vers, og da initierer du at det starter opp en ny prosess. I Linux-verdenen, i Linux-kjernen, så er det alltid én prosess som lager en annen. Et såkalt folk-systemkall. Det som er spesielt med folk, er at det kloner seg selv. Når man gjør et formsystemkall, så får man en kloning av den eksisterende prosessen. Det høres litt rart ut, men det er ikke verre enn at du får en kloning, og så setter du i gang og kjører et annet program i den kloningen. En helt ny prosess som kan være helt forskjellig fra foreldreprosessen. Men det er alltid én prosess som starter en annen. Og den som starter, er naturlig nok foreldreprosessen.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0014", "start": 1132.42, "end": 1228.62, "token_count": 292, "text": "og så setter du i gang og kjører et annet program i den kloningen. En helt ny prosess som kan være helt forskjellig fra foreldreprosessen. Men det er alltid én prosess som starter en annen. Og den som starter, er naturlig nok foreldreprosessen. Og så får den et barn. En child-prosess. I prosessverdenen så er det bare én forelder til hvert barn. Her ser vi et eksempel på det. PID er prosess-ID. En parent med payday 17.12. Så gjør den en fock. Så får man en child der nede med en ny payday. Typisk at det blir en høyere payday, for paydayene øker hele veien. Også den vil ha en parent-payday på 17.12. Så kan den her gjøre en fock igjen og lage et barnebarn til den her oppe. Så får du den type hierarkier. Det fins eksempler på at man kan drepe en parenprosess med alle barn. Så hender det at det skjer noe galt der, og da kan man få zombieprosesser. Som er sånne halvdøde prosesser. De gjør ikke noe, men det er typisk hvis...", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0015", "start": 1200.02, "end": 1305.86, "token_count": 295, "text": "Så får du den type hierarkier. Det fins eksempler på at man kan drepe en parenprosess med alle barn. Så hender det at det skjer noe galt der, og da kan man få zombieprosesser. Som er sånne halvdøde prosesser. De gjør ikke noe, men det er typisk hvis... Hvis en skjellent har blitt drept uten at skjellet er blitt drept, så blir det hengende igjen en sånn zombieprosess. Det kan være vanskelig å bli kvitt, du kan se det i topp noen ganger. Men stort sett så fungerer det ryddig, så det er bare med feil at det blir zombieprosesser. Linux Fork er et systemkall for å lage en skjellprosess. Det er en identisk prosess med kopi av alt, med PCB, data osv. Her ser dere parent-dataene. Når man gir dem folk, så lages en kopi av alt dette her. Det høres jo veldig tungt ut. Og det er ikke helt riktig, for det som egentlig skjer... Den tar ikke og kopierer alt dette minnet. Det er mer en copy on demand. Sånn at hvis den trenger noen av de dataene fra parent,", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0016", "start": 1276.76, "end": 1378.66, "token_count": 291, "text": "av alt dette her. Det høres jo veldig tungt ut. Og det er ikke helt riktig, for det som egentlig skjer... Den tar ikke og kopierer alt dette minnet. Det er mer en copy on demand. Sånn at hvis den trenger noen av de dataene fra parent, så kopieres de over. Det er ikke sånn at du tar en absolutt kopi av alt. Det meste av strukturen kopieres, men av effektivitetshensyn tar man ikke Dere må bare ha en link til de delene av minnet som man trenger. Så kan man starte opp en... Som vi skal se på etterpå... Her i Child så kan det være en if-test. If I'm a child, if I'm a child, so... Start et annet program. I Windows så er det en litt annen måte å starte prosesser på. Det er hard støtte for folk, men ikke den vanlige måten å starte prosesser på. Den vanlige standardmetoden er å gjøre det kalt i Crate Process. Da sender du med ti forskjellige parametere som definerer den prosessen. Og da lages et nytt prosessobjekt. Windows er skrevet fra scratch som et objektorientert program.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0017", "start": 1350.0, "end": 1453.9, "token_count": 281, "text": "Det er hard støtte for folk, men ikke den vanlige måten å starte prosesser på. Den vanlige standardmetoden er å gjøre det kalt i Crate Process. Da sender du med ti forskjellige parametere som definerer den prosessen. Og da lages et nytt prosessobjekt. Windows er skrevet fra scratch som et objektorientert program. Det skal vi se på senere også når vi begynner med PowerShell. Så er også alltid PowerShell objekter. Så Windows er i veldig stor grad objektorientert. Ja... Bindingen mellom pant og time er ikke like sterk som den er under Linux. Det er altså create process. Da blir det... Da kan man lage en helt uavhengig prosess som ikke har noen kobling til parent. I utgangspunktet kan man også ha en sånn kobling, men den er ikke like sterk. Avslutte prosesser... Det er mange måter å stoppe prosesser på. En normal avslutning - frivillig. I et skjell kan vi skrive 'exit'... Da stopper vi, eller i 'c' 'exit'. Så kan vi ha en avslutning med feil.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0018", "start": 1431.3, "end": 1523.68, "token_count": 297, "text": "Avslutte prosesser... Det er mange måter å stoppe prosesser på. En normal avslutning - frivillig. I et skjell kan vi skrive 'exit'... Da stopper vi, eller i 'c' 'exit'. Så kan vi ha en avslutning med feil. Det er også frivillig. Programmet sier 'fire not found', og så 'exit'. Men så kan man ha fatal feil. At det er en ufrivillig situasjon hvor det er vanskelig for operativstøtten å gå videre. Deling med null. Hvordan skal du kunne gå videre? Da kan hele programmet krasje. Også hvis et program prøver å skrive til en del av minnene som en ikke har lov til, eller gjøre noe virkelig galt. Så kan hele programmet krasje. Da får du gjerne en sånn segmentation fault. Og det betyr at det er et eller annet minneprogram. Og at det da vil avsluttes. Så kan du bli drept av andre prosesser. I Linux har vi sett en kjørekill, eller terminert prosess i Windows. Det er et godt spørsmål i chatten. Windows er objektidentitet i motsetning til Unix, som er hva?", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0019", "start": 1500.0, "end": 1594.38, "token_count": 296, "text": "Og at det da vil avsluttes. Så kan du bli drept av andre prosesser. I Linux har vi sett en kjørekill, eller terminert prosess i Windows. Det er et godt spørsmål i chatten. Windows er objektidentitet i motsetning til Unix, som er hva? Jo... Unix er så mangt mens vi ser på Linux. Så er Linux stort sett skrevet i C. Det er noen ganger denne uken man skal se på alle kodelinjene i Linux-kildekoden. Dere vil da se at de aller fleste linjene er C. Og programmet C er i utgangspunktet ikke objektorientert. Det vil si at Linus-stjernen er da ikke bygd opp av... Men den er jo veldig modulær. Hvis man har et objektorientert språk, så er man fullstendig tvunget til å skrive objekter og gjøre det modulært med objekter og metoder osv. Og det er veldig nyttig, for da sikrer man at man gjør det. Men det går også an å skrive programmer i programmingsspråk som ikke er objektorienterte. På en veldig ryddig, modulær og systematisk måte.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0020", "start": 1573.06, "end": 1664.92, "token_count": 281, "text": "til å skrive objekter og gjøre det modulært med objekter og metoder osv. Og det er veldig nyttig, for da sikrer man at man gjør det. Men det går også an å skrive programmer i programmingsspråk som ikke er objektorienterte. På en veldig ryddig, modulær og systematisk måte. Det kan da si Linux er. Men i utgangspunktet er da Linux ikke objektorientert. Rett og slett fordi C i programmeringsspråket det er skrevet i, ikke er objektorientert. Men at det ikke er objektorientert, betyr ikke at det er... Metoder og funksjoner og så videre... Det har det, så det er veldig systematisk oppbygging. Men det har ikke eksplisitt objektorientering. Signaler... Ja, det har vi sett på tidligere. Jeg hadde et script som jeg kjørte, og som brukte... En kommando som heter 'trapp til å fange opp signaler'. Det er ikke den trappen man har i kjernen, men den... En shell-kommando som kan ta imot et kill-signal.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0021", "start": 1635.88, "end": 1751.22, "token_count": 290, "text": "Signaler... Ja, det har vi sett på tidligere. Jeg hadde et script som jeg kjørte, og som brukte... En kommando som heter 'trapp til å fange opp signaler'. Det er ikke den trappen man har i kjernen, men den... En shell-kommando som kan ta imot et kill-signal. F.eks. kontroll-C er vel kill-signalet 2. Og så kan den behandle det. Så alle prosesser kan ta imot signaler og behandle det. Et unntak er kill-minus-9. Så den vil drepe prosessen. Jeg kjørte en liten demo av den i en tidligere forelesning, så jeg kan legge inn en link tilbake dit. Så kan man studere hvordan man kan sende signaler til prosesser, og hvordan de kan behandle det. Men det er måten prosesser kommuniserer på. Skal vi se litt på Linux-arkitektur... Ja... Hovedprinsippet bak denne tegningen er at dette som er inni boksen her, det er Linux-kjernen. Og så ser vi alle applikasjoner og verktøy. Og så gjør de systemcall til Linux-kjernen. Linux-kjernen er delt opp i fem moduler.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0022", "start": 1725.56, "end": 1820.2, "token_count": 278, "text": "Ja... Hovedprinsippet bak denne tegningen er at dette som er inni boksen her, det er Linux-kjernen. Og så ser vi alle applikasjoner og verktøy. Og så gjør de systemcall til Linux-kjernen. Linux-kjernen er delt opp i fem moduler. Som sagt er det ikke objektorientert, men det er modulært. Så det er veldig systematisk satt opp. Men i prinsippet så kan skeduleren der borte endre på ting... I filene her... Hvis man skrev koden som var skikkelig hårete, så ville det bli ekstremt komplekst og aldri funke. Det er et enormt svært program. Konklusjonen på oppgaven denne uken, så er det noe sånt som at hvis man... Skriver ned kildekoden til lynkjernen som dere skal se på, i bøker, og stabler dem oppå hverandre, så får man en stabel som er 25 meter høy. Så det er enormt mye kode. Så dette må være veldig modulært og bygd systematisk opp. Det er fem viktige hovedmoduler.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0023", "start": 1800.0, "end": 1897.44, "token_count": 293, "text": "Skriver ned kildekoden til lynkjernen som dere skal se på, i bøker, og stabler dem oppå hverandre, så får man en stabel som er 25 meter høy. Så det er enormt mye kode. Så dette må være veldig modulært og bygd systematisk opp. Det er fem viktige hovedmoduler. Det første som vi har sett på veldig mye nå, er alt som har med prosessmanagement å gjøre. Skeduler, multitasking osv. Neste punkt vi skal se på, er ram. Vi har vært innom det, ram og cash. Cash styres ikke av operativsystemet direkte. Det er hardware-styrt, men alt som har med ram å gjøre, det styres av operativsystemet. Det skal vi se på i detalj senere. Vi kommer også til å se på filsystemet. Directories, mapper... og hvordan de... Alt dette er lagret på harddisk. Så det er de tre viktige komponentene. I tillegg har vi alle mulige deviser. Sånn som... Tastatur og terminaler og... Nettverkskort kommer under nettverk, men alle mulige andre devices. Her er det masse kode. De er i prinsippet ganske enkle ting.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0024", "start": 1864.78, "end": 1971.08, "token_count": 290, "text": "Alt dette er lagret på harddisk. Så det er de tre viktige komponentene. I tillegg har vi alle mulige deviser. Sånn som... Tastatur og terminaler og... Nettverkskort kommer under nettverk, men alle mulige andre devices. Her er det masse kode. De er i prinsippet ganske enkle ting. Men det som gjør det vanskelig, er at det er hardware. Så det er veldig mye jobb å skrive drivere til alle mulige typer hardware. Det kom vi ikke så veldig mye inn på. Vi kommer heller ikke inn på nettverk. Mange av dere har nettverk med Alfred, så i det kurset... Iallfall for dataingeniører og IT, så er det det kurset hvor vi ser på nettverk. Tidligere var nettverk en del av OS-kurset, men nå er det et eget kurs. Windows-arkitektur... I prinsippet er det mye som ligner, men noen forskjeller. Her igjen er denne nederste boksen kjernen. Så vi kjører YSMOD her oppe med brukerapplikasjoner. Alt dette kjører YSMOD og ber da operativsystemskjernen om hjelp", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0025", "start": 1942.3, "end": 2044.78, "token_count": 288, "text": "Windows-arkitektur... I prinsippet er det mye som ligner, men noen forskjeller. Her igjen er denne nederste boksen kjernen. Så vi kjører YSMOD her oppe med brukerapplikasjoner. Alt dette kjører YSMOD og ber da operativsystemskjernen om hjelp gjennom API-et, gjennom systemkallet. Med liten skrift Ntoskurnal.exe. Den vil du finne på en Windows-maskin. Hele dette programmet er LTOS-kernel.xe. Windows har også en såkalt monolittisk kjerne. Det vil si at du har én stor kodeenhet, hvor i prinsippet man kan... Her borte fra devices og filsystemer kan det ødelegge for grafikken. Fra såkalt mikrokjerne, hvor du da har en veldig liten mikrokjerne... Og da typisk disse delene er helt uavhengige... Og snakker med hverandre via signaler. Altså det kommuniserer med mikrokjernen og seg imellom. Mens i mononettiske kjerner, som både Linux og Minus er... Kan alle deler av kjernen snakke med alle deler av kjernen?", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0026", "start": 2023.92, "end": 2126.46, "token_count": 298, "text": "Og snakker med hverandre via signaler. Altså det kommuniserer med mikrokjernen og seg imellom. Mens i mononettiske kjerner, som både Linux og Minus er... Kan alle deler av kjernen snakke med alle deler av kjernen? Det betyr også at kompleksiteten blir veldig stor, og det øker sjansen for feil. En viktig forskjell på Windows og Linux er at grafikken er en del av kjernen. Det er noen forskjeller på det, har man tatt ut i noen sølveversjoner. Så er alt med grafikk en del av vinduets kjerne. Sånn er det ikke i Linux. Som vi ser her, har vi ikke noen direkte del av kjernen som styrer med grafikk. Det som skjer der, er at grafikk kjøres i user mode. Så er det sånn... X vindussystemer kjøres i user space.  Og det gjør også at det ikke er like effektivt. Spesielt har det tradisjonelt vært en del problemer med spill på Linux. Iallfall tradisjonelt, nettopp pga. pilene der. I tillegg har vi denne mikrokernen her som styrer alle disse underdelene, sånn som...", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0027", "start": 2097.58, "end": 2236.24, "token_count": 284, "text": " Og det gjør også at det ikke er like effektivt. Spesielt har det tradisjonelt vært en del problemer med spill på Linux. Iallfall tradisjonelt, nettopp pga. pilene der. I tillegg har vi denne mikrokernen her som styrer alle disse underdelene, sånn som... Objektmanager, fyllsystem osv. Men det er ikke en ekte microcarnal i den for sånn at den bare kommuniserer med signaler med de andre modulene. Men det er en liten del av kjernen som styrer alt det andre. I tillegg har man HAL, som skal gjøre at kjernen her... Får et uniforms grensesnitt mot hardware. Så hvis man endrer hardware her nede, så tar HAL det av seg. Sånn at Colonel får det samme grensesnittet. Uansett hva slags hardware som ligger under. Ok, det var litt om arkitektur. Og da tenkte jeg helt til slutt at vi skulle se på folk. En demo her oppe, så da skal vi se på... Fock. Da skal vi gå tilbake hit. Og så... Da skal vi se på en folk-demo. Folk er litt merkelige.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0028", "start": 2176.36, "end": 2313.5, "token_count": 290, "text": "Ok, det var litt om arkitektur. Og da tenkte jeg helt til slutt at vi skulle se på folk. En demo her oppe, så da skal vi se på... Fock. Da skal vi gå tilbake hit. Og så... Da skal vi se på en folk-demo. Folk er litt merkelige. Det er ikke så lett med en gang å skjønne hvordan det fungerer. Men det som skjer når jeg gjør et folk-kall... Og jeg trenger disse bibliotekene her for å kunne bruke folk. Det første programmet skriver ut folk dem òg, en linje. Og så gjør man et system kalt 'folk'. Så skriver man ut en linje til. Og det som skjer da, når du gjør 'folk', er at fra og med neste linje... Den fortsetter å kjøre og skriver ut den linjen. Men så startes det også opp en Child. Og Child er en kopi av Parent. Så siden den er en kopi av Parent, så vil den fortsette der Parent slapp. Og så vil den også skrive ut folk de må. Så vi kan prøve å kjøre den. Og så se hva som skjer. Men da får vi ut tre folk-demoer.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0029", "start": 2285.06, "end": 2388.26, "token_count": 290, "text": "Men så startes det også opp en Child. Og Child er en kopi av Parent. Så siden den er en kopi av Parent, så vil den fortsette der Parent slapp. Og så vil den også skrive ut folk de må. Så vi kan prøve å kjøre den. Og så se hva som skjer. Men da får vi ut tre folk-demoer. Det ser jeg liksom... Jeg ble alltid litt overrasket første gang. Oi, jeg skriver jo bare to ganger. Men den første folk-demoen her... For å gjøre det helt klart... Folk-demo... Vi kan kalle den én. Og så kan jeg skrive folk-demo to. Så den første, det er den første. Og så kommer det to som er folk demo to. For den ene er da parent, og den andre er sire. Så vi kan gjøre det eksplisitt. Komplimerer å kjøre i. Folk demo én skrives ut av den første. Og så folk demo to av den andre. Og sånn kan man jo fortsette. De som gjør det sånn... Hvor mange får ikke det må skrives ut, sånt totalt antall linjer? Hva tror dere? Det er et forslag om sju stykker.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0030", "start": 2351.82, "end": 2457.4, "token_count": 289, "text": "Folk demo én skrives ut av den første. Og så folk demo to av den andre. Og sånn kan man jo fortsette. De som gjør det sånn... Hvor mange får ikke det må skrives ut, sånt totalt antall linjer? Hva tror dere? Det er et forslag om sju stykker. Ja, det høres fornuftig ut, fordi man kunne kanskje tenke at det bare ble fem. Men... Her har jeg en fork, og da er det allerede... Den ville også childgjøre, så den vil lage et barnebarn, så her vil jeg doble igjen. Så jeg får liksom først én prosess, så er jeg to, og så er jeg fire. Så da burde det bli syv stykker. Yes. Dere er altfor gode. Dere svarer riktig med en gang. Mye bedre om noen av dere feiler først, men veldig bra. Så skal vi prøve å se på litt... Ja, hvor da? Hvordan kan man egentlig bruke dette her? Det ville jo ikke være så veldig hensiktsmessig hvis... Hvis man bare... kjørte videre akkurat det samme programmet.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0031", "start": 2427.46, "end": 2540.92, "token_count": 284, "text": "Mye bedre om noen av dere feiler først, men veldig bra. Så skal vi prøve å se på litt... Ja, hvor da? Hvordan kan man egentlig bruke dette her? Det ville jo ikke være så veldig hensiktsmessig hvis... Hvis man bare... kjørte videre akkurat det samme programmet. Så skal vi prøve å se på litt hva... Hva er det... Hva er det denne folk returnerer int. payday? Så kan jeg ta... Skal vi se... Kan jeg ta en printf...? Ja, det er spørsmål om hvorfor det skrives nummer tre ut fire ganger. La oss se litt nærmere på det. Jo, det er fordi... Her startes en shale. Og dermed er det to programmer som skriver et Folk-demo 2. Og da vil det første... Parent som skriver et Folk-demo 2 her... Det vil gjøre folk... Og da vil du få... Da vil Terence selv skrive ut demo 3, og den charten som lagde, skrive ut demo 3. Det samme skjer da med den demo 2 her, som ble startet. Den skriver ut demo 2, og så lager den chart.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0032", "start": 2517.46, "end": 2628.5, "token_count": 289, "text": "Det vil gjøre folk... Og da vil du få... Da vil Terence selv skrive ut demo 3, og den charten som lagde, skrive ut demo 3. Det samme skjer da med den demo 2 her, som ble startet. Den skriver ut demo 2, og så lager den chart. Og så selv skriver den ut demo 3, og så er det charten dens igjen som skriver ut enda en demo 3. Så dermed blir det fire ganger utskrift med Demo 3. Men det er ganske forvirrende når man driver og setter det opp. Det er ikke så opplagt at det blir syv. Men det er noen oppgaver denne uken som går på dette her, så prøv og feil litt med folk. Men hovedpoenget var at man kan... Hvis jeg husker riktig syntaks... Så kan man skrive ut... PiD er lik... Skal vi se... 1,5 % D. Kan få ha noe sånt. Og så er det payday lik 0. Akkurat dette kan vi bruke til noe. Det er en kommentar at dette er nesten som rekvisjon. Ja. Det er rekvisjon, men ikke helt som når en metode kaller seg selv.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0033", "start": 2594.56, "end": 2695.62, "token_count": 283, "text": "Kan få ha noe sånt. Og så er det payday lik 0. Akkurat dette kan vi bruke til noe. Det er en kommentar at dette er nesten som rekvisjon. Ja. Det er rekvisjon, men ikke helt som når en metode kaller seg selv. For når en metode kaller seg selv, så starter den alltid fra starten. Men her er en slags rekvisjon hvor du... Eller... Man kunne tenke seg at når du gjør en fork... At du starter programmet på nytt. Men da må man huske på at dette er en kopi av det programmet som kjører. Så det er en kopi som fortsetter å kjøre derfra parent-prosessen er. Det er akkurat det samme programmet, og dermed vil ikke... Child vil ikke sette i gang og kjøre den første printen. Den vil bare fortsette derfra. Det er derfor jeg aldri får noen førsteprint fra skjerm. Så det er et slags rekkerskiftkall, men det rekkerskiftkallet starter fra nøyaktig der parent er, og fortsetter derfra. Så det er rett og slett en kopi. Man kopierer alt ved prosessen...", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0034", "start": 2669.48, "end": 2840.22, "token_count": 286, "text": "Det er derfor jeg aldri får noen førsteprint fra skjerm. Så det er et slags rekkerskiftkall, men det rekkerskiftkallet starter fra nøyaktig der parent er, og fortsetter derfra. Så det er rett og slett en kopi. Man kopierer alt ved prosessen... Og så kjører den videre derfra den forrige slapp, som en eksakt kopi. Men det er en forskjell, og det er nemlig den payday-en. For da er det sånn at i Child så returnerer forkallet null. Mens i Parents så returneres paydayen til Child. Så dermed så kan man utnytte dette, og så kan man si... If payday er lik null... Hva skjer da? Jo, da kan man si... Jeg er child. Folk ga PD... Og da bør det bli PD-lignende. Sånn. Og så kan vi si Elds. Jeg er ferdig... Skrives denne siste linjen ut her... Jo, det som forhåpentligvis skjer nå, er at for Child så kjører jeg denne. Og så for Parent så kjører jeg bare den der. Så vi skal få to utskrifter.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0035", "start": 2787.46, "end": 2930.22, "token_count": 289, "text": "Jeg er ferdig... Skrives denne siste linjen ut her... Jo, det som forhåpentligvis skjer nå, er at for Child så kjører jeg denne. Og så for Parent så kjører jeg bare den der. Så vi skal få to utskrifter. Men hvor mange ganger kjører den? Får ikke det noe avsluttet på? Jo... To ganger, ja. Flere som sier to. Helt riktig. Dette er bare en if-test. Hvis den er skjelt, så kjører du den der. Men etter den if-testen så vil den ikke gå inn her, men den vil faktisk fortsatt kjøre den der. Så rekker den akkurat å skrive ut folk de har måttet avslutte før Shield kommer inn. Shield er nå light og skriver ut 'jeg er Shield, folk har payday' eller knull. Det vanlige er at du har en sånn test, og så kjører du ikke noe mer felles kode. Man kan også kjøre felleskode sånn som det. Og da kan man få litt mer avanserte måter å bruke folk på. Sånn som dette her... Hvor man har parent og shield. Vi skal ikke se på det i detalj...", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0036", "start": 2897.16, "end": 3012.24, "token_count": 293, "text": "Det vanlige er at du har en sånn test, og så kjører du ikke noe mer felles kode. Man kan også kjøre felleskode sånn som det. Og da kan man få litt mer avanserte måter å bruke folk på. Sånn som dette her... Hvor man har parent og shield. Vi skal ikke se på det i detalj... Men bare for å gi et inntrykk, så kan det se sånn ut. Med prosess-paydate 2697. Og så sier den jeg er shield. I dette tilfellet venter parent ikke på at shield er avsluttet. Da ser vi den bare fortsetter. Siden det er en kloning, så har den samme terminal output også, så den skriver default output. Child-prosess har ikke null i payday, men forkalle returnerer null. Så payday-entershield-prosessen, det er den som parent får. Dette vil da være payday-entershield-prosessen. Men... nei, dette er payday-entershield-prosessen. Child får en payday, men variabelen payday er ikke null inni child. Dette er kommunikasjon mellom de to prosessene. Vi kan gjøre en wait-pay-idé. Her er jeg nå i parent. Og den sier ok, jeg skal vente på...", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0037", "start": 2982.42, "end": 3090.76, "token_count": 299, "text": "Men... nei, dette er payday-entershield-prosessen. Child får en payday, men variabelen payday er ikke null inni child. Dette er kommunikasjon mellom de to prosessene. Vi kan gjøre en wait-pay-idé. Her er jeg nå i parent. Og den sier ok, jeg skal vente på... Jeg skal vente på shard. Så... Så burde det stått sånn. Her ser vi parents står og venter. Skjærprosess avslutter. Og så avslutter parents også. På den måten kan man starte nye prosesser, og så kan de kommunisere med hverandre. Og siden man har en sånn if-test, så kan den nye skjærprosessen gjøre hva som helst. F.eks. så kan man lage en skjærprosess, og så kan man be den... Og dermed har man en helt ny, uavhengig prosess som kjører et annet program. Ok... Oi! Nå har jeg brukt masse tid her. Nå er det sikkert rimelig utslett. Hvis dere er her, så skal jeg vel lage breakout-rooms med en gang. Så er vi... Forhåpentligvis så er vi fire stykker i dag. Med studenter og studenter.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0038", "start": 3065.58, "end": 3166.66, "token_count": 292, "text": "Ok... Oi! Nå har jeg brukt masse tid her. Nå er det sikkert rimelig utslett. Hvis dere er her, så skal jeg vel lage breakout-rooms med en gang. Så er vi... Forhåpentligvis så er vi fire stykker i dag. Med studenter og studenter. Så da blir det masse anledning til å gå inn i breakout rooms og spørre og grave og komme med alle mulige spørsmål og problemer dere har. Så utnytt den sjansen. Det tror jeg kan være veldig nyttig. Så hvis det ikke er noen kommentarer eller spørsmål inne... Er du der fortsatt? Du er der. Supert. Jeg måtte bare få på mikrofonen. Er det noe du har lyst til å legge til eller kommentere om? For eksempel om... Hvordan er situasjonen med første opplegg? Er den...? En ferdig...? Det er ferdig retta, men det er vel gitt nye flister og sånt noe. Så det har vært noen spørsmål om løsningsforslag skal legges ut, men det vil jo ikke da bli lagt ut før det har fått sin sjanse til å levere på nytt.", "source": "lecture"}
{"lecture_id": "os9time2", "chunk_id": "os9time2_0039", "start": 3149.82, "end": 3185.2, "token_count": 116, "text": "Det er ferdig retta, men det er vel gitt nye flister og sånt noe. Så det har vært noen spørsmål om løsningsforslag skal legges ut, men det vil jo ikke da bli lagt ut før det har fått sin sjanse til å levere på nytt. Nei, det er sånn vi pleier å ha det. Men forhåpentligvis så blir det ganske snart. Da kommer vi til å legge ut løsningsforslag.", "source": "lecture"}
{"lecture_id": "linux7del6", "chunk_id": "linux7del6_0000", "start": 0.0, "end": 103.18, "token_count": 285, "text": "OK. Nå skal vi straks begynne å kjøre noen containere. Da skal vi se at det er en liten applikasjon. Som sagt, i praksis er det en prosess som er veldig avlukket. Sånn at ingen andre prosesser i det hele tatt, eller nesten i det hele tatt, kan se hva som skjer innenfor. Vi kan kjøre starte og stoppe og flytte og delete. Vi kan laste ned nye fra Dokkerøb. Og vi kan også lage eggene. Ja. Litt mer om VM-er i forhold til konteinere. Vi ser på høyre side her, så ser vi en VM. Dette er VM-en som kjører da på. Så har vi Linux-kjernen her. Så ser vi at en konteiner, det er på en måte midt imellom en vanlig prosess og en VM. Virtuell maskin kjører prosessen her oppe på gjeste-OS. Mens her, konteineren... Vi ser at det er en vanlig prosess, men den er isolert fra... På en mye bedre måte enn standard. På venstre side ser vi det han nevnte, at her kjører de en Ubuntu-container,", "source": "lecture"}
{"lecture_id": "linux7del6", "chunk_id": "linux7del6_0001", "start": 78.06, "end": 179.76, "token_count": 280, "text": "Virtuell maskin kjører prosessen her oppe på gjeste-OS. Mens her, konteineren... Vi ser at det er en vanlig prosess, men den er isolert fra... På en mye bedre måte enn standard. På venstre side ser vi det han nevnte, at her kjører de en Ubuntu-container, og så kjører de en SentOS-container, men begge to kjører på den samme Linux-kjernen. De har også vinduskonteinere, men de trenger da en vinduskjerne under. Muligens får vi litt tid senere til å se på det også. Litt terminologi. Vi har konteinere og det er på en måte... Vi har konteinere og images. Images er hele den blokken av kode som man kjører. Hvis man har virtuell maskin, så er et image absolutt... Hele apparativsystemet og alt som kjører. Mens for konteinere så er et image ikke så stort som hele OS. Det er alt det du trenger for å få en generell Linux-kjerne til å se ut som en ubundet kjerne. Men iallfall så starter man images, og en instans som kjører et image...", "source": "lecture"}
{"lecture_id": "linux7del6", "chunk_id": "linux7del6_0002", "start": 150.0, "end": 200.5, "token_count": 133, "text": "Hele apparativsystemet og alt som kjører. Mens for konteinere så er et image ikke så stort som hele OS. Det er alt det du trenger for å få en generell Linux-kjerne til å se ut som en ubundet kjerne. Men iallfall så starter man images, og en instans som kjører et image... Neste uke skal vi se litt på volumer, men det vil da være lagringsplass for konteinerne. Opplagt så har de nettverk. Det er egentlig stort sett det vi ser på i dag.", "source": "lecture"}
{"lecture_id": "os8del13", "chunk_id": "os8del13_0000", "start": 0.0, "end": 76.28, "token_count": 290, "text": "Og det er denne Need resched. Det står altså trenger reschedulering. Og det skjer hvis det i løpet av epoken kommer inn et interrupt, så vil dette flagget bli satt. Det er en sånn 01-bit i CPU-en. Og hvis dette bitet blir satt, så vil scheduleren kjøres etter neste timetick. Husker du at hvis det var en prosess som hadde la oss si 20 tics, Sheduleren går inn og kontrollerer om det har skjedd noen interrupts. Nei, det har ikke det. Da bare kjører samme prosess videre. Så slipper den cotex-witchen. Men hvis det har kommet en interrupt, så er den bitte satt, og da kjøres scheduleren på nytt. Og da kan den gå inn og sag. Ok, da gir jeg den... Den prosessen som har høyst prioritet, den får nå kjøre. Interaktive prosesser som har bygd seg opp høy prioritet ved å ikke bruke CPU. Du får liksom goodwill. Når jeg kommer inn, så bruker jeg omtrent ikke CPU. Men da vil jeg ha høy prioritet. Og det er akkurat sånn skeduleren bygger opp systemet.", "source": "lecture"}
{"lecture_id": "os8del13", "chunk_id": "os8del13_0001", "start": 60.0, "end": 141.0, "token_count": 266, "text": "Interaktive prosesser som har bygd seg opp høy prioritet ved å ikke bruke CPU. Du får liksom goodwill. Når jeg kommer inn, så bruker jeg omtrent ikke CPU. Men da vil jeg ha høy prioritet. Og det er akkurat sånn skeduleren bygger opp systemet. Noe tilsvarende må alle andre skedulere gjøre også. Dette er en veldig viktig mekanisme når du skal kjøre både interaktive prosesser og regneprosesser samtidig på det samme systemet. Hvis vi ikke hadde sånn, så måtte man vente helt til den CPI-intensive prosessen var ferdig med sin del. Og hvis det tok flere tidelssekunder, så ville det oppleves som veldig tregt for en interaktiv prosess. Ok. Dette var de viktige prinsippene bak skredulering. De to viktigste prinsippene var user mode og cull mode. Og i tillegg systemkall og trap. Disse begrepene må dere ha... De må dere ha greie på. De er det viktigste når det gjelder operativsystem.", "source": "lecture"}
{"lecture_id": "os4del6", "chunk_id": "os4del6_0000", "start": 0.0, "end": 101.98, "token_count": 283, "text": "Neste spørsmål var om Harvard-arkitektur eller ikke. Og det er... Og det er et litt vanskelig spørsmål i denne sammenhengen. For det vi vet om Neumann-arkitekturen, den er sånn at både instruksjoner... Og data sendes gjennom den samme bussen. Så det betyr at hvis dette hadde hatt en von Neumann-arkitektur, så skulle programmet som ligger her, det skulle ha ligget i RAM. Og maskinen skulle da lese inn institusjonene, og så utføre de institusjonene. Og samtidig, når den skulle skrive data, så skulle de gå ut disse kanalene til RAM. Ligger denne nærmere Harvard-arkitektur? Og det er rett og slett fordi bussen, eller dataene fra institusjonene følger en annen vei enn dataene fra... Variablene som lagres i ramme. Altså dataene som lagres i ramme. En annen buss eller en annen kanal som går mellom institusjonene og SEPPU. Så derfor kan man si at dette er en hardware... hardware arkitektur.", "source": "lecture"}
{"lecture_id": "os14del15", "chunk_id": "os14del15_0000", "start": 0.0, "end": 103.96, "token_count": 296, "text": "Jo, filsystemcash... Det er rett og slett at man tar... I stedet for å lese bit for bit av en fil. La oss si jeg ønsker å... La oss si jeg gjør dette her. Og leser den biten der. Det Linux gjør neste gang jeg skal lese den filen... Så går det lynraskt, for da har Linux brukt ram og lagt hele filen inn i ram. Så hele filen ligger da i ram. Og spesielt hvis det er en stor fil, 4 GB fil, og hele ligger i ram, så går det lynraskt å hente ut deler av den fila i forhold til om den ligger på disk. Så det er det filsystem-cash er. Den bruker da ram som cash mellom... Ja, på en måte mellom ramm og disken. Skal vi se om vi ikke har noen... Om vi ikke har en slide som viser det. Nei, det har jeg ikke. Men det er da altså... På samme måte som cash, L1 og L2 og Eltre Cash, ligger mellom registrene og ramm, Så kan du si at filsystemcachen ligger mellom disken og CPU-en som en cache, sånn at det som ligger i filen,", "source": "lecture"}
{"lecture_id": "os14del15", "chunk_id": "os14del15_0001", "start": 78.68, "end": 108.0, "token_count": 93, "text": "Nei, det har jeg ikke. Men det er da altså... På samme måte som cash, L1 og L2 og Eltre Cash, ligger mellom registrene og ramm, Så kan du si at filsystemcachen ligger mellom disken og CPU-en som en cache, sånn at det som ligger i filen, kommer raskere inn i CPU-en og behandler seg.", "source": "lecture"}
{"lecture_id": "os11del11", "chunk_id": "os11del11_0000", "start": 0.0, "end": 84.08, "token_count": 281, "text": "Men vi skal også se at vi kan ha en race condition selv om det bare er én enkelt kodelinje. Og en problemstilling for dette er at én linje høynivåkode... Selv om man bare ser koden, så ser man at dette er bare én linje. Så her kan det ikke skje noe galt med race condition. Men som vi har sett tidligere, så kan... Ofte én linje med høynivåkode oversettes til flere linjer med maskinkode. I noen tilfeller er det helt nødvendig, og det vil faktisk skje. En context switch kan oppstå når som helst mellom to maskininstitusjoner. Vi har sett mange ganger at operativsystemet ikke aner noe om hva de forskjellige... Om hva de forskjellige... Institusjonene betyr, og hva de gjør. Så operativstemme bare sier OK, kjør. Institusjon. Institusjon. Institusjon. Når som helst så kan det komme en kontekstsvikt. Og hvis prosessen opererer på to forskjellige stuper, så har man operativstemme enda mindre kontroll.", "source": "lecture"}
{"lecture_id": "os11del11", "chunk_id": "os11del11_0001", "start": 60.0, "end": 141.72, "token_count": 293, "text": "Institusjonene betyr, og hva de gjør. Så operativstemme bare sier OK, kjør. Institusjon. Institusjon. Institusjon. Når som helst så kan det komme en kontekstsvikt. Og hvis prosessen opererer på to forskjellige stuper, så har man operativstemme enda mindre kontroll. Så da skal vi se på et eksempel med to prosesser som opptatt... De oppdaterer én felles variabel. Og da er det en saldo de oppdaterer. Og her ser vi koden for P1. Den gjør nå kode, og så gjør den et eller annet sted. Saldo eller saldo minus mill. Så den trekker fra en million kroner på saldo. Tilsvarende gjør P2 noen operasjoner, og så øker den saldo med én. Og da er det lett å tenke sånn at ja, dette er bare én. Så om disse to kjører samtidig, så vil ikke det ha noe å si. For først trekker den fra en mil, og så ligger den til en mil. Man skulle tro at dette, spesielt hvis man har kjørt på samme CPU, at dette burde gå fint.", "source": "lecture"}
{"lecture_id": "os11del11", "chunk_id": "os11del11_0002", "start": 116.68, "end": 205.8, "token_count": 280, "text": "Og da er det lett å tenke sånn at ja, dette er bare én. Så om disse to kjører samtidig, så vil ikke det ha noe å si. For først trekker den fra en mil, og så ligger den til en mil. Man skulle tro at dette, spesielt hvis man har kjørt på samme CPU, at dette burde gå fint. Men hva skjer egentlig hvis det på et uheldig sted kommer en Context Switch fra P1 til P2? Jo... Da må vi tenke på maskinarkitektur og assembly, og at det faktisk prosesser gjør, er å utføre maskinkode. I dette tilfellet er det maskinkode for X86, altså rett på halvvei. Vi skal se senere at vi har det tilsvarende når vi kjører i Java. Og da vil disse operasjonene, sånn som saldo og saldo pluss mill... Denne operasjonen kan ikke utføres av én enkelt maskininstitusjon. Det har vi sett tidligere. X86 tillater ikke to referanser til minnet samtidig. Så på en eller annen måte, uansett hvordan man kompilerer dette,", "source": "lecture"}
{"lecture_id": "os11del11", "chunk_id": "os11del11_0003", "start": 180.0, "end": 265.0, "token_count": 289, "text": "Og da vil disse operasjonene, sånn som saldo og saldo pluss mill... Denne operasjonen kan ikke utføres av én enkelt maskininstitusjon. Det har vi sett tidligere. X86 tillater ikke to referanser til minnet samtidig. Så på en eller annen måte, uansett hvordan man kompilerer dette, eller om man skriver assembly-kode selv, så må man gjøre noe tilsvarende dette. Man kunne gjort det kanskje ett steg videre, men noe tilsvarende som dette må skje. Men man må flytte saldo inn i et register. Og så har vi mill. Det ligger også ute i minnet. Så vi flytter det inn i BX, og så legger vi BX til AX. Da har vi lagt til saldo lik saldo pluss mill, og så legger vi resultatet ut i saldo. Og så er det tilsvarende for... Og da får vi et problem. Da kan vi risikere at en million forsvinner. Og da tenker vi oss at saldo er fem først, og så begynner vi med prosess én som trekker ifra. Den flytter saldo og mill inn i registrene sine, og så skjer en context nitch.", "source": "lecture"}
{"lecture_id": "os11del11", "chunk_id": "os11del11_0004", "start": 240.0, "end": 329.92, "token_count": 297, "text": "Og da får vi et problem. Da kan vi risikere at en million forsvinner. Og da tenker vi oss at saldo er fem først, og så begynner vi med prosess én som trekker ifra. Den flytter saldo og mill inn i registrene sine, og så skjer en context nitch. Og da er det viktig å huske på at ved en context nitch så må alt lagres. De lagres da for den prosessen. Og så kommer prosess 2 inn. Og den vil jo gjøre det samme, men flytte saldo og mill inn i AX og BX. Og allerede her aner vi at her kan ting gå galt. Denne P2 vil da ta og legge én mill til de fem eksisterende, sånn at den får AX eller X. Så flytter den verdien ut, sånn at det blir seks millioner her ute. Før eller senere skjer det en contact switch tilbake til prosess 1. Og så tar prosess 1 sub BX minus AX. Men den bruker jo de gamle verdiene. Altså den tar og trekker fra saldoen. Fem minus én, og da får den fire. Og så flytter den resultatet ut i saldo, og saldoen har blitt fire.", "source": "lecture"}
{"lecture_id": "os11del11", "chunk_id": "os11del11_0005", "start": 305.44, "end": 389.14, "token_count": 285, "text": "Og så tar prosess 1 sub BX minus AX. Men den bruker jo de gamle verdiene. Altså den tar og trekker fra saldoen. Fem minus én, og da får den fire. Og så flytter den resultatet ut i saldo, og saldoen har blitt fire. Opplagt i dette tilfellet så burde jo saldo ha blitt 5, og 1 mill. er borte. Og det er alltid kjedelig fra en saldo. Så konklusjonen her er... Dette må opplagt serialiseres. Og det man må gjøre, er å serialisere aksess til felles data. Å serialisere betyr at først gjør P1 seg ferdig med sine operasjoner med saldo, og så gjør P2 seg ferdig. Eller motsatt. Men de må ikke kunne gjøre det samtidig. Og akkurat dette kalles et kritisk avsnitt. Altså når en prosess gjør en operasjon på en felles variabel. Da er det et såkalt kritisk avsnitt. Og ideen med å serialisere er at kritisk avsnitt må fullføres i sin helhet før den andre.", "source": "lecture"}
{"lecture_id": "os11del11", "chunk_id": "os11del11_0006", "start": 363.98, "end": 425.08, "token_count": 157, "text": "Og akkurat dette kalles et kritisk avsnitt. Altså når en prosess gjør en operasjon på en felles variabel. Da er det et såkalt kritisk avsnitt. Og ideen med å serialisere er at kritisk avsnitt må fullføres i sin helhet før den andre. Og for å få til dette så fins det en rekke forskjellige metoder. Men det skal vi se på neste gang hva slags metoder man kan bruke for å fikse dette. Nå skal vi se på noen eksempler på hvordan dette ser ut i praksis. Og med Petrads. Altså for tiden.", "source": "lecture"}
{"lecture_id": "os12del13", "chunk_id": "os12del13_0000", "start": 0.0, "end": 118.96, "token_count": 290, "text": "Da tenker jeg at vi bare har én CPU. Én CPU her, og så har vi ramme her oppe. Og her har vi svar. Svarlekk 10. Og da er det litt greiere, for hvis vi bare ser... La oss kalle den institusjonen for INKSVAR. Da skjer den operasjonen der. Det er bare én institusjon. Så da vil det hele tiden være sånn at hvis du... Hvis jeg gjør INKSVAR, så henter jeg ut tallet ti. Den tar databussen. Inn til Alun. Alun får inn ti, sender elleve tilbake. Og så kommer det elleve opp her. Og dette er da én operasjon. Men så har jeg nå to prosesser, eller to tråder, som kjører samtidig på denne CPU-en. Og da vil det liksom være P1 og P2... Men gjett gitt... P1 og P2 har liksom et lite område. De har en sånn PCB her oppe hvor de har sine verdier lagret. Ops... Dårlig kulepenn. Der. P1 og P2 har... ... sine verdier lagret her oppe. Og det er når du gjør en Context Switch.", "source": "lecture"}
{"lecture_id": "os12del13", "chunk_id": "os12del13_0001", "start": 90.0, "end": 205.72, "token_count": 298, "text": "Men gjett gitt... P1 og P2 har liksom et lite område. De har en sånn PCB her oppe hvor de har sine verdier lagret. Ops... Dårlig kulepenn. Der. P1 og P2 har... ... sine verdier lagret her oppe. Og det er når du gjør en Context Switch. Så henter man inn de gamle verdiene. Men da er poenget her... Når vi kjører et task-sett, og vi bare har én institusjon, så da så vi at en context switch hadde ikke noe å si. For da utføres den institusjonen her ferdig, og det går bare én i operasjon. Så hver gang prosess 1 er inne og gjør dette her, så økes det pent fra 10 og 11. P2 inn, og skal jobbe. Da vil den hente ut verdien 11, for P1 er jo ferdig med den. Kjøre ned til aluen og øke igjen. Og da kommer den opp til 12. Og alt går fint. Men det som ble problemet, er... Hva skjer om vi bruker den koden som... Move svar til... Ja, det er prosent AX, ink, prosent AX. Og move prosent AX til svar.", "source": "lecture"}
{"lecture_id": "os12del13", "chunk_id": "os12del13_0002", "start": 162.86, "end": 274.44, "token_count": 281, "text": "Og da kommer den opp til 12. Og alt går fint. Men det som ble problemet, er... Hva skjer om vi bruker den koden som... Move svar til... Ja, det er prosent AX, ink, prosent AX. Og move prosent AX til svar. Da var det tre instruksjoner. Og da så vi at da ble det også trøbbel for... Selv om vi kjørte Task-sett. Og da har vi to prosesser, P1 og P2, og det var litt sånn som med den MILD-en som vi så på. Da, selv om det bare er én CPU og én buss, så får du problemer. For da vil... La oss si vi... Ja, la oss si vi... Vi har verdien 11 her, da. Så er det ProsessP1 som kjører, henter inn verdien 11 og legger den i AX. Og så kommer det en ContextSwitch. Og da ligger da verdien 11... Den vil da lagres i PCB for P1. Og den verdien 11, den ligger der, da. Og så kommer den ContextSwitch akkurat etter den institusjonen der. Her kommer det Context Itch.", "source": "lecture"}
{"lecture_id": "os12del13", "chunk_id": "os12del13_0003", "start": 253.1, "end": 342.36, "token_count": 296, "text": "Og så kommer det en ContextSwitch. Og da ligger da verdien 11... Den vil da lagres i PCB for P1. Og den verdien 11, den ligger der, da. Og så kommer den ContextSwitch akkurat etter den institusjonen der. Her kommer det Context Itch. Så starter P2 å kjøre, og den vil da begynne på koden her og hente inn verdien 11, som ligger i svar, inn i sitt register. Og så øker den den og legger ut osv. Og da ville da P2 kunne gjøre det en rekke ganger. 100 ganger, kanskje. Så den kommer opp i et svar på 111. Og så kommer den kontekstfritz tilbake, og så er det P1 sin tur. Men da vil jo P1 begynne å operere på sin gamle 11 som ligger der. Den legges inn i registrene. Og så øker den AX10 og får 12. Og så sendes 12 ut. Og da ser vi... Da blir det totalt kaos, fordi det var tre linjer her. Men hvis vi kjørte Task-sett og tvang begge prosessene til å kjøre på samme CPU, så så vi at INK svarte", "source": "lecture"}
{"lecture_id": "os12del13", "chunk_id": "os12del13_0004", "start": 316.82, "end": 350.0, "token_count": 91, "text": "Og så sendes 12 ut. Og da ser vi... Da blir det totalt kaos, fordi det var tre linjer her. Men hvis vi kjørte Task-sett og tvang begge prosessene til å kjøre på samme CPU, så så vi at INK svarte med én enkel operasjon så fungerte det som det skulle. Da fikk vi ikke noe trøbbel.", "source": "lecture"}
{"lecture_id": "linux10del6", "chunk_id": "linux10del6_0000", "start": 0.0, "end": 80.88, "token_count": 279, "text": "Det punktet vi så på nå, var kanskje det mest teknisk kompliserte med virtualisering. Hvis du ikke fikk det helt med, så prøv å se gjennom de slidene et par ganger til. Men jeg kan gjenta det som er hovedpoenget. Det er at når vi kjører virtuelle maskiner, så kjører Gjeste-OS, altså det operativsystemet som da kjører Det kjører i user mode. For Hypoviser har nå rollen til operativsystemkjernen og kjører i corner mode. Tidligere når vi så på dette med at vi bare hadde et operativsystem, så ble denne boksen operativsystemet sitt. Og oppå denne boksen så kjørte applikasjonene. Og da var det alltid sånn, applikasjonene måtte spørre OS-kjernen. Og de måtte bruke kjernekall osv. Men applikasjoner kjørte da alltid i use mode. Hvis de skulle be OS om noe, så måtte de bruke systemkall. Men nå er de rollene snudd litt på hodet. Hypervisor har rollen å kjøre i curl-mode.", "source": "lecture"}
{"lecture_id": "linux10del6", "chunk_id": "linux10del6_0001", "start": 58.04, "end": 147.92, "token_count": 297, "text": "Og da var det alltid sånn, applikasjonene måtte spørre OS-kjernen. Og de måtte bruke kjernekall osv. Men applikasjoner kjørte da alltid i use mode. Hvis de skulle be OS om noe, så måtte de bruke systemkall. Men nå er de rollene snudd litt på hodet. Hypervisor har rollen å kjøre i curl-mode. Og gjeste-OS, det må da be Hypervisor om tjenester. Men det er problemet... Når vi virtualiserer, så ønsker vi at Gjest-OS skal kunne oppføre seg nøyaktig som om det OS-et kjørte direkte på hardware. Da er det klart at hvis Gjest-OS utfører en instruksjon... Om jeg kan gjenta det siste? Ja, jeg kan prøve. Så... Hypervisor har rollen til operativsystemkjernen. Den kjører i curlen mode. Du kan se på hypervisor som en operativsystemkjerne. Når det gjelder KVM, så er hypervisor faktisk Linux-operativsystemet. Så hypervisor kjører direkte på hardware. Når gjeste-OS kjører, så må det derfor kjøre i user-mode. Og når gjeste-OS skal", "source": "lecture"}
{"lecture_id": "linux10del6", "chunk_id": "linux10del6_0002", "start": 128.62, "end": 218.68, "token_count": 280, "text": "Du kan se på hypervisor som en operativsystemkjerne. Når det gjelder KVM, så er hypervisor faktisk Linux-operativsystemet. Så hypervisor kjører direkte på hardware. Når gjeste-OS kjører, så må det derfor kjøre i user-mode. Og når gjeste-OS skal Når GjestOS skal utføre en institusjon som bare kan kjøres i current mode, så forventer GjestOS at denne institusjonen, den... 'Jeg er i current mode. I denne institusjonen skal jeg kunne kjøre.' Dette skal f.eks. kunne skru av interrupts. Men det GjestOS ikke vet, er at den kjører i use of mode. Og det ikke er hardware-støtte for virtualisering. Så vil POPF-institusjonen bare forsvinne ut i løse luften. Ingenting vil skje. Den vil ikke trappe ned til Hypervisor, sånn at Hypervisor kan sørge for at det GjestOS ønsker å gjøre, blir gjort. Og dermed så... Hvis ikke alle sensitive instruksjoner Hvis institusjoner trapper ned til hypervisor, vil ikke virtualiseringen fungere.", "source": "lecture"}
{"lecture_id": "linux10del6", "chunk_id": "linux10del6_0003", "start": 190.94, "end": 257.04, "token_count": 223, "text": "Den vil ikke trappe ned til Hypervisor, sånn at Hypervisor kan sørge for at det GjestOS ønsker å gjøre, blir gjort. Og dermed så... Hvis ikke alle sensitive instruksjoner Hvis institusjoner trapper ned til hypervisor, vil ikke virtualiseringen fungere. Det vi så på, sensitive institusjoner, det er de som bare kan utføres i curlen mode. Alle disse må trappe, ellers så vil ikke OS oppleve at det er et OS. Da vil du oppleve at noen av institusjonene bare forsvinner ut i lufta fordi de utføres i use mode. Det betyr at alle sensitive institusjoner må være privilegerte. Alle kjerneinstitusjoner som gjøres av gjeste-OS i use-mode, må trappe til hypervisor, slik at hypervisor kan sørge for at det gjeste-OS ønsker å gjøre, det blir utført.", "source": "lecture"}
{"lecture_id": "os6del7", "chunk_id": "os6del7_0000", "start": 0.0, "end": 119.98, "token_count": 287, "text": "Det var også spørsmål om grupper, så vi kan ta det også hvis vi går inn på studentgruppene her. Så ser dere at det er OS-grupper, og nå er det 96 grupper. Så for å få en... For å få tilgang til en Linux-VM, så må du melde deg inn i... Hvis du ennå ikke har fått tilgang, f.eks. ikke har levert obliger, så meld deg inn i OS84. Det du da får som OS84, det er da bare et passord. Så du får kun passordet, og da er tanken at hvis du har passord... 84... Så skal du da logge deg inn som brukeren Group84. Og i tillegg så skal... Så er hosten som du skal inn på, det er OS84. Sånn logger du deg inn til denne adressen. Først, før vi logger oss inn, kan vi f.eks. bruke ping. Så kan vi se... Sende en ping til en HOS-en. Da ser vi at den svarer på ping. Så dette er en sånn typisk måte man sjekker om en server er oppe på. Ved å pinge den... Men så er det da viktig at du går inn...", "source": "lecture"}
{"lecture_id": "os6del7", "chunk_id": "os6del7_0001", "start": 95.64, "end": 194.4, "token_count": 290, "text": "Så kan vi se... Sende en ping til en HOS-en. Da ser vi at den svarer på ping. Så dette er en sånn typisk måte man sjekker om en server er oppe på. Ved å pinge den... Men så er det da viktig at du går inn... Hvordan vi finner passordet? Jo, gå på OS-gruppen og så klikk på... Annonsement. Jeg trodde kanskje man fikk det annonsementet i e-post også. Altså alt på gruppen. Hvis ikke, så gå inn på... gå inn på gruppe. Og så klikk på announcement der. Det skal jeg ikke gjøre, for der ligger da passordet til OS28. Det kom altså på e-post, ja. Både på e-post... Men hvis dere har glemt eller slettet den e-posten, så gå inn i gruppen og se på announcements. Der ligger det bare en streng. Det er vel fire tegn, altså et tall, og så fire nye tegn. Et lite ord, altså et tall, og så et annet ord. Da logger dere inn som group84. At os84. Og så er det... Hvis dere får opp noe sånt som dette, så svar yes.", "source": "lecture"}
{"lecture_id": "os6del7", "chunk_id": "os6del7_0002", "start": 170.52, "end": 249.8, "token_count": 295, "text": "Der ligger det bare en streng. Det er vel fire tegn, altså et tall, og så fire nye tegn. Et lite ord, altså et tall, og så et annet ord. Da logger dere inn som group84. At os84. Og så er det... Hvis dere får opp noe sånt som dette, så svar yes. Det er sånn typisk du får første gang du logger inn på en server. Og etterpå lagrer den da Mac-adressen som den serveren. Så hvis du senere logger inn på den samme adressen, og Mac-adressen er endret... Altså adressen til nettverkskortet på nivå 2, på lavnivå, eternettadressen... Hvis den har blitt endret, så kan det tyde på at det er en sånn man in the middle attack. Altså at noen prøver å gjøre lureri med IP-adressen og sende deg til et annet sted enn du skal, osv. Så derfor må man første gang svare bare yes på den, så kommer man inn. Du må taste passord, men jeg har lagt opp SSO-nøkler, sånn at jeg kommer inn på alle disse VM-ene, sånn at jeg kan hjelpe til.", "source": "lecture"}
{"lecture_id": "os6del7", "chunk_id": "os6del7_0003", "start": 227.48, "end": 261.0, "token_count": 119, "text": "og sende deg til et annet sted enn du skal, osv. Så derfor må man første gang svare bare yes på den, så kommer man inn. Du må taste passord, men jeg har lagt opp SSO-nøkler, sånn at jeg kommer inn på alle disse VM-ene, sånn at jeg kan hjelpe til. Men i hvert fall... Er du på gruppe 1, så logger du inn på denne måten. Groupe 1 at OEC. Med passordet fra Kanas.", "source": "lecture"}
{"lecture_id": "os6del6", "chunk_id": "os6del6_0000", "start": 0.0, "end": 124.96, "token_count": 294, "text": "Da skal vi se på en kode som ser ganske vanlig ut, men som har en veldig spesiell oppførsel. Og det er et C++-program. Vi kan ta det først. Vi ser det heter B.cpp. Og det er et C++-program. Det kopieres da ikke med GCC, men med B.cpp på den måten her. Og kjøres med.a.dot. Akkurat som for GCC. Så veldig forskjellig er det ikke. Men... Dette kunne også vært kjørt i C, men jeg gjør det i C pluss pluss. Eller å operere med Array der. Så et C-pluss-pluss-program ligner veldig på C. Den store forskjellen på C-pluss-pluss og C er at C-pluss-pluss er objektorientert, mens C ikke er objektorientert. Men det er ikke det som er fokus her. Fokus her er dette litt enkle... Men det er lagd for å illustrere dette med branch prediction. Og det er et ganske enkelt program. Vi har et stort RA som har 32 000 elementer. RA-sizen er her. Man deklarerer dette som et RA med 32 768 elementer. I første omgang er det bare en enkel forløkke", "source": "lecture"}
{"lecture_id": "os6del6", "chunk_id": "os6del6_0001", "start": 98.48, "end": 198.72, "token_count": 284, "text": "Og det er et ganske enkelt program. Vi har et stort RA som har 32 000 elementer. RA-sizen er her. Man deklarerer dette som et RA med 32 768 elementer. I første omgang er det bare en enkel forløkke som initialiserer alle disse 32 000 r-elementene. Variabelen c løper gjennom alle tall opp til 32 000. Og så er det kode her... Her står det RAND. Det er en funksjon som trekker ut... Et tilfeldig tall. Og så ser vi at det prosent, det er... Det er en heltallsdivisjon. Så... Og den prosent, den gir da resten, sånn at... Det eneste du trenger å vite, er at resultatet av denne her, det er et tilfeldig tall mellom 0 og 255. Det er da resten hvis du tar et tall og deler på 256. Enten går det opp, du får rest 0, eller så får du 1 i rest. Da blir tallet 1, eller så får du helt opp til 255 i rest. Hvis tallet er ett større, så går det opp igjen. Rad gir et tilfeldig svært heltall.", "source": "lecture"}
{"lecture_id": "os6del6", "chunk_id": "os6del6_0002", "start": 176.84, "end": 255.04, "token_count": 280, "text": "Det er da resten hvis du tar et tall og deler på 256. Enten går det opp, du får rest 0, eller så får du 1 i rest. Da blir tallet 1, eller så får du helt opp til 255 i rest. Hvis tallet er ett større, så går det opp igjen. Rad gir et tilfeldig svært heltall. Og dette gir da tilfeldige tall mellom 0 og 255. Så det er utgangspunktet. Vi har et sånt r-ei. Så går vi litt lenger ned. I programmet, så ser vi liksom hovedprogrammet, hva det utfører. Og det er her som det skjer rare ting. For det første så skriver vi bare ut de ti første verdiene for å se om R-øyet er sortert eller ikke. I utgangspunktet er det ikke sortert, men etterpå skal vi skru på sortering, og det er da rare ting skjer. Det det litt naive programmet gjør, er at det legger sammen alle tall større enn 127. Og det gjør vi inni den indre løkka her. Så ser vi at jeg har lagt på en ytre løkke.", "source": "lecture"}
{"lecture_id": "os6del6", "chunk_id": "os6del6_0003", "start": 232.14, "end": 316.1, "token_count": 297, "text": "men etterpå skal vi skru på sortering, og det er da rare ting skjer. Det det litt naive programmet gjør, er at det legger sammen alle tall større enn 127. Og det gjør vi inni den indre løkka her. Så ser vi at jeg har lagt på en ytre løkke. Ikke tenk så mye på den. Det er bare lagt til for at dette skal ta litt tid. CPU-er er utrolig kjappe, sånn at hvis vi bare hadde gjort én kjøring, så ville det å bare starte opp programmet tatt så mye tid. Se på forskjell i tiden det tar å kjøre. Det er den som er spesiell. Vi gjør dette 50 000 ganger, men hovedpoenget er hva vi gjør inni løkka her. Jo, der sier vi at hvis dette tilfeldige tallet mellom 0 og 255 er større enn 127, så skal det summeres. Så det betyr bare... Vi tar alle tall større enn 127 og legger seg an. Og så skrive ut summen. Foreløpig har det jo ikke noe merkelig skjedd med det. Vi kan ta det ut og kompliere det. Og så kan vi kjøre det.", "source": "lecture"}
{"lecture_id": "os6del6", "chunk_id": "os6del6_0004", "start": 290.62, "end": 382.44, "token_count": 280, "text": "så skal det summeres. Så det betyr bare... Vi tar alle tall større enn 127 og legger seg an. Og så skrive ut summen. Foreløpig har det jo ikke noe merkelig skjedd med det. Vi kan ta det ut og kompliere det. Og så kan vi kjøre det. Men vi må da ta tiden på det når vi kjører. Og så ser vi... Dette er starten av æreiet. Så jeg har skrevet ut de ti første elementene. Det er ikke sortert. Det kommer helt tilfeldig. Og vi ser at dette programmet tok noe 20 sekunder. RIL her, det er hvor lang totaltid det tok. User, det er hvor mye CPU som ble brukt i use mode. Det skal vi snakke om i neste uke. Men kort sagt er det vanlige kommandoer som... ... brukerprogrammet utfører. System er hvor mye tid som ble brukt av dette programmet i current mode. Typisk for et regneprogram som dette her bruker man veldig lite operativsystemkjernen. Stort sett er det bare programmet selv som står og kjører. Men så skal vi se på det som er litt mystisk...", "source": "lecture"}
{"lecture_id": "os6del6", "chunk_id": "os6del6_0005", "start": 362.84, "end": 453.92, "token_count": 292, "text": "System er hvor mye tid som ble brukt av dette programmet i current mode. Typisk for et regneprogram som dette her bruker man veldig lite operativsystemkjernen. Stort sett er det bare programmet selv som står og kjører. Men så skal vi se på det som er litt mystisk... Vi går nå inn i programmet igjen og så gjør jeg én liten endring, og det er at... Jeg sorterer... dataeie. Det er en sånn sort-metode som har den syntaksen der. Det eneste dere trenger å vite, er at dette funksjonsskallet sorterer ereie-data. Og da... Det er den eneste forskjellen jeg gjør. Ellers så skjer nøyaktig det samme her nede. Går gjennom like mange løkker. Det er ikke forskjell på summen, for summen bør bli den samme. Det er bare at her ligger tallene i rekkefølge i dataeriet. Så kompilerer jeg på nytt. Og så tar tiden på hvor lang tid det tar. Og nå ser vi at nå er de første elementene sortert, med null først. Alle elementene med null i kommer først. Og så kommer alle de andre elementene.", "source": "lecture"}
{"lecture_id": "os6del6", "chunk_id": "os6del6_0006", "start": 425.12, "end": 526.4, "token_count": 298, "text": "Det er bare at her ligger tallene i rekkefølge i dataeriet. Så kompilerer jeg på nytt. Og så tar tiden på hvor lang tid det tar. Og nå ser vi at nå er de første elementene sortert, med null først. Alle elementene med null i kommer først. Og så kommer alle de andre elementene. Men da ser vi... Her gikk plutselig programmet veldig mye fortere. Du brukte 17 sekunder her oppe og 11 sekunder her nede. Og det er... Det er det som er det store spørsmålet. Er det noen som kan se hva dette kan komme av? Hvorfor i all verden går plutselig programmet fortere? Man sorterte RE. For... Nå må vi begynne å se på hva i all verden som skjer her. Random RE er det samme i begge tilfeller. Så sorterer man RE. Og så hopper man hit. Her skriver du ut de ti første. I det andre tilfellet var det bare nuller. Men den indre løkken her, den går... Her skjer jo akkurat det samme. Den eneste forskjellen er at data-r-et er sortert. Og hva vil det si i praksis? Jo, det...", "source": "lecture"}
{"lecture_id": "os6del6", "chunk_id": "os6del6_0007", "start": 499.68, "end": 606.92, "token_count": 294, "text": "I det andre tilfellet var det bare nuller. Men den indre løkken her, den går... Her skjer jo akkurat det samme. Den eneste forskjellen er at data-r-et er sortert. Og hva vil det si i praksis? Jo, det... I praksis så vil... ... vil man først gå gjennom en masse elementer hvor data... Og etterpå går man gjennom en masse elementer, altså ca. 15 000, hvor dette slår til. Det kommer noen forslag... Mer effektiv pipelining? Ja, det... det k... Absolutt, det kan man si. At pipeliningen er mer effektiv. Men på hvilken måte? Går inn i if flere ganger, den som foreslår. Det gjør man ikke. Dette vil slå til akkurat like mange ganger. Så antallet institusjoner som utføres, er faktisk den samme. Kanskje den bare sjekker if-testen én gang? Nei, den vil måtte sjekke if-testen hver eneste gang. For selv om r-a-y er sortert, så vet ikke... Operativsystemet eller noen andre at det er sortert. Så det må sjekke hver gang.", "source": "lecture"}
{"lecture_id": "os6del6", "chunk_id": "os6del6_0008", "start": 584.64, "end": 694.26, "token_count": 289, "text": "Kanskje den bare sjekker if-testen én gang? Nei, den vil måtte sjekke if-testen hver eneste gang. For selv om r-a-y er sortert, så vet ikke... Operativsystemet eller noen andre at det er sortert. Så det må sjekke hver gang. Er ikke dette speculative execution? Jo, nettopp! Dette er speculative execution. For når programmet kjøres, så lærer... CPU-en lærer da hva som har skjedd. Føre statistikk over hva som skjer når man kommer til denne if-testen i maskinkoden. Når arrayet er sortert, så vil systemet lære at denne testen her, den slår ikke til. Så her satser vi på at den ikke slår til. Da bruker man speculative execution, så man begynner å utføre... Da går det mye fortere, for da hopper man over når det ikke er større enn 127. Og etterpå kommer det masse RAI-data som er større enn 127. Og da gjetter systemet, eller CPU-en, på at nå skal vi legge sammen. Og da utføres den addisjonen hver gang. Den gjetter riktig hver gang, og det er ganske mange ganger.", "source": "lecture"}
{"lecture_id": "os6del6", "chunk_id": "os6del6_0009", "start": 670.4, "end": 749.98, "token_count": 297, "text": "Og etterpå kommer det masse RAI-data som er større enn 127. Og da gjetter systemet, eller CPU-en, på at nå skal vi legge sammen. Og da utføres den addisjonen hver gang. Den gjetter riktig hver gang, og det er ganske mange ganger. Det er 32 000 elementer, så hver eneste gang den kommer til gift-testen, så gjetter den riktig. Eller det vil si, de 15 000 første gangene, så blir det en bom, kanskje noen bommer, helt til den skjønner... OK, her, herfra og ut, så gjetter den riktig. Og dermed går det mye fortere. Derimot, når R1 er hulter til bulter, så vil det omtrent ca. annenhver gang... Og da er det typisk at branch prediction bare bommer hele tiden. Så... Ja, så det er riktig som oppsummert er. Branch prediction gjetter da veldig ofte korrekt. Og systemet går mye raskere. Det er et spørsmål om hvorfor det går så fort å sortere r-øyet. Ja, det kommer jo egentlig i tillegg. Det er et godt spørsmål.", "source": "lecture"}
{"lecture_id": "os6del6", "chunk_id": "os6del6_0010", "start": 730.42, "end": 798.3, "token_count": 220, "text": "Branch prediction gjetter da veldig ofte korrekt. Og systemet går mye raskere. Det er et spørsmål om hvorfor det går så fort å sortere r-øyet. Ja, det kommer jo egentlig i tillegg. Det er et godt spørsmål. Men denne operasjonen her med å sortere... Hvor hadde jeg den? Her, ja. Sort data. Denne operasjonen er veldig rask. Og i tillegg ser vi at den utføres før løkkene. Så jeg sorterer ikke 50 000 ganger. Hvis jeg hadde lagt inn sorteringen der, hadde det ikke vært så stor... Men i forhold til å kjøre den løkka 50 000 ganger, hvor man går gjennom 32 000 RAI-biter, så er denne operasjonen veldig rask. Men det tar litt tid, men det har ikke noe særlig effekt for totaltiden.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0000", "start": 0.0, "end": 140.56, "token_count": 293, "text": "Sånn. Der er vi i gang med recording. Ja... Dette er noe vi kommer tilbake til i neste uke i mer detalj. Men det kan være greit å ha det helt klart for seg. Og det kan være litt forvillende noen ganger også. Mange ganger 8K. Sånn som det der. Og strengt tatt definisjonen på K, altså i si-enheter... Skal vi se... Si-enheter er de som definerer kilo og alt mulig sånt. Så er egentlig K lik 1000, sånn som her. M er da ti i sjette, G er milliard, eller ti i niende. Men når vi snakker om Bite, så er det naturlig å snakke om det... I PowerA2. Og det... Det vi ofte gjør da, er at vi sier K er lik... Er lik 2 oppe i tiende? Så to i tiende bite. Men det er jo lik 1024.  Og pga. den lille forskjellen der, så er det noen som har prøvd å innføre, det har ikke helt lykkes, men at ki er lik to i tiende. Da vil du se at det står kib for kilobite.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0001", "start": 116.28, "end": 247.84, "token_count": 297, "text": " Og pga. den lille forskjellen der, så er det noen som har prøvd å innføre, det har ikke helt lykkes, men at ki er lik to i tiende. Da vil du se at det står kib for kilobite. Er da eksakt lik 1024 byte. Så der kan det være en sånn liten forskjell. Men når jeg snakker om 8K, så når det gjelder ram, så betyr det 1024... Så tenker jeg på 1024 når jeg sier K. Men strengt tatt burde jeg sagt key. Og tilsvarende så har du da MIB. Som da er lik 1024 ganger 1024 bites. Eller ikke to i tiende, men to i tyvende. Men det 32 er tilnærmet lik 10 niende. Men... Eller en milliardbite. Eller det vi kaller for en gigabyte. Men når du begynner å komme her, så har den faktoren 1024 litt å si. Så da kan det begynne å bli litt forskjeller, spesielt når du kommer opp i terabyte. Men vi kan se på det senere. Men uansett så er akkurat det viktig å ha med seg. Ok. Da skal vi...", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0002", "start": 223.6, "end": 324.26, "token_count": 282, "text": "Men når du begynner å komme her, så har den faktoren 1024 litt å si. Så da kan det begynne å bli litt forskjeller, spesielt når du kommer opp i terabyte. Men vi kan se på det senere. Men uansett så er akkurat det viktig å ha med seg. Ok. Da skal vi... ... se på nok et konkret eksempel på interne mine. Og vi skal se på noe som virker ganske rart i utgangspunktet. Vi starter ut med et lite og enkelt program. Det eneste som ikke er så enkelt, er at det er veldig mange nuller her. Skulle kanskje brukt den definerte med ganger osv., sånn som vi gjorde i det andre programmet. Men hvis jeg holder på de nullene her, så ser vi at her er det... Så det er 1024 millioner. Så dette er da én milliard... eller én giga. Så det jeg prøver å definere her nå, er et... Eller det jeg definerer her, er et RAI som da bruker fire gigabyte ramme. Et svært RAI. Og så ser vi om jeg har en enkel...", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0003", "start": 295.32, "end": 376.32, "token_count": 277, "text": "Så det er 1024 millioner. Så dette er da én milliard... eller én giga. Så det jeg prøver å definere her nå, er et... Eller det jeg definerer her, er et RAI som da bruker fire gigabyte ramme. Et svært RAI. Og så ser vi om jeg har en enkel... En liten fåløkke. Den er enkel, og den går ikke helt opp, men den går til 10 millioner. Så vi ser at jeg bruker da en hundredel av det store R-øyet. Eller går opp til en hundredel. Dette ser litt rart ut foreløpig, men bare tenk på det som en institusjon som vi ikke bruker. Vi setter J lik I gang i 100. Så den J-en går helt. Men i første omgang, det jeg gjør, er at jeg setter nå hvert ri lik i. Så jeg begynner med ri av 0 og setter den ned lik 0. ri av 1 lik 1, ri av 2 lik 2, osv. oppover. Så det er jo... ja. Dette er bare en demo på hva som skjer når man bruker ramm.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0004", "start": 355.32, "end": 450.52, "token_count": 294, "text": "Men i første omgang, det jeg gjør, er at jeg setter nå hvert ri lik i. Så jeg begynner med ri av 0 og setter den ned lik 0. ri av 1 lik 1, ri av 2 lik 2, osv. oppover. Så det er jo... ja. Dette er bare en demo på hva som skjer når man bruker ramm. Og da, hvis vi gjorde sånn som vi gjorde før pause, at vi så på topp som vi gjorde før pause... Så ville vi sett at etter hvert som man brukte det jeg er i, så ville det komme inn i RES osv. Men nå skal jeg bare kompilere programmet. Det heter MDC. Og så ta tiden på å kjøre. Skriver man til 1 million RAI-elementer, altså 10 millioner, så går det på 0,02 sekunder. Selv om man sier at RAM er tregt, så går det jo veldig fort. Mye raskere enn til disk. Det er bare det at registeret er enda raskere, så der er det ekstremt raskt. Men i hvert fall - dette går fort. Men så skal jeg gjøre det som er litt spesielt. Endre i til j her.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0005", "start": 430.08, "end": 518.52, "token_count": 284, "text": "Mye raskere enn til disk. Det er bare det at registeret er enda raskere, så der er det ekstremt raskt. Men i hvert fall - dette går fort. Men så skal jeg gjøre det som er litt spesielt. Endre i til j her. Det er den eneste endringen jeg gjør. Jeg bytter nå i ut med j. Det vil si at jeg gjør jo akkurat like mange instruksjoner. For det er ti millioner ganger som jeg løper gjennom her. Så den eneste forskjellen er at det første jeg gjør, er jeg av null lik null. Så er jeg av... Når i er lik 1, så vil j bli 100. Så neste institusjon er ra 100 lik 1. Og så ra 200 lik 2 osv. Men jeg gjør dette da 10 millioner ganger. Så i utgangspunktet... I hvert fall hvis ram var ram, så burde dette ta akkurat like lang tid. Men vi ser dette tar enormt mye lengre tid. Det tar 1,5 sekunder i stedet for 0,19. Altså... Dette er faktisk nesten en faktor 100.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0006", "start": 486.94, "end": 594.2, "token_count": 300, "text": "Men jeg gjør dette da 10 millioner ganger. Så i utgangspunktet... I hvert fall hvis ram var ram, så burde dette ta akkurat like lang tid. Men vi ser dette tar enormt mye lengre tid. Det tar 1,5 sekunder i stedet for 0,19. Altså... Dette er faktisk nesten en faktor 100. Så hvordan kan det ha seg? Er det noen som har noen idé om hva det kan skyldes? Veldig stor forskjell i effektivitet. Vi gjør det samme antall institusjoner. Ti millioner ganger så skriver vi noe til et RI-ram. Fyller opp programmet med tall. Ti millioner ganger. Helt det samme hver gang. Vel... Vi har snakket med om cash, og dette er absolutt noe som har med cash å gjøre. Ja, det er forslaget at det er på grunn av r-øyet. Ja, det er på grunn av r-øyet, og vi må prøve å tenke oss... Hva er det som... Hva er det egentlig som skjer her? Dette er et viktig poeng, så jeg tenker vi kan bruke litt tid på det. Kanskje jeg skal prøve å tegne...", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0007", "start": 571.0, "end": 743.52, "token_count": 288, "text": "Ja, det er på grunn av r-øyet, og vi må prøve å tenke oss... Hva er det som... Hva er det egentlig som skjer her? Dette er et viktig poeng, så jeg tenker vi kan bruke litt tid på det. Kanskje jeg skal prøve å tegne... Jo, vi har et ærei. Og det... Dette ville da være logiske eller virtuelle adresser. Men de ville mappes over, avbildes på fysisk R-øye, ram, og da ligger de etter hverandre. Og det vi gjorde i det første programmet, det var å legge inn sånn... 0, 1, 2, 3, 4, 5 osv. Og da ser vi... Kanskje vi kom ned til 100 her nå? Eller vi kom egentlig mye lenger. Vi kom ned til faktisk 10 millioner. Vi kan ta med masse nuller der. Ti millioner... Kjempestort ære. Men likevel så må vi huske på at dette var bare én av de hundre sånne som vi hadde bortover. Hvis vi tenker oss at RAM bare fortsetter sånn, ned dit, O, ned dit, osv....", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0008", "start": 715.32, "end": 834.92, "token_count": 296, "text": "Ti millioner... Kjempestort ære. Men likevel så må vi huske på at dette var bare én av de hundre sånne som vi hadde bortover. Hvis vi tenker oss at RAM bare fortsetter sånn, ned dit, O, ned dit, osv.... Her oppe hadde vi 10 millioner og 1... Og her så hadde vi plassnummer 20 millioner. Den lå her nede. Og så hadde vi 100 sånne bortover. For vi har 100 ganger så mye som 10 millioner. Det vi gjorde i det første programmet, det var bare å fylle opp. Det var... prog 1. Men så... Hva gjorde vi i prog 2? Jo, da så vi at vi fikk en faktor 100. Så hvis jeg prøver å skrive prog 2 med rødt der... Så i prog 2 så la vi fortsatt J lik 1. Så la vi... Fortsatt la vi 0 inn her. Men så begynte vi å legge inn her, i 100. Så la vi 1. Og så lenger ned her. 200. Så la vi 2. Og så fortsetter vi sånn nedover. Men da begynte vi å legge inn her også.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0009", "start": 805.32, "end": 934.44, "token_count": 292, "text": "Fortsatt la vi 0 inn her. Men så begynte vi å legge inn her, i 100. Så la vi 1. Og så lenger ned her. 200. Så la vi 2. Og så fortsetter vi sånn nedover. Men da begynte vi å legge inn her også. Når vi kommer opp i over 10... over 10 millioner... Kanskje vi fikk da... Ja, her nede så la vi inn... I 20 millioner så la vi vel inn noe sånt som 200 millioner. Men håppoenget er at vi da legger over alt i ramm. Nå fyller vi ut hele det herreiet. Og så legger vi i den andre kjøringen. Altså når jeg hadde prog 2 var array av J lik I. Det var prog 2. Prog 1 var... Var... Jodligi. Da bare la vi nedover her. Jodligi, da økes... Det er da produkt O. Da økes jod med 100 for hver gang. Sånn at vi legger data utover i hele jordeiet, og totalt sett så var... Hele dette var på 4G. Så svært ærlig. Men da kommer vi til løsningen på dette.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0010", "start": 907.56, "end": 1009.56, "token_count": 277, "text": "Det er da produkt O. Da økes jod med 100 for hver gang. Sånn at vi legger data utover i hele jordeiet, og totalt sett så var... Hele dette var på 4G. Så svært ærlig. Men da kommer vi til løsningen på dette. Ja, det er noen som kommer med et forslag her. Du må ut til Ramm og hente en ny del av RAM hver gang. Ja, det er riktig. Eller riktignok nå skriver vi til Ramm. Og skrive ut til Ramm. Men... Ja, og da, når du legger inn tall på alle plassene, kan du legge inn flere tall før den må ut igjen. Jo, men problemet... Da er jeg ikke helt sikker på om jeg forstår deg riktig. Men en skulle på en måte tro at... Det var... For å si det på en annen måte... Hvis dette var ramm i ordets rette betydning, random access memory, så skal det gå like raskt å skrive noe hit som å skrive noe dit. Eller hvor som helst i ramm. Så du er inne på noe der når du sier hvis du går...", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0011", "start": 986.02, "end": 1090.4, "token_count": 294, "text": "For å si det på en annen måte... Hvis dette var ramm i ordets rette betydning, random access memory, så skal det gå like raskt å skrive noe hit som å skrive noe dit. Eller hvor som helst i ramm. Så du er inne på noe der når du sier hvis du går... På alle plassene. På én gang. Må systemet kanskje flushe cashen? Ja, men det er akkurat dette som er... Akkurat det er poenget. Cashen må flushes. Altså... Når du legger alle etter hverandre på denne måten her... Så det systemet vil gjøre da, det vil ta... Den vil ikke skrive én og én bite ut. Den vil ikke legge hver bite... Den vil ta hele... Litt avhengig av hvor stor LN Cash er. Kanskje det er plass til 200 bite i LN Cash. Så tar den hele den biten der og legger ut i LN Cash. Den kan ta hele biten etter hverandre, for den biten skal ligge på samme sted i RAM. Og da kan man ta hele biter og skrive ut. Eller hvis man leser, så leser man ikke én bite, men man leser fra RAM.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0012", "start": 1070.56, "end": 1153.64, "token_count": 291, "text": "Den kan ta hele biten etter hverandre, for den biten skal ligge på samme sted i RAM. Og da kan man ta hele biter og skrive ut. Eller hvis man leser, så leser man ikke én bite, men man leser fra RAM. Først fyller man opp hele EltreCash, så El2Cash og så L1Cash. Men hovedpoenget er at når de ligger etter hverandre, så kan de i sin helhet legges ut i L1Cash. Så kan du ta mange hundre bite av gangen. Og som vi ser, så går det 100 ganger så fort. Derimot, når vi prøver å kjøre program 2, så ser vi... Disse er spredt med 100 bite imellom. Så kanskje det er bare noen få bite som da treffer med hver gang L1 cash kjøres. Og noen flere treffer med L2, enda flere med L3, men du får ikke plass til alt. Så dette vil ta veldig mye lengre tid. Og vi ser det tar nesten 100 ganger så lang tid med Prog2. Og vi kan... Vi kan se litt mer i detalj på det. For vi har da et program som heter Perf.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0013", "start": 1124.12, "end": 1219.24, "token_count": 289, "text": "Og noen flere treffer med L2, enda flere med L3, men du får ikke plass til alt. Så dette vil ta veldig mye lengre tid. Og vi ser det tar nesten 100 ganger så lang tid med Prog2. Og vi kan... Vi kan se litt mer i detalj på det. For vi har da et program som heter Perf. Som jeg kan bruke til å se nøyaktig hva som skjer når jeg kjører programmet. Den enkleste versjonen først. Sette i den som går raskest. Her ligger det pent etter hverandre, så dette kan pusses i store biter ut i cash. Da går det kjapt. Det er den der. 0,02 sekunder. Men så kan jeg kjøre en... Altså, jeg har kjørt den før. Det er en kommando som heter perf, og den gir statistikk med antall... Her er jeg bedt eksplisitt om å skrive ut antall sykler, antall instruksjoner, antall cash references. Det er hvor mange ganger du har en cash-referanse. Hvor mange ganger du henter ut noe for cash. Ikke minst cash misses. Major faults og minor faults. Major faults, det er når man må...", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0014", "start": 1197.04, "end": 1287.14, "token_count": 299, "text": "Her er jeg bedt eksplisitt om å skrive ut antall sykler, antall instruksjoner, antall cash references. Det er hvor mange ganger du har en cash-referanse. Hvor mange ganger du henter ut noe for cash. Ikke minst cash misses. Major faults og minor faults. Major faults, det er når man må... Ut på disken og hente. Og det skjer ikke her. Det er når du får en virkelig page fault. Minor faults, det er når man må... Når man ikke har lagd en side i MMU. Og det skal vi se, det må vi gjøre ganske ofte. Jeg kjører den først. Og da får vi statistikken for dette programmet. Igjen ser vi det går lynrask. 0,02 sekunder. Likevel ser vi... Den utfører 63 millioner sykler. Og gjør 71 millioner instruksjoner. Men omtrent da en instruksjon per sekund. Så ser vi... Cash misses. Ja, den bommer ganske ofte på cash. Og det er fordi at den nå tar ut bit for bit. Men ganske ofte så må den hoppe videre til... Til neste del av cashen. Den må fylle ut cash på nytt.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0015", "start": 1259.06, "end": 1352.32, "token_count": 283, "text": "Men omtrent da en instruksjon per sekund. Så ser vi... Cash misses. Ja, den bommer ganske ofte på cash. Og det er fordi at den nå tar ut bit for bit. Men ganske ofte så må den hoppe videre til... Til neste del av cashen. Den må fylle ut cash på nytt. Men fordelen når de ligger etter hverandre, er at den fyller hele cashen av gangen med elementene som ligger etter hverandre. Men vi ser her minor falts. 10 000 minor falts. Og det passer ganske bra med... Hvis det er 10K. På 1000 bytes. Vanligvis er den på 4K, så det går ikke helt opp. Men dette er omtrent 10 000 K. Og vi ser at vi får 10 000 minor folts. Og det er fordi at man... En minor folts er når man ikke har referert til denne delen av minnet. Og da lages det en adressering i MMU. Det gjøres 10 000 ganger. Så det tar også litt tid. Men alt i alt så går dette lynraskt. Så prøver vi å sette J1.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0016", "start": 1327.64, "end": 1416.12, "token_count": 288, "text": "Og det er fordi at man... En minor folts er når man ikke har referert til denne delen av minnet. Og da lages det en adressering i MMU. Det gjøres 10 000 ganger. Så det tar også litt tid. Men alt i alt så går dette lynraskt. Så prøver vi å sette J1. Nei, vi setter inn ra av J. Og da hopper vi rundt i 4 GB. Og dette tar da mye lengre tid. Komplerer... Og kjører det samme. Og nå ser vi... Nå får vi først og fremst så får vi... Vi burde egentlig kunne sammenligne... Sånn, ja. Nå ser vi det tar 1,6 sekunder. Mye lengre tid. Og det er opplagt mange flere cycles. Og vi ser vi har veldig mange flere cash references og nesten alle bommer. Jeg har på en måte konstruert dette sånn at... Sånn at det skal bomme. Vi hopper med 100 hver gang. Det er veldig uvanlig at man gjør det på denne måten her. Men dette er bare for å illustrere hvordan cash virker, at det er viktig å være klar over det.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0017", "start": 1396.6, "end": 1498.4, "token_count": 283, "text": "Jeg har på en måte konstruert dette sånn at... Sånn at det skal bomme. Vi hopper med 100 hver gang. Det er veldig uvanlig at man gjør det på denne måten her. Men dette er bare for å illustrere hvordan cash virker, at det er viktig å være klar over det. Så vi får 75 millioner cash misses i stedet for 800 000 her oppe. Det er først og fremst det som gjør at det tar mye lengre tid. Det tar også tid å bygge opp MMU. For her ser vi... Her trengs det 1 million sider. For vi... Det r-øyet er på 4 g. 4 gigabyte. Og med en sidestørrelse på 4K... Så så trenger man 1 million sider. Ja, så det går pent opp. Jeg glemte det... At en integer er på fire. Så dette, det tilsvarer da fire ganger ti millioner bite. Så i det første tilfellet så trengte vi bare 10 000 sider i MMU. Men her trenger vi én million sider for å kunne adressere... Og dette tar også mye tid å bygge opp NMU.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0018", "start": 1465.88, "end": 1577.0, "token_count": 293, "text": "Så dette, det tilsvarer da fire ganger ti millioner bite. Så i det første tilfellet så trengte vi bare 10 000 sider i MMU. Men her trenger vi én million sider for å kunne adressere... Og dette tar også mye tid å bygge opp NMU. Og da ser vi at det er oppe i 1,6 sekunder. Det kan vi også se på... ... Så kan vi se på hva tiden går bort til. Vi ser user. Det er 0,4. Men veldig mye brukes av system. Og det er da for å bygge opp MMU-sidene. Så det er også en faktor her. Så det er ikke bare cash, men det er også det at du må bygge opp MMU. Hvis vi nå kjører... Jeg ser på det samme med Adatat. Så ser vi... Jo, det er en andel system her også. Som er ganske stor. Den er faktisk litt større. For her også må de sidene bygges opp. Men altså, i begge tilfeller så ser vi at kjernen er inne og hjelper til med å bygge opp, da i dette tilfellet, 1 million pages. Og det tar litt tid.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0019", "start": 1550.56, "end": 1676.04, "token_count": 288, "text": "Som er ganske stor. Den er faktisk litt større. For her også må de sidene bygges opp. Men altså, i begge tilfeller så ser vi at kjernen er inne og hjelper til med å bygge opp, da i dette tilfellet, 1 million pages. Og det tar litt tid. Cash misses i Prog1? Jo, det skyldes at... Tross alt, selv om man går etter hverandre, så går man veldig langt. Her så ser vi det er 10 millioner... 10 millioner bite, eller da 10 000 kilobite. Og hvis du regner med Int, så er det da 40 000 kB. Og det krever jo da... Det krever at man lager de 10 000 sidene her oppe. Men spørsmålet var kanskje hvorfor det var så mange catchmines som 801? Jo... Cash er da mindre enn 4K, så selv om du... Selv om du treffer veldig ofte, så er det jo med en gang du kommer utenfor i første omgang LN-cash-størrelsen. Så vil du måtte hoppe over på... En cash måtte reflushes. Og den vil da reflushes 800 000 ganger", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0020", "start": 1652.1, "end": 1774.56, "token_count": 298, "text": "Selv om du treffer veldig ofte, så er det jo med en gang du kommer utenfor i første omgang LN-cash-størrelsen. Så vil du måtte hoppe over på... En cash måtte reflushes. Og den vil da reflushes 800 000 ganger når det går oppover. Først med opptil 100, men du ser du skal helt opp til 10 millioner. Så derfor vil du ha flere cash misses enn der det er pages. Ok. Vi skal se på ett eksempel til før vi gir oss i dag. Vi skal bare se på internen min i dag, og så ser vi på disk neste gang. Skal vi se... Da skal vi se på... Nei, da må jeg finne fram her. Matt skal vi se på. Vi skal nå se på... ... dette programmet, som skriver til et RAI. Og noe av det som er viktig å vite her nå, er hvordan et RAI eller... Et todimensjonalt RAI, eller en matrise, hvordan den lagres i ramm. Ofte bruker man matriser sånn som dette her, RABA, med to indekser. For å lagre data. I maskinlæring og AI, f.eks., har man ofte sånne store matriser som dette her.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0021", "start": 1748.2, "end": 1855.0, "token_count": 297, "text": "Et todimensjonalt RAI, eller en matrise, hvordan den lagres i ramm. Ofte bruker man matriser sånn som dette her, RABA, med to indekser. For å lagre data. I maskinlæring og AI, f.eks., har man ofte sånne store matriser som dette her. Da er det viktig å vite hvordan et RA er organisert. For det er på en måte et valg når du har to indekser. Hvordan skal de ligge etter hverandre i ramm? Og da har jeg skrevet opp fasit. For C her nede... Det kan i prinsippet være organisert av forskjellige kompulatorer for forskjellige språk. Men for C så er det sånn at ra00 ligger rett før ra01 og r02. Så... Ja, dette er litt viktig for hele problemstillingen. Så jeg tenker vi skal... Vi kan prøve å tegne opp det også. Så hvis jeg kaller bare reiet A... Jeg har A, A, A... B. Sånn som det der. Og så har vi ram nedover her. Og da er det et velgør. De viktige poengene når vi skal kjøre dette, er at A av 00...", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0022", "start": 1820.56, "end": 1944.44, "token_count": 284, "text": "Så hvis jeg kaller bare reiet A... Jeg har A, A, A... B. Sånn som det der. Og så har vi ram nedover her. Og da er det et velgør. De viktige poengene når vi skal kjøre dette, er at A av 00... Det er første element. Det ligger her. Og så kommer A av 01. Og så kommer A av 02. Og så videre nedover. Helt til vi kommer til å ha fylt opp første delen av r-øyet. Så kommer vi til AA1. Så kommer A av 1, 1 og så videre. Og så fortsetter den nedover i ramma. Og så kommer A av 2. Og så videre i det uendelige. Og her ser vi med en gang at her kan det bli noe trøbbel, eller noen forskjeller med hensyn på cash. For det er klart... Hvis vi skriver ut på denne måten av null først, og løper gjennom 1-2-3, 0-1-2, sånn, så vil det treffe bra med cash. For da vil hele den biten sendes ut i cash. Det er det vi nå skal se på.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0023", "start": 1924.08, "end": 2016.76, "token_count": 294, "text": "For det er klart... Hvis vi skriver ut på denne måten av null først, og løper gjennom 1-2-3, 0-1-2, sånn, så vil det treffe bra med cash. For da vil hele den biten sendes ut i cash. Det er det vi nå skal se på. Og da ser vi... Skal vi se hvordan jeg gjør det her... I det eksempelet her... Så ser vi at... Ja, jeg har B, A... Kanskje jeg kan prøve å gjøre det sånn? Sette A først. For da... La oss si jeg skal prøve å få det til å gå så fort som mulig nå. A lik 0. Da er det den ytre forløkken der. Og da starter jeg på A av 0, og da vil jeg få A av 0, A av 0, A av 01 osv. Så denne måten burde være den raskeste. Men da prøver vi. Kompilerer og kjører. Ja... Jeg kan se om det er noen forskjell å komplere med stor O. På mer effektivt gode. Jo, det går fortere. Ikke tenk på at jeg bruker stor O når jeg skal komplere etterpå", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0024", "start": 1996.08, "end": 2094.4, "token_count": 292, "text": "Kompilerer og kjører. Ja... Jeg kan se om det er noen forskjell å komplere med stor O. På mer effektivt gode. Jo, det går fortere. Ikke tenk på at jeg bruker stor O når jeg skal komplere etterpå med den andre måten. Så bruker jeg fortsatt stor O. Og vi ser... Det går på 0,75 sekunder. Men så kan jeg prøve. Og det er opplagt... Det er det samme jeg gjør hver gang. Jeg bare løper gjennom på litt forskjellige måter. Totalt sett så vil programmet gjøre akkurat det samme. Men da ser vi... Dette programmet, som gjør nok til det samme, det går... Ca. 8... Det bruker 8 ganger så lang tid. Og det er akkurat den effekten som vi da forutsa. Her i det første programmet så tok vi og skrev til Errøya på denne måten. Vi skrev ut hvert element som da ligger etter hverandre pent og pyntelig i ramm. Og det kan kjøres i hele bolker i cash og sendes av gårde. På klasseforsøk så gjorde vi da noen enorme hopp", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0025", "start": 2071.04, "end": 2179.56, "token_count": 294, "text": "Her i det første programmet så tok vi og skrev til Errøya på denne måten. Vi skrev ut hvert element som da ligger etter hverandre pent og pyntelig i ramm. Og det kan kjøres i hele bolker i cash og sendes av gårde. På klasseforsøk så gjorde vi da noen enorme hopp fordi at vi måtte hoppe fra... Først skrev vi A00, og så skrev vi AA10. Og da måtte vi gjøre et svært hopp i ram herfra og hit, som var på 20 000. Og dermed ble det totalt cash miss. Og det kan vi da også se hvis du kjører perf på dette her. Heter det fortsatt Out og Out, så vi kjører perf på det andre forsøket. Og her ser vi... masse minor folts. Minner bare bygges opp. Det er kanskje ikke så forskjellig, men det er vel først og fremst cash misses som blir forskjellen her. Endre til det vi trodde var det beste. AB. Komplør på nytt. Og kjøre perf. Ja, da ser vi. Minor folds ble det samme. For i dette tilfellet bruker vi jo akkurat like stor del av ramm.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0026", "start": 2146.46, "end": 2247.24, "token_count": 290, "text": "som blir forskjellen her. Endre til det vi trodde var det beste. AB. Komplør på nytt. Og kjøre perf. Ja, da ser vi. Minor folds ble det samme. For i dette tilfellet bruker vi jo akkurat like stor del av ramm. Det blir det samme. Så det gir ikke noe stor tidsforskjell. Men her ser vi på cash misses. Her er det en stor forskjell. Her er det 29 millioner cash misses, så det er en god del. Men her oppe så ser vi... Dette tar tid, for det er 700 millioner cash misses. Cash-referanser... Altså der hvor du i det hele tatt refererer til cash. Og igjen så ser vi at det er en... Her er det først og fremst en enorm forskjell i cash-bruken. Vi gjør akkurat det samme, men vi henter det fra et annet sted. Vi kunne også lurt på... Har det noe med at man bare legger ut fem? Det vi kunne gjøre, var for å gjøre det veldig eksplisitt, så kunne vi prøve å legge ut. Hva om vi legger ut A pluss B? Blir det noe særlig forskjell da?", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0027", "start": 2228.38, "end": 2320.32, "token_count": 281, "text": "Vi kunne også lurt på... Har det noe med at man bare legger ut fem? Det vi kunne gjøre, var for å gjøre det veldig eksplisitt, så kunne vi prøve å legge ut. Hva om vi legger ut A pluss B? Blir det noe særlig forskjell da? Og blir det noen annen forskjell på programmene? Vi ser... Ja, det tok litt lengre tid. Men vi ser i Cashmisses, så... Så er det ikke noe forskjell. For det er... Du gjør det samme. Kanskje hun gjorde et smart triks med at det ligger et tall 5 i hele cash, sånn at man bare hiver det ut. Men vi ser, selv når vi legger forskjellige tall, så er forskjellene samme. Og vi får den samme forskjellen... Med at det tar mye lengre tid... Og vi får omtrent det samme antall cash misses uansett. Så det at vi la ut det femtallet, hadde ingen betydning. Den store forskjellen var at i det ene tilfellet så måtte vi hoppe langt i ramm. Og det passer dårlig med cash.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0028", "start": 2300.56, "end": 2414.16, "token_count": 299, "text": "Og vi får omtrent det samme antall cash misses uansett. Så det at vi la ut det femtallet, hadde ingen betydning. Den store forskjellen var at i det ene tilfellet så måtte vi hoppe langt i ramm. Og det passer dårlig med cash. I det andre tilfellet så lå alle dataene pent etter hverandre når vi skrev det ut. Jeg skal prøve å oppsummere RAM med noen minnebegreper som er viktige. Den første er soft miss. Og det er en miss når pagereferansen ikke er i TLB. Og så har vi en hard miss, eller det som er mer vanlig å kalle en major fault eller en page fault. Da er det en side som mangler i ram, altså i minnet, og også da selvfølgelig i TLB. TLB er cash for minnereferanser, og den må hentes helt ut på disk. Og så en major fault. En minor fault, det er når det mangler en side i pagetabellen. Da må du ikke ut på disk og hente den, men den må lages. Vi så det ta litt tid. I det ene tilfellet så vi at vi skulle lage en million sider. Så da var det en én million minor faults.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0029", "start": 2393.2, "end": 2476.14, "token_count": 298, "text": "En minor fault, det er når det mangler en side i pagetabellen. Da må du ikke ut på disk og hente den, men den må lages. Vi så det ta litt tid. I det ene tilfellet så vi at vi skulle lage en million sider. Så da var det en én million minor faults. Og selv om det går raskt, alt skjer bare i ram og MMU, så... Så tar det litt tid. En dirty page, det er en side som har blitt endret, slik at... Hvis du da skal skrive ut den til disk, så må den ut av... Hvis den skal ut av minnet og ut på disk, så må den faktisk skrives ut. Hvis en side ikke er dirty, altså hvis den er akkurat som før, så kan man bare droppe den i rammen, for da ligger den allerede på såpeområdet på disken. Working set er et Windows-begrep som betyr så å si akkurat det samme som Ress, eller Resident, i Linux. Det er da de sidene som er i bruk, og som har vært i bruk nylig, og som ligger aktive der. Et segment vi har brukt noen ganger tidligere, det er da en hel logisk del av et programsminne.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0030", "start": 2457.32, "end": 2558.24, "token_count": 295, "text": "eller Resident, i Linux. Det er da de sidene som er i bruk, og som har vært i bruk nylig, og som ligger aktive der. Et segment vi har brukt noen ganger tidligere, det er da en hel logisk del av et programsminne. Sånn som hele programteksten eller hele tag-segmentet. Eller heap, og altså et stort segment. Til slutt buffer cash. Det høres ut som det har noe med L1 og L2 cash osv., men det er da, som vi så, et filsystem-cash. Så det er noen av de viktige minnebegrepene som dere må huske. Ok... Jeg ser... Da skal vi slutte. Men før vi slutter, skal jeg oppsummere noen spørsmål. Ja, det var et godt poeng. Det var en som la merke til at det var mange context switcher. Så spørsmålet om den var nedprioritert på noen måte... Ja, det er et godt spørsmål. For det første så kjører den seks ganger lenger. Det er ikke så rart at det blir flere kontekst-witcher, men det er jo litt påfallende at det blir så mange. Det er ikke noen god forklaring på det annet enn at", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0031", "start": 2524.16, "end": 2641.76, "token_count": 296, "text": "Så spørsmålet om den var nedprioritert på noen måte... Ja, det er et godt spørsmål. For det første så kjører den seks ganger lenger. Det er ikke så rart at det blir flere kontekst-witcher, men det er jo litt påfallende at det blir så mange. Det er ikke noen god forklaring på det annet enn at kontekst-witcher vil skje når det er andre prosesser som kjører på samme CPU. Så det vil alltid være litt tilfeldig. Men kanskje det kan være at den siden den prosessen her... ... venter så mye, siden det er så mange cash misses, at den oftere blir tatt ut av ready-list og oftere må bytte. Men vi kan jo se... Prøv å kjøre den noen flere ganger. Ja, så ser vi... Det var den samme adotat, og denne gang ble det Så det er nok... Den laptopen kjøres ganske hardt med OBS og med Zoom. Så det virket veldig som... Å, vi ser ikke koden! Sorry. Det er en lang dag. Begynne på nytt. Da får dere holde ut litt til. Der... Da hopper vi tilbake. Det var et godt poeng her om...", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0032", "start": 2610.44, "end": 2707.58, "token_count": 294, "text": "Så det virket veldig som... Å, vi ser ikke koden! Sorry. Det er en lang dag. Begynne på nytt. Da får dere holde ut litt til. Der... Da hopper vi tilbake. Det var et godt poeng her om... Først så kjørte jeg den raske versjonen, 0,9 sekunder, som tok matrissen på riktig måte. Da fikk jeg bare én kontekst-witch. Og så er det spørsmål... Hvorfor fikk jeg 204 kontekst-witcher her? Og det første man kan si, er at programmet kjører seks ganger så lenge. Så da burde det naturlig være flere kontekst-witcher. Kontekst-witcher skjer når man... Når flere prosesser kjører på samme CPU, og her konkurrerer de bl.a. med OBS og med Zoom, og de kjører en masse prosesser. En gang iblant. Men så prøvde jeg å kjøre programmet om igjen. Og da fikk jeg åtte kontekst-witcher og seks kontekst-witcher. Så vi ser at det... Det var nok litt tilfeldig at det ble så veldig mange akkurat der.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0033", "start": 2685.84, "end": 2790.16, "token_count": 298, "text": "og med Zoom, og de kjører en masse prosesser. En gang iblant. Men så prøvde jeg å kjøre programmet om igjen. Og da fikk jeg åtte kontekst-witcher og seks kontekst-witcher. Så vi ser at det... Det var nok litt tilfeldig at det ble så veldig mange akkurat der. Der ble det tolv. Mens hvis jeg... kjører på nytt den raske, så ser vi også at det er noen kontekst-witcher. Men jeg tror da som sagt at det var litt tilfeldig at det ble veldig mange context switcher. Jeg kjører et par ganger til. Ja, der var det oppe i 95. Men context switcher er jo da noe man ikke kan forutsi. Det vil variere fra gang. Og det vil jo også... Det er jo et poeng at det kan ta lengre tid hvis det er mange context sitcher, for da blir cash ødelagt for den prosessen. Så vi kan se om det... Det ser ut som det er noe forskjell på hvor lang tid det tar når det er mange context sitcher. Skal vi se... I det tilfellet overtok her oppe... Du kan kanskje se en antydning. 5,46 sekunder.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0034", "start": 2760.76, "end": 2853.48, "token_count": 285, "text": "for den prosessen. Så vi kan se om det... Det ser ut som det er noe forskjell på hvor lang tid det tar når det er mange context sitcher. Skal vi se... I det tilfellet overtok her oppe... Du kan kanskje se en antydning. 5,46 sekunder. De kontekst-switchene tar jo litt ekstra tid, men i tillegg vil du da ødelegge cash, sånn at det tar litt ekstra tid. Men i det tilfellet så ødelegger jo programmet cash for seg selv hele tiden. Men alt i alt, som svar på spørsmålet... Det var nok tilfeldig at det var så veldig mange. Antall kontekstsituasjoner varierer veldig med hvor mange andre prosesser som kjører. Så det er litt tilfeldig dette inn i bildet. Så jeg tror først og fremst at når en kjører lenger, så er det flere kontekster. Ok. Da stopper vi der i hvert fall. Så skal jeg lage... I rekke... Et siste spørsmål! Det var... Eller tar et siste spørsmål. Det var filsystemcash, hva det var for noe.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0035", "start": 2826.68, "end": 2932.4, "token_count": 286, "text": "så er det flere kontekster. Ok. Da stopper vi der i hvert fall. Så skal jeg lage... I rekke... Et siste spørsmål! Det var... Eller tar et siste spørsmål. Det var filsystemcash, hva det var for noe. Jo, filsystemcash, det er rett og slett at man tar... I stedet for å lese bit for bit av en fil. La oss si jeg ønsker å... La oss si jeg gjør dette her. Og leser den biten der. Det Linux gjør neste gang jeg skal lese den filen... Så går det lynraskt, for da har Linux brukt ram og lagt hele filen inn i ram. Så hele filen ligger da i ram. Spesielt hvis det er en stor fil. 4 GB fil. Og hele ligger i ram, så går det lynraskt å hente ut deler av den fila i forhold til ovnen ligger på disk. Så det er det filsystem-cash er. Den bruker da ram som cash mellom... Ja, på en måte mellom ram og disken. Skal vi se om vi ikke har noen... Nei, det har jeg ikke. Men det er det, altså.", "source": "lecture"}
{"lecture_id": "os14time2", "chunk_id": "os14time2_0036", "start": 2902.18, "end": 2965.8, "token_count": 155, "text": "i forhold til ovnen ligger på disk. Så det er det filsystem-cash er. Den bruker da ram som cash mellom... Ja, på en måte mellom ram og disken. Skal vi se om vi ikke har noen... Nei, det har jeg ikke. Men det er det, altså. På samme måte som cash, L1 og L2 og Eltre cash, ligger mellom registrene og ram, så kan du se at filsystem-cashen ligger mellom disken og Osepun. Sånn at det som ligger i filen, kommer raskere inn. Og behandle seg. Ok. Da skal jeg stoppe recording.", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0000", "start": 0.0, "end": 86.64, "token_count": 296, "text": "Det jeg skal se på, er et STED-program. Vi skal se i detalj på hvordan det virker. Men det vi aller først ser her, er at vi definerer et stort RA. Og da har jeg definert et tall S, som er 1024 ganger 1024. Dette er bare for at jeg skal få... Én megabyte, eller det vil si... Det er et int RA. Altså én int er fire bite, så derfor blir dette fire megabyte. Dette er da et RA som tar... Hvis størrelsen er fire megabyte. Men før vi gjør det, så kan du... Altså... Det første vi skal gjøre, er å se på hva som skjer når vi deklarerer dette RA-et, og så begynne å kjøre. Så ser vi at det stopper ved første linje og skriver ut størrelse kolon. Og Scanf leser inn den variabelen. Så det programmet vil skrive ut størrelse, og så vil det stoppe der. Etterpå skal vi se hvordan vi da kan lese inn størrelsen på dette. Og så allokere det med Mallock. Men vi ser først bare på starten. Og da trenger vi bare å bry oss om de tre første linjene her.", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0001", "start": 70.2, "end": 155.8, "token_count": 289, "text": "Så det programmet vil skrive ut størrelse, og så vil det stoppe der. Etterpå skal vi se hvordan vi da kan lese inn størrelsen på dette. Og så allokere det med Mallock. Men vi ser først bare på starten. Og da trenger vi bare å bry oss om de tre første linjene her. Så kanskje det kan gjøres. Aller først er det bare å lage et bitte lite array med én bite. For det vi skal se på nå, er hvordan... Hvordan ser det ut i topp når vi kjører dette programmet? Og programmet heter Res, så jeg compilerer det sånn. Og så kjører jeg det med Adopt Out. Da ser vi jeg blir bedt om størrelse. Det jeg ønsker å gjøre nå, er å se på det i Topp. Og da har jeg en litt smart kommando her som ser sånn ut. Den sier Topp minus P. For nå ønsker jeg å se på akkurat bare Topp for dette programmet. Og når jeg gjør Topp minus P, der kan jeg spesifisere hvilken payday jeg vil se på. I tillegg - paydayofa.out. Jeg kan gjøre det eksplosivt.", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0002", "start": 130.68, "end": 228.54, "token_count": 293, "text": "Den sier Topp minus P. For nå ønsker jeg å se på akkurat bare Topp for dette programmet. Og når jeg gjør Topp minus P, der kan jeg spesifisere hvilken payday jeg vil se på. I tillegg - paydayofa.out. Jeg kan gjøre det eksplosivt. Den gir meg da hvilken payday A.out har. Så dermed kan jeg starte Topp på den måten her. Og så får jeg se bare info om A.out. Og det er denne infoen her om minnene som vi skal se på nå. Tidligere har vi sett på payday og priority and nice osv. Men nå skal vi se på... De tre bitene der. VIRT, DRESS og SHELL. Og kortversjonen er at VIRT, det er på en måte det virtuelle adresserommet. Det er så mye som er definert for denne prosessen. Altså så mye ram. Og ram her er definert i K. Så dette betyr at det er 4516. Med virtuelt adresserom. Så det er det som det lages plass til for hele prosessen. Alt den inneholder. Og så kommer det en kolonne som heter Ress. Her ser vi det er 748 K.", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0003", "start": 200.36, "end": 311.04, "token_count": 297, "text": "Og ram her er definert i K. Så dette betyr at det er 4516. Med virtuelt adresserom. Så det er det som det lages plass til for hele prosessen. Alt den inneholder. Og så kommer det en kolonne som heter Ress. Her ser vi det er 748 K. Og Ress, det er det som er resident. Altså det som ligger i RAM nå, og som er i bruk. Så ligger alt, men det er ikke alt som er i bruk. Og det kommer ikke nødvendigvis i bruk. Det spørs hvordan programmet kjøres. Men hvis mer tas inn i RAM, så skal vi se. Da vil RES øke. Men det vi først kan se, er VIRT gir 4516 K. Og så kan vi prøve å se... Å lage det RA-et på nytt, men denne gangen lage... En 4 MB RA. Så da stopper jeg programmet igjen. Så går jeg inn her og bruker den opprinnelige S-faktoren. Og da... Bare for å se hva som skjer, så kan jeg regne litt her nede. 1024 ganger 1024... Ja, det blir omtrent én million. Men det jeg egentlig er interessert i,", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0004", "start": 283.4, "end": 398.88, "token_count": 299, "text": "Så går jeg inn her og bruker den opprinnelige S-faktoren. Og da... Bare for å se hva som skjer, så kan jeg regne litt her nede. 1024 ganger 1024... Ja, det blir omtrent én million. Men det jeg egentlig er interessert i, det er hvor mye vil... Hvor mye vil Virt øke når jeg legger på et r-øy? Så da må jeg kanskje ta med og... Skal vi se hva vi hadde her. Sånn. Og så skal jeg nå øke... Nå burde jo den VIRT-adresserommet øke med fire ganger 1024 ganger 1024. Det vil si den burde da øke med fire ganger 1024. Eller... Ja, vi kan skrive 4 ganger 1024. Fire ganger 1024. For det er K vi snakker om. Da burde det komme 8612 K. Så skal vi se hva som skjer her, da. Om vi får til det. Jeg kompilerer nå på nytt med det store r-eiet med én million integer. Så må jeg starte topp på nytt for å få med den... Riktig add-add-out. Og da ser vi... Jo, det flingerer faktisk akkurat.", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0005", "start": 370.48, "end": 477.92, "token_count": 290, "text": "Så skal vi se hva som skjer her, da. Om vi får til det. Jeg kompilerer nå på nytt med det store r-eiet med én million integer. Så må jeg starte topp på nytt for å få med den... Riktig add-add-out. Og da ser vi... Jo, det flingerer faktisk akkurat. Da står det 8612 her, som er da... Det opprinnelige adresserommet vi hadde. Så har vi i tillegg definert fire... Hva blir det? Fire megabyte. 4 ganger 1024 K. Og da får vi akkurat den størrelsen der i hvitt. Men vi ser... Så det... Det passet akkurat med teorien. Men vi ser... Ress her er fortsatt 748. Så kan det spørres hvorfor... Hvorfor ble ikke den endret? Hvis vi ser i koden her, så har vi bare kommet hit. Så vi har ikke begynt å bruke det static-reiet i det hele tatt. Så etter hvert som man begynner å bruke det, så vil den vil da kunne øke. Men i stedet for å bruke det, så skal vi se nå på hvordan vi kan legge til statisk minne.", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0006", "start": 454.4, "end": 583.88, "token_count": 290, "text": "Så vi har ikke begynt å bruke det static-reiet i det hele tatt. Så etter hvert som man begynner å bruke det, så vil den vil da kunne øke. Men i stedet for å bruke det, så skal vi se nå på hvordan vi kan legge til statisk minne. Men... Nå glemmer vi den første. Og så... skal vi se på statusen min. Det er ett spørsmål i chatten her. Kjempebra. Stopp å spørre. Vi... Én int er fire bite. Så for det første så ble... Én int er fire bite. Og så i tillegg... Så dette... Dette teller jo opp antall elementer. 1024 ganger 1024, det er én mega. Men det vil også si at når vi regner i K, så er dette 1024 K. 1024 bite, det er én K. Så dermed ble totalstørrelsen på dette ærøyet, dette her, det ble fire ganger 1024 K. Eller fire ganger 1024 ganger 1024 bite. Så derfor ble det fire ganger 1024. Fire ganger 1024 ganger 1024... Er lik 4096 K.", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0007", "start": 546.54, "end": 666.08, "token_count": 300, "text": "Så dermed ble totalstørrelsen på dette ærøyet, dette her, det ble fire ganger 1024 K. Eller fire ganger 1024 ganger 1024 bite. Så derfor ble det fire ganger 1024. Fire ganger 1024 ganger 1024... Er lik 4096 K. Så det er det som var de fire ganger 1024 her nede. Ok. Da skal vi gå tilbake. Så skrur jeg av det ri her, og så skal vi se det lage... et like stort ri dynamisk. Da stopper jeg Adatalt igjen. Sånn. Og så ser vi... Ja, da kan vi egentlig bare kompilere det programmet her. Og starte det. Så kan vi gå og se på topp hva som skjer. Så er det 4516. Det er da... Det vi starter med i utgangspunktet. Og så kan vi prøve å regne ut... Vi kan prøve å lage et r-e som er like stort, som har så mange elementer. Og når vi ser i koden her... Scanf, den leser inn... Med prosent d, så leser den inn Det som skjer i programmet når jeg skriver inn noe her, det er det blir lest inn...", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0008", "start": 637.16, "end": 735.0, "token_count": 297, "text": "Det vi starter med i utgangspunktet. Og så kan vi prøve å regne ut... Vi kan prøve å lage et r-e som er like stort, som har så mange elementer. Og når vi ser i koden her... Scanf, den leser inn... Med prosent d, så leser den inn Det som skjer i programmet når jeg skriver inn noe her, det er det blir lest inn... Jeg skriver ut lager interrøy med det antallet elementer. Og her er det en kommando mallock. Mallock er opplagt en... Må opplagt gjøre et kall til kjernen, et systemkall, for å be operativstemma om å allokere minner. Og da ser vi... Det jeg sender med, er size. Det er den størrelsen i tallet. Ganger size of int. Size of int pleier å være 4. Det kan også i prinsippet endres. Men dette gir da... Størrelsen i bite som jeg ønsker å lokkere til her. I C er det... Skal ikke gå for mye inn på det, men dette er da en... En adresse. Når du definerer et r-øye, så definerer du adressen til første punkt i r-øyet i minnet.", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0009", "start": 713.68, "end": 796.46, "token_count": 299, "text": "Størrelsen i bite som jeg ønsker å lokkere til her. I C er det... Skal ikke gå for mye inn på det, men dette er da en... En adresse. Når du definerer et r-øye, så definerer du adressen til første punkt i r-øyet i minnet. Så det er da en minneadresse. Men etterpå bruker vi r-øye akkurat som med Java. Nå står det 'klar til å bruke r-øye'. Og så har jeg en løkke her hvor jeg går gjennom alle elementene og skriver til det. Og så stopper jeg bare med å vente på å avslutte. Men da ser vi... Her går jeg i gang og faktisk bruker r-øyet. Og det skal vi se på hvordan det funker i res. Men aller først... Vi har virtuelt 4516. Og så sier jeg... OK, jeg ønsker et så stort ære. Og da så vi... Da spratt den der opp til 8616. Det ble litt mer enn forrige gang, hvis du husker det regnestykket der. 8-6-12. Det ser ut som det er 4K som bør brukes av ramm til å administrere et eller annet rundt...", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0010", "start": 772.92, "end": 854.2, "token_count": 278, "text": "Og da så vi... Da spratt den der opp til 8616. Det ble litt mer enn forrige gang, hvis du husker det regnestykket der. 8-6-12. Det ser ut som det er 4K som bør brukes av ramm til å administrere et eller annet rundt... Sannsynligvis bruker Mallock noe ekstra ramm i tillegg til akkurat det som setter seg til her. Men foreløpig er det bare i virt. Det er bare den biten som har endret seg. Men nå klarte jeg å bruke r-øye, så da kan jeg sende meg hva som helst. Den bare leses, egentlig bare for at det skal stoppe. Så begynner jeg å bruke r-øye, og da så vi at det tok litt tid, og så spratt den opp i 5384. Og da, hvis en fulgte godt med, så jeg at det var kanskje noe sånn som... Hva var det det sto her? 700 og noe. Det ble ikke helt riktig... Altså... Eller riktig... Det skulle blitt noe sånt som 700 pluss 1466. Men vi ser at det ble en del mer.", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0011", "start": 830.72, "end": 923.58, "token_count": 298, "text": "Og da, hvis en fulgte godt med, så jeg at det var kanskje noe sånn som... Hva var det det sto her? 700 og noe. Det ble ikke helt riktig... Altså... Eller riktig... Det skulle blitt noe sånt som 700 pluss 1466. Men vi ser at det ble en del mer. Og det er tydeligvis en del mer som hentes inn i RAM og brukes aktivt. Men vi ser i hvert fall... Med en gang man da bruker dette her, så kommer det i bruk som i RAM. Registreres i MMU osv. Og da dukker det opp som RES her. Og når man kjører programmer og ser og kanskje har mine problemer, så er det veldig viktig å se hvite forskjeller på dette her. Du kan ha et kjempestort hvitt, men så lenge det ikke er i bruk i RES, så er det ikke tungt for systemet. Så det er den viktige forskjellen på de to målene her - på hvor mye... Veldig kort til slutt om SHR, eller Shared. Det er da minnet som deles med andre programmer. F.eks. så kan det være dynamisk bibliotek. Stort sett så fins det noen dynamiske bibliotek som brukes.", "source": "lecture"}
{"lecture_id": "os14del4", "chunk_id": "os14del4_0012", "start": 893.78, "end": null, "token_count": 154, "text": "Så det er den viktige forskjellen på de to målene her - på hvor mye... Veldig kort til slutt om SHR, eller Shared. Det er da minnet som deles med andre programmer. F.eks. så kan det være dynamisk bibliotek. Stort sett så fins det noen dynamiske bibliotek som brukes. F.eks. C-bibliotek som da deles.  Det så vi på sist, at vi kunne lage statisk bibliotek som blir kompilert inn i programmet. Da vil det være en del av Virt og en del av Ress. Men dynamiske bibliotek, de er da... De vil da dukke opp som sjel.", "source": "lecture"}
{"lecture_id": "linux5del15", "chunk_id": "linux5del15_0000", "start": 0.0, "end": 104.48, "token_count": 289, "text": "Hvis man kjører en prosess og taster kontroll c, så dreper man prosessen. Vi har også sett at man kan bruke kill, kommandoen kill, til å drepe en prosess. Det vi skal se på nå, er at prosesser kan behandle den type signaler som sendes til dem. Og det skal vi se på i et skjellskrift som behandler signaler. Her har vi noen definisjoner fra en Linux headerfile, som definerer forskjellige typer kill-signaler. Og dette er signaler som da kan sendes til... Som kan sendes til prosesser. For eksempel så er... SIGIN2 tror jeg er kontroll C. Ja, vi ser her nede at sigint 20 er kontroll Z. Og det er disse trappinstruksjonene her. Det er de som tar imot signalet. For eksempel den første her. Den tar imot signal 1, som står helt til slutt her. Og så gir den den meldingen til... I skjellet. Når... Når dette signalet tas imot. Tilsvarende tar den og behandler signal 15, 2, 20, 3, 4, 5 og kill minus 9.", "source": "lecture"}
{"lecture_id": "linux5del15", "chunk_id": "linux5del15_0001", "start": 82.96, "end": 168.56, "token_count": 283, "text": "Og så gir den den meldingen til... I skjellet. Når... Når dette signalet tas imot. Tilsvarende tar den og behandler signal 15, 2, 20, 3, 4, 5 og kill minus 9. Det vil si, den prøver å ta imot og behandle kill minus 9. Men 9, det er en sånn sikker dreping. Sure kill. Og den kan ikke stoppe kill minus 9. Dette programmet er da bare en Lucky som står og går, og så spør den... 'Vil du avslutte?' Svarer ja eller nei? Og med mindre du svarer ja da, så nekter den å avslutte. Så vi kan starte dette skriptet. Så hvis jeg bare tasser et eller annet, så fortsetter den å kjøre. Men så kan jeg f.eks. si at jeg prøver å stoppe denne, så taster jeg kontroll C. Men da ser vi... Nei, sorry. Ignores kontroll C. Og det er fordi da, når man taster kontroll C, så sender man egentlig et signal 2, et kill-signal 2.", "source": "lecture"}
{"lecture_id": "linux5del15", "chunk_id": "linux5del15_0002", "start": 150.0, "end": 249.4, "token_count": 288, "text": "Men så kan jeg f.eks. si at jeg prøver å stoppe denne, så taster jeg kontroll C. Men da ser vi... Nei, sorry. Ignores kontroll C. Og det er fordi da, når man taster kontroll C, så sender man egentlig et signal 2, et kill-signal 2. Et interrupt-signal, men det tas imot, og så trapper man og sier... Man tar imot dette og sier... Nei, jeg vil ignorere... Så kan vi prøve å sende et kill-signal direkte til prosessen. Men da må jeg greppe på... Nå må jeg se på alle prosesser. Og da ser vi... Kan jeg prøve å sende et kill-signal til denne prosessen? For det er Terpetot-shell. 19055. Hvis vi gjør det, så ser vi... Nei. Ignorerer kill minus 15. Som et standard kill-signal tilsier. Men så kan man spesifisere hvilket nummer på kill-signalet. Jeg kan prøve med minus 2. Nei, minus 2 er det samme. Så den ignorerer det. Jeg kan prøve med én. Det er hanging up.", "source": "lecture"}
{"lecture_id": "linux5del15", "chunk_id": "linux5del15_0003", "start": 227.18, "end": 290.76, "token_count": 226, "text": "Som et standard kill-signal tilsier. Men så kan man spesifisere hvilket nummer på kill-signalet. Jeg kan prøve med minus 2. Nei, minus 2 er det samme. Så den ignorerer det. Jeg kan prøve med én. Det er hanging up. Nei, ni genererer. Det, altså. Altså for eksempel 20. Det tilsvarer kontrollsett... Det gjør vel 15, altså? Nei, det går heller ikke. Men det som fungerer, er kill minus 9. Så det... Hvis man prøver å drepe en prosess, så nekter den å dø. Og da gjør den den type signalbehandling at den... Den tar imot signalet, og så nekter den å la seg drepe. Men kill minus ni, det er en sure kill, og da ser vi... Da drepes prosessen likevel.", "source": "lecture"}
{"lecture_id": "linux7del17", "chunk_id": "linux7del17_0000", "start": 0.0, "end": 138.66, "token_count": 297, "text": "Jeg skal starte med å kjøre det første eksempelet på... Ja. I oppgaven i dag så står det, i eksempelet på slidene til Mike, eller til opplegget til Rakhma, så står det port 8080. Med port 8080 så får man ikke kontakt med serveren. Vi kan... nei, vi tar en annen port med en gang, sånn at det virker. Problemet med port 8080 er at den ble stoppet i brannmuren inn til OsloMet. Så hvis man da kommer utenfra og prøver å koble seg til, så funker det ikke. Så sender vi den videre til port 80 og så kjører vi EngineX. Sånn. Og da laster jeg opp... EngineX. Den da starta å kjøre. Nå står den her og kjører, og det vi må teste ut da, er... Hvordan kan vi... Hvordan kan vi nå koble oss til den på 7970? Da... trenger jeg et blåsevindu. Sånn. Og jeg var jo på OS70. Det går til OU70 Welab der. Den kan ikke nås. Det er fordi der har jeg ikke noen webserver som kjører. Men hvis jeg da tar E79, så ser vi...", "source": "lecture"}
{"lecture_id": "linux7del17", "chunk_id": "linux7del17_0001", "start": 100.72, "end": 156.34, "token_count": 119, "text": "Da... trenger jeg et blåsevindu. Sånn. Og jeg var jo på OS70. Det går til OU70 Welab der. Den kan ikke nås. Det er fordi der har jeg ikke noen webserver som kjører. Men hvis jeg da tar E79, så ser vi... Da kommer jeg... Welcome to EngineX. Og da er det den webserveren, konteineren som jeg startet opp, Det er fantastisk å se hvordan folk oppfører seg og hvordan de oppfører seg.", "source": "lecture"}
{"lecture_id": "os6del4", "chunk_id": "os6del4_0000", "start": 0.0, "end": 94.52, "token_count": 291, "text": "Og i dag skal vi snakke om Branch Prediction. Vi skal fortsette litt der vi slapp sist, men først og fremst skal vi se på multitasking. Først skal vi ha en generell innføring om multitasking, hva det er, og hvordan det teoretisk sett fungerer. Og til slutt i dag så skal vi se på multitasking på forskjellige servere med forskjellig antall CPU-er. Men dette med multitasking som dere ser, det skal vi få... Fortsett med i neste uke og se på en del forskjellige praktiske problemer og løsninger relatert til multitasking. Aller først lite gram om hva vi holdt på med sist. En ting som var veldig viktig å få med seg fra forrige gang, var at én linje høynivåkode kan gi Det trenger vi nå når vi i dag skal begynne med multitasking, for da må vi multitaske mellom kodelinjer fra forskjellige prosesser. Generelt er kompilering av høynekode til maskinkode en veldig komplisert prosess. Det er vanskelig å skrive en kompulator som kan kompilere alle mulige program. Det er bare linje for linje å oversette.", "source": "lecture"}
{"lecture_id": "os6del4", "chunk_id": "os6del4_0001", "start": 67.1, "end": 123.88, "token_count": 185, "text": "for da må vi multitaske mellom kodelinjer fra forskjellige prosesser. Generelt er kompilering av høynekode til maskinkode en veldig komplisert prosess. Det er vanskelig å skrive en kompulator som kan kompilere alle mulige program. Det er bare linje for linje å oversette. Så alle kan skrive en assembler, men ikke alle kan skrive en komplator. I hvert fall ikke uten videre. Det tar halvt år. I tillegg så vi på sist at én enkelt assemblinstitusjon, én maskininstitusjon, er delt opp i mikrooperasjoner. Og i praksis utføres det faktisk parallelt i pipelines. Det er akkurat det vi skal se litt på i dag.", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0000", "start": 0.0, "end": 96.08, "token_count": 294, "text": "Vi så før pause på hvordan vi kompilerte sammen disse to programmene her. Det var da et trådprogram som kjører to tråder, som hele tiden utfører én linje. Og én linje, det er bare å øke svar med én. Så når begge gjør dette her 100 millioner ganger, så bør svaret bli 200 millioner. Og vi kompilerte sammen på denne måten. Og så kjørte vi det på denne måten. Og så ser vi at svaret ble ikke 200 millioner. Og det er... Det skyldes da at man ikke synkroniserer. At disse to trådene... De kjører på hver sin CPU, og de går da ut og henter inn. Verdier fra ramm. Og så ødelegger de for hverandre. Men det som spørsmålet gjaldt, var om jeg tok tiden på disse her. Hvis jeg timer Adatat på den måten, så ser vi at de bruker... ja, ett sekund. Men mitt poeng var at det at det bruker 200 % CPU, det viser at her så bruker de de to sekundene imot. Hvis jeg eksplisitt med task-sett sier", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0001", "start": 69.94, "end": 183.4, "token_count": 300, "text": "Hvis jeg timer Adatat på den måten, så ser vi at de bruker... ja, ett sekund. Men mitt poeng var at det at det bruker 200 % CPU, det viser at her så bruker de de to sekundene imot. Hvis jeg eksplisitt med task-sett sier at nå skal begge trådene kjøre på samme superhjul... Da... Da ser vi at... tiden var raskere. Her ble faktisk sluttresultatet... riktig også. Og det var altså noe av det vi skulle se på. Men... At det går raskere her... Det kan nok skyldes at... At det tar mer tid å synkronisere mellom to CPU-er. Men svaret er kanskje ikke fullt så enkelt heller. For jeg testet det også. Ved å prøve å skru av den joinen som vi gjør til slutt. Men iallfall - det som kan ha en effekt, det må vi undersøke nærmere. Og det er tema for forelesningen neste uke. Og det er cashing. Neste uke skal vi se på minnet. Og det som kan ha en effekt her, som gjør at det går raskere når du kjører på Det er at...", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0002", "start": 157.76, "end": 239.96, "token_count": 279, "text": "Men iallfall - det som kan ha en effekt, det må vi undersøke nærmere. Og det er tema for forelesningen neste uke. Og det er cashing. Neste uke skal vi se på minnet. Og det som kan ha en effekt her, som gjør at det går raskere når du kjører på Det er at... Ja, det kan ha med cashing å gjøre. At man mellomlagrer verdien og så gjør en endring før den er skrevet helt ut til dem. Vi kan prøve å se i neste uke om vi kan finne ut av det, for da kan vi se på hvor mange sånne cash-operasjoner som utføres. Så det kan ha en effekt når noe går raskere på samme CPU enn hvis man kjører på to forskjellige CPU-er. Vi så her at dette gikk på 0,34 sekunder, men så opp i 1 sekund her, selv om de kjørte på to forskjellige CPU-er. Men akkurat den biten, den ser vi på neste gang. Men nå skal vi konsentrere oss om ikke om timingen, men om det som kjører...", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0003", "start": 219.4, "end": 304.0, "token_count": 283, "text": "Vi så her at dette gikk på 0,34 sekunder, men så opp i 1 sekund her, selv om de kjørte på to forskjellige CPU-er. Men akkurat den biten, den ser vi på neste gang. Men nå skal vi konsentrere oss om ikke om timingen, men om det som kjører... Det som skjer når vi kjører på samme SIPU og på forskjellige SIPU-er... Vi kan gjenta det vi... det vi gjorde. Hvis jeg nå ikke tenker på tiden, bare kjører av-og-taut, så ser vi når jeg kjører dette programmet på to forskjellige SIPU-er. Så selv om dette her bare er én enkel institusjon, så blir sluttresultatet forskjellig hver gang. Fordi de driver og henter ut samme verdi og overskriver hverandres resultater. Men hvis jeg kjører på... på samme suppe, så ser vi... Da blir resultatet riktig hver gang. Og det er fordi når det bare er én institusjon her, så blir dette som en atomisk operasjon. Men forskjellen er at vi låser ikke minnebussen.", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0004", "start": 277.54, "end": 368.4, "token_count": 297, "text": "Men hvis jeg kjører på... på samme suppe, så ser vi... Da blir resultatet riktig hver gang. Og det er fordi når det bare er én institusjon her, så blir dette som en atomisk operasjon. Men forskjellen er at vi låser ikke minnebussen. Men vi kan ikke ha en contex-switch som ødelegger for denne atomiske operasjonen. For da... Hvis det skjer en contex-switch, så er enten så er denne institusjonen ferdig, eller så er den ikke ferdig. Så en contex-switch vil ikke kunne ødelegge for dette. Men hvis de kjører på to forskjellige CPU-er, som vi ser her... Da trenger det ikke å være kontekster som kommer midt inn i en kode. Da kommer de omtrent likt ut til ram for å hente inn verdien. Etterpå skal jeg prøve å tegne opp litt hvorfor dette skjer, og prøve å forklare enda litt mer i detalj. For det er viktig å få med seg akkurat den biten her. Men før vi kommer så langt, så skal vi se på et annet... Et annet eksempel hvor jeg har en ikke-minimal.s, men minimal-2.s.", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0005", "start": 349.88, "end": 428.42, "token_count": 282, "text": "og prøve å forklare enda litt mer i detalj. For det er viktig å få med seg akkurat den biten her. Men før vi kommer så langt, så skal vi se på et annet... Et annet eksempel hvor jeg har en ikke-minimal.s, men minimal-2.s. For å gjøre det litt enklere enn det jeg viste fram før pause. For der hadde jeg kode som var lagd av GCC. Men vi ser nå på... Dette er nå assembly-kode. Og assembly-kode og maskinkode... Jeg bruker ofte de ordene om hverandre, og det er fordi én linje assemblykode, sånn som dette, det fører til én linje maskinkode. Så hvis det er enkelprosent dax, det blir direkte oversatt til nulldeler og enere. Men det vil alltid være sånn at én assemblykodelinje, det blir én maskinkodelinje. Så dette kan man stole på at dette er det operativsystemet ser. Derimot, hvis du har høynivåkode, Så kan det være at én linje høynivåkode kan gi flere linjer maskinkode eller asemblykode.", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0006", "start": 407.32, "end": 496.0, "token_count": 289, "text": "Men det vil alltid være sånn at én assemblykodelinje, det blir én maskinkodelinje. Så dette kan man stole på at dette er det operativsystemet ser. Derimot, hvis du har høynivåkode, Så kan det være at én linje høynivåkode kan gi flere linjer maskinkode eller asemblykode. Men i dette tilfellet så ser vi, i stedet for å bare øke svar med én direkte i ramm, som man kan gjøre, så har jeg delt opp dette i tre institusjoner. Først en som henter svar og legger det i EAX. Og så en institusjon som øker EAX med én. Og så flyttes resultatet ut til svaret. Det er sånn som en kompilator kan finne på å lage kode. Det kan vi ikke være sikre på om dette skjer. Så hvis jeg nå prøver å kompilere med denne i stedet... Så jeg tar nå minimal... Ikke tre, men minimal to. Og så prøver jeg å kjøre med Task-sett. Og da ser vi igjen så oppstår problemet. Igjen så blir det nå trøbbel.", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0007", "start": 465.2, "end": 556.96, "token_count": 282, "text": "Så hvis jeg nå prøver å kompilere med denne i stedet... Så jeg tar nå minimal... Ikke tre, men minimal to. Og så prøver jeg å kjøre med Task-sett. Og da ser vi igjen så oppstår problemet. Igjen så blir det nå trøbbel. Og det er fordi her er det tre linjer med kode. Man henter inn eksplisitt fra RAM, så hentes det inn til AAX. Så økes den, og så legges den ut igjen. Og da kan vi få problemet med Yrvis, og det er det som skjer. Hvis det kommer da en contact switch før den har øket verdien, så kan den hoppe til den andre tråden, som nå henter inn svar på nytt, gjør en rekke økninger og legger tilbake resultatet. Men da, i mellomtiden, så er denne første prosessen frosset her. Den vil øke da på... den verdien som den hentet inn, og så skrive den ut igjen. Og da blir det trøbbel. Da blir det trøbbel. Men hvis vi derfor i stedet bruker minimal.s,", "source": "lecture"}
{"lecture_id": "os12del11", "chunk_id": "os12del11_0008", "start": 533.12, "end": 575.98, "token_count": 150, "text": "Men da, i mellomtiden, så er denne første prosessen frosset her. Den vil øke da på... den verdien som den hentet inn, og så skrive den ut igjen. Og da blir det trøbbel. Da blir det trøbbel. Men hvis vi derfor i stedet bruker minimal.s, denne, med bare én enkelinstitusjon... Så komponere på nytt. Én enkelinstitusjon, så kjøre med Taset. Da vil hver eneste gang så får man riktig svar. Fordi det ikke kan komme en kontekst-witch inne i den operasjonen.", "source": "lecture"}
{"lecture_id": "os8del14", "chunk_id": "os8del14_0000", "start": 0.0, "end": 89.92, "token_count": 293, "text": "Så tenkte jeg kunne si litt om... Denne simuleringen som jeg snakket om. Skal vi se... Her. Skedulering av samtidig forelesning og vaffelrørlaging. Ja, dere kan jo i fred og ro kose dere med denne videoen. Litt popkorn og cola osv. Så kan dere se hvordan et operativsystem virker i praksis. Det jeg har prøvd å gjøre her, er å lage et operativsystem som bruker dette med poker fra Linux 2.6-kjernen. Og stort sett opererer på samme måte. Og da vil dere se i videoen at jeg har på en... En bandyhjelm, eller en sykkelhjelm? Eller iallfall en hjelm. Og hovedpoenget med den hjelmen, det er modusbyttet. Så dere kan se... Når timeren går av, så tar jeg på meg hjelmen. Og dette skal da skje automatisk. Det er på en måte hardware som gjør det. Med en gang jeg sier den piper, så skal hjelmen komme på av seg selv. Det er vanskelig å være operativ system, så det er ikke alltid jeg klarer å få det helt til.", "source": "lecture"}
{"lecture_id": "os8del14", "chunk_id": "os8del14_0001", "start": 68.96, "end": 158.68, "token_count": 281, "text": "Så dere kan se... Når timeren går av, så tar jeg på meg hjelmen. Og dette skal da skje automatisk. Det er på en måte hardware som gjør det. Med en gang jeg sier den piper, så skal hjelmen komme på av seg selv. Det er vanskelig å være operativ system, så det er ikke alltid jeg klarer å få det helt til. Men det er utgangspunktet. Så det er da et ytre interrupt. Og så i tillegg så har vi noen... Så dette er da institusjoner, operatissysteminstitusjoner. Så dette er kjernen. Så jeg starter opp med å lese readylist over prosesser som jeg ønsker skal kjøre. Og så er det da to prosesser. Kan hoppe til det. Vaffelprosess og Forelesningsprosess. Og disse to prosessene, det er da to programmer som jeg ønsker å kjøre. Og vaffelprosessen, det er omtrent sånn som jeg lager vafler. Selv om jeg ikke skriver når jeg assemblerer kode for det. Og så sjekker jeg om det er blandet. Det er en typisk compare-oppgave.", "source": "lecture"}
{"lecture_id": "os8del14", "chunk_id": "os8del14_0002", "start": 131.92, "end": 221.76, "token_count": 291, "text": "Og disse to prosessene, det er da to programmer som jeg ønsker å kjøre. Og vaffelprosessen, det er omtrent sånn som jeg lager vafler. Selv om jeg ikke skriver når jeg assemblerer kode for det. Og så sjekker jeg om det er blandet. Det er en typisk compare-oppgave. JMPNB - jump not blandet. Da hopper jeg tilbake, og så fortsetter det sånn. Men så kommer det et viktig poeng i denne sammenhengen. Og det er når jeg skal hente melk... Det tilsvarer på en måte at jeg skal... Nå trenger jeg melk til røra, og det ligger på disk. Og da må jeg gjøre et systemkall. For det å hente melk må jeg få hjelp av operativsystemkjernen til å gjøre. Og da er jeg et vanlig program som opererer uten hjelm. Og så når jeg gjør et systemkall, da vil du se at da kommer hjelmen på. For da må jeg be operativsystemkjernen om hjelp. Da ber kjernen... Den setter i gang den prosessen. Eller da hopper vi tilbake til kjernekode et eller annet sted her.", "source": "lecture"}
{"lecture_id": "os8del14", "chunk_id": "os8del14_0003", "start": 190.36, "end": 288.4, "token_count": 296, "text": "Og da er jeg et vanlig program som opererer uten hjelm. Og så når jeg gjør et systemkall, da vil du se at da kommer hjelmen på. For da må jeg be operativsystemkjernen om hjelp. Da ber kjernen... Den setter i gang den prosessen. Eller da hopper vi tilbake til kjernekode et eller annet sted her. Jo, her er det... Legg melk i buffer. Set need rechard osv. Og så vil dere se at det er Eva, som mange av dere kjenner fra Diskrematematikk, som er melkemannen i dette opplegget. Spoiler alert... At det fungerer ikke helt optimalt. For tanken er at... Dette med å hente melk skal ta veldig lang tid. Men det har jeg ikke formidlet godt nok. Og jeg bare står på døra med melken med en gang. Da blir det litt forviklinger. Dere får se. Og hovedpoenget er da at en vanlig brukerprosess må bli bedre. Og da tar den på en måte frivillig på seg... hjelmen, og kommer over i køllen mot... Mens så ville hvert minutt... Så skjer det et timertick, for jeg har en hardware-timer.", "source": "lecture"}
{"lecture_id": "os8del14", "chunk_id": "os8del14_0004", "start": 263.84, "end": 355.32, "token_count": 293, "text": "Og hovedpoenget er da at en vanlig brukerprosess må bli bedre. Og da tar den på en måte frivillig på seg... hjelmen, og kommer over i køllen mot... Mens så ville hvert minutt... Så skjer det et timertick, for jeg har en hardware-timer. Det er en sånn liten kjøkkenklokke som hvert minutt så ringer den. Og da kommer hjelmen automatisk rett på. Og så... Her er en timer call. Det er den interrupt-rutinen som man hopper til når det kommer et time-out-call. Og da ser du... Da sjekkes det om counter er null. Hvis summen av alle er null, så startes en ny epoke. Hvis ikke, så... Ja, hvis den ene counteren... Er den null, så flyttes den fra ready-list, og så gjør man et kall til scheduler. Og så kommer scheduleren inn, og da velger den én av de to prosessene som skal kjøre. Men hvis det ikke har skjedd noe spesielt, hvis det ikke har vært noe interrupt, så er det bare den prosessen som står og kjører, som fortsetter, sånn at man unngår context switch.", "source": "lecture"}
{"lecture_id": "os8del14", "chunk_id": "os8del14_0005", "start": 338.22, "end": 409.12, "token_count": 283, "text": "Og så kommer scheduleren inn, og da velger den én av de to prosessene som skal kjøre. Men hvis det ikke har skjedd noe spesielt, hvis det ikke har vært noe interrupt, så er det bare den prosessen som står og kjører, som fortsetter, sånn at man unngår context switch. Hvis ikke, så må man sette i gang et context switch. Eller så switcher man til forelesningsprosessen. Og forelesningsprosessen, det er denne prosessen her hvor jeg har dagens faktum og snakker om Linux og utviklingen av Linux, og Linus Torvalds bor på en hybel i Helsinki osv. Og det er da altså operasjoner som jeg som hardware... Jeg ønsker å få utført disse to prosessene her samtidig. Og så ønsker jeg at de ikke skal ødelegge for hverandre. Og da har jeg da den tredje prosessen, som er operativ stemkjernen, som sørger for at disse to samkjører på en riktig måte. Sånn jeg gjør det, ligger den ganske så tett opp til Linux 2.6-kjernen med epoker,", "source": "lecture"}
{"lecture_id": "os8del14", "chunk_id": "os8del14_0006", "start": 390.0, "end": 474.54, "token_count": 276, "text": "Og så ønsker jeg at de ikke skal ødelegge for hverandre. Og da har jeg da den tredje prosessen, som er operativ stemkjernen, som sørger for at disse to samkjører på en riktig måte. Sånn jeg gjør det, ligger den ganske så tett opp til Linux 2.6-kjernen med epoker, så det er en relativt realistisk simulering. Men den ligger som sagt her. Ja, dere har også sett på OS Egg. Det er liksom høydepunktet. Her vil dere se hvorfor det er viktig å ha på seg hjelm når man skal knuse egg. For å knuse egg er opplagt noe som du må gjøre med et systemkall. Det kan ikke en vanlig brukerprosess gjøre.  Så jeg håper dere får... At det også er litt fornøyelse å se på dette her. Men samtidig så er det veldig seriøst. Det er akkurat sånn... Eller det er veldig tett opptil hvordan operativsystemet utfører sin kjernevirksomhet. Bruke hjelm når man klekker egg? Nei, når man knuser egg.", "source": "lecture"}
{"lecture_id": "linux1del2", "chunk_id": "linux1del2_0000", "start": 0.0, "end": 86.06, "token_count": 298, "text": "Linux er åpen kildekode. Det vil si, Linux-kjernen er GPL, GNU Public License, og det er en lisens som gjør at ikke bare kildekoden skal være åpen, sånn at alle kan lese den og se hva som foregår inni operativstemkjernen. Det gjør også at man ikke kan ta denne koden, endre den og lage noe nytt, og så selge den som sin. Som lukket, kjørbar kode. Det er ikke lov etter GPL. Det betyr at alle endringer vil da komme Linux til nytte senere. For alle som gjør noen fornuftige endringer, må også publisere de endringene. Og dette har vært grunnlaget for Linus, og har gjort at det har blitt så stort som det er. Som jeg sa, lagde Linus Tordalse i 1991, og det var ikke tilfeldig at det var Det var samtidig med World Wide Web og den enorme spredningen av kode og de enorme mulighetene til å samarbeide om kode, som er essensielt for fri-kildekode-prosjekter. Og det finnes en rekke distribusjoner av Linux i alle størrelser. Det fins masse små, i kameraer og mobiltelefoner ikke minst.", "source": "lecture"}
{"lecture_id": "linux1del2", "chunk_id": "linux1del2_0001", "start": 68.12, "end": 163.82, "token_count": 296, "text": "og de enorme mulighetene til å samarbeide om kode, som er essensielt for fri-kildekode-prosjekter. Og det finnes en rekke distribusjoner av Linux i alle størrelser. Det fins masse små, i kameraer og mobiltelefoner ikke minst. Eller har en Linux-kjerne. Og så fins det ruter og switcher og en masse forskjellige devices som bruker Linux. Så fins det store distribusjoner, sånn som Ubuntu, som vi bruker. Og Debian, som er relatert... Eller ligger ganske tett opp til Ubuntu. Så har vi Red Hat, Fedora Cento S, som er stor i USA. og en rekke andre distribusjoner. De har samme operativsystemkjerne, men alt det rundt, system software rundt, og hvordan man installerer, osv., det er det som er de forskjellige distribusjonene. Forskjellig vindussystem kan det være osv. Vindussystemer, GUI, har man også på Linux med pek og klikk. For de som trenger det... Etter hvert som vi blir gode på kommandolinjen, så trenger vi ikke nødvendigvis å bruke GUI. En fordel med kommandolinjen i forhold til GUI", "source": "lecture"}
{"lecture_id": "linux1del2", "chunk_id": "linux1del2_0002", "start": 139.72, "end": 236.12, "token_count": 290, "text": "Forskjellig vindussystem kan det være osv. Vindussystemer, GUI, har man også på Linux med pek og klikk. For de som trenger det... Etter hvert som vi blir gode på kommandolinjen, så trenger vi ikke nødvendigvis å bruke GUI. En fordel med kommandolinjen i forhold til GUI er at det er mye lettere å automatisere. Ja... Noen fordeler med Linux, som jeg har nevnt... Det er gratis å ha åpen kildekode. Det er ofte en naturlig del av åpen kildekode-prosjekter. Tradisjonelt så er sikkerheten stor rundt Linux. Og alt det samme gjelder også stabilitet. Linux' operativstema er veldig stabilt. Det krasjer sjelden. Hvorfor du bruker Linux? Som jeg nevnte, er det ikke så mange som bruker det på desktopen. Disse tallene er typisk hentet fra... Når man ser folk som broser, går innom webservere, så kan man se hva slags plattform de kommer fra. Om de kommer fra Mac eller Windows eller mobil eller Linux. Så en av hundre, kanskje, bruker Linux på desktop.", "source": "lecture"}
{"lecture_id": "linux1del2", "chunk_id": "linux1del2_0003", "start": 210.0, "end": 317.18, "token_count": 284, "text": "Disse tallene er typisk hentet fra... Når man ser folk som broser, går innom webservere, så kan man se hva slags plattform de kommer fra. Om de kommer fra Mac eller Windows eller mobil eller Linux. Så en av hundre, kanskje, bruker Linux på desktop. Men det er veldig anbefalt å prøve. Det går an å ha duold boot også på laptopen, så installer Linux. Det er absolutt verdt et forsøk på egen laptop. Mens det er på servere som Linux blir veldig mye brukt. Webservere i et røft anslag, kanskje 70 % av webservere, kjører Linux. Så blir det nå veldig mye brukt i cloud, i skyen, i public cloud. 70 % Linux. Til og med Microsoft Acer har en god del Linux. Så blir det veldig mye brukt i smartphones og i nettbrett. Hvor Android har 70 % av markedet. IOS har også et stort marked. Om ikke Linux-basert, så er det Unix-basert. I supercomputere så er det bare Linux. De 500 største supercomputerne, de kjører Linux. Linux og konteinere.", "source": "lecture"}
{"lecture_id": "linux1del2", "chunk_id": "linux1del2_0004", "start": 283.22, "end": 386.74, "token_count": 293, "text": "Så blir det veldig mye brukt i smartphones og i nettbrett. Hvor Android har 70 % av markedet. IOS har også et stort marked. Om ikke Linux-basert, så er det Unix-basert. I supercomputere så er det bare Linux. De 500 største supercomputerne, de kjører Linux. Linux og konteinere. Som vi har nevnt tidligere, så kommer vi til å bruke konteinere en god del. Da dere-konteinere. Og de var... Opprinnelig også basert på Linux. I dag er det hovedsakelig basert på Linux, men det fins også Viddos-konteinere. Kanskje kom vi litt inn på det også, men dokkekonteinere skal vi bruke mye. Kybernetis er et system for å orkestrere, eller sette opp og organisere drift av konteinere. Så vi kommer nok ikke... Men det er sånn... Når dere begynner å jobbe i næringslivet, vil dere oppdage at kubernettis er veldig hot. Det blir brukt mer og mer. Og konteinere blir brukt mer og mer. I 2018 ble det annonsert at IBM kjøper Red Hat for 34 mrd. dollar.", "source": "lecture"}
{"lecture_id": "linux1del2", "chunk_id": "linux1del2_0005", "start": 360.02, "end": 467.0, "token_count": 279, "text": "Men det er sånn... Når dere begynner å jobbe i næringslivet, vil dere oppdage at kubernettis er veldig hot. Det blir brukt mer og mer. Og konteinere blir brukt mer og mer. I 2018 ble det annonsert at IBM kjøper Red Hat for 34 mrd. dollar. Selv om Linux er fri software, i utgangspunktet gratis, så er det andre forretningsmodeller som gjør at man kan tjene penger på det. Sjefen for RedApp sa at... Det er også litt av grunnen til at vi jobber med dokker. For gjennom dette kurset ønsker vi at dere skal kunne lære teknologi og teknikker som ligger til bunn for veldig mye av det som... Mye av det som skjer i dataverdenen. Ok. Da skal vi se litt mer spesifikt på Linux og Linux-skjellet. Og ikke minst - hva er et skjell? Et skjell er i utgangspunktet et kommandobasert verktøy som tar imot kommandoer fra tastatur. Du taster inn kommandoer, og så snakker de kommandoene", "source": "lecture"}
{"lecture_id": "linux1del2", "chunk_id": "linux1del2_0006", "start": 438.98, "end": 528.36, "token_count": 286, "text": "Ok. Da skal vi se litt mer spesifikt på Linux og Linux-skjellet. Og ikke minst - hva er et skjell? Et skjell er i utgangspunktet et kommandobasert verktøy som tar imot kommandoer fra tastatur. Du taster inn kommandoer, og så snakker de kommandoene med operativstemt kjern. Det er derfor vi kaller det et skjell eller et skall. Som figuren viser her, så er dette et skall rundt... Linux-hjernen som sitter innerst. Og så utfører vi en rekke kommandoer, sånn som LSMV, CAT osv. Det er små programmer som gjennom skjellet snakker med Linux-tjernen. Og innholdet i disse små programmene vil da til syvende og sist være systemkall til Linux-tjernen. Så kan man spørre seg hvorfor trenger man et skjell? Hvorfor kommandolinjer i det hele tatt? Kunne man ikke... Sånn som man gjør på Windows og på Mac... Hvorfor bruker man ikke et GUI og pek og klikk? Jo, det er noen viktige grunner til det.", "source": "lecture"}
{"lecture_id": "linux1del2", "chunk_id": "linux1del2_0007", "start": 506.36, "end": 596.08, "token_count": 289, "text": "Så kan man spørre seg hvorfor trenger man et skjell? Hvorfor kommandolinjer i det hele tatt? Kunne man ikke... Sånn som man gjør på Windows og på Mac... Hvorfor bruker man ikke et GUI og pek og klikk? Jo, det er noen viktige grunner til det. Først og fremst har man mye større frihetsgrad når man bruker et shell og kommandolinje. Så kan man automatisere det man gjør. Men man kan løse kompliserte oppgaver veldig effektivt ved å sette sammen alle disse små skjellkommandoene. Og den teknikken skal dere lære veldig godt, sånn at dere raskt kan sette sammen masse små kommandoer for å få utført nøyaktig det du ønsker. Vi skal også lære skjell som et programmeringsspråk. Vi skriver såkalte Shell-skript, som da kombinerer Linux-kommander, og du ender opp med små systemprogrammer som styrer system. Det som er problemet generelt med lange sekvenser av pek og klikk for å utføre noe, er at det er vanskelig å automatisere.", "source": "lecture"}
{"lecture_id": "linux1del2", "chunk_id": "linux1del2_0008", "start": 574.08, "end": 657.08, "token_count": 291, "text": "Vi skriver såkalte Shell-skript, som da kombinerer Linux-kommander, og du ender opp med små systemprogrammer som styrer system. Det som er problemet generelt med lange sekvenser av pek og klikk for å utføre noe, er at det er vanskelig å automatisere. Delvis er det vanskelig å forklare også. Man må kanskje se en hel video om hvordan man peker og klikker. Hvis du skal gjøre noe med kommandoer, så kan du bare skrive ned en kommando. Så er det copy og paste. Du kan vise dette kommandoene. Eller du kan lage et lite script som gjør akkurat det du trenger. Ellers er kommandolinje generelt veldig mye brukt i Linux-automatisering. I skyen og mest sånn som i dokker, kubernetisk, git osv.... Alt dette kan du styre og effektivisere ved hjelp av Linux' kommandolinje. Vi kommer også til å se på Bindofs kommandolinje, spesielt PowerShell, som faktisk ligner ganske mye på Linux' shadescript. En del av kommandoene er akkurat det samme. Og PowerShell er veldig inspirert av Linux-shellet.", "source": "lecture"}
{"lecture_id": "linux1del2", "chunk_id": "linux1del2_0009", "start": 630.0, "end": 734.04, "token_count": 292, "text": "Alt dette kan du styre og effektivisere ved hjelp av Linux' kommandolinje. Vi kommer også til å se på Bindofs kommandolinje, spesielt PowerShell, som faktisk ligner ganske mye på Linux' shadescript. En del av kommandoene er akkurat det samme. Og PowerShell er veldig inspirert av Linux-shellet. Nå skal vi prøve å logge inn på noen systemer, og da... ... skal vi først si litt generelt om innlogging. På et Linux-system så har hver bruker har ett entydig brukernavn og et passord. Det er akkurat som på de fleste andre systemer. Det som er mer spesielt for Linux, er at alle brukerne på systemet ligger i en spesiell fil. Og alle de krypterte passordene ligger i Etzer Shadow. Det er standard på en Linux-maskin. For noen av de serverne som vi har her, så er det ikke fullt så enkelt. Da har vi en autentisering som går til en sentral database på OsloMet. Installerer du Linux fra scratch på en laptop, så får du dette opplegget, hvor passordene ligger i password, og de krypterte passordene ligger i shadow-filen.", "source": "lecture"}
{"lecture_id": "linux1del2", "chunk_id": "linux1del2_0010", "start": 707.4, "end": 788.0, "token_count": 233, "text": "så er det ikke fullt så enkelt. Da har vi en autentisering som går til en sentral database på OsloMet. Installerer du Linux fra scratch på en laptop, så får du dette opplegget, hvor passordene ligger i password, og de krypterte passordene ligger i shadow-filen. Den shadow-filen kan ikke leses av vanlige brukere, kun av Root. Og Root er administrator eller superuser på Linux. På StudieSSO så får man autentiseringen via Oslomet. Så det passordet er det samme som dere bruker i Canadas og andre steder. Så det passordet settes der, sånn som det gjør med det vanlige passordet. Eller det vil si, på Linux-serverne vi bruker, StudieSSO, så er det samme autentisering. Men etter hvert, når dere skal få egne, Da vil dere se at dere kan sette passordet selv og styre deg på egen hånd.", "source": "lecture"}
{"lecture_id": "os10del10", "chunk_id": "os10del10_0000", "start": 0.0, "end": 110.2, "token_count": 289, "text": "Oppgavene går ut på å ta en kopi av dette programmet. Det er et Java-program med et trådeksempel. Og så kompilere og kjøre dette programmet. Det er som å se hva som foregår, kompilere og kjøre, og se på koden. Hovedideen er at vi har en tellerkont som teller opp fra 012 oppover. Og så en int id. Den variabelen her vil da være lokal for hver tråd. Hver tråd vil ha sin egen id, men count vil være felles. Så da har vi da her nede... Her. To tråder. Så først lager en tråd S, så starter den. Og så lager en tråd S2, og så starter den. Og når den starter, så utfører den den utføreren. Så sier den tråd nummer ID is starting. Det aller første som skjer når det starter, Da ser vi at den fellesveihavlen økes med én. Så først blir det kalt lik én, og så ID settes lik én. Så i den første tråden vil ID være lik én. Og i neste tråd vil den være lik to.", "source": "lecture"}
{"lecture_id": "os10del10", "chunk_id": "os10del10_0001", "start": 85.78, "end": 135.96, "token_count": 165, "text": "Det aller første som skjer når det starter, Da ser vi at den fellesveihavlen økes med én. Så først blir det kalt lik én, og så ID settes lik én. Så i den første tråden vil ID være lik én. Og i neste tråd vil den være lik to. Og på den måten har du startet av to tråder. Og så gjør du et arbeid, og arbeidet består av å stå her og regne. Kjør på hver sin seppu. Men det kan vi se på mer neste gang. Oi, det har gått langt inn. Da trenger dere sikkert en pause. Så... Da stopper vi.", "source": "lecture"}
{"lecture_id": "os3del4", "chunk_id": "os3del4_0000", "start": 0.0, "end": 81.76, "token_count": 291, "text": "Det man lager da, er en alu. Det skal vi snakke mye om i dag. Arithmetic Logic Unit, som det står ALU for. Altså en aritmetisk og logisk enhet. Den heter det fordi den både kan gjøre aritmetikk, altså legge sammen og trekke fra osv. Og i tillegg kan den gjøre logikk, sammenligne og ande over osv. At det viser seg at en del kretser kan ligne litt på hverandre. F.eks. hvis du skal trekke fra, så kan du bruke addisjon. Altså gjøre noen smarte triks med toer-kompliment, som er en måte å representere negative tall. Hvis du representerer negative tall med toer-kompliment, så kan man nesten bruke akkurat det samme som en adderer, og så får man inn fortegn også. Og tilsvarende med andre komponenter. Man kan bruke litt av de andre portene, sånn at det blir mer effektivt. Og så kommer det smarte at man putter inn noen kontrollbit i aluen. Her står det S0 og S1. I dette tilfellet har jeg lagd en alu som er sånn at", "source": "lecture"}
{"lecture_id": "os3del4", "chunk_id": "os3del4_0001", "start": 60.0, "end": 160.18, "token_count": 300, "text": "Og tilsvarende med andre komponenter. Man kan bruke litt av de andre portene, sånn at det blir mer effektivt. Og så kommer det smarte at man putter inn noen kontrollbit i aluen. Her står det S0 og S1. I dette tilfellet har jeg lagd en alu som er sånn at f.eks. hvis S0 er 0 og S1 er 1, så adderer denne kretsen. Men hvis begge to er null, så kanskje så utføres a minus b. Og hvis det er to e-ener inne her, så kanskje det som kommer ut da, er a pluss 1. Og det er tilfellet i dette tilfellet her. At det som kommer ut av c, er a pluss 1. Altså man øker verdien med igjen. Ja, det er spørsmål om man når ser slides. Ja, det er fint at de fleste ser slides her. Ja, det er meningen. På denne måten så kan man få kretsen til å gjøre akkurat det. Den operasjonen. Ved å sette inn kontroll dit. Det er viktig å ha med seg videre. Når vi skal bygge opp en CPU, så bruker vi nøyaktig den biten der.", "source": "lecture"}
{"lecture_id": "os3del4", "chunk_id": "os3del4_0002", "start": 132.44, "end": 217.48, "token_count": 294, "text": "Ja, det er fint at de fleste ser slides her. Ja, det er meningen. På denne måten så kan man få kretsen til å gjøre akkurat det. Den operasjonen. Ved å sette inn kontroll dit. Det er viktig å ha med seg videre. Når vi skal bygge opp en CPU, så bruker vi nøyaktig den biten der. Det er dette som fører til såkalte instruksjoner, eller maskininstruksjoner. En viktig del av en maskininstruksjon er disse bitene som kontrollerer nøyaktig hva Alun gjør. For Alun, det er virkelig hjernen til CPU-en. Og CPU-en er hjernen til datamaskinen. Så det er... Det er her det skjer. All logikk og alt som du programmerer, det vil til syvende og sist utføres inni ALU. Ja, her har jeg listet opp mulige ALU-operasjoner. Som å addere, som vi så på. Riktignok med 3D-er. Men subtrahere, eller subtrahere, det er å trekke fra. Og increment eller pluss-pluss... Decrement skulle være minus-minus. Altså du trekker fra én.", "source": "lecture"}
{"lecture_id": "os3del4", "chunk_id": "os3del4_0003", "start": 192.76, "end": 277.94, "token_count": 286, "text": "Ja, her har jeg listet opp mulige ALU-operasjoner. Som å addere, som vi så på. Riktignok med 3D-er. Men subtrahere, eller subtrahere, det er å trekke fra. Og increment eller pluss-pluss... Decrement skulle være minus-minus. Altså du trekker fra én. Og litt mer komplekse operasjoner som å multiplisere og dividere. De aller enkleste aluene kan ikke multiplisere og dividere. Hvis de skal lage noen små multiplikasjoner, så må de legge sammen mange ganger. Men i de mer komplekse aluene så har man en egen krets som multipliserer. Men det betyr at disse operasjonene kan ta litt lengre tid enn av dere. De første her er aritmetiske operasjoner. Så de tre siste er logiske. Så det er den logiske delen med logiske operasjoner. Skift, f.eks., som flytter alle bitt i én retning. Det skal vi se på etterpå. En NIF-test er å sammenligne to størrelser. Finne ut om de er like eller forskjellige.", "source": "lecture"}
{"lecture_id": "os3del4", "chunk_id": "os3del4_0004", "start": 259.06, "end": 347.0, "token_count": 280, "text": "Så det er den logiske delen med logiske operasjoner. Skift, f.eks., som flytter alle bitt i én retning. Det skal vi se på etterpå. En NIF-test er å sammenligne to størrelser. Finne ut om de er like eller forskjellige. Eller eventuelt den ene er større eller mindre enn den andre. Hvis det f.eks. er 4-bit, så kan du spesifisere 16 operasjoner til denne alderen. Ofte har de enda flere operasjoner. På en maskin som het Edzak 2, som ble lagd i 1958. Dette var akkurat på overgangen til man begynte med transistorer. Men disse maskinene hadde radiorør. Og da er det liksom et helt sånt radiorør tilsvarer da en transistor. Og da sier seg selv at da ble disse maskinene ganske enormt store. Det er ikke så langt tilbake, men det illustrerer den enorme revolusjonen som transistoren gjorde, hvor vi kan få i dag milliarder av sånne transistorer inn på en liten brikke.", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0000", "start": 0.0, "end": 95.06, "token_count": 290, "text": "I dag så skal vi... I første omgang så tenkte jeg bare å vise hvordan det ser ut når man mer teoretisk kjører JavaC og Bæsj-programmer under forskjellige OS. Og de eksemplene jeg har i utgangspunktet, er da Linux på vanlig PC, eller en laptop som kjører X86-institusjoner. Den kjører... Det er kanskje ikke en Pentium jeg kjører, det er vel en Seon som jeg har på laptopen nå. Men uansett, den kjører og forstår Exo 86-instruksjoner. Akkurat som det vi har sett på hele tiden. I dag skal vi se på noen andre instruksjonssett. Men i tillegg så har jeg en vindusmaskin som kjører på i dette tenkte eksperimentet. Der kjører den på akkurat den samme Intel-PC-en. Det er bare sånn dual-boot, så en booter opp på den helt samme Intel-PC-en, og har de samme X86-instruksjonene sånn underliggende. Men det tredje eksempelet er operativsystemet Solaris. Og det er et Sun operativsystem. Et Unix-firma som da,", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0001", "start": 64.36, "end": 165.28, "token_count": 294, "text": "Det er bare sånn dual-boot, så en booter opp på den helt samme Intel-PC-en, og har de samme X86-instruksjonene sånn underliggende. Men det tredje eksempelet er operativsystemet Solaris. Og det er et Sun operativsystem. Et Unix-firma som da, som typisk Unix-firmaer flest på 90-tallet og 2000-tallet... De bygde sin egen hardware og hadde sitt eget operativsystem som de kjørte alle institusjonene på. Og da kjørte Sunt på en Spark-prosessor, og den maskinen hadde da bare... Som var helt forskjellige fra X86-maskininstruksjoner. Like forskjellige som X86 er fra de maskininstruksjonene som vi hadde i det simulerte ZPU-en. Etterpå, når vi skal kjøre en demo av plattformen Uavhengighet, så skal vi da se på et tredje instruksjonssett, nemlig ARM-instruksjonssettet. Det er det som kjører på alle mobiltelefoner. Men det kan også brukes på servere. Vi skal kjøre på noen servere og sammenligne med hvordan det ser ut i forhold til Intel.", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0002", "start": 136.36, "end": 225.16, "token_count": 288, "text": "Etterpå, når vi skal kjøre en demo av plattformen Uavhengighet, så skal vi da se på et tredje instruksjonssett, nemlig ARM-instruksjonssettet. Det er det som kjører på alle mobiltelefoner. Men det kan også brukes på servere. Vi skal kjøre på noen servere og sammenligne med hvordan det ser ut i forhold til Intel. Men det viktigste å ha med her i denne sammenhengen er at dette er institusjoner som er helt forskjellige fra X86-institusjoner, som er det vi er vant til. Stort sett overalt. Hvis du logger inn på laptoper eller servere, Men det kan da være forskjellig operativstemme på toppen av det. Og den sammenkoblingen, det kaller vi en plattform. Så... Dette er det samme eksemplet som vi skal bruke senere. Hello.java. Det er bare et javaprogram som skriver ut Hello World. Og som vi også skal se når vi kompilerer det på Linux. Så kompilerer vi sånn. Java.chello.java. Og da lages en Java classfile. Og den inneholder da Java bite-kode.", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0003", "start": 191.8, "end": 289.16, "token_count": 292, "text": "Så... Dette er det samme eksemplet som vi skal bruke senere. Hello.java. Det er bare et javaprogram som skriver ut Hello World. Og som vi også skal se når vi kompilerer det på Linux. Så kompilerer vi sånn. Java.chello.java. Og da lages en Java classfile. Og den inneholder da Java bite-kode. Og det er kode som er for en JVM eller en Java-virtuell maskin. Så vi kan se på bildet her nede. Det ser ut som noe sånt som dette her. Og så får vi en hello.class-fil. Og da er det helt essensielt at dette er helt forskjellig fra A.out, som vi har sett på tidligere, som inneholder maskinkode. Som er da instruksjoner for X86. X86-instruksjoner. A.out kjører på en måte direkte på X86. Men Hello.class, det kjører inne i... I en JVM, en Java virtuell maskin. Og da er hele poenget som gjør Java plattform uavhengig, at på Linux er det en egen Linux-JVM. På Windows er det en annen Windows-JVM, og på Solaris er det en Solaris-JVM.", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0004", "start": 270.0, "end": 387.92, "token_count": 300, "text": "I en JVM, en Java virtuell maskin. Og da er hele poenget som gjør Java plattform uavhengig, at på Linux er det en egen Linux-JVM. På Windows er det en annen Windows-JVM, og på Solaris er det en Solaris-JVM. Så på den måten så kan hello.class kjøres på alle disse plattformene. Og man kan til og med ta hello.class herfra, kopiere opp en Windows-maskin, Og så kan den kopiere Overs på en sparkmaskin. Og så kjører den likevel fordi den har en JVM som tolker instruksjonene. Det blir litt overhead. Ting går litt saktere. Men Java er veldig god på overhead, altså den... Opp gjennom årene så har Java klart å optimalisere veldig, sånn at det faktisk går nesten like bra. Men igjen, det vesentlige her er hello the class. Det er en helt egen... Man kan si at det er et maskinspråk, dette også, men det er for en virtuell maskin. Så vi skal se på det i detalj senere, hvordan instruksjonene i bite-koden til Java ser ut. Og det er faktisk mulig å lage hardware-Java-virtuell maskin.", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0005", "start": 363.96, "end": 465.8, "token_count": 295, "text": "Man kan si at det er et maskinspråk, dette også, men det er for en virtuell maskin. Så vi skal se på det i detalj senere, hvordan instruksjonene i bite-koden til Java ser ut. Og det er faktisk mulig å lage hardware-Java-virtuell maskin. Det har blitt laget reell hardware som kjører Class-kode direkte. Og med prinsippet er det samme. Og dette med virtuelle maskiner, det gjelder også sånn som Python og Csharp og Pearl. Veldig mange av de nye språkene, de kjører på virtuell maskin på denne måten. En tradisjonell, sånn som C og C pluss pluss, kompileres det, så kjører man direkte på hardway. Så plattformuavhengighet, det er at man kan ta hello.class-filer og kopiere over til andre plattformer og kjøre dem der som om ingenting skulle ha skjedd. Så kom vi til hello.c. Og dette er da... Et program som er i høyeste grad plattform avhengig av. For når vi komplerer Hello.dat.se, sånn som vi har gjort mange ganger, så ser vi at så får vi en adopt-out,", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0006", "start": 445.62, "end": 538.68, "token_count": 295, "text": "Så kom vi til hello.c. Og dette er da... Et program som er i høyeste grad plattform avhengig av. For når vi komplerer Hello.dat.se, sånn som vi har gjort mange ganger, så ser vi at så får vi en adopt-out, og den vil inneholde X86-instruksjoner, sånn som denne her. Move X til EBX. Og det er klart... De instruksjonene forstås bare av en X86-CPU. Altså en CPU som har innebygd, brent inn X86-instruksjoner fra bunnen av. Den kan ikke få se spark-instruksjoner, f.eks. Så her, med object dump fra en adopt-out, så kan du se hvilke instruksjoner som adopt-out inneholder. Det object dump gjør her, er på en måte mot... I tillegg har vi sett på en assembly hvor vi går fra assembly-kode til maskinkode. Men denne her på en måte viser hva maskinkoden inneholder. Og hvis vi gjør dette her på Solaris... Dette er et eksperiment hvor vi har gjort det på Solaris. Så vil vi rett og slett se at her er det andre institusjoner. De har faktisk ad og sub.", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0007", "start": 518.12, "end": 604.24, "token_count": 296, "text": "Men denne her på en måte viser hva maskinkoden inneholder. Og hvis vi gjør dette her på Solaris... Dette er et eksperiment hvor vi har gjort det på Solaris. Så vil vi rett og slett se at her er det andre institusjoner. De har faktisk ad og sub. Ad har tre argumenter. Her oppe er det to. Så fins det en del andre... Det fins noen andre instruksjoner også, sånn som TST og Load. Så dette er helt fundamentalt forskjellige maskininstruksjoner. Og når vi da skal prøve å flytte rundt på a.not.out, så fungerer det... Dårlig. Så hvis jeg tar AdoptOut, som er komplert for en Linux-maskin, og flytter over på Windows og prøver å kjøre det, så enten så skjer det ingenting, eller så får man en feilmelding om wrong binary eller et eller annet sånt. Men det fungerer ikke. Og det til tross for at X86-institusjonene i bunnen er akkurat de samme. Så her er det Move A, XB, X osv. X86-institusjoner. Men et program må også snakke med operativsystemet.", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0008", "start": 584.36, "end": 659.8, "token_count": 295, "text": "om wrong binary eller et eller annet sånt. Men det fungerer ikke. Og det til tross for at X86-institusjonene i bunnen er akkurat de samme. Så her er det Move A, XB, X osv. X86-institusjoner. Men et program må også snakke med operativsystemet. Hvis du flytter over adopt-out hit, så kommer du inn på Windows, og så begynner du å snakke med Linux-biblioteket for å printe ut noe. Da er det klart at det fungerer dårlig. Da vil programmet ikke virke. Hvis vi tar adopt-out og så flytter over hit på Solaris, så vil det dobbelt ikke fungere. Å snakke med Linux-operativsystemet. Det går veldig dårlig. I tillegg så prøver du å utføre X86-institusjoner på en helt annen arkitektur. Så det er dømt til å mislykkes å prøve å kjøre ADAT-out på en plattform som både har et annet operativsystem og et annet instruksjonssett. Men det vi så over, var at man kan oppnå plattform-uavhengighet ved å bruke...", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0009", "start": 639.04, "end": 723.68, "token_count": 288, "text": "på en helt annen arkitektur. Så det er dømt til å mislykkes å prøve å kjøre ADAT-out på en plattform som både har et annet operativsystem og et annet instruksjonssett. Men det vi så over, var at man kan oppnå plattform-uavhengighet ved å bruke... Virtuelle maskiner som da tolker koden her. Men det har også en pris, at ting går litt saktere. Men veldig mange programmeringsspråk har valgt det. Men hvordan kan man da kjøre et C-program på Windows eller Solaris? Jo, det som da er clouet, er at da må du gjøre ett step til. Du må kompilere. Du må ha en kompilator for den plattformen. Og da kan vi kompilere Og få en A.xe, og så kan den kjøre på Windows. Eller en S.out, som man fikk til folk med GCC på Spark. På Solaris. Og da kan man kjøre C-programmet på denne plattformen. Men da er hele forskjellen at du må kompilere og laste inn maskinkoden, og så kan du kjøre den. Og dermed er det da...", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0010", "start": 697.48, "end": 796.22, "token_count": 289, "text": "Eller en S.out, som man fikk til folk med GCC på Spark. På Solaris. Og da kan man kjøre C-programmet på denne plattformen. Men da er hele forskjellen at du må kompilere og laste inn maskinkoden, og så kan du kjøre den. Og dermed er det da... Og dermed sier vi da at C-kode er ikke plattformavhengig. Nei, hva sa jeg nå? C-kode ER plattformavhengig. Viktig forskjell. Ikke der. Ja... Solais og Spark, den maskinen her finnes ikke lenger. Det kjører sikkert en del sånne rundt omkring, akkurat som det fortsatt kjører IBM-stormaskiner, men de blir færre og færre. Det meste nå går på Exo26, men som vi skal se, det fins også servere som kjører på Arm. Til slutt i denne oversikten så tar vi altså med HelloDotBæsj. Et bæsjprogram på de forskjellige plattformene her. Det går... Det går fint på Linux og Spark, som... Men da igjen, da må du installere bæsj, og så kjøre det.", "source": "lecture"}
{"lecture_id": "os10del2", "chunk_id": "os10del2_0011", "start": 767.16, "end": 832.0, "token_count": 193, "text": "Til slutt i denne oversikten så tar vi altså med HelloDotBæsj. Et bæsjprogram på de forskjellige plattformene her. Det går... Det går fint på Linux og Spark, som... Men da igjen, da må du installere bæsj, og så kjøre det. Det ligner jo litt på en virtuell maskin, det også, for da må du tolke det. På Window går det ikke i utgangspunktet, men hvis du f.eks. installerer... Du kan installere Linux på Windows. Og da kjører Linux rett på X86. Og i tillegg så kan du da installere et bæsjel. Det kan du på andre måter òg. Så det er mulig å installere Vers på Windows. Sånn at du kan kjøre skript der.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0000", "start": 0.0, "end": 99.2, "token_count": 285, "text": "Sånn. Da tar vi opp forelesningen fra nå av. Ine, er det noe du vil si relatert til opplegger eller oppgaver og erfaringene fra første innlevering f.eks.? Nei, ikke noe spesifikt noe. Det var veldig mange som svarte veldig bra og fikk til veldig mye, så det var fint å se. Det er jo sprøyt. Ja... Nei, fint. Men hvis dere har spørsmål til oppgaver eller INE eller de som er studentassistenter, så still gjerne spørsmål i 17. Hvis ikke, så begynner vi å se på hvor vi er og prøver å orientere oss litt. Forrige uke var det... Komte uke, så jeg håper at... Mange av dere klarte å ta inn det tapte hvis dere lå litt tilbake. For det har vært ganske... Ganske intenst, egentlig, de første ukene. Vi har på en måte kommet litt lenger enn vi var i fjor. Så det kommer nok... Det er en hard periode nå i dette kurset. Mye roligere etter påske. Vi har bare satt opp undervisning fram til uke 16.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0001", "start": 72.42, "end": 164.8, "token_count": 299, "text": "For det har vært ganske... Ganske intenst, egentlig, de første ukene. Vi har på en måte kommet litt lenger enn vi var i fjor. Så det kommer nok... Det er en hard periode nå i dette kurset. Mye roligere etter påske. Vi har bare satt opp undervisning fram til uke 16. Det er mulig vi da får ganske mye tid til å se på tidligere eksamensoppgaver og så fordøye det stoffet vi har lært. Så da blir det litt mindre trykk mot slutten av kurset. Men her vi er nå, så har vi begynt med en container. Der ligger det en forelesning ute. Jeg hadde i hvert fall tenkt å dele den opp i litt mer deler, sånn at dere kan se på enkeltdeler. Men det er en ganske sakte, rolig, systematisk måte å begynne i praksis med containere, spesielt med dokkercontainere, Og kjøre de på de VM-ene som dere har. Så dokker er noe vi skal jobbe mye med de neste ukene. Jeg får se hvor langt vi kommer i dag. Men jeg tenkte kanskje å bruke litt tid på å se på", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0002", "start": 139.12, "end": 231.64, "token_count": 280, "text": "å begynne i praksis med containere, spesielt med dokkercontainere, Og kjøre de på de VM-ene som dere har. Så dokker er noe vi skal jobbe mye med de neste ukene. Jeg får se hvor langt vi kommer i dag. Men jeg tenkte kanskje å bruke litt tid på å se på de første oppgavene denne uken, som går nettopp på dette her, med å kjøre Hello World på dokker og starte opp. Og så, i løpet av dagen, komme frem til det å kunne starte opp en dokkecontainer som kjører en webserver på Linux-VM deres. Så tidligere så har dere kjørt en webserver direkte på Linux-VM, men nå skal dere kjøre en dokkecontainer inni Linux-VM som kjører en webserver. Så det er en del ting der som kan være litt forvirrende. Jeg skal prøve å sette av litt tid mot slutten i dag, og så kan vi gå inn og se på de oppgavene og se hvordan det er tenkt det skal være. Men ellers så er hovedfokus i dag på scheduling og hvordan et operativsystem egentlig virker. ", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0003", "start": 205.64, "end": 312.16, "token_count": 288, "text": "Jeg skal prøve å sette av litt tid mot slutten i dag, og så kan vi gå inn og se på de oppgavene og se hvordan det er tenkt det skal være. Men ellers så er hovedfokus i dag på scheduling og hvordan et operativsystem egentlig virker.  Altså hele det store bildet av operativsystemet, hvordan det styrer alle prosesser som kjører på en maskin. Vi har sett en del i praksis sånn som... Med multitasking og multitredding som vi holdt på med forrige gang... Hvordan operativsystemet da fordeler prosesser på... Og så hvordan et operativsystem deler inn tiden og lar én og én prosess kjøre. Men det er en del problemstillinger som vi ikke har sett på, spesielt hvordan man i praksis kan få til dette her. For der er det en del tilfeller hvor operativsystemet er nødt til å ha hjelp Og ha egne instruksjoner for å kunne kontrollere prosessene. Hvis vi tenker tilbake på dette med prosess, som er et levende liv, så tenker vi oss nå at vi har tusenvis av levende liv innenfor en datamaskin.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0004", "start": 282.84, "end": 381.6, "token_count": 295, "text": "For der er det en del tilfeller hvor operativsystemet er nødt til å ha hjelp Og ha egne instruksjoner for å kunne kontrollere prosessene. Hvis vi tenker tilbake på dette med prosess, som er et levende liv, så tenker vi oss nå at vi har tusenvis av levende liv innenfor en datamaskin. Og så skal operatørsystemet nå holde orden på alle de tusen. Enkelte liv, altså prosesser, må fryses helt. Alt må lagres. Og så må man sette i gang andre prosesser. Og samtidig så må man sørge for at de ikke ødelegger for hverandre. Og det er de problemstillingene vi skal se på i dag. Så ser vi at det også står vaffelrøre på programmet i dag. Og det er da en simulering som jeg har lagd av hvordan... Rett og slett hvordan et operativsystem virker. Og det... Et operativsystem kan kjøre to prosesser samtidig på samme CPU. Og det er det jeg har illustrert med den vaffelrøre-videoen som ligger ute. Her så er jeg da... Jeg er på en måte... Jeg er en CPU.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0005", "start": 351.64, "end": 436.56, "token_count": 298, "text": "Rett og slett hvordan et operativsystem virker. Og det... Et operativsystem kan kjøre to prosesser samtidig på samme CPU. Og det er det jeg har illustrert med den vaffelrøre-videoen som ligger ute. Her så er jeg da... Jeg er på en måte... Jeg er en CPU. Og så tenker jeg at jeg skal både holde forelesning og lage vaffelrøre samtidig. Og da må jeg jo switche mellom de to oppgavene. Og da har jeg prøvd å gjøre det på en veldig systematisk måte, nemlig med å kjøre et operativsystem som styrer de to prosessene, som kjører da på meg. Og operativsystemet kjører også da på meg. Og da... Ja, vi kan komme litt mer tilbake til det på slutten. Kanskje vi setter av litt tid også, sånn at du kan se på den. Men det er altså en... Skal vi se... For de som syns forelesningen blir kjedelig, så kan dere hoppe og så se på den videoen. Så... Ja. Da ønsker jeg velkommen til denne. Vi skal ikke kjøre denne her, men dere ser jeg har et operativstem.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0006", "start": 411.64, "end": 500.6, "token_count": 296, "text": "Kanskje vi setter av litt tid også, sånn at du kan se på den. Men det er altså en... Skal vi se... For de som syns forelesningen blir kjedelig, så kan dere hoppe og så se på den videoen. Så... Ja. Da ønsker jeg velkommen til denne. Vi skal ikke kjøre denne her, men dere ser jeg har et operativstem. Og så lager jeg vafler og holder forelesning samtidig. Dette ligger veldig tett opp til scheduleren i versjon 2.6 i Linux-kjernen. Så det er en litt eldre kjerne. I dag ser scheduleren litt annerledes ut. Men hovedideen er å få vist prinsippene. Så... Men vi kommer tilbake til det mot slutten av forelesningen. Først skal vi se på noen av de tingene som er viktige. For i det hele tatt å få til dette her. Og da er det spesielt prosessormodus. Og så er det trap og systemcall. Det er også en viktig ingrediens i det å lage et operativsystem. Aller først skal vi se på litt... Noe som egentlig henger mer sammen med det vi holdt på med forrige gang med multitasking.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0007", "start": 479.8, "end": 588.4, "token_count": 294, "text": "Og så er det trap og systemcall. Det er også en viktig ingrediens i det å lage et operativsystem. Aller først skal vi se på litt... Noe som egentlig henger mer sammen med det vi holdt på med forrige gang med multitasking. Én prosess ikke kan utnytte to sepur. Ja... Da hopper vi dit. Ja, sist, forrige gang, så holdt vi på med... Vi startet egentlig med cash og så på minne, og hvor viktig det er at vi har... for cash imellom CPU og ram, fordi CPU-en er mye raskere enn ram. Og da må man ha et mellomlager for å kunne utnytte hele effekten av raske CPU-er. Så så vi mye på cores, eller kjerner, regneenheter. Og da regnet de med at... Eller hver kjerne eller regneenhet. Det så vi på som én alu. Og da, når vi etterpå så på hypertrening... Intel hypertrening består da av at operatørsystemet ser på... Det som egentlig er én core, én kjerne, som har én alu... Den ser på det som to CPU-er eller to regneenheter.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0008", "start": 566.88, "end": 657.2, "token_count": 282, "text": "Og da, når vi etterpå så på hypertrening... Intel hypertrening består da av at operatørsystemet ser på... Det som egentlig er én core, én kjerne, som har én alu... Den ser på det som to CPU-er eller to regneenheter. Men i virkeligheten så er det ved hjelp av Hardware så kan Hardware switche lynraskt, altså på nanosekunder. Så kan den switche mellom to prosesser som kjører samtidig inn i denne kjernen. Og de har da typisk to sett med registre osv. Og så switcher man veldig fort mellom dem. Og da kan man i enkelte tilfeller... Kan man utnytte den ventetiden som man vanligvis har på å hente noe i RAM, så kan det utnyttes, sånn at prosesser går mye raskere. Men det er igjen så veldig mye av alt annet, som cash og andre... Andre viktige deler ved en CPU. Det er egentlig der bare for at ting skal gå fortere. Da skal vi se på hvorfor ikke en prosess kan utnytte to CPU-er.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0009", "start": 625.02, "end": 724.16, "token_count": 297, "text": "så kan det utnyttes, sånn at prosesser går mye raskere. Men det er igjen så veldig mye av alt annet, som cash og andre... Andre viktige deler ved en CPU. Det er egentlig der bare for at ting skal gå fortere. Da skal vi se på hvorfor ikke en prosess kan utnytte to CPU-er. Og problemstillingen her er nå spesielt det at man tenker at... OK, her har jeg en... Det kan være en regnejobb, typisk, som bruker mye CPU. Og nå vil jeg kjøre den på en svær server som har 96 CPU-er. Det må da gå... Fantastisk fort. Men da... Men det er ikke så lett å utnytte flere parallelle CPU-er. Flere forskjellige, samtidige renhentede enhenter. Og det er som regel fordi at... Én prosess, det er ett dataprogram som skal kjøres. Og som vi har sett, det som skjer når et dataprogram kjøres... Det er, som vi ser på denne illustrasjonen her, at det er instruksjoner etter hverandre som bare står og kjører om og om igjen. For det første vet ikke operativsystemet noe om", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0010", "start": 700.04, "end": 782.8, "token_count": 279, "text": "Én prosess, det er ett dataprogram som skal kjøres. Og som vi har sett, det som skjer når et dataprogram kjøres... Det er, som vi ser på denne illustrasjonen her, at det er instruksjoner etter hverandre som bare står og kjører om og om igjen. For det første vet ikke operativsystemet noe om hva som foregår inni denne koden. Den ser bare instruksjoner, og den sier til CPU-e... Sett i gang. Kjør disse instruksjonene. hva som egentlig foregår her. Det er det programmereren som het. Så derfor er det veldig vanskelig å gjøre noen fordeling her. Operativsystemet kan ikke si at OK, CPU1, du gjør instruksjon 1, 2, 3, og CPU2, du gjør 4 og 5. I prinsippet så kunne man gjøre det, men da måtte man flytte hele prosessen fra CPU1 og over på CPU2. Og det ville bare ta veldig mye tid. Så her er det på en måte opplagt at disse institusjonene må kjøre på samme CPU.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0011", "start": 758.0, "end": 834.2, "token_count": 297, "text": "og CPU2, du gjør 4 og 5. I prinsippet så kunne man gjøre det, men da måtte man flytte hele prosessen fra CPU1 og over på CPU2. Og det ville bare ta veldig mye tid. Så her er det på en måte opplagt at disse institusjonene må kjøre på samme CPU. For hele tiden er man avhengig av hva som skjedde i forrige institusjon. Man kan ikke kjøre dette uavhengig på en annen CPU. Og det vi ser her, er en veldig enkel implementasjon av Fibonacci-rekken. Først legger du én inn i AX og én inn i BX. Og så på ledd 3 så ser du legg til AX til BX. Så da blir BX 2, og AX er fortsatt 1. Og så hopper du til neste ledd. Legg til BX til AX. Da legger du 2 pluss 1 er 3, så da blir AX 3. Og så hopper du opp til 3 igjen. Og sånn fortsetter det. Da blir BX lik... 2 pluss 3 er 5. Og så på neste så blir AX lik... Tre pluss fem er åtte, og så... og så videre.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0012", "start": 813.52, "end": 895.88, "token_count": 295, "text": "Da legger du 2 pluss 1 er 3, så da blir AX 3. Og så hopper du opp til 3 igjen. Og sånn fortsetter det. Da blir BX lik... 2 pluss 3 er 5. Og så på neste så blir AX lik... Tre pluss fem er åtte, og så... og så videre. Ja, jeg ser forresten den Fimonacci-rekken her. Så ikke veldig riktig ut. Én, én, to, tre, fem, skulle stå der, og åtte. Det blir et problem for oppgavene. Hva er feil i denne Fimonacci-rekken? Men hovedpoenget er at man kan ikke utnytte... To eller hundre prosessorer, når du bare har ett program som kjører sånn som dette her... Det må kjøres sekvensielt. Og her er det altså... Det vi kunne få til, er hvis man som programmerer kan skrive kode som kan kjøres i parallell. Men det er opp til programmereren. Hvis programmereren kan klare å få til å splitte opp denne koden... Sånn at den kan kjøre på to steder samtidig, gjøre noen milliarder institusjoner på hvert sted,", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0013", "start": 879.04, "end": 965.32, "token_count": 292, "text": "Men det er opp til programmereren. Hvis programmereren kan klare å få til å splitte opp denne koden... Sånn at den kan kjøre på to steder samtidig, gjøre noen milliarder institusjoner på hvert sted, og så slå sammen resultatene. Da kan man utnytte to eller flere prosesser. Men i de fleste tilfeller så er det vanskelig. Og i et sånt tilfelle som dette her, hvor alt avhenger av forrige to-tre institusjoner, så vil det ikke være mulig å utnytte flere CPU-er. Men i noen tilfeller så har man parallelliserbar kode. Og vi tenker oss et enkelt tilfelle sånn som dette her. At vi skal legge sammen en stor sum. Vi skal telle fra 1 pluss 2 pluss 3 pluss 4 opp til 2000. Nå er det klart. I dette tilfellet så fins det en formel. Man kan utlede en formel som gir... Som er 1 ganger 1 pluss 1½, er det vel? Men det er jo ikke poenget. Poenget er at her skal vi gjøre en lang regneroperasjon. Vi skal gjøre den på denne måten.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0014", "start": 946.18, "end": 1028.94, "token_count": 287, "text": "Man kan utlede en formel som gir... Som er 1 ganger 1 pluss 1½, er det vel? Men det er jo ikke poenget. Poenget er at her skal vi gjøre en lang regneroperasjon. Vi skal gjøre den på denne måten. Og dette er da kode som opplagt er parallelliserbart. For da, hvis vi har en oppgave som er på denne måten her, at det er veldig mange helt like operasjoner... Da kan vi dele dette i to. Én CPU kan regne ut summen fra 1 til 1000. Og en annen CPU kan regne ut summen fra 1001 til 2000. Og så, etterpå at de to prosessene er ferdige, kan man slå sammen resultatet, og så får man totalsummen. Og dermed har man klart å parallellisere koden, og dermed kan man utnytte flere CPU-er. Men hvis man bare kjører et C-program som lager denne summen her, og overleverer det, laster det inn i RAM og ber operativsystemet om å kjøre, så aner ikke operativsystemet noe om hva alle disse institusjonene i denne summen gjør.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0015", "start": 1001.68, "end": 1098.52, "token_count": 298, "text": "og dermed kan man utnytte flere CPU-er. Men hvis man bare kjører et C-program som lager denne summen her, og overleverer det, laster det inn i RAM og ber operativsystemet om å kjøre, så aner ikke operativsystemet noe om hva alle disse institusjonene i denne summen gjør. Så operativsystemet selv er overhodet ikke i stand til å utnytte... Og har 48 CPU-er til rådighet. Det går bare ikke. Så man kan ikke forvente at operativsystemet skal kunne sørge for at man utnytter alle CPU-ene. Og da er det programmereren selv som må sørge for parallellisering. Da kunne man løse dette her med to prosesser eller to tråder. Vi skal se på javatråder og p-treds i C, som vi da kan sette opp for å gjøre ting i parallelt. Vi har vel egentlig delvis sett på det når vi har gjort regnejobber i parallelt også. Da er det en sånn type regnejobb. Så setter vi opp akkurat like regnejobber på fire søppeur ved å bare starte fire bæsjscript samtidig. Ikke har slått sammen resultatene ennå.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0016", "start": 1079.76, "end": 1180.32, "token_count": 299, "text": "når vi har gjort regnejobber i parallelt også. Da er det en sånn type regnejobb. Så setter vi opp akkurat like regnejobber på fire søppeur ved å bare starte fire bæsjscript samtidig. Ikke har slått sammen resultatene ennå. Men det er en liten detalj som man kan få til. Et eksempel på når dette kan være nyttig, er passordkracking. Og det var en student som syntes at den passordkrakking-algoritmen gikk litt tregt. Den tok jo over to minutter på studietid. Men i hvert fall da den stunten... klarte å dele opp... Dele opp det problemet i åtte like biter, og utnyttet da de åtte sekundene som var på PC-en. Og passord-cracking er typisk et problem som er parallelliserbart. Men hvis vi da setter i gang en skript som kjører gjennom alle de... Så kan ikke operativsystemet forstå dette her. ... Oi, dette her er jo parallelliserbart. Så intelligent er ikke operativsystemet. Det finnes noen kompilatorer som kan automatisk parallellisere på den måten. Så noen automatiske måter finnes det.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0017", "start": 1155.32, "end": 1264.52, "token_count": 296, "text": "Så kan ikke operativsystemet forstå dette her. ... Oi, dette her er jo parallelliserbart. Så intelligent er ikke operativsystemet. Det finnes noen kompilatorer som kan automatisk parallellisere på den måten. Så noen automatiske måter finnes det. Men stort sett så er det da programmereren som må se... Og på hver CPU så kan jeg kjøre gjennom ett antall passord. Så fordeler jeg de jobbene likt. Og det er først da man kan virkelig utnytte at man har mange CPU. Og dette er viktig å kunne, for veldig ofte så kan man nå kjøre på servere som har mange CPU-er. Og da kan det være viktig å ha kode som utnytter CPU-er. Hvis det er CPU-avhengig kode som man ønsker skal kjøre fort. Så dette er problemstillinger man ofte kommer ut for hvis man koder og er utvikling. Men det vi ser på, er liksom de prinsipielle delene av dette. Ok. Da skal vi se litt mer teoretisk på dette med scheduling og samtidige prosesser, og hvordan et operativsystem da styrer det. Det store bildet av hvordan et operativ styrer.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0018", "start": 1229.68, "end": 1318.22, "token_count": 286, "text": "hvis man koder og er utvikling. Men det vi ser på, er liksom de prinsipielle delene av dette. Ok. Da skal vi se litt mer teoretisk på dette med scheduling og samtidige prosesser, og hvordan et operativsystem da styrer det. Det store bildet av hvordan et operativ styrer. Ja, vi har allerede snakket mye om at det er viktig at to prosesser ikke må ødelegge for hverandre. To programmer som står og kjører. Samtidig, på samme CPU... Også delvis. Hvis de kjører på hver sin CPU, så må de f.eks. ikke skrive til samme del av minnet. For med multicore CPU-er så har vi jo samme minne. Så det må ikke være sånn at én prosess overskriver minnet for en annen. Så må det heller ikke være sånn at én CPU, nei, én prosess, hvis den ønsker det, at den kan kapre all... Den setter opp en løkke og bare jobber og jobber, og andre prosesser ikke får gjort noe. Og så kan det ikke være sånn at enkeltprosesser tar over hele CPU-en.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0019", "start": 1295.84, "end": 1383.44, "token_count": 294, "text": "Så må det heller ikke være sånn at én CPU, nei, én prosess, hvis den ønsker det, at den kan kapre all... Den setter opp en løkke og bare jobber og jobber, og andre prosesser ikke får gjort noe. Og så kan det ikke være sånn at enkeltprosesser tar over hele CPU-en. At de f.eks. får hele systemet til å fryse. I verste fall kjører kommandoen holdt og stopper hele systemet. Sånn kan det opplagt ikke være. ... løsninger opp gjennom tiden. En tidlig Windows-løsning, så var det sånn at man... Det var jo sånn Windows 95, hvor man begynte med multitasking. Så var det litt sånn at man hadde en frivillig operativstemme. Bare overlot hele CPU-en til en prosess. Men så måtte prosessen frivillig gi den fra seg. Men da var det klart med en gang det. Og et eller annet galt, så kunne hele systemet låse seg. Så etter hvert har alle moderne operativstemmer gått over til den beste løsningen, som er all makt til operativstemme, og som ofte kalles for preemptive multitasking.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0020", "start": 1359.1, "end": 1449.84, "token_count": 292, "text": "Men så måtte prosessen frivillig gi den fra seg. Men da var det klart med en gang det. Og et eller annet galt, så kunne hele systemet låse seg. Så etter hvert har alle moderne operativstemmer gått over til den beste løsningen, som er all makt til operativstemme, og som ofte kalles for preemptive multitasking. Og preemptive, det er... Opprinnelig så var det sånn i England at man skulle dele ut landområder til folk, til innbyggerne. På samme måte som Operativ Stem gjør det. Den deler ut rettigheter til innbyggerne i landet, som da er prosessene. Og hver får sin del, og hver får sin del av ram, av minne, og sin del av CPU. Så det vi skal se på nå, er hvordan kan Operativ Stem i praksis få til dette. Da er det ett prinsipp som er viktig. Operativstøy må ha litt hjelp fra Hardware for å kunne få til dette. Og en viktig bestanddel i den hjelpen er prosessormodus. Og alle moderne prosessorer har et modusbytt som er 011, og som begrenser hva som er lov å gjøre.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0021", "start": 1421.36, "end": 1512.92, "token_count": 300, "text": "Da er det ett prinsipp som er viktig. Operativstøy må ha litt hjelp fra Hardware for å kunne få til dette. Og en viktig bestanddel i den hjelpen er prosessormodus. Og alle moderne prosessorer har et modusbytt som er 011, og som begrenser hva som er lov å gjøre. Og det modusbyttet svitser imellom, det er da brukermodus og privilegier. Privilegert modus, eller cornal mode som det heter på engelsk. User mode og cornal mode. Dette kalles også ofte protection hardware. Og det er helt nødvendig for å kunne kjøre multitasking i det hele tatt. Hvis du ikke har noen forskjell på brukermodus og privilegert modus, så vil da i prinsippet enhver prosess kunne ta over kontrollen på systemet. Og da vil alt avhenge av at den prosessen gjør ting riktig og ikke fryser systemet. Det finnes systemer som er sånn. Vi skal se på unicunnels senere. Og da er det typisk at du har en kjerne som bare gjør én bestemt ting. F.eks. bare er webserver. Og da har man ikke brukere og andre prosesser osv. ", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0022", "start": 1485.32, "end": 1567.6, "token_count": 287, "text": "Og da vil alt avhenge av at den prosessen gjør ting riktig og ikke fryser systemet. Det finnes systemer som er sånn. Vi skal se på unicunnels senere. Og da er det typisk at du har en kjerne som bare gjør én bestemt ting. F.eks. bare er webserver. Og da har man ikke brukere og andre prosesser osv.  Da er det full kontroll til denne prosessen. Men den må da selvsagt ikke ødelegge systemet. Men dette med prosess og modus er veldig viktig i et generelt operativsystem som skal kjøre mange prosesser samtidig. Vi kommer ofte til å bruke ordet user mode, altså engelske betegnelsen på brukermodus. Og i user mode så er det begrenset aksess til ram. Og til instruksjoner. Så når CPU-en er switchet til use mode, så kan ikke alle instruksjoner utføres. F.eks. hvis du er i use mode og prøver å gjøre institusjonen holdt, eller stoppe maskinen, så blir den bare ignorert. Da skjer det ingenting. Og det er hovedhensikten med use mode.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0023", "start": 1550.04, "end": 1644.4, "token_count": 295, "text": "så kan ikke alle instruksjoner utføres. F.eks. hvis du er i use mode og prøver å gjøre institusjonen holdt, eller stoppe maskinen, så blir den bare ignorert. Da skjer det ingenting. Og det er hovedhensikten med use mode. Og det samme gjelder minne. Man får ikke tilgang til alt som er i minnet. I corner mode, eller privilegert modus, så kan alt... Alle institusjoner kan utføres, alt minne og alle registre, alt kan gjøres. Og det er opplagt her, i corner mode, der kjører operativsystemkjernen. Og det er hele ideen. Fra corner mode så kontrollerer operativsystemkjernen alt som skjer. Men... Selv om vi har kernel mode og use mode, hvordan kan operativstem effektivt kontrollere brukerprosessene? Det er et godt spørsmål i chatten som ofte dukker opp, og som er et veldig viktig poeng. Spørsmålet er... Hvis du gjør dette... Sudo PC-user, altså hvis du kjører et skript som RUT, med sudo, kjører du da skript i privilegert modus?", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0024", "start": 1615.44, "end": 1717.88, "token_count": 293, "text": "Det er et godt spørsmål i chatten som ofte dukker opp, og som er et veldig viktig poeng. Spørsmålet er... Hvis du gjør dette... Sudo PC-user, altså hvis du kjører et skript som RUT, med sudo, kjører du da skript i privilegert modus? Nei, det er det viktig at man ikke gjør. Det er en veldig stor forskjell på det å være RUT på en maskin, RUT eller administrator, og det å være operativkjerne. For Ruth har adgang til alle... Hva kan man si... Alle devices. Altså... Det vil si da alle filer, alle nettverkspakker som kommer inn. Og... Så alt dette har Ruth tilgang til. Den kan stoppe prosesser, og den kan gjøre alt mulig. Men den kjører ikke i den grunn av... Kernelmode, det er en modus som operativsystemkjernen kjører deg i. Hvis du er Rut og du starter opp en regnejobb, så kjører du ikke da i kernelmode. Du kjører i usermode. Så det er en veldig distinkt forskjell på operativsystemkjernen og det å være Rut eller administrator.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0025", "start": 1687.96, "end": 1777.58, "token_count": 289, "text": "Kernelmode, det er en modus som operativsystemkjernen kjører deg i. Hvis du er Rut og du starter opp en regnejobb, så kjører du ikke da i kernelmode. Du kjører i usermode. Så det er en veldig distinkt forskjell på operativsystemkjernen og det å være Rut eller administrator. Så har du full kontroll på alle deviser, men ikke på selve institusjonene inni kjernen. Det er det bare operativsystemkjernen som har. Det er et godt og viktig spørsmål. Men hvordan kan OS effektivt kontrollere brukerprosesser? Jo... Problemet er at vi kan ikke bare si til en prosess... OK. Nå har du full kontroll på denne CPU-en. Gjør hva du vil. For da får vi et problem hvis den prosessen da bare sier - holdt... Eller setter opp en nøkkel og bare står i en evig løkke og står og går. Men samtidig, hvis operativsystemet skal kontrollere hver eneste instruksjon som brukerprosessen utfører, en slags emulering, så gir det veldig mye system overhead. Selv om det på en måte er litt...", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0026", "start": 1760.0, "end": 1844.88, "token_count": 299, "text": "Eller setter opp en nøkkel og bare står i en evig løkke og står og går. Men samtidig, hvis operativsystemet skal kontrollere hver eneste instruksjon som brukerprosessen utfører, en slags emulering, så gir det veldig mye system overhead. Selv om det på en måte er litt... Det er litt det man kan se med virtuelle maskiner, med virtualisering, sånn som KVM og WMW osv. Men også med Java-virtuell maskin. Så finnes det systemer som på en måte kontrollerer alle institusjoner. Men så for igjen da... For å få det effektivt så ofte så til syvende og sist så ender det med at... Prosessene må få full kontroll på CPU-en. Må kunne gjøre hver institusjon uten et overhead. F.eks. sånn som den Fibonacci-rekken... Hvis vi skal utføre den prosessen effektivt, så kan ikke operativstemmene gå inn og kontrollere hver institusjon og se at den ikke gjør noe galt, i den koden. Så vi må prøve å finne en løsning på det problemet. Ja... Så... En effektiv løsning på dette problemet...", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0027", "start": 1824.4, "end": 1933.72, "token_count": 299, "text": "så kan ikke operativstemmene gå inn og kontrollere hver institusjon og se at den ikke gjør noe galt, i den koden. Så vi må prøve å finne en løsning på det problemet. Ja... Så... En effektiv løsning på dette problemet... Vi har allerede vært litt inne på det i prinsippet. Men ikke hvordan det i praksis utføres. Men den effektive løsningen, den går da ut på at man bruker en hardwaretimer. I systemet så er det en hardwaretimer som da gir et begrenset tidsinnstilling. I den simuleringen som ligger ute, så bruker jeg en sånn kjøkkenklokke. Der ringer hardware-timeren hvert minutt. Så der er den. Der tar det lang tid. Men her, når vi snakker om OS-hardware-timere, så er det typisk et hundredels sekund. Veldig ofte kommer det et sånt hardware-timer-tick. Og da er det sånn... ved hardware... Så når det kommer et tikk fra timeren, så switches det til... Skal vi se... Har vi sett for det riktige her... Hver gang hardware-timeren slår inn, så kommer operativsystemet inn.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0028", "start": 1897.96, "end": 2000.22, "token_count": 291, "text": "Og da er det sånn... ved hardware... Så når det kommer et tikk fra timeren, så switches det til... Skal vi se... Har vi sett for det riktige her... Hver gang hardware-timeren slår inn, så kommer operativsystemet inn. Da svisjes det til privilegert modus, eller kurl-mode, og så har kjernen kontrollen. Og så, i starten av dette tikket, så sier operativsystemet... Ok, nå skal den prosessen få lov å kjøre. Så da svisjer operativsystemet... Operativstemkjernen svisjer. Og så laster den inn den første instruksjonen. Det kan være Zikes lik 1. Det er typisk førsteinstruksjonen til koden som skal kjøre. Og så får den koden stå og kjøre i et hundredels sekund. Og hele hovedpoenget da er... Uansett hva den prosessen gjør, så vil den ikke kunne ødelegge systemet, for den vil da kjøre i brukermodus. Og det er helt ufarlig. Den kan ikke hvis en utfører holdt, så skjer det ingenting. Vi kan gå tilbake og se på den koden her.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0029", "start": 1975.4, "end": 2063.84, "token_count": 297, "text": "Og hele hovedpoenget da er... Uansett hva den prosessen gjør, så vil den ikke kunne ødelegge systemet, for den vil da kjøre i brukermodus. Og det er helt ufarlig. Den kan ikke hvis en utfører holdt, så skjer det ingenting. Vi kan gå tilbake og se på den koden her. Tenk deg nå - timeren går på. Operativsystemkjernen kommer inn. Det switches automatisk over til curl mode. Og første operativsystemkodelinje settes inn. Det operativsystemet gjør da, er å laste inn alt som er nødvendig for at denne prosessen skal begynne å kjøre. Og så switcher operativsystemet. For når du er i corner mode, da kan du switche til use mode. Men ikke motsatt. Så du er i corner mode, så switcher du til use mode, og så legger du denne instruksjonen inn i instruksjonsregisteret. Og så overlater du full kontroll til den prosessen. Så løper den prosessen opp og ned, opp og ned, opp og ned her milliarder av ganger, lager kjempemange ledd i femmodazji-rekken. Og så går det en timer.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0030", "start": 2047.96, "end": 2128.96, "token_count": 279, "text": "Og så overlater du full kontroll til den prosessen. Så løper den prosessen opp og ned, opp og ned, opp og ned her milliarder av ganger, lager kjempemange ledd i femmodazji-rekken. Og så går det en timer. Da kommer det en hardware timer inn etter 100 sekunder. Og idet hardware timeren kommer inn, så tar operativstemma over kontrollen igjen. Og på den måten så kan brukerprosesser kjøre Og utnytter CPU-en direkte, veldig effektivt og så mye det vil. Mens hvert hundredels sekund så kommer operativsystemet inn og tar over og sier OK, nå er det neste prosess som kjører. Så sånn kan operativsystemet da effektivt kontrollere brukerprosessene på en sikker måte uten at brukerprosessene kan f.eks. skru av helmaskinen. Dette er et minnekart, altså det bildet av ramm, på hvordan brukermodus og privilegertmodus eller corner mode ser ut på rammenivå. Og da tenker vi oss at vi har her øverst...", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0031", "start": 2099.6, "end": 2187.36, "token_count": 287, "text": "på en sikker måte uten at brukerprosessene kan f.eks. skru av helmaskinen. Dette er et minnekart, altså det bildet av ramm, på hvordan brukermodus og privilegertmodus eller corner mode ser ut på rammenivå. Og da tenker vi oss at vi har her øverst... Så har vi den delen av minnet som er tilgjengelig fra brukermodus. Det er typisk brukerdata og vanlige programmer. Men så er det også noe av operativsystemkjernen. Ikke operativsystemkjernen, men noe av operativsystemet. Altså den delen av operativsystemet som er utenfor kjernen. Det kan være system software som ikke nødvendigvis trenger å gjøre privilegerte institusjoner. Som ikke trenger det, men som utfører en del jobb, akkurat som et vanlig program utfører. Men så har du den privilegerte delen av minnet som utgjør OS-kjernen. Og her er det opplagt... Her kan ikke vanlige brukerprogrammer... De kan ikke få aksess her inne. For da kunne de endre på operativstemme og ødelegge alt.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0032", "start": 2166.04, "end": 2270.04, "token_count": 300, "text": "akkurat som et vanlig program utfører. Men så har du den privilegerte delen av minnet som utgjør OS-kjernen. Og her er det opplagt... Her kan ikke vanlige brukerprogrammer... De kan ikke få aksess her inne. For da kunne de endre på operativstemme og ødelegge alt. Det ville være en hackers drøm å kunne få tilgang til OS-kjernen.  For da kan du virkelig endre planen for alt. Så det må utgås. Og da er det igjen sånn at når modusbytt switcher til brukermodus, og en prosess prøver å endre på noe i denne adressen her, i ram, Hvis en prosess prøver å endre på noe i RAM som tilhører en annen prosess, så får den heller ikke lov. Så dette ville være styrt. Men den privilegerte delen av mine, den er det helt umulig å touche. Så på den måten kontrollerer da operativsystemet alle prosessene, både CPU og RAM, ved hjelp av brukermodus og... OK. Da skal vi se på det andre viktige prinsippet i dag, og det er systemkall. Men da ser vi at vi trenger en pause.", "source": "lecture"}
{"lecture_id": "os8time1", "chunk_id": "os8time1_0033", "start": 2243.56, "end": 2279.0, "token_count": 110, "text": "Men den privilegerte delen av mine, den er det helt umulig å touche. Så på den måten kontrollerer da operativsystemet alle prosessene, både CPU og RAM, ved hjelp av brukermodus og... OK. Da skal vi se på det andre viktige prinsippet i dag, og det er systemkall. Men da ser vi at vi trenger en pause. Så da tar vi et kvarter pause før vi starter med systemkall.", "source": "lecture"}
{"lecture_id": "linux10del7", "chunk_id": "linux10del7_0000", "start": 0.0, "end": 96.46, "token_count": 293, "text": "Da skal vi se på to typer hypervisor, type 1 og type 2. Det er litt flytende skiller mellom de, men det er ett poeng som er viktig, og det er at type 1 hypervisor... Det er på en måte en helt selvstendig hypervisor som kjører... Oppå hardware, direkte. Sånn som med WMWare, f.eks. Hvis du skal virtualisere med WMWare, så må du installere WMWare på en server, og så etterpå så installerer du virtuelle maskiner oppå det. Det samme gjelder Send og Hyperware, Microsofts virtualisering. Da setter de opp en hypervisor i bunnen her, og så... Oppå den kan man kjøre forskjellige operativstemmer. Sånn som Windows, Linux og andre OS. Og her ser vi at det går fint å kjøre Windows og Linux på samme Hypoviser. For Hypervisoren tilbyr bare CPU, ram og IO. Den tilbyr bare grensesnittet som hardware gir. Og ikke noe annet. Så da er det ved ekte virtualisering... Så er det ikke noe problem å kjøre Windows. Og Linux som to VM-er ved siden av hverandre oppå på den samme hypervisoren.", "source": "lecture"}
{"lecture_id": "linux10del7", "chunk_id": "linux10del7_0001", "start": 73.0, "end": 173.12, "token_count": 295, "text": "For Hypervisoren tilbyr bare CPU, ram og IO. Den tilbyr bare grensesnittet som hardware gir. Og ikke noe annet. Så da er det ved ekte virtualisering... Så er det ikke noe problem å kjøre Windows. Og Linux som to VM-er ved siden av hverandre oppå på den samme hypervisoren. Her vil det være sånn at alle sensitive instruksjoner som utføres i juss-mode, de trapper til kernel-mode og fanges opp av hypervisor. Så... Og vi kan si at hypervisor kjører direkte på hardbet. Type 2 hypervisor er litt annerledes. For da... Da har man et eksisterende OS. Her har du et OS sånn som f.eks. Linux, som kjører direkte på hardware. Det som vi har her nede, det er et standard Linux-oppsett. Men så... Så ser vi at man får en type to... Ops. Unnskyld hvis jeg skrur av litt lyd her. Du kjører oppå Linux. Dette vil du f.eks. se med KVM. Virtual Box er en annen sånn løsning. I praksis vil man rett og slett starte en hypervisor. I KVM har du en Kemu hypervisor.", "source": "lecture"}
{"lecture_id": "linux10del7", "chunk_id": "linux10del7_0002", "start": 136.52, "end": 248.76, "token_count": 287, "text": "Men så... Så ser vi at man får en type to... Ops. Unnskyld hvis jeg skrur av litt lyd her. Du kjører oppå Linux. Dette vil du f.eks. se med KVM. Virtual Box er en annen sånn løsning. I praksis vil man rett og slett starte en hypervisor. I KVM har du en Kemu hypervisor. På Linux OS så starter man en prosess som heter Kemu. Det imaget kan være en Linux-VM, eller en Windows-VM. Da er det en prosess som står der og kjører på Linux-operativsystemet. Mens Host-OS kan ha andre prosesser som kjører sammen med Hypervisor. Men dette ser jo da veldig lite effektivt ut. Vi skal se noen resultater. Som viser hvor lite effektivt det er. Hvis det kjører kun som en fortolker... Hvis denne hypervisoren ikke får hjelp av kjernemoduler, så vil dette gå veldig sakte. For da må på en måte... Dette vil da bli en emulering av hardware. Og det er for tungt i praksis. Det som redder dette opplegget, er at her nede så har du KVM.", "source": "lecture"}
{"lecture_id": "linux10del7", "chunk_id": "linux10del7_0003", "start": 220.66, "end": 307.0, "token_count": 287, "text": "Hvis denne hypervisoren ikke får hjelp av kjernemoduler, så vil dette gå veldig sakte. For da må på en måte... Dette vil da bli en emulering av hardware. Og det er for tungt i praksis. Det som redder dette opplegget, er at her nede så har du KVM. Cornal Virtual Machine. Det er altså kjernemoduler som hjelper Linux med å gjøre dette her mer effektivt. Man kan si at kjernemodulene gjør at det ligner mer på dette. Altså at hypervisoren kjører rett på ram. Sånn at... Prosessen her oppe kan kjøre mer effektivt på hardware. Det man ønsker er at hvis det er en Windows-applikasjon som legger sammen tall, så ønsker man at de institusjonene skal kjøre rett på CPU. Det får man også til. Nå er det mange lag imellom her, men på samme måte som en applikasjon som kjører på Linux, hvis den legger sammen tall, så står ikke Linux og kontrollerer hver institusjon. Det Linux gjør, er at den sørger for at koden til denne applikasjonen her oppe,", "source": "lecture"}
{"lecture_id": "linux10del7", "chunk_id": "linux10del7_0004", "start": 288.32, "end": 384.1, "token_count": 300, "text": "Nå er det mange lag imellom her, men på samme måte som en applikasjon som kjører på Linux, hvis den legger sammen tall, så står ikke Linux og kontrollerer hver institusjon. Det Linux gjør, er at den sørger for at koden til denne applikasjonen her oppe, den blir lagt direkte i CPU-en og utføres fort som bare det. Og det samme klarer man ved hjelp av kjernemoduler å få til her også. At det meste av koden vil kjøre direkte på hardware. Men Hypervisor vil hele tiden kontrollere, og ikke minst hvis Gjeste-OS, Gjør et kall til kjernen, så vil det trappe til hypervisor. Og så tar den kontroll. OK. Vi skal se noen eksempler på KVM-virtualisering litt senere. Binær oversettelse. Før 2005 så måtte alternative metoder brukes uten hardwarestøtte. At hvis man ikke gjorde det, så fikk man problemer med de institusjonene som ikke trappet. Da lagde VMWer en hypervisor som mens programmet kjørte, så skannet den koden og så etter sensitive instruksjoner. Typisk sensitive institusjoner som ikke trapper til kjernen.", "source": "lecture"}
{"lecture_id": "linux10del7", "chunk_id": "linux10del7_0005", "start": 360.02, "end": 465.94, "token_count": 293, "text": "At hvis man ikke gjorde det, så fikk man problemer med de institusjonene som ikke trappet. Da lagde VMWer en hypervisor som mens programmet kjørte, så skannet den koden og så etter sensitive instruksjoner. Typisk sensitive institusjoner som ikke trapper til kjernen. Da gjorde den det for hver kodeblokk som endte i jump, call, trap eller lignende. Hvor du ønsket å snakke med kjernen. Så ble disse sensitive institusjonene oversatt til kall i WMW-prosedyrer inni hypervisoren. Og da fikk man til å kunne kjøre disse kodebitene veldig effektivt. Og i enkelte tilfeller så kunne han faktisk få det til å kjøre enda mer effektivt enn om man kjørte direkte på bare metal. Et problem med hardware-støttet virtualisering er at det genererer mange traps. Hver gang Gjeste-OS gjør et kall som trapper, så tar det litt ekstra tid. Paravirtualisering er en type virtualisering som gjør at gjeste-OS må endres. Derfor er ikke det helt optimalt, for da må man inn og gjøre endringer i gjeste-OS.", "source": "lecture"}
{"lecture_id": "linux10del7", "chunk_id": "linux10del7_0006", "start": 420.0, "end": 484.0, "token_count": 158, "text": "Et problem med hardware-støttet virtualisering er at det genererer mange traps. Hver gang Gjeste-OS gjør et kall som trapper, så tar det litt ekstra tid. Paravirtualisering er en type virtualisering som gjør at gjeste-OS må endres. Derfor er ikke det helt optimalt, for da må man inn og gjøre endringer i gjeste-OS. Det som kan være en fordel, er at da kan man ha egne drivere som er laget for paravirtualisering, og det er en veldig effektiv metode. Men stort sett brukes det ikke så mye. Det er viktig at vi tåler det selv.", "source": "lecture"}
{"lecture_id": "os2del15", "chunk_id": "os2del15_0000", "start": 0.0, "end": 83.72, "token_count": 295, "text": "OK. Vi startet ut med at vi ønsket å lage en krets som utfører binær addisjon mellom to binære tall. Og det vi må gjøre da, er at vi må... implementere denne algoritmen for å legge sammen binært. Det må vi implementere med logiske funksjoner. Etter det kan vi tegne en krets som utfører det vi ønsker. Da må vi først se på hvordan virker binær adhesjon. Den virker nøyaktig som, om dere ikke har gjort dette før, så er metoden nøyaktig sånn som når man legger sammen desimaltall. Med mente osv. Vi kan se på hvordan vi legger sammen to tall her. Dette er 01 pluss 11. 01 er jo tallet 1. Det er en null toere og en ener. Og så legger man til en toer og en ener, som er tallet tre. Da kan man gjøre det ved å rett og slett... Man starter her med én pluss én. Én pluss én er jo to, men binært så er én pluss én én null. Så vi får da én null, og null er det siste sifferet, så det skrives ned her.", "source": "lecture"}
{"lecture_id": "os2del15", "chunk_id": "os2del15_0001", "start": 68.36, "end": 138.44, "token_count": 293, "text": "Da kan man gjøre det ved å rett og slett... Man starter her med én pluss én. Én pluss én er jo to, men binært så er én pluss én én null. Så vi får da én null, og null er det siste sifferet, så det skrives ned her. Og så kommer det én i mente opp hit. Og så gjør man akkurat samme operasjonen på neste to siffer. Da er det en ener der, en null der og en ener der. Så det blir igjen 1 pluss 1 er 2, og 2 er 1,0. Så da kommer det en mente opp hit, og så kommer denne eneren ned hit. Og så får man svaret 1,00. Og 1,00, det er da 4. Så det vi har gjort nå, er å regne ut 1 pluss 3 er lik 4. Tilsvarende algoritme kan man da bruke på appen. Absolutt alle binære addisjoner. Om du har 64-bit, så kjører du da denne algoritmen, den med mente, 64 ganger. Og så får du ut svaret. Og det vi skal se på nå, er da...", "source": "lecture"}
{"lecture_id": "os2del15", "chunk_id": "os2del15_0002", "start": 114.68, "end": 159.14, "token_count": 171, "text": "Tilsvarende algoritme kan man da bruke på appen. Absolutt alle binære addisjoner. Om du har 64-bit, så kjører du da denne algoritmen, den med mente, 64 ganger. Og så får du ut svaret. Og det vi skal se på nå, er da... Ja, men hva om vi kan lage en krets som gjør akkurat denne operasjonen her? Ta mente og de to sifferne, og så får du ut et svar og et mente. Og det er akkurat det man gjør. Man lager 64. Så setter man sammen de 64 kretsene, og vips så har du en aderi som kan legge sammen 64-bitstall.", "source": "lecture"}
{"lecture_id": "linux9del3", "chunk_id": "linux9del3_0000", "start": 0.0, "end": 114.58, "token_count": 288, "text": "Vi kan starte med PØL, som dere kanskje ikke har så stort tett forhold til. Bare for å forklare hvordan dette ser ut. Ja, her ser vi... Nei, dette var POP. Her ser vi POP-koden. Så denne POP-koden gjør dette, som er nøyaktig det samme som... Den har klart å gjøre dette 400 ganger på samme tid. Det betyr at POP-koden er 400 ganger så raskt som skjellskriftet. Så POP er oppe som en kandidat til å være raskest. Vi kan prøve å ta alle under én kamp. Jeg tror det står times equal i alle filene. Så jeg kan prøve å greppe på times equal. Og da får vi på en måte opp en resultatliste, hvis vi nå sorterer etter det største tallet. Og da ser vi... Vi kan komme tilbake til den. Men vi ser faktisk at av de som vi har kjørt, så er Java det raskeste programmet. Det er kanskje ganske overraskende. Det var bare fire av dere som trodde det. Java er 20 000 ganger raskere enn Skjellskriftet.", "source": "lecture"}
{"lecture_id": "linux9del3", "chunk_id": "linux9del3_0001", "start": 90.0, "end": 186.72, "token_count": 291, "text": "Vi kan komme tilbake til den. Men vi ser faktisk at av de som vi har kjørt, så er Java det raskeste programmet. Det er kanskje ganske overraskende. Det var bare fire av dere som trodde det. Java er 20 000 ganger raskere enn Skjellskriftet. Så det viktigste å ta med seg her fra dette, er at det er en... Ekstrem forskjell i regnekraft på programmeringsspråk som Java og C sammenlignet med et Shellscript. Shellscript er ekstremt trege til denne type oppgaver. På andreplass her så ser vi C-programmet kommer. Og på... skal vi se... ja, tredjeplass... Så kommer POP med 400, som vi så. Ganske overraskende så ser vi at Pyton også er vesentlig tregere enn f.eks. C. Vi ser at det er en faktor på 100 her. Så å kjøre dette i C og Java går mer enn 100 ganger så fort som om man kjører det i Pyton. En spearl er omtrent like rask som Pyton. Hvilken er den som har 28 000? Ja, det kommer jeg tilbake til.", "source": "lecture"}
{"lecture_id": "linux9del3", "chunk_id": "linux9del3_0002", "start": 164.2, "end": 259.84, "token_count": 294, "text": "Vi ser at det er en faktor på 100 her. Så å kjøre dette i C og Java går mer enn 100 ganger så fort som om man kjører det i Pyton. En spearl er omtrent like rask som Pyton. Hvilken er den som har 28 000? Ja, det kommer jeg tilbake til. Så... Det første vi kan lære her, er at det er veldig stor forskjell. Og delvis skyldes dette at språk som Python, POP og Pearl er interpretert. Det betyr at de tolkes, så de kjører ikke kode direkte på CPU. Men også Java. Ved hjelp av just in time compiling, så vil Java kunne optimalisere, sånn at den i praksis kjører kode rett på CPU-en. Dvs. at det ikke er noen virtuell maskin imellom som først tolker koden, og så kjører den. Dette gjør at disse programmene er ganske mye tregere. Da kommer jeg tilbake til 28 000. For som vi så, så gikk faktisk sånn default, så gikk C-programmet saktere enn jeg var. Og det er det mange som stusser på, med god grunn, for man har alltid hørt", "source": "lecture"}
{"lecture_id": "linux9del3", "chunk_id": "linux9del3_0003", "start": 240.0, "end": 339.48, "token_count": 292, "text": "Da kommer jeg tilbake til 28 000. For som vi så, så gikk faktisk sånn default, så gikk C-programmet saktere enn jeg var. Og det er det mange som stusser på, med god grunn, for man har alltid hørt at C og C pluss pluss, det er det raskeste som fins. Og det stemmer faktisk også. Men det vi har glemt å tenke på her, er... Når jeg kompilerer C-programmet på den måten her, og kjører det, så er GCC optimalisert for å kompilere raskt. Og det er ikke optimalisert for å gi rask kode. Derfor så har jeg da lagd en sum O, hvor O står for optimalisert. Og hvis man... Det er da samme koden. Hvis man kompilerer den... Og kjører. Så får man en optimalisert ferdig kode som går raskest mulig. Den gikk da litt under fem sekunder, men hovedpoenget med dette var at der kom tallet 28 000, som faktisk skulle vært litt større. Vi ser at vi kunne kanskje kommet opp i 35 000 med denne her. Så C er faktisk den...", "source": "lecture"}
{"lecture_id": "linux9del3", "chunk_id": "linux9del3_0004", "start": 300.0, "end": 396.54, "token_count": 297, "text": "Og kjører. Så får man en optimalisert ferdig kode som går raskest mulig. Den gikk da litt under fem sekunder, men hovedpoenget med dette var at der kom tallet 28 000, som faktisk skulle vært litt større. Vi ser at vi kunne kanskje kommet opp i 35 000 med denne her. Så C er faktisk den... Det aller raskeste språket. Og vi ser her i kommentaren at det er nesten sju ganger raskere med minus O. Så det jeg kan... Ja, og i oppgaven denne uken, så... Så blir dere bedt om å tilpasse disse programmene til å kjøre på dokker. Jeg kommer tilbake til dokker etterpå og ser hvordan det går der. Men tanken er da at hvis tiden ikke er helt den samme som her, så må dere prøve å tilpasse tallene sånn at dere får et antall ganger i dokker på Linux-VM. For det vil være litt forskjell på dette her. Hvis vi kjører det rett over, så skal vi se at ikke alle går på på samme tid. Måten man kan gjøre det på, den kan vi prøve å illustrere her, er at vi ser...", "source": "lecture"}
{"lecture_id": "linux9del3", "chunk_id": "linux9del3_0005", "start": 383.56, "end": 473.5, "token_count": 297, "text": "For det vil være litt forskjell på dette her. Hvis vi kjører det rett over, så skal vi se at ikke alle går på på samme tid. Måten man kan gjøre det på, den kan vi prøve å illustrere her, er at vi ser... Dette programmet, SumO.c, det burde kjørt litt flere ganger. For det skal opp i 5,5 sekunder. Så det man kan gjøre da, at man kan regne ut tiden det tok på skjellskriftet, som er ca. 5,5. Og så kan man dele på 3,69, som er tiden C-programmet bruker. Da skal vi få 1,5. R er for øvrig en liten schellscript som gjør at det kan regne i kommandolinjen. Jeg får nå 1,5, og det betyr at da kan faktisk dette programmet klare å kjøre 1,5 ganger... Jeg kan ta 1,5 ganger... 28 000. Da ser vi at jeg får 42 000. Så tanken er da... Ok, da går jeg inn i sumo.c. Og så endrer jeg den til 42 000. Sånn. Så tar jeg og kompilerer på nytt med GCC.", "source": "lecture"}
{"lecture_id": "linux9del3", "chunk_id": "linux9del3_0006", "start": 438.42, "end": 554.74, "token_count": 291, "text": "Jeg får nå 1,5, og det betyr at da kan faktisk dette programmet klare å kjøre 1,5 ganger... Jeg kan ta 1,5 ganger... 28 000. Da ser vi at jeg får 42 000. Så tanken er da... Ok, da går jeg inn i sumo.c. Og så endrer jeg den til 42 000. Sånn. Så tar jeg og kompilerer på nytt med GCC. Nå har jeg endret times, sånn at også denne tar 5,5 sekunder. Så den riktige fasiten nå er at C, optimalisert C-kode, er 42 tuner. Det er ganske enorm forskjell. Så... dette er det viktig å ha med seg når man ser på... når man vurderer hvilket språk man skal velge for å gjøre denne oppgaven. Med en gang det har noe med regning å gjøre, Så er det fornuftig å velge C eller C++. C++ er omtrent like raskt som C. Alternativt Java, som pga. Just in time compiler også er veldig raskt. Den vi ser her nå, er i dette tilfellet dobbelt så raskt som Java.", "source": "lecture"}
{"lecture_id": "linux9del3", "chunk_id": "linux9del3_0007", "start": 535.74, "end": 607.3, "token_count": 207, "text": "Så er det fornuftig å velge C eller C++. C++ er omtrent like raskt som C. Alternativt Java, som pga. Just in time compiler også er veldig raskt. Den vi ser her nå, er i dette tilfellet dobbelt så raskt som Java. OK. Hvis vi går og ser på det dere svarte i utgangspunktet, så... Så er det opplagt at det er ikke så lett å... Eller generelt så har man ikke så mye intuisjon på hvor raskt ting går. Men det er en veldig stor forskjell, så det er det greit å huske å ha med seg videre. Vi skal se etterpå, etter pausen, at resultatene er veldig forskjellige. Så man kan ikke ta dette resultatet og bruke som det er. Dette gjelder kun for CPU-intensive jobber.", "source": "lecture"}
{"lecture_id": "linux3del10", "chunk_id": "linux3del10_0000", "start": 0.0, "end": 104.42, "token_count": 298, "text": "Vi skal nå se på subshelt, som er en konstruksjon som kan være veldig nyttig i mange tilfeller. Jeg skal vise den med et eksempel på et problem som vi kan løse. Da tenker vi oss først at vi har to filer med noe tekstig. 1, 2, 3, f.eks. Og jeg lager en fil 2, som skriver noen tall i litt annen rekkefølge. Sånn. Og så tenker vi oss nå at vi ønsker å sortere disse filene. Ser hvis jeg sorterer fil 2, så får jeg 1, 4, 2, 3 - riktig alfabetisk. Men så kunne det kanskje være at jeg ønsker å sortere begge disse filene samtidig. Slå dem sammen. Uten eksplisitt å legge dem inn i samme file, vil det være mulig å gjøre. Da kan jeg sende output av begge to ut i terminal på den måten her. Og hele denne listen her ønsker jeg å sortere. Det er klart. Jeg kunne prøve å sende dette til... Legge det inn i samme fil og så sortere. Men jeg skulle ta de to kommandoene opp ut fra de to kommandoene og sortere.", "source": "lecture"}
{"lecture_id": "linux3del10", "chunk_id": "linux3del10_0001", "start": 84.9, "end": 174.8, "token_count": 296, "text": "Og hele denne listen her ønsker jeg å sortere. Det er klart. Jeg kunne prøve å sende dette til... Legge det inn i samme fil og så sortere. Men jeg skulle ta de to kommandoene opp ut fra de to kommandoene og sortere. Og da tenker vi jo at da kunne vi gjøre sånn - sort - for å få sortert begge to. Men da viser det seg at da får jeg ikke sortert i starten her. 1, 2, 3. Altså den... Den første filen skrives ut til terminal. 1, 2, 3... Og så etterpå utføres kommando nummer 2. Og så... Den, da sorteres fil 2. Men den samsorteres ikke med den andre filen. Så måten vi kan løse det på, er å bruke denne konstruksjonen her, som gir en... Som gir en subkommando... Det ligner litt på sånn når man... Når man skal kjøre en kommando og så legge den i en variabel og legge på en dollar her, men her... Her lager vi et subshell. Det som kommer inn i parentes her... Det startes da opp et lite skjell som de to kommandoene kjøres i.", "source": "lecture"}
{"lecture_id": "linux3del10", "chunk_id": "linux3del10_0002", "start": 150.0, "end": 200.22, "token_count": 175, "text": "Som gir en subkommando... Det ligner litt på sånn når man... Når man skal kjøre en kommando og så legge den i en variabel og legge på en dollar her, men her... Her lager vi et subshell. Det som kommer inn i parentes her... Det startes da opp et lite skjell som de to kommandoene kjøres i. Og så sendes alt opp ut fra det videre. Og dermed så ser vi at de får... Slått sammen output fra de to, og så får vi en samsortering. Så hele hovedpoenget her er at vi lager et subcell hvor alt dette utføres. Og så kan vi pipe og bruke output fra det subscellet videre som vi måtte ønske.", "source": "lecture"}
{"lecture_id": "os5del7", "chunk_id": "os5del7_0000", "start": 0.0, "end": 93.96, "token_count": 289, "text": "Skal vi se... Jo... Her ser vi at man trenger to linjer kode for å gjøre en høynivålinje svar, leksvar pluss memoer. Men hva hadde vi trengt å gjøre dette her? Move memoer til RBX, og så add RBX? Kunne vi ikke rett og slett kommentert den, og så bare tatt... Istedenfor å flytte memoer til RBX først, så kunne vi bare... For da ville det blitt én linje maskinkode som gjorde akkurat den jobben med å legge sammen de to. Den linjen her, det er jo bare for å returnere. Så dette ville da gjøre den operasjonen i to... Nei, i én institusjon. Men da kan vi prøve å se hva som skjer. Hvis jeg... Ja, nå kan jeg jo... Jeg kan gjøre sånn, og da ser vi... Assemble message. Too many memory references for that. Og dette gjenspeiler da... Dette gjenspeiler da at X86-arkitekturen har ikke en sånn institusjon som kan legge sammen to referanser i minnet samtidig. Du kan ikke ta to variabler og legge sammen på den måten.", "source": "lecture"}
{"lecture_id": "os5del7", "chunk_id": "os5del7_0001", "start": 73.48, "end": 129.1, "token_count": 188, "text": "Og dette gjenspeiler da... Dette gjenspeiler da at X86-arkitekturen har ikke en sånn institusjon som kan legge sammen to referanser i minnet samtidig. Du kan ikke ta to variabler og legge sammen på den måten. Og det er rett og slett fordi at det kan ikke ha noe med å gjøre. I prinsippet så kunne man ha lagd X86-arkitekturen sånn at det var mulig, men man har funnet det hensiktsmessig å ikke bruke den type operasjoner. Men det er det da viktig å vite, sånn at kode som dette her, det vil da nødvendigvis... Medføre at man må lage to uavhengige institusjoner i maskinkoden når den...", "source": "lecture"}
{"lecture_id": "linux9del8", "chunk_id": "linux9del8_0000", "start": 0.0, "end": 97.56, "token_count": 300, "text": "Et problem som dukket opp da jeg hadde forelesning i fjor, som jeg da ikke skjønte helt, er hvis man prøver å gjøre en sånn match og så legger inn et mellomrom, så vil du se at jeg får en feilmelding. Det betyr at denne måten å skrive regulære uttrykk på i skjellet ikke er helt safe. Det er noen ganger det ikke funker, og det er det viktig å ha med seg. En bedre måte å gjøre dette her på er følgende. Vi kan først se på hvorfor. Jo, som dere har sett, så er skjellet ofte veldig hårsårt når det gjelder mellomrom og så videre. Og et problem her er at dette blir da tolket av skjellet. Måten man løser det på, er i stedet å alltid skrive, definere, et regulært uttrykk i en variabel på denne måten. Mellom to enkeltapostrofer. Hvis jeg skal ha med et mellomrom i det regulære uttrykket, så tar jeg det sånn. Og definerer nå det regulære uttrykket på den måten. En frittstående streng som det som matcher mot det regulære uttrykket.", "source": "lecture"}
{"lecture_id": "linux9del8", "chunk_id": "linux9del8_0001", "start": 75.28, "end": 161.0, "token_count": 280, "text": "Mellom to enkeltapostrofer. Hvis jeg skal ha med et mellomrom i det regulære uttrykket, så tar jeg det sånn. Og definerer nå det regulære uttrykket på den måten. En frittstående streng som det som matcher mot det regulære uttrykket. På mange måter er det en mer ryddig måte å skrive en match på. Og da ser vi... Nå fungerer det. Vi får en match fordi hei og... Vi ser det er et mellomrom der, så det burde virke. Vi kan f.eks. se hvis jeg gjør det. Så får jeg ikke noe match. Og da kan man stille seg spørsmål om hvorfor man ikke får noe match her. Hvorfor får jeg ikke en hei og...? Jo, fordi regulære uttrykk er veldig presise. Du er nødt til å matche nøyaktig det som står. Og vi ser at i linje her oppe, så er det ikke to mellomrom, et etternavn. Så ser vi. Da får vi en match. Da matcher High Og inni her. Så kommer det to mellomrom, så kommer hun.", "source": "lecture"}
{"lecture_id": "linux9del8", "chunk_id": "linux9del8_0002", "start": 134.76, "end": 167.8, "token_count": 106, "text": "veldig presise. Du er nødt til å matche nøyaktig det som står. Og vi ser at i linje her oppe, så er det ikke to mellomrom, et etternavn. Så ser vi. Da får vi en match. Da matcher High Og inni her. Så kommer det to mellomrom, så kommer hun. Så generelt så må man være veldig nøyaktig med å matche akkurat det som står.", "source": "lecture"}
{"lecture_id": "os11del4", "chunk_id": "os11del4_0000", "start": 0.0, "end": 128.12, "token_count": 284, "text": "Da skal vi se på prioritet i Java. Da skal vi se på et annet eksempel. Og prioritet i Java er... Det vi skal se, er at prioritet er litt merkelig implementert på en måte i Java. I Linux og i Windows, f.eks. Java burde være helt plattformuavhengig. Men i dette eksempelet skal vi se at det faktisk ikke er det. Men før vi diskuterer det, så kan vi se på... Skal vi se... Jeg har et Java-program som heter prio.java. Dette programmet implementerer da prioritet. Og det ligner ganske på de andre programmene vi har sett på. I dette tilfellet så startes det to tråder. Prioritredd én som jeg kaller S1, og én som jeg kaller S2. Først starter jeg tråd nummer 1, S1, og så setter jeg prioriteten til 5. Det er faktisk default-prioritet, så hvis jeg ikke hadde gjort det, så ville den likevel vært 5. Og så er det noen variabler. SN Norm Priority, jeg skriver ut den. Eller standard. Og så ser vi... Jeg skriver ut maks prioritet og min prioritet.", "source": "lecture"}
{"lecture_id": "os11del4", "chunk_id": "os11del4_0001", "start": 90.0, "end": 184.2, "token_count": 282, "text": "Først starter jeg tråd nummer 1, S1, og så setter jeg prioriteten til 5. Det er faktisk default-prioritet, så hvis jeg ikke hadde gjort det, så ville den likevel vært 5. Og så er det noen variabler. SN Norm Priority, jeg skriver ut den. Eller standard. Og så ser vi... Jeg skriver ut maks prioritet og min prioritet. Maks prioritet er ti, hvis jeg husker riktig, og min er én. Så dette er motsatt av nice, for nice er jo hvor snill man er med andre. Så det er ti prioritetsklasser. Ja, min er null. Vi starter på null, og så er jeg maks ti. Så... Nei... Sorry. Glem det jeg sa. Dette er bare en... Dette er ikke prioriteten. Det som jeg sender med der, er antall millisekunder som tråden skal sove før den starter. Vi ser begge starter med en gang. Men jeg setter prioriteten for tråd nummer to. Den setter jeg til ti. Så vi starter én tråd med prioritet fem og én med prioritet ti. Ti er det aller høyeste, så da burde man forvente", "source": "lecture"}
{"lecture_id": "os11del4", "chunk_id": "os11del4_0002", "start": 167.08, "end": 239.96, "token_count": 274, "text": "Vi ser begge starter med en gang. Men jeg setter prioriteten for tråd nummer to. Den setter jeg til ti. Så vi starter én tråd med prioritet fem og én med prioritet ti. Ti er det aller høyeste, så da burde man forvente at et eller annet skjer sånn at tråd nummer to kjører mer. Vi har jo bedt om at den skal få høyere prioritet. Vi kan se kjapt øverst hva vi gjør, og det vi gjør, ligner veldig på det vi gjorde tidligere. Vi har en telle-count og en ID, så de får ID 1 og 2. Og så i tillegg har jeg millisekunder. Det skal vi bruke på Windows etterpå, når vi skal kjøre det der. Der skal vi gi tråden noen millisekunder før den starter. Men vi gir den null millisekunder her, sånn at det er lettere å se hva som skjer i vårt tilfelle. Så vi kan jo også se hvordan vi behandler to forskjellige tråder. For de kjører i utgangspunktet samme gode, men så ser vi...", "source": "lecture"}
{"lecture_id": "os11del4", "chunk_id": "os11del4_0003", "start": 220.16, "end": 313.96, "token_count": 295, "text": "Men vi gir den null millisekunder her, sånn at det er lettere å se hva som skjer i vårt tilfelle. Så vi kan jo også se hvordan vi behandler to forskjellige tråder. For de kjører i utgangspunktet samme gode, men så ser vi... Her er Rønn-metoden, som sier tråd nummer én sove først, null millisekunder, og så starter den. Men så ser vi... Her har jeg en if-test hvor jeg da tester hvis ID er lik to, så setter jeg prioritet til én. Så på den måten kan man da behandle tråder og gjøre forskjellige ting, selv om trådene i utgangspunktet er like. Så vi kan se hvordan dette ser ut når vi kompilerer og... ... kjører denne tråden. Så da ser vi. Vi starter defolt prioritet til 5. Vi starter nummer 1 med prioritet 5. Og så starter nummer 2 med prioritet 5. Men vi ser de kjører annenhver gang. Det går akkurat like fort med nummer én som med nummer to. Og så går vi ned her og så setter vi prioriteten for tråd nummer to.", "source": "lecture"}
{"lecture_id": "os11del4", "chunk_id": "os11del4_0004", "start": 292.48, "end": 408.56, "token_count": 294, "text": "Vi starter nummer 1 med prioritet 5. Og så starter nummer 2 med prioritet 5. Men vi ser de kjører annenhver gang. Det går akkurat like fort med nummer én som med nummer to. Og så går vi ned her og så setter vi prioriteten for tråd nummer to. Den setter vi til én, så da burde den ha minst prioritet. Én er da det minste, men likevel så ser vi at disse to jobber akkurat like fort. Hvis vi prøver å se på topp når de jobber, så får begge 100 % CPU. Vi har ikke noe nice eller noe sånt der. Men vi har jo også sett tidligere at hvis man har nice-prosesser, så vil det ikke være nice i forhold til... Så det vi kunne prøve å gjøre, var å starte trådene med TaskSet. Det har jeg faktisk ikke tenkt på tidligere, men vi kan gjøre et forsøk. Hvis jeg nå ser på Last Use TPU... Og så kan jeg prøve å starte Java med TaskSet. Aset minus 1,0. Sånn. Og så H... Da ser vi begge trådene kjører på tråd 0.", "source": "lecture"}
{"lecture_id": "os11del4", "chunk_id": "os11del4_0005", "start": 376.04, "end": 491.92, "token_count": 297, "text": "Hvis jeg nå ser på Last Use TPU... Og så kan jeg prøve å starte Java med TaskSet. Aset minus 1,0. Sånn. Og så H... Da ser vi begge trådene kjører på tråd 0. Men vi ser at de deler helt broderlig. Selv om den ene tråden nå har... Prioritert fem. Og den andre har prioritert ti. Så tråd nummer to har prioritert ti, men dette gir ikke utslag på hvor mye CPU de får. Og vi kan ikke annet enn konkludere her med at Linux faktisk ikke bryr seg om den prioriteten. Om du setter prioritet én eller ti, spiller ingen rolle. I oppgavene denne uken så... Så blir dere bedt om å prøve å få Linux til å ta hensyn til Java-prioriteten. Og det er mulig hvis du kjører Java på en spesiell måte med et spesielt flagg. Men det virker ikke da hvis du kjører som vanlig bruker. Du må faktisk kjøre som Ruth, og i tillegg må du ha et spesielt flagg. Da implementerer JVM dette her med NICE. At man setter NICE på Java-trådene,", "source": "lecture"}
{"lecture_id": "os11del4", "chunk_id": "os11del4_0006", "start": 464.2, "end": 565.28, "token_count": 299, "text": "Og det er mulig hvis du kjører Java på en spesiell måte med et spesielt flagg. Men det virker ikke da hvis du kjører som vanlig bruker. Du må faktisk kjøre som Ruth, og i tillegg må du ha et spesielt flagg. Da implementerer JVM dette her med NICE. At man setter NICE på Java-trådene, sånn at de har prioritet i forhold til hverandre. For å se dette eksplisitt, så må du gjøre sånn som jeg gjorde nå, og bruke tasten din, sånn at de eksplisitt kjører på samme CPU. Eller har veldig mange tråder. Flere tråder enn Sepur. Ok. Da tenkte jeg å... Ja, jeg tenkte egentlig også å kjøre trådene på... Kjøre trådene på Windows. Men skal vi se... Ja, det tar litt tid å sette opp de... Så jeg lurer på om vi gjør det etter pausen, så kan vi heller se på... Nå gå til litt flere slides om tråder. Så vi skal se litt mer teoretisk på tråder. Og aller først skal vi se på blokkerende systemkall. Men før vi avslutter demoen her...", "source": "lecture"}
{"lecture_id": "os11del4", "chunk_id": "os11del4_0007", "start": 544.48, "end": 598.0, "token_count": 178, "text": "så kan vi heller se på... Nå gå til litt flere slides om tråder. Så vi skal se litt mer teoretisk på tråder. Og aller først skal vi se på blokkerende systemkall. Men før vi avslutter demoen her... Vi skal se etter pause at hvis vi gjør dette samme på... kjører helt den samme Claes-bilen, kjører det samme programmet, så vil vi se at Windows faktisk tar hensyn til prioriteten. Og den tar kraftig hensyn, sånn at hvis du har en tråd med prioritet 4, så får den mye lavere prioritet enn en tråd med prioritet 5. Mens Linux da ikke tar hensyn i det hele tatt.", "source": "lecture"}
{"lecture_id": "os3bdel9", "chunk_id": "os3bdel9_0000", "start": 0.0, "end": 88.24, "token_count": 279, "text": "Ja. For å utføre en sånn... For å utføre en sånn oppgave som å kjøre den summen, så hvis man skal skrive maskinkode, så må man lage... Så er det enkleste før man skriver maskinkoden, å bruke et slags... et språk som ligger tett opp mot maskinkoden. Det jeg har skrevet opp her, er assemble-kode som utfører den forløkken som vi så på her. Den utfører denne forløkken. Når man skriver maskinkode eller assemble-kode, så må man tenke litt annerledes enn når man skriver høynivåkode. Men det viktigste man alltid må ha, det er en... Enten en løkke eller en if-test. Og for å utføre en løkke eller en if-test, så må man hoppe i koden. Vi kan se veldig raskt på hvordan denne maskinkoden her utføres. Så det vi gjør først i de fire første institusjonene, er bare å legge verdier i r0rnr2r3. r0rnr2r3, det er da registeret. Så første institusjon...", "source": "lecture"}
{"lecture_id": "os3bdel9", "chunk_id": "os3bdel9_0001", "start": 68.32, "end": 157.38, "token_count": 286, "text": "Vi kan se veldig raskt på hvordan denne maskinkoden her utføres. Så det vi gjør først i de fire første institusjonene, er bare å legge verdier i r0rnr2r3. r0rnr2r3, det er da registeret. Så første institusjon... Legg tallet 3 i R0, og så legg tallet 1 i R1. Null i auto og null i R3. Og så utfører jeg en addisjon, I pluss pluss. Jeg bestemmer meg da bare for at variabelen I lagres i auto. Men det er noe jeg bestemmer når jeg skal skrive dette programmet. Tar verdien i auto og legger den til r1. Tallet r1 vil alltid være 1, så dette vil alltid bli en i pluss pluss. Altså at man øker auto med. Så utfører jeg summen. Jeg bare definerer da i hodet mitt at jeg velger da r3. Det vil jeg ha. Der vil jeg lagre s. Det er derfor jeg legger 0 inn i det registeret først. Denne institusjonen tar S, som er R3, og legger til I, som er R2,", "source": "lecture"}
{"lecture_id": "os3bdel9", "chunk_id": "os3bdel9_0002", "start": 132.32, "end": 219.8, "token_count": 294, "text": "Så utfører jeg summen. Jeg bare definerer da i hodet mitt at jeg velger da r3. Det vil jeg ha. Der vil jeg lagre s. Det er derfor jeg legger 0 inn i det registeret først. Denne institusjonen tar S, som er R3, og legger til I, som er R2, og så lagres det i R3. Det vil da være S lik S pluss I. Denne institusjonen kan datamaskinen min utføre. Så kommer et veldig viktig step. Jeg sammenligner. Og det jeg sammenligner, det er R2 og R0. R0, det er maks. Jeg ønsker at løkka skal bare gå opp til 3. Altså dette er maks. Og da sammenligner jeg R2, som er da... På en måte variabelen i. Har den blitt så stor som 3? Men foreløpig er I liggende 1, så det har den ikke. Og når jeg da gjør neste institusjon, jump not equal, så hopper jeg opp til 4 igjen. Og den består av at man øker i med én. Så får jeg i lik to, og så får jeg summen lik én pluss to er lik tre.", "source": "lecture"}
{"lecture_id": "os3bdel9", "chunk_id": "os3bdel9_0003", "start": 198.4, "end": 282.24, "token_count": 300, "text": "Men foreløpig er I liggende 1, så det har den ikke. Og når jeg da gjør neste institusjon, jump not equal, så hopper jeg opp til 4 igjen. Og den består av at man øker i med én. Så får jeg i lik to, og så får jeg summen lik én pluss to er lik tre. Og så gjør jeg dette en gang til. Her er i lik to, jeg hopper opp. Øker i lik tre. S er lik tre... Tre pluss tre, og da er summen seks. Og nå har i blitt tre, og da hopper jeg ikke opp igjen. Jeg har fått resultatet seks. Og programmet har blitt utført. Og det er nøyaktig sånn man går fra høynivåkode til assemblerkode eller maskinkode. Neste steppe nå er at jeg må kode inn denne maskinkoden eller denne asemblyen inn i maskinkode. Og det er veldig rett frem, for det er bare å oversette instruksjon for instruksjon. Og... Ja, hvis jeg bruker mye tid her nå... Jeg går litt over tiden, håper dere holder ut. Selv om det er litt tungt dette her, så får dere jobbe dere gjennom dette", "source": "lecture"}
{"lecture_id": "os3bdel9", "chunk_id": "os3bdel9_0004", "start": 256.4, "end": 347.18, "token_count": 294, "text": "denne maskinkoden eller denne asemblyen inn i maskinkode. Og det er veldig rett frem, for det er bare å oversette instruksjon for instruksjon. Og... Ja, hvis jeg bruker mye tid her nå... Jeg går litt over tiden, håper dere holder ut. Selv om det er litt tungt dette her, så får dere jobbe dere gjennom dette ved å se på oppgavene. Men hele clouet er nå at vi oversetter disse institusjonene én for én. F.eks. den første linjen'move i r03', altså legg tallet 3 inn i r0. R0 er destination. Source er det tallet vi skal legge inn. Det er tallet 3. Det skal legges i register 0. På samme måte, samme instruksjon, men nå skal vi legge 1 i r1. Da må det stå 1 der og 1 der. Etter hvert kommer vi ned til add. Lik R2 pluss R1. Da må vi skrive inn her av instruksjon nummer fire. Og så... Destination register, det er da R2, og da ser vi at det står et 2-tall der. Det gir da R2 og 1.", "source": "lecture"}
{"lecture_id": "os3bdel9", "chunk_id": "os3bdel9_0005", "start": 322.42, "end": 383.98, "token_count": 240, "text": "Da må det stå 1 der og 1 der. Etter hvert kommer vi ned til add. Lik R2 pluss R1. Da må vi skrive inn her av instruksjon nummer fire. Og så... Destination register, det er da R2, og da ser vi at det står et 2-tall der. Det gir da R2 og 1. Det betyr R1. Så dermed utføres R2 lik R2 pluss R1. Hvis jeg f.eks. hadde skrevet 3 her i stedet, så ville jeg utført R3 lik R3 pluss R1. Så på denne måten programmerer jeg maskinen med akkurat den koden jeg ønsker. Vanligvis, hvis du f.eks. har høynivåkode i C, så har man en kompulator. Du kompilerer høynivåkoden, og så lager kompulatoren denne maskinkoden. Og så kjøres den. Men i vårt tilfelle, så gjør vi dette.", "source": "lecture"}
{"lecture_id": "os3bdel11", "chunk_id": "os3bdel11_0000", "start": 0.0, "end": 98.68, "token_count": 284, "text": "Og i oppgaven denne uken så blir dere bedt om å laste ned en maskin. Det er da hele maskinen. Det er denne maskinen. Og her ligger da... Her kan man gå inn og se... Velge Edith Makro, så kan man gå inn og se, OK, her har vi Alle-Hund. Så kan man bevege seg innover. Her er Alle-Hund, og her ser vi de fire fulleiderne. for bl.a. å kunne legge sammen. Det er en sånn Bionary Full Ladder som vi forrige gang konstruerte. Vi ser at dette er et stort byggverk hvor man hele tiden abstraherer lagerbokser. Dette er register file. Denne inneholder da registrene. R0, R1, R2, R3. Det er da de små registrene som vi har. Og dette er da logikken i registrene, men vi ser hovedbiten er vippene. Så her er det fire d-vipper som lagrer da fire-bit i fire-bitsregisteret. Helt til slutt skal jeg bare vise hvordan maskinen kjører. Hvis man tar høyreklikker og edit på den, så ser man det programmet.", "source": "lecture"}
{"lecture_id": "os3bdel11", "chunk_id": "os3bdel11_0001", "start": 60.02, "end": 163.6, "token_count": 297, "text": "Og dette er da logikken i registrene, men vi ser hovedbiten er vippene. Så her er det fire d-vipper som lagrer da fire-bit i fire-bitsregisteret. Helt til slutt skal jeg bare vise hvordan maskinen kjører. Hvis man tar høyreklikker og edit på den, så ser man det programmet. Dette er da maskinkode som viser det programmet som regner en fåløkke. Og så kan man trykke på rønn og kjøre. Alternativet som kanskje er bedre, er å trykke på step. Da tar man én instruksjon av gangen. Nå utførte jeg den første instruksjonen her. Så trykker jeg på steppe en gang til. Dvs. to ganger må man trykke, for klokka går av og så på. Og så utføres instruksjonen. Det som ble gjort nå, det var at én ble lagt i r1. Og så blir null lagt i r2, og null i r3. Det ser man ikke, men så adderer man. Man skal gjøre nå å ta R2 lik 0 pluss R1. Og da får man en ener i R2. Og så gjør man en test.", "source": "lecture"}
{"lecture_id": "os3bdel11", "chunk_id": "os3bdel11_0002", "start": 137.12, "end": 243.54, "token_count": 292, "text": "Det som ble gjort nå, det var at én ble lagt i r1. Og så blir null lagt i r2, og null i r3. Det ser man ikke, men så adderer man. Man skal gjøre nå å ta R2 lik 0 pluss R1. Og da får man en ener i R2. Og så gjør man en test. Man øker R3 med én. Det er telleren. Og så sjekker man om den er lik R0. Nei, den er ikke lik R0, og det er jump not equal, så da hopper man opp hit. Det man gjør nå, er R2 lik R2 pluss telleren R3. Da får man to i R2. I telleren R2 så er det R3. Det er her summen ligger. Er vi ferdig med løkka? Nei, det er vi ikke, så vi gjør det én gang til. Da skal vi til slutt ta... Telleren R2 blir nå 3, og så skal vi legge R3 lik R3 pluss R2. Da ser vi at vi får 6, som er sluttresultatet. Så når nå R2 sammenlignes med R0, så er den... Equal. Og da fortsetter den rett frem.", "source": "lecture"}
{"lecture_id": "os3bdel11", "chunk_id": "os3bdel11_0003", "start": 215.46, "end": 299.96, "token_count": 298, "text": "så vi gjør det én gang til. Da skal vi til slutt ta... Telleren R2 blir nå 3, og så skal vi legge R3 lik R3 pluss R2. Da ser vi at vi får 6, som er sluttresultatet. Så når nå R2 sammenlignes med R0, så er den... Equal. Og da fortsetter den rett frem. Og da har vi kjørt hele programmet. Og så kan... Nå kjører jeg programmet bare hurtig gjennom. Og da, om og om igjen, så utføres hele den samme operasjonen ved at man legger sammen. Helt til slutt så kan... Det er en oppgave som går ut på at dere skal endre. Litt på koden. Det dere må gjøre da, er å klikke her. Og så kan man gå inn sånn, og så endre. Nå endret jeg verdi fra én til tre, og da vil programmet gjøre noe annet. Men etter at du har endret, så må du ikke bare trykke på OK. Du må endre først, og så trykke på neste. Og så kan programmet kjøre. Hvis dere endrer noe feil, og et eller annet galt skjer, så er det enkleste", "source": "lecture"}
{"lecture_id": "os3bdel11", "chunk_id": "os3bdel11_0004", "start": 280.46, "end": 308.98, "token_count": 123, "text": "Nå endret jeg verdi fra én til tre, og da vil programmet gjøre noe annet. Men etter at du har endret, så må du ikke bare trykke på OK. Du må endre først, og så trykke på neste. Og så kan programmet kjøre. Hvis dere endrer noe feil, og et eller annet galt skjer, så er det enkleste Det er bare å krasje hele maskinen, ta ned simuleringen og starte på nytt. For da starter de med et ferskt program.", "source": "lecture"}
{"lecture_id": "os12del6", "chunk_id": "os12del6_0000", "start": 0.0, "end": 94.54, "token_count": 296, "text": "Her er et lite Linux-eksempel på... Som viser den i et annet tilfelle hvor man bruker en lås. Og det ligner på lokk og Mutex, dette også. Og det er en teknikk man ofte bruker for å si ifra at... Denne filen. Ingen aner om å bruke den. Og i SendMail, som er Linux-mailprogram, så gjøres det ved at man lager en lokk per bruker. Så hvis man driver og leser og skriver e-post til denne brukeren... For alle e-postene i SendMail, det er bare en stor fil med e-poster. Og hvis man får e-post eller gjør noen endringer på den filen... Så lager Linux-systemet en sånn lokkfil. Og det sørger da for at andre prosesser ikke endrer på innboksen. Men det er klart, da må alle prosesser som skal endre på denne filen... Altså på... Ikke på lokkfilen, men på innholdet i mailen... Det er en annen fil, som kanskje heter Varmail Haugerud i dette tilfellet. Så sjekker da bare prosessene. Nei, hvis den ikke finnes, OK, da kan jeg gjøre endringer.", "source": "lecture"}
{"lecture_id": "os12del6", "chunk_id": "os12del6_0001", "start": 76.74, "end": 160.44, "token_count": 292, "text": "Altså på... Ikke på lokkfilen, men på innholdet i mailen... Det er en annen fil, som kanskje heter Varmail Haugerud i dette tilfellet. Så sjekker da bare prosessene. Nei, hvis den ikke finnes, OK, da kan jeg gjøre endringer. Men hvis den finnes, så må prosessen da så vente. Og den kan gjøre å stå i en venteløkke og sjekke om og om igjen om denne filen finnes, og så gå inn hvis den ikke finnes. Så det er et enkelt eksempel på en lokk. Men vi skal se at et sånt system er ikke helt bombesikkert. For igjen så kan du få trøbbel med contact switcher. I Windows har vi akkurat den samme problemstillingen. Og bind 32 av PI har to funksjonskall, enter critical section og leave critical section, som er da igjen et tilbud til programmerere å lage kritiske avsnitt. Og disse funksjonskallene vil da sørge for at etter enter critical section... Så vil ingen andre prosesser, heller ikke på andre CPU-er, vil endre på de felles variablene.", "source": "lecture"}
{"lecture_id": "os12del6", "chunk_id": "os12del6_0002", "start": 130.48, "end": 202.0, "token_count": 229, "text": "enter critical section og leave critical section, som er da igjen et tilbud til programmerere å lage kritiske avsnitt. Og disse funksjonskallene vil da sørge for at etter enter critical section... Så vil ingen andre prosesser, heller ikke på andre CPU-er, vil endre på de felles variablene. Det som typisk er felles, det ligger i ramm. Så igjen så vil disse funksjonskallene låse av bussen, sånn at man har enerett på å endre de områdene av ramm som man ser på. Dette forsinker alle jobber som kjører i parallell. Vi kjører i parallell for å få det til å gå fortere. Så hvis det er veldig mye synkronisering, så vil det gå saktere. Men dette er da opp til programmereren å lage et system som er smart nok, og som ikke bruker altfor mye tid i kritiske avsett.", "source": "lecture"}
{"lecture_id": "os12del5", "chunk_id": "os12del5_0000", "start": 0.0, "end": 89.92, "token_count": 297, "text": "Kritisk avsnitt er det avsnittet i koden som er helt avgjørende når det gjelder synkronisering. Og det er da typisk når man aksesserer en felles variabel. Vi har sett på en problemstilling hvor vi har en felles variabel saldo. Hvor vi hadde en felles variabel saldo som én prosess... Økte med 1 mill. og en annen prosess, P1, minket med 1 mill. Og så så vi da på hvordan dette kunne gjøre at saldoen... At det forsvant 1 mill. Og det er jo opplagt uheldig. Og akkurat den kodebiten hvor den millen forsvinner, det er når saldoen oppdateres. Og dette kalles kritisk avsnitt. Som er helt avgjørende, er at en prosess som er inni et kritisk avsnitt, den må kunne fullføre det helt alene, uten at da noen andre endrer på saldoen. Så serialiseringen, den må da sørge for at det kritiske avsnittet, det gjøres bare av én prosess av gangen. Og vi begynte å se på metoder som kan gjøre dette her, så vi hadde en lokkinstitusjon.", "source": "lecture"}
{"lecture_id": "os12del5", "chunk_id": "os12del5_0001", "start": 69.88, "end": 153.72, "token_count": 297, "text": "uten at da noen andre endrer på saldoen. Så serialiseringen, den må da sørge for at det kritiske avsnittet, det gjøres bare av én prosess av gangen. Og vi begynte å se på metoder som kan gjøre dette her, så vi hadde en lokkinstitusjon. Og den hindret da at andre prosesser endret på saldoen. Det gjorde vi med Petrads. Og det som også var avgjørende da, var at vi låste minnebussen. Altså bussen ut til RAM. For det er det som er avgjørende når du har tråder som kjører på forskjellige CPU-er. Så er det ikke så lett å koordinere dem, for da opererer de totalt samtidig og helt uavhengig av hverandre. Hvis begge kjører på samme CPU, så har du tross alt en context switch, sånn at da går det an å koordinere i litt større grad. Selv om det kan bli trøbbel, det òg. Men når du er på forskjellige CPU-er, så må minnebussen låses for at ikke to prosesser skal da... Samtidig hente ut en kode, eller samtidig endre.", "source": "lecture"}
{"lecture_id": "os12del5", "chunk_id": "os12del5_0002", "start": 133.44, "end": 222.48, "token_count": 296, "text": "sånn at da går det an å koordinere i litt større grad. Selv om det kan bli trøbbel, det òg. Men når du er på forskjellige CPU-er, så må minnebussen låses for at ikke to prosesser skal da... Samtidig hente ut en kode, eller samtidig endre. Det vil si at ikke begge skal hente ut den nåværende verdien, og så skrive tilbake uten å koordinere med den andre. Det er da problemene skjer. Men hvis vi kjører selv, hvis vi kjører på samme CPU, så har vi sett at én institusjon sånn som dette her... Den fører faktisk til minst to instruksjoner på maskinnivå. På assembly-nivå. Og det er det operativsystemet ser. Så når operativsystemet skedulerer to prosesser sånn som dette, selv på samme CPU, så kan det da komme en context switch midt inne i denne oppdateringen. Og da kan det som prosess 2... Utfører av institusjoner. Det kan da bli ødelagt av den andre fordi de ikke koordinerer. Og fordi det kan komme context-switch midt inn i kritisk avsnitt.", "source": "lecture"}
{"lecture_id": "os12del5", "chunk_id": "os12del5_0003", "start": 196.36, "end": 285.4, "token_count": 289, "text": "selv på samme CPU, så kan det da komme en context switch midt inne i denne oppdateringen. Og da kan det som prosess 2... Utfører av institusjoner. Det kan da bli ødelagt av den andre fordi de ikke koordinerer. Og fordi det kan komme context-switch midt inn i kritisk avsnitt. For da blir kritisk avsnitt større enn én linje. Hvis kritisk avsnitt faktisk bare er én maskininstitusjon, så vil vi ikke få det problemet med context-switching på samme SPU. Men problemet kan likevel oppstå når vi har flere SPU. Nå skal jeg se på noen metoder for å behandle kritiske avsnitt. Og målet med disse metodene er at vi skal sikre oss at bare én prosess av gangen, eller én tråd av gangen, utfører sitt kritiske avsnitt før en annen prosess gjør det. I prinsippet så kan det være ti tråder som samtidig ønsker å gå inn i... Men det avgjørende her er bare én av gangene. En veldig direkte måte å sørge dette for, det er å skru av interrupts.", "source": "lecture"}
{"lecture_id": "os12del5", "chunk_id": "os12del5_0004", "start": 261.32, "end": 352.12, "token_count": 300, "text": "utfører sitt kritiske avsnitt før en annen prosess gjør det. I prinsippet så kan det være ti tråder som samtidig ønsker å gå inn i... Men det avgjørende her er bare én av gangene. En veldig direkte måte å sørge dette for, det er å skru av interrupts. For hvis man da skrur av interrupts, så er du sikker på at... Da er du sikker på at det ikke kommer noe context switch. Så kan det være trøbbel med andre CPU-er. Men hvis vi er på samme CPU, så kan vi sikre et kritisk avsnitt ved først å disable interrupts, så utføre det kritiske avsnittet, og så enable interrupts etterpå. For da er vi... Selv om dette kritiske avsnittet da består av flere maskininstitusjoner, så er man likevel sikker på at ingen... Det kan ikke skje noe kontekstuelt. For interrupt er skrudd av. Det skjedde ved at det kommer en timer-interrupt. Så om man ikke behandler timer-interrupten med en gang, men venter til koden er ferdig, så vil det ikke kunne skje... Da vil ingen kunne avbryte knyttet til avsnittet.", "source": "lecture"}
{"lecture_id": "os12del5", "chunk_id": "os12del5_0005", "start": 333.0, "end": 428.4, "token_count": 296, "text": "Det skjedde ved at det kommer en timer-interrupt. Så om man ikke behandler timer-interrupten med en gang, men venter til koden er ferdig, så vil det ikke kunne skje... Da vil ingen kunne avbryte knyttet til avsnittet. Dette er OK for en OUS-kjerne. Det er kode i OUS-kjernen som skrur av interrupts. Være helt sikker på å fullføre et kritisk gassnitt. Men det ville vært veldig kritisk hvis brukerprosesser kunne gjøre dette her, for da kunne de straks ta over styringen. Så dette er OK for en O-stjerne, men generelt så kan man ikke gi en slik metode til en vanlig brukerprosess. Det er å lage en slags lås. Det er litt sånn som den lock-instruksjonen som vi har sett på. Man lager en lås sånn at bare én prosess av gangen har tilgang til fellesdata. Generelt så kalles en slik lås mutix. Det står da for mutual exclusion. På norsk betyr det gjensidig utelukkelse. man... Sørge for å utelukke hverandre. Og dette er den mest brukte metoden generelt.", "source": "lecture"}
{"lecture_id": "os12del5", "chunk_id": "os12del5_0006", "start": 398.72, "end": 486.26, "token_count": 280, "text": "Man lager en lås sånn at bare én prosess av gangen har tilgang til fellesdata. Generelt så kalles en slik lås mutix. Det står da for mutual exclusion. På norsk betyr det gjensidig utelukkelse. man... Sørge for å utelukke hverandre. Og dette er den mest brukte metoden generelt. Og det fins mange implementasjoner av det. Og vi skal se noen eksempler på implementasjoner. Men det som er viktig her, er at man må da utelukke alle andre. Ja, en mutex... Den lockwill-funksjonen vi hadde, den gjelder bare for én institusjon. Men en mutex generelt, det er på en måte en nøkkel som man tar tak i. Og så lenge man beholder den nøkkelen, så er man inne i kritiske avsnitt, og da kan ingen andre komme inn i kritiske avsnitt og gjøre noe. Så det kan vare lenger enn en enkelt institusjon, og dermed så kan det Den kan også brukes til å serialisere kode, som har mer enn én institusjon i Kritisk avsnitt.", "source": "lecture"}
{"lecture_id": "os8del2", "chunk_id": "os8del2_0000", "start": 0.02, "end": 101.8, "token_count": 291, "text": "Sist, forrige gang, så holdt vi på med... Vi startet egentlig med cash og så på minnet, og hvor viktig det er at vi har cash imellom CPU og ram. Fordi CPU-en er mye raskere enn ram. Og da må man ha et mellomlager for å kunne utnytte hele effekten Så så vi mye på cors, eller kjerner, altså regneenheter. Og da regnet de med at... Hver CPU, eller hver kjerne eller regneenhet, så vi på som én alu. Og da, når vi etterpå så på hypertrening, så består hypertrening...  Består da av at operatyssystemet ser på det som egentlig er én kore, én kjerne, som har én alu, den ser på det som to CPU-er, eller to regneenheter. Men i virkeligheten så er det ved hjelp av Hardware, så switcher... Så kan Hardware switche lynraskt på nanosekunder. Så kan den sitte. Som kjører samtidig inn i denne kjernen. Og de har da typisk to sett med registre osv. Og så switcher man veldig fort mellom de.", "source": "lecture"}
{"lecture_id": "os8del2", "chunk_id": "os8del2_0001", "start": 73.4, "end": 131.0, "token_count": 186, "text": "Men i virkeligheten så er det ved hjelp av Hardware, så switcher... Så kan Hardware switche lynraskt på nanosekunder. Så kan den sitte. Som kjører samtidig inn i denne kjernen. Og de har da typisk to sett med registre osv. Og så switcher man veldig fort mellom de. Og da kan man i enkelte tilfeller utnytte den ventetiden som man vanligvis har på å hente noe i RAM, f.eks. Så kan det utnyttes, sånn at prosesser går mye raskere. Igjen, som veldig mye av alt annet, som cash og andre... Andre viktige deler ved en CPU, det er egentlig der bare for at ting skal gå fortere.", "source": "lecture"}
{"lecture_id": "os5del14", "chunk_id": "os5del14_0000", "start": 0.0, "end": 88.76, "token_count": 289, "text": "Det som er veldig viktig å ha med videre, er at vi har en CPU-ulykke. Akkurat som med den i simuleringen. Så lenge maskinen ikke blir skrudd av, så utfører den instruksjoner. Hvis den ikke har noe å gjøre, så må den utføre en NOP-instruksjon. Noen ting bare står og slår i lufta. Så dette er gangen for enhver CPU. Først henter den inn institusjonen den skal kjøres. Og så øker programkontoen. Og så utføres den institusjonen. Institusjoner kan være sånne som hopper i koden, men hvis det ikke er noe hopp i koden, så økes PC bare med én. Og så fortsetter den å kjøre. Men en CPU er jo også koblet til annen hardware, sånn som tastatur og nettverkskort osv. Så når som helst så kan CPU-en bli avbrutt av et interrupt. Det skal vi se på senere. Og da må CPU-en stoppe i de operasjonene den gjør, og så må den behandle interruptet. For eksempel hvis det kommer et tegn inn fra tastatur,", "source": "lecture"}
{"lecture_id": "os5del14", "chunk_id": "os5del14_0001", "start": 64.28, "end": 100.02, "token_count": 110, "text": "sånn som tastatur og nettverkskort osv. Så når som helst så kan CPU-en bli avbrutt av et interrupt. Det skal vi se på senere. Og da må CPU-en stoppe i de operasjonene den gjør, og så må den behandle interruptet. For eksempel hvis det kommer et tegn inn fra tastatur, Den type avbrudd er det ikke Sippun som styrer, for det er avbrudd som kommer utenfra.", "source": "lecture"}
{"lecture_id": "os12del4", "chunk_id": "os12del4_0000", "start": 0.0, "end": 79.94, "token_count": 269, "text": "Så vi skal først snakke litt teoretisk, noen slider... Og en del litt sånn teoretiske slidere om hvordan man kan løse Mutex-problemer. Og om de problemene vi konkret så på forrige gang. Og så... kommer vi kanskje litt tilbake til den X86-instruksjonen Lock, og så se på... Det vi gjorde der, var et par ting vi ikke gjorde der. Så vi skal se på det spesielt. Så så vi ikke direkte på hva som skjer hvis det ikke bare er én institusjon. Vi så på LOK før påske, og da var det én enkeltinstitusjon som endret på en feltsvariabel. Og likevel så ble det problemer. Så vi skal se litt mer på det. Så skal vi se igjen noe generelt om synkronisering, med semaforer bl.a. Semaforer skal vi se på i dag. Og så skal vi mot slutten synkronisere det Java-programmet vi hadde sist. Ved hjelp av Synchronized. Og helt til slutt i dag skal vi se på deadlock.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0000", "start": 0.0, "end": 111.24, "token_count": 293, "text": "Ja... Da starter vi igjen. Aller først så var det et godt spørsmål i pausen om Output fra Time. Om... Så vidt jeg forstår spørsmålet, så var det hvorfor det er en liten forskjell på totaltiden. Og user og system, hvis du legger sammen. At det kan være større forskjell, men her ser du 4 pluss 12... Det blir ikke 5. 18. Og her er det også enda litt mer forskjell. Og svaret på det er at så skal ikke de nødvendigvis bli de samme. Og det kan vi også se av den prosenten bak her. Hvis den er 100 %, så skal de to være samme. For det betyr at da har CPU-en vært 100 % i bruk, og da vil du kunne se at de er like. Men i utgangspunktet så er denne kolonnen... Det er hvor mye CPU-tid som er brukt i såkalt jus. User mode er en modus av CPU-en hvor brukerprogrammet selv styrer alt og kjører CPU-en. Og det brukes stort sett hele tiden når man f.eks. regner, for da må brukerprosessen få tilgang til CPU-en", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0001", "start": 90.0, "end": 192.48, "token_count": 298, "text": "User mode er en modus av CPU-en hvor brukerprogrammet selv styrer alt og kjører CPU-en. Og det brukes stort sett hele tiden når man f.eks. regner, for da må brukerprosessen få tilgang til CPU-en og står og regner om og om igjen inni aluen. Og det er hvor mye tid operativsystemkjernen bruker på denne prosessen. Og hvis det er mye kall til disk og andre... områder... Eller mange kall til prosedyrer i operativsystemkjernen, så vil du se at... Skal vi se senere? Da kan man bruke mye tid her. Og sammenlagt så er dette hvor mye tid som... Som brukes da av CPU-en på denne prosessen. Men realtime, det er faktisk realtime, det er hvor lang tid det tar. Så realtime kan være dobbelt så lenge hvis det er to prosesser som... Hvis det er to prosesser som kjører, for eksempel... Ja, dette blir kanskje et dårlig eksempel. Hvis vi kjører de to sånne... Samtidig så... ja, så vil vel de kjøre på... De vil kjøre på samme CPU... Nei, de vil kjøre på hver sin.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0002", "start": 164.48, "end": 251.5, "token_count": 292, "text": "Hvis det er to prosesser som kjører, for eksempel... Ja, dette blir kanskje et dårlig eksempel. Hvis vi kjører de to sånne... Samtidig så... ja, så vil vel de kjøre på... De vil kjøre på samme CPU... Nei, de vil kjøre på hver sin. Sånn at de vil vel få en... Ja, de vil få en tilsvarende... Jo, vi kan se på et annet eksempel, men da passer det bra å ta en poll for akkurat det eksempelet vi skal se på. Det kan vi teste ut etter pollen. Så et lite spørsmål til alle... Man må jo til og med regne litt med papir og blyant hvis man ikke har en kalkulator eller er god i hoderegning. Spørsmålet e.r.: Hvis en 100 % CPU-avhengig prosess bruker 18 sekunder på én enkelt CPU, hvor lang tid bruker da fem slike prosesser på en server med fire CPU-er? Dette vil da være tilsvarende... 18 var kanskje ikke helt riktig, men jeg tenkte å teste ut med denne prosessen her, som tar omtrent 18 sekunder.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0003", "start": 225.28, "end": 363.7, "token_count": 300, "text": "Spørsmålet e.r.: Hvis en 100 % CPU-avhengig prosess bruker 18 sekunder på én enkelt CPU, hvor lang tid bruker da fem slike prosesser på en server med fire CPU-er? Dette vil da være tilsvarende... 18 var kanskje ikke helt riktig, men jeg tenkte å teste ut med denne prosessen her, som tar omtrent 18 sekunder. Så problemstillingen er... Jeg kjører én enkelt prosess, og den bruker 18 sekunder. Men hvor lang tid tar det når jeg nå kjører... Hvis jeg da starter opp med en forløkke... Starter opp og kjører... Ja, jeg ser vi har fått inn en del svar allerede. Det er i hvert fall veldig mange riktige svar her, så dette ser bra ut. Ja... begynner det å se ut som de flere... Nei, det er fortsatt... Bruk gjerne litt mer tid på det, så kan vi etterpå både... Prøve å kjøre og se hvordan det ser ut i praksis, og så kan vi prøve å regne det ut. Ja, skal vi se. Nå tror jeg 75 % av dere her har svart. Ja, vi kan stoppe der.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0004", "start": 304.84, "end": 440.8, "token_count": 277, "text": "Bruk gjerne litt mer tid på det, så kan vi etterpå både... Prøve å kjøre og se hvordan det ser ut i praksis, og så kan vi prøve å regne det ut. Ja, skal vi se. Nå tror jeg 75 % av dere her har svart. Ja, vi kan stoppe der. Så kan jeg prøve å dele resultatene, men da ser dere kanskje ikke... Jo, det ser dere der. Sånn. Dere ser Polly-resultatene nå? Rune er med oss også. Rune, hører du meg? Ja, det kan jeg. Du hører meg. Flott. Supert. Da er du med i denne andre timen, og så svarer du på spørsmål hvis det er noe jeg ikke får med meg. Eller hvis et eller annet galt skjer. Supert. Ja. Rune, du ser Polla-resultatene nå? Ja. Flott. Ja, som vi ser... 75 % av dere har gått for 22,5 sekunder. Og det er veldig bra. For det... Det er i hvert fall det jeg trodde svaret skulle bli. Så vi kan gjøre to ting. Vi kan kjøre det her.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0005", "start": 420.0, "end": 520.96, "token_count": 299, "text": "Ja. Flott. Ja, som vi ser... 75 % av dere har gått for 22,5 sekunder. Og det er veldig bra. For det... Det er i hvert fall det jeg trodde svaret skulle bli. Så vi kan gjøre to ting. Vi kan kjøre det her. Og mens det står og kjører, så kan vi prøve å regne på det. Så... Utgangspunktet var at vi hadde fem prosesser. Prosesser... Og hver av de bruker 18 sekunder. Og så har vi da fire CPU-er som de fem prosessene skal fordeles på. Så da er det typisk at 0, 1, 2, 3 kjører sånn. De vil jo da kjøre parallell, men så må nummer 4 settes på en av de andre CPU-ene. Og da, som vi så tidligere, så er dette bare et øyeblikksbilde. Man bytter da på hvilke CPU-er som har to prosesser av gangen. Sånn at totalt sett så fordeles tiden likt. Og da... Ja, det kan være litt sånn... Det kan være flere måter å regne det ut på. Men det som jeg tenker kanskje er den enkleste måten,", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0006", "start": 498.5, "end": 597.2, "token_count": 295, "text": "Man bytter da på hvilke CPU-er som har to prosesser av gangen. Sånn at totalt sett så fordeles tiden likt. Og da... Ja, det kan være litt sånn... Det kan være flere måter å regne det ut på. Men det som jeg tenker kanskje er den enkleste måten, og gjerne bruke andre måter, det er at hvis du har fem prosesser som skal kjøre i 18 sekunder, så trenger de... Hver av de trenger 18 CPU-sekunder. Så vi kan regne oss i 5 CPU ganger 18... Så mange CPU-sekunder trenger man for å utføre de jobbene ferdig. Og 5 ganger 18... 548... Det skulle bli 90 CPU-sekk. Og da... Når du har 90 CPU-sekunder, og så skal du dele det på... De må jo fordeles på fire sepuuer. For hvis alle de fire sepuuene kjører så mye de kan av de 90 sepuu-sekundene hele tiden, så vil det bli fordelt på den måten der. Og dermed får man 90 fjerdedelssekund. Og 90 fjerdedeler er 45,5...", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0007", "start": 573.2, "end": 671.2, "token_count": 287, "text": "For hvis alle de fire sepuuene kjører så mye de kan av de 90 sepuu-sekundene hele tiden, så vil det bli fordelt på den måten der. Og dermed får man 90 fjerdedelssekund. Og 90 fjerdedeler er 45,5... Og det blir da 22,5 sekunder. Så det er derfor... Veldig bra at tre fjerdedeler av dere har kommet fram til at dette bør ta 22,5 sekunder. Og så kan vi også se på fasiten. Jeg tror ikke den er helt 22,5 sekunder, men vi kan se... Her var det faktisk ikke så veldig fair. Den stoppa, ser du det sultne... Vi ser her... Her var det litt forskjell i CPU-bruken. Det burde jo vært 80 %, men vi ser at den her faktisk fikk 88 %. Så den var nede i 21 sekunder, mens denne fikk bare 76 og var oppe i 24. Så her var ikke schedulerne helt feil. Varierer litt også om det er mye annen trafikk på serveren. Men vi ser røft i snitt så ville det blitt 22,5", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0008", "start": 645.8, "end": 744.32, "token_count": 284, "text": "Det burde jo vært 80 %, men vi ser at den her faktisk fikk 88 %. Så den var nede i 21 sekunder, mens denne fikk bare 76 og var oppe i 24. Så her var ikke schedulerne helt feil. Varierer litt også om det er mye annen trafikk på serveren. Men vi ser røft i snitt så ville det blitt 22,5 hvis operativstemma hadde klart å fordele dette helt likt. Men her kan vi også se et eksempel på det spørsmålet som kom tidligere. Her ser vi at hvis man legger sammen user og system, Og i hvert fall ikke her. Og det er fordi at dette er liksom... Totalen her er hvor mye CPU-tid den prosessen her trenger. Og dette tallet her kommer da rett og slett fram for at... Dette er i hvor mange prosent den faktisk hadde. Og dermed så tar realtiden... er blitt realtiden mye lengre. Den blir av 24 sekunder. Ok. Da skal vi fortsette der vi slapp. Og hvor var det vi slapp? Her, ja. Med multitasking og multiprosessing.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0009", "start": 710.5, "end": 826.32, "token_count": 282, "text": "Dette er i hvor mange prosent den faktisk hadde. Og dermed så tar realtiden... er blitt realtiden mye lengre. Den blir av 24 sekunder. Ok. Da skal vi fortsette der vi slapp. Og hvor var det vi slapp? Her, ja. Med multitasking og multiprosessing. Og multiprosessing. Det er mange begreper som man må forholde seg til. Her er en liten oppsummering av noen av begrepene. Multitasking, eller multiprogramming, det er det som vi har sett på når operativsystemet fordeler tid på samme CPU. Den lar da flere prosesser dele på CPU-en. Og så dele ut tid til hver prosess. Det er multitasking. Multiprosessing er når to eller flere CPU-er samtidig kjører flere prosesser. I samme datamaskin kan du f.eks. ha fire CPU-er. Og hver av de kan da jobbe på én prosess helt samtidig, og det er multiprosessing. Og så har du det som kalles symmetrik multiprosessing. Da er det... Jo, den vesentlige forskjellen her er at da deler du på samme internmine.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0010", "start": 796.2, "end": 889.24, "token_count": 298, "text": "I samme datamaskin kan du f.eks. ha fire CPU-er. Og hver av de kan da jobbe på én prosess helt samtidig, og det er multiprosessing. Og så har du det som kalles symmetrik multiprosessing. Da er det... Jo, den vesentlige forskjellen her er at da deler du på samme internmine. I multiprosessing så trenger du ikke å dele på samme internmine engang. SMP er det som er vanlig når du kjører i en server, sånn som de eksemplene vi har sett på tidligere. Da er... Alle prosessorene er da koblet til samme internminer. Og så kjører de helt samtidig i virkeligheten, i sanntid samtidig. Men det vi har sett på eksempler på hele tiden, er at vi har SMP samtidig som vi har multitasking. For operativstemme fordeler da mange prosesser på samme CPU, men samtidig så er det mange som kjører i parallell. En liten forskjell der er at da... Når du sier multicore, så sitter da flere prosessorer på samme brikke. Altså multicore. Core er en kjerne eller en regneenhet.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0011", "start": 863.08, "end": 958.68, "token_count": 290, "text": "men samtidig så er det mange som kjører i parallell. En liten forskjell der er at da... Når du sier multicore, så sitter da flere prosessorer på samme brikke. Altså multicore. Core er en kjerne eller en regneenhet. De sitter da på samme brikke og deler også cash. Og kjører prosesser samtidig. Og det regnes også som SMP. Og her er det heller ikke så veldig store forskjeller. I praksis så vil du ikke merke noen forskjell om det er SMP eller Multicore. Og du kan også ha en kobling av dette her. Altså at du har... En CPU-brikke med fire kjerner. Og så er det to sånne CPU-brikker inne i den samme maskinen. På det samme motherboardet. Og jeg vil dele interne mine. Så det var noen begreper. Skal vi se på noen eksempler på disse begrepene? Ja. Her ser vi fra venstre mot høyre... For det første singelprosessor, sånn som det var i gamle dager. Nå er det nesten umulig å oppdrive noen som helst prosessor som ser sånn ut.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0012", "start": 938.48, "end": 1032.96, "token_count": 300, "text": "Skal vi se på noen eksempler på disse begrepene? Ja. Her ser vi fra venstre mot høyre... For det første singelprosessor, sånn som det var i gamle dager. Nå er det nesten umulig å oppdrive noen som helst prosessor som ser sånn ut. Dette er en duel-prosessor. Da ser vi at det er to separate brikker. Som sagt, man merker ikke så veldig stor førsel på det og den ved siden av, som er duel-core. Men her er det to separate fysiske brikker som du kan ta inn og ut av maskinen. Men begge er da koblet til samme ramm, men de har hver sin cash. Og så har vi to eksempler på multicore-prosessorer. Dette er en dual-core AMD-prosessor. Her ser vi CPU, eller da regneenheten, ALU, registeren og alt dette her, sitter inne i CPU. Og så har vi to atskilte L1- og L2-cash. Og så har du en dual-core Intel-prosessor som er litt annerledes. Her har du CPU med L1-cash, men så ser vi at L2-cash er felles. Og hva som er best av disse arkitekturene, det varierer litt.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0013", "start": 1007.64, "end": 1090.84, "token_count": 288, "text": "Og så har vi to atskilte L1- og L2-cash. Og så har du en dual-core Intel-prosessor som er litt annerledes. Her har du CPU med L1-cash, men så ser vi at L2-cash er felles. Og hva som er best av disse arkitekturene, det varierer litt. Som sagt så er det vanlig at man legger på en L3-cash her også, som f.eks. kan være felles. Men hva som er best, det kan variere litt med hva slags load du har på prosessoren. Hva den skal kjøre, altså på den serveren. Noen ganger, så... Hvis det er veldig mange like prosesser som deler veldig mye, så kan det være en fordel å ha mye felles cash. Men hvis de hele tiden gjør helt forskjellige ting, så kan det være en fordel å ha hvert sitt cash på denne måten her. Så der er det ikke noen fasit på hva som er best av det. Intel Core AMD K10. Dette er noen ikke helt nye CPU-er. De fleste CPU-er ser ganske like ut som disse her i dag. Dette her ser vi er en fire-core CPU.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0014", "start": 1063.12, "end": 1197.24, "token_count": 297, "text": "så kan det være en fordel å ha hvert sitt cash på denne måten her. Så der er det ikke noen fasit på hva som er best av det. Intel Core AMD K10. Dette er noen ikke helt nye CPU-er. De fleste CPU-er ser ganske like ut som disse her i dag. Dette her ser vi er en fire-core CPU. Så Intel Core E7, den har denne arkitekturen her. Så her ser vi... Det er fire CPU-er. Hver har L1-cash og L2-cash separat. Og så har de en felle. AMD-K10 er ganske lik. Den har litt mer L2-cash. Ellers er de ganske like. Neste punkt vi skal se på, er hypertrening, men vi kan se på... Et eksempel til før vi går inn på det. For... Skal vi se... Skal jeg finne riktig vindu? Linux-VM-ene deres kjører. Eller det vil si... Egentlig er det dokkercontainere. Dokker PC-er, så får jeg opp 100 forskjellige dokkercontainere. Som er de dere kjører. Men det jeg egentlig skulle se på, var... LSCPU, den sier litt om... Gir litt informasjon om CPU-en. ", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0015", "start": 1174.42, "end": 1273.04, "token_count": 294, "text": "Egentlig er det dokkercontainere. Dokker PC-er, så får jeg opp 100 forskjellige dokkercontainere. Som er de dere kjører. Men det jeg egentlig skulle se på, var... LSCPU, den sier litt om... Gir litt informasjon om CPU-en.  Og her så ser vi... Her står modellnavnet AMD Epic. Epic er en... Eller Epic 7552. Det er da modellnavnet på denne prosessoren. Og den bruker Zen Z1-mikroarkitekturen, som er en mikroarkitektur som AMD har designet. Og mikroarkitektur, det er... Og litt om det i notatene i dag. Det er på en måte hvordan instruksjonssettet er implementert av AMD. For instruksjonssettet, det er X86. Og Intel lager også CPU-er som implementerer dette institusjonssettet. Dvs. Move og Ad og alle disse institusjonene er helt like. Sånn at kode som kjører på AMD, den kan også kjøre Men hvordan dette her er implementert med LN-cash og med mikrooperasjoner og med pipelining osv., det er forskjellig fra prosessor til prosessor.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0016", "start": 1250.84, "end": 1343.28, "token_count": 287, "text": "Dvs. Move og Ad og alle disse institusjonene er helt like. Sånn at kode som kjører på AMD, den kan også kjøre Men hvordan dette her er implementert med LN-cash og med mikrooperasjoner og med pipelining osv., det er forskjellig fra prosessor til prosessor. Og AMD og Intel har hatt helt forskjellige approaches i mange tilfeller. Vi ser dette er en 48-corer-prosessor, men den har SMT, simultaneous multi-tredding. Og det er noe av det vi skal se på nå. Det er en helt annen tippemultetrening som foregår helt på prosessornivå. Men vi ser at den har 48 courses per socket. Og så har den... Et eller annet sted her så står det... Threads per core er 2 her, ja. Så totalt sett så har den hatt 96... Uavhengige treads. Vi skal se litt nøyere hva det egentlig betyr. Men så kan vi også se på cash. Her ser vi det er ganske mye cash. LND er datacash. LNI er instruksjonscash. Og... Så LNCash er på 3 MB. L2 er på 24...", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0017", "start": 1317.24, "end": 1431.36, "token_count": 283, "text": "Uavhengige treads. Vi skal se litt nøyere hva det egentlig betyr. Men så kan vi også se på cash. Her ser vi det er ganske mye cash. LND er datacash. LNI er instruksjonscash. Og... Så LNCash er på 3 MB. L2 er på 24... Og eldre på hele 192. Og det er ganske mye mer enn det vi så på AMD K10. OK. Så det var AMDoc, som er serveren som dere kjører på. Så når dere er inne på VM-ene og kjører LSPU, så er det... Dockercontainere deler på den underliggende operativsystemet, og da selvfølgelig også den underliggende serveren med serverservene. Til forskjell fra virtuelle maskiner, så kan du med dockercontainere... Når du lister, så vil du se den virkelige, fysiske serveren. For containere sitter tettere på operativstemme enn det virtuelle maskiner gjør. Vi ses inntil senere. Da skal vi gå videre og se på hypertrading. Ja, hypertrading er opprinnelig en markedsføringsterminologi", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0018", "start": 1395.84, "end": 1494.6, "token_count": 284, "text": "Når du lister, så vil du se den virkelige, fysiske serveren. For containere sitter tettere på operativstemme enn det virtuelle maskiner gjør. Vi ses inntil senere. Da skal vi gå videre og se på hypertrading. Ja, hypertrading er opprinnelig en markedsføringsterminologi som Intel innførte. Det er altså Intels varemerke hypertrading. Som vi ser her nede, så er... Den generelle betegnelsen er SMT. Simultaneous Multitreading. Så når AMD bruker det samme prinsippet, så kaller de det for SMT. Men vi ser først på Intel og hyperthreading. Hyperthreading består i at én single core CPU, dvs. én CPU som har én enkelt alu, én regneenhet, én kjerne, Litt av innholdet i CPU-en er da duplisert. Spesielt registre. Man må ha egne registre for hver av de to prosessene. For det kan ikke lastes ut. Men dette foregår da på hardware-nivå. Så operativsystemet opplever dette som to selvstendige prosessorer.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0019", "start": 1467.24, "end": 1567.28, "token_count": 295, "text": "Litt av innholdet i CPU-en er da duplisert. Spesielt registre. Man må ha egne registre for hver av de to prosessene. For det kan ikke lastes ut. Men dette foregår da på hardware-nivå. Så operativsystemet opplever dette som to selvstendige prosessorer. Men det som skjer i virkeligheten, er at når OS fordeler prosesser til denne prosessoren som er hypertraining, så settes det i gang to prosesser på samme CPU. Men de to prosessene deler da alønn som er på denne CPU-en. Da er det hardware som switcher kjøpt imellom de to prosessene. Dette skjer i løpet av nanosekunder. Altså ekstremt hurtig. Og dette er ikke i nærheten av det som skjer når man gjør contex-switch med OS. Det tar veldig mye lengre tid. Og denne teknologien er da lagd fordi man har sett at selv om man har pipelining og mikrooperasjoner som utføres i parallell på superskalare CPU-er, Det må hele tiden være litt hardware-ressurser som ikke blir brukt. F.eks. at alun ikke blir utnyttet fullstendig.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0020", "start": 1537.84, "end": 1630.88, "token_count": 296, "text": "Og denne teknologien er da lagd fordi man har sett at selv om man har pipelining og mikrooperasjoner som utføres i parallell på superskalare CPU-er, Det må hele tiden være litt hardware-ressurser som ikke blir brukt. F.eks. at alun ikke blir utnyttet fullstendig. Det er typisk fordi at selv med cash må man noen ganger vente på resultater, eller vente på noe fra RAM eller fra andre devices. Og denne ventetiden utnyttes av å lynhurtig switche frem og tilbake mellom de to prosessene som kjører. Og det er dette som er hypertrening. Det typiske er at de har egne registre for hver prosess, men deler felles alder. Etterpå skal vi kjøre noen tester, og da vil vi se at det går saktere når man har hypertrening, fordi de må dele på alderen. Og som jeg nevnte - hypertrening styrer, så har du vel. Så OS vet egentlig ikke noe om dette her. Jeg vet litt om det, men den er ikke med og styrer. Den bare gir prosesser til CPU-en, og så utfører CPU-en disse lynhurtige switchene", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0021", "start": 1610.08, "end": 1749.32, "token_count": 288, "text": "Og som jeg nevnte - hypertrening styrer, så har du vel. Så OS vet egentlig ikke noe om dette her. Jeg vet litt om det, men den er ikke med og styrer. Den bare gir prosesser til CPU-en, og så utfører CPU-en disse lynhurtige switchene mellom de to prosessene vi kjører. Ok. Da skal vi se på noen eksempler på hypertrening. Så da skal vi se... Da må jeg skifte om på å gå litt... Ja, da skal vi ta et eksempel fra den maskinen vi var på. Rex, for det er en... en desktop som har åtte sepur. Men så må jeg jobbe litt i bakgrunnen her. Og så må jeg... Hvis dere husker, så skrudde jeg av noen av sepurene hennes. Jeg lovte jeg skulle vise hvordan jeg gjorde det. Her er jeg nå på den Rex, en desktop. Den ser vi her når jeg taster én i topp, så får jeg opp at den har fire supper. Men her ser vi at jeg har en løkke som endrer på noe... Og den kan sette de forskjellige CPU-ene online. Så det er åtte CPU-er her.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0022", "start": 1714.04, "end": 1818.6, "token_count": 287, "text": "Her er jeg nå på den Rex, en desktop. Den ser vi her når jeg taster én i topp, så får jeg opp at den har fire supper. Men her ser vi at jeg har en løkke som endrer på noe... Og den kan sette de forskjellige CPU-ene online. Så det er åtte CPU-er her. Så det jeg gjør nå, er at jeg setter de resterende fire online. Sånn at hvis jeg nå taster topp og én, så ser vi - vips, så kom det fire CPU-er til. Så nå er denne en server. Eller en desktop med fire... Nei, med åtte CPU-er. Og hvis jeg gjør LSCPU, så ser vi også at dette her er... One-line CPU-list. Null til syv. Åtte CPU-er. Men så ser vi at det står to threads per core og core per sockets. Og vi ser også at dette er en Intel Core E7. Slår man opp på det, så vil man finne ut at denne her bruker hypertrening. Og min påstand nå er at dette er hypertrening. Den er faktisk... Det er egentlig ikke åtte helt uavhengige course, sånn som operativsystemet fremstiller det.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0023", "start": 1791.5, "end": 1882.68, "token_count": 296, "text": "Og vi ser også at dette er en Intel Core E7. Slår man opp på det, så vil man finne ut at denne her bruker hypertrening. Og min påstand nå er at dette er hypertrening. Den er faktisk... Det er egentlig ikke åtte helt uavhengige course, sånn som operativsystemet fremstiller det. Og sånn som det ser ut når man kjører topp eller hope-topp, så ser man at her er det åtte suppeur. Men vi skal nå se på hva... Hvordan ser det ut når vi kjører prosesser på disse åtte CPU-ene? Eller er det egentlig fire? Det er problemstillingen her nå. Er dette åtte helt selvstendige CPU-er? Eller er det fire CPU-er som kjører hypertraining og på en måte lurer OS til å... Til å tro at det er åtte? Så det første vi kan gjøre da, det er jo også å prøve å kjøre mange prosesser. Og så se hvordan det ser ut. Og vi hadde en fåløkke med reine... Ja, det ble det veldig mange. Én, to, tre, fire, fem. Det man kan gjøre litt enklere, er å si noe sånt.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0024", "start": 1861.9, "end": 1990.28, "token_count": 281, "text": "det er jo også å prøve å kjøre mange prosesser. Og så se hvordan det ser ut. Og vi hadde en fåløkke med reine... Ja, det ble det veldig mange. Én, to, tre, fire, fem. Det man kan gjøre litt enklere, er å si noe sånt. Da sier jeg har én til... Åtte prosesser. Så kjører jeg topp her samtidig. Oi. Nå ser jeg at jeg har feil vindu. Rop ut. Ja vel. Jeg kan gjøre det på nytt. Det jeg gjorde, var at jeg startet... Nå er det åtte CPU-er som står og kjører her. Bare for å få det veldig eksplisitt, så kan vi sette på den last used CPU her nede. Da må jeg få utvide topp lite grann. Der, ja. Der har vi Las Jusipu. Så kjører jeg nå åtte prosesser. Og vi ser da 016728 osv. De kjører i parallell på disse åtte Sipuene. Sånn sett så ser det jo vel og bra ut. Men da er spørsmålet... Hvordan kan jeg finne ut nå?", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0025", "start": 1957.52, "end": 2053.12, "token_count": 297, "text": "Der, ja. Der har vi Las Jusipu. Så kjører jeg nå åtte prosesser. Og vi ser da 016728 osv. De kjører i parallell på disse åtte Sipuene. Sånn sett så ser det jo vel og bra ut. Men da er spørsmålet... Hvordan kan jeg finne ut nå? Er dette 100 %? Kjører de 100 % på helt uavhengige regneenheter? Eller er det hypertraining, som man kan lese at det faktisk er?  Og hvordan ser man i så fall forskjell på det? Jo, for å gjøre en lang historie kort, så kan man jo... Hvis det er hypertrening, så betyr det at da er det fire A-lur. Og hvis det da er åtte jobber som står og jobber, så er det klart... Da har operativsteamet satt inn to stykker på hver av CPU-ene. Og de må da bytte på. Og de må da dele på den aluen. Og det vil jo ikke da gå like fort å kjøre fire som å kjøre åtte. Så det vi kan gjøre, er å prøve å ta noen eksperimenter. Først så kan jeg prøve å kjøre fire jobber.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0026", "start": 2033.32, "end": 2120.72, "token_count": 293, "text": "Og de må da dele på den aluen. Og det vil jo ikke da gå like fort å kjøre fire som å kjøre åtte. Så det vi kan gjøre, er å prøve å ta noen eksperimenter. Først så kan jeg prøve å kjøre fire jobber. Nå er de på hver sine CPU. Og kjører fulle ruller på dem. Og så kan vi se hvor lang tid tar egentlig det. Så dette er på en måte litt sånn som... Ja, altså, i notatene så har jeg et eksempel på... Hvis man har potetskrellere, altså personer som skreller poteter, som står inne i hver sin bod, så kan man jo teste... Hvis det er to personer som står inne der og deler en potetskreller. Så vil det måtte gå dobbelt så lang tid å skrelle poteter. Så det er potetskrelling jeg egentlig holder på med her. Vi ser når jeg kjørte åtte... Nei, når jeg kjørte fire... Så tok dette her realtime 18,5 sekunder. Usertime 18,5... Jo, det betyr at disse prosessene fikk tilgang til 100 % av CPU.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0027", "start": 2093.32, "end": 2182.22, "token_count": 294, "text": "Så det er potetskrelling jeg egentlig holder på med her. Vi ser når jeg kjørte åtte... Nei, når jeg kjørte fire... Så tok dette her realtime 18,5 sekunder. Usertime 18,5... Jo, det betyr at disse prosessene fikk tilgang til 100 % av CPU. Og da skulle også realtiden... Den totale realtiden skulle da være 18,5. Så dette er riktig. Sånn... Sånn bør det være. Men vi kan begynne å ane nå at dette tar mye lengre tid. Og vi ser faktisk... Jo... Dette tok nesten dobbelt så lang tid. Vi ser... 18 sekunder tok det for én CPU. Én prosess på én enkel CPU. Men når vi delte inn i åtte prosesser, så tok det 35,7 sekunder. Altså... 37 ville vært det dobbelte. Så vi kan se at vi har hatt en ørliten effekt av hyperthreading. Men stort sett så ser vi disse to prosessene her... De måtte faktisk dele på samme alu, og det er derfor det tok mye lengre. Nesten dobbelt så lang tid å regne ut.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0028", "start": 2166.6, "end": 2267.52, "token_count": 294, "text": "Så vi kan se at vi har hatt en ørliten effekt av hyperthreading. Men stort sett så ser vi disse to prosessene her... De måtte faktisk dele på samme alu, og det er derfor det tok mye lengre. Nesten dobbelt så lang tid å regne ut. Det er også litt forvirrende, for det står fortsatt 99 %, men dette er sånn som operativsystemet ser det på. Men i virkeligheten så switcher de lynhastig frem og tilbake. Og da kan man jo lure på hvorfor er dette... Hvorfor er dette hypertrening så viktig i det hele tatt? Men da har vi et... Skal vi se... Et program som heter RAM2. Det er et program som bruker et RA. Og så gjør den en masse RA-operasjoner. Den leser masse inn og ut fra RAM. Og da vil sånn som hypertraining kunne ha en effekt. Ramm2-programmet. Og så kjører det i stedet. Vi kan gjøre den samme testen. Vi kan kjøre én til fire. Nei... Det var... Det var feil. Sorry. Vi skulle ikke kjøre regn nå. Nå skulle vi kjøre Adopt-Alt. Sånn.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0029", "start": 2243.32, "end": 2341.32, "token_count": 298, "text": "Ramm2-programmet. Og så kjører det i stedet. Vi kan gjøre den samme testen. Vi kan kjøre én til fire. Nei... Det var... Det var feil. Sorry. Vi skulle ikke kjøre regn nå. Nå skulle vi kjøre Adopt-Alt. Sånn. Nå kjører jeg fire av de Ramm-programmene samtidig. Vi lar kjøre på hver sin CPU, og de bruker det fire sekunder. Og så setter jeg i gang åtte av dem. Hvis hypertraining ikke er noe effektivt nå, så ville dette tatt åtte sekunder. Men vi ser... Her hadde hypertraining plutselig en veldig stor effekt. For nå brukte vi realtid 4,3 sekunder. Mens her så brukte vi bare fire. Og dette viser hypertreading med sitt største potensial. Her så klarte Operativstemme da setter inn to prosesser på én og samme CPU med samme alu. Men siden her er det mye snakk med minnet, man må hele tiden vente for å... Her oppe så klarer ikke én prosess å utnytte CPU-en fullstendig. Derfor er hypertrening veldig effektivt, for da kan disse to stå og bytte på", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0030", "start": 2320.98, "end": 2421.76, "token_count": 288, "text": "Men siden her er det mye snakk med minnet, man må hele tiden vente for å... Her oppe så klarer ikke én prosess å utnytte CPU-en fullstendig. Derfor er hypertrening veldig effektivt, for da kan disse to stå og bytte på og gjøre de institusjonene de trenger på CPU-en. Og så får de gjort jobben veldig mye raskere. Men dette var de to ekstreme tilfellene. En regnejobb kan ikke utnytte hypertrening, men en rammejobb kan utnytte det veldig godt. Ofte så er det litt imellom, men i snitt så kan du kanskje få en sånn 30-40 % forbedring. Med hypertrening. Ok. Da skal... Ja, jeg ser vi har brukt ganske mye tid her. Jeg lurer på om vi skal utsette den biten med... Med hvorfor man ikke kan kjøre to prosesser samtidig. Vi kan se i stedet... Litt mer på hypertraining. Og spesielt så kan vi se på task-sett. For det er en interessant metode hvis vi... Jo, vi har sett at operativsystemet fordeler prosesser på CPU.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0031", "start": 2382.0, "end": 2512.92, "token_count": 285, "text": "Jeg lurer på om vi skal utsette den biten med... Med hvorfor man ikke kan kjøre to prosesser samtidig. Vi kan se i stedet... Litt mer på hypertraining. Og spesielt så kan vi se på task-sett. For det er en interessant metode hvis vi... Jo, vi har sett at operativsystemet fordeler prosesser på CPU. Men nå skal vi se på en metode vi kan bruke for å selv spesifisere hvilken CPU en oppgave skal kjøres på. Og det kan vi gjøre med TaskSet. Og da kan vi time dette også. Men programmet TaskSet er et verktøy som gjør at vi kan se... Tasset minus C null sier plasser den følgende jobben på CPU0. Så når jeg kjører denne regnejobben her nå, så sier jeg at den skal så på CPU0. Da kunne jo kanskje... Hvis vi kjører AgeStop... Jeg kan kjøre Toppe. Skrur på Last Used CPU. For å se hvor den kjører. Der har vi med Last Used CPU. Så sier jeg start den på... Kjør den på prosessor 0, og da ser vi. Den kommer på.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0032", "start": 2477.06, "end": 2598.76, "token_count": 286, "text": "Hvis vi kjører AgeStop... Jeg kan kjøre Toppe. Skrur på Last Used CPU. For å se hvor den kjører. Der har vi med Last Used CPU. Så sier jeg start den på... Kjør den på prosessor 0, og da ser vi. Den kommer på. Hvis jeg i stedet sier kjør den på prosessor 1... Så ser vi. Da starter den å kjøre på 1. Det gjør at vi kan gjøre noen interessante eksperimenter, for da kan vi eksplisitt se nå vil jeg kjøre begge regnejobbene på prosessor 1. La oss bruke Adatat, som er litt raskere. La oss si nå... Jeg skal starte to regnejobber. Men så vil jeg da time task-sett, og så vil jeg sette begge på null. Sånn. Og nå vil begge de to regnejobbene kjøre på samme prosessor. Da får de bare 50 % CPU. Fordi da har jeg eksplisitt satt de på den samme CPU-en. Hvis jeg i stedet hadde satt de på CPU1 og -2 på den måten, da ville de to regnejobbene kjørt på hver sin CPU.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0033", "start": 2573.32, "end": 2685.8, "token_count": 300, "text": "Da får de bare 50 % CPU. Fordi da har jeg eksplisitt satt de på den samme CPU-en. Hvis jeg i stedet hadde satt de på CPU1 og -2 på den måten, da ville de to regnejobbene kjørt på hver sin CPU. Da gjør vi sånn som operativsystemet ville ha gjort det. Og det går da dobbelt så fort. Helt til slutt så kan vi se litt på... Se litt på hvordan man kan... Finne ut hvilke CPU-er som tilhører hvilken... Nei... Hvilke par det er av CPU-er som er hyperthrødding. Denne Thrød-siblings-list som jeg lister her, er en liste over hvilke CPU-er som hører sammen. Da kan vi se på denne her. I dette tilfellet så er det CPU-110 og -4 som egentlig er Thrød-siblings, som er de to som da deler på aluen. Helt til slutt så kan vi... Prøve å se om det er tilfellet. For jeg kan... Først kan jeg kjøre regnejobber på denne måten. Da sier je... Sett nå regnejobben på CPU1. Den første settes på CPU1, og den andre settes på CPU2.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0034", "start": 2659.4, "end": 2750.72, "token_count": 297, "text": "Helt til slutt så kan vi... Prøve å se om det er tilfellet. For jeg kan... Først kan jeg kjøre regnejobber på denne måten. Da sier je... Sett nå regnejobben på CPU1. Den første settes på CPU1, og den andre settes på CPU2. Hvor lang tid tar det nå å kjøre den regnejobben? Jo, det tar 18 sekunder. Men så kan jeg i stedet si... OK, nå vil jeg eksplisitt sette de to jobbene på 0 og 4. Dette betyr nå kjør den ene på 0 og kjør den andre på 4. Og det var ikke tilfeldig valg, for nå har jeg bedt dem om å kjøre regnejobbene på den samme hyperthreading-CPU-en. Så nå er det 0-4. De er siblings. Det betyr... De deler på en del av hardwaren, inkludert Sippuen. Så nå ser vi straks at dette tar lengre tid. De står på 0-4. Kunne si at de står på 0-4 her. Men tiden det tok, den var nå... Den ble da plutselig så godt som doblet. Det er fordi 0-4...", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0035", "start": 2726.88, "end": 2816.4, "token_count": 296, "text": "De deler på en del av hardwaren, inkludert Sippuen. Så nå ser vi straks at dette tar lengre tid. De står på 0-4. Kunne si at de står på 0-4 her. Men tiden det tok, den var nå... Den ble da plutselig så godt som doblet. Det er fordi 0-4... Det er akkurat samme kommandoen her. 1 og 2. I stedet her kjører vi på 0 og 4, og da er det på samme hypertrening CPU. Og da må du bytte på å dele aluen, og dermed går det dobbelt så lang tid å få det feil. OK... Jeg ser det er noen spørsmål i chatten her. Hadde også tatt fire sekunder om du kun kjørte ett, ja. Ja. Det var litt tilbake her. Men hvis jeg bare kjører én, så tar det også fire sekunder. Så om man kjører... Så. Det var vel den her. Hvis jeg bare kjører én prosess, sånn som dette, så tar det fire sekunder. Og hvis jeg da kjører fire uten noe task-sett eller noe som helst... Hvis jeg ikke bruker Tastset...", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0036", "start": 2793.14, "end": 2889.52, "token_count": 298, "text": "Det var vel den her. Hvis jeg bare kjører én prosess, sånn som dette, så tar det fire sekunder. Og hvis jeg da kjører fire uten noe task-sett eller noe som helst... Hvis jeg ikke bruker Tastset... Og kjører fire prosesser, så er dette fire helt uavhengige CPU-er. Og de bruker da like lang tid som om jeg kjører igjen. Vi kan se noen ganger at det tar litt mer tid. Og det er fordi at da kjører du 100 % på alle fire CPU-ene på en server. Og det er alltid noe prosesseringskraft som trengs på en server for å styre alle andre prosesser. Sånn at ofte så vil du se at det går litt mer tid. Men generelt sett så tar det omtrent fire sekunder. Om du kjører på én, eller om du kjører på fire. Men som vi har sett når vi da kjører på alle åtte, så... Og så tar det nesten dobbelt så lang tid fordi det egentlig er hypertrening. AMD har det samme, som på din IMDoc-serveren som dere har konteinere. Den har også hypertrening, eller AMDs hypertrening, som er SMT.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0037", "start": 2867.72, "end": 2955.04, "token_count": 287, "text": "Men som vi har sett når vi da kjører på alle åtte, så... Og så tar det nesten dobbelt så lang tid fordi det egentlig er hypertrening. AMD har det samme, som på din IMDoc-serveren som dere har konteinere. Den har også hypertrening, eller AMDs hypertrening, som er SMT. Simultaneous Multitredding. Det er det også på den serveren. OK. Men da stopper vi der, og så... Er vi nå... Jeg tror vi faktisk er tre studentassistenter. Så jeg skal sette opp break-out-rooms. Så der er det masse hjelp å få i dag. Og så må dere huske at det er oblig-innlevering, men det er først etter... etter konteuken. Så når dere er ferdig med oppgaven denne uken, så er det først etter... etter... etter... konteuken. Og så må dere også huske å ta MC1. Ta den så snart som mulig. Og så spør studentassistenten om hjelp hvis dere får mindre enn syv og må gjøre den om igjen. Da får dere kanskje noen gode tips også om hva dere bør se på før dere tar den en gang til.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0038", "start": 2930.84, "end": 2967.7, "token_count": 93, "text": "Og så må dere også huske å ta MC1. Ta den så snart som mulig. Og så spør studentassistenten om hjelp hvis dere får mindre enn syv og må gjøre den om igjen. Da får dere kanskje noen gode tips også om hva dere bør se på før dere tar den en gang til. Da tar jeg en liten pause der og bygger opp Break Old Rooms.", "source": "lecture"}
{"lecture_id": "linux12del5", "chunk_id": "linux12del5_0000", "start": 0.0, "end": 118.12, "token_count": 289, "text": "Ok. Vi kunne jo teste ut... Nå er jeg i skjellet, men vi kunne jo teste ut den PowerShell... GUI... Eller utviklingsverktøyet. Som er default. Hvis jeg begynner å skrive PowerShell her, så kommer den ISE opp. Så kan jeg teste ut den. Her kommer det opp noen eldre skrift jeg har skrevet tidligere. Så kommer det opp en oversikt over kommandoer. Den kan du skru av og på. Jeg skrur den av. Det er ganske enkelt å gjøre det sånn at man har... Man har ett vindu her oppe hvor man skriver skrift, og så kjører man det samtidig. ... i Linux, hvor vi deler opp. Har ett vindu med Jet og ett vindu med en kommandolinje. Så kan jeg f.eks. lage en ny... ja, du kan starte med Hello World. Nei... Man trenger ikke å ha med ekko, man kan bare skrive 'hello'. Nå er dette et skript. Da må jeg taste FM. Så kan jeg kjøre det skriptet. Så kan jeg lagre det kanskje som... Som hello.pc. Oi. Da vil jeg her nede ha fått en hello.pc.", "source": "lecture"}
{"lecture_id": "linux12del5", "chunk_id": "linux12del5_0001", "start": 80.46, "end": 221.12, "token_count": 290, "text": "Nei... Man trenger ikke å ha med ekko, man kan bare skrive 'hello'. Nå er dette et skript. Da må jeg taste FM. Så kan jeg kjøre det skriptet. Så kan jeg lagre det kanskje som... Som hello.pc. Oi. Da vil jeg her nede ha fått en hello.pc. Ja, men vi kan kanskje... Jo, vi kan fortsette her. Så kan vi prøve f.eks. å lage et skript som legger sammen størrelsen på filer. Størrelsen på tekstfiler. Da kan vi starte med det. Det man typisk bruker, er foreach. Her ser du at han også kan bruke tab. Foreach-konstruksjonen ser sånn ut. Man starter med en parentes. Så kan jeg... La oss si jeg vil ha for hver fil i... LS. Sånn. For hver fil ønsker jeg å legge sammen lengden. Og da inni 4-ition vil da fil være hvert objekt. Og fil sin lengde... fil sin lengde... det vil da være størrelsen på filen. Men jeg skal summere den størrelsen, så da kan jeg si dollarsum pluss enikk fil sin lengde og sånn.", "source": "lecture"}
{"lecture_id": "linux12del5", "chunk_id": "linux12del5_0002", "start": 190.72, "end": 318.64, "token_count": 294, "text": "Og da inni 4-ition vil da fil være hvert objekt. Og fil sin lengde... fil sin lengde... det vil da være størrelsen på filen. Men jeg skal summere den størrelsen, så da kan jeg si dollarsum pluss enikk fil sin lengde og sånn. Og så kan jeg avslutte. Og så kan jeg kanskje til slutt skrive ut... Lengde... dollar... sum. Sånn. Og så kan jeg prøve å kjøre det. Da får jeg bare en melding om at den saver. Det er greit. Da ser vi her nede, så ble da den fint kjørt. Man kan også gå opp og ned med kontroll i og kontroll d. Og så kan man kjøre programmene her direkte i kommandolinjen. Ja, der ser vi... Nå står jeg i OS her, mens den som jeg lagde, den ligger i det. Så jeg kan gå ned til moppen der. Så kan jeg kjøre den hello jeg har lagd her. Og da ser vi at vi får den sånn. Ja, så kan man... lage varianter av den her. Eller stjernedottekst er det mulig å gjøre, men man kunne også gjøre noe tilsvarende.", "source": "lecture"}
{"lecture_id": "linux12del5", "chunk_id": "linux12del5_0003", "start": 287.04, "end": 409.6, "token_count": 293, "text": "Så jeg kan gå ned til moppen der. Så kan jeg kjøre den hello jeg har lagd her. Og da ser vi at vi får den sånn. Ja, så kan man... lage varianter av den her. Eller stjernedottekst er det mulig å gjøre, men man kunne også gjøre noe tilsvarende. Bare for å legge inn en if-test der også. If... if dollar feel... Jeg nå prøver å tampe her. Ja, så fungerer den. Hvis jeg ønsker at den skal være lik trekksted... Vi kan prøve først og så gjøre det sånn. Dette fungerer ikke. Vi skal se på hvorfor. Men først så tar vi hvis den extension er trekksted. Ønsker jeg å legge til... Sånn. La oss bare prøve å kjøre det med F5. Jo. Det ser faktisk ut som den virket. Jeg trodde man trengte.xl, men det ser ikke sånn ut. Ja. Da ser det ut som begge deler fungerer. Hvis jeg tar doktekster også, så får man det samme svaret. Uansett. Dette er en generell måte man kan utvikle forskjellig skript på.", "source": "lecture"}
{"lecture_id": "linux12del5", "chunk_id": "linux12del5_0004", "start": 377.52, "end": 426.34, "token_count": 141, "text": "Jeg trodde man trengte.xl, men det ser ikke sånn ut. Ja. Da ser det ut som begge deler fungerer. Hvis jeg tar doktekster også, så får man det samme svaret. Uansett. Dette er en generell måte man kan utvikle forskjellig skript på. Det er ganske enkelt med det verktøyet her. Og du kan ha et skript her oppe, og så raskt kan teste du ut fire kjøl. Det er fantastisk å se hvordan folk oppfører seg og hvordan de oppfører seg.", "source": "lecture"}
{"lecture_id": "linux6del1", "chunk_id": "linux6del1_0000", "start": 0.0, "end": 102.44, "token_count": 297, "text": "Få de virtuelle Linux-maskinene, som egentlig er Linux-containere, eller Docker-containere. Så har dere alle rettigheter, dvs. dere har sudo-rettigheter. Og det betyr at dere kan bli RUT. Generelt så kan man bli RUT hvis man har RUT-passordet. Men det er enda vanligere å sette opp brukere som såkalte sudobrukere, som da kan Spesielt fordi da kan man se senere i logger osv. om hvem som, som Ruth, gjorde de forskjellige operasjonene. Og så kan man gjøre Ruth-operasjoner med sudo. F.eks. sudo-app-install, også et program, uten å åpne et Ruth-shell. Men vi kan først se hvordan dere logger inn på... Gruppene på VM-ene. Nå har jeg OS 100. Så hvis dere må først bli med i en OS-gruppe... I mitt tilfelle OS 100, og så... Nei, vi skal være at. Så Gruppe 100 at OS 100. Det er da... OS 100 er hovednavnet. Og så må dere bruke.vel. Det er hele domenenavnet til OS100. Da kan du longe inn sånn, akkurat som på Study SSO.", "source": "lecture"}
{"lecture_id": "linux6del1", "chunk_id": "linux6del1_0001", "start": 73.56, "end": 174.36, "token_count": 296, "text": "I mitt tilfelle OS 100, og så... Nei, vi skal være at. Så Gruppe 100 at OS 100. Det er da... OS 100 er hovednavnet. Og så må dere bruke.vel. Det er hele domenenavnet til OS100. Da kan du longe inn sånn, akkurat som på Study SSO. Litt på tilsvarende måte med SSH eller med Putty eller med andre måter. Og så... Her ser jeg jeg kommer rett inn uten å taste passord. Og det er fordi jeg har lagt opp en SSH-key. Det kommer vi til senere. Sånn at dere da senere kan logge rett inn fra Study SSO til Linux-femmene. Men vanligvis må man ha et tastepassord. Og da ser dette ganske ut som på Study SSO. Og her har jeg noen filer som jeg har lagd. Det er hjemmemappe i Home Group 100. Og det at dere har sudorettigheter... Det betyr at hvis dere gjør sudo su, denne kommandoen... Og så skriver passordet. Så ser dere at dere får opp en annen prompt enn hashtag-prompt. Så det betyr at dere er Rut. Nå gjør jeg CD, så kommer jeg hjem til Rut.", "source": "lecture"}
{"lecture_id": "linux6del1", "chunk_id": "linux6del1_0002", "start": 145.88, "end": 239.4, "token_count": 290, "text": "Og det at dere har sudorettigheter... Det betyr at hvis dere gjør sudo su, denne kommandoen... Og så skriver passordet. Så ser dere at dere får opp en annen prompt enn hashtag-prompt. Så det betyr at dere er Rut. Nå gjør jeg CD, så kommer jeg hjem til Rut. Hjem til Rut, det er ikke i HomeRut, men det er i SlashRut. Og Ruth hører hjemme. I utgangspunktet så er det ikke så mye som ligger der. Jeg har lagd en historiefeil, men i utgangspunktet så er Ruth-mappen tom. Og når du er Ruth, så har dere da alle muligheter både til å ødelegge alt, men også til å f.eks. installere. Så her kunne man si Apt install, og så... F.eks. Ersping 3, som er en nettverkspakke, bare som et eksempel. Og da installerer man det. Og det vil altså være... Da kan alle brukere også bruke Ersping 3. Så kan man bruke sudo direkte. Det er kanskje å anbefale. Sudo app install... Ja, la oss si 3.", "source": "lecture"}
{"lecture_id": "linux6del1", "chunk_id": "linux6del1_0003", "start": 218.48, "end": 306.34, "token_count": 270, "text": "Og da installerer man det. Og det vil altså være... Da kan alle brukere også bruke Ersping 3. Så kan man bruke sudo direkte. Det er kanskje å anbefale. Sudo app install... Ja, la oss si 3. Den finnes ikke. Så jeg kan ta sudo app install. Og nå trengte jeg ikke å taste passordet. Det er fordi jeg allerede hadde sudo-passordet. Og da varer det en stund sånn at du ikke må taste det med en gang. Neste gang du logger inn, eller litt senere, så må du taste passordet på nytt. Og da kan man bruke kommandoen 3. Vi kan f.eks. ikke se passordfilen. Jo, passordfilen kan man se. Det går fint, som vanlig bruker. Men man kan ikke se shadowfilen med passordherskene. Da får du permission denied. Men så kan man da alltid, hvis man får permission denied som det, ikke ha lov, så kan man bruke sudo, og så får man plutselig lov. Hva er det som er så spesielt med denne filmen?", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0000", "start": 0.0, "end": 97.34, "token_count": 300, "text": "Hva er Linux? Linux er et operativsystem, et stort og komplisert program som styrer en datamaskin. Linux-kjernen ble opprinnelig lagd av Linus Thorvalds i 1991, mens Hansen var student. Og Gnu Linux er et mer korrekt navn på Linux. Egentlig bare operativstem, kjernen. Alle verktøyene rundt kjernen, sånn som et skjell og kompilator osv., det må man ha i tillegg til selve kjernen. Det finnes også en rekke andre distribusjoner, som Luntu og RedDat osv., og de lager sitt tilbehør på toppen av denne kjernen. Så ofte når man sier Linux... Så tenker man på alt som har med operatører å gjøre, inkludert kjernen. Strengt tatt så er Linux-kjernen i hvert fall det som Linus Thormalds utviklet. Linux er mest brukt som server Wes. Noen få, sånn som meg, bruker det som desktop, men det er ikke så mye utbredt der. Det er først og fremst som servere at det er mye brukt. Linus er et unix-OS. Andre unix-OS er sånn som BSD, Solaris og AX.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0001", "start": 73.82, "end": 169.2, "token_count": 291, "text": "Linux er mest brukt som server Wes. Noen få, sånn som meg, bruker det som desktop, men det er ikke så mye utbredt der. Det er først og fremst som servere at det er mye brukt. Linus er et unix-OS. Andre unix-OS er sånn som BSD, Solaris og AX. Det var noe som fantes for lenge siden. Altså, på 80-, 90-tallene så dominerte de verden når det gjaldt servere. Mens MacOS, altså operativsystemet som brukes som Mac, det er også et unix-operativsystem. I hvert fall halvdelen av det. Hvis du har en Mac, så kan du åpne en terminal, så får du en terminal som ligner veldig på det du har på et Linux-system. Operativsystemet Unix ble utviklet av Kent Homsen og Dennis Ritchie i 1969. På 70- og begynnelsen av 80-tallet var Unix det som Linux har vært de siste 20 årene. En viktig del av Linux-filosofien er å sette sammen mange små programmer på mange måter. Og det er det vi kommer til å jobbe med å se på når vi bruker Linux fra kommandolinjen.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0002", "start": 140.58, "end": 228.28, "token_count": 284, "text": "På 70- og begynnelsen av 80-tallet var Unix det som Linux har vært de siste 20 årene. En viktig del av Linux-filosofien er å sette sammen mange små programmer på mange måter. Og det er det vi kommer til å jobbe med å se på når vi bruker Linux fra kommandolinjen. Man har masse små programmer, og så setter man dem sammen på nye måter. Linux er et åpent kildegode. Det vil si Linux-kjernen er KPL. Gnu Public License, og det er en lisens som gjør at ikke bare kildekoden skal være åpen, sånn at alle kan lese den og se hva som foregår inni operativstrømkjernen. Det gjør også at man ikke kan ta denne koden, endre den og lage noe nytt, og så selge den som sin kode, som lukket, kjørbar kode. Det er ikke lov etter GPL. Endringer vil da komme Linux til nytte senere. For alle som gjør noen fornuftige endringer, må også publisere de endringene. Og dette har vært grunnlaget for Linux, og gjort at det har blitt så stort som det er.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0003", "start": 210.0, "end": 297.88, "token_count": 286, "text": "Endringer vil da komme Linux til nytte senere. For alle som gjør noen fornuftige endringer, må også publisere de endringene. Og dette har vært grunnlaget for Linux, og gjort at det har blitt så stort som det er. Som jeg sa, lagde Linus Tordalse i 1991, og det var ikke tilfeldig at det var samtidig med World Wide Web og denne enorme spredningen av kode. Og de enorme mulighetene til å samarbeide om kode, som er essensielt for fri-kildekode-prosjekter. Og det fins en rekke distribusjoner av Linux i alle størrelser. Det fins masse små i kameraer og mobiltelefoner, ikke minst. Android er bygd på... Eller har en Linux-kjerne. Og så fins det sånne som ruter og switcher og en masse forskjellige. Så finnes det store distribusjoner, sånn som Ubuntu, som vi bruker. Og Debian, som ligger ganske tett opp til Ubuntu. Så har vi Red Hat, Fedora Cento S, som er stor i USA. Suse, som er stor i Europa. Og en rekke andre distribusjoner.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0004", "start": 270.0, "end": 373.88, "token_count": 300, "text": "Så finnes det store distribusjoner, sånn som Ubuntu, som vi bruker. Og Debian, som ligger ganske tett opp til Ubuntu. Så har vi Red Hat, Fedora Cento S, som er stor i USA. Suse, som er stor i Europa. Og en rekke andre distribusjoner. De har samme operativsystemkjerne, men alt det rundt, systemsoftware rundt, og hvordan man installerer osv., det er det som er de forskjellige distribusjonene. Forskjellige vindussystem kan være osv. Vindussystemer, GUI, har man også på Linux med pek og klikk for de som trenger det. Altså etter hvert når vi blir gode på kommandolinjen, så trenger vi ikke... Denne bruker Gui. En fordel med kommanolinjen i forhold til Gui er at det er mye lettere å automatisere. Noen fordeler med Linux, som jeg har nevnt... Det er gratis med åpen kildekode. Det er ofte en naturlig del av åpen kildekode-prosjekter. Tradisjonelt så er sikkerheten stor på rundt Linux. Og alt det samme gjelder også stabilitet. Linux-operativsystemet er veldig stabilt. Det krasjer sjelden.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0005", "start": 345.76, "end": 455.8, "token_count": 291, "text": "Det er gratis med åpen kildekode. Det er ofte en naturlig del av åpen kildekode-prosjekter. Tradisjonelt så er sikkerheten stor på rundt Linux. Og alt det samme gjelder også stabilitet. Linux-operativsystemet er veldig stabilt. Det krasjer sjelden. Hvorfor du bruker Linux? Som jeg nevnte, er det ikke så mange som bruker det på desktopen. Browser går innom webservere, så kan man se hva slags plattform de kommer fra. Om de kommer fra Mac eller Windows eller mobil eller Linux. Så én av hundre, kanskje, bruke Linux på desktop. Men det er veldig anbefalt å prøve. Det går an å ha duel boot også på laptopen. Så installer Linux. Det er absolutt verdt et forsøk på. Egen laptop. Mens det er på servere som Linux blir veldig mye brukt. Webservere i en røfft anslag, kanskje 70 % av webservere kjører Linux. Så blir det nå veldig mye brukt i cloud, i skyen, i public cloud. Amazon, for eksempel, har 90 % Linux. Microsoft Acer har en god del Linux.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0006", "start": 420.0, "end": 539.56, "token_count": 300, "text": "Egen laptop. Mens det er på servere som Linux blir veldig mye brukt. Webservere i en røfft anslag, kanskje 70 % av webservere kjører Linux. Så blir det nå veldig mye brukt i cloud, i skyen, i public cloud. Amazon, for eksempel, har 90 % Linux. Microsoft Acer har en god del Linux. Så blir det veldig mye brukt i smartphones og i nettbrett. Hvor Android har noe sånt som 70 % av markedet. IOS har også et stort marked, men det er også, om ikke Linux-basert, så er det Unix-basert. I supercomputere så er det bare Linux. De 500 største supercomputerne kjører Linux. Linux og konteinere. Som vi har nevnt tidligere, så kommer vi til å bruke containere en god del. Da dokker-konteinere. Og de var opprinnelig også basert på Linux. Kanskje kom vi litt inn på det også, men dokkekonteinere skal vi bruke mye. Kybernetis er et system for å orkestrere, eller sette opp og organisere drift av konteinere. Vi kommer nok ikke inn på det, men det er sånn når dere begynner å jobbe i...", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0007", "start": 510.0, "end": 608.88, "token_count": 292, "text": "Kanskje kom vi litt inn på det også, men dokkekonteinere skal vi bruke mye. Kybernetis er et system for å orkestrere, eller sette opp og organisere drift av konteinere. Vi kommer nok ikke inn på det, men det er sånn når dere begynner å jobbe i... vil dere oppdage at kubernetis er veldig hot. Det blir brukt mer og mer, og konteinere blir brukt mer og mer. I 2018 ble det annonsert at IBM kjøper RedHat for 34 mrd. dollar. Så vi ser at det er veldig mye penger inhalert. Selv om Linux er free software, i utgangspunktet gratis, så... Og så er det andre forretningsmodeller som gjør at man kan tjene penger på det. Og nettopp sjefen for RedApp sa at 'Kupernetis is the new operating system'. Og det er også litt av grunnen til at vi jobber med dokker. Også lignende kommandolinje, fordi at vi gjennom dette kurset her ønsker at dere skal kunne lære teknologi og teknikk... Som ligger til bunn for veldig mye av det som skjer i dataverdenen.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0008", "start": 582.92, "end": 677.38, "token_count": 278, "text": "Og det er også litt av grunnen til at vi jobber med dokker. Også lignende kommandolinje, fordi at vi gjennom dette kurset her ønsker at dere skal kunne lære teknologi og teknikk... Som ligger til bunn for veldig mye av det som skjer i dataverdenen. Ok. Da skal vi se litt mer spesifikt på Linux og Linux-skjellet. Og ikke minst - hva er et skjell? Jo, et skjell er i utgangspunktet et kommandobasert verktøy. Som tar imot kommandoer fra tastatur... Du taster inn kommandoer, og så snakker de kommandoene med operativstemkjernen. Det er derfor vi kaller det et skjell eller et skall. Som figuren viser her, så er dette et skall rundt Linux-hjernen som sitter innerst. Og så utfører vi en rekke kommandoer, sånn som LSM... Det er små programmer som gjennom skjellet snakker med Linux-tjernen. Og inni alle disse små programmene er det til syvende og sist systemkall til Linux-tjernen.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0009", "start": 651.44, "end": 742.84, "token_count": 283, "text": "rundt Linux-hjernen som sitter innerst. Og så utfører vi en rekke kommandoer, sånn som LSM... Det er små programmer som gjennom skjellet snakker med Linux-tjernen. Og inni alle disse små programmene er det til syvende og sist systemkall til Linux-tjernen. Ja, så kan man spørre seg hvorfor trenger man et skjell, og hvorfor kommandolinjer i det hele tatt? Kunne man ikke, sånn som man gjør på Windows og...? Og på Mac... Og så... Hvorfor bruker man Gidgui og pek og klikk? Jo, det er noen viktige grunner til det. Først og fremst har man mye større frihetsgrad når man bruker et shell og kommandolinje. Og kanskje først og fremst så kan man automatisere det man gjør. Men man kan løse komplikasjoner. Vi setter sammen alle disse små Shell-kommandoene. Den teknikken skal dere lære veldig godt, sånn at dere raskt kan sette sammen masse små kommandoer for å få utført nøyaktig det du ønsker.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0010", "start": 716.92, "end": 802.32, "token_count": 279, "text": "Men man kan løse komplikasjoner. Vi setter sammen alle disse små Shell-kommandoene. Den teknikken skal dere lære veldig godt, sånn at dere raskt kan sette sammen masse små kommandoer for å få utført nøyaktig det du ønsker. Vi skal også lære Shell som et programmeringsspråk. Vi skriver såkalte Shell-script. Du kombinerer Linux-kommander, og du ender opp med små systemprogrammer som styrer systemet. Det som er problemet generelt med lange sekvenser av pek og klikk for å utføre noe, er at det er vanskelig å automatisere. Delvis er det vanskelig å forklare også. Man må kanskje ha CNL-video om hvordan man peker og klikker. Så kan du bare skrive ned en kommando. Så er det copy og paste. Du kan vise dette kommandoene. Eller du kan lage et lite skript som gjør akkurat det du trenger. Ellers er kommandolinjer generelt veldig mye brukt i Linux-automatisering. I skyen og mye sånt som i dokker, kubernetisk, git osv.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0011", "start": 783.64, "end": 869.12, "token_count": 296, "text": "Så er det copy og paste. Du kan vise dette kommandoene. Eller du kan lage et lite skript som gjør akkurat det du trenger. Ellers er kommandolinjer generelt veldig mye brukt i Linux-automatisering. I skyen og mye sånt som i dokker, kubernetisk, git osv. Alt dette kan du styre og effektivisere ved hjelp av Linux' kommandolinje. Vi kommer også til å se på Bindoff-kommandolinja, spesielt PowerShell, som faktisk ligner ganske mye på Linux-skjellskriptet. En del av kommandoene er akkurat det samme. Og PowerShell er veldig inspirert av Linux-skjellet. Ja... Nå skal vi prøve å logge inn på noen systemer, og da skal vi først si... Litt generelt om innlogging. På et Linux-system så har... Hver bruker har ett entydig brukernavn og et passord. Det er akkurat som på de fleste andre systemer. Det som er mer spesielt for Linux, er at alle brukerne på systemet, det ligger i en spesiell fil. I et passord. Og alle de krypterte passordene ligger i et...", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0012", "start": 846.56, "end": 947.68, "token_count": 298, "text": "Hver bruker har ett entydig brukernavn og et passord. Det er akkurat som på de fleste andre systemer. Det som er mer spesielt for Linux, er at alle brukerne på systemet, det ligger i en spesiell fil. I et passord. Og alle de krypterte passordene ligger i et... Shadow. Det er standard på en Linux-maskin. For noen av de serverne som vi har her, så... Så er det ikke fullt så enkelt. Da har du en autentisering som går til en sentral database på OsloMet. Men sånn generelt, hvis du bare installerer Linux fra scratch på en laptop, så får du dette opplegget, hvor passordene... Det krypterte passordet ligger i shadow-filen. Den shadow-filen kan ikke leses av vanlige brukere, kun av Root. Root er administrator eller superuser på Linux. Når dere logger inn på StudySSO, så får man autentisert igjen via Oslo-medisin. Så det passordet er det samme som dere bruker i Kannas og andre steder. Så det passordet settes der, sånn som det gjør med det vanlige passordet. Eller det vil si, på Linux-servene vi bruker, Studies&Saw,", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0013", "start": 917.56, "end": 1019.76, "token_count": 299, "text": "Når dere logger inn på StudySSO, så får man autentisert igjen via Oslo-medisin. Så det passordet er det samme som dere bruker i Kannas og andre steder. Så det passordet settes der, sånn som det gjør med det vanlige passordet. Eller det vil si, på Linux-servene vi bruker, Studies&Saw, så er det samme autentisering. Men etter hvert når dere skal få egne VM-er, da vil dere se at dere kan sette passordet selv og styre det på. Som du ser befinner jeg meg nå på en virtualbox-maskin. Det er en virtualbox-vindows som jeg kjører. Det er den samme som ligger i oppgave 1, eller de første uka-oppgavene. Så blir de som har Mac bedt om å installere en virtualbox-vindows. Og der den kjører fra. Se på nå hvordan man logger seg inn fra Windows til StudySOS, som dere trenger å gjøre oppgaver i uke to. Så hvis jeg nå prøver å kjøre Putty, som er det programmet som jeg anbefaler at dere bruker for å logge dere inn med SO til en Linux-server fra Windows, så sier vi at den fins ikke her.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0014", "start": 996.52, "end": 1087.68, "token_count": 289, "text": "som dere trenger å gjøre oppgaver i uke to. Så hvis jeg nå prøver å kjøre Putty, som er det programmet som jeg anbefaler at dere bruker for å logge dere inn med SO til en Linux-server fra Windows, så sier vi at den fins ikke her. Så da... Hvis du ikke har Putty installert, så kan du installere den. Og da er det egentlig bare å søke på Putty. Den første linken så er det End of Solid Download, Putty here. Så kan du bruke en sånn installasjonsopplegg. Det enkleste er kanskje bare å ta den 64-bits-putty.xe her. Og så lagre den. Save Linkass. Da legger jeg den på desktopen, så har man den til senere. Og da har jeg putti her oppe. Så kjører jeg putti. Bare dobbeltklikker og rønner. Og det... Nå er alt klart til å logge inn på Studio SSO. Så det man trenger å gjøre da, er å skrive inn host name for Studio SSO. ... så må man faktisk bruke Hiwa. Jeg tror ikke DNS er oppdatert,", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0015", "start": 1064.68, "end": 1161.36, "token_count": 292, "text": "Bare dobbeltklikker og rønner. Og det... Nå er alt klart til å logge inn på Studio SSO. Så det man trenger å gjøre da, er å skrive inn host name for Studio SSO. ... så må man faktisk bruke Hiwa. Jeg tror ikke DNS er oppdatert, sånn at OsloMet virker, men denne funker iallfall. Og det er på port 22, som er default, når man bruker SSH. Så egentlig bare skriv inn den, og så return eller klikk open. Melding her dersom man gjerne får første gang man logger inn på en Linux-server, på en SSO-server... Som er en sånn sikkerhet, en sånn ekstra sikkerhet for at det ikke er en man-in-the-middle-attack. Men når det er første gang, så kan du svare yes på den. Hvis det samme skjer andre gang, så kan man kanskje være litt mer obs. Da får man login as, og det du gjør da, er å skrive inn studentnummeret ditt. Jeg har en testbruker. S318329. Så du skriver inn det studentnummeret. Og så må du ikke legge på at Oslomett osv.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0016", "start": 1135.3, "end": 1247.68, "token_count": 293, "text": "Hvis det samme skjer andre gang, så kan man kanskje være litt mer obs. Da får man login as, og det du gjør da, er å skrive inn studentnummeret ditt. Jeg har en testbruker. S318329. Så du skriver inn det studentnummeret. Og så må du ikke legge på at Oslomett osv. Hvis man gjør det, så kommer man inn, men da blir det noe trøbbel med innloggingen. Men hvis du bruker bare studentnummeret, og så det samme passordet som du har på Kalmas og overalt ellers... Skal vi se om jeg får til det her... Sånn, ja. Hvis du skriver riktig passord, så kommer du da inn på studentnummeret. Hvis det er behov for det, så kan man endre på fonter i Putty. Jeg kan vise deg denne første der inne. Her er det en... Det gjorde nå høyreklikket her oppe. Ja, jeg må opp på den baren der, og så høyreklikket. Her kan man endre fant. For eksempel jeg skrur 14, apply... Så får jeg litt større fanter. Så kan jeg utføre Windows... Nei, ikke Windows,", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0017", "start": 1215.2, "end": 1338.78, "token_count": 298, "text": "Her er det en... Det gjorde nå høyreklikket her oppe. Ja, jeg må opp på den baren der, og så høyreklikket. Her kan man endre fant. For eksempel jeg skrur 14, apply... Så får jeg litt større fanter. Så kan jeg utføre Windows... Nei, ikke Windows, men Linux-kommandor i skjellet, som Pwd, LS, LS-l osv. Jeg logger meg inn på min egen Linux-desktop. Det jeg tenkte å vise nå, er hvordan man logger seg inn på Studio CSO fra Linux, eller fra det som gjelder for mange flere, fra Mac. Hvis man har en Mac, så er det mulig å oppdatere en terminal. Programmet Terminal. Da får du opp et terminalvindu som ser litt sånn ut. Den viser hvor du er, eller hosename, som gir deg navnet på maskinen. Men det vi skal se på nå, er hvordan logge seg inn på Studio SSH fra en Mac-terminal. Og da bruker man programmet SSH. Og så må du skrive brukernavnet. Og Jens har jeg en testbruker. Så må jeg bruke ats. Og så return. Da blir man bedt om passord, og da må du bruke ditt studentnummer.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0018", "start": 1302.8, "end": 1409.88, "token_count": 288, "text": "fra en Mac-terminal. Og da bruker man programmet SSH. Og så må du skrive brukernavnet. Og Jens har jeg en testbruker. Så må jeg bruke ats. Og så return. Da blir man bedt om passord, og da må du bruke ditt studentnummer. Og ditt eget passord, det som du bruker på CANDAS. Hvis jeg klarer å skrive det passordet riktig, så kommer jeg inn. Ja. Jeg har opplevd tidligere, når jeg har logget inn med samme bruker, at det noen ganger tar veldig lang tid. Opptil et halvt minutt. Hvis det bare står sånn og henger, så kan det skyldes det. Så ha litt tålmodighet. Men når det første da har kommet inn, så kan du skrive Linux-kommandoer LS, LSminus L, Utføre de første ukeoppgavene i uke to. Filer er et sentralt Linux-begrep. Alt i Linux er filer. Og alle data som strømmes mellom kommandoer, de kan også legges inn i filer. Så det er veldig viktig i Linux å ha oversikt over Linux-filsystemet.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0019", "start": 1380.0, "end": 1494.48, "token_count": 298, "text": "Utføre de første ukeoppgavene i uke to. Filer er et sentralt Linux-begrep. Alt i Linux er filer. Og alle data som strømmes mellom kommandoer, de kan også legges inn i filer. Så det er veldig viktig i Linux å ha oversikt over Linux-filsystemet. Og her ser vi et bilde av et Linux-fillsystem. Øverst så har vi det som kalles ROT-katalogen. Og alle mapper, eller directories, de ligger da under denne ROT-katalogen. Og her ser vi en del sånne typiske mapper, som bind var user. Fire kjørbare programmer. Hva er det like blant analog-filer? USR... Det er sånn en del lokale filer og man-pages og... Jussi bind ligger nok de aller fleste bind-filene nære. Temp er for temperære filer. Boot er boot. Og så er det Sandra Home for hjemme. ETC - en spesiell katalog som inneholder resten. Der ligger det veldig ofte konfigurasjonsfiler. Det vi skal se på noen år fremover, er spesielt filene med passive shadow. De ligger her. Hvis vi går ned i filteret til dobbelte til dobbelte her,", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0020", "start": 1470.0, "end": 1574.04, "token_count": 291, "text": "ETC - en spesiell katalog som inneholder resten. Der ligger det veldig ofte konfigurasjonsfiler. Det vi skal se på noen år fremover, er spesielt filene med passive shadow. De ligger her. Hvis vi går ned i filteret til dobbelte til dobbelte her, så kan man referere til denne mapen her som slash... Så dette er et typisk Linux-filter. Det vi skal se på nå i starten, er hvordan manøvrerer man seg rundt i et slikt filter. Her ser vi en liste over noen av de viktigste kommandene man bruker. For å manøvrere seg rundt i filteret. Så det vi skal gjøre videre, er å bruke de kommandoene. Det er også oppgaver som går på det. Så den beste måten å lære seg etterpå er egentlig bare å prøve og feile. Og om og om igjen å bli vant til å orientere seg i det indiske filteret og bevege seg rødt. Så egentlig så var det Print Working Directory. Alle disse kommadene har sånne forkortelser, og det var faktisk opprinnelig fordi man hadde så ekstremt lite minner", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0021", "start": 1549.68, "end": 1628.16, "token_count": 288, "text": "Og om og om igjen å bli vant til å orientere seg i det indiske filteret og bevege seg rødt. Så egentlig så var det Print Working Directory. Alle disse kommadene har sånne forkortelser, og det var faktisk opprinnelig fordi man hadde så ekstremt lite minner i de opprinnelige maskinene. Så det gjaldt å ha korte kommander. Det gjør altså at det er kjappere å skrive, da. CD står for Change Directory. Så for eksempel CDHome. Det betyr flytt meg til... Men her ser vi at vi ikke har noen slash først. Og det betyr at da beveger jeg meg i forhold til der jeg står. Så hvis det ikke er noen mappe som heter Home i den mappen jeg står i, så vil jeg ikke komme dit. Så alltid når man går inn der selv, så er man i en eller annen mappe. Det vanlige når du logger deg inn, er at du kommer til din hjemmemappe, Men det kan være annerledes, og så er det litt annerledes. Men når det lugger deg inn, hvis du da gjør en pen jobb til det,", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0022", "start": 1610.52, "end": 1688.32, "token_count": 291, "text": "Så alltid når man går inn der selv, så er man i en eller annen mappe. Det vanlige når du logger deg inn, er at du kommer til din hjemmemappe, Men det kan være annerledes, og så er det litt annerledes. Men når det lugger deg inn, hvis du da gjør en pen jobb til det, så vil du se hva hjemmevåpenet ditt heter. Så kan man alltid bruke absolutt path når man flytter seg. Så jeg kan alltid skrive cd slash etc. Da vil jeg alltid komme dit, uansett hvor jeg står på forhånd. Hvis jeg ikke har en slash foran, da beveger jeg meg relativt til der jeg står. Det betyr flytt en katalog opp, nærmere roten av fjellsystemet. Så kan man sette sammen CD. Da flytter man seg to kataloger opp. Så bare skriv CD, så kommer du faktisk bare hjem til hjemmekatalogen. LS viser filer i den mappen du ligger i. LSMSL legger på ekstra info om disse filene. Så har man en masse små Linux-kommandoer som dette. Og så kan man legge på opsjoner som gjør", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0023", "start": 1663.4, "end": 1764.2, "token_count": 281, "text": "Så bare skriv CD, så kommer du faktisk bare hjem til hjemmekatalogen. LS viser filer i den mappen du ligger i. LSMSL legger på ekstra info om disse filene. Så har man en masse små Linux-kommandoer som dette. Og så kan man legge på opsjoner som gjør at kommandoene virker på andre måter enn defolt uten opsjoner. Jeg har nå logget inn i et terminalvindu, et såkalt Linux-skjell. Vi skal nå se litt på hvordan man beveger seg rundt i filsystemet. Ved hjelp av kommandoer. En første kommando er pwd, Print Working Directory, som viser meg hvor jeg står i filsystemet. Og her er logget inn som en student, en testbruker på Studiesesong. Og da ser vi at i dette tilfellet så er ikke home... Dette er fordi disse filene ligger ikke på denne serveren, men de ligger på en annen server. Før man beveger seg rundt i filsystemet, kan det være greit å kunne liste hvilke filer man har. Da er det en kommando som heter LS, som lister filer og mapper.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0024", "start": 1740.0, "end": 1827.56, "token_count": 300, "text": "Dette er fordi disse filene ligger ikke på denne serveren, men de ligger på en annen server. Før man beveger seg rundt i filsystemet, kan det være greit å kunne liste hvilke filer man har. Da er det en kommando som heter LS, som lister filer og mapper. Her ser vi at det som kommer ut i blått, er mapper. Og det andre er filer. Hvis man lister med LS minus L, legger til opsjon L, så får man en lang listing. Vi skal senere se i detalj på hva alt dette her betyr. Men her kan man se at der det står en D først... Det er for directory. Da er det en mappe. Og mapper kan man bevege seg ned i. Og hvis jeg f.eks. ønsker å gå til mappen undervisning, Så bruker jeg CD, \"-change directory\", og så skriver jeg undervisning. Hvis det er litt lange ord, så er det et fint tips å trykke på \"-tab\", for da fylles resten ut hvis det er entydig. Så en kjapp måte å gå ned til undervisning på, det er å bare skrive CDU, og så -tab, og så utføre kommandoen ved å trykke -return.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0025", "start": 1807.64, "end": 1889.96, "token_count": 283, "text": "Hvis det er litt lange ord, så er det et fint tips å trykke på \"-tab\", for da fylles resten ut hvis det er entydig. Så en kjapp måte å gå ned til undervisning på, det er å bare skrive CDU, og så -tab, og så utføre kommandoen ved å trykke -return. Så kommer jeg ned i undervisning. Det vises hele tiden hvor jeg er. Så når man kommer et nytt sted, så er det ofte lurt å finne ut hva det er som finnes her. Jo, her er det en mappe under her igjen. Så da kan jeg gå ned i den mappen med CD-mappe. Jeg kan skrive det helt ut sånn CD-mappe. Og så er jeg kommet hit. Hvis mappen er tom, så viser jeg sånn at den er tom. Da kommer det bare 12-0. LS viser ingenting. Men så må jeg også kunne gå oppover igjen i filsystemet. Så da kan jeg ta CD... Den går ett hakk opp. Så er det kommet opp til undervisning. Hvis jeg nå går ned igjen, så kan jeg gå to steg opp på denne måten.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0026", "start": 1871.24, "end": 1958.84, "token_count": 286, "text": "Men så må jeg også kunne gå oppover igjen i filsystemet. Så da kan jeg ta CD... Den går ett hakk opp. Så er det kommet opp til undervisning. Hvis jeg nå går ned igjen, så kan jeg gå to steg opp på denne måten. Prikk, prikk, slash, prikk, prikk. Da kommer jeg helt øverst igjen. Så da kan jeg gå ned i undervisningen. Hvis jeg bare taster CD, så kommer jeg til hjemmemappen. Hvis man ønsker å få en blank skjerm, så kan man taste Kontroll L. Så blanke skjermen. Det kan også være praktisk. En del sånne tips som dette her står under hjelp - Linux-hjelp på kursiden. Vi kommer også til å gå gjennom i litt mer detalj. Sånne små triks som gjør det raskere å bruke kommandolinjen. Nå er jeg et stykke ned i filteret, men det kan gå sakte bakover, sånn som dette her. Og så gå helt opp i toppen av filteret. Og da ser vi. Her nå er jeg på roten av filsystemet. I slash. Og så kan jeg gå tilbake igjen.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0027", "start": 1932.36, "end": 2030.08, "token_count": 294, "text": "Sånne små triks som gjør det raskere å bruke kommandolinjen. Nå er jeg et stykke ned i filteret, men det kan gå sakte bakover, sånn som dette her. Og så gå helt opp i toppen av filteret. Og da ser vi. Her nå er jeg på roten av filsystemet. I slash. Og så kan jeg gå tilbake igjen. Ned til Cube. Ned til U0. Og ned til min bruker. S318.320. Jeg kunne gjort alt dette her også. Til roten. Da er jeg helt ørst i filteret. Og så kan jeg gå hjem igjen med bare CD-en. Pledd over til det, så vil jeg nå se at nå er jeg hjemme igjen. Nå skal vi se på hvordan vi lager skjellskript. Å lage skjellskript er veldig enkelt. Det er bare å åpne ned. Og skrive inn tekst linje for linje med kommandoer, og så save den, og kjøre den. Så vi skal se helt konkret på hvordan vi gjør det. For det første så trenger vi en editor. Eller jeg kan først si jeg er nå i en mappe, mappe, og den mappen er tom.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0028", "start": 2010.0, "end": 2091.44, "token_count": 289, "text": "Og skrive inn tekst linje for linje med kommandoer, og så save den, og kjøre den. Så vi skal se helt konkret på hvordan vi gjør det. For det første så trenger vi en editor. Eller jeg kan først si jeg er nå i en mappe, mappe, og den mappen er tom. Så lister jeg den, så ser vi at det ikke ligger noen ting der. Så dermed må jeg lage et skript fra scratch. Jeg skal bruke en enkel editor som heter Nano. Som kanskje er den enkleste å starte med. I mange av eksemplene bruker jeg Jed. Vi kan se på det etter hva. Men jeg starter med Nano. Og så kaller jeg scriptet mitt... Det kan hete hva som helst. Og så tar jeg på en extension.sh, som er vanlig å bruke for Shell-script. Så åpner jeg editoren, og da er det bare å starte å skrive her. Det er standard å bruke noen besvergelser i starten av et bæsjskript. Og det dette her betyr, det er herstein, utropstegn. Det betyr at dette skriptet skal tolkes av programmet som kommer etterpå.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0029", "start": 2064.56, "end": 2143.2, "token_count": 281, "text": "Så åpner jeg editoren, og da er det bare å starte å skrive her. Det er standard å bruke noen besvergelser i starten av et bæsjskript. Og det dette her betyr, det er herstein, utropstegn. Det betyr at dette skriptet skal tolkes av programmet som kommer etterpå. I dette tilfellet er det bindbæsj. Dette er da selve skjellet. Det er et binært program som ligger i mappen Bind. Og dette programmet heter Bæsj. Og det er da det programmet som tolker alle kommandoene som kommer nedover her. Så her kan jeg begynne å skrive Shell-kommandoer som p2d, ls kanskje... ls-l osv. Og dermed så har jeg allerede et skript. Så det jeg trenger å gjøre nå, er å save det og gå ut. Så det kan jeg gjøre ved å bruke noen av de kommandoene som er her. Her nede ser du Control O. Den hakken der betyr kontroll. Hvis jeg taster nå Kontroll O, så skriver jeg... lagrer... dette skriptet.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0030", "start": 2120.92, "end": 2192.84, "token_count": 300, "text": "Så det jeg trenger å gjøre nå, er å save det og gå ut. Så det kan jeg gjøre ved å bruke noen av de kommandoene som er her. Her nede ser du Control O. Den hakken der betyr kontroll. Hvis jeg taster nå Kontroll O, så skriver jeg... lagrer... dette skriptet. Fineline to write, script and chell. Det er greit. Nå har jeg savet skriptet. Hvis jeg er ferdig og har lyst til å gå ut og kjøre det, så taster jeg Kontroll X, som er exit. Og dermed er jeg ute. Da kan jeg aller først liste opp. Og så ser jeg at nå har jeg lagd dette skriptet. Jeg kan se på innholdet i skriptet med CAT. Det ser sånn ut. Det ser bra ut. Og så kan jeg prøve å kjøre det. Det jeg typisk prøver på da, det er å bare skrive navnet. Men da ser vi... Nei. Da får jeg en command not found. Og det er av sikkerhetshensyn. Man må spesifisere hvor skriptet som jeg skal kjøre, ligger. Det går an å sette opp systemet. Da ville det bare ha startet.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0031", "start": 2175.72, "end": 2261.52, "token_count": 290, "text": "Men da ser vi... Nei. Da får jeg en command not found. Og det er av sikkerhetshensyn. Man må spesifisere hvor skriptet som jeg skal kjøre, ligger. Det går an å sette opp systemet. Da ville det bare ha startet. Men her må jeg eksplisitt si hvor dette scriptet ligger. Og da kan jeg skrive full path til mappen det ligger i. Så jeg kunne kjørt det ved å skrive hele denne strengen her. Og så script it out selv. Da sier man hvor det ligger. Men noe som er enklere, er å si prikk. Det er den mappen jeg ligger i. Så jeg kan si at det skriptet jeg skal kjøre, det ligger i prikk-slæsj. Her ligger dette skriftet. Og så kan jeg kjøre det. Men da ser vi. Jeg får permission in light, og det er fordi dette skriptet har ennå ikke rettigheter til å kjøre det. Vi skal se på dette i detalj senere, men rettighetene er de som står... For her... rw dash... eller rw-strek. Dette er rettighetene for programmet. Og det betyr read and write.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0032", "start": 2235.54, "end": 2322.28, "token_count": 299, "text": "dette skriptet har ennå ikke rettigheter til å kjøre det. Vi skal se på dette i detalj senere, men rettighetene er de som står... For her... rw dash... eller rw-strek. Dette er rettighetene for programmet. Og det betyr read and write. Men så burde det stått en x der. For den x-en må man ha for å kunne kjøre. Og det kan vi få til ved å bruke en annen kommando. Vi skal se mer på dette seinere. Men den kommandoen heter chmode. Change modus. Og så bruker jeg en kode for å endre den. Vi skal se hva det betyr også. Og så navnet på skriptet. Jeg skriver CMOD 700 skriftdatskjell. Hvis jeg nå lister, så vil jeg se at nå står det RWX. Og det betyr at jeg som bruker har rettighet til å lese, skrive og kjøre dette skriptet. Så nå kan jeg på nytt prøve å kjøre det. Nå kan jeg altså taste tab. Det jeg gjorde nå, var at jeg skrev.slash sc, og så tastet jeg tab. Og da ser du at skjellet fullfører den kommandoen", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0033", "start": 2296.48, "end": 2369.92, "token_count": 286, "text": "Og det betyr at jeg som bruker har rettighet til å lese, skrive og kjøre dette skriptet. Så nå kan jeg på nytt prøve å kjøre det. Nå kan jeg altså taste tab. Det jeg gjorde nå, var at jeg skrev.slash sc, og så tastet jeg tab. Og da ser du at skjellet fullfører den kommandoen så lenge den er entydig. Og dermed kan jeg taste return og kjøre skriptet. Og nå ser vi... Det som skjedde nå, var at skriptet kjørte, og dere utførte kommandoene én for én. Først pwd, som ga denne linjen her. Så LS, som ga linjen med script og shell, og så LS minus L, som ga hele denne utskriften. Og dermed har vi laget og kjørt et skript. Og det er egentlig så enkelt, den prosessen her. Det eneste man må passe på, er at skriptet må ha rettigheter til å kjøre for at man skal få kjørt det. Jeg nevnte at i Afterbruk gjedd, og det er en...", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0034", "start": 2353.72, "end": 2435.84, "token_count": 290, "text": "Og det er egentlig så enkelt, den prosessen her. Det eneste man må passe på, er at skriptet må ha rettigheter til å kjøre for at man skal få kjørt det. Jeg nevnte at i Afterbruk gjedd, og det er en... Også en veldig enkel editor. Men den er litt mer kryptisk. Kommandoene står ikke som om man lærer seg noen få kommandoer for å lagre bl.a. Så jeg kan vise kjapt hvordan den virker også. Jed, jdd, script og chill. Da ser det ganske likt ut som ellers. Kan skrive inn nye kommandoer her. Det jeg sier jeg trenger å vite da, er hvordan saver jeg, og hvordan går jeg ut? Save er en tastekombinasjon kontroll-x-s. Da så vi nå taste kontroll-x, og så s, og da savet den. Kontroll-x og C. Da går man ut. Så stort sett er det de to man trenger. Så er jeg ute, og så kan jeg kjøre på nytt. Og da ser vi scriptet kjørte som før. Det eneste tillegget var at jeg fikk Som viser output fra Uname minus A.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0035", "start": 2418.62, "end": 2515.36, "token_count": 289, "text": "Så stort sett er det de to man trenger. Så er jeg ute, og så kan jeg kjøre på nytt. Og da ser vi scriptet kjørte som før. Det eneste tillegget var at jeg fikk Som viser output fra Uname minus A. Uname ber meg si hva slags OS jeg kjører. Filbehandling er spesielt viktig i Linux fordi så å si alt i Linux av konfigurasjon og andre data er lagret som filer. Det å kunne manipulere på tekstfiler, det er veldig viktig i Linus. Vi har allerede sett på noen kommaler, sånn som ls, som listede filer. ls minus l, se, den lager en lang listing. Her har jeg fått en fil som heter script shell, med en liten trille til slutt. Det er en liten forskjell på de to fillene. Og Jed sparer alltid en sikkerhetskopi med navn tidligere når man gjør endringer. Så dette er i fall man gjør noen endringer man skulle ønske man ikke hadde gjort, så har man en sikkerhetskopi når man bruker Jed. Hvis man bruker Nano, så lages det ikke en sånn sikkerhetskopi", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0036", "start": 2494.36, "end": 2588.84, "token_count": 291, "text": "Og Jed sparer alltid en sikkerhetskopi med navn tidligere når man gjør endringer. Så dette er i fall man gjør noen endringer man skulle ønske man ikke hadde gjort, så har man en sikkerhetskopi når man bruker Jed. Hvis man bruker Nano, så lages det ikke en sånn sikkerhetskopi hvis man blir irritert over alle de tidligere filmene. Man kan også legge på andre opsjoner på LS. F.eks. kan man legge på LS minus A. Og da er det to mapper til som vises. Det er prikk, og så er det prikk, prikk. Og de mappene er mappene man står i, og i tillegg er det mappen et hakk opp. Og da ser vi tydeligere hva prikk og prikk er, eller at de er mapper. Prikk er en mappe. Den starter med det her. Og det er altså den mappen man står i. Så rettighetene for denne mappen, det er rettighetene for mappen jeg står i nå. Den mappen som listes under, det er mappen ett hakk opp, som i dette tilfellet har de samme rettighetene.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0037", "start": 2562.5, "end": 2662.44, "token_count": 286, "text": "Og det er altså den mappen man står i. Så rettighetene for denne mappen, det er rettighetene for mappen jeg står i nå. Den mappen som listes under, det er mappen ett hakk opp, som i dette tilfellet har de samme rettighetene. Og i tillegg har vi de to versjonene av Script of Shell som er listet. Man kan også liste hvilken som helst mappe, f.eks. en rød liste slash etc., som var en rekke mapper. Da har disse alle mappene i slash etc.. Ved å tasse kontrollet L, så får jeg clear screen. Da får jeg bort alle kommandoer og opphav fra terminalen. Det kan være praktisk mange ganger. Så man kan også kunne lage mapper og filer. Og da kan jeg f.eks. lage en mappe som heter Dir. Og da bruker jeg MKDir. Eller jeg kan gjøre det eksplisitt. Da får jeg en ny mappe som heter 'Ny mappe'. Så er det altså en kommando som heter 'Touch', som jeg kan bruke for å lage tomme filer. Så får jeg nå en tom fil som heter 'Tom fil'.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0038", "start": 2632.76, "end": 2734.12, "token_count": 278, "text": "Og da bruker jeg MKDir. Eller jeg kan gjøre det eksplisitt. Da får jeg en ny mappe som heter 'Ny mappe'. Så er det altså en kommando som heter 'Touch', som jeg kan bruke for å lage tomme filer. Så får jeg nå en tom fil som heter 'Tom fil'. Det ligger ingenting i den. Og så har jeg en mappe som heter 'Ny mappe'. Da får jeg ut innholdet av den filen. Så må jeg kunne endre på filer. Vi har sett tidligere at vi har brukt Nano. Jed kan jeg også bruke. Endre her. Lagre med ctrl-s. Gå ut med ctrl-c eller ctrl-x. Det fins også andre... mange editorier. Amax er en stor og omfattende editori hvor du kan gjøre veldig mye. Jed er på en måte en billigutgave eller en lightwhite-utgave av Amax. Så kommandoen som gjelder i Jed, gjelder også Amax. Så hvis du skal gå ut av Amax, bruker jeg Kontroll X, Kontroll C. Starten kan kanskje være å bruke Nano, som vi så på tidligere.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0039", "start": 2710.64, "end": 2789.46, "token_count": 299, "text": "Jed er på en måte en billigutgave eller en lightwhite-utgave av Amax. Så kommandoen som gjelder i Jed, gjelder også Amax. Så hvis du skal gå ut av Amax, bruker jeg Kontroll X, Kontroll C. Starten kan kanskje være å bruke Nano, som vi så på tidligere. Fordi her kan man se nederst hvilke shortcut man kan bruke for å komme ut. Man har ikke pek og klikk her. I utgangspunktet så skal man kunne gå inn på en server og invitere filer. Og dermed skal man jo ikke klikke for å save. Så på en eller annen måte må man da vite hvilke kommandoer man kan bruke for å gå ut. Det er spesielt tenkt på Nano, for de står nederst. Kontroll-X, det er da exit. Så kan det være nyttig å kopiere. Og da er kommandoen for å kopiere CP... Hvis jeg nå ønsker f.eks. å kopiere det scriptet, script.shell... Det jeg gjorde nå som gjorde at jeg raskt fikk ut script, det var å trykke på tab. Så jeg skrev cpec, og så trykker jeg tab. Så blir det script og shell.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0040", "start": 2766.94, "end": 2847.94, "token_count": 290, "text": "Så kan det være nyttig å kopiere. Og da er kommandoen for å kopiere CP... Hvis jeg nå ønsker f.eks. å kopiere det scriptet, script.shell... Det jeg gjorde nå som gjorde at jeg raskt fikk ut script, det var å trykke på tab. Så jeg skrev cpec, og så trykker jeg tab. Så blir det script og shell. Kanskje la det bli starten på et nytt script. Sånn. Da kopierer jeg filen script og shell til nytt script og shell. Hvis jeg nå taster LS-minus L, så ser vi... Da har jeg her oppe fått en ny fil som heter nyttscript.shell. Som med alle kommandoer så kan man legge på... Jeg bladde meg tilbake. Det kan man gjøre med pil opp. Nå tastet jeg pil opp, så bladde jeg meg tilbake i tidligere kommandoer. Hvis jeg tastet pil ned, så kom jeg frem igjen. Så la oss si jeg ønsker å gjøre denne kommandoen her om igjen, men med minus... Da vil jeg bruke opsjonen minus i. Minus i er så fint og aktiv, og hvis jeg prøver å skrive over en fil som fins...", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0041", "start": 2830.5, "end": 2923.12, "token_count": 293, "text": "Hvis jeg tastet pil ned, så kom jeg frem igjen. Så la oss si jeg ønsker å gjøre denne kommandoen her om igjen, men med minus... Da vil jeg bruke opsjonen minus i. Minus i er så fint og aktiv, og hvis jeg prøver å skrive over en fil som fins... Så da kan jeg få sjansen til å svare nei her. Det ønsker jeg ikke. Da blir den ikke kopiert. En annen veldig nyttig kommando er å flytte. Så la oss si jeg ønsker å få et nytt navn på nytt script.shell. Jeg liker ikke det navnet, så da kan jeg bruke kommandoen mv for move. Nytt skript, det kan kanskje hete... Moved Totshell. Så det denne kommandoen gjør, er at den tar nytt skript, Totshell, og flytter til Moved Totshell. Og det vil i praksis si her at man renamer. Altså at man får et nytt navn på nytt skript. Hvis jeg nå gjør LSMD selv, så ser vi at jeg har moved.shell. Jeg har fått nytt navn på dette nyhetsskriftet. Men jeg kan også flytte fra en mappe til en annen.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0042", "start": 2906.88, "end": 2991.08, "token_count": 281, "text": "Altså at man får et nytt navn på nytt skript. Hvis jeg nå gjør LSMD selv, så ser vi at jeg har moved.shell. Jeg har fått nytt navn på dette nyhetsskriftet. Men jeg kan også flytte fra en mappe til en annen. Så er det en annen måte å bruke MV på, er hvis jeg tar moved, og så ønsker jeg å flytte den ned til ny mappe. Da tar jeg MV moved til ny mappe. Return. Og hvis jeg rister filen nå, så ser vi at... Move... Den er borte. Hvis jeg går ned i ny mappe, så ser vi... Der ligger denne filen. Så på den måten vil det være sånn at hvis jeg bruker Move inne i samme mappe, så vil den endre navn. Men hvis jeg flytter Mo til en annen mappe, så flyttes filen fra mappen jeg er i, til mappene skal til. På denne måten kan jeg også flytte hele mapper. La oss si jeg lager en mappe som heter Dirr. Så har jeg denne... dette filteret. Nå har jeg en mappe som heter Dirr som er tom.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0043", "start": 2961.92, "end": 3063.84, "token_count": 289, "text": "så flyttes filen fra mappen jeg er i, til mappene skal til. På denne måten kan jeg også flytte hele mapper. La oss si jeg lager en mappe som heter Dirr. Så har jeg denne... dette filteret. Nå har jeg en mappe som heter Dirr som er tom. Og så har jeg en ny mappe her, og da kan jeg flytte hele ny mappe til Dirr. Hvis jeg lisser nå, så ser vi nymapperen er borte. Og den har blitt lagt ned i... Ja, her ligger det. Og det er noen mapper som er spesielle. Vi har vel kanskje sett på de fleste. Hvis man lisser med LA, så ser man for det første at det er mappen du står i. Jeg ønsker å kopiere noe til mappen jeg står i. Hvis jeg lister nå det som er i mappen over, så ser jeg at der ligger script.shell. Mens her ligger ingen til. OK, nå skal jeg kopiere script.shell som ligger i mappen over. Da gjør jeg det sånn. CP... Script.shell, og så hit. Prikk betyr da denne mappen. Og dermed, hvis vi utfører den kommandoen,", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0044", "start": 3045.0, "end": 3136.36, "token_count": 287, "text": "Mens her ligger ingen til. OK, nå skal jeg kopiere script.shell som ligger i mappen over. Da gjør jeg det sånn. CP... Script.shell, og så hit. Prikk betyr da denne mappen. Og dermed, hvis vi utfører den kommandoen, så vil du se at da har jeg fått en kopi av ScriptOutShell i mappen jeg står i. Mens i mappen over, så ligger fortsatt originalen. Så kopien har da blitt flyttet hit. Og det er eksempler på bruk av mappen. Vi ser vi har brukt. tidligere. Hvis jeg sier change directory til., så går jeg ett hakk opp. Et annet tegn på en mappe er Tilde. Hvis jeg skriver 'Ekko Tilde', så vil du se at Tilde det er faktisk hjemmemappen. Så det kan man bruke til å flytte seg til hjemmemappen. CD Tilde. Da kommer jeg øverst i hjemmemappen. Så kan jeg også... La oss si... Ja, jeg kan gå ned mappen igjen. Så kan jeg også bruke det, f.eks. ved å si at jeg ønsker å kopiere det som ligger øverst i hjemmemappen.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0045", "start": 3115.4, "end": 3214.28, "token_count": 299, "text": "Da kommer jeg øverst i hjemmemappen. Så kan jeg også... La oss si... Ja, jeg kan gå ned mappen igjen. Så kan jeg også bruke det, f.eks. ved å si at jeg ønsker å kopiere det som ligger øverst i hjemmemappen. Der er det en fil... hei.tk. Den ønsker jeg å kopiere hit. Tilde betyr da hjemmemappen, og der ligger hei.tk, så jeg kan se her oppe. Det er mappen jeg står i. Og dermed gjør den kommandoen at jeg kopierer hei.tks til øverste hjemmemappe ned hit jeg står. Så nå har jeg fått en kopi av hei.tks-t her. Litt om oppgaver. Generelt når det gjelder oppgaver, så... Når man skal dokumentere at man har gjort en oppgave, så kan... Så holder det lenge å bare copy og paste tekst fra de kommandoene du har gjort. Hvis du f.eks. har gjort... Ja, la oss si uname minus a. Så skal jeg vise at du har gjort det. Så kan du ta den teksten som står her, og så bare copy og så paste ned et dokument. Og så levere det. Så det holder lenge som dokumentasjon.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0046", "start": 3187.44, "end": 3269.96, "token_count": 286, "text": "Hvis du f.eks. har gjort... Ja, la oss si uname minus a. Så skal jeg vise at du har gjort det. Så kan du ta den teksten som står her, og så bare copy og så paste ned et dokument. Og så levere det. Så det holder lenge som dokumentasjon. Litt generelt om oppgavene denne uken. Det er bl.a. en oppgave hvor du skal bruke topp. Og topp er den kommandoen jeg skrev nå. Det er en kommando som viser fortløpende prosesser som står og kjører. Den stopper man ved å tasse Q. Q, så kommer jeg ut igjen. Kontroll L, så får jeg en clear screen. Men så skal man ned i den oppgaven, så skal man også gjøre en kommando som heter PSAUX. Hvis du gjør den, så kommer det en masse linjer. Det er alle prosessene som står og kjører. Og da skal man i oppgaven, så skal man også bruke grep. Og da setter man først en pipe. Dette er en pipe som sender nå alle dataene som kommer ut, alle linjene fra PSAUX. Det sendes nå videre til et annet program.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0047", "start": 3250.56, "end": 3336.84, "token_count": 289, "text": "Det er alle prosessene som står og kjører. Og da skal man i oppgaven, så skal man også bruke grep. Og da setter man først en pipe. Dette er en pipe som sender nå alle dataene som kommer ut, alle linjene fra PSAUX. Det sendes nå videre til et annet program. Som heter Grep. Og i det Grep-programmet så kan jeg f.eks. Der kan jeg grepe på tekst. Og f.eks. så kan jeg grepe på linjen... Eller på teksten 318329. Da får jeg alle linjer i PSA og X hvor dette brukernavnet står. På den måten. Og så går videre av oppgaven ut på at du skal... Lag et skript som gjør dette. Og til slutt så skal skriptet virke på en sånn måte. Skripte PS-user. Det skal virke på en sånn måte at hvis du skriver f.eks..ps-user og så S318 som et argument... Det som kommer da etter skriptet, S318... Jeg kan legge på S318329. Det som kommer etter skriptet, det er argumentet. Så skal det i praksis gjøre det som står her oppe.", "source": "lecture"}
{"lecture_id": "linux1a", "chunk_id": "linux1a_0048", "start": 3311.6, "end": 3393.22, "token_count": 260, "text": "at hvis du skriver f.eks..ps-user og så S318 som et argument... Det som kommer da etter skriptet, S318... Jeg kan legge på S318329. Det som kommer etter skriptet, det er argumentet. Så skal det i praksis gjøre det som står her oppe. Det som må skje inni skriptet da, er at S18329 må legges bakerst i den kommandolinjen der. Det kan man gjøre ved å bruke en spesiell variabel som heter dollar1. Det første argumentet til skript vil legges internt i skriptet. Dermed kan man inni skriptet bruke den verdien. Det skal vi snakke om senere, men prøv å få det til nå, sånn at du kan kjøre det skriptet her med vilkårlige kommandoer. Nei, med vilkårlige argumenter. F.eks. kan jeg i stedet si:\" Kjør med Ruth.\" Og da skrives ut alle linjer som inneholder 'Ruth' ut. 3.18,329.", "source": "lecture"}
{"lecture_id": "os3del7", "chunk_id": "os3del7_0000", "start": 0.0, "end": 74.4, "token_count": 293, "text": "Her har vi en litt mer komplisert krets, hvor vi da kan endre en bitverdi. Etter pause tenkte jeg å ta en liten poll, hvor vi får noen spørsmål fra dette. Så her gjelder det å følge med. Det ser jo litt komplisert ut, men det er egentlig ikke så komplisert. Her fremme så har vi den samme konstitusjonen med not-porter. Men i tillegg, for å kunne legge inn en... Verdien D er den som vi ønsker å lagre. For å legge inn den, har vi satt opp et system med to overporter, altså en not-port foran der. Da kan man overbevise om at hvis man setter inn en null her, så lagres en null. Hvis man setter inn en ener, så lagres en ener. Vi kan jo se på hva som skjer hvis man setter inn en null. Jo, da kommer det en null inn her. Går inn i not-porten. Da må det bli en ener her. Og så vet vi det at når det kommer en ener inn i en orport, så vil det alltid komme en ener ut. For den or-porten gir bare null hvis det kommer to nuller inn. Så kommer det en ener inn her,", "source": "lecture"}
{"lecture_id": "os3del7", "chunk_id": "os3del7_0001", "start": 54.08, "end": 119.92, "token_count": 296, "text": "Jo, da kommer det en null inn her. Går inn i not-porten. Da må det bli en ener her. Og så vet vi det at når det kommer en ener inn i en orport, så vil det alltid komme en ener ut. For den or-porten gir bare null hvis det kommer to nuller inn. Så kommer det en ener inn her, så uansett hva som er der, så kommer det da faktisk en ener ut. Og dermed får vi lagt inn denne verdien null i denne kretsen. For det kommer en ener inn her, og da blir det en null der. Og så får vi på samme måte som tidligere. At det er en lukket krets. Det går null inn i denne orporten. Og så kommer det en null herfra. Da er det null som går videre. Og så blir det en ener der. Og så kommer den eneren inn her igjen. Og én og én gir én og null, og så videre. Og hvis man da ønsker å switche og legger inn en ener her, så får vi akkurat det motsatte. Og da vil det til slutt bli en ener her. Det som skjer da, er at da kommer det en ener inn her. Og en ener inn i en orport.", "source": "lecture"}
{"lecture_id": "os3del7", "chunk_id": "os3del7_0002", "start": 100.32, "end": 187.44, "token_count": 287, "text": "Og én og én gir én og null, og så videre. Og hvis man da ønsker å switche og legger inn en ener her, så får vi akkurat det motsatte. Og da vil det til slutt bli en ener her. Det som skjer da, er at da kommer det en ener inn her. Og en ener inn i en orport. Så kommer det null her. Og da kommer det null inn der. Da kommer det to nuller inn der, og så blir det en ener her. Så på samme måte så funker den også. Men hva er problemet nå? Problemet nå er ikke like lett å se. Men det vi skulle ønske, er at man på en måte kan skape... Man ønsker å ha en vippe, eller en lagerenhet, som er sånn at hvis du setter på null her, så lagres nullen, men så skulle man ønske å skru av kretsen, sånn at den nullen blir bevart. Uansett om D-en her endres. Jeg ønsker å ha et system som er sånn at om jeg endrer D-en til 1 her nå, så kan jeg velge. Velge at VIP-en, eller et register som holder denne verdien, det skal være uendret.", "source": "lecture"}
{"lecture_id": "os3del7", "chunk_id": "os3del7_0003", "start": 160.82, "end": 198.72, "token_count": 140, "text": "så lagres nullen, men så skulle man ønske å skru av kretsen, sånn at den nullen blir bevart. Uansett om D-en her endres. Jeg ønsker å ha et system som er sånn at om jeg endrer D-en til 1 her nå, så kan jeg velge. Velge at VIP-en, eller et register som holder denne verdien, det skal være uendret. Og det kan du ikke få til med denne kretsen her. Med en gang du gjør en endring her, så forplanter den endringen seg, og så lager vi en annen bit.", "source": "lecture"}
{"lecture_id": "os5del10", "chunk_id": "os5del10_0000", "start": 0.0, "end": 115.3, "token_count": 291, "text": "Jo... Hvis vi tenker oss... At denne boksen er CPU-en. Håper det ser OK ut nå. Så inni CPU-en, så ligger da de registrene. AXBXCX osv. Og de er registre sånn som vi hadde i simuleringen. I simuleringen så var registerstørrelsen 4-bit. Her. Ax er egentlig enda lengre. Den er på 32-bit. Nei, forresten. Den er 16-bit. Eax er på 32-bit, og rax er på 64-bit. Så da er det bare lengre ri. Og... med nuller og enere. Og så inni CPU-en så har vi da en alu. Og da har vi sett tidligere at det som skjer inni CPU-en, er at du har en kanal fra registrene av XBX som går inn i aluen. Etter at Alun har gjort beregninger, den kommer tilbake til registrene. Så her kan vi sitte og regne og holde på. F.eks. de Fibonacci-tallene. De regnes ut lokalt inne i CPU. Men så begynner vi å gjøre institusjoner sånn som Move. Da vi f.eks. hadde en institusjon sånn som...", "source": "lecture"}
{"lecture_id": "os5del10", "chunk_id": "os5del10_0001", "start": 91.0, "end": 221.22, "token_count": 300, "text": "Så her kan vi sitte og regne og holde på. F.eks. de Fibonacci-tallene. De regnes ut lokalt inne i CPU. Men så begynner vi å gjøre institusjoner sånn som Move. Da vi f.eks. hadde en institusjon sånn som... Sendt eax til svar i den koden som vi kjørte nå nettopp. Så betyr det flytt resultatet av det vi hadde, til ram. Så dette er ram. Og ram skal vi studere senere i detalj. Det er egentlig bare et svært reim med bites. Her er det, skal vi se... Åtte bit. Så dette er da adresse null i ramm. Så dette er adressen i ramm. Så... Det vi holder på med når vi sier move prosent EAX til svar, det er at vi ønsker å legge verdien av EAX fra CPU-en og så ut i ramm. Og så kan det godt være at... Hvis så... La oss si den svaret er long, da. Hvis jeg har definert en variabel som long, så er den på fire bytes. Da betyr det at det settes av fire biter i ram. Og dette her er da de fire bitene til svar. Det vi så i koden, det var noe sånt som", "source": "lecture"}
{"lecture_id": "os5del10", "chunk_id": "os5del10_0002", "start": 192.26, "end": 310.48, "token_count": 292, "text": "Hvis så... La oss si den svaret er long, da. Hvis jeg har definert en variabel som long, så er den på fire bytes. Da betyr det at det settes av fire biter i ram. Og dette her er da de fire bitene til svar. Det vi så i koden, det var noe sånt som minus fire prosents RDB eller noe i den stillingen her. Hvor dette er da... Det er et register. Men det inneholder et tall. Så dette er en adresse. Og den adressen kan f.eks. være til rammelinje nummer 357. Og det er minus 4. Det betyr at det er den adressen minus 4. Så dette her, når du ser det i et asemblerprogram, så peker det til et eller annet sted i ramm. Og den inneholder da en adresse, som er den adressen her. Hvilket nummer... Hvilket bite i ram som skal legges der. Så det som skjer med den institusjonen her, det er at man tar de verdiene som lå i Ax, og så legger man ut her. De 32 bitene får da plass i det som er satt av i ramm til de 32 bitene. Og når man skriver kode...", "source": "lecture"}
{"lecture_id": "os5del10", "chunk_id": "os5del10_0003", "start": 276.14, "end": 391.26, "token_count": 287, "text": "Så det som skjer med den institusjonen her, det er at man tar de verdiene som lå i Ax, og så legger man ut her. De 32 bitene får da plass i det som er satt av i ramm til de 32 bitene. Og når man skriver kode... Hvis man skriver kode sånn som dette her... Int svar er lik 42. Så det kompulatoren gjør da, nå som vi kan gjøre direkte i assembly... Finne en plass her i ram, og så skrive inn ener og nullere som tilsvarer 42, sånn at du lagrer dataene. Men når vi da gjør operasjoner sånn som add, så... Så opererer da add på registrene. Men en add-operasjon kan også operere på en variabel. Og et register samtidig. Så vi kan f.eks. si add % eax til svar. Så hvis jeg gjør en sånn... Hvis jeg gjør en sånn operasjon, så sier jeg ta det tallet som ligger i eax... Kanskje det er et tall 10 som ligger der. Og legg til svar. Og så ligger det allerede 32 her i svar.", "source": "lecture"}
{"lecture_id": "os5del10", "chunk_id": "os5del10_0004", "start": 370.12, "end": 474.24, "token_count": 297, "text": "Så hvis jeg gjør en sånn... Hvis jeg gjør en sånn operasjon, så sier jeg ta det tallet som ligger i eax... Kanskje det er et tall 10 som ligger der. Og legg til svar. Og så ligger det allerede 32 her i svar. Og så ligger det kanskje... Her ligger det 10 i det eksempelet vi hadde. Denne maskininstitusjonen her, den vil nå utføre operasjonen at den tar det tallet 10 og legger til 32, sånn at etter denne institusjonen er utført, så står det 42 her. Det er klart at dette er hardware-kodet, altså denne institusjonen, på en sånn måte at først må verdien 32 som ligger her, sendes på databussen fra RAM til CPU. Her er databuss. Og det skjer da. Når man utfører en sånn operasjon som dette. Men det er hardware-kodet på forhånd, at når den institusjonen der utføres, så tar man først 32 og legger det inn her i et register. Og så legges det tallet sammen med AX gjennom aluen, for det tallet 32 må selves.", "source": "lecture"}
{"lecture_id": "os5del10", "chunk_id": "os5del10_0005", "start": 446.24, "end": 540.44, "token_count": 290, "text": "Når man utfører en sånn operasjon som dette. Men det er hardware-kodet på forhånd, at når den institusjonen der utføres, så tar man først 32 og legger det inn her i et register. Og så legges det tallet sammen med AX gjennom aluen, for det tallet 32 må selves. Det går via registeret, og så lagres det ut igjen i mellomlagrets resultat. Og så lempes det ut via databussen ut hit, sånn at 42 lagres. Nøyaktig hva som skjer ved en institusjon, det er brent inn i kretskortet i hardware. Så det er liksom forhåndsbestemt hvordan dette skjer. Det eneste vi som programmerere vet, og det eneste operatørsystemet vet, er at resultatet blir sånn som det. Dette vet kompulatoren om, så den kan i stedet for å lage instruksjoner som da går inn og ut av databussen, som tar tid, så prøver den å optimalisere og gjøre mest mulig med registeret her inne. For da trengs ikke den lange ferden ut på databussen og ut til ham. Det fungerer.", "source": "lecture"}
{"lecture_id": "os5del13", "chunk_id": "os5del13_0000", "start": 0.0, "end": 82.54, "token_count": 222, "text": "Først skal jeg si litt om forenklinger ved den CPU-simuleringen vi hadde. Den simulerte CPU-en vi hadde, virker i prinsipp som alle mer komplekse og moderne CPU-er. Men den har en rekke forenklinger. Det vil si... De er lagd mer komplekse for at de skal være raskere. I prinsippet virker de på samme måte. For det første bruker institusjoner mer tid enn én CPU-sykkel på å utføres. Det er fordi de operasjonene er mer komplekse enn i vår enkle CPU, så det tar mer tid. Først værer instruksjonen inn fra RAM, så deles den opp i flere biter. Hvis en institusjon leser fra RAM eller skriver til RAM, er det egne deler av institusjonen. Så en X86-instruksjon deles generelt opp i små biter, eller mikrooperasjoner.", "source": "lecture"}
{"lecture_id": "os13del15", "chunk_id": "os13del15_0000", "start": 0.0, "end": 95.4, "token_count": 290, "text": "Og dette med å bruke et virtuelt minnerom, det kalles generelt paging. Og det er fordi man deler inn hver sin prosess, sitt virtuelle minnerom, i et antall sider. Så la oss si de forrige prosessene, da. De hadde 50 bite per side. Så hvis den besto av 500 bites, så ville de fått 10 sider. I MMU vil det bare stå hvor disse ti sidene ligger. Og da... Når vi organiserer ram, det virtuelle ram, i sider, eller pages på denne måten, så kan operativsystemet da dynamisk laste inn og ut disse sidene fra ram. Og det kan da types å være enheter på 4K, f.eks., En vanlig sidestørrelse er 4K. Og da deles alle programmer inn i biter av 4K, og så laster operativstemmet inn og ut disse bitene. Og på den måten så har jeg operativstemmet full kontroll over minibruken og kan dynamisk da endre tildelingen av ramm til alle prosesser. Et lite fiktivt eksempel på hvordan dette kan se ut. En page har størrelse 2 jentebites.", "source": "lecture"}
{"lecture_id": "os13del15", "chunk_id": "os13del15_0001", "start": 65.04, "end": 153.5, "token_count": 279, "text": "og så laster operativstemmet inn og ut disse bitene. Og på den måten så har jeg operativstemmet full kontroll over minibruken og kan dynamisk da endre tildelingen av ramm til alle prosesser. Et lite fiktivt eksempel på hvordan dette kan se ut. En page har størrelse 2 jentebites. Skal se senere hvorfor det må være akkurat 2 jenter. Typiske verdier er 1 lik 12 eller 13, sånn at du får sidestørrelse på 4 eller 8 kilobite. 4 kilobite er vanlig for X86-prosessorer. Det er ganske standard. Så... Så dette gjelder per prosess. Så vi har da en tabell... Hver prosess har en egen tabell. Og hvis du har én CPU, så er det jo bare én prosess som kjører av gangen. Så vi trenger egentlig bare å ha i MMU den ene tabellen for prosessen som kjøres. Når en prosess switches ut, så lagres da MMU-tabellen i PCB. Men her har vi en prosess med logisk minne, side 01234...", "source": "lecture"}
{"lecture_id": "os13del15", "chunk_id": "os13del15_0002", "start": 125.64, "end": 216.28, "token_count": 296, "text": "Og hvis du har én CPU, så er det jo bare én prosess som kjører av gangen. Så vi trenger egentlig bare å ha i MMU den ene tabellen for prosessen som kjøres. Når en prosess switches ut, så lagres da MMU-tabellen i PCB. Men her har vi en prosess med logisk minne, side 01234... Og MMU vil da være en tabell som sier hvor i det fysiske minnet disse sidene ligger. Så f.eks.... Her står det frame nummer... Eller virtuell side nummer 0 ligger i page nummer 1. Eller i frame nummer 1. Det logiske minnet kaller jeg pages. Og så er dette i fysisk minne - det er frames. Og i MMU så står det her at page nr. 0 ligger i frame 1. Og page nr. 1 ligger i frame 4. Enkelt og greit, bare en tabell som viser denne oversettelsen. Men det er veldig viktig at denne oversettelsen må være veldig hurtig. Så vi skal se litt i detalj på etter hvert hvordan... I en sånn pagetabell så har vi da en pagetable-entry for hver eneste side.", "source": "lecture"}
{"lecture_id": "os13del15", "chunk_id": "os13del15_0003", "start": 191.08, "end": 295.24, "token_count": 280, "text": "Enkelt og greit, bare en tabell som viser denne oversettelsen. Men det er veldig viktig at denne oversettelsen må være veldig hurtig. Så vi skal se litt i detalj på etter hvert hvordan... I en sånn pagetabell så har vi da en pagetable-entry for hver eneste side. Og det viktigste da er sidenummeret. Det er altså det nummeret her. Denne virtuelle siden. I hvilken fysisk frame ligger den? Men vi har også noen andre bits. F.eks. sånn at man kan sette skrive- og leserettigheter på minnet også. Per prosess og per page. Og så har man present-absent-bit. Det sier om... Det sier om denne siden faktisk ligger i det fysiske minnet. Hvis du står null her, så betyr det at den ligger bare på disken. Og da, hvis du ønsker... Hvis programmet ønsker å hente noe fra denne siden, så må man ut på disken og hente den. Og det er en såkalt page fault. Siden mangler, og må ut på disken og hente, og det tar veldig lang tid.", "source": "lecture"}
{"lecture_id": "os13del15", "chunk_id": "os13del15_0004", "start": 277.24, "end": 340.86, "token_count": 214, "text": "Og da, hvis du ønsker... Hvis programmet ønsker å hente noe fra denne siden, så må man ut på disken og hente den. Og det er en såkalt page fault. Siden mangler, og må ut på disken og hente, og det tar veldig lang tid. Men hvis den er 1, så betyr det at siden er dirty eller har blitt endret. Og det betyr at hvis... Hvis den siden skal ut av ramm, så må verdien skrives til disk. Hvis den ikke har blitt endret og skal ut av ramm, så kan du bare droppe den. Men hvis endret-bit er 1, så er siden dirty og den må skrives til disk før den kan... Før den kan fjernes fra rammen. Så er det reference. Det brukes av pensing-algoritmer. Som velger hvilke sider som til enhver tid skal ha plass i rammen.", "source": "lecture"}
{"lecture_id": "os11del12", "chunk_id": "os11del12_0000", "start": 0.0, "end": 118.9, "token_count": 298, "text": "Da har vi... et ja-program her som heter saldo. Det skal vi studere nå. Det gjør litt av det samme som det saldoprogrammet vi så på, gjorde. Men i vårt tilfelle så er det to saldotretts. Det er to tråder, S1 og S2. Ja, saldo av 1000. Den bare sover 1000 millisekunder. Det spiller ingen rolle i dette tilfellet. Men det som er viktig, er at vi har en public static int-saldo. En static int-saldo, så det betyr at den er felles. Og så har vi to tråder som oppdaterer denne saldoen. Og det som vi ser, skjer, er at hvis ID er lik 1, så økes saldoen med én maks antall ganger. Hvis ID er to, så minskes saldoen med én. Og da er det klart. Ja, maks er et svært tall. Det er én million. Så det er klart, hvis du øker en saldo Og så minsker den ml noen ganger med én. Så burde det ende opp med null til slutt. Men... Da skal vi se hvordan det ser ut når vi kjører den... Den jobba. Ja... Da starter to tråder.", "source": "lecture"}
{"lecture_id": "os11del12", "chunk_id": "os11del12_0001", "start": 83.84, "end": 189.4, "token_count": 290, "text": "Det er én million. Så det er klart, hvis du øker en saldo Og så minsker den ml noen ganger med én. Så burde det ende opp med null til slutt. Men... Da skal vi se hvordan det ser ut når vi kjører den... Den jobba. Ja... Da starter to tråder. Begge med samme prioritet. Det spiller ikke så stor rolle. Men så ser vi et eller annet galt her... skjer. Den endelige, totale saldoen er 38 000. Og hvis vi prøver å kjøre på nytt, så ser vi... Da ble det 92 000. Og her... Det er 27 642. Så vi ser. Hver gang vi kjører, så... Så får vi en helt annen verdi. Her ble det minus 32 000. Dette ser jo veldig merkelig ut. Men det er akkurat den effekten vi så i eksempelet med saldo og én million som blir borte. Det er ikke noen serialisering mellom trådene. Sånn at... De vil hente inn den samme saldoverdien, og så vil de endre den. Og her ser vi at vi får en veldig stor effekt,", "source": "lecture"}
{"lecture_id": "os11del12", "chunk_id": "os11del12_0002", "start": 167.48, "end": 207.96, "token_count": 140, "text": "med saldo og én million som blir borte. Det er ikke noen serialisering mellom trådene. Sånn at... De vil hente inn den samme saldoverdien, og så vil de endre den. Og her ser vi at vi får en veldig stor effekt, fordi at de vil gjøre mange operasjoner. Øke saldoen med 30 000, kanskje, og så kommer den andre inn, og den har da allerede lest inn den samme verdien. Og så fortsetter de å jobbe med den. Så her blir forskjellene veldig...", "source": "lecture"}
{"lecture_id": "os1del17", "chunk_id": "os1del17_0000", "start": 0.0, "end": 103.22, "token_count": 283, "text": "OK, da har vi ti minutter igjen, så skal vi ta en kort introduksjon til datamaskinarkitektur, som er det vi skal jobbe med de neste ukene. Da har vi så vidt sett litt på hva operativsystemer og prosesser osv. er. For å kunne forstå det helt i detalj, hvordan operativsystemet virker. så trenger man også å forstå hardware. Man må forstå hvordan CPU og ramme fungerer, for å forstå hvordan operativsystemkjernen styrer denne hardwaren. Og hardware, det bygger i bunn og grunn på digitalteknikk. Alt i en datamaskin er representert ved null og enere. Og det er ganske enkelt. Det er ingen spenning. Og en ener er f.eks. 5 volts spenning i forhold til jord. Med en gang man har nuller og enere, så kan man representere tall med nuller og enere, binære tall. F.eks. kan du sette 32-bit ved siden av hverandre med nuller og enere. Da får man et heltall, en integer, og da kan man representere tall opp til 32 andre. Eller omtrent 4 milliarder.", "source": "lecture"}
{"lecture_id": "os1del17", "chunk_id": "os1del17_0001", "start": 78.34, "end": 175.76, "token_count": 280, "text": "med nuller og enere, binære tall. F.eks. kan du sette 32-bit ved siden av hverandre med nuller og enere. Da får man et heltall, en integer, og da kan man representere tall opp til 32 andre. Eller omtrent 4 milliarder. I en datamaskin så er alt tall. Og utgangspunktet er da nuller og enere. Dette er typisk sånn som man har i en standard CPU. At du har null er representert med ingen spenning. Fem volt betyr da at her er det spenning, og det er da en ener. Man sier alltid at alle datamaskiner er drevet binært, og det er riktig. Men det er ikke opplagt at man skulle bruke det binære tallsystemet. Det var en del forskjell på å bruke desimale tall. Og det kunne man da oppnå ved å liksom si at null er null volt, én er én volt, to er to volt, tre er tre volt osv. Og så representere alt med desimale tall. Men det viser seg at det blir veldig komplisert i praksis å få til, sånn at...", "source": "lecture"}
{"lecture_id": "os1del17", "chunk_id": "os1del17_0002", "start": 150.52, "end": 229.96, "token_count": 293, "text": "Det var en del forskjell på å bruke desimale tall. Og det kunne man da oppnå ved å liksom si at null er null volt, én er én volt, to er to volt, tre er tre volt osv. Og så representere alt med desimale tall. Men det viser seg at det blir veldig komplisert i praksis å få til, sånn at... Etter hvert så har alle datamaskiner benyttet det binære tallsystemet, fordi det er veldig enkelt å skille mellom null og én. Men ut fra binære tall, så kan man representere alt. F.eks. er det lett å representere disse med alle tall, sånn som her. 0101 er fem. En ener pluss en firer, det blir en femmer. Og så kan man representere bokstaver. F.eks. bokstaven P er tallnummer... Da har du bokstaver. Så kan man representere piksler i grafikk, og fargen til piksler. Dermed har du alt som er en datamaskin, og alt kan da representeres ved nuller og enere. Datamaskinarkitektur går da ut på å manipulere på disse nuller og enerne,", "source": "lecture"}
{"lecture_id": "os1del17", "chunk_id": "os1del17_0003", "start": 205.8, "end": 289.2, "token_count": 284, "text": "Da har du bokstaver. Så kan man representere piksler i grafikk, og fargen til piksler. Dermed har du alt som er en datamaskin, og alt kan da representeres ved nuller og enere. Datamaskinarkitektur går da ut på å manipulere på disse nuller og enerne, sånn at man får gjort nøyaktig det man ønsker å gjøre. Så alt er tall, og her ser vi da konkret hvordan et binært tall kan se ut. Og her ser vi sånne ledninger, og det er ikke tull, det er virkelig ledninger. Så kan du da måle... Du måler at det er spenningsforskjell i forhold til jord. Og da kan du... Hvis det er null her, så betyr det at det er faktisk en null. Og fem volt her, det betyr en ener. Og sånn får vi... Det er ener her. To en-toer. Ingen firere og en åtter. Og det blir til sammen tallet ti. Men for å lage en datamaskin, så trenger man ikke bare å representere tall. Man må kunne lagre f.eks. 32-bit.", "source": "lecture"}
{"lecture_id": "os1del17", "chunk_id": "os1del17_0004", "start": 261.44, "end": 350.56, "token_count": 296, "text": "Og fem volt her, det betyr en ener. Og sånn får vi... Det er ener her. To en-toer. Ingen firere og en åtter. Og det blir til sammen tallet ti. Men for å lage en datamaskin, så trenger man ikke bare å representere tall. Man må kunne lagre f.eks. 32-bit. Men man må kunne utføre alle mulige logiske og matematiske operasjoner på samlinger av bit. Som f.eks. addere, subtrahere, multiplisere, dividere, sammenligne, skifte operasjoner og en rekke andre operasjoner. Men disse er faktisk de viktigste. De fleste programmer kan man utføre bare ved å ha disse få operasjonene. Og dette er da maskininstruksjoner som vi skal se på i stor detalj. Men det vi skal se på aller først, er hvordan kan man lage Det er en enkel operasjon. Hvordan kan man få til det? Hvordan kan man få til å lage logiske operasjoner rent fysisk? Jo, det kan gjøres med logiske kretser. Først skal man bygge de logiske kretsene sånn teoretisk. Tenke seg hvordan bør dette se ut.", "source": "lecture"}
{"lecture_id": "os1del17", "chunk_id": "os1del17_0005", "start": 325.8, "end": 414.48, "token_count": 295, "text": "Det er en enkel operasjon. Hvordan kan man få til det? Hvordan kan man få til å lage logiske operasjoner rent fysisk? Jo, det kan gjøres med logiske kretser. Først skal man bygge de logiske kretsene sånn teoretisk. Tenke seg hvordan bør dette se ut. Og etterpå så kan man da bygge de logiske kretsene fysiske som integrerte kretser. Noen fysiske integrerte kretser. Logiske kretser. Det er kretser som da utfører binær logikk eller binær algebra. Og alle binære operasjoner kan utføres med såkalte and or not-operasjoner. Så da kan man... Alt man ønsker å få til, kan man få til ved disse operasjonene. Da gjør man ganske enkelt sånn at man bygger disse tre logiske operatorene i hardware. Og dermed så kan man få til hva man vil av både addisjon og divisjon og... Alle operasjoner er mulige å få til hvis man setter sammen de riktige logiske operasjonene and or not. På en helt spesiell måte. Man må finne ut nøyaktig hvordan man skal sette det sammen.", "source": "lecture"}
{"lecture_id": "os1del17", "chunk_id": "os1del17_0006", "start": 394.08, "end": 494.88, "token_count": 288, "text": "Og dermed så kan man få til hva man vil av både addisjon og divisjon og... Alle operasjoner er mulige å få til hvis man setter sammen de riktige logiske operasjonene and or not. På en helt spesiell måte. Man må finne ut nøyaktig hvordan man skal sette det sammen. Disse operasjonene kalles porter. Før vi går og ser på hvordan portene opererer, hva som er logikken i det, så må vi se litt på den fysiske utførelsen av de. I de aller første datamaskinene brukte man... Radiorør som man brukte for å implementere And or not-porter. Men de radiorørene har en fysisk størrelse som er... De er store. Så dermed... Det som i dag er bitte små datamaskiner, fylte da opp store saler. Det trengte enormt mye plass. Men... det var en god start. Det var en veldig stor oppdagelse i forrige århundre, kvantemekanikken. Nemlig hvordan verden virker helt nede på mikronivå, på atomnivå. Og denne teknologien gjorde det mulig å lage transistoren,", "source": "lecture"}
{"lecture_id": "os1del17", "chunk_id": "os1del17_0007", "start": 467.06, "end": 561.0, "token_count": 293, "text": "Det trengte enormt mye plass. Men... det var en god start. Det var en veldig stor oppdagelse i forrige århundre, kvantemekanikken. Nemlig hvordan verden virker helt nede på mikronivå, på atomnivå. Og denne teknologien gjorde det mulig å lage transistoren, som var helt grunnleggende for datamaskinen. Det som var fantastisk med transistoren, var at man kunne lage and or not. Som var ekstremt små. Sånn at man kan få i dag mange milliarder av dem på en kvadratcentimeter. Det er hele grunnlaget for datamaskinen. Og de er så små at ledningene er sånn type ned på fem nanometer i bredde. Og et hårstrå er 100 000 nanometer. Du kan tenke deg hvor ekstremt små de er. Og det man da bruker disse transitionordene til, det er å lage en liten logisk port, sånn som dette her. Dette er AND-porten. Og den fungerer sånn at du har input A, B, nuller og enere. Så her kommer A inn som en... La oss si det kommer en null inn her,", "source": "lecture"}
{"lecture_id": "os1del17", "chunk_id": "os1del17_0008", "start": 535.8, "end": 615.2, "token_count": 293, "text": "Og det man da bruker disse transitionordene til, det er å lage en liten logisk port, sånn som dette her. Dette er AND-porten. Og den fungerer sånn at du har input A, B, nuller og enere. Så her kommer A inn som en... La oss si det kommer en null inn her, og B er en null. Og da kommer A, prikk B. Eller A og B, som dere som har diskré matematikk, som kanskje er vant til å le. Men hvis det kommer to nuller inn, så kommer det en null ut. Og tilsvarende, hvis det kommer null og én eller én og null inn, så kommer det også null ut. Og det er bare i tilfelle én-én kommer inn, så kommer det en ener ut. Og dette er da én byggescene, én port. Det tar veldig kjapt. De andre er år, som har en litt annen virkemåte. Og not, som er rett og slett sånn at hvis det kommer en null inn, så kommer en ener ut. Hvis det kommer en ener inn, så kommer en null ut. Her snakker vi om spenninger. Hvis du kobler på en spenning null her,", "source": "lecture"}
{"lecture_id": "os1del17", "chunk_id": "os1del17_0009", "start": 595.8, "end": 678.2, "token_count": 291, "text": "Det tar veldig kjapt. De andre er år, som har en litt annen virkemåte. Og not, som er rett og slett sånn at hvis det kommer en null inn, så kommer en ener ut. Hvis det kommer en ener inn, så kommer en null ut. Her snakker vi om spenninger. Hvis du kobler på en spenning null her, så vil det komme en spenning én ut i den andre enden. Det som er helt fantastisk, er at bare ved hjelp av de tre portene, så kan man lage en vilkårlig. Å få til alle mulige logiske kretser, sånn som dette her er eksempel på. Her setter vi sammen en and og en overport, og så får vi ut et resultat. Det vi skal se på i neste uke, er hvordan man generelt kan lage en stor, kompleks sak av sånne and og overporter. Og så kan man f.eks. få til det At man starter med to binære tall, kanskje 32-bits binære tall til og med. Og så setter man sammen en masse and-of-ar-porter på en sånn måte at i andre enden så kommer det som kommer ut da, er summen av de to tallene.", "source": "lecture"}
{"lecture_id": "os1del17", "chunk_id": "os1del17_0010", "start": 648.64, "end": 726.08, "token_count": 255, "text": "en stor, kompleks sak av sånne and og overporter. Og så kan man f.eks. få til det At man starter med to binære tall, kanskje 32-bits binære tall til og med. Og så setter man sammen en masse and-of-ar-porter på en sånn måte at i andre enden så kommer det som kommer ut da, er summen av de to tallene. Og det er veldig langt fra opplagt hvordan man kan sette sammen de. Men ved hjelp av binærlogikk så kan man få til... Og sette sammen en smørja masse and or not-porter på en sånn måte at hvis man sender to binære tall inn i denne svære boksen med and or not-porter, så kommer det alltid ut summen i den andre enden. Og sånn er generelt en datamaskin bygget opp. Og vi skal faktisk i ganske stor detalj bygge opp en virtuell sånn maskin. Som den skal teste ut. Og så skal vi kjøre programmer på den maskinen. For å se helt nøyaktig hvordan den sitter ut.", "source": "lecture"}
{"lecture_id": "os11del6", "chunk_id": "os11del6_0000", "start": 0.0, "end": 99.0, "token_count": 299, "text": "Synkronisering. Ja, da er vi over på et helt nytt tema, men som ligger tett opp til dette med tråder og problemer man kan få når man kjører tråder samtidig. Synkronisering er generelt viktig når man har felles ressurser eller felles data som flere prosesser samtidig... Dette kommer til å være tema resten av dagen. Vi skal se på noen konkrete eksempler på hva som kan gå galt hvis prosesser prøver å endre på fellesdata samtidig. Da kan det bli en skikkelig krasj. Og de prinsippene som følger, er at prosesser må ikke endre fellesdata samtidig. Vi har et eksempel med et billettsystem. Hvis den ene prosessen da tar en billett og oppdaterer og deler ut den billetten samtidig som en annen gjør det samme, da ser vi med en gang at da kan vi få problemer. Det er en såkalt race condition. Det har noe å si hvem som kommer først frem. Og databasen kan ødelegges. Den variabelen kan få en feil verdi hvis man ikke synkroniserer. Det er derfor synkronisering er så viktig.", "source": "lecture"}
{"lecture_id": "os11del6", "chunk_id": "os11del6_0001", "start": 74.74, "end": 169.08, "token_count": 296, "text": "samtidig som en annen gjør det samme, da ser vi med en gang at da kan vi få problemer. Det er en såkalt race condition. Det har noe å si hvem som kommer først frem. Og databasen kan ødelegges. Den variabelen kan få en feil verdi hvis man ikke synkroniserer. Det er derfor synkronisering er så viktig. Og dette er altså noe som praktisk dukker opp med en gang man har prosesser som jobber mot noe felles. Og det er veldig vanlig nå som man har massedistribuerte systemer som kobler seg opp mot samme database, så er det veldig viktig å ha... For å synkronisere disse tilgangene til data. Et annet prinsipp er at en prosess ikke bør lese felles data mens en annen endrer dem. En prosess må også kunne vente på resultater fra en annen prosess. Det er en annen måte å synkronisere på, som vi skal se på senere. Da må prosessene seg imellom synkroniseres. Serialisering er det temaet vi først og fremst skal se på i dag. Da ser vi på prosesser eller tråder som aksesserer felles data.", "source": "lecture"}
{"lecture_id": "os11del6", "chunk_id": "os11del6_0002", "start": 144.6, "end": 229.04, "token_count": 289, "text": "Det er en annen måte å synkronisere på, som vi skal se på senere. Da må prosessene seg imellom synkroniseres. Serialisering er det temaet vi først og fremst skal se på i dag. Da ser vi på prosesser eller tråder som aksesserer felles data. Det kan være bare én enkelt variabel. Men det som er viktig, er at de har felles. Med Java-tråder vil det være en... Når vi definerer en variabel som static, så er den felles. Vi skal se noen eksempler med at dette er en saldo. Det er opplagt at når man gjør endringer på saldo, så må det gjøres systematisk. Og da må én av gangen jobbe på de dataene. Det vi skal se er problemet, er typisk at man leser av en saldo... Det kan være fra en database, men det kan også være fra ram. Men som vi har sett tidligere, når Seppjord skal regne på det, så vil den verdien vil lastes inn i registrene. Og der kan det fort bli krøll hvis to prosesser ikke er synkronisert, eller serialisert, når du gjør dette.", "source": "lecture"}
{"lecture_id": "os11del6", "chunk_id": "os11del6_0003", "start": 210.0, "end": 284.0, "token_count": 295, "text": "Men som vi har sett tidligere, når Seppjord skal regne på det, så vil den verdien vil lastes inn i registrene. Og der kan det fort bli krøll hvis to prosesser ikke er synkronisert, eller serialisert, når du gjør dette. Det at vi serialiserer, er at vi sie. Ok, én av gangen får tilgang til denne felleshånddrabelen. Hele denne problemsiden kalles 'of the race condition'. Konkurranse om en felles ressurs. Og den race condition vil da være sånn at utfallet av å kjøre programmene er forskjellig avhengig av hvilken prosess som kommer først fram til den felles ressursen. Og sånn kan det absolutt ikke være. Alt programmet bør være sånn at hvis du kjører de med akkurat samme randbetingelser, akkurat samme forutsetninger, så bør resultatet bli det samme. Men det skal vi se. Hvis man ikke serialiserer, så kan vi se. Flere eksempler på at da går det virkelig galt, og data ødelegges. Så er det også et viktig poeng at det er programmereren selv som må selvrealisere prosesser.", "source": "lecture"}
{"lecture_id": "os11del6", "chunk_id": "os11del6_0004", "start": 263.06, "end": 297.0, "token_count": 130, "text": "randbetingelser, akkurat samme forutsetninger, så bør resultatet bli det samme. Men det skal vi se. Hvis man ikke serialiserer, så kan vi se. Flere eksempler på at da går det virkelig galt, og data ødelegges. Så er det også et viktig poeng at det er programmereren selv som må selvrealisere prosesser. Men operativstemmet legger til rette for det. Så det er en rekke forskjellige muligheter som programmereren har for å selvrealisere.", "source": "lecture"}
{"lecture_id": "os10del6", "chunk_id": "os10del6_0000", "start": 0.0, "end": 116.7, "token_count": 293, "text": "Da kan vi se litt på... resultatene. Den første er Adopt-alt, komplert med GCC. Skal vi se... Da må vi prøve å huske hva som egentlig skjedde her. Jo, Adopt-alt... Den kjørte i hvert fall på den AMD med AMD-opptråd. Alt synes. Jo, Adopt-Alt her... På Arm så kjører ikke Adopt-Alt. Og det er rett og slett fordi det er Arm-instruksjoner som ligger i bunnen. Så den CPU-en forstår ikke hvilke instruksjoner som ligger i Adopt-Alt når den er kompilert for en Exo86-prosessor. Så den er ikke riktig. På Windows-server kan du si at den både kjørte og ikke kjørte. I utgangspunktet så kjører den ikke. Men når du da kjører en ekte Linux-kjørne på Windows, så kjør den. På Mac så kjørte den heller ikke, det er en del som har svart at den kjørte der. Til tross for at det er en del leacuper, Adolf kjører ikke fordi den prøver å snakke med Linux-kjørnen, og så treffer den MacOS.", "source": "lecture"}
{"lecture_id": "os10del6", "chunk_id": "os10del6_0001", "start": 90.02, "end": 197.08, "token_count": 297, "text": "Men når du da kjører en ekte Linux-kjørne på Windows, så kjør den. På Mac så kjørte den heller ikke, det er en del som har svart at den kjørte der. Til tross for at det er en del leacuper, Adolf kjører ikke fordi den prøver å snakke med Linux-kjørnen, og så treffer den MacOS. Så det er bare den her, som de aller fleste svarte, som er riktig. Ja, den... Hello... Her har de fleste fått med seg hva som skjedde. På eldre Java-versjoner så kjørte ikke den Helado-plass. Men den kjørte bare her, som 90 % har sagt, på Linux i bunntur på ARM. Python... Ja, det vi har sett, så kjørte vel Python egentlig overalt. I hvert fall når vi ikke tok med dem... Når vi hadde med parenteser, som på en måte var plattformuavhengig. Da... Eller Python-versjoner er bra, men Python kjørte overalt. Det samme kan man vel egentlig si at LOD-bæsj gjorde. Det kjørte på Mac, og det kjørte nesten selvfølgelig på disse Linux-punktene.", "source": "lecture"}
{"lecture_id": "os10del6", "chunk_id": "os10del6_0002", "start": 165.68, "end": 243.0, "token_count": 228, "text": "Når vi hadde med parenteser, som på en måte var plattformuavhengig. Da... Eller Python-versjoner er bra, men Python kjørte overalt. Det samme kan man vel egentlig si at LOD-bæsj gjorde. Det kjørte på Mac, og det kjørte nesten selvfølgelig på disse Linux-punktene. Her igjen så er det både ja og nei. Jeg har tatt på en standard Windows-server, så kjører ikke et Bæsj her. Men hvis du installerer Linux subsystem... Så kjører... Så installerer du også bæsj, og da kan du få bæsjskrittet til å kjøre. Men det... Ja, det er på en måte litt... Litt juks, for da installerer du en ny plattform. Eller juks... Man må ta med det i beregningen. Men defolt vil verken et skjellskrift eller Adopt... Kjøre på vinduene.", "source": "lecture"}
{"lecture_id": "os1del9", "chunk_id": "os1del9_0000", "start": 0.0, "end": 89.2, "token_count": 281, "text": "Ja. Eksamen nevnte jeg også. Igjen så avhenger dette av koronasituasjonen. Men dere kan gjerne komme med innspill til hva dere ønsker. Obligatoriske gruppeinnleveringer. Jeg kommer til å legge ut til Kanvas-grupper, sånn at dere kan lage egne grupper. Jeg tror vi har pleid å ha maks på fire. Men hvis det er noen som ønsker å være enda større enn det, så går det an. Og det går også an å være alene på grupper. Men det er et krav at alle de tre obligene må være godkjent for å kunne melde seg opp til eksamen. Så kommer det også til å være noen multiple choice-tester, som er obligatoriske. Systemet der også, pga. autentisering mot OsloMet sentralt. Men hvis vi får det opp å kjøre, så kommer opplegget til å fungere som dette her. Hvis ikke, så blir det noen Kanvas multiprofile-tester med omtrent omtrent samme opplegg. Men det kommer vi tilbake til. Men uansett så er ikke disse veldig omfattende. Det er sånn som man gjør på ti minutter.", "source": "lecture"}
{"lecture_id": "os1del9", "chunk_id": "os1del9_0001", "start": 66.44, "end": 127.0, "token_count": 233, "text": "Men hvis vi får det opp å kjøre, så kommer opplegget til å fungere som dette her. Hvis ikke, så blir det noen Kanvas multiprofile-tester med omtrent omtrent samme opplegg. Men det kommer vi tilbake til. Men uansett så er ikke disse veldig omfattende. Det er sånn som man gjør på ti minutter. Hvis man har jobbet bra med kurset, så bør disse gå ganske så greit. Hovedtanken med disse er at det skal gi en feedback til dere. Hvor står dere, hva har dere fått med dere av det som er pensel. Viktigste grunn til at vi begynte med dette, var at det var mange studenter som først da de kom på eksamen, oppdaget at dette har de ikke fått med seg. Så dette er en viktig tilbakemelding til dere også. Det er ikke bare en sånn obligg og jeg må gjøre det, men dette er en tilbakemelding til dere.", "source": "lecture"}
{"lecture_id": "os3bdel6", "chunk_id": "os3bdel6_0000", "start": 0.0, "end": 99.22, "token_count": 284, "text": "Beregningsenheter. Her er det listet opp en rekke forskjellige beregningsenheter. Bare for å sette det vi har sett på i perspektiv. I dag har vi sett på aluen, som er CPU-ens hjerne. Og CPU, Central Processing Units, det er da den viktigste biten av en datamaskin, hvor all prosessering gjøres. Så har vi noen andre varianter. Vanligvis er det integrert i CPU, og det er egentlig bare en spesiell alu som også kan brukes i floating point. Da trenger man mer komplekse og kompliserte kretser som utfører det. Det tar typisk litt lengre tid å dele to floating points på hverandre i forhold til helt annet. Det trengs mye prosessorkraft, og mye gjøres i parallell. Så da har man typisk tusenvis av små aluer som gjør beregninger samtidig i parallell. Og alt dette sitter vanligvis i vanlige datamaskiner. Til slutt har Lisset et par andre FPGA, Field Programmable Gate Array. Hvis man har et logisk diagram, så kan man programmere det inn i en FBGA.", "source": "lecture"}
{"lecture_id": "os3bdel6", "chunk_id": "os3bdel6_0001", "start": 64.08, "end": 169.78, "token_count": 296, "text": "Så da har man typisk tusenvis av små aluer som gjør beregninger samtidig i parallell. Og alt dette sitter vanligvis i vanlige datamaskiner. Til slutt har Lisset et par andre FPGA, Field Programmable Gate Array. Hvis man har et logisk diagram, så kan man programmere det inn i en FBGA. Og det går veldig hurtig. Men det fine med den er at den brennes ikke engang for alle. Den kan da reprogrammeres. ASIC derimot, Application Specific Integrated Circuit, det er virkelig en integrert krets. Da tar du en logisk krets, så sender du den til en ASIC-fabrikk, og så lager du nøyaktig den. Det er da... Det er da ekstremt hurtig. Hvis du har fulgt med på sånn som bitcoin, hvor man da... Hvor man da bruker CPU-kraft for å regne ut og finne bitcoins, så starter man gjerne på... Men etter hvert gikk man over til GPU for å kunne gjøre dette raskere. Men nå går det for sakte med både CPU-er og GPU-er, så man gikk over til FPGA. Og helt til slutt så har man lagd ASIC, altså helt spesifikke integrerte kretser", "source": "lecture"}
{"lecture_id": "os3bdel6", "chunk_id": "os3bdel6_0002", "start": 150.0, "end": 246.02, "token_count": 289, "text": "Men etter hvert gikk man over til GPU for å kunne gjøre dette raskere. Men nå går det for sakte med både CPU-er og GPU-er, så man gikk over til FPGA. Og helt til slutt så har man lagd ASIC, altså helt spesifikke integrerte kretser som regner ut bitcoins hurtigst mulig. Et spørsmål i chatten om man snakker om flere kjerner i en CPU. Er det da snakk om flere? Ja, det er et godt spørsmål. Ja, man har da... Man må da ha minst... Eller man har én alu per core. Så når vi snakker om flere course, så er det uavhengig regneenheter. Men det hender det varierer litt. F.eks. så er det noen versjoner av IMD. Som har 40 course. Og da... Men da... I noen tilfeller har den 20 course som er hypertrening. Sånn at... Man har 40 alluer, men så har man bare 20 FPU-er. Så det varierer litt. Men stort sett så kan du bare si at... Hver kår er en alu, altså en uavhengig, rene enhet.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0000", "start": 0.0, "end": 107.98, "token_count": 298, "text": "Før vi begynner å se på tråder og trets generelt, så tenkte jeg at vi skulle ta en poll. Jeg hadde egentlig tenkt å ta ett spørsmål av gangen, men vi kan ikke gjerne ta alle på en gang. Så jeg loungerer en poll nå. Den kommer opp. Flott. Da er det bare å svare. Og så er det viktige poenget at dette er multiple choice også. Som det første - hvor vil Adot, outcomplert med GSSI, kjøre? Og da kan man velge flere alternativer. Så hvis du så før pausen, så var det ikke bare ett sted det fungerte. Prøv å huske hva som skjedde, og de forskjellige forskjellene. Og start å svare. Det er noen gjenhold som er i gang allerede. Mens dere holder på, kan jeg gå gjennom spørsmålene ett for ett. Det første er hvor Vil-ah.out kjøre uten ferdigmeldinger. Så kopierer jeg det med KSUSR på Linux med Interm. Det vil da være Exo til seks instruksjoner. Så kopierer jeg det over til alle de andre plattformene. Så er spørsmålet hvor...", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0001", "start": 81.24, "end": 192.9, "token_count": 295, "text": "Det første er hvor Vil-ah.out kjøre uten ferdigmeldinger. Så kopierer jeg det med KSUSR på Linux med Interm. Det vil da være Exo til seks instruksjoner. Så kopierer jeg det over til alle de andre plattformene. Så er spørsmålet hvor... På hvilke av disse plattformene vil faktisk Adolt Alt kunne kjøre? Spørsmål nummer to er det tilsvarende med Lodoto? Og så er det poeng at den er komplett med Java 11. Og som ikke er kompatibel med alle eldre versjoner av Java. Så her er Java-versjonen viktig. Hvis det ikke var for det, så er Java helt plattformuavhengig. Og så er det Pyton. Han kjører... Man kopierer 1.02.pi til alle plattformene, og hvor kjører de uten feilmelding? Og til slutt er det tilsvarende med 1.02.pi. Hvor kjører den uten feilmelding? Og da er det et poeng at... I chatten i pausen om Python... Ja, om spesifikke Python-versjoner. Og da svarte jeg at... Ja, som dere ser...", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0002", "start": 157.84, "end": 269.96, "token_count": 281, "text": "Og til slutt er det tilsvarende med 1.02.pi. Hvor kjører den uten feilmelding? Og da er det et poeng at... I chatten i pausen om Python... Ja, om spesifikke Python-versjoner. Og da svarte jeg at... Ja, som dere ser... Det ble sånn som at Javar kompileres av en lager, en klassefil. Men i Python så kompileres den ikke eksplisitt. Med Python blir programmet kompilert all the flies. Når du kjører et Python-program, så kompileres det til bitekode, sånn som Java, men man ser ikke hvem mellomleddet. Det først kompileres, og så kjøres det i en Python-virtuell maskin. Så det er i prinsippet det samme som skjer på Java, men der har man en eksplisitt kopilering til Java bitekode. Og dermed kan du få den typen problemstillinger med alltid forskjellige versjoner hvor det da ikke fungerer. Ja... Skal vi se hvordan det går med Pollen her... Vi kan godt gi det et par minutter til, så dere får tenkt dere om.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0003", "start": 240.0, "end": 341.9, "token_count": 285, "text": "Og dermed kan du få den typen problemstillinger med alltid forskjellige versjoner hvor det da ikke fungerer. Ja... Skal vi se hvordan det går med Pollen her... Vi kan godt gi det et par minutter til, så dere får tenkt dere om. Det er generelt veldig viktig å prøve å være litt aktive på forelesningene. Uansett... Når du leser om oppletissemsof, så prøv å tenke gjennom problemstillingene, og først og fremst prøv å teste det ut selv. Hvis du lurer på et eller annet, så kan man alltids teste det ut. Det tar tid. Så... Men derfor... Vi bruker gjerne litt tid på et poll som dette her, for det er viktig å prøve å tenke over hva var det som egentlig skjedde når han kjørte alle disse programmene. Og da er det altså lettere å komme litt mer under utenpå hva som egentlig skjer. Og så kan du, hvis det er noen spørsmål som dukker opp her, så kunne vi jo... Så kan vi teste det ut og se hvordan det fungerer.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0004", "start": 313.6, "end": 473.12, "token_count": 273, "text": "hva var det som egentlig skjedde når han kjørte alle disse programmene. Og da er det altså lettere å komme litt mer under utenpå hva som egentlig skjer. Og så kan du, hvis det er noen spørsmål som dukker opp her, så kunne vi jo... Så kan vi teste det ut og se hvordan det fungerer. Eksplosivt... kjøre... Pyton. Pyton 2, f.eks. Så det vil da ikke være noen forskjell på å kjøre med Pyton 2 eller jo, kanskje. Skal vi se... Så skjønner jeg hva du mener. Her står det Jussebien Python. Og det er Python 2, ja. Så... Så det er vel egentlig det som står her, som er litt... ... litt feilaktig. Det er jo ikke feil. Python 3 er versjonen Python 3. Men... Vi ser at... Vi ser at dette er akkurat den institusjonen her og er faktisk avhengig av Python 3. Og når jeg kjører jusbilen Python, så må jeg vite...", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0005", "start": 439.68, "end": 575.72, "token_count": 299, "text": "... litt feilaktig. Det er jo ikke feil. Python 3 er versjonen Python 3. Men... Vi ser at... Vi ser at dette er akkurat den institusjonen her og er faktisk avhengig av Python 3. Og når jeg kjører jusbilen Python, så må jeg vite... Og her nede er det piten 2. Så det ser faktisk ut som det var piten 2 overalt. Skal vi se hvordan det var her. Her er piten 3. Så når man har kopiert den nye piten der, så vil vel da... Men det ser da ut som... Det opprinnelige jeg hadde, var med permittenser, og da fungerer det både på Python 2 og Python 3. Igjen, det er et eksempel på hvordan Python også ikke fungerer. Helt fullstendig plattformuavhengig. Her har vi en... eller ikke plattform, men versjonsuavhengig. Men i prinsippet er både Java og Python plattformuavhengig på den måten at de har virtuelle maskiner for begge plattformene som de kjører bytekode i. Men forskjellen er at Python kompilerer underfly. Da kan vi kanskje stoppe...", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0006", "start": 546.12, "end": 659.94, "token_count": 288, "text": "Her har vi en... eller ikke plattform, men versjonsuavhengig. Men i prinsippet er både Java og Python plattformuavhengig på den måten at de har virtuelle maskiner for begge plattformene som de kjører bytekode i. Men forskjellen er at Python kompilerer underfly. Da kan vi kanskje stoppe... Pollingen. Jeg tenkte jeg bare skulle ta et... En screenshot av den. Så dette er en anonym poll, så... Så ingenting blir lagret om hvem som svarer hva osv. Men da stopper jeg pollingen. Og så deler jeg resultatene. Sånn, Ine, ser du resultatene da? De kommer opp. Flott. Da kan vi se litt på resultatene. Den første er avdådt alt, komplert med gisselser. Skal vi se, da må vi prøve å huske hva som egentlig skjedde her. Jo, adopt... Den kjørte i hvert fall på en AMD med AMD-opptråd. Og de aller fleste har svart at den gjorde det. Det er riktig. Men jeg ser det er mange som har svart at den kjørte på Arm Linux i bunk til morgen.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0007", "start": 630.0, "end": 718.62, "token_count": 286, "text": "Skal vi se, da må vi prøve å huske hva som egentlig skjedde her. Jo, adopt... Den kjørte i hvert fall på en AMD med AMD-opptråd. Og de aller fleste har svart at den gjorde det. Det er riktig. Men jeg ser det er mange som har svart at den kjørte på Arm Linux i bunk til morgen. Det gjorde den faktisk ikke. Den her... Skal vi se... Altså her borte... Dere ser en av skjermene nå, gjør dere ikke det? Alt synes. Ja, flott. Jo, Adopt-Alt her... På Arm så kjører ikke Adopt-At. Og det er rett og slett fordi... Det er ARM-instruksjoner som ligger i bunnen, så CPU-en forstår ikke hvilke instruksjoner som ligger i ADAT når den er kompilert for en X86-prosessor. Så den er ikke viktig. På Windows-server kan du si at den både kjørte og ikke kjørte. I utgangspunktet kjører den ikke fordi det er en Windows-operativsted. Men når du da kjører en ekte Linux-kjerne...", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0008", "start": 697.92, "end": 785.54, "token_count": 285, "text": "når den er kompilert for en X86-prosessor. Så den er ikke viktig. På Windows-server kan du si at den både kjørte og ikke kjørte. I utgangspunktet kjører den ikke fordi det er en Windows-operativsted. Men når du da kjører en ekte Linux-kjerne... På Mac så kjørte den heller ikke. Det er en del som har svart at den kjørte der. Til tross for at det er en del likheter, Adolf kjører ikke fordi den prøver å snakke med lingvistjernen, og så treffer den MacOS. Og da fungerer det ikke. Så det er bare den her, som de aller fleste svarte, som er riktig. Hallo...! Her har de fleste fått med seg hva som skjedde. På eldre Java-versjoner så kjørte ikke den helodo-plass. Men den kjørte bare her, som 90 % har sagt, på Linux-sekundtur. På ARM, fordi den hadde en nyere Java-versjon. Python... Ja, det vi har sett, så kjørte vel Python egentlig overalt. I hvert fall når vi ikke tok med det med...", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0009", "start": 757.72, "end": 855.34, "token_count": 291, "text": "På eldre Java-versjoner så kjørte ikke den helodo-plass. Men den kjørte bare her, som 90 % har sagt, på Linux-sekundtur. På ARM, fordi den hadde en nyere Java-versjon. Python... Ja, det vi har sett, så kjørte vel Python egentlig overalt. I hvert fall når vi ikke tok med det med... Når vi hadde med parenteser, som på en måte var plattformuavhengig... Da... Det er jo Python-versjoner, da, men Python kjørte overalt. Og var veldig plattformuavhengig. Det samme kan man vel egentlig si at LOD-bæsj gjorde. Og på Mac... Og det kjørte nesten selvfølgelig på disse Linux-punktene. Her igjen så er det både ja og nei. På en standard Windows-server, så kjører du ikke et bæsjer. Men hvis du installerer Linux subsystem... Så kjører... Så installerer du også bæsj, og da kan du få det... Men det... ja, det er på en måte litt... Litt juks for å installere en ny plattform. Eller juks... Man må ta med det i beregningen.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0010", "start": 827.44, "end": 1019.1, "token_count": 299, "text": "Men hvis du installerer Linux subsystem... Så kjører... Så installerer du også bæsj, og da kan du få det... Men det... ja, det er på en måte litt... Litt juks for å installere en ny plattform. Eller juks... Man må ta med det i beregningen. Men default vil verken et kjeldeskreft eller adotat kjøre på Windows. Skal vi se... Det er spørsmål... Spørsmål 1, så skal vi begynne å se på... Tror... Eller et lite... Et lite blikk. Det var... Vi så kanskje på det, ja. Skal vi se... Men hva kan vi gjøre? Bare for å gjøre det eksplisitt, så kan vi bare søy raskt på... her. Her er det armfrektor. Så det kan være interessant å se på... Men med den aksjonen minus stor S, så er det... sånn. Da får jeg en sum.s som inneholder... Vi ser at dette er ganske forskjellig fra de X86-institusjonene vi er vant til. Men noen av de heter de samme, sånn som AD. Men her er det AD med tre argumenter og... ja... Elderøster... Jeg kjenner ikke de institusjonene.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0011", "start": 967.0, "end": 1097.94, "token_count": 284, "text": "Da får jeg en sum.s som inneholder... Vi ser at dette er ganske forskjellig fra de X86-institusjonene vi er vant til. Men noen av de heter de samme, sånn som AD. Men her er det AD med tre argumenter og... ja... Elderøster... Jeg kjenner ikke de institusjonene. Men prinsippene er de samme. Her har vi en compere, f.eks. Og vi har løkker som hopper rundt. Hvis man studerte disse institusjonene, så vil du se at dette er det summeprogrammet som legger sammen tall fra 1 pluss 2 pluss 3 pluss 4. I prinsippet så fungerer maskinkoden på samme måte. Men det er andre institusjoner. Så de vil se helt forskjellige ut. Og disse institusjonene her... Hvis man kopierer dem over til en X86-maskin, så fungerer det opplagt ikke i det hele tatt. Fordi disse institusjonene er totalt uforståelige for en X86-maskin. Ok. Da skal vi opp til tråder. Tråder er en måte å findele prosesseringen av en prosess på.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0012", "start": 1060.62, "end": 1168.8, "token_count": 283, "text": "en X86-maskin, så fungerer det opplagt ikke i det hele tatt. Fordi disse institusjonene er totalt uforståelige for en X86-maskin. Ok. Da skal vi opp til tråder. Tråder er en måte å findele prosesseringen av en prosess på. Tidligere har vi sett på prosesser som bare har én tråd. Alle prosesser har en tråd, og tråden er på en måte den... Veien gjennom et program. Det er den veien som følges når man utfører et program. Jeg har en... Jeg har en litt senere sløyd her som... ... som viser disse trådene. Det er sånn man tenker seg en tråd. At det er veien som... Man snor seg gjennom når man kjører kode. Her er det en sånn tradisjonell singeltradisjonsprosess. Når vi er oppe i data her, så kanskje vi har en kommando som lagrer noe til data. Og så gjør den noen instruksjoner. Og så hopper den frem og tilbake. Den følger da en tråd gjennom kode og data.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0013", "start": 1143.24, "end": 1234.46, "token_count": 294, "text": "Her er det en sånn tradisjonell singeltradisjonsprosess. Når vi er oppe i data her, så kanskje vi har en kommando som lagrer noe til data. Og så gjør den noen instruksjoner. Og så hopper den frem og tilbake. Den følger da en tråd gjennom kode og data. For én prosess vil dette bare være én tråd som følges. Hele tiden vet man nøyaktig hvilken institusjon prosessen utfører. Det er denne rekken av institusjoner som vi kaller en tråd. Så kommer den nye når vi snakker om begrepet tråder, og det er at man innenfor den samme prosessen har flere tråder.  Man utfører den samme koden i parallell. Samtidig så kjøres denne koden her. Den har altså noen fellesdata, men den har også noen data som er spesielle for hver tråd. PCB, f.eks. Det er registerverdier for trådene. De er forskjellige. Så man har da... Når man har flere tråder i... Inni en prosess har man flere utførelser av det samme programmet.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0014", "start": 1210.34, "end": 1309.92, "token_count": 290, "text": "som er spesielle for hver tråd. PCB, f.eks. Det er registerverdier for trådene. De er forskjellige. Så man har da... Når man har flere tråder i... Inni en prosess har man flere utførelser av det samme programmet. Og det er det jeg prøver å lage en analogi om. Jeg tror det var denne analogien som inspirerte meg til å lage vafler og forelese samtidig. Og det er et bilde av hva tråden er. Vi har en prosess som er at en kokk lager én porsjon middag i et kjøkken. Da er CPU-en selve kokken. Hjernen min, hvis jeg er kokken. Så har man masse ressurser, som et kjøkken med kniver og føll og matvarer. Og eksplisitt oppskriften. Som er den oppskriften på den porsjonen med middag som kokken skal lage. Tråden er den sammenhengende serien av hendelser som skjer når kokken lager en porsjon. Når jeg lagde vafler, så var det å følge oppskriften punkt for punkt.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0015", "start": 1291.88, "end": 1375.62, "token_count": 293, "text": "som kokken skal lage. Tråden er den sammenhengende serien av hendelser som skjer når kokken lager en porsjon. Når jeg lagde vafler, så var det å følge oppskriften punkt for punkt. Tråden var den veien jeg fulgte oppskriften. Jeg skulle sjekke om noe var nok pisket, og da er det avhengig av andre forhold hvor tråden hopper. Det kan være input fra brukere, det kan komme noen inn på kjøkkenet... Tråden kan endre seg. Og når den porsjonen med mat er ferdig, da er den prosessen avsluttet. Men man kan gjøre dette på forskjellige måter, spesielt hvis man... Hvis man ønsker å lage vafler eller... Lage en rett fortere... Ønsker du å lage to retter... Da er det to måter man kan gjøre det på. Enten kan man ha to uavhengige prosesser. Det er sånn vi har sett på prosesser helt til nå. Uten tråder. Da har vi to helt uavhengige prosesser som jobber hver for seg. Det tilsvarer i kokkeanalogien...", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0016", "start": 1357.14, "end": 1445.0, "token_count": 297, "text": "Da er det to måter man kan gjøre det på. Enten kan man ha to uavhengige prosesser. Det er sånn vi har sett på prosesser helt til nå. Uten tråder. Da har vi to helt uavhengige prosesser som jobber hver for seg. Det tilsvarer i kokkeanalogien... Vi har to kjøkken, men så har vi fortsatt bare én CPU. Vi gjør en multitasking ved at kokken løper fram og tilbake mellom de to kjøkkenene. Så lager den én porsjon i hvert kjøkken. Så har du en oppskrift i hvert kjøkken, og så følges den oppskriften. Det er sånn som vi har gjort med multitasking. Da har vi kanskje gitt 100 sekunder. Da kan de to rettene vi har laget, være to rene jobber. De gjør jo samme jobben, men Superhund løper langt tilbake mellom kjøkkenet og lager mat. Så kommer den nye, store måten å gjøre dette på, og det er med treds. Det koster litt mye å ha to hele kjøkken, og så skal denne kokken løpe fram og tilbake...", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0017", "start": 1412.8, "end": 1502.14, "token_count": 285, "text": "De gjør jo samme jobben, men Superhund løper langt tilbake mellom kjøkkenet og lager mat. Så kommer den nye, store måten å gjøre dette på, og det er med treds. Det koster litt mye å ha to hele kjøkken, og så skal denne kokken løpe fram og tilbake... Det er jo akkurat den samme koden som utføres. Hvorfor kan vi ikke reise oss da? To tråder... Og da forenkles dette med at vi har bare ett kjøkken, og så bytter kokken på å jobbe med de to porsjonene. Da kan kokken lage to porsjoner fra samme oppskrift. I mitt tilfelle med vafler kunne jeg hatt den samme vaffeloppskriften. Men så kunne jeg kanskje hatt to forskjellige boller. Og så kunne jeg hente egg fra det samme... Fra det samme eggbrettet, og melk som melkemann kommer... Det kunne jeg bruke på begge porsjonene. Men så kunne jeg da... Ha en del ting som har felles. F.eks. oppskriften vil være den samme.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0018", "start": 1481.48, "end": 1577.32, "token_count": 300, "text": "Og så kunne jeg hente egg fra det samme... Fra det samme eggbrettet, og melk som melkemann kommer... Det kunne jeg bruke på begge porsjonene. Men så kunne jeg da... Ha en del ting som har felles. F.eks. oppskriften vil være den samme. Da vil det være kjøpere for meg å hoppe fra den ene til den andre enn om jeg måtte gå ut av kjøkkenet, inn på et annet kjøkken, og så fortsette med en vaffeloppskrift på det kjøkkenet. En prosess er ganske tung å starte opp. Den har en masse ressurser. Da benytter man de ressursene bedre. I den tradisjonelle prosessen er det kun én kokk som jobber i et kjøkken av gangen. Da kan det være samme kokken som hopper fram og tilbake. Men vi har også sett på SMP at vi kan ha én kokk i hvert kjøkken. Men SMP, det er ikke tråder. Da har man i utgangspunktet to helt forskjellige prosesser, og så er det bare én CPU som jobber med hver sin prosess. Da er det fortsatt én tråd i hver prosess.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0019", "start": 1555.74, "end": 1656.3, "token_count": 282, "text": "Men SMP, det er ikke tråder. Da har man i utgangspunktet to helt forskjellige prosesser, og så er det bare én CPU som jobber med hver sin prosess. Da er det fortsatt én tråd i hver prosess. Men med to år så kan man da ha flere kokker inne i hvert kjøkken. Man kan ha flere tråder i hver prosess. Da kan man ha flere CPU-er som jobber innenfor den samme prosessen. Og kjører den samme koden. F.eks. kan gjøre regneoppgaver i paralleller. Vi hadde et eksempel hvor vi skulle regne summen fra 1 til 2000. Og så kunne en annen tråd som rev ut summen fra 1000 til 2000, gjøre dette til parallell. Og når de skreduleres som to uavhengige enheter, så da kunne faktisk den ene tråden kunne kjørt på SMPU, og den andre på NAH, og faktisk i parallell kjøre helt samtidig. Ja, så... Det var en intro om tråder. Det finnes noen forskjellige definisjoner av tråder.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0020", "start": 1630.08, "end": 1724.64, "token_count": 299, "text": "så da kunne faktisk den ene tråden kunne kjørt på SMPU, og den andre på NAH, og faktisk i parallell kjøre helt samtidig. Ja, så... Det var en intro om tråder. Det finnes noen forskjellige definisjoner av tråder. Den som jeg har brukt her, er på sammenheng i rekken av helser, institusjoner som utføres når et program kjøres. Og den neste er tråden som følges når et program utføres. Når det hopper fra institusjon til institusjon. Det er på en måte det vi har prøvd å lage et bilde av hele veien. Det er også brukt om tråder, men det er kanskje litt mer upresist fordi... Fordi en tråd ikke inneholder alle de begrepene som en prosess har. Så man kan ha flere tråder innenfor samme prosess. Noe som er veldig viktig, er at det er programmereren som vet hva som skal gjøres. Det så vi på tidligere... Hvis vi hadde en kopilert versjon av en regneprosess som summerer fra 1 til 2000, så er det umulig for operativsystemet å vite at...", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0021", "start": 1697.82, "end": 1788.38, "token_count": 294, "text": "Noe som er veldig viktig, er at det er programmereren som vet hva som skal gjøres. Det så vi på tidligere... Hvis vi hadde en kopilert versjon av en regneprosess som summerer fra 1 til 2000, så er det umulig for operativsystemet å vite at... ... her kan jeg gjøre så smart. Jeg kan la én CPU legge seg sammen fra 1000 til 2000, og så kan jeg la en annen CPU legge seg sammen Det er det umulig for operativsystemet å forstå. Operativsystemet ser bare enkeltinstitusjonene i programmet. Så det er helt opp til programmereren å gjøre den type vurderinger og tenke sånn at dette kan parallelliseres. Ok, her går jeg inn med to tråder. Så sånn som JA-tråder og Petreds trådbiblioteket det legger til rette for at programmereren Kan styre hele prosessen sånn at flere uavhengige tråder jobber samtidig med oppgavene som skal gjøres. Programmereren kan også fordele arbeidsoppgaver mellom troene. Men så overlater programmereren til operativsystemet å skredulere troene.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0022", "start": 1765.72, "end": 1854.52, "token_count": 293, "text": "Kan styre hele prosessen sånn at flere uavhengige tråder jobber samtidig med oppgavene som skal gjøres. Programmereren kan også fordele arbeidsoppgaver mellom troene. Men så overlater programmereren til operativsystemet å skredulere troene. Standard er at trådene skreduleres uavhengig av hverandre. Dette er det første bildet vi begynte med med en singeltreddert prosess, som er sånn vi har sett det til nå. Én tråd følges, og hvis vi bare har én CPU hver, så vil en CPU-en følge denne tråden. Med multitreddert prosess så ser vi at vi har tre samtidige trådere. Hvis man har et system med tre CPU-er eller flere, så vil typisk operativstema skruddelere dette, sånn at disse trådene jobber på hver sin CPU og kan jobbe reelt samtidig. Men hvis denne prosessen kjører på én enkel CPU, som kjører TaskSet f.eks., tvinger den til å være på samme CPU, så vil operativstema skruddelere disse trådene helt uavhengig.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0023", "start": 1835.32, "end": 1926.02, "token_count": 291, "text": "sånn at disse trådene jobber på hver sin CPU og kan jobbe reelt samtidig. Men hvis denne prosessen kjører på én enkel CPU, som kjører TaskSet f.eks., tvinger den til å være på samme CPU, så vil operativstema skruddelere disse trådene helt uavhengig. Så dette ble helt tilsvarende som om man multitasker med flere prosesser. Men i tilfelle med tråder så sparer man en del ressurser, for man har felles data, felles kode, og så går det raskere å switche mellom tråder enn mellom prosesser. Og her er en oppsummering av fordelene med Teretz. Som vi har nevnt mange ganger, så er det ressursdeling. Man trenger ikke å duplisere koden mellom hver prosess. Hvis jeg kjører 100 rene jobber og starter med et dotter-r, så vil det være 100 kopier av denne koden og av dataene. Men hvis man har flere tråder innenfor samme prosess, så kan man kjøre på samme. Og lagre i de samme dataene. Respons er en viktig fordel.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0024", "start": 1897.44, "end": 1990.16, "token_count": 295, "text": "Hvis jeg kjører 100 rene jobber og starter med et dotter-r, så vil det være 100 kopier av denne koden og av dataene. Men hvis man har flere tråder innenfor samme prosess, så kan man kjøre på samme. Og lagre i de samme dataene. Respons er en viktig fordel. F.eks. hvis du har et program som står og regner og kverner på et eller annet, og så skal gi tilbakemelding, så... Så vil det være veldig kjedelig hvis du da må vente på at utregningen skal bli ferdig, Hvis man da har én tråd som regner... Den kunne til og med nices, altså ligge pent i bakgrunnen og jobbe. Og så kunne man ha en annen tråd som svarer på henvendelser. Og da får du veldig god respons for den applikasjonen. Effektivitet - jeg nevnte så vidt at det går mye raskere å switche mellom enn å switche mellom to prosesser. En hel context switch kan ta fem ganger så lang tid som å switche mellom tråder. Så tar det lengre tid å starte prosesser også.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0025", "start": 1964.6, "end": 2042.6, "token_count": 289, "text": "Og da får du veldig god respons for den applikasjonen. Effektivitet - jeg nevnte så vidt at det går mye raskere å switche mellom enn å switche mellom to prosesser. En hel context switch kan ta fem ganger så lang tid som å switche mellom tråder. Så tar det lengre tid å starte prosesser også. Rett og slett fordi det er tyngre med mer ressurser og mer som skal settes opp. Multiprosessor-gangenett er opplagt veldig niktig. Hver tråd kan tildeles en egen SIPU. Så hvis du har en selv om du har ført den opp til SIPU, så kan du da... Jobbe 48 ganger så raskt hvis prosessen din er mulig å paradenisere. Felles variabler... Det er ikke så lett å sette opp mellom prosesser. Det går an, men det kan være ganske tungvint. Altså felles deler av ramm som to forskjellige prosesser snakker til. Men med tre år så er det trivielt å sette opp. Java-tråder. Jeg tror ikke jeg rekker å se så veldig mye på det i praksis nå.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0026", "start": 2019.66, "end": 2107.48, "token_count": 282, "text": "Det går an, men det kan være ganske tungvint. Altså felles deler av ramm som to forskjellige prosesser snakker til. Men med tre år så er det trivielt å sette opp. Java-tråder. Jeg tror ikke jeg rekker å se så veldig mye på det i praksis nå. Men det er veldig rett fram, og der er et par av oppgavene denne uken som går ut på å komplere en Java-regnejobb og så kjøre den med flere tråder. Men det er noen sånne... Ja, når man lager Java-dretts, som vi skal se på nå, så må man arve klassen. Da får man noen tredje metoder. Den første er start... Som liksom setter av plass for alt på stack osv. Men den begynner ikke å kjøre tråden. Det er først når startmetoden nesten er ferdig, så kaller den rund. Som da setter i gang tråden til å jobbe med første institusjon. Så har vi også en metode som heter gi opp. Det er ikke så vanlig å gjøre. Stort sett overlater man til operativsystemet å skredulere.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0027", "start": 2082.92, "end": 2208.12, "token_count": 288, "text": "nesten er ferdig, så kaller den rund. Som da setter i gang tråden til å jobbe med første institusjon. Så har vi også en metode som heter gi opp. Det er ikke så vanlig å gjøre. Stort sett overlater man til operativsystemet å skredulere. Det er sjelden et poeng at tråden gir fra seg CPU-en på den måten. Prioritet kan man sette for tråder. Det skal vi se på senere i neste uke. Skrutinering... JVM måtte da skredulere tronene selv. Det var egentlig et ganske rart opplegg. Da måtte man bruke yield osv. for å gi fra seg CPU-en. Men da overlot man på en måte alt til brukeren. Så det som er standard, er native trends. Da vil Java-tronene skreduleres av å protestere. Da kan vi sette i gang ti... Så forventer du at operativsystemet skredulerer mellom dem. Hvis du har ti CPU-er, så får du en CPU hver. Hvis ikke, så multitasker operativsystemet. I Javar-tellemaskinen er det ikke helt spesifisert hvordan prioritet skal implementeres.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0028", "start": 2185.72, "end": 2288.2, "token_count": 292, "text": "Så forventer du at operativsystemet skredulerer mellom dem. Hvis du har ti CPU-er, så får du en CPU hver. Hvis ikke, så multitasker operativsystemet. I Javar-tellemaskinen er det ikke helt spesifisert hvordan prioritet skal implementeres. Her vil du se noen store forskjeller mellom Linux og Windows. Det er et AT-eksempel på at... Java er ikke helt plattformuordninger. Ja... På Linux-vemmene skal dere kunne installere JDK og kompilere Java-filler med Java C, kalt et Java, og så kjøre med Java Talk. Og jeg tror... Jeg har ikke sjekket hvilke nasjoner du får... Men det kan dere sjekke ut og isolere defoldt JTK. Helt til slutt... Det er én ting som er viktig å være klar over for variabler i Java-trådet. Hvis man definerer en tråd, en variabel som static... Static in count... Så vil den variabelen være felles for alle tråder. Så da har man en fellesvariabel. Hvis man ikke evakuerer den som static, bare som int id, så vil denne eksistere i hver tråd.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0029", "start": 2262.88, "end": 2406.4, "token_count": 295, "text": "Hvis man definerer en tråd, en variabel som static... Static in count... Så vil den variabelen være felles for alle tråder. Så da har man en fellesvariabel. Hvis man ikke evakuerer den som static, bare som int id, så vil denne eksistere i hver tråd. Det ser omtrent ut som dette her. Vi har nå én java-prosess som inneholder to tråder. ID vil være en egen variabel for hver tråd som du starter. Da kan man gi tråder av ID like én i den første tråden og like to i den andre tråden. Men den felles variabelen som ble deklarert som static, collective, den kan brukes til å telle opp antall tråder. Man kan ha en løkke og starte tråden, og så kommer colten igjen. Bære de trådene. Ok... Jeg tenker vi... Vi stopper der. Vi kan bare veldig kjapt vise... Hva oppgavene går ut på. Sånn. Oppgaven her går ut på å bare ta en kopi av dette programmet her. Et Java-program med et trådeksempel. Og så kompilere og kjøre dette programmet, og så...", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0030", "start": 2356.76, "end": 2489.94, "token_count": 293, "text": "Hva oppgavene går ut på. Sånn. Oppgaven her går ut på å bare ta en kopi av dette programmet her. Et Java-program med et trådeksempel. Og så kompilere og kjøre dette programmet, og så... Det er egentlig som at man ser hva som foregår der, er å kompilere og kjøre, og så se på koden hva som foregår. Hovedideen er at vi har en tellerkont som teller opp fra 0, 1, 2 og oppover. Den variabelen her vil da være lokal for hver tråd. Hver tråd vil ha sin egen id, men count vil være felles. Så når vi da... Her nede... Her er på en måte main hvor du starter to tråder. Så først lager en tråd S. Så starter den seg. Og så startes det. Når den starter, så utfører den utføreren. Så sier den tråd nummer ID is started. Det aller første som skjer når det starter, det er dette her. Da ser vi colt. Den felles havnen økes med én. Så først blir colt lik én. Så ID settes lik 1.", "source": "lecture"}
{"lecture_id": "os10time2", "chunk_id": "os10time2_0031", "start": 2467.74, "end": 2560.0, "token_count": 268, "text": "Så sier den tråd nummer ID is started. Det aller første som skjer når det starter, det er dette her. Da ser vi colt. Den felles havnen økes med én. Så først blir colt lik én. Så ID settes lik 1. I den første tråden lar ID være lik 1, og i neste tråd vil den være lik 2. På den måten har du startet av to tråder, og så gjør det et arbeid, og arbeidet består av å stå her og regne. Og da vil du kunne se hvordan de kjører på hver sin CPU. Men det kan vi se på mer neste gang. La oss se... Oi, jeg har gått langt inn. Dere trenger sikkert en pause, så... Da stopper vi der. Og så kan dere jobbe mer med lov og tro i oppgavene. Ok, Ine? Hallo? Der var det noen spørsmål i... Som du har fått i chatten, som vi burde ta opp? Nei, jeg har ikke tatt noen. Ikke noen private meldinger i chatten? Nei, ikke nå.", "source": "lecture"}
{"lecture_id": "linux12del12", "chunk_id": "linux12del12_0000", "start": 0.0, "end": 133.6, "token_count": 294, "text": "Det vi tenkte å gjøre nå, var å prøve å bruke dette til å lete etter filer som er fra et visst tidspunkt. Vi har gjort det på Linux også, men det er litt mer komplisert å manipulere på et tidspunkt der. Her. Så kan vi prøve... Ja, kanskje vi skal... Kanskje vi skal lete etter noen filer. Skal vi se. Vi kan gå inn og se hvor vi har filer. La oss si jeg... Jeg husker at en eller annen gang i 1930 så endret jeg noen filer på... La oss si jeg ikke visste hvor de filene var. Så jeg skal prøve å finne alle filer som er lagd den 19.03.2019. La oss si mellom morgen og kveld. Det jeg kan starte med da, er å lage en variabel... La oss si jeg kaller den morgen. Det skal være get-date... Hva var det jeg sa? 14.4.219. La oss si 8 om morgenen. Sånn. 14.4, har du ikke det? Nei, det har du ikke. Helt om 19. mars var det jeg skrev på rødbladet. Ok... 19. mars. Sånn.", "source": "lecture"}
{"lecture_id": "linux12del12", "chunk_id": "linux12del12_0001", "start": 95.4, "end": 233.72, "token_count": 296, "text": "14.4.219. La oss si 8 om morgenen. Sånn. 14.4, har du ikke det? Nei, det har du ikke. Helt om 19. mars var det jeg skrev på rødbladet. Ok... 19. mars. Sånn. Og så kan jeg definere kveld. La oss si jeg ønsker at kveld skal defineres sånn. Da gjelder det å finne filer som er laget... eller som er endret innenfor disse tidsrommene her. Men da trenger jeg jo... Ja, da trenger jeg igjen noen metoder eller properties. Som alltid så sender jeg da kveld til Get Mattered, metoden jeg ønsker å se på. Jo, men dette var datoen. Det er jo ikke datoen jeg ønsker å se på. Jeg ønsker å se på egenskapene til filer. Det er filer som jeg må se på. Og her ser vi på filer, så... Har vi en egenskap last right time? Den er det jeg ønsker å se på. For det er den som dukker opp her. Dette er last right time. Det står jo her også. OK. Så da kan jeg gjøre et forsøk. Jeg kan ta LS, og så kan jeg pipe til where object.", "source": "lecture"}
{"lecture_id": "linux12del12", "chunk_id": "linux12del12_0002", "start": 210.0, "end": 359.72, "token_count": 293, "text": "Har vi en egenskap last right time? Den er det jeg ønsker å se på. For det er den som dukker opp her. Dette er last right time. Det står jo her også. OK. Så da kan jeg gjøre et forsøk. Jeg kan ta LS, og så kan jeg pipe til where object. Og så kan jeg nå prøve å plukke ut objekter hvor... Sånn. Jeg ønsker deg en fin kveld. Ha det bra. Sprite time... Den skal være større enn om morgenen. Skal se om det funker i det hele tatt. Ja, det så ut som det kunne virke. Får nå ut alle objekter som har et tidspunkt som er større enn det tidspunktet, om morgenen. Men jeg ønsker jo å se på det som er varig i løpet av den dagen. Og da kan jeg ta... I tillegg så ønsker jeg da at... The last right time skal være... Mindre enn... Mindre enn om kvelden. Sånn som det. Da får jeg ut akkurat det jeg ønsker av alle filene som har den egenskapen. Og igjen så kunne jeg jo ta... Bruke litt... Jeg kan ta LS minus R. Og så kan jeg ta C kolon slash...", "source": "lecture"}
{"lecture_id": "linux12del12", "chunk_id": "linux12del12_0003", "start": 330.0, "end": 471.98, "token_count": 295, "text": "Mindre enn om kvelden. Sånn som det. Da får jeg ut akkurat det jeg ønsker av alle filene som har den egenskapen. Og igjen så kunne jeg jo ta... Bruke litt... Jeg kan ta LS minus R. Og så kan jeg ta C kolon slash... Nå finner jeg raskt alle filer under der, som er innenfor det tidsrommet. Men da ser vi igjen at det ble veldig mye... output. Noen feilmeldinger også. Så igjen kan vi rette på det ved å sende feilmeldinger til null. Konsekvenser. Last write er større enn om morgenen, mindre enn om kvelden. Men så kan jeg sende til format table, og så kan jeg si OK, kanskje jeg vil ha... Ha ut... Name og kanskje... Last write time, da. Da får jeg en oversiktlig liste over alle filer på systemet som ligger under her, som er endret i det tidsrommet. Da er det også lett å endre på... La oss si jeg ville begrense dette til mellom... Og la oss si... 13.45. Da definerer jeg kvelden sånn. Og så definerer jeg morgen som 13.45. Sånn.", "source": "lecture"}
{"lecture_id": "linux12del12", "chunk_id": "linux12del12_0004", "start": 428.76, "end": 508.96, "token_count": 198, "text": "som er endret i det tidsrommet. Da er det også lett å endre på... La oss si jeg ville begrense dette til mellom... Og la oss si... 13.45. Da definerer jeg kvelden sånn. Og så definerer jeg morgen som 13.45. Sånn. Og så gjør jeg det samme søket. Og vips, så får jeg ut akkurat de to filmene som ble endret her. Ja... Hvis jeg vet et eller annet som har foregått på maskinen, og jeg ønsker å finne det ut, så vil dette også lete gjennom alle systemfiler og alle filer som har endret seg akkurat innen dette tidsrommet. Så du ser igjen Sin PowerShell-commandlets returnerer objekter, så blir dette en veldig kraftig metode.", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0000", "start": 0.0, "end": 101.92, "token_count": 299, "text": "Ok. Da skal vi se på... Da skal vi se på et annet eksempel. Som på en måte er ligner, men denne gangen så er det... Så skal vi se på maskinkode. Og da skal vi se på faktisk... Helt enkeltinstitusjoner. Som likevel kan ha problemer med synkronisering. Så... Utgangspunktet her er... Dette programmet, Tredd.c, det er da... Dette er da en implementasjon av P-tredds i C. Og det er Cs motto å... Det er et bibliotek. Som gjør det mulig å kjøre tråder i et C-program. Vi skal ikke se så veldig mye på implementasjonen av det. Det er ikke kjempeviktig, men det er litt sånn som med Yawa. Her skaper vi en tråd. Tråd 1 og tråd 2. Og de skapes, og så sendes de med en metode, INK. Det er den metoden her oppe. Det som skjer, er at trådene kjøres. Så ser vi at de har en join her nede. Det betyr at de venter på hverandre, sånn at begge er ferdige før Maine avslutter og skriver ut svaret.", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0001", "start": 78.44, "end": 166.36, "token_count": 282, "text": "Og de skapes, og så sendes de med en metode, INK. Det er den metoden her oppe. Det som skjer, er at trådene kjøres. Så ser vi at de har en join her nede. Det betyr at de venter på hverandre, sånn at begge er ferdige før Maine avslutter og skriver ut svaret. Og det metoden gjør, det ligner jo litt på saldo, men det er at den veldig mange ganger, 100 millioner ganger, så kaller den på metoden én linje. Og jeg har kalt det én linje, den metoden, for å eksplisitt se Også for å kunne implementere den metoden direkte i Assembly. Og da må vi se hva én linje gjør. Og den... Én dot c, den er ganske enkel. Den bare... Den tar en ekstern int-svar. Og så øker den den med én. Enkelt og greit. Sånn som saldo. Her så ser vi... Denne variabelen her er deklarert globalt. Så når vi kompilerer den, kompilerer dette programmet sammen med 1.c,", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0002", "start": 145.22, "end": 252.36, "token_count": 297, "text": "Og så øker den den med én. Enkelt og greit. Sånn som saldo. Her så ser vi... Denne variabelen her er deklarert globalt. Så når vi kompilerer den, kompilerer dette programmet sammen med 1.c, så vil dette være en global variabel som da denne én-linje får tak i. Så alt i alt... Det som da bør skje, er at... Nå er det ikke én som trekker fra en som legger til, men begge disse her legger til. Sånn at vi har... 100 mill. ganger så kaller vi svart pluss-pluss for den ene tråden og 100 mill. for den andre. Så resultatet til slutt bør bli 200 mill. Så da kan vi prøve å kopilere Tredoce. Men... ja... Det kan være greit å se på en typisk feil. Hvis vi bare kompilerer sånn, så ser dere at den gir en feilmelding om p3d. Det er fordi man må ha på en opsjon minus p3d. Den linker inn et bibliotek, p3d-biblioteket. Så må jeg skrive det riktig. Sånn. Da er jeg klar til å kjøre.", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0003", "start": 221.32, "end": 356.4, "token_count": 294, "text": "en feilmelding om p3d. Det er fordi man må ha på en opsjon minus p3d. Den linker inn et bibliotek, p3d-biblioteket. Så må jeg skrive det riktig. Sånn. Da er jeg klar til å kjøre. Oi, se. Nå kjører Adatat. Så kjører den. Men vi ser... Akkurat som med javatrådene, så... Blir svaret forskjellig fra gang til gang. Her får jeg noe sånt som 114 millioner. Det jeg burde fått, var 200 millioner. Så igjen ser vi... Her er det et eller annet som går galt. Ja... Det vi ikke vet her, er... Kan dette være fordi den institusjonen... Altså én linje? Det kunne jo være at når den kompileres, at kompilatoren lager flere linjer når den kompileres. For å sjekke ut det, for å være sikker på at den ikke gjør det, så kan vi da lage... I stedet for én linje, så kan vi lage en liten minimal... Jeg kaller den minimal.s. En veldig liten assemblyfil. Et lite assemblyprogram som implementerer én linje.", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0004", "start": 330.0, "end": 428.24, "token_count": 300, "text": "For å sjekke ut det, for å være sikker på at den ikke gjør det, så kan vi da lage... I stedet for én linje, så kan vi lage en liten minimal... Jeg kaller den minimal.s. En veldig liten assemblyfil. Et lite assemblyprogram som implementerer én linje. Og den implementerer det som... Med én enkel institusjon. Så dette er nå bare... Her er det liksom svart på hvitt at dette er bare én enkel assemblyinstitusjon. Jeg skal ikke gå inn på det... RIP er et spesielt register som brukes til å overføre variabler. Så det som skjer når jeg kjører den her, er at den felles variabelen... Så den gjør i praksis akkurat det som 1.c gjør. Men 1.c ble komplert, så da var jeg ikke sikker på om dette faktisk ga én enkeltinstitusjon. Men dette her gir én enkeltinstitusjon. Så jeg kan da prøve å komplere på nytt, men i stedet for 1.c så tar jeg med minimal. Sånn som det. Og så prøver jeg igjen. Og vi ser at... Jo, fortsatt...", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0005", "start": 403.08, "end": 505.88, "token_count": 285, "text": "Men dette her gir én enkeltinstitusjon. Så jeg kan da prøve å komplere på nytt, men i stedet for 1.c så tar jeg med minimal. Sånn som det. Og så prøver jeg igjen. Og vi ser at... Jo, fortsatt... Så får jeg altså forskjellige svar. Og det... Det virker jo veldig rart, for her er det jo bare én institusjon. Så det kan ikke være noen context hitch som gjør at den ene... At det får den samme effekten. At man henter inn variabelen, og så kommer kontekst-session, og så lagres den. Men det virker rart fordi... Det virker rart fordi her er det bare én institusjon. Så vi har ikke noen sånn... Sånn som vi hadde Java. Og da er det jo én ting som er nærliggende å tenke deg. Hva om vi prøver med TaskSet her? Fordi at disse to programmene, eller dette programmet, de to trådene, de vil jo kunne skeduleres på hver sin CPU. Og da har vi plutselig ikke noe kontroll på det som skjer.", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0006", "start": 487.52, "end": 587.14, "token_count": 292, "text": "Hva om vi prøver med TaskSet her? Fordi at disse to programmene, eller dette programmet, de to trådene, de vil jo kunne skeduleres på hver sin CPU. Og da har vi plutselig ikke noe kontroll på det som skjer. Så et naturlig forsøk å gjøre her. Altså se hva... Hvis vi tvinger disse til å kjøre på samme SUPU, får vi da den samme effekten. Nei, det får vi ikke. Da ser vi... Hvis jeg tvinger dem til å kjøre på samme SUPU, så takket være at dette bare er én institusjon, så... Dette er bare én institusjon, så da kan vi ikke få noen kontekster som hopper fra prosess A til prosess B. For du har ikke den mellomlagringen. Så her klarer operativstyrken og CPU-en, og den ene CPU-en, å styre dette. Men det er klart... Vanligvis kjører man ikke med Taset, så med en gang man... Kjører man med to i to CPU-er, så får man problemer. Spørsmålet er hvorfor det har noe å si at de kjører på hver sin CPU", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0007", "start": 554.62, "end": 650.44, "token_count": 290, "text": "Så her klarer operativstyrken og CPU-en, og den ene CPU-en, å styre dette. Men det er klart... Vanligvis kjører man ikke med Taset, så med en gang man... Kjører man med to i to CPU-er, så får man problemer. Spørsmålet er hvorfor det har noe å si at de kjører på hver sin CPU når det bare er én linje med kodeminimal. Ja, det er fordi at vi har sett at det som egentlig skjer... Når man utfører en kodelinje, selv om det bare er svar pluss, pluss... I praksis så må den verdien hentes fra RAM og inn i et register. Selv om det gjøres som én operasjon, så har vi også sett at én operasjon er delt opp i mange sånne små minioperasjoner. Så ting skjer ikke sånn atomisk. Det skjer ikke som én operasjon. Operasjon hvor ingen andre ting utenom skjer. Da må vi huske på at dette er to forskjellige CPU-er. Hver av de CPU-ene henter da inn denne variabelen. Den svarvariabelen ligger i ett spesielt sted i RAM.", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0008", "start": 630.0, "end": 732.56, "token_count": 293, "text": "Operasjon hvor ingen andre ting utenom skjer. Da må vi huske på at dette er to forskjellige CPU-er. Hver av de CPU-ene henter da inn denne variabelen. Den svarvariabelen ligger i ett spesielt sted i RAM. Begge to CPU-ene er koblet inn med databussen. Og begge henter ut den verdien når de skal gjøre svar pluss, pluss. Da vil det avhenge av hvem som blir ferdig med svaret før den sender, og før den henter ut neste, og trafikken på databussen. Og når man gjør dette 200 millioner ganger, så ser vi at hele tiden så... Hele tiden så kan det gå galt. Men det man kan gjøre... Jeg har en lock minimal her. Der har jeg fortsatt den ene institusjonen. Men så har jeg en institusjon som heter LOCK. Og det er den første metoden vi skal se på som kan løse dette problemet. Og LOCK, den må jo da videreformidle til alle de andre CPU-ene at nå må ingen bruke databussen. Neste instruksjon... Fra og med lokk, som jeg sender, som jeg gjør nå... Den låser databussen, så ingen andre kan...", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0009", "start": 704.12, "end": 819.86, "token_count": 293, "text": "som kan løse dette problemet. Og LOCK, den må jo da videreformidle til alle de andre CPU-ene at nå må ingen bruke databussen. Neste instruksjon... Fra og med lokk, som jeg sender, som jeg gjør nå... Den låser databussen, så ingen andre kan... Etter at jeg har satt lokk, så kan ingen bruke databussen. Og dermed... Hvis jeg nå kompilerer den... Lokk minimale stødighet. Så kan vi se at selv om jeg nå kjører Adopt-out... Uten å låse... uten å være på samme SUPPU, så ser vi at svaret blir riktig hver gang. Men så så vi, la kanskje merke til også, at dette tar lengre tid. Og det er ikke så rart, for nå må databussen låses hele tiden, sånn at de to trådene som kjører på hver sin CPU, de må nå koordineres. De opererer samtidig, men de må vente på hverandre. Så vi ser... Det tar nå sånn som 4,3 sekunder. Hvis jeg...  Hvis jeg kjører med den opprinnelig, minimal. Old timer, så tar det... Ja, det går nesten fire ganger så fort.", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0010", "start": 793.84, "end": 901.12, "token_count": 298, "text": "De opererer samtidig, men de må vente på hverandre. Så vi ser... Det tar nå sånn som 4,3 sekunder. Hvis jeg...  Hvis jeg kjører med den opprinnelig, minimal. Old timer, så tar det... Ja, det går nesten fire ganger så fort. Og dette er noe som generelt gjelder for koordinering. Det vil opplagt ta lengre tid, for da må... Da låses bussen med gjennom mellomrom, og dermed tar det rett og slett lenger tid. Men opplagt ikke minsten er at da unngår man race condition. Man får serialisert de to trådene, og resultatene blir riktige. Ja... Vi skal avslutte det, men det er et spørsmål til... Hva er forskjellen på dette med plassering i ramm? Når man kjører to tråder på samme CPU og hver sin CPU... Ja, det er ikke noen direkte forskjell. Altså, én CPU er koblet med databussen til RAM. Men hvis, når disse to institusjonene kjører på samme CPU, altså med Task-sett, så... Når man utfører Svar pluss-pluss, eller altså når man utfører...", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0011", "start": 876.32, "end": 964.12, "token_count": 280, "text": "Altså, én CPU er koblet med databussen til RAM. Men hvis, når disse to institusjonene kjører på samme CPU, altså med Task-sett, så... Når man utfører Svar pluss-pluss, eller altså når man utfører... Når man utfører denne institusjonen her, så... Hvis vi tenker oss at vi har to tråder, og den ene tråden utfører denne, så vil hele den institusjonen fullføres før det gjør en context-witch. Henter ut fra ram, variabelen svar... La oss si den er 50. Så øker den med 1 til 51 og legger ut svar igjen. Og dette foregår på én atomisk operasjon. Det er bare én operasjon i CPU-en. Og CPU-en blir aldri avbrutt midt inni den operasjonen. Men når denne operasjonen er ferdig, da kan det skje en context switch, og da kan... Den andre tråden kom inn. Men på den måten så ser vi at når de jobber på samme CPU, så vil først tråd én gjøre ferdig den.", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0012", "start": 943.2, "end": 1023.88, "token_count": 297, "text": "Og CPU-en blir aldri avbrutt midt inni den operasjonen. Men når denne operasjonen er ferdig, da kan det skje en context switch, og da kan... Den andre tråden kom inn. Men på den måten så ser vi at når de jobber på samme CPU, så vil først tråd én gjøre ferdig den. Og så kommer tråd to inn, og så vil den gjøres sin addisjon. Og da går det helt fint. Men når de er på to forskjellige CPU-er, så henter bare hver CPU da ut... Med denne institusjonen sender den en beskjed ut på databusse. ... hent inn variabelen Svar. Og de er ikke koordinerte i det hele tatt. Så den trafikken går frem og tilbake totalt uten koordinasjon. Og da kan man risikere at Prosess 1, som er på CPU1, kan hente svar i ett tilfelle. Og så kommer Prosess 2, som er på CPU2. Den henter ut den samme. De kan sende meldingen helt likt, og da får begge svaret tilbake samtidig. Og begge vil da øke med én og sende svaret tilbake.", "source": "lecture"}
{"lecture_id": "os11del14", "chunk_id": "os11del14_0013", "start": 998.08, "end": 1047.0, "token_count": 185, "text": "Og da kan man risikere at Prosess 1, som er på CPU1, kan hente svar i ett tilfelle. Og så kommer Prosess 2, som er på CPU2. Den henter ut den samme. De kan sende meldingen helt likt, og da får begge svaret tilbake samtidig. Og begge vil da øke med én og sende svaret tilbake. Og da får vi akkurat det samme problemet tidligere. Hvis den opprinnelig var 50, så sender begge to tilbake svaret 51. Og 51 lagres to ganger, men ett tall har da blitt borte. Og dermed så ser vi at det totale antallet ofte blir mindre. Mindre enn det det skal.", "source": "lecture"}
{"lecture_id": "linux2del7", "chunk_id": "linux2del7_0000", "start": 0.0, "end": 96.76, "token_count": 288, "text": "Vi skal se litt på filnavn. Det meste er lov når det gjelder filnavn. Men det kan være litt vanskelig fra kommandolinjen å behandle filnavn som har mellomrom. F.eks. hvis jeg vil lage en fil som heter... ... min fil, i to ord, og prøver å gjøre det sånn, så vil du se at jeg lager én fil som heter fil, og en som heter min. Hvis man skal få til noe sånt, så må man gjøre sånn. Da får man en fil. Min fil. Men hvis jeg nå prøver å skrive R min fil, så... Skal vi se hva som skjer da? Jo, da slettes min og fil, og ikke min fil. Så man kan prøve R min fil... Og vi ser at denne måten er mulig. Så får man til å slette den. Hvis man gjør sånn, så finner den verken min eller fil. Men en backslash foran space, så får man slette den. OK. En annen ting som jeg er litt kjent til, er prosesser. Hvis man bruker PS, så lister man prosessene man har i dette lokale... PSA med noen opsjoner. AUX er en sånn opsjon...", "source": "lecture"}
{"lecture_id": "linux2del7", "chunk_id": "linux2del7_0001", "start": 67.42, "end": 190.28, "token_count": 294, "text": "Men en backslash foran space, så får man slette den. OK. En annen ting som jeg er litt kjent til, er prosesser. Hvis man bruker PS, så lister man prosessene man har i dette lokale... PSA med noen opsjoner. AUX er en sånn opsjon... Et sett av opsjoner som gjør at man lister alle prosesser på systemet. Og det ser vi er ganske mange. Vi kan telle de ved å bruke pipe til WCM-en selv. Det er 209 prosesser. Hvis man får for lange lissinger, kan man pipe det til. Det kan være enda bedre å pipe til en kommando som heter less, for da kan man altså bla oppover igjen. Og alle disse avsluttes med q. Vi hadde noen oppgaver som bruker topp. Det er en annen måte å vise alle prosessene på. Dynamisk. Ok... Litt om Linux-host. Det er ganske vanlig å kalle alle Linux-maskiner for host, eller vertsmaskiner, men en Linux-host har da typisk et host-navn. Det er en kommando som heter host-navn, som gir da host-navn på den maskinen du... Som jeg har sett med Studies SO, kan man logge seg på alle maskiner", "source": "lecture"}
{"lecture_id": "linux2del7", "chunk_id": "linux2del7_0002", "start": 161.68, "end": 257.2, "token_count": 281, "text": "Det er ganske vanlig å kalle alle Linux-maskiner for host, eller vertsmaskiner, men en Linux-host har da typisk et host-navn. Det er en kommando som heter host-navn, som gir da host-navn på den maskinen du... Som jeg har sett med Studies SO, kan man logge seg på alle maskiner hvis man kjenner HOS-navnet. F.eks. kan jeg logge meg på en house som heter Nexus, som er på Hioa. Da holder det ikke med bare navnet Nexus. Men jeg må også ha domenenavnet. Men når jeg har hele... Når jeg har navn og domenenavn, så kan jeg logge meg på den fra hvor som helst i verden. Og jeg kan også slå opp i DNS og se hvilken IP-adresse den har, med command and host. Da ser vi at denne maskinen har denne IP-adressen. Så hvis man først har IP-adressen, så kan man også logge seg på med SSO. Så direkte til en app-adresse. Da kommer man til den samme maskinen. Litt mer orientering og hvordan man orienterer seg. En nyttig kommando er 'Who am I?' Det høres litt rart ut.", "source": "lecture"}
{"lecture_id": "linux2del7", "chunk_id": "linux2del7_0003", "start": 235.96, "end": 323.84, "token_count": 289, "text": "Så hvis man først har IP-adressen, så kan man også logge seg på med SSO. Så direkte til en app-adresse. Da kommer man til den samme maskinen. Litt mer orientering og hvordan man orienterer seg. En nyttig kommando er 'Who am I?' Det høres litt rart ut. Vet man ikke hvem man er? Litt sånn schizofren kommando. Men f.eks. script kan være nyttig å bruke. Og også hvis du har gjort sudo av Route. Og da kan man også bli andre brukere. Så da kan det være nyttig å kunne... Who am I? Hostname har vi sett på. Uname er en annen nyttig kommando som gir operativsystemet. Som alltid er det masse opsjoner. Uname minus A gir operativsystemet, Linux, og litt mer hvilken kjerne det er, osv. når den ble bygd. SV, dette er... Gnu-linux. Ja... Who kan vi bruke? Den viser hvem som er logget på. Her ser vi en del studentkontor. Generelt så er det også nyttig å kunne bruke type. Typemann, f.eks., viser... Hvis jeg skriver kommando mann,", "source": "lecture"}
{"lecture_id": "linux2del7", "chunk_id": "linux2del7_0004", "start": 300.0, "end": 389.68, "token_count": 289, "text": "Gnu-linux. Ja... Who kan vi bruke? Den viser hvem som er logget på. Her ser vi en del studentkontor. Generelt så er det også nyttig å kunne bruke type. Typemann, f.eks., viser... Hvis jeg skriver kommando mann, hvilken kommando er det jeg bruker da? Hvilken kommando er det som egentlig utføres da? Og type-touch... Det betyr at når jeg bruker kommandoen touch, så er det egentlig dette programmet som ligger her, som er et binært eksekverbart program, som utføres. Og så kan jeg f.eks. ta touch co-mod. Nei... Type co-mod. Det viser hvor co-mod er. Så kan jeg prøve... Type PWD. Og da får jeg opp at PWD, Print Working Directory, det er et skjell built in. Så PWD er da en del av skjellet. Og det er ikke da et eksternt program som man kjører som ligger et eller annet sted. PWD, den funksjonaliteten, er bygd inn i selve skjellet. Altså, det er en type... Hvis den som bruker skjellet,", "source": "lecture"}
{"lecture_id": "linux2del7", "chunk_id": "linux2del7_0005", "start": 374.36, "end": 423.7, "token_count": 167, "text": "Og det er ikke da et eksternt program som man kjører som ligger et eller annet sted. PWD, den funksjonaliteten, er bygd inn i selve skjellet. Altså, det er en type... Hvis den som bruker skjellet, Så print ut hvor... Hvor i filsystemet brukeren står. Og så sett tidligere... History kan være nyttig å bruke. Men da kommer det en svært lang liste, så da kan man pipe den til More. Så får man alle tidligere kommandoer. Og som sagt, enda nyttigere med History er å bruke kontroll-r for å... Lete tilbake i historien.", "source": "lecture"}
{"lecture_id": "os3bdel2", "chunk_id": "os3bdel2_0000", "start": 0.0, "end": 93.4, "token_count": 295, "text": "Det er denne. Da har vi den latchen som har på en kontroller. Og da er spørsmålet hvis input d er lik 0 og kontroller input c er lik 1. Hva blir x og q? Ja, kontroller input 1, det skal bety at da skal verdien settes til den innkomne. Så det bør bli q lik 0. Men igjen, så kan vi se... Hvis det er null, og så er jeg like enig, hvis det er null, så kommer det en null inn her. Og da ser vi at X blir null. Men en null inn i en or-port, da kan man ikke uten videre si hva som kommer ut. Men vi kan se på... Det kommer en ener inn her, og så kommer det en null inn her. Da kommer det to ener inn i andporten, og da kommer det en ener inn i denne årporten. Og en ener i årporten. Da kommer det alltid en ener ut, og den blir til null. Så q blir også null. Så igjen er det veldig bra. 70 % av dere har svart x lik 0 q anlik 0. Så... Og det er da det riktige svaret. Men dette er ganske komplisert, så kjempebra. Godt med mye.", "source": "lecture"}
{"lecture_id": "os1del2", "chunk_id": "os1del2_0000", "start": 0.0, "end": 99.78, "token_count": 289, "text": "Jeg får et spørsmål om pensum. Om det er det som ligger på nettsiden? Ja, i utgangspunktet er det det som ligger på nettsiden. Men det er også en anbefalt lærebok som... Ja, jeg kan si litt om det etterpå. Men det er bare anbefalt. I utgangspunktet får dere alt dere trenger. Det får dere i to kompendier, jeg kan vise det med det samme. Her på siden er det noen... en liten meny. Herunder forelesninger så ser dere at jeg legger ut notater etter hver forelesning, men så ligger det også da her forelesningsnotater fra 2020 som ett PDF-dokument og Linux-forelesninger fra 2020 som ett PDF-dokument. Så hvis dere går inn på det, så vil dere se... Notatene fra i fjor. Og da vil du se at dette er etter hvert et kompendium på 160 sider. Så dette fungerer da i praksis som en lærebok. Det er litt... Jeg legger ofte til å trekke fra noe stoff, så det kan variere. Men totalt sett til våren så vil ikke disse dokumentene være veldig, veldig forskjellige.", "source": "lecture"}
{"lecture_id": "os1del2", "chunk_id": "os1del2_0001", "start": 70.2, "end": 112.84, "token_count": 119, "text": "Og da vil du se at dette er etter hvert et kompendium på 160 sider. Så dette fungerer da i praksis som en lærebok. Det er litt... Jeg legger ofte til å trekke fra noe stoff, så det kan variere. Men totalt sett til våren så vil ikke disse dokumentene være veldig, veldig forskjellige. Så disse ligger ute. I tillegg så er det en lærebok som vi kan ta... Jeg kan si noen år om senere.", "source": "lecture"}
{"lecture_id": "os7del4", "chunk_id": "os7del4_0000", "start": 0.0, "end": 87.06, "token_count": 259, "text": "Et annet spørsmål er om én reinhet er én alu. Ja, én reinenhet er én alu. Spesielt når man regner heltallsoperasjoner, så er det en alu. Men der kan det være én alu per core, eller regneenhet. Men det vi kanskje kommer inn på, så... Hvis man har flytall, så har man... Gjerne en egen regneenhet som regner flytall. Og da hender det forskjell på om man har én alu og én flytallsregneenhet. Det hender derfor at man inni en CPU har to aluer og én flytallsregneenhet. Det varierer. Men når jeg snakker om det, når jeg sier én CPU eller én core, så tenker jeg på én ALU som gjør enkeltoperasjonen. Vi kommer tilbake til det senere i dag når vi skal se på multitredding. For da deler man på å bruke den samme ALU-en innenfor en core. Men mer om det senere.", "source": "lecture"}
{"lecture_id": "linux12del78", "chunk_id": "linux12del78_0000", "start": 0.0, "end": 133.0, "token_count": 300, "text": "Generelt så kan man ta prosesser sånn som det her, og så kan man teipe til... Så kan man pipe til Forage. Og da er det... Egentlig så er det Forage of Objects. Som Forage er et... Så har man en løkke inni forage-objektstatementet. Og inni her vil man da løpe gjennom hvert av de objektene man fikk tilsendt. Da kan man f.eks. gjøre en test som if... Og når man løper gjennom forage-løkken, så har man en slags default variable, som er dollar underscore. Dollar underscore, den er da det objektet som nå testes ut i løkken. Så kan man da si hvis dollar underscorer sitt navn, hvis det er lik... Bruker samme eksempel som sist. Nopad. Nopad. Sånn. Hva om... Og da igjen dollar underscore sitt ikke navn, men id. Ja. Nå har vi vel ikke noen natta ennå for å kjøre, så jeg må starte den natta først. Hvis jeg da kjører målnineren... Så ser vi igjen. Så får vi... Så får vi det som kommer til å skje hvis vi ikke har med WATF,", "source": "lecture"}
{"lecture_id": "linux12del78", "chunk_id": "linux12del78_0001", "start": 107.36, "end": 220.28, "token_count": 294, "text": "Ja. Nå har vi vel ikke noen natta ennå for å kjøre, så jeg må starte den natta først. Hvis jeg da kjører målnineren... Så ser vi igjen. Så får vi... Så får vi det som kommer til å skje hvis vi ikke har med WATF, nemlig at Nopad blir drept. Så dette er en sånn veldig kraftig wallliner-metode. At man sender til Forage, og så inne i denne kodeblokken,  Så kan man da skrive kode som behandler ett objekt en gang. Det går an å gjøre dette på en litt annen måte, som er enda mer pipelining. Vi kan ta... Vi kan ta den biten her og kopiere. Så kan vi... Istedenfor å sende til Forridge, så kan vi sende det til en annen konstruksjon som jeg ikke har sett på før, som heter Ware Object. Og det er en konstruksjon som da plukker ut objekter av en spesiell type. Og så piper videre til Forridge. Så vi kan... Vi ønsker alle objekter som har et navn lik Knallpad, de ønsker vi å ta tak i pipen og sende videre.", "source": "lecture"}
{"lecture_id": "linux12del78", "chunk_id": "linux12del78_0002", "start": 187.76, "end": 289.36, "token_count": 277, "text": "så kan vi sende det til en annen konstruksjon som jeg ikke har sett på før, som heter Ware Object. Og det er en konstruksjon som da plukker ut objekter av en spesiell type. Og så piper videre til Forridge. Så vi kan... Vi ønsker alle objekter som har et navn lik Knallpad, de ønsker vi å ta tak i pipen og sende videre. Da ser vi at vi får enda mer sånn én av én operasjon langs pipeninen. Så her sender vi prosesser, piper det til Vere Object. Dette ble en litt tilsvarende metode som sist. I forrige forsøk hadde vi en løkke inni forhåndsobjektet. Dette blir da enda mer pipelining. Og igjen så skjer det ikke noe før vi har en opput. At det ene objektet som heter Noped, det kommer nå inn i pipeline. Da følger det sånn. Først å sende PS ut alle prosessobjekter. BareObject har en klausul her. Den sjekker... Jeg vil ha alle objekter hvor navnet er Noped.", "source": "lecture"}
{"lecture_id": "linux12del78", "chunk_id": "linux12del78_0003", "start": 267.6, "end": 308.06, "token_count": 142, "text": "At det ene objektet som heter Noped, det kommer nå inn i pipeline. Da følger det sånn. Først å sende PS ut alle prosessobjekter. BareObject har en klausul her. Den sjekker... Jeg vil ha alle objekter hvor navnet er Noped. Så sendes det videre til 4H-objekt, og 4H-objektene tar alle objektene. Og for hvert av objektene, så... Det dreper den prosessen. Så dette er en sånn veldig ryddig måte å lage en fair plan på.", "source": "lecture"}
{"lecture_id": "linux1del8", "chunk_id": "linux1del8_0000", "start": 0.0, "end": 105.28, "token_count": 297, "text": "Filbehandling er spesielt viktig i Linux, fordi så å si alt i Linux av konfigurasjon og andre data er lagret som filer, og veldig mye av det er lagret som tekstfiler. Så det å kunne manipulere på tekstfiler, det er veldig viktig i Linus. Vi har allerede sett på noen kommandoer, sånn som ls, som listede filer. Se her. Den lager en lang listing. Jeg har fått en fil som heter ScriptShell med en liten trille til slutt. Det er fordi jeg brukte Jed. Det er en liten forskjell på de to filene. Og Jed sparer alltid en sikkerhetskopi med en annen trille når man gjør endringer. Hvis man bruker nano, så lages det ikke en sånn sikkerhetskopi, hvis man blir irritert over alle de tidligere filmene. Man kan også legge på andre opsjoner på LS. F.eks. kan man legge på LS minus A. Og da er det to mapper til som vises. Det er prikk. Og de mappene er mappene man står i, og i tillegg er det mappen et hakk opp. Hvis jeg ønsker å gi flere opsjoner samtidig,", "source": "lecture"}
{"lecture_id": "linux1del8", "chunk_id": "linux1del8_0001", "start": 76.12, "end": 169.44, "token_count": 300, "text": "F.eks. kan man legge på LS minus A. Og da er det to mapper til som vises. Det er prikk. Og de mappene er mappene man står i, og i tillegg er det mappen et hakk opp. Hvis jeg ønsker å gi flere opsjoner samtidig, så kan jeg legge på begge to, så jeg kan skrive L-L og A samtidig. Og da ser vi tydeligere hva prikk og prikk-prikk er, eller at de er mapper.  Det er at prikk er en mappe. Den starter med det her. Og det er altså den mappen man står i. Så rettighetene for denne mappen, det er rettighetene for mappen jeg står i nå. Mens den mappen som vises under, det er mappen ett hakk opp. Som i dette tilfellet har den samme rettigheten. Og i tillegg har vi de to versjonene av Skript av Sjel som er listet. Man kan også liste hvilken som helst mappe. F.eks. kan jeg prøve å liste.slash rtc, som er en rekke mapper. Da har jeg listet alle mappene i slash rtc. Ved å taste kontrollet L, så får jeg clear screen.", "source": "lecture"}
{"lecture_id": "linux1del8", "chunk_id": "linux1del8_0002", "start": 147.08, "end": 246.32, "token_count": 298, "text": "Og i tillegg har vi de to versjonene av Skript av Sjel som er listet. Man kan også liste hvilken som helst mappe. F.eks. kan jeg prøve å liste.slash rtc, som er en rekke mapper. Da har jeg listet alle mappene i slash rtc. Ved å taste kontrollet L, så får jeg clear screen. Da får jeg bort alle kommandoer og åpnet fra terminalen. Jeg kan lage mapper og filer. Og da kan jeg f.eks. lage en mappe som heter Dir. Og da bruker jeg MKDir. Eller jeg kan gjøre det eksplisitt. Jeg kan kalle det en ny mappe. Da får jeg en ny mappe som heter Ny mappe. Så er det også en kommando som heter Touch, som jeg kan bruke Hvis jeg gjør det, så får jeg nå en tom fil som heter Tom fil. Det ligger ingenting i den, og så har jeg en mappe som heter Ny mappe. Hvis jeg vil se på og inneholde filer, så kan jeg bruke command-cat. Da får jeg ut innholdet av den filen. Så må jeg kunne endre på filer. Jeg har sett tidligere... At vi har brukt Nano. Jed kan også brukes. Endre her...", "source": "lecture"}
{"lecture_id": "linux1del8", "chunk_id": "linux1del8_0003", "start": 216.56, "end": 307.6, "token_count": 289, "text": "Det ligger ingenting i den, og så har jeg en mappe som heter Ny mappe. Hvis jeg vil se på og inneholde filer, så kan jeg bruke command-cat. Da får jeg ut innholdet av den filen. Så må jeg kunne endre på filer. Jeg har sett tidligere... At vi har brukt Nano. Jed kan også brukes. Endre her... Lagre med kontroll S og gå ut med kontroll X, kontroll C. Det fins også andre editorier. Emax er en stor og omfattende editori hvor du kan gjøre veldig mye. Jed er på en måte en billig utgave, eller en light white utgave av Amax. Så kommandoen som gjelder i Jed, gjelder også Amax. Og hvis du skal gå ut av Amax, så bruker jeg kontroll X, kontroll C. Det enkleste i starten kan kanskje være å bruke Nano, som vi så på tidligere, fordi her kan man se nederst hvilke shortcut man kan bruke. Man har ikke pek og klikk her. I utgangspunktet så skal man kunne gå inn på en server og editere filer. Og dermed skal man jo ikke klikke for å save.", "source": "lecture"}
{"lecture_id": "linux1del8", "chunk_id": "linux1del8_0004", "start": 282.48, "end": 360.6, "token_count": 291, "text": "Det enkleste i starten kan kanskje være å bruke Nano, som vi så på tidligere, fordi her kan man se nederst hvilke shortcut man kan bruke. Man har ikke pek og klikk her. I utgangspunktet så skal man kunne gå inn på en server og editere filer. Og dermed skal man jo ikke klikke for å save. Så på en eller annen måte må man da vite hvilke kommandoer man kan bruke for å gå ut. Og det er spesielt egentlig på Nano, for de står nederst. Kontroll-X, det er da exit. Så kan det være nyttig å... Kopierer. Og da er kommandoen for å kopiere CP... Hvis jeg nå ønsker f.eks. å kopiere det skriptet, script.selv... Det jeg gjorde som gjorde at jeg raskt fikk ut skript, det var å trykke på tab. Så jeg skrev cp.sc, og så trykker jeg tab. Så får jeg script.selv, og så vil jeg kanskje la det bli starten på et nytt skript. Sånn. Da kopierer jeg filen... Hvis jeg nå taster LS-minuscell, så ser vi", "source": "lecture"}
{"lecture_id": "linux1del8", "chunk_id": "linux1del8_0005", "start": 337.6, "end": 423.88, "token_count": 300, "text": "det var å trykke på tab. Så jeg skrev cp.sc, og så trykker jeg tab. Så får jeg script.selv, og så vil jeg kanskje la det bli starten på et nytt skript. Sånn. Da kopierer jeg filen... Hvis jeg nå taster LS-minuscell, så ser vi at da har jeg her oppe fått en ny fil som heter nyttskript.shell. Som med alle kommandoer, så kan man legge på opsjoner. Og det jeg gjorde nå, var at jeg bladde meg tilbake. Det kan man gjøre med pil opp. Nå taster jeg pil opp. Hvis jeg taster pilen ned, så kommer jeg frem igjen. Så la oss si jeg ønsker å gjøre denne kommandoen her om igjen, men med minus... Da vil jeg bruke opsjonen minus i. Minus i er så fint og aktiv, og hvis jeg prøver å skrive over en fil som finnes fra før, så blir jeg da spurt om det. Så da kan jeg få sjansen til å svare nei her. Det ønsker jeg ikke. Da blir den ikke kopiert. Allmennlig nyttet kommando er å flytte. Så la oss si jeg ønsker å få et nytt navn på nytt script selv.", "source": "lecture"}
{"lecture_id": "linux1del8", "chunk_id": "linux1del8_0006", "start": 402.64, "end": 495.96, "token_count": 296, "text": "over en fil som finnes fra før, så blir jeg da spurt om det. Så da kan jeg få sjansen til å svare nei her. Det ønsker jeg ikke. Da blir den ikke kopiert. Allmennlig nyttet kommando er å flytte. Så la oss si jeg ønsker å få et nytt navn på nytt script selv. Jeg likte ikke det navnet, så da kan jeg bruke kommandoen mv for move. Og så kan jeg flytte nytt script... Det kan kanskje hete moved. Det denne kommandoen gjør, er at den tar nytt skript... Og flytter til move.chell. Og det vil i praksis si her at man renamer, altså at man får et nytt navn på nytt skript. Så hvis jeg nå gjør LSM-en selv, så ser vi at jeg har moved.chell. Jeg har fått nytt navn på dette nytt skript. Fra en mappe til en annen, så er det en annen måte å bruke MV på. Er å ta Moved, og så ønsker jeg å flytte den ned til ny mappe. Da tar jeg MV Moved til ny mappe. Return. Og hvis jeg rister filen nå, så ser vi at Moved, den er borte.", "source": "lecture"}
{"lecture_id": "linux1del8", "chunk_id": "linux1del8_0007", "start": 474.0, "end": 569.2, "token_count": 295, "text": "Fra en mappe til en annen, så er det en annen måte å bruke MV på. Er å ta Moved, og så ønsker jeg å flytte den ned til ny mappe. Da tar jeg MV Moved til ny mappe. Return. Og hvis jeg rister filen nå, så ser vi at Moved, den er borte. Hvis jeg går ned i ny mappe, så ser vi... Der ligger denne filen. På den måten vil det være sånn at hvis jeg bruker move inne i samme mappe, så vil den endre navn. Men hvis jeg flytter noe til en annen mappe, så... Så flyttes filen fra mappen jeg er i, til mappen jeg skal til. På den måten kan jeg også flytte hele mapper. La oss si jeg lager en mappe som heter Dirr. Så har jeg denne... dette filteret. Nå har jeg en mappe som heter DIR, som er tom. Og så har jeg en ny mappe her. Da kan jeg flytte hele min nymappe. Og sånn. Jeg flytter ny mappe til DIR. Hvis jeg lisser nå, så ser vi nymappen der borte. Og den har blitt lagt ned i DIR. Og det er noen mapper som er spesielle.", "source": "lecture"}
{"lecture_id": "linux1del8", "chunk_id": "linux1del8_0008", "start": 545.16, "end": 635.92, "token_count": 296, "text": "Og så har jeg en ny mappe her. Da kan jeg flytte hele min nymappe. Og sånn. Jeg flytter ny mappe til DIR. Hvis jeg lisser nå, så ser vi nymappen der borte. Og den har blitt lagt ned i DIR. Og det er noen mapper som er spesielle. Vi har vel kanskje sett på de fleste. Hvis man lister med LA, så ser man for det første at det er mappen du står i. Det kan man bruke for å kopiere noe til mappen jeg står i. Skal vi se... La oss si hvis jeg lister nå det som er i mappen over. Så sier jeg at der ligger script.shell. Mens her ligger ingen til. Ok, nå ønsker jeg å kopiere script.shell, som ligger i mappen over. Da gjør jeg det sånn. cp... script.shell... og så hit. Prikk betyr da denne mappen som jeg står i nå. Og dermed, utover den kommandoen, har jeg fått en kopi av script.shell i mappen jeg står i. Mens i mappen over så ligger fortsatt originalen. Så kopien har da blitt flyttet hit. Og det er et eksempel på bruk av mappen.", "source": "lecture"}
{"lecture_id": "linux1del8", "chunk_id": "linux1del8_0009", "start": 611.32, "end": 703.2, "token_count": 287, "text": "Prikk betyr da denne mappen som jeg står i nå. Og dermed, utover den kommandoen, har jeg fått en kopi av script.shell i mappen jeg står i. Mens i mappen over så ligger fortsatt originalen. Så kopien har da blitt flyttet hit. Og det er et eksempel på bruk av mappen. Vi ser vi har brukt prikk-prikk tidligere. Hvis jeg sier change directly til prikk-prikk, så går jeg ett hakk opp. Et annet tegn på en mappe er Tilde. Skriver Ekko Tilde, så vil de se at Tilde, det er faktisk hjemmemappen. Så det kan man bruke til å flytte seg til hjemmemappen. CD Tilde. Da kommer jeg øverst i hjemmemappen. Så kan jeg også... La oss si jeg kan gå ned mappe igjen. Så kan jeg også bruke det f.eks. ved å si... At jeg ønsker å kopiere det som ligger øverst i hjemmemappen. Der er det en fil på hei.tk. Den ønsker jeg å kopiere hit. Tilde betyr da hjemmemappen, og der ligger hei.tk, som vi kan se her oppe.", "source": "lecture"}
{"lecture_id": "linux1del8", "chunk_id": "linux1del8_0010", "start": 680.08, "end": 719.16, "token_count": 138, "text": "Så kan jeg også bruke det f.eks. ved å si... At jeg ønsker å kopiere det som ligger øverst i hjemmemappen. Der er det en fil på hei.tk. Den ønsker jeg å kopiere hit. Tilde betyr da hjemmemappen, og der ligger hei.tk, som vi kan se her oppe. Prikk. Det er mappen jeg står i, og dermed så gjør den kommandoen at jeg kopierer hei.tk øverst i hjemmemappen ned hit jeg står. Så nå har jeg fått en kopi av Heidot-tekstet her.", "source": "lecture"}
{"lecture_id": "linux11del15", "chunk_id": "linux11del15_0000", "start": 0.0, "end": 101.08, "token_count": 299, "text": "I Linux har vi sett at f.eks. hvis vi skal liste, telle opp antall prosesser, så gjør vi PSIOX. Så sender vi det til WS-minus selv. Bare som et eksempel fra PowerShep, så går det an å installere SSO. Jeg tror det er en oppgave denne uken som går ut på å installere SSO. Så jeg kan prøve å logge inn på min desktop. Der ser vi det går fint. Og da har jeg et Linux-skjell inni PowerShell. Så på den måten så kan man, hvis man installerer åpen SSO, så kan man også logge inn på. Og så starte opp et powercell der. På den måten kan man akkurat som med Linux-maskiner, så kan man gå rundt. Det jeg skulle vise, var at for å telle opp alle prosesser på en maskin, så har vi gjort noe sånt som dette her. PCoX. Så her ser vi... Her står det 255 prosesser og kjører. Når jeg skal gjøre det samme i PS, så er det enda enklere. Så kan jeg bare ta PS-innlegg, og så får jeg ut alle prosessene som kjører. Da ser jeg at dette er 53 prosesser.", "source": "lecture"}
{"lecture_id": "linux7del8", "chunk_id": "linux7del8_0000", "start": 0.0, "end": 119.98, "token_count": 229, "text": "Disse slidene er bygd opp sånn at her står det... Your turn, hello world. Men da fant jeg ut i går at det er litt problem hvis man trykker på dem, så... Jo, så kommer man ikke... Det er en feil med... Den går til Exercise1, og den... Da får du en feilmelding om at du ikke finner siden. Men man trenger ikke å gå gjennom det på den måten. Man kan også gå... Jeg har en link i oppgavesettet. Man kan gå inn der. Jeg kan jo prøve å gå dit den måten her. Jeg deler et annet vindu, sånn at de... Sånn, ja. Hvis jeg trykker her, så ser du det kommer opp en 0,4. Hvis jeg da tasser inn null foran eneren der... Tydeligvis er ikke dette oppdatert. Da kommer jeg til den riktige. Ellers kan dere følge linken som står i oppgaven, som sagt.", "source": "lecture"}
{"lecture_id": "os4del4", "chunk_id": "os4del4_0000", "start": 0.0, "end": 89.98, "token_count": 299, "text": "Det er et spørsmål om... Hvis man skulle lagt inn fire, er ikke det mulig? Nei, det er et godt spørsmål, fordi at vi har sett på... Vi kan gå tilbake, så kan vi se på instruksjonene til denne maskinen. Det hadde vi om på slutten forrige gang. Men her i avsnitt 3 til Løkker og bransjekontroll så vi på institusjonene, hvordan de var definert. Og det jeg tenker... Den som spør, refererer til om det ikke er mulig å legge inn fire. Og nei, det er faktisk ikke mulig, for her er det en institusjon som heter MoveE. Den kan brukes til å legge inn tall. Så ser vi at den har to operander. Den første operanden er hvilket register skal man legge inn tallet? Den andre operanden er selve tallet. Og der er det bare satt av to bit til dette tallet. Og dermed så er det største tallet man kan legge inn, tre. Så for å legge inn fire til register, hva kan man gjøre da? Og det er faktisk en oppgave, den siste oppgaven i dag, vi går ut på akkurat det, en utfordring.", "source": "lecture"}
{"lecture_id": "os4del4", "chunk_id": "os4del4_0001", "start": 73.9, "end": 164.46, "token_count": 297, "text": "Og dermed så er det største tallet man kan legge inn, tre. Så for å legge inn fire til register, hva kan man gjøre da? Og det er faktisk en oppgave, den siste oppgaven i dag, vi går ut på akkurat det, en utfordring. Jo, da kan man trikse det til ved at man først legger inn et tretall og et ett-tall, og så adderer man. Og så får man et firetall. Det er riktig. Man kan ikke legge firetall rett inn. Og det er klart, på andre arkitekturer så er dette fikset ved at man har flere bits. Altså sånn at et tall, det kan være... Det er kanskje plass til 32-bit som utgjør heltall som man kan legge inn. Så dette er en veldig minimalistisk arkitektur. Men det finnes en del tilsvarende CPU-er for veldig enkle embedded systemer, sånn vaskemaskiner f.eks. De integrerte kretsene, inntil 404, den hadde bare fire bit. Og hadde omtrent 2000 transistorer. Og det er størrelsesorden det denne her har. Ca. 2000 transistorer totalt sett.", "source": "lecture"}
{"lecture_id": "os4del12", "chunk_id": "os4del12_0000", "start": 0.0, "end": 89.94, "token_count": 297, "text": "Et siste spørsmål var om branch-kontroll i boksen på bildet, altså den her, tilsvarer kontrollenheten i CPU. Og det er også et godt spørsmål. Og svaret er ja. Men i tillegg så tilhører også instruksjonsdekoderen og program counter og alt det som ligger rundt Datapath det... Tilhører også kontrollenheten i CPU. Og det spørsmålet tenker jeg er referert til... ... bildet av en von Neumann-arkitektur, nemlig dette bildet. Og her... her ser vi at vi har en kontrollenhet og en alu og registeret. Og dette er et litt unøyaktig bilde. Det er vel kanskje det som er tilfellet. Men kontrollenhet her, det symboliserer bransjekontroll og instruksjonskoder og alt det som ligger rundt. Som gjør at en instruksjon som kommer inn her, den sørger for... Eller kontrollenheten sørger da for, når instruksjonen kommer, at alle de rette knappene trykkes på i Alun og i registrene. Sånn at riktig tall her aderes til et annet tall.", "source": "lecture"}
{"lecture_id": "os4del12", "chunk_id": "os4del12_0001", "start": 68.2, "end": 124.2, "token_count": 210, "text": "Som gjør at en instruksjon som kommer inn her, den sørger for... Eller kontrollenheten sørger da for, når instruksjonen kommer, at alle de rette knappene trykkes på i Alun og i registrene. Sånn at riktig tall her aderes til et annet tall. Og lagres her nede, f.eks. Så ALU og registers i denne figuren, det er det som vi vanligvis kaller datapath. Og på vår tegning så er det veldig detaljert nøyaktig hva datapath er. Still gjerne enda flere spørsmål underveis. Det er veldig nyttig at dere stiller spørsmål. Hvis du har et eller annet du lurer på, så er det sikkert mange andre som lurer på akkurat samme. Ikke vær redd for å stille spørsmål.", "source": "lecture"}
{"lecture_id": "os11del13", "chunk_id": "os11del13_0000", "start": 0.0, "end": 108.2, "token_count": 286, "text": "Det som kan være interessant da, er å se på... Hvordan er det egentlig Javakoden som... Hvordan ser Javakoden som kjører dette her? Hvordan ser den ut? Og da er det en egen... En egen applikasjon, Javap, som kan vise... Javabyte-kode. Men hvis vi tar på Minus Private, så får man se akkurat den koden som kjører saldotråden. Vi kan kjøre den kommandoen. Så det jeg gjorde, var Javap Minus Private på saldotredd. Og det vi ser her, det er Java Bite-kode. Så jeg... Det kan jo minne litt om Assembler-kode. Den eneste forskjellen er at Assembler-kode er for X86 fysiske maskiner. Mens denne Java Bite-koden, den er for en Java virtuell maskin. Og... Da kan vi prøve oss å finne ut... Jo, her er den Update saldo. Det er den metoden som oppdaterer saldoen. Da kan vi se at det er to områder her. Her er det en e-ad, og her er det en e-sub. Og dette er de to områdene som saldoen blir oppdatert i.", "source": "lecture"}
{"lecture_id": "os11del13", "chunk_id": "os11del13_0001", "start": 90.0, "end": 184.12, "token_count": 287, "text": "Jo, her er den Update saldo. Det er den metoden som oppdaterer saldoen. Da kan vi se at det er to områder her. Her er det en e-ad, og her er det en e-sub. Og dette er de to områdene som saldoen blir oppdatert i. Og hvis vi konsentrerer oss om den delen som gjør... Dette er da tråd 1, som gjør saldo pluss, pluss. Og da skal jeg ikke gå så veldig inn på dette i detalj, men JVM er en såkalt stackmaskin. Det vil si at den legger variabler på stacken, og så opererer den på stacken. Så det som faktisk foregår her, er... Her er det getstatic. Det betyr hente inn saldoen. Så hvis saldoen er 50, så legges... Og så icons1. Den sier... Den legger tallet 1 på stacken. Og eadd, den legger sammen de to tallene. Så da tar den 50 pluss 1 får 51. Og så gjør den put static og legger verdien ut. Og helt tilsvarende skjer med sub her nede. Da ser vi med en gang at dette tar litt tid.", "source": "lecture"}
{"lecture_id": "os11del13", "chunk_id": "os11del13_0002", "start": 157.28, "end": 243.78, "token_count": 298, "text": "Og eadd, den legger sammen de to tallene. Så da tar den 50 pluss 1 får 51. Og så gjør den put static og legger verdien ut. Og helt tilsvarende skjer med sub her nede. Da ser vi med en gang at dette tar litt tid. Først så hentes verdien inn og legges på sekken. Og dette implementeres jo da igjen av JVM, som så kjører maskinkode som gjør dette her. Så det som er tydelig, er at saldo blir lagt inn og så legges i registeret som bare denne prosessen eier. Og den aner da ikke noe om hva som skjer her nede. Så når dette kjøres samtidig, Så er det helt kaos. Saldo hentes inn, men det er ikke noe kontroll på hvor mange ganger det gjøres. Det er ingen kontroll på at det ikke kan bli et avbrudd akkurat her. Og så overføres CPU-en til den andre tråden, og så trekker den fra. Og på en måte enda verre blir det når disse trådene opererer på hver sin CPU. For da jobber de helt uavhengig av hverandre. Og henter inn og ut saldo hele tiden", "source": "lecture"}
{"lecture_id": "os11del13", "chunk_id": "os11del13_0003", "start": 220.58, "end": 293.52, "token_count": 266, "text": "at det ikke kan bli et avbrudd akkurat her. Og så overføres CPU-en til den andre tråden, og så trekker den fra. Og på en måte enda verre blir det når disse trådene opererer på hver sin CPU. For da jobber de helt uavhengig av hverandre. Og henter inn og ut saldo hele tiden uten å kontrollere hva den andre gjør i mellomtiden. Så det er helt klart at for at dette skal virke, så må man serialisere. Nøyaktig hvordan det gjøres, skal vi se på neste gang, etter påske. Men det er en metode som heter synchronized, som man kan bruke. Som da synkroniserer trådene i forhold til hverandre. Det som uansett er sikkert, er at hvis man ikke tar hensyn til dette her, hvis man ikke gjør programmene trådsikre, ikke tenker på race conditions, så kan ting som dette her oppstå. At man kjører samme programmet to ganger, og så er det helt vilkårlig hva man får ut som resultat.", "source": "lecture"}
{"lecture_id": "os13del21", "chunk_id": "os13del21_0000", "start": 0.0, "end": 82.84, "token_count": 282, "text": "Hvorfor legger man ikke mer lagringsplass i LNC i en GB? Det er et godt spørsmål, men... Kunne du ikke bare hatt enormt mye lagringsplass her? Og dette er et fysisk spørsmål. Man lager dette her så effektivt som mulig, men hvis du har... Én GB her inne, så... Eller la oss si du hadde én GB her, da, og ikke hadde noe L1, så... Da ville du straks hatt det problemet at det tok lengre tid, rett og slett fordi det er så mange... Én GB er enormt mange transistorer. Og det er jo fysiske systemer, dette her. Så det er derfor jeg vil ha L1-cash, L2-cash, L3-cash osv. Man skulle jo ønske at så mye som mulig var nær CPU-en, men der er det fysiske begrensninger, så alt kan ikke være nær CPU-en. Og de størrelsene man har på L1, L2 og L3 Cash, de har liksom blitt tilpasset og lagd sånn ut fra hardwaren. Hvordan kan man få det mest mulig effektivt?", "source": "lecture"}
{"lecture_id": "os13del21", "chunk_id": "os13del21_0001", "start": 63.32, "end": 146.08, "token_count": 280, "text": "men der er det fysiske begrensninger, så alt kan ikke være nær CPU-en. Og de størrelsene man har på L1, L2 og L3 Cash, de har liksom blitt tilpasset og lagd sånn ut fra hardwaren. Hvordan kan man få det mest mulig effektivt? Og en grunn til at man da ikke lager L1-cash på én gigabyte, er at... Er at det... Stort sett så er det ikke én gigabyte med data som brukes hele tiden om og om igjen. Ut fra statistikk av hvordan programmet kjører, så har man funnet ut at sånn som et TLB... At det er 1 %... 99 % av tilfellene så treffer man med den TLB-en som ligger her, Med kanskje bare 500K med data. Helt tett opp. Og da er det bedre å ha disse 500K med data veldig tett i CPU-en, sånn at det går lynraskt når de skal inn til registrene. Og så heller ha én GB her ute med neste ledd. Men kanskje ikke så mye som én GB, men appetit megabyte i hvert fall.", "source": "lecture"}
{"lecture_id": "os13del21", "chunk_id": "os13del21_0002", "start": 122.0, "end": 200.0, "token_count": 300, "text": "Og da er det bedre å ha disse 500K med data veldig tett i CPU-en, sånn at det går lynraskt når de skal inn til registrene. Og så heller ha én GB her ute med neste ledd. Men kanskje ikke så mye som én GB, men appetit megabyte i hvert fall. Så er det en sånn avveining. Hvis du skulle hatt én GB her, så måtte det være plass til alle, og da ville det tatt lengre tid å få et vilkårlig bite herfra inn til CPU-en. Så dette med størrelsen på L1, L2, L3 cash, de er nøye avveiet for å få det til å gå fortest mulig. Så kunne man tenke seg at man kunne kjøre alt til cash. Ja, man prøver å lage cash større og større, men det er mye dyrere. Og det krever mer strøm, så det er begrensninger på det òg. Men utviklingen av CPU-er har hele tiden vært sånn at man legger inn mer og mer cash. Det er sånn Wars Law har funket de siste årene. Man øker cashmengden for å få ting til å gå enda raskere.", "source": "lecture"}
{"lecture_id": "linux11del17", "chunk_id": "linux11del17_0000", "start": 0.0, "end": 111.04, "token_count": 274, "text": "Vi er vant til fra skjellet at vi gjør noe sånt som dette her - LS. Og så ønsker jeg kanskje å se på alle filer som har noe med Teks3 i seg. Og da gjør jeg sånn, grepp-tekster. Men i Porscheel fins det ikke noe som heter grepp. Men det fins en litt tilsvarende kommando òg - select string. Men vi ser... Dette er... Gir ikke akkurat det vi ønsket. Det gir ikke det samme som grep. Fordi at select string går på en måte inn i... inn i filene. Så dette fungerer ikke akkurat som man skulle ønske. Det man kan gjøre da, er... Å endre opp ut ved LS, sånn at det faktisk blir tekst. Man på en måte tvinger objektet til å ta en tekstform. Det kan man gjøre på denne måten her. Man kan først pipe det til commandleten outstring. For å få det helt til å funke, så må man også legge på den til outstring. Så må man legge på opsjonen stream. En fin ting med PowerShell er at hvis jeg skriver outstring minus st,", "source": "lecture"}
{"lecture_id": "linux11del17", "chunk_id": "linux11del17_0001", "start": 90.0, "end": 172.16, "token_count": 282, "text": "Man kan først pipe det til commandleten outstring. For å få det helt til å funke, så må man også legge på den til outstring. Så må man legge på opsjonen stream. En fin ting med PowerShell er at hvis jeg skriver outstring minus st, så kan jeg igjen tabbe. Sånn at jeg kan tabbe meg gjennom opsjoner til kommando.  Og så kan jeg sende til Selections. Og da fungerer det på samme måte som grep. Så dette er en litt sånn tung måte å gå gjennom grep på. Men i praksis så gjør man det ofte annerledes med command lets. Man gjør kanskje noe sånt som dette her i stedet. For å få ut det man elsker. Men først og fremst... Så jobber man på en annen måte i PowerShell. Man tar imot objektene, og så henter man ut informasjon fra objektene. Man bruker ikke da på samme måte som i Linux kommandolinje, hvor man hele tiden bruker grep for å trekke ut tekstrenger. Da bruker man andre metoder, fordi man har ferdigdefinerte objekter,", "source": "lecture"}
{"lecture_id": "linux11del17", "chunk_id": "linux11del17_0002", "start": 150.24, "end": null, "token_count": 112, "text": "Man tar imot objektene, og så henter man ut informasjon fra objektene. Man bruker ikke da på samme måte som i Linux kommandolinje, hvor man hele tiden bruker grep for å trekke ut tekstrenger. Da bruker man andre metoder, fordi man har ferdigdefinerte objekter, og da kan man hente all informasjonen man trenger, direkte ut fra objektene,  I stedet for å gå om tekstil.", "source": "lecture"}
{"lecture_id": "os9del1", "chunk_id": "os9del1_0000", "start": 0.0, "end": 93.84, "token_count": 292, "text": "Vi har kommet ganske så langt. Det er nå tre uker frem til påske. Og i operativsystemer, i den teoretiske delen, så skal vi i dag se litt mer på prosesser, som vi har drevet mye med. Og vi skal egentlig fortsette med det neste uke også, hvor vi skal se på plattformer. Formavhengighet og threads. Tråder, eller threads, det blir liksom det siste store temaet innen prosesser. Så vi jobber veldig mye med prosesser, men det er tross alt det man... Det er en veldig viktig del av et operativsystem og en veldig viktig del av hverdagen til utviklere og programmerere og alle som jobber med data. Så vi bruker mye tid på det. På de digitale forelesningene så skal vi fortsette noe med dere. Vi skal også se på regulære uttrykk. Og så skal vi begynne å se på virtuelle maskiner. Men vi får se hvor langt vi kommer. Kanskje etter påske så... Så skal vi starte med Windows og PowerShell. Eventuelt blir det etter påske. Ja... Det er spørsmål om... Om eksamen.", "source": "lecture"}
{"lecture_id": "os9del1", "chunk_id": "os9del1_0001", "start": 69.16, "end": 161.04, "token_count": 292, "text": "Og så skal vi begynne å se på virtuelle maskiner. Men vi får se hvor langt vi kommer. Kanskje etter påske så... Så skal vi starte med Windows og PowerShell. Eventuelt blir det etter påske. Ja... Det er spørsmål om... Om eksamen. På informasjon om faget på Oslomedisinens sider står det at eksamenvurdering er bestått, ikke bestått. Det må jeg undersøke, men iallfall jeg har søkt om at vi skal få bokstavkarakterer. Jeg trodde det egentlig var avgjort, men det er veldig fint dere spør. Sjekk ut det. Og hvis dere ikke får beskjed snart, så... Så si ifra. For det er viktig å få avklart det med eksamen. Så det jeg planlegger, i hvert fall hvis vi egentlig uansett er... I en digital eksamen, og så tilrettelegge det sånn at i hvert fall deler av eksamen blir... Sånn at ikke alle får samme spørsmål, sånn at det er veldig lett å samarbeide. Allerede i fjor hadde vi det, med multiple choice-oppgaver,", "source": "lecture"}
{"lecture_id": "os9del1", "chunk_id": "os9del1_0002", "start": 134.6, "end": 190.28, "token_count": 212, "text": "Så det jeg planlegger, i hvert fall hvis vi egentlig uansett er... I en digital eksamen, og så tilrettelegge det sånn at i hvert fall deler av eksamen blir... Sånn at ikke alle får samme spørsmål, sånn at det er veldig lett å samarbeide. Allerede i fjor hadde vi det, med multiple choice-oppgaver, hvor man fikk forskjellige typer oppgaver, eller veldig like oppgaver, men forskjellige tallverdier, da, f.eks. Sånn at ikke man bare kunne kopiere fra en annen og samarbeide og levere inn sammen. Så det er planen. Håper også at det er mulig å få en noenlunde rettferdig bokstavkarakterfordeling. Men det er fint dere spør, og da skal jeg sjekke ut det.", "source": "lecture"}
{"lecture_id": "linux8del10", "chunk_id": "linux8del10_0000", "start": 0.0, "end": 93.66, "token_count": 199, "text": "Men neste problemstilling blir da hvordan kan man endre på innholdet. Og i utgangspunktet så må man da gå inn i konteineren og endre på innholdet. Ja, vi kan jo prøve det også. Sånn generelt så kan jeg gå inn i en konteiner, f.eks. denne her. Går jeg inn i den på... 81 er det vel jeg går inn i nå. Og så kan jeg gå til hit. Her ligger indeksbilen. Så kan jeg legge til... fra 8081, f.eks. Så kan det gå ut igjen. Da har vi fortsatt tre konteinere som kjører. Så kan vi se om... Ja, da ser vi her. Nå får vi en spesiell melding fra 8081. Fra 8082. Så får vi den samme gamle meldingen.", "source": "lecture"}
{"lecture_id": "os2del2", "chunk_id": "os2del2_0000", "start": 0.0, "end": 100.48, "token_count": 292, "text": "OK. Før jeg begynner på selve slidene, så tenkte jeg å prøve å hoppe til slutten for å se på hva vi egentlig ønsker å... Hva jeg egentlig ønsker å fortelle dere i dag. Og slutten er dette her som vi skal komme fram til i løpet av dagen. Som vi skal bruke en del tid på. For dette gir på en måte... Og hvordan den er bygd opp fra enkle, logiske enheter. Det vi skal komme frem til i dag, som vi skal jobbe videre med fra neste gang for å lage en hel CPU, det er å få til å forstå hvordan en krets kan lage, gjøre en eller annen. Den spesielle logiske operasjonen vi ser på her, er hvordan kan en CPU legge sammen to tall. Det er på en måte lett å tenke seg at hvis en CPU kan legge sammen to tall, så kan du få til alle andre mulige logiske operasjoner også. Å legge sammen tall er en ganske kompleks logisk operasjon, som man ikke uten videre gjør. Men hvis vi får til dette her, så kan vi bygge videre. Lage gange og subtraksjon og sammenligning og alt mulig annet.", "source": "lecture"}
{"lecture_id": "os2del2", "chunk_id": "os2del2_0001", "start": 77.48, "end": 169.2, "token_count": 292, "text": "så kan du få til alle andre mulige logiske operasjoner også. Å legge sammen tall er en ganske kompleks logisk operasjon, som man ikke uten videre gjør. Men hvis vi får til dette her, så kan vi bygge videre. Lage gange og subtraksjon og sammenligning og alt mulig annet. På tilsvarende måte. Det vi skal se på i dag, er å logisk, men også praktisk, vise hvordan man kan lage innmaten i denne boksen her. Som er en slags trolldomsboks. Hvis man putter inn binære tall på toppen, A og B, så kommer svaret ut som A pluss B. Og da må man starte med nulleregnere. Og på en eller annen måte så må man da få lagret dette. Og det er temaet for neste gang. Da skal vi se på registeret, hvordan man lager bits inne i ICPU. Si OK, jeg vil legge sammen A pluss B. Hva blir det? Men det vi ser på nå, er hvordan kan man da kable dette her sammen på en sånn måte at uansett hva du putter inn for AB, så kommer summen C ut i den andre enden.", "source": "lecture"}
{"lecture_id": "os2del2", "chunk_id": "os2del2_0002", "start": 144.76, "end": 223.96, "token_count": 282, "text": "Da skal vi se på registeret, hvordan man lager bits inne i ICPU. Si OK, jeg vil legge sammen A pluss B. Hva blir det? Men det vi ser på nå, er hvordan kan man da kable dette her sammen på en sånn måte at uansett hva du putter inn for AB, så kommer summen C ut i den andre enden. Og det er ikke noen enkel oppgave. Hvis du fikk den oppgaven og aldri hadde hørt om transistorer og and or not, så vil det... Det har vært en relativt vanskelig oppgave. Men det går an å helt logisk bare sette opp dette her, og systematisk lage denne innhatten her med Andor & Not-porter. Og når man har gjort det, så kan man... I dag så kan man sende inn det til en produsent av halvlederbrikker. Og så kan man få brent dette inn i hardware. Man kan sette opp denne logikken med Andorra night porter, og så kan man brenne det hardware, og så får man ut i andre enden en dataskip som gjør akkurat det man ønsker. Det er i bunn og grunn det en CPU er.", "source": "lecture"}
{"lecture_id": "os2del2", "chunk_id": "os2del2_0003", "start": 204.46, "end": 236.98, "token_count": 123, "text": "Og så kan man få brent dette inn i hardware. Man kan sette opp denne logikken med Andorra night porter, og så kan man brenne det hardware, og så får man ut i andre enden en dataskip som gjør akkurat det man ønsker. Det er i bunn og grunn det en CPU er. Så det vi skal se på i detalj i dag, er hvordan kan man logisk sett, eller i praksis, få til dette og lage en vilkårlig krets som gjør en hopp.", "source": "lecture"}
{"lecture_id": "os10del5", "chunk_id": "os10del5_0000", "start": 0.0, "end": 149.92, "token_count": 295, "text": "Ja, det er et spørsmål der... Hvis du hadde lagd en Python-film med Python 3, kunne man da kjøre med bare Python? Ja, altså man kan eksplosivt... Kjøre Python... Python 2, f.eks. Så... Det vil da ikke være noen forskjell på å kjøre... med Python 2. Eller jo, kanskje. Det var kanskje det vi møtte med parenteser, skal vi si. Ja, det var Anders som lurte på dette. Hva er forskjellen med uten... Ja, akkurat... For... nå skjønner jeg hva du mener. Her står det Jusubin Pauten. Og det er Pauten II, ja. Så det er vel egentlig det som står her, som er litt... Det er jo ikke feil at Tyton 3 er versjonen Tyton 3. Men vi ser at... Nå må jeg vite... Så er... Så ser vi at det er piten 2. Og her nede er det piten 2. Så det ser ut som det var piten 2 overalt. Skal vi se hvordan det var her. Dette er piten 3. Så nå har han kopiert den nye piten der.", "source": "lecture"}
{"lecture_id": "os10del5", "chunk_id": "os10del5_0001", "start": 127.84, "end": 216.98, "token_count": 220, "text": "Så ser vi at det er piten 2. Og her nede er det piten 2. Så det ser ut som det var piten 2 overalt. Skal vi se hvordan det var her. Dette er piten 3. Så nå har han kopiert den nye piten der. Ja, da gir Python3 en feilmelding. Men det ser da ut som at det opprinnelige jeg hadde, var med permittelser. Og da fungerer både Python2 og Python3. Igjen... Det er et eksempel på... Hvordan Python også ikke er helt fullstendig plattformuavhengig. Her har vi en... eller ikke plattform, men versjonsuavhengig. Men i prinsippet er Boliava og Python plattformuavhengig på den måten at de har virtuelle maskiner. Som de kjører bitekode i. Men forskjellen er at Pyton...", "source": "lecture"}
{"lecture_id": "os14del6", "chunk_id": "os14del6_0000", "start": 0.0, "end": 101.4, "token_count": 292, "text": "Hvis jeg bare taster free, så får jeg ut en del minneinfo. Stort sett så kan du se dette i toppen også, men her får vi konsentrert oss om minnet. Dette er i... Dette er i utgangspunktet K. Så jeg kan be om free minus M. Så kan jeg be om free minus G. Så vi kan kanskje først se på den siste her, 3 minus G. Her får vi de store tollene. 31 betyr at det er... Det er vel rundt da, så dette er... Denne laptopen har 32 gigabyte internt. Og det er det vi ser her totalt. Og så ser vi... Used er 3. Så vi går opp her og ser på megabyte. 32 000 megabytes og 3000 egges. 3500 er brukt. Så det bestyrer at du bruker ca. 3 GB. Så det betyr igjen at det er veldig mye som er ledig. Men så ser vi... Ja, og ser. Det er også da delt i libraries, som ikke er... som er fordelt mellom flere prosesser. Men her er det en bit som er interessant - Bufcash. Vi ser at det er 4G. Den kan ofte være enda større.", "source": "lecture"}
{"lecture_id": "os14del6", "chunk_id": "os14del6_0001", "start": 70.46, "end": 168.14, "token_count": 300, "text": "Så det betyr igjen at det er veldig mye som er ledig. Men så ser vi... Ja, og ser. Det er også da delt i libraries, som ikke er... som er fordelt mellom flere prosesser. Men her er det en bit som er interessant - Bufcash. Vi ser at det er 4G. Den kan ofte være enda større. Det har ikke noe med L1 og L2-cash osv. å gjøre. Det er filcash. Så... Så dette her er fil... filcash. Og det som skjer da, er... Linux ser at her er det masse minne, mange gigabyte med minne, som er ledig, som ikke brukes av noen prosesser. Da tar Linux operativsystemkjernen og casher filer fra filsystemet. Så når man da leser inn filer, så lagres det i ramm i et område som da er satt av av operativsystemet. At etterpå, når man leser fra en fil, så i stedet for å bruke veldig lang tid på å lese på disken, så leser man direkte fra RAM. Da går det 100 000 ganger så fort. Så dette er en veldig effektiv måte å bruke RAM på for å få systemer til å gå fortere.", "source": "lecture"}
{"lecture_id": "os14del6", "chunk_id": "os14del6_0002", "start": 150.0, "end": 184.0, "token_count": 137, "text": "At etterpå, når man leser fra en fil, så i stedet for å bruke veldig lang tid på å lese på disken, så leser man direkte fra RAM. Da går det 100 000 ganger så fort. Så dette er en veldig effektiv måte å bruke RAM på for å få systemer til å gå fortere. Men så kan det være at man smører opp et svært RA som trenger masse RAM. Da vil man se at Bufcash-andelen vil gå ned. Hvis programmet bruker opp alt RAM, Så droppes filters.", "source": "lecture"}
{"lecture_id": "os3del1", "chunk_id": "os3del1_0000", "start": 0.0, "end": 94.04, "token_count": 292, "text": "Ja, god morgen, alle sammen. Kjempehyggelig å se at dere er... Så mange av dere som har kommet dere opp og kommer på forelesning. Det er veldig hyggelig. Og som sagt, jeg tror det er kjempebra å ha noen sånne faste punkter. For det ser ut som det fortsatt kommer til å bli digitalundervisning frem til påske. Forhåpentligvis vil vi i hvert fall da kunne starte med fysisk undervisning. Men vi får ta det fra uke til uke. I dag så er det lagt ut oppgaver, sånn at man kan faktisk gjøre ferdig førsteobligg. Og levere inn det. Det har alltid gått med ting som er ferdig. Hvis du ligger litt i forkant, så prøv å få ferdig obligen så snart du klarer. Så er første av tre obliger i havn. Jeg tenkte å starte med å si litt praktisk om det, men før jeg kommer så langt, så spør gjerne i skjetten underveis eller på timen. Og spesielt hvis det er noe... Hvis det er noe viktig, f.eks. at dere ikke hører meg,", "source": "lecture"}
{"lecture_id": "os3del1", "chunk_id": "os3del1_0001", "start": 69.3, "end": 160.42, "token_count": 297, "text": "Så er første av tre obliger i havn. Jeg tenkte å starte med å si litt praktisk om det, men før jeg kommer så langt, så spør gjerne i skjetten underveis eller på timen. Og spesielt hvis det er noe... Hvis det er noe viktig, f.eks. at dere ikke hører meg, eller at det er opplagt noe som er galt, så er det kjempefint om dere bare tar av lyden og bryter inn. Det kan dere uansett gjøre når som helst. I tillegg så kommer Ine i dag og kommer til å sitte og hjelpe meg med chatten og svare på alt som er av spørsmål. Kan ikke se at hun er her ennå. Hadde litt problemer med laptopen sin, men hun er forhåpentligvis her snart. OK. Aller først skal vi se litt på oppleggene. Så skal jeg si litt mer om det og grupper osv. Så det blir litt praktisk å starte med. Da skal vi se på denne. Her er kanalsrommet. Og som dere ser nå, så har det... Ommøte øyeblikk-tider. Den første er satt, de andre skal jeg tilpasse med andre fag dere har.", "source": "lecture"}
{"lecture_id": "os3del1", "chunk_id": "os3del1_0002", "start": 135.0, "end": 238.8, "token_count": 297, "text": "Så skal jeg si litt mer om det og grupper osv. Så det blir litt praktisk å starte med. Da skal vi se på denne. Her er kanalsrommet. Og som dere ser nå, så har det... Ommøte øyeblikk-tider. Den første er satt, de andre skal jeg tilpasse med andre fag dere har. Så si gjerne fra også, hvis dere allerede nå ser at oi, dette kolliderer. Så kan vi flytte på innleveringer, sånn at det passer best for dere. Det er ikke så lett å få til for alle, men vi prøver å få det til så bra som mulig. Men først og fremst så ligger første opplegg her. Så... Og her står det en tekst om den. Opplegget er sånn at alle oppgaver som er merket rødt med opplegg, i de første ukeoppgavene, til og med uke fire, det utgjør den første obligatoriske oppgaven. Det inkluderer oppgaver i neste uke. Dere skal... Ine er tilgjengelig i chatten. Dere skal levere dette som grupper. Vi anbefaler grupper på to og tre. Det kan være mulig å være ene, hvis du er alene.", "source": "lecture"}
{"lecture_id": "os3del1", "chunk_id": "os3del1_0003", "start": 210.0, "end": 313.72, "token_count": 297, "text": "Det inkluderer oppgaver i neste uke. Dere skal... Ine er tilgjengelig i chatten. Dere skal levere dette som grupper. Vi anbefaler grupper på to og tre. Det kan være mulig å være ene, hvis du er alene. Det er alltid noen som tidligere har jobbet i gruppe på fire, og til og med på fem. Vi anbefaler det ikke, men hvis dere er en sammensiset gruppe, så går det an. Uansett om dere er én, to eller opptil fem, så skal dere levere som en av OS-gruppene.  Og hvis man går inn på People, personer er det her, så ser man at det er en meny som heter OS her oppe. Og da ser vi at her er det en rekke OS1 og OS2-grupper nedover. En del av dere har allerede meldt dere inn i grupper. Men da er det veldig fint om dere når dere fortsetter å gjøre det, så melder dere inn i første tomme gruppe. Her ser vi OS6 er nå den første tomme. Så hvis dere skal lage en gruppe nå, så tar dere OS6. Og da, etter at dere har laget gruppe, så leverer dere inn obliger som den gruppen.", "source": "lecture"}
{"lecture_id": "os3del1", "chunk_id": "os3del1_0004", "start": 291.58, "end": 369.06, "token_count": 278, "text": "En del av dere har allerede meldt dere inn i grupper. Men da er det veldig fint om dere når dere fortsetter å gjøre det, så melder dere inn i første tomme gruppe. Her ser vi OS6 er nå den første tomme. Så hvis dere skal lage en gruppe nå, så tar dere OS6. Og da, etter at dere har laget gruppe, så leverer dere inn obliger som den gruppen. Og det kan være selv om det da sånn som her, bare én student, så leverer du likevel inn. Etter hvert skal dere få VM-er, virtuelle maskiner. Aktisk dokker, virtuelle maskiner. Og da vil dere få utlevert passord osv. i disse gruppene. Så du trenger uansett å være medlem av en gruppe. Dette står også på kursiden. Her ser vi... Dette er de fire første ukene. Vi er nå her i uke tre. Dette er oppgavene vi skal jobbe med i dag. Men du kan allerede nå gå i gang med uke fire-oppgavene. Og så ser vi også at fristen for obligasjonen, det er ikke i neste uke,", "source": "lecture"}
{"lecture_id": "os3del1", "chunk_id": "os3del1_0005", "start": 348.0, "end": 385.96, "token_count": 134, "text": "Dette er de fire første ukene. Vi er nå her i uke tre. Dette er oppgavene vi skal jobbe med i dag. Men du kan allerede nå gå i gang med uke fire-oppgavene. Og så ser vi også at fristen for obligasjonen, det er ikke i neste uke, men det er i uken etter at dere har litt tid på å få de siste oppgavene ferdige. Her står egentlig bare den samme teksten som på Kanvas. Det er det jeg tror dere trenger å vite om oppgavene.", "source": "lecture"}
{"lecture_id": "os3del8", "chunk_id": "os3del8_0000", "start": 0.0, "end": 110.32, "token_count": 299, "text": "Så dette er foreløpig løsningen. Det er en såkalt de-lås, eller de-latch på engelsk. Det er en enhet som lager et bitt, men i tillegg kan man velge å skru av enheten, sånn at den ikke reagerer på input. Vi har fått inn en C her i tillegg. Den virker sånn, det er en kontrollenhet. Den er sånn at hvis jeg liker én, så vil verdien som kommer inn på det her, den vil lagres. Og hvis jeg liker null, så vil denne lagrede verdien beholdes. Helt uavhengig av hva som kommer inn her. Og det ser vi at vi har fått til ved å endre litt på den forrige. Vi ser vi har lagt inn to and-porter. Ellers så er de to. Konstruksjonen er helt lik, bortsett fra at vi har lagt inn to and-porter. Da kan man igjen overbevise seg selv om at vi ser lik én. Da vil denne løsningen virke akkurat som den forrige løsningen. Vi vet at med and, hvis det kommer en ener inn i en and-port, så... Så er det den andre verdien som gir oppet, for eksempel hvis...", "source": "lecture"}
{"lecture_id": "os3del8", "chunk_id": "os3del8_0001", "start": 68.88, "end": 195.96, "token_count": 294, "text": "Da kan man igjen overbevise seg selv om at vi ser lik én. Da vil denne løsningen virke akkurat som den forrige løsningen. Vi vet at med and, hvis det kommer en ener inn i en and-port, så... Så er det den andre verdien som gir oppet, for eksempel hvis... Hvis det kommer en ener inn her og en ener inn der, så får man en... Men det er ikke helt riktig. Hvis det kommer en null inn, så kommer det alltid en null ut. For å overbevise om at denne virker, så kan vi kanskje se på... Hva skjer f.eks. hvis en er igjen? Og denne nå skal virke og skal endre. Jo, da... Hvis det kommer en ener inn på D og CL1, så kommer det en ener inn der. Og samtidig vil det komme null inn der. Og da vil kretsen fungere akkurat som denne her, på samme måte. Men så ser vi... Vi ser likt null. Det er på en måte av innvirkningen fra kretsen. Får vi se litt null, så vil det komme en null inn i begge anportene. Og da går det null videre til begge årportene.", "source": "lecture"}
{"lecture_id": "os3del8", "chunk_id": "os3del8_0002", "start": 173.8, "end": 264.04, "token_count": 285, "text": "Men så ser vi... Vi ser likt null. Det er på en måte av innvirkningen fra kretsen. Får vi se litt null, så vil det komme en null inn i begge anportene. Og da går det null videre til begge årportene. Og når det kommer null inn i begge årportene, så vil denne kretsen bli helt isolert. Så den vil ikke endre seg. Uansett om man endrer på det. Så man kan... Man kan være overbevist om det er slik kretsen virker. Det er egentlig bare å prøve alle kombinasjoner. Men det aller viktigste er bare å vite at sånn funker den kretsen. Hvis c er lik 1, så leser den intet-verdien og lagrer den. Hvis c er lik 0, så beholdes verdien som er lagret, uavhengig av hva det er. Som vi hele tiden gjør på i datamaskinarkitektur. Vi lager da en liten sånn logisk boks som inneholder alt dette. Akkurat som vi lagret den aritmetiske enheten. Nei, akkurat som vi lagde den adereren.", "source": "lecture"}
{"lecture_id": "os3del8", "chunk_id": "os3del8_0003", "start": 229.56, "end": 326.0, "token_count": 294, "text": "Hvis c er lik 0, så beholdes verdien som er lagret, uavhengig av hva det er. Som vi hele tiden gjør på i datamaskinarkitektur. Vi lager da en liten sånn logisk boks som inneholder alt dette. Akkurat som vi lagret den aritmetiske enheten. Nei, akkurat som vi lagde den adereren. Så lagde vi en kompleks aderer, og så lagde vi en liten boks. Spørsmål i kretsen om i disse lukkede kretsene, hvordan kommer verdien ut? Går den ikke rundt og rundt i evighet? Jo, de går på en måte rundt og rundt i en evighet. Det er sånn vi ønsker å lagre f.eks. denne kretsen her. Her vil den gå rundt og rundt i evighet. Men når vi lager en krets som dette, så kan vi koble de sammen. Og da vil vi se at når vi setter c-lik 1 og endrer på input-verdien det, så vil vi få en endring her. Og dermed får man en endring. Og da endres systemet hele tiden, og det er nøyaktig det som skjer i en CPU.", "source": "lecture"}
{"lecture_id": "linux7del5", "chunk_id": "linux7del5_0000", "start": 0.0, "end": 87.12, "token_count": 298, "text": "Ja, dette var litt av det jeg begynte å snakke om. Tilbake på 2000-tallet hadde man svære servere. Og så fikk man en periode hvor man begynte å virtualisere. At da istedenfor å ha store fysiske servere som sto og kjørte i årevis, så var det en katastrofe om det gikk ned, så begynte man å få virtuelle maskiner. Og veldig ofte så hadde man da bare én tjeneste per maskin. Det er kommet enda lenger i dag med dokker. Det typiske med dokker er at du har én instans, én dokkercontainer, som kjører én tjeneste. Det er det den gjør, ikke noe annet. Tilbake tidligere så var det store servere som gjerne kjørte flere tjenester. De sto og gikk i årevis og de måtte da vedlikeholdes. Og det var veldig tungt å oppgradere, f.eks. å få inn nye biblioteker osv. Ofte så unngikk man det, sånn at det tok veldig lang tid å oppgradere. Med dere så kan man bare i en fei lasse ned et nytt operativsystem med nye biblioteker.", "source": "lecture"}
{"lecture_id": "linux7del5", "chunk_id": "linux7del5_0001", "start": 60.0, "end": 154.94, "token_count": 294, "text": "De sto og gikk i årevis og de måtte da vedlikeholdes. Og det var veldig tungt å oppgradere, f.eks. å få inn nye biblioteker osv. Ofte så unngikk man det, sånn at det tok veldig lang tid å oppgradere. Med dere så kan man bare i en fei lasse ned et nytt operativsystem med nye biblioteker. Én ting som må nevnes når det gjelder docker i forhold til virtuelle maskiner, det er sikkerhet. Og da må man si at generelt er virtuelle maskiner sikrere, fordi det eneste de gir til VM-ene, er et API. Og det er veldig vanskelig gjennom det API-et å kunne gå fra én VM til en annen. Mellom oransje og... var det... Mellom gul og grønn VM, så er det i praksis umulig. I hvert fall veldig vanskelig å komme opp her. Skillet er ikke så sterkt mellom to dokkecontainere, for du kan se på det som prosesser som kjører på samme maskin. Hvis du får hacket en av dem, så er det Større muligheter til å komme inn på systemet og hacke den enn andre.", "source": "lecture"}
{"lecture_id": "linux7del5", "chunk_id": "linux7del5_0002", "start": 127.14, "end": 160.62, "token_count": 108, "text": "i praksis umulig. I hvert fall veldig vanskelig å komme opp her. Skillet er ikke så sterkt mellom to dokkecontainere, for du kan se på det som prosesser som kjører på samme maskin. Hvis du får hacket en av dem, så er det Større muligheter til å komme inn på systemet og hacke den enn andre. Sikkerhetsmessig er kanskje det største problemet til...", "source": "lecture"}
{"lecture_id": "os2del12", "chunk_id": "os2del12_0000", "start": 0.0, "end": 108.0, "token_count": 292, "text": "Kjempebra. Da kan vi se på det første svaret. Og her ser vi at tre fjerdedeler av dere har svart A ganger B pluss B. Og det er kjempebra, for det er helt riktig. For det som skjer her, er at dette er en anport. Og da er det A og B kommer inn i anporten. I tillegg tar man en kabel fra B her og så inn i denne årporten. Dette er en and, og dette er en år. Da kommer det inn i årporten, og da vil det som kommer ut da, være A ganger B pluss er år, pluss den B-en som kommer derfra. Så veldig bra. En stor del av dere hadde fått med seg dette. Neste spørsmål er litt vanskeligere. Hva kan kretsen forenkles til? Og det er jo ikke så opplagt. Jeg kan se på et par måter å forenkle på. En måte er å ta utgangspunkt i det uttrykket. A ganger B pluss B. Ikke at vi skal drive veldig mye med Bolska-algebra, men det er fint å være klar over muligheten. I Bolska-algebra kan man faktisk bruke en del av de metodene", "source": "lecture"}
{"lecture_id": "os2del12", "chunk_id": "os2del12_0001", "start": 74.84, "end": 165.08, "token_count": 289, "text": "Og det er jo ikke så opplagt. Jeg kan se på et par måter å forenkle på. En måte er å ta utgangspunkt i det uttrykket. A ganger B pluss B. Ikke at vi skal drive veldig mye med Bolska-algebra, men det er fint å være klar over muligheten. I Bolska-algebra kan man faktisk bruke en del av de metodene som man bruker i vanlig algebra. F.eks. kan jeg sette B utenfor parentes, akkurat som om det skulle vært vanlig algebra, og så skrive A pluss 1. Ganger B, eller er B. Og A pluss 1. Det er altså A år 1. Og man vet da om en årport... Hvis man får inn en ener på en... Hvis én av inputene er én, så er årporten alltid én. Så det er en identitet i Bord-Skal-Gebra at A pluss 1, det er rett og slett én. Så dette her vil da være lik én ganger B. Det er også en identitet, den vil alltid være lik B. Så riktig svar på den... Det har også flertallet fått til, veldig bra.", "source": "lecture"}
{"lecture_id": "os2del12", "chunk_id": "os2del12_0002", "start": 138.74, "end": 223.6, "token_count": 293, "text": "Så det er en identitet i Bord-Skal-Gebra at A pluss 1, det er rett og slett én. Så dette her vil da være lik én ganger B. Det er også en identitet, den vil alltid være lik B. Så riktig svar på den... Det har også flertallet fått til, veldig bra. 43 % hadde svart at man kan forenkle den til en B. Det går også an å se dette her ved å prøve og feile. Så man kan f.eks. si sånn... OK. Hvis det kommer en ener inn i B-en, så går den bort til overporten. Og hvis det kommer en ener inn i overport, så kommer det alltid en ener ut. Så i det tilfellet at B ligger 1, da er det B. Hvis B er 0, så kommer det en 0 inn i overporten. Så det som kommer ut til slutt, er det som kommer inn her. Men hvis B er 0, så vil det da komme en 0 inn i overporten, og uansett hva A er da... Så vil det gå en null inn der. Og da får man null ut. Dermed kan man også på den måten se at uttrykket er lik B.", "source": "lecture"}
{"lecture_id": "os2del12", "chunk_id": "os2del12_0003", "start": 201.88, "end": 284.06, "token_count": 283, "text": "Så det som kommer ut til slutt, er det som kommer inn her. Men hvis B er 0, så vil det da komme en 0 inn i overporten, og uansett hva A er da... Så vil det gå en null inn der. Og da får man null ut. Dermed kan man også på den måten se at uttrykket er lik B. En siste måte å se dette på, det er å rett og slett skrive opp sannhetsstabellen. Det kan man alltid gjøre. Da skriver jeg opp standardstabellen og så sier jeg OK. Så sjekker jeg punkt for punkt. Hvis 0-0 kommer inn, så finner jeg ut at da kommer 0 ut. Hvis 0-1 kommer inn, så ser jeg hva alt blir. Da kommer en ener ut. Hvis 1-0 kommer inn, hva blir det da? Jo, da kommer det en null ut. Sjekker alle portene osv. Hvis én, én kommer inn, så kommer én ut. Og så kan jeg rett og slett fra sandenstabellen se at... OK, men her ser vi at F er lik B, faktisk. I alle tilfeller så er F lik B.", "source": "lecture"}
{"lecture_id": "os2del12", "chunk_id": "os2del12_0004", "start": 265.46, "end": 298.66, "token_count": 119, "text": "Jo, da kommer det en null ut. Sjekker alle portene osv. Hvis én, én kommer inn, så kommer én ut. Og så kan jeg rett og slett fra sandenstabellen se at... OK, men her ser vi at F er lik B, faktisk. I alle tilfeller så er F lik B. Så da kan vi bare lese ut fra sandenstabellen og se at F er lik B. Sånn kan man forklare svaret på de to Poll-resultatene.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0000", "start": 0.0, "end": 89.74, "token_count": 287, "text": "Ja, så dette er... Her kommer dere inn i Canvas. Det jeg kommer til å bruke i år, det er... Det står en link først i Canvas, og det er en link til en kurs i det. Som ser sånn ut. Og dette er egentlig et... Når dere ser det er litt sånn farger og design fra sent 90-tall... Dette er litt sånn retro websider, men de funker ganske bra, iallfall. Og... ja, så når dere ser opplegget, så er... all informasjon dere trenger, ligger på denne ene siden. Dere ser sånn som i dag, tirsdag 5.1, så er det første OS-forelesning. Og her har jeg lagt ut notater. Også en link til slides. Og her ligger all den infoen jeg kommer til å gå gjennom. Jeg prøver å legge ut det på forhånd, så dere kan se på. Og gjerne forberede dere på denne forelesningen også. Så står det noen F-er og D-er nedover her. Og det F betyr rett og slett forelesning, sånn som i dag. Og den kommer til å gå live hver tirsdag.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0001", "start": 68.78, "end": 164.34, "token_count": 299, "text": "Jeg prøver å legge ut det på forhånd, så dere kan se på. Og gjerne forberede dere på denne forelesningen også. Så står det noen F-er og D-er nedover her. Og det F betyr rett og slett forelesning, sånn som i dag. Og den kommer til å gå live hver tirsdag. Etter hvert kanskje i forelesningssalen, hvis smittetallene tillater det. Men så ser du at det også står en D, og det står for digital. Og det vil på en måte være en slags digital forelesning. Der kommer jeg til å gå gjennom det som er pensum for dette området. Praktisk programmering osv. Det kommer jeg til å legge ut som videoer. Relativt korte videobiter for de forskjellige delene. Da er tanken at dere i løpet av denne uka går gjennom og ser på de videoene, eventuelt leser notatene som står der. Det som da står her, det er... De vil komme som oppgaver i neste uke igjen. Her er uke to, og da er det introduksjon til Linux' kommandolinje. Så det er oppgaver for neste uke.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0002", "start": 132.78, "end": 227.72, "token_count": 279, "text": "Da er tanken at dere i løpet av denne uka går gjennom og ser på de videoene, eventuelt leser notatene som står der. Det som da står her, det er... De vil komme som oppgaver i neste uke igjen. Her er uke to, og da er det introduksjon til Linux' kommandolinje. Så det er oppgaver for neste uke. Men så er det hele tiden ukens oppgaver, det er fokus i dag. Så det er ikke så veldig mye oppgaver i dag. Vi starter ganske rolig. Det er jo rett etter nyttår, så ja. Alle trenger litt tid på å komme i gang, det gjør jeg også. Så vi har en relativt forsiktig start, men som Ine sa, det er ganske omfattende kurs. Så det er veldig lurt å prøve å ligge litt tidlig an i løypa. Og jobb gjerne med oppgavene for neste uke allerede nå. Vi kan se veldig kort på planen. Den... Du ser det er noen obligatoriske oppgaver her. De består rett og slett av å legge sammen", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0003", "start": 193.84, "end": 282.12, "token_count": 286, "text": "Så det er veldig lurt å prøve å ligge litt tidlig an i løypa. Og jobb gjerne med oppgavene for neste uke allerede nå. Vi kan se veldig kort på planen. Den... Du ser det er noen obligatoriske oppgaver her. De består rett og slett av å legge sammen enkeltoppgaver fra de første ukene. Fra uke 1, 2, 3, 4 typisk, blir den første obligatoriske innleveringen. Da kan dere se her i dag. I dag er det bare tre oppgaver, men vi ser at alle er obligatoriske. Så det betyr at da skal dere, når dere skal levere obligg én, så skal dere levere en rapport hvor det er svart på alle de spørsmålene som er merket obligger. Og det jeg håper du oppnår på med det der, at ikke obliggene nødvendigvis blir en sånn stor skjev, men at dere ved å jobbe... Jevnt og trøtt. Så kan dere plukke ut her det som er obliger. Sånn som her er det neste uke. De første ni oppgavene kanskje er mer sånn", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0004", "start": 259.66, "end": 339.84, "token_count": 300, "text": "Og det jeg håper du oppnår på med det der, at ikke obliggene nødvendigvis blir en sånn stor skjev, men at dere ved å jobbe... Jevnt og trøtt. Så kan dere plukke ut her det som er obliger. Sånn som her er det neste uke. De første ni oppgavene kanskje er mer sånn øve og komme i gang. Og så kommer det noen obliger etter hvert nedover her. Så det er hovedsakelig strukturen på kurset. Vi møttes her hver tirsdag. Og da er det også fire timer mellom. Så det blir en veldig én intensiv dag, men dere må også regne med å jobbe mer med kurset, spesielt med det som ligger i Linux 1, 2, 3 osv. Hvor det står onsdag, men det betyr da kan dere se eller jobbe med det når som helst. Men det er viktig at dere begynner å jobbe med det denne uken, sånn at dere neste tirsdag er klare til å jobbe med det. Med disse oppgavene. Og det som også kan være veldig nyttig, er at dere da kan komme opp med spørsmål som dere lurer på", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0005", "start": 319.0, "end": 406.24, "token_count": 290, "text": "Men det er viktig at dere begynner å jobbe med det denne uken, sånn at dere neste tirsdag er klare til å jobbe med det. Med disse oppgavene. Og det som også kan være veldig nyttig, er at dere da kan komme opp med spørsmål som dere lurer på fra dette stoffet. Så kan vi også ta opp det på forelesningen sånn direkte. Jeg syns det fungerer veldig mye bedre hvis dere kommer med spørsmål. Og det er ofte ting som jeg ikke tenker på i det hele tatt, som dere brenner inn med. Så... Det er litt lavere terskel å spørre studentassistenter, så gjør gjerne det på laben. Men enda bedre hvis dere spør nå når vi møtes hver tirsdag. Ja... Kurset består... Ja, jeg ser... Jeg får et sterkt spørsmål i chatten om pensum. Om det er det som ligger på denne nettsiden. Ja. I utgangspunktet så er det det som ligger på nettsiden. Men det er også en anbefalt lærebok som... Ja, jeg har en slide om det, så jeg kan si litt om det etterpå.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0006", "start": 387.84, "end": 485.1, "token_count": 297, "text": "Om det er det som ligger på denne nettsiden. Ja. I utgangspunktet så er det det som ligger på nettsiden. Men det er også en anbefalt lærebok som... Ja, jeg har en slide om det, så jeg kan si litt om det etterpå. Men det er bare anbefalt. I utgangspunktet så får dere all... Alt dere trenger av pensum, det får dere i to compendier. Jeg kan vise det med det samme. Er det noen... en liten meny? Herunder forelesninger så ser dere at jeg legger ut notater etter hver forelesning. Men så ligger det også da her forelesningsnotater fra 2020 som ett PDF-dokument, og Linux-forelesninger fra 2020 som ett PDF-dokument. Så hvis dere går inn på det, så vil dere se... Notatene fra i fjor. Og da vil du se at dette er etter hvert et kompendium på 160 sider. Så dette fungerer da i praksis som en lærebok. Det er litt... Jeg legger ofte til å trekke fra noe stoff, så det kan variere litt. Men totalt sett til våren så vil ikke disse dokumentene være Veldig forskjellig. Så disse ligger ute.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0007", "start": 457.2, "end": 563.84, "token_count": 282, "text": "et kompendium på 160 sider. Så dette fungerer da i praksis som en lærebok. Det er litt... Jeg legger ofte til å trekke fra noe stoff, så det kan variere litt. Men totalt sett til våren så vil ikke disse dokumentene være Veldig forskjellig. Så disse ligger ute. I tillegg er det en lærebok som vi kan ta... jeg kan si noen år om senere. For øvrig, når vi er inne på forelesninger, så ser vi her også ligger det emnevalueringer. Det pleier Lorence, instituttlæreren min, å si at det må jeg alltid si fra om. Det kan være nyttig å lese for dere fra hva studentene sa i fjor. Her står det litt om tilbakemelding fra emne-evalueringen. Og det som ja, kanskje mange sier er at 54 % mener at pensumet er for stort. Så dette kurset er nok litt... litt omfattende. Men samtidig så tenker jeg at man... Det er veldig mye matnyttig. Det er også en del sånne tilbakemeldinger på at de søker på sommerjobb", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0008", "start": 529.0, "end": 628.68, "token_count": 297, "text": "Og det som ja, kanskje mange sier er at 54 % mener at pensumet er for stort. Så dette kurset er nok litt... litt omfattende. Men samtidig så tenker jeg at man... Det er veldig mye matnyttig. Det er også en del sånne tilbakemeldinger på at de søker på sommerjobb eller jobb, for den saks skyld. At de sitter igjen med mye som er konkret. Så derfor har nok kurset blitt relativt omfattende, men det er jo ikke alt som er like viktig. Det som er viktig, er at dere sitter igjen med de vesentlige delene av kurset. Og det er ikke nødvendigvis så omfattende. Det var litt om foreløpninger og foreløpingsnotater. Når vi er inne... Vi kan se øvingstimer... Jo, det er det viktig å ta med. Dette er da Ine som dere har hilst på. Og så er det Rune Bakken som kommer på lab etter forelesning i dag. Og de kan dere også nå på e-poset her. Så hvis det er noen spørsmål spesielt relatert til øvingsoppgavene, så gå inn.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0009", "start": 608.36, "end": 705.68, "token_count": 295, "text": "Dette er da Ine som dere har hilst på. Og så er det Rune Bakken som kommer på lab etter forelesning i dag. Og de kan dere også nå på e-poset her. Så hvis det er noen spørsmål spesielt relatert til øvingsoppgavene, så gå inn. Foreløpig blir det øvinger på Zoom. Etter hvert håper vi å komme inn i PO51 på datalaben. Men det ser ikke så veldig bra ut foreløpig. Så vi får se hvordan det går. Ja... Timeplaneksamen er kanskje viktig å si noe om. I utgangspunktet så er det avsluttende tre timers eksamen i Inspera. Men så har det, pga. eksamensavviklingen, at den ikke kan gjøres i lurveien. I hvert fall i utgangspunktet, så er det ikke helt bestemt ennå om det blir som i fjor, hvor det ble bestått eller ikke bestått med tre timers Inspera-eksamen. Dette er som sagt ikke avgjort ennå, men det er noe dere kan ha en innflytelse på. Jeg tenker jeg etter hvert kan legge ut en poll og spørre dere litt om hva dere ønsker.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0010", "start": 681.92, "end": 797.02, "token_count": 295, "text": "om det blir som i fjor, hvor det ble bestått eller ikke bestått med tre timers Inspera-eksamen. Dette er som sagt ikke avgjort ennå, men det er noe dere kan ha en innflytelse på. Jeg tenker jeg etter hvert kan legge ut en poll og spørre dere litt om hva dere ønsker. Det er mange som syns det er kjedelig å ha en CV med bare bestått eller ikke bestått. Det er noen problemstillinger rundt det, men der er det ikke bestemt hva årets løsning blir. Men her under eksamen ser dere en mengde løsningsforslag. Vår 2020 er den forrige fra 2020. Det kan være fornuftig å ta en titt på vår, høst, 2019. Spesielt de siste eksamensoppgavene. For å se hvordan de ser ut. Da får man et godt inntrykk av hva vi ønsker at dere skal lære i kurset. Ja. Det... Hva er vel det meste av sånn praktisk... informasjon rundt kurset? Vi kan... Ja, igjen... Hiv av gårde spørsmål i chatten, så svarer vi forhåpentligvis fortløpende.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0011", "start": 775.46, "end": 880.44, "token_count": 287, "text": "Ja. Det... Hva er vel det meste av sånn praktisk... informasjon rundt kurset? Vi kan... Ja, igjen... Hiv av gårde spørsmål i chatten, så svarer vi forhåpentligvis fortløpende. OK. Da tenkte jeg å gå gjennom noen slider om kurset. Bare for å dobbeltsikre at jeg har fått med det jeg har sagt. Eller at jeg har fått med det viktigste. Så skal vi se... Da skal vi se på en slide her. Den. Ser dere en slide om operativstemmer nå? Ine, ser du det? Ja, den er oppe. I hvert fall for meg. Supert. Ja... Jeg har pratet lenge, har ikke presentert meg ennå. Dere ser kanskje navnet mitt også, men jeg heter Hårek Haugerud. Jeg sitter... Jeg pleide å sitte i P35, men nå har jeg flyttet opp til AI-laben, siden jeg jobber en del med de som jobber der. Så jeg sitter fysisk i P52. Så langt har jeg hjemmekontor, men når jeg kommer tilbake til campus, så sitter jeg i P52.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0012", "start": 854.2, "end": 953.52, "token_count": 298, "text": "Jeg sitter... Jeg pleide å sitte i P35, men nå har jeg flyttet opp til AI-laben, siden jeg jobber en del med de som jobber der. Så jeg sitter fysisk i P52. Så langt har jeg hjemmekontor, men når jeg kommer tilbake til campus, så sitter jeg i P52. Det jeg kanskje ikke har gjort så klart hittil, er at kurset består av to relativt uavhengige deler. Den ene er operativsystemer, OS. Og denne delen er mer teoretisk om hvordan et operativsystem... Hvordan Linux og Windows og kjente operativsystemer er bygd opp. Og hvordan alt dette her henger sammen helt fra grunnen. Og vi bruker en god del tid på også å se på hardware, datamaskinarkitektur. For målet er at dere etter å ha tatt kurset, skal vite alt som skjer i en datamaskin. Nullvolt, femvolt spenninger og bitte små, de aller minste delene i datamaskinen. Helt opp til operativsystemet og dokker og virtuelle maskiner og alt som skjer på toppen. Så tradisjonelt er operativsystemet veldig spesifikt", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0013", "start": 918.62, "end": 1014.76, "token_count": 289, "text": "For målet er at dere etter å ha tatt kurset, skal vite alt som skjer i en datamaskin. Nullvolt, femvolt spenninger og bitte små, de aller minste delene i datamaskinen. Helt opp til operativsystemet og dokker og virtuelle maskiner og alt som skjer på toppen. Så tradisjonelt er operativsystemet veldig spesifikt om schedulere og minnebruk og CPU-er og hvordan alt dette er. Det jeg har prøvd å legge inn etter hvert, er å ta med hva som skjer på høyere nivå. Spesielt det vi har gjort de siste årene, er å se på dokker. Altså se på konteinere, og bruke og kjøre og lage konteinere. Og også har vi sett på virtuelle maskiner. Sånn at dere... Når dere går ut i arbeidslivet og begynner å bruke dette her, så vet dere hva en container er, og dere vet hva operativsystem er, og hvordan ting henger sammen. Så dette er en slags sånn... For å si det veldig fint, en dannelsesreise innen data. Dere skal kjenne til hvordan alt henger sammen.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0014", "start": 990.0, "end": 1079.94, "token_count": 294, "text": "Når dere går ut i arbeidslivet og begynner å bruke dette her, så vet dere hva en container er, og dere vet hva operativsystem er, og hvordan ting henger sammen. Så dette er en slags sånn... For å si det veldig fint, en dannelsesreise innen data. Dere skal kjenne til hvordan alt henger sammen. Og det er ikke nødvendigvis noe som dere får... Men jeg håper dere skal sitte med en dypere og grundigere forståelse av hvordan alt henger sammen. Sånn at når dere møter på et problem som ikke jeg vet om, og som ikke dere vet om eksisterer engang, som kanskje kommer i fremtiden, så har dere en dypere forståelse. Og da er det alltid lettere å takle problemene deres. Det er mange problemer å forstå hva som skjer der oppe på overflaten. Men sånn i praksis, hvis du er utvikler og jobber som konsulent, så tenker du ikke hele tiden på hva som skjer i operativsystemet, men noen ganger så blir det plutselig viktig å vite hva som foregår. Så det er den første delen. Den mer teoretiske delen.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0015", "start": 1056.42, "end": 1150.08, "token_count": 296, "text": "Men sånn i praksis, hvis du er utvikler og jobber som konsulent, så tenker du ikke hele tiden på hva som skjer i operativsystemet, men noen ganger så blir det plutselig viktig å vite hva som foregår. Så det er den første delen. Den mer teoretiske delen. Den andre delen er mer praktisk bruk av operativstemmer. Det vi først og fremst jobber med da, er kommandolinje. Og spesielt Linux-kommandolinje. Men vi kommer også til å drive noe med Windows og PowerShell, og skrive PowerShell-skript. I Linux-delen kommer vi til å skrive såkalte Bæsj-skript. Linux-kommandolinjeskript, som egentlig består av bare Sette sammen kommandoer til et systematisk program. Dette blir da sånne små systemskript som brukes til å styre operativstemme og til å snakke med operativstemme. Jeg nevner også dere her. Og vi kommer til å holde på noen uker med dere. Det som er nytt av året, er at... Jo, tidligere... Dere har blitt delt inn i grupper, og da har hver studentgruppe en virtuell maskin.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0016", "start": 1123.9, "end": 1221.12, "token_count": 274, "text": "og til å snakke med operativstemme. Jeg nevner også dere her. Og vi kommer til å holde på noen uker med dere. Det som er nytt av året, er at... Jo, tidligere... Dere har blitt delt inn i grupper, og da har hver studentgruppe en virtuell maskin. VM, som dere logger inn på. Nytt av året er at serverne har blitt så gamle og dårlige som kjørte disse. Så de har begynt å bryte sammen. Derfor har vi lagd et nytt system. Men i virkeligheten så er dette dokkecontainere som ved litt ekstra detaljer ser ut som selvstendige virtuelle maskiner. Dere får da tilgang til en sånn dokkecontainer som har en offentlig IP, og som dere kan installere og kjøre f.eks. webservere på osv. Og som dere kan bruke og teste og eksperimentere med sånn som dere vil. Så dere kommer vi til å bruke og jobbe en god del med i den praktiske delen. Ja, mer om kurset. Dette har jeg vist fram, kurssiden. Som Ine også sa,", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0017", "start": 1187.82, "end": 1272.7, "token_count": 281, "text": "og som dere kan installere og kjøre f.eks. webservere på osv. Og som dere kan bruke og teste og eksperimentere med sånn som dere vil. Så dere kommer vi til å bruke og jobbe en god del med i den praktiske delen. Ja, mer om kurset. Dette har jeg vist fram, kurssiden. Som Ine også sa, det er veldig viktig å jobbe med oppgaver. Det er derfor jeg også har gjort en endring på hele... I fjor og tidligere så har jeg pleid å ha fire timer forelesninger, altså to deler. En mer teoretisk om OUS, en om Linux og praktisk bruk. Den delen med praktisk bruk tror jeg det er aller viktigst å jobbe hands on. Altså jobbe med oppgavene. Og da tror jeg det kanskje er like bra å bruke... Starte med oppgavene, sette deg ned, prøve å løse oppgavene og gjøre det. For ofte er det ikke noe ekstremt vanskelig med hvert enkelt delspørsmål, men det er mye, det er mange detaljer å holde styr på.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0018", "start": 1251.12, "end": 1341.2, "token_count": 299, "text": "Altså jobbe med oppgavene. Og da tror jeg det kanskje er like bra å bruke... Starte med oppgavene, sette deg ned, prøve å løse oppgavene og gjøre det. For ofte er det ikke noe ekstremt vanskelig med hvert enkelt delspørsmål, men det er mye, det er mange detaljer å holde styr på. Og da tror jeg man får det beste inn i fingrene, bokstavelig talt, ved å sette seg ned ved tastaturet og jobbe gjennom oppgaven. Ja, et par ting med dette kurset er også at det er et grunnlag for et valgfag vi har Administrasjon, som det er veldig nyttig å kunne linje godt for å ta det. Vi har også en mastergrad som jeg også underviser på i parallell dette semesteret. Crowd-based services and operations, noe som tidligere het Network and system administration. Men dette handler om infrastruktur og hvordan... Sette opp virtuelle maskiner, containere, sette opp systemer for utviklere og alle andre til å bruke. Og hvis... Hvis dere tenker på å ta en massegrad, spesielt denne massegraden, så er dette kurset veldig nyttig.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0019", "start": 1315.58, "end": 1415.08, "token_count": 297, "text": "Men dette handler om infrastruktur og hvordan... Sette opp virtuelle maskiner, containere, sette opp systemer for utviklere og alle andre til å bruke. Og hvis... Hvis dere tenker på å ta en massegrad, spesielt denne massegraden, så er dette kurset veldig nyttig. Hvis dere liker dette kurset, spesielt den praktiske delen, så burde dere absolutt ta en titt på den. På den ACIT-massegraden. Ja... Vesentlig mål for kurset. Det første mest praktiske er å kunne lære å bruke kommandolinje. Og skrive systemskript. Vi bruker mest Linux og dokker, men også noe Windows. Det er den første praktiske delen. Den andre er, som jeg sa, å lære hvordan en datamaskin virker på alle nivåer. Helt fra transistorer, kanskje som jeg ser litt på i dag, og helt opp til operativstemme og applikasjonene som sitter på toppen av operativstemme. Det ble spurt om pensumlitteratur, og svaret var da at to compendier dekker pensum. De ligger ute, de som er fra i fjor, men de blir fortløpende oppdatert.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0020", "start": 1396.44, "end": 1494.46, "token_count": 293, "text": "som sitter på toppen av operativstemme. Det ble spurt om pensumlitteratur, og svaret var da at to compendier dekker pensum. De ligger ute, de som er fra i fjor, men de blir fortløpende oppdatert. Men så er det også en anbefalt støttelitteratur, Tan Baum. Det er en veldig god bok, men den er veldig omfattende og stor og dyr. Så jeg vil ikke forlange at dere alle skal gå og kjøpe og lese hele den. Men spesielt for de som liker dette kurset og er interessert, så er det en veldig dyptpløyende og god bok. Men den er nok i overkant omfattende. Det er kanskje på 1000 sider. Overkant omfattende for et kurs som dette her. Ja... Eksamen nevnte jeg også. Igjen så avhenger dette av koronasituasjonen. Men dere kan gjerne komme med innspill til hva dere ønsker. Obligatoriske gruppeinnleveringer. Jeg kommer til å legge ut til Kanvas-grupper, sånn at dere kan lage egne grupper. Jeg tror jeg pleide å ha maks på fire.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0021", "start": 1470.0, "end": 1559.94, "token_count": 294, "text": "Igjen så avhenger dette av koronasituasjonen. Men dere kan gjerne komme med innspill til hva dere ønsker. Obligatoriske gruppeinnleveringer. Jeg kommer til å legge ut til Kanvas-grupper, sånn at dere kan lage egne grupper. Jeg tror jeg pleide å ha maks på fire. Men hvis det er noen som ønsker å være enda større enn det, så går det an. Og det går også an å være alene på grupper. Men det er et krav at alle de tre obliggene må være godkjent for å kunne meldes opp til eksamen. Så kommer det også til å være noen multiple choice-tester som er obligatoriske. Nå har det vært en del trøbbel med det systemet der også pga. autentisering Men hvis vi får det opp å kjøre, så kommer opplegget til å fungere som dette her. Hvis ikke, så blir det noen Canvas multibeshare-tester med omtrent samme opplegg. Men det kommer vi tilbake til. Men uansett så er ikke disse veldig omfattende. Det er sånn man gjør på ti minutter. Hvis man har jobbet bra med kurset, så bør disse her gå ganske så greit.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0022", "start": 1543.12, "end": 1631.04, "token_count": 296, "text": "samme opplegg. Men det kommer vi tilbake til. Men uansett så er ikke disse veldig omfattende. Det er sånn man gjør på ti minutter. Hvis man har jobbet bra med kurset, så bør disse her gå ganske så greit. Hovedtanken med disse er at jeg skal gi en feedback til dere. Hvor står dere, hva har dere fått med dere av det som er pensel. Viktigste grunn til at jeg begynte med dette, var at det var mange studenter som først når de kom på eksamen, oppdaget at dette har de ikke fått med seg. Så dette er en viktig tilbakemelding til dere også. Ikke bare en sånn oblig... Å, jeg må gjøre det. Men dette er en tilbakemelding til dere. Nyttepersoner. Jeg viste frem studentassistentene. I tillegg har vi Taiba, som jobber med Linux-drift. Her på vårt institutt. På Institutt for informatikk. Og hun styrer spesielt med Linux-drift. Stud.SSH, for eksempel. I neste uke, eller gjerne allerede nå, skal logge dere inn på. Der vet jeg det har vært en del trøbbel med studiesesong.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0023", "start": 1603.2, "end": 1709.72, "token_count": 295, "text": "Her på vårt institutt. På Institutt for informatikk. Og hun styrer spesielt med Linux-drift. Stud.SSH, for eksempel. I neste uke, eller gjerne allerede nå, skal logge dere inn på. Der vet jeg det har vært en del trøbbel med studiesesong. Så det er egentlig fint om vi kan teste ut i laben. Det vil jo da være oppgang til neste uke, men test gjerne ut allerede nå om dere klarer å logge inn på studiesesong, om det er noen problemer rundt det. Hvis det er store problemer med det, så skal vi prøve å sette opp disse virtuelle maskinene. Sånn at dere kan bruke dem allerede nå de første ukene. OK. Da var jeg egentlig ferdig med alt det praktiske. Så med mindre det er noe dere brenner inne med og lurer på... Det ser ikke ut fra chatten som det er noe spesielt. Så da skal vi begynne helt på toppen og snakke om hva et operativsystem er. Hva er et operativsystem? Jo, som dere ser av dette bildet, så sitter operativsystemet mellom hardware. Her nede på hardware er det CPU.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0024", "start": 1674.92, "end": 1794.68, "token_count": 296, "text": "Det ser ikke ut fra chatten som det er noe spesielt. Så da skal vi begynne helt på toppen og snakke om hva et operativsystem er. Hva er et operativsystem? Jo, som dere ser av dette bildet, så sitter operativsystemet mellom hardware. Her nede på hardware er det CPU. Så sitter operativsystemet mellom den hardwaren og brukerprogrammene. Og så har vi deg eller flere som en bruker her på toppen, som bruker disse brukerprogrammene. Det operativsystemet gjør, det er å sørge for at brukerprogrammene får tilgang til den hardwaren som er her nede. Det er også veldig viktig at operativstemme er et software-grensesnitt. Det er ikke noe hardware i operativstemme. Riktignok så bruker det ofte helt spesielle funksjoner i hardware som vanlige programmer ikke bruker. Men OS er i bunn og grunn et svært... Det er bare et digert program. Hvor stort er et operativsystem? Det er egentlig ganske enormt. Hvis man ser på kildekoden til operativsystemer som Linux eller Windows, så kan det være noe sånt som fem millioner linjer med kode.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0025", "start": 1770.0, "end": 1867.5, "token_count": 297, "text": "Det er bare et digert program. Hvor stort er et operativsystem? Det er egentlig ganske enormt. Hvis man ser på kildekoden til operativsystemer som Linux eller Windows, så kan det være noe sånt som fem millioner linjer med kode. Og disse linjene med kode er bare operativsystemkjernen. Altså den viktigste delen av operativsystemet. Med GUI og biblioteker og system software osv. så blir det enda større enn dette. Men bare kjernen er så stor sånn at hvis man skriver ned dette i bøker, den koden, så får du noe sånn som 100 tannbarnbøker. Den er svær, 1000 sider. Stabler de opp hverandre, får du en fem meter høy stabel med kildekode. Og det er omtrent det største... Man har ikke særlig mange andre program som er større der ute, heldigvis. Det er veldig omfattende å generelt styre en hel datamaskin. Og det første man må tenke på når man ser dette, er at dette gjør også at... Et sånt system vil ikke fungere akkurat som det skal, hele tiden. Moderne operativsystemer er ganske så stabile.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0026", "start": 1843.9, "end": 1934.36, "token_count": 285, "text": "Det er veldig omfattende å generelt styre en hel datamaskin. Og det første man må tenke på når man ser dette, er at dette gjør også at... Et sånt system vil ikke fungere akkurat som det skal, hele tiden. Moderne operativsystemer er ganske så stabile. Det er relativt sjelden det skjer feil, men det er i praksis umulig å programmere et perfekt operativsystem sånn at det alltid virker som det skal. Man skulle jo tro at det var mulig å få til, men... Når noe er så komplekst, så... så er det ikke mulighet for å gjennomteste et operativsystem. Man kan ikke forutse absolutt alle muligheter for input og for hva som skjer samtidig. For mindre programbiter, f.eks. hvis du har en klasse med noen metoder, så kan du teste. Denne koden får absolutt alle muligheter, rett og slett alle mulige input. Så sjekker du om dette virker, for den gir alltid riktig kode, den krasjer aldri. Men i praksis er et operativsystem så stort at det aldri kan gjøres helt perfekt.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0027", "start": 1914.68, "end": 2010.7, "token_count": 286, "text": "Denne koden får absolutt alle muligheter, rett og slett alle mulige input. Så sjekker du om dette virker, for den gir alltid riktig kode, den krasjer aldri. Men i praksis er et operativsystem så stort at det aldri kan gjøres helt perfekt. Her prøver vi å gå litt dypere inn på hvor operativsystemet sitter. Fortsatt har vi hardware her nede, men oppå der sitter det masse software. Og på toppen sitter det applikasjoner, webbrosere osv. Men så ser vi her på venstre side, så ser vi use and mode. Dette er da programvare som kjører i såkalt user mode. Og det som er spesielt med user mode, er at da har man ikke alle rettigheter. Det er f.eks. ikke lov til å aksessere alle deler av ram eller internminne. Og da er det ikke alle instruksjoner som kan utføres. En viktig instruksjon som ikke kan utføres i user mode, det er å be datamaskinen hardware her Og det ville vært kjedelig, for da kunne den som skrev en webbok,", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0028", "start": 1984.48, "end": 2080.04, "token_count": 286, "text": "Det er f.eks. ikke lov til å aksessere alle deler av ram eller internminne. Og da er det ikke alle instruksjoner som kan utføres. En viktig instruksjon som ikke kan utføres i user mode, det er å be datamaskinen hardware her Og det ville vært kjedelig, for da kunne den som skrev en webbok, liksom bare velge... Hvis brukeren lastet en spesiell side, så kunne en skru av datamaskinen. Så use mode er en ganske sterkt begrenset modus, hvor programmene ikke har lov til å gjøre alle instruksjoner som Harvard kan. Derimot, i corner mode, der er alle instruksjoner mulig. Man kan aksessere alle deler av hardware. Og operativsystemet må da naturlig nok kjøre i corner mode. For det må kunne aksessere alle deler av hardware. Og må kunne gjøre absolutt alle operasjoner. Så dette kommer vi masse tilbake til. Det var én del, altså det å styre hardware. Men vi kan også si en annen viktig del, som OS da gjør, er å forenkle.", "source": "lecture"}
{"lecture_id": "os1", "chunk_id": "os1_0029", "start": 2057.64, "end": 2130.88, "token_count": 227, "text": "Og må kunne gjøre absolutt alle operasjoner. Så dette kommer vi masse tilbake til. Det var én del, altså det å styre hardware. Men vi kan også si en annen viktig del, som OS da gjør, er å forenkle. Og vi ser applikasjonsprogrammene her på toppen. De trenger et... De har et vakkert brukergrensenett mot operativstemme. Alt er pent og enkelt. De har enkle operatører. Så leser de en fil fra disk. Og da sørger operativsystemet for å snakke med hardware. Her er en skikkelig ugly interface. Dette er veldig grisete saker når du skal snakke med hardware. Ikke minst fins det en masse forskjellige harddisker. Sånn at når du snakker med hardware, Så er det en masse grums. Og alt dette grumset, det må operativt stemme.", "source": "lecture"}
{"lecture_id": "os6del1", "chunk_id": "os6del1_0000", "start": 0.0, "end": 96.6, "token_count": 281, "text": "Ja... Før vi starter i dag, så er det noen praktiske ting som vi skal se på først. Ja... Branch Prediction, det er det vi skal holde på med i dag. Men aller først til oversikten over kurset. Da har vi kommet. Vi er nå i uke seks. Det er et par ting som er nytt her. Først og fremst er det MC1. Som er da en obligatorisk multiple choice-test. Det har tatt litt tid å få ut den også, fordi det har vært problemer med SSH-innlogging på studentserverne. Ikke StudioSSH, men en annen server. Så... Men det er relaterte problemer. Så hvis det skulle være noen problemer med innlogging, så si ifra med en gang. Det har vært litt problemer tidligere, men jeg håper det fungerer som det skal nå. Det er delvis av historiske årsaker at vi har dette multipurpose-systemet, men jeg har bygd opp en svær database med spørsmål der. Og også mot slutten så skal vi ha en... Så er det en World of Operating Systems. Som er en slags konkurranse hvor man kan oppnå levels ved å svare på i dette systemet.", "source": "lecture"}
{"lecture_id": "os6del1", "chunk_id": "os6del1_0001", "start": 74.84, "end": 162.7, "token_count": 298, "text": "Det er delvis av historiske årsaker at vi har dette multipurpose-systemet, men jeg har bygd opp en svær database med spørsmål der. Og også mot slutten så skal vi ha en... Så er det en World of Operating Systems. Som er en slags konkurranse hvor man kan oppnå levels ved å svare på i dette systemet. Men uansett... Så tidlig som mulig, gå gjennom og gjør denne flervalgstesten. Først og fremst så er det en tilbakemelding på hvor dere sår, hva dere har fått med dere av pensum. I tillegg kan det være ganske nyttig fram til eksamen. For vanligvis så dukker det opp noen spørsmål fra disse Multiprofile-spørsmålene. Noen ganger helt de samme, andre ganger en variant som ligner. Oppgavene er fra kursets fire uker. Den første obliggen er det mest om Linux og verskommandoer. Du må svare på minst syv av ti riktige spørsmål. Syv av ti riktige. Og det er ikke så lett. Du kan være litt uheldig med spørsmålene. Noen er vanskeligere enn andre. Men ikke for tidlig hvis du ikke får det til.", "source": "lecture"}
{"lecture_id": "os6del1", "chunk_id": "os6del1_0002", "start": 146.66, "end": 227.44, "token_count": 274, "text": "Du må svare på minst syv av ti riktige spørsmål. Syv av ti riktige. Og det er ikke så lett. Du kan være litt uheldig med spørsmålene. Noen er vanskeligere enn andre. Men ikke for tidlig hvis du ikke får det til. Da er tanken at du skal ta kontakt med en studentassistent. Og nå, typisk, så må du da gå inn i et break-out-room hvis du er på en lab-dag. Bruk labdagen til å gå inn i breakover-room, snakke med studentassistent, og se på spørsmålene. Så gir studentassistentene deres mulighet til å få en ny sjanse. I tillegg... Var det noe annet fornuftig jeg skulle si om disse testene? Jo, dere får nye sjanser. Men det er viktig å gjøre... Sånn at dere får tid til å få nye sjanser. Hvis det er én type spørsmål dere bommer på, så er det kanskje fornøyelig å jobbe litt mer med oppgavene rundt de. Så kan dere, før dere begynner på de, nye sjanser.", "source": "lecture"}
{"lecture_id": "os6del1", "chunk_id": "os6del1_0003", "start": 206.64, "end": 295.64, "token_count": 275, "text": "Sånn at dere får tid til å få nye sjanser. Hvis det er én type spørsmål dere bommer på, så er det kanskje fornøyelig å jobbe litt mer med oppgavene rundt de. Så kan dere, før dere begynner på de, nye sjanser. Ok, det var multiple choice. Var det noe annet... Ja, Oblique 2 står og lyser her nede i det fjerne. Det er ikke så lenge til. Den har da frist... skal vi se... fredag 5. mars. Så det er en stund til, men alle oppgavene til Oblikk 2 ligger nå ute. Så Oblikk 2 består av fem-, seks- og syvoppgavene herfra. Og så vil det da etter påske komme en Oblikk 3 med oppgaver fra de fire ukene. Sånn er det standard-opplegget. En annen ting... Oppgavene denne uken, de har ligget ute en uke. Men disse oppgavene til neste uke, som er uke syv... Det er da de siste som inneholder obligoppgaver.", "source": "lecture"}
{"lecture_id": "os6del1", "chunk_id": "os6del1_0004", "start": 266.64, "end": 305.64, "token_count": 96, "text": "Sånn er det standard-opplegget. En annen ting... Oppgavene denne uken, de har ligget ute en uke. Men disse oppgavene til neste uke, som er uke syv... Det er da de siste som inneholder obligoppgaver. Men temaet derfra har vi ikke snakket om ennå. Det snakker vi delvis om i neste uke, og...", "source": "lecture"}
{"lecture_id": "os11del10", "chunk_id": "os11del10_0000", "start": 0.0, "end": 100.3, "token_count": 286, "text": "Problemstillingen er at... Hvis man jobber med felles data, så må man serialisere. Hvis ikke, som vi skal se, så kan det gå veldig galt. Da kan man slåss om å bruke en felles variabel og ødelegge hele datagrunnlaget. Resultatene kan bli helt feil. Et enkelt eksempel på dette er... Hvis vi tenker oss at vi har en webside som skriver ut billetter... Og da er det ofte en database som holder på antallet billetter. Så det vil jo kanskje gjøre dette enda mer komplisert. Men da vil vi alltid tenke på at vi må ha en trådsikker database. Det er da en database som er serialisert, hvor dette er tatt hensyn til. Men vi kan også tenke oss at vi bare har én webserver, hvor det er to prosesser som står og kjører. Og begge må da ha tilgang til antall billetter. Ellers kan de ikke dele ut billetter i det hele tatt. Så i dette tilfellet tenker vi oss at vi har én variabel, ledigbilletter, som sier hvor mange ledige billetter som finnes.", "source": "lecture"}
{"lecture_id": "os11del10", "chunk_id": "os11del10_0001", "start": 84.52, "end": 165.64, "token_count": 292, "text": "Og begge må da ha tilgang til antall billetter. Ellers kan de ikke dele ut billetter i det hele tatt. Så i dette tilfellet tenker vi oss at vi har én variabel, ledigbilletter, som sier hvor mange ledige billetter som finnes. Så kan vi tenke at koden for webserveren er noe sånt som dette her. Hvis ledige billetter er større enn null, jo, da trekker vi fra ledigbilletten med én og skriver ut en billett. Og det ser jo enkelt og greit ut. Men vi kan da få et mulig problem. Det problemet er... Hva skjer hvis man er litt uheldig og Prosess1 står og kjører og sjekker at det er ledigbilletter? Den felles variabelen ledigbilletter, den er én. Men så vet vi at en sånn if-test, den utføres ikke i én instruksjon. Det er først en if. Først så vil det være en compare av ledigbilletter. Og se om den er større enn null. Og i dette tilfellet så vil dette slå til. Men før Prosess 1 har rukket å minske ledigbillett med én,", "source": "lecture"}
{"lecture_id": "os11del10", "chunk_id": "os11del10_0002", "start": 136.4, "end": 234.36, "token_count": 297, "text": "Men så vet vi at en sånn if-test, den utføres ikke i én instruksjon. Det er først en if. Først så vil det være en compare av ledigbilletter. Og se om den er større enn null. Og i dette tilfellet så vil dette slå til. Men før Prosess 1 har rukket å minske ledigbillett med én, så skjer det en Context-witch. Så hopper jeg over til Prosess 2, og så utfører den den samme. Den sjekker at ledigbilletter er større enn null. Og så ser vi... Så gjør... Så kommer den Context Switch-en tilbake. Ledig billett til minus-minus. Og den blir ned i minus én, og så skriver den ut enda en billett. Og det er klart det er to stykker som har fått billetter. Og her er det noe som går helt galt. Så på denne måten kan man ikke ha det. Og man må sørge for at noe sånt som dette her ikke kan skje. I dette tilfellet så er det kanskje logisk å tenke seg at... Og lett å forestille seg at dette kan skje, siden det er flere kodeoperasjoner involvert.", "source": "lecture"}
{"lecture_id": "os11del10", "chunk_id": "os11del10_0003", "start": 202.88, "end": 268.44, "token_count": 208, "text": "Og her er det noe som går helt galt. Så på denne måten kan man ikke ha det. Og man må sørge for at noe sånt som dette her ikke kan skje. I dette tilfellet så er det kanskje logisk å tenke seg at... Og lett å forestille seg at dette kan skje, siden det er flere kodeoperasjoner involvert. At man først sjekker LED-billetter, og så trekker man fra. Her er det en kontekstfetch. Det tilfellet man også har, er at P1 og P2 kjører på hver sin CPU. Og da vil det være enda mer problematisk, for da vil ikke de kunne sjekke seg imellom. Da vil de hente ned lederbilletter til sin CPU uten å sjekke om den andre da har gjort det. Så da er det enda vanskeligere å serialisere.", "source": "lecture"}
{"lecture_id": "linux6del13", "chunk_id": "linux6del13_0000", "start": 0.0, "end": 106.12, "token_count": 299, "text": "Kommandoen vget er veldig nyttig. Den kan brukes til å hente ned websider. For eksempel, hvis jeg ønsker å hente ned denne siden, så kan jeg bare skrive vget, og så vr. Da ser vi vi får ut en del meldinger. Og så sier den save to rein. Det går an å sette på noen opsjoner her, f.eks. hvis jeg setter på minus O til log.tksd, f.eks., så ser vi da... Får jeg sendt loggteksten til log.tksd. Så ser vi at den serverer til rein.1. Hvis det allerede ligger en fil her som heter det samme, så setter den på. Versjonsnummer. Så kan man også si eksplisitt hvilken fil man ønsker å laste ned til. F.eks. kan jeg si jeg vil ha en fil som heter REIN, med store bokstaver. Og da sender vi den til REIN. En annen ting som kan være nyttig, det er å... I stedet for å sende til en fil, Som man sender til StandardOut sånn som det. Så for at du skal se hva som skjer, så kan jeg kanskje legge på minus liten o også. Minus liten o til en loggfill.", "source": "lecture"}
{"lecture_id": "linux6del13", "chunk_id": "linux6del13_0001", "start": 75.12, "end": 138.12, "token_count": 158, "text": "Og da sender vi den til REIN. En annen ting som kan være nyttig, det er å... I stedet for å sende til en fil, Som man sender til StandardOut sånn som det. Så for at du skal se hva som skjer, så kan jeg kanskje legge på minus liten o også. Minus liten o til en loggfill. Og så minus stor o til strek. Da ser vi at output skrives direkte hit. Sånn at det kan omdirigeres. Legge det inn i RE... Da har jeg fått en fil. RE. Så på den måten kan man laste ned websider og legge det dit man ønsker det.", "source": "lecture"}
{"lecture_id": "os12del2", "chunk_id": "os12del2_0000", "start": 0.0, "end": 89.9, "token_count": 275, "text": "Det er oppgaver denne uken som går på Windows PowerShell. Og for dere som kjører Windows-laptoper, så... Så kan dere gjøre de aller fleste av oppgavene direkte. Men det er noen oppgaver med å lage nye brukere osv. Og så er det noen oppgaver med Windows Registry med å endre på innstillinger. Da... Kan det være greit for å være sikker på ikke å ødelegge noe på eget oppsett, så kan det være greit å bruke en Virtual Box vindus-VM, som mange av dere har brukt tidligere. Men det står instruksjoner her også på hvordan den kan installeres og settes opp. Videre er det en... Etter de PowerShell-oppgavene så er det oppgaver om det vi snakker om i dag. Og her ser vi... Et script sånn som dette her kan kjøres omtrent direkte i PowerShell. Så veldig mye er likt, fordi det er lagd alias i PowerShell som gjør mange av de samme kommandoene. Når vi først kan binde bæsjskrift, så kan det også mye på oss selv.", "source": "lecture"}
{"lecture_id": "os12del2", "chunk_id": "os12del2_0001", "start": 70.2, "end": 157.04, "token_count": 291, "text": "Et script sånn som dette her kan kjøres omtrent direkte i PowerShell. Så veldig mye er likt, fordi det er lagd alias i PowerShell som gjør mange av de samme kommandoene. Når vi først kan binde bæsjskrift, så kan det også mye på oss selv. Masse kan overføres direkte. Og så, etter hvert, så er det oppgaver i dag. Så er det javatrådoppgaver og diverse oppgaver rundt synkronisering. Og serialisering. Så er det blant annet noen litt mer vanskelige teoretiske oppgaver. Men det skal vi se på først. I forløsningene. Så temaet i dag er generell synkronisering. Vi skal spesielt se på synchronized i Java for å se hvordan vi kan synkronisere den Java-koden som vi hadde før påske, hvor man talte opp en saldo, og to tråder ødela for hverandre. Synkroniserer vi riktig, ser vi ofte at det ikke er tread safe. Det betyr at trådene kan ødelegge for hverandre. Synchronized er en metode som kan brukes for å synkronisere", "source": "lecture"}
{"lecture_id": "os12del2", "chunk_id": "os12del2_0002", "start": 137.04, "end": 200.0, "token_count": 222, "text": "og to tråder ødela for hverandre. Synkroniserer vi riktig, ser vi ofte at det ikke er tread safe. Det betyr at trådene kan ødelegge for hverandre. Synchronized er en metode som kan brukes for å synkronisere og gjøre et trådprogram tread safe. Så skal vi til slutt i dag se på deadlock. Det er noe som kan oppstå når man fortvilet prøver å synkronisere mange prosesser, og det gjør man typisk alt ved at de vet... Men hvis flere prosesser venter f.eks. i en ring, en sirkel, på hverandre, så kan det oppstå deadlock. Og da kommer ingen videre. Og det er et problem man må være klar over når man begynner å programmere og synkronisere tråder. Eller prosesser, for den saks skyld. Så det er... Det er temaet i dag.", "source": "lecture"}
{"lecture_id": "linux9del2", "chunk_id": "linux9del2_0000", "start": 0.0, "end": 137.02, "token_count": 297, "text": "I mellomtiden tenkte jeg å gjøre noe annet. Nemlig å teste ut dette interaktivt på en standard Linux-maskin. Så da vil jeg dele et annet vindu med dere. Her. Nå er jeg... Nå er jeg i... faktisk på desktopen min nede på OsloMet. Da skal jeg gjøre interaktivt det som jeg etterpå har tenkt å gjøre i dokker. Først kloner jeg disse filene. Så går jeg ned i mappen. Her ligger... Så tanken er nå at jeg skal teste hvor lang tid dette tar. Og da skal jeg teste... Ja, vi kan... Aller først så kan jeg teste bæsjskriptet. Jeg kjører det. Disse skriptene og programmene har jeg tilpasset til denne maskinen, sånn at de tar omtid. Det som kan være interessant å se, er at tiden kan være forskjellig på andre maskiner. Som f.eks. hvis man kjører det i dokker på Linux-V. Sum.vers ser sånn ut. Og den regnet ut denne summen ferdig på 5,5 sekunder. Vi kan starte øverst. Da lages det som vi vet en A.not. Så kan vi ta tiden på det.", "source": "lecture"}
{"lecture_id": "linux9del2", "chunk_id": "linux9del2_0001", "start": 101.82, "end": 233.44, "token_count": 300, "text": "Som f.eks. hvis man kjører det i dokker på Linux-V. Sum.vers ser sånn ut. Og den regnet ut denne summen ferdig på 5,5 sekunder. Vi kan starte øverst. Da lages det som vi vet en A.not. Så kan vi ta tiden på det. Den tar også ca. 5,5 sekunder. Sånn har jeg gjort tilsvarende med alle programmene. Det er å kompilere Java. Og da trenger man å installere Java sånn som jeg nå gjør på docketcontaineren. Med app-get-install JK. Så først kompilerer jeg Java. Det er sånn man kjører Java fra Linux-kommandolinja. Med Javak-kompilator først, og så kjører jeg med Javasum. Men jeg glemte å ta tiden. Den tar også omtrent fem sekunder. Sånn fortsetter vi. Pøl er som regel installert i polt på ubundet. Pøl er et språk som ble brukt mye tidligere. Tidligere var det en del av pensum med operativstemmer. Men etter hvert har Pearl blitt mindre brukt. Og spesielt Python har tatt over det som er Pearls rolle.", "source": "lecture"}
{"lecture_id": "linux9del2", "chunk_id": "linux9del2_0002", "start": 180.02, "end": 296.96, "token_count": 269, "text": "Den tar også omtrent fem sekunder. Sånn fortsetter vi. Pøl er som regel installert i polt på ubundet. Pøl er et språk som ble brukt mye tidligere. Tidligere var det en del av pensum med operativstemmer. Men etter hvert har Pearl blitt mindre brukt. Og spesielt Python har tatt over det som er Pearls rolle. Men det skal vi se nærmere på snart. Det var Python. Vi kan ta helt til slutt, så kan vi ta tiden på PHP også. I oppgaven dere får, så tar jeg ikke med PHP. Delvis fordi det kan bli et plastproblem med å få installert alt. Sånn. Så alt tar omtrent fem og et halvt skudd. Men så kommer selve clouet. I denne koden her så vil det være forskjell på hvor mange ganger hver av de klarer å kjøre gjennom Løkken på 5,5 sekunder. Så nå kommer spørsmålet til dere, og det er... Det er... hvilket av disse språkene tror dere er raskest?", "source": "lecture"}
{"lecture_id": "linux11del7", "chunk_id": "linux11del7_0000", "start": 0.0, "end": 114.18, "token_count": 286, "text": "OK. Nå har jeg startet opp Bindosti fra imaget som ligger i dagens oppgaver med virtual box. Så det jeg skal gjøre nå, det er hvis jeg tar vindustassen og X, så... Eller hvis jeg går ned her... Sånn. Her får jeg opp et kommandoprompt. Da er det mulig å sette opp det til å gi påskjell, men default, så er det command.exe som jeg får opp. Hvis jeg her prøver å skrive LS, så ser vi at det er ikke en kjent kommando òg. Men hvis jeg skriver dir, dos-kommandoen dir, så får jeg listet filer. Dette er da et veldig begrenset... Men vi kan ta... Vi kan lage en liten hello.butt. Nå var den ferdig... Den hadde jeg lagd allerede. Hvis man bare skriver... så kan man kjøre den som... hello..hello.butt. Og så kjører den hello.world. Og helt tilsvarende ser det ut med webbeskrift. Så jeg tenker vi heller kan... Vi kan heller gå på og se på powershelf. Spørsmålet er om man må bruke hydrocox hvis man har Vinos PC.", "source": "lecture"}
{"lecture_id": "linux11del7", "chunk_id": "linux11del7_0001", "start": 90.0, "end": 199.48, "token_count": 291, "text": "Og så kjører den hello.world. Og helt tilsvarende ser det ut med webbeskrift. Så jeg tenker vi heller kan... Vi kan heller gå på og se på powershelf. Spørsmålet er om man må bruke hydrocox hvis man har Vinos PC. Nei, man trenger ikke å gjøre det. Man kan kjøre rett i sin egen Vinos. Det eneste kan være hvis man... I neste uke så skal vi gjøre noen oppgaver hvor vi endrer på Windows registry. Stort sett så er det helt uproblematisk. Vi skal ikke gjøre noen store endringer. Så da vil det funke fint å bruke egen Windows PC. Men òg hvis man er bekymret for å gjøre noen endringer, og hvis man har lyst til å eksperimentere litt mer, så kan det være lurt å bruke... Ok. Man kan faktisk i... I kommando til XV, så kan man taste påbeskjed, og da får man opp et påbeskjed. Hvis jeg nå skriver les, så ser vi... Da funker den kommandoen. Da kan vi prøve å lage... Å lage en hello word på vår selv. Jeg kan bare starte Notepad sånn.", "source": "lecture"}
{"lecture_id": "linux11del7", "chunk_id": "linux11del7_0002", "start": 161.64, "end": 303.88, "token_count": 285, "text": "I kommando til XV, så kan man taste påbeskjed, og da får man opp et påbeskjed. Hvis jeg nå skriver les, så ser vi... Da funker den kommandoen. Da kan vi prøve å lage... Å lage en hello word på vår selv. Jeg kan bare starte Notepad sånn. Og så kan jeg skrive 'hello word'. Sånn. Man må være litt forsiktig når man saver for å få dette som en... Unnskyld. For å få dette som en PowerShell-fil, så kan man ikke save som.txc, for da vil filen hete hello.pcn.txc. Så da er det viktig å velge all files før man saver, og så skrive navnet. Og så servere. Da har man en Hello Word-fil, og så kan man kjøre den ved å skrive hello.pc. Den henter ut execution policy. Det betyr at her har jeg allerede satt den til remote side. Men i Default så er den satt til restricted. Så jeg kan prøve å sette den tilbake til Default, sånn som den var opprinnelig. Men da ser vi det Faiquer lover. Og det er fordi jeg er nå en vanlig bruker.", "source": "lecture"}
{"lecture_id": "linux11del7", "chunk_id": "linux11del7_0003", "start": 280.0, "end": 397.4, "token_count": 293, "text": "Men i Default så er den satt til restricted. Så jeg kan prøve å sette den tilbake til Default, sånn som den var opprinnelig. Men da ser vi det Faiquer lover. Og det er fordi jeg er nå en vanlig bruker. Så for å få lov til dette her, så må jeg starte Powershell som administrator. Og det er nyttig å kunne. Da kan man f.eks. taste Windows R. Hvis jeg taster Windows R og Powershell, så får jeg opp et vanlig Powershell-vindu. Så det funker ikke. Hvis jeg taster vindus-knappen og X deg imot, og så begynner... Oi. Nei, det funker heller ikke. Hvis jeg starter her med vindus-X, og så starter å skrive powershell, så vil du se at da får jeg opp diverse powershell-muligheter her. Med en editor osv. Men hvis jeg tar det øverste, og så høyreklikker der... Da får jeg muligheten til å kjøre som administrator. Det er det jeg må gjøre. Og da svarer jeg ja på det. Og så kan jeg... Sette execution policy f.eks. til default. Hvis jeg da går tilbake til mitt vanlige...", "source": "lecture"}
{"lecture_id": "linux11del7", "chunk_id": "linux11del7_0004", "start": 360.0, "end": 431.0, "token_count": 172, "text": "Med en editor osv. Men hvis jeg tar det øverste, og så høyreklikker der... Da får jeg muligheten til å kjøre som administrator. Det er det jeg må gjøre. Og da svarer jeg ja på det. Og så kan jeg... Sette execution policy f.eks. til default. Hvis jeg da går tilbake til mitt vanlige... ... forskjell, som vanlig bruker, så vil du se, jeg får ikke lov... ... og jeg får ikke lov å kjøre dette skriftet. Så da må jeg inn som administrator. Og så må jeg sette execution polter, polsier... Til... Erim Motzheim. Yes. Hvis jeg nå går tilbake, så får jeg lov å kjøre.", "source": "lecture"}
{"lecture_id": "linux9del7", "chunk_id": "linux9del7_0000", "start": 0.0, "end": 125.0, "token_count": 293, "text": "Det jeg tenkte å se litt på nå, var regulære uttrykk. Det jeg tenkte å gjøre nå, var å teste ut noen regulære uttrykk i kommandolinjen. Vi kan først prøve... Vi kan først teste ut et eksempel på hvordan man kan bruke regulært uttrykk. Dette skriptet her... Hvis jeg kaller det RegDot selv... Dette skriptet lager et regulært uttrykk her oppe. Og så er det en wildlucky som leser inn. Og så ser vi... Her har vi testen med regulært uttrykk. Er lik til det. Det er operatoren som bæsj bruker for å teste regulære uttrykk. Og det er det samme som PØL bruker. Det vi gjør, er at vi tar én og én linje i dette programmet og tester mot det regulære uttrykket. Dette er syntaks som har kommet sent, så derfor trenger vi sånn doble klamme parenteser. Og dette skriptet sier det har match hvis vi får en match. Så vi kan bare prøve å kjøre det. Hvis vi skriver inn O sånn, så ser vi at vi får en match.", "source": "lecture"}
{"lecture_id": "linux9del7", "chunk_id": "linux9del7_0001", "start": 90.0, "end": 196.12, "token_count": 286, "text": "Dette er syntaks som har kommet sent, så derfor trenger vi sånn doble klamme parenteser. Og dette skriptet sier det har match hvis vi får en match. Så vi kan bare prøve å kjøre det. Hvis vi skriver inn O sånn, så ser vi at vi får en match. Hei, så får jeg ikke noe match. Hva med en O? Nei, ingenting. Men hvis jeg skriver 'hallo', så ser vi at vi får match, for da matcher jeg den biten der. Og RGX-en så sånn ut. Det er en måte man kan bruke regulære uttrykk i skjellspråk på. Så tenkte jeg skulle se noen flere eksempler. Da kan jeg prøve å gjøre det interaktivt, sånn som det er gjort i notatene. Hvis jeg har en linje som heter Hei og ho, og så ønsker jeg å kjøre et litt mer... Avansert regulært uttrykk. Vi kan starte fra starten her. Her så ser vi vi matcher linje. Er lik tilde, den sier match med det regulære uttrykket som kommer her. Og dette er da det regulære uttrykket.", "source": "lecture"}
{"lecture_id": "linux9del7", "chunk_id": "linux9del7_0002", "start": 172.8, "end": 260.52, "token_count": 285, "text": "og så ønsker jeg å kjøre et litt mer... Avansert regulært uttrykk. Vi kan starte fra starten her. Her så ser vi vi matcher linje. Er lik tilde, den sier match med det regulære uttrykket som kommer her. Og dette er da det regulære uttrykket. Og prikk betyr den prikken som står der. Den prikken, det betyr match med... Match hvilket som helst tegn. Hvis dere ser i forelesningsnotatene lenger ned her, så har jeg listet opp noen av de viktigste regulære uttrykkene. For de av dere som har programmert til Java, så har dere kanskje brukt regulære uttrykk der. Og det er stort sett de samme regulære uttrykkene. Dette bygger delvis på PØL-regulære uttrykk. Men det er noen koder som er vanlige regulære uttrykk, som man ikke kan bruke i bæsjcell. F.eks. siffer. Så har dere kanskje brukt det i regulære uttrykk slash d. Men i utgangspunktet kan man ikke gjøre det i skjell-regulære uttrykk.", "source": "lecture"}
{"lecture_id": "linux9del7", "chunk_id": "linux9del7_0003", "start": 244.88, "end": 349.94, "token_count": 292, "text": "som man ikke kan bruke i bæsjcell. F.eks. siffer. Så har dere kanskje brukt det i regulære uttrykk slash d. Men i utgangspunktet kan man ikke gjøre det i skjell-regulære uttrykk. Man må bruke klammeparentes og null til ni for å matche et siffer. Det vi også illustrerer i dette regulære uttrykket, som generelt er veldig nyttig, er å kunne trekke ut noe av det man matcher. Hvis jeg setter parentes rundt det i det regulære uttrykket jeg vil matche, så legges det som er inni parentesen og matches, inn i en variabel som heter ra. Som heter batch. Bæsj rematch. Når vi kjører den der, så får jeg en match. For det matcher jo Hei og ho. Og så ser vi at den matchen jeg fikk inn, er Hei og... For det var det som sto inni parentesen her. Det er match én eller flere vilkårlige tegn. Og den matcher da hei og i. Det uttrykket her. Ja... Jeg ser det kommer et par spørsmål her. Skiller den på store og små bokstaver? Det er et godt spørsmål.", "source": "lecture"}
{"lecture_id": "linux9del7", "chunk_id": "linux9del7_0004", "start": 312.92, "end": 422.28, "token_count": 225, "text": "er Hei og... For det var det som sto inni parentesen her. Det er match én eller flere vilkårlige tegn. Og den matcher da hei og i. Det uttrykket her. Ja... Jeg ser det kommer et par spørsmål her. Skiller den på store og små bokstaver? Det er et godt spørsmål. Ja, den skiller på store og små bokstaver. Hvis jeg prøver å matche henne her, da. Så ser vi. Da får vi ingen match. Du er nødt til å ha... Du er nødt til å ha direkte match. Oi, hva klarte jeg der nå? Ja, det ser ut som jeg... Klarte å stoppe hele skjermen. Jeg kan hoppe over her. Prøver en gang til. Linje hei og ho. Og så matcher jeg med denne. Men som du ser, med en gang jeg prøver en stor bokstav, så får jeg... Ikke noe væsj.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0000", "start": 0.0, "end": 110.7, "token_count": 300, "text": "Ja, før pause så kom det et godt spørsmål om hvorfor det tar... Hvorfor det tok lengre tid å kjøre når man brukte to CPU-er? Altså gjøre disse... ikke beregningene, men det å øke verdien med én hele tiden. Og det... Vi kan se på det en gang til. Vi kan repetere hva vi... Gjorde. Vi kompilerte sammen disse to... Oi! Nå ser dere ikke hva jeg sier. Du viser fortsatt pauseskjerm? Sorry. Da starter vi på nytt. Tilbake til... Der var hun. Da starter vi på nytt. Vi så før pause på hvordan vi kompilerte sammen disse to programmene her. Det var da et trådprogram som kjører to tråder, som hele tiden utfører én linje. Og én linje, det er bare å øke svar med én. Så når begge gjør dette her 100 millioner ganger, så bør svaret bli 200 millioner. Og vi kompilerte sammen på denne måten. Og så kjørte vi det på denne måten. Og så ser vi at svaret ble ikke 200 mill. Og det er... Det skyldes da at man ikke synkroniserer.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0001", "start": 87.0, "end": 200.2, "token_count": 300, "text": "så bør svaret bli 200 millioner. Og vi kompilerte sammen på denne måten. Og så kjørte vi det på denne måten. Og så ser vi at svaret ble ikke 200 mill. Og det er... Det skyldes da at man ikke synkroniserer. At disse to trådene... De kjører på hver sin CPU, og de går da ut og henter inn... Og så ødelegger de for hverandre. Men det som spørsmålet gjaldt, var om jeg tok tiden på disse her. Hvis jeg timer Adatot på den måten, så ser vi at de bruker... Ja, 1 sekund. Men mitt poeng var at det at de bruker 200 % CPU, det viser at her så bruker de de to sekundene. I motsetning til... Hvis jeg eksplisitt med task-sett sier at nå skal begge trådene kjøre på samme suppe... Da... Da ser vi at... tiden var raskere. Her ble faktisk sluttresultatet riktig også. Det var altså noe av det vi skulle se på. Men at det går raskere her... Det kan nok skyldes at... At det tar mer tid å synkronisere mellom to CPU-er.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0002", "start": 160.44, "end": 269.96, "token_count": 291, "text": "Da... Da ser vi at... tiden var raskere. Her ble faktisk sluttresultatet riktig også. Det var altså noe av det vi skulle se på. Men at det går raskere her... Det kan nok skyldes at... At det tar mer tid å synkronisere mellom to CPU-er. Men svaret er kanskje ikke fullt så enkelt heller. For jeg testet det også. Ved å prøve å skru av den joinen som vi gjør til slutt. Men iallfall - det som kan ha en effekt, det må vi undersøke nærmere. Og det er tema for forelesning i neste uke. Og det er cashing. For neste uke skal vi se på minne. Og det som kan ha en effekt her, som gjør at det går raskere når du kjører på samme suppo, Det er at... Ja, det kan ha med cashing å gjøre. At man mellomlagrer verdien og så gjør en endring før den er skrevet helt ut til dem. Vi kan prøve å se i neste uke om vi kan finne ut av det. For da kan vi se på hvor mange sånne cash-operasjoner som utføres.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0003", "start": 251.12, "end": 329.86, "token_count": 292, "text": "At man mellomlagrer verdien og så gjør en endring før den er skrevet helt ut til dem. Vi kan prøve å se i neste uke om vi kan finne ut av det. For da kan vi se på hvor mange sånne cash-operasjoner som utføres. Så det kan ha en effekt når noe går raskere på samme CPU enn hvis man kjører det på to forskjellige CPU-er. Dette gikk på 0,34 sekunder, men så opp i 1 sekund her selv om du kjørte på to forskjellige CPU-er. Men akkurat den biten, den ser vi på neste gang. Men nå skal vi konsentrere oss om... ikke om timingen, men om det som kjøres... Det som skjer når vi kjører på samme SIPU og på forskjellige SIPU-er. Så vi kan gjenta det vi... det vi gjorde. Hvis jeg nå ikke tenker på tiden, bare kjører av-og-taut, så ser vi når jeg kjører dette programmet på to forskjellige SIPU-er... Så selv om dette bare er én enkel institusjon, så blir sluttresultatet forskjellig hver gang.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0004", "start": 306.18, "end": 395.72, "token_count": 296, "text": "Så vi kan gjenta det vi... det vi gjorde. Hvis jeg nå ikke tenker på tiden, bare kjører av-og-taut, så ser vi når jeg kjører dette programmet på to forskjellige SIPU-er... Så selv om dette bare er én enkel institusjon, så blir sluttresultatet forskjellig hver gang. Fordi de driver og henter ut samme verdi og overskriver hverandres resultater. Men hvis jeg kjører på... på samme suppe, så ser vi... Da blir resultatet riktig hver gang. Og det er fordi når det bare er én institusjon her, så blir dette som en atomisk operasjon. Men forskjellen er at vi låser ikke minnebussen. Men vi kan ikke ha en contex-switch som ødelegger for denne atomiske operasjonen. For da... Hvis det skjer en contex-switch, så er enten så er denne institusjonen ferdig, eller så er den ikke ferdig. Så en contex-switch vil ikke kunne ødelegge for dette. Men hvis de kjører på to forskjellige CPU-er, som vi ser her oppe... Da trenger det ikke å være kontekster som kommer midt inn i en kode.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0005", "start": 376.36, "end": 460.64, "token_count": 291, "text": "så er enten så er denne institusjonen ferdig, eller så er den ikke ferdig. Så en contex-switch vil ikke kunne ødelegge for dette. Men hvis de kjører på to forskjellige CPU-er, som vi ser her oppe... Da trenger det ikke å være kontekster som kommer midt inn i en kode. Da kommer de omtrent likt ut til dem for å hente inn verdien. Etterpå skal jeg prøve å tegne opp litt hvorfor dette skjer, og prøve å forklare enda litt mer detalj. For det er viktig å få med seg akkurat den biten her. Men før vi kommer så langt, så skal vi se på et annet eksempel. For eksempel hvor jeg har en ikke-minimal.s, men minimal-2.s. For å gjøre det litt enklere enn det jeg viste fram før pause. For der hadde jeg kode som var lagd av GCC. Men vi ser nå på... Dette er nå assembly-kode. Og... Assembly-kode og maskinkode... Vi bruker ofte de ordene om hverandre, og det er fordi én linje assemblykode, sånn som dette, det fører til én linje maskinkode.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0006", "start": 438.36, "end": 517.56, "token_count": 297, "text": "Men vi ser nå på... Dette er nå assembly-kode. Og... Assembly-kode og maskinkode... Vi bruker ofte de ordene om hverandre, og det er fordi én linje assemblykode, sånn som dette, det fører til én linje maskinkode. Så hvis det er enkelprosent-dax, det blir direkte oversatt til nulldeler og enere. Men det vil alltid være sånn at én assemblykodelinje, det blir én maskinkodelinje. Så dette kan man stole på, at dette er det operativsystemet ser. Derimot, hvis du har høynivåkode... Så kan det være at én linje høynivåkode kan gi flere linjer maskinkode. Eller asemblykode. Men i dette tilfellet så ser vi, i stedet for å bare øke svar med én direkte i ram, som man kan gjøre, så har jeg delt opp dette i tre institusjoner. Først en som henter svar og legger det i EAX. Og så en institusjon som øker EAX med én. Og så flyttes resultatet ut til svaret. Det er sånn som en kompilator kan finne på å lage kode.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0007", "start": 497.92, "end": 592.3, "token_count": 295, "text": "så har jeg delt opp dette i tre institusjoner. Først en som henter svar og legger det i EAX. Og så en institusjon som øker EAX med én. Og så flyttes resultatet ut til svaret. Det er sånn som en kompilator kan finne på å lage kode. Det kan vi ikke være sikre på om dette skjer. Så hvis jeg nå prøver å kompilere med denne i stedet... Så jeg tar nå minimal to, som er denne koden. Og så prøver jeg å kjøre med Task-sett. Og da ser vi igjen så oppstår problemet. Igjen så blir det nå trøbbel. Og det er fordi her er det tre linjer med kode. Man henter inn eksplisitt fra RAM, så hentes det inn til AAX. Så økes den, og så legges den ut igjen. Og da kan vi få problemer med Urvis, og det er det som skjer. Hvis det kommer da en context switch før den har økt verdien, så kan den hoppe til den andre tråden, som nå henter inn svar på nytt, gjør en rekke økninger og legger tilbake resultatet.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0008", "start": 572.46, "end": 670.84, "token_count": 289, "text": "Og da kan vi få problemer med Urvis, og det er det som skjer. Hvis det kommer da en context switch før den har økt verdien, så kan den hoppe til den andre tråden, som nå henter inn svar på nytt, gjør en rekke økninger og legger tilbake resultatet. Men da i mellomtiden så er denne første prosessen, den er frosset her. Den vil øke da på... den verdien som den hentet inn, og så skrivende ut igjen. Og da blir det trøbbel. Da blir det trøbbel. Men... Hvis vi derfor i stedet bruker minimal.s... Denne, med bare én enkelinstitusjon... Så komponere på nytt. Én enkel instruksjon, så kjøre med Taset. Da vil hver eneste gang så får man riktig svar. Fordi vi ikke kan komme en context-witch inne i den operasjonen. Ja... Da skal jeg prøve å ta en pause... Men skal vi se... Her. Jeg tenkte jeg bare skulle prøve å forklare... hva som skjer her. Hvis vi tenker oss... Hvis vi tenker oss at dette er CPU1...", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0009", "start": 630.0, "end": 779.92, "token_count": 298, "text": "Fordi vi ikke kan komme en context-witch inne i den operasjonen. Ja... Da skal jeg prøve å ta en pause... Men skal vi se... Her. Jeg tenkte jeg bare skulle prøve å forklare... hva som skjer her. Hvis vi tenker oss... Hvis vi tenker oss at dette er CPU1... Og så har vi... skal vi se... sånn... En buss som går opp til RAM her oppe. Her er han. Og det som skjer hele tiden, er at her oppe i Ramm så har vi en adresse hvor vi har en arabel som heter'svar'. Og la oss si'svar nå er kanskje 10'. Så... Det som da skjer... Vi kan ta det første eksempelet først. Hvor vi bare har én institusjon her, som heter INK-L. INK-lung. Svar av... Altså det er én institusjon som øker den verdien. Da er det opplagt ikke noe problem hvis denne her kjører helt alene. Da vil vel den bare hente... I én institusjon så øker den da verdien. Men på en eller annen måte... Den kan ikke... Den må på en eller annen måte hente inn verdien her. Så verdien vil gå på data.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0010", "start": 763.12, "end": 874.8, "token_count": 294, "text": "Da vil vel den bare hente... I én institusjon så øker den da verdien. Men på en eller annen måte... Den kan ikke... Den må på en eller annen måte hente inn verdien her. Så verdien vil gå på data. Det er en del av hele denne maskininstitusjonen INK med svar. Den henter inn verdien, øker med en og legger den tilbake i én enkelt operasjon. Men da er det klart... Da kan vi ha problemer her hvis... CPU2, den også gjør den samme operasjonen. Og så er jo begge de to koblet på... Dette er buss. De er koblet på den samme bussen. Og de snakker med hverandre og henter inn verdier. Men da er problemet hvis disse to CPU-ene ikke er koordinerte. Sånn som de generelt. Så vil... De vil da operere samtidig. Og hvis verdien her oppe er 10, så vil begge de to hente ned verdien 10. Og de vil da måtte... Den verdien vil da lagres i et register her nede. Vi lagrer det ikke eksplisitt i registeret. Den maskininstruksjonen som gjør dette,", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0011", "start": 840.0, "end": 944.4, "token_count": 288, "text": "Så vil... De vil da operere samtidig. Og hvis verdien her oppe er 10, så vil begge de to hente ned verdien 10. Og de vil da måtte... Den verdien vil da lagres i et register her nede. Vi lagrer det ikke eksplisitt i registeret. Den maskininstruksjonen som gjør dette, den må lagre et register, og så må de sende verdien inn i aluen osv. Den må i hvert fall kanalisere den tieren der inn i aluen, sånn at aluen øker den med én. Og så må den sende 11 tilbake. Men da er det klart... Da får vi allerede et problem hvis de gjør dette her. Helt samtidig. Ber om den tieren. Da kommer det en tier kjørende ned der. Disse bitene sendes over bussen. En tier inn her og en tier inn der. Og så øker begge... Øker den til 11 med alu. Og så sender begge 11 tilbake. Her går det... Dette går ikke bra fordi at... Uansett hvilken som da kommer først tilbake... Uansett så vil 11 lagres her oppe.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0012", "start": 915.44, "end": 1016.36, "token_count": 293, "text": "Og så øker begge... Øker den til 11 med alu. Og så sender begge 11 tilbake. Her går det... Dette går ikke bra fordi at... Uansett hvilken som da kommer først tilbake... Uansett så vil 11 lagres her oppe. Og det som skulle ha skjedd, det er at 12 skulle ha blitt lagret. Fordi begge har lagt til. Og det er da... Det er da vi kommer inn med den smarte tingen at vi legger på en... Lokk. Der skal det stå 'lokk'. Vi legger på en lokk foran. Foran institusjonen. Og det som skjer da, er at da... La oss si den CPU1 gjør dette her først. Den lokker da hele databussen. Nå får ingen andre lov til å... endre på den variabelen. Det vil jo ikke gjelde alle. Men man sjekker at den ene variabelen der... Her skal ingen andre kunne... Den skal ingen andre kunne endre. Og det som skjer da, er at da får CPU1 i fred og ro utføre sin alun øke fra 10 til 11, sende den tilbake på bussen, og denne her går opp til 11.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0013", "start": 996.66, "end": 1084.08, "token_count": 296, "text": "Her skal ingen andre kunne... Den skal ingen andre kunne endre. Og det som skjer da, er at da får CPU1 i fred og ro utføre sin alun øke fra 10 til 11, sende den tilbake på bussen, og denne her går opp til 11. Og så, i neste omgang, når den er ferdig, og så i neste omgang, når den er ferdig, Med den ene institusjonen. Så får CPU2 utføre sin institusjon. Den hadde kanskje prøvd å gjøre det samtidig, men så fant den ut at databussen var lokket. Den var låst, så da måtte den vente litt. Og da begynner CPU2 på sin operasjon. Og den vil da, istedenfor å hente inn 10, så vil den hente inn 11. Og den får da resultatet 12, og så sendes det tilbake. Og så blir det 12 her. Og alt ble riktig. Så det går fint med... med lokk. Men så var det det som skjedde med... når vi kjører Task-sett. Så... ja. Vi kan kanskje ta... Vi tar en ny figur ved, så ser vi på Task-sett. Du vil bare ha én CPU.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0014", "start": 1053.2, "end": 1177.76, "token_count": 291, "text": "Så det går fint med... med lokk. Men så var det det som skjedde med... når vi kjører Task-sett. Så... ja. Vi kan kanskje ta... Vi tar en ny figur ved, så ser vi på Task-sett. Du vil bare ha én CPU. Én CPU her, og så har vi ramme her oppe. Og her har vi svar. Svar likt 10. Og da er det litt greiere, for hvis vi bare sier... Da skjer den operasjonen der. Det er bare én institusjon. Så da vil det hele tiden være sånn at hvis du... Hvis jeg gjør ink-svar, så henter jeg ut tallet ti. Den tar databussen inn til Alund. Alund... Får inn 10, sender 11 tilbake. Og så kommer det 11 opp her. Og dette er da én operasjon. Men så har jeg nå to prosesser, eller to tråder, som kjører samtidig på denne CPU-en. Og da vil det liksom være P1 og P2. Men gjett gitt P1 og P2. De har liksom en... Et lite område, en sånn PCB her oppe, hvor de har sine verdier lagret.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0015", "start": 1154.08, "end": 1247.68, "token_count": 290, "text": "eller to tråder, som kjører samtidig på denne CPU-en. Og da vil det liksom være P1 og P2. Men gjett gitt P1 og P2. De har liksom en... Et lite område, en sånn PCB her oppe, hvor de har sine verdier lagret. Ops... Dårlig kulepenn. Der. P1 og P2 har sine verdier lagret her oppe. Og når det gjør en context switch, så henter man inn de gamle verdiene. Men da er poenget her... Når vi kjører et task-sett, og vi bare har én institusjon, så da så vi at en context switch hadde ikke noe å si. For da utføres den institusjonen her ferdig, og det går bare én i operasjon. Så hver gang prosess én er inne og gjør dette her, så økes det pent fra 10 til 11, og så kanskje kommer P2 inn og skal jobbe. Men hente ut verdien 11, for P1 er jo ferdig med den. Kjøre ned til aluen og øke igjen. Da kommer den opp til 12. Og alt går fint. Men det som ble problemet, er...", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0016", "start": 1223.96, "end": 1341.54, "token_count": 290, "text": "så økes det pent fra 10 til 11, og så kanskje kommer P2 inn og skal jobbe. Men hente ut verdien 11, for P1 er jo ferdig med den. Kjøre ned til aluen og øke igjen. Da kommer den opp til 12. Og alt går fint. Men det som ble problemet, er... Hva skjer om vi bruker den koden som... Det var det andre tilfellet vi kjørte. Da var det tre instruksjoner. Og da så vi at da ble det også trøbbel for... Selv om vi kjørte Task-sett. Og da har vi to prosesser, P1 og P2, og det var litt sånn som det med den MILD-en som vi så på. Da, selv om det bare er én CPU og én buss, så får vi problemer. For da vil... La oss si vi har verdien 11 her, da. Så er det Prosess P1 som kjører, henter inn verdien 11 og legger den i AX. Og så kommer det en Context Switch. Og da ligger da verdien 11... Den vil da lagres i PCB for P1. Og den verdien 11, den ligger der, da.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0017", "start": 1312.18, "end": 1397.16, "token_count": 287, "text": "For da vil... La oss si vi har verdien 11 her, da. Så er det Prosess P1 som kjører, henter inn verdien 11 og legger den i AX. Og så kommer det en Context Switch. Og da ligger da verdien 11... Den vil da lagres i PCB for P1. Og den verdien 11, den ligger der, da. Og så kommer den Context Switch akkurat etter den instruksjonen der. Så starter P2 å kjøre, og den vil da begynne på koden her og hente inn verdien 11, som ligger i svar, inn i sitt register. Og så øker den den og legger ut osv. Og da vil da P2 kunne gjøre det en rekke ganger. 100 ganger, kanskje. Så den kommer opp i et svar på 111 her oppe. Og så kommer den kontekst-witch-tilbake, og så er det P1 sin tur. Men da vil jo P1 begynne å operere på sin gamle 11 som ligger der. Den legges inn i registrene, og så øker den AX-men og får 12. Og så sendes 12 ut. Og da ser vi...", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0018", "start": 1380.0, "end": 1492.84, "token_count": 291, "text": "Og så kommer den kontekst-witch-tilbake, og så er det P1 sin tur. Men da vil jo P1 begynne å operere på sin gamle 11 som ligger der. Den legges inn i registrene, og så øker den AX-men og får 12. Og så sendes 12 ut. Og da ser vi... Da blir det totalt kaos, fordi det var tre linjer her. Men hvis jeg kjørte Task-sett... Og tvang begge prosessene til å kjøre på... på samme CPU. Så så vi at ink svar, med én enkel operasjon, så fungerte det som det skulle. Da fikk vi ikke noe trøbbel. Så hvis vi hopper tilbake hit... Gjenta den problemstillingen... Når vi kjørte en enkel institusjon sånn som dette... Så gir Tasset det samme svaret. Fordi da blir det på en måte automisk. Selv uten å bruke lokk så får vi samme svar. Derimot... Derimot hvis jeg bruker... Oi... Her. Hvis jeg bruker minimal to, med tre instruksjoner... Vi kjører Tasset... Oi. Der brukte jeg minimal én. Minimal to.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0019", "start": 1457.84, "end": 1588.72, "token_count": 299, "text": "Selv uten å bruke lokk så får vi samme svar. Derimot... Derimot hvis jeg bruker... Oi... Her. Hvis jeg bruker minimal to, med tre instruksjoner... Vi kjører Tasset... Oi. Der brukte jeg minimal én. Minimal to. Komplirer med minimal to, og så kjører Tasset. Så ser vi hver gang det blir forskjellig. Og det er fordi... Og det er fordi verdiene overskriver hverandre. Fordi det da skjer en context switch på akkurat feil feilse. Ok. Det var enda litt mer detaljer rundt Lundstaset og Sepur. Det er litt vanskelige problemstillinger, så derfor prøvde jeg å legge inn enda litt mer tid på det. Ok. Da skal vi tilbake og se på noen slider. Og X86-institusjonslokk, så nå skal vi se på semaforer. Semaforer er et begrep som er mye brukt når det gjelder synkronisering. Og semaforer, de... Det er en slags teller. Så en binær semafor, altså en semafor som bare har 0 eller 1, det er akkurat som en mytex.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0020", "start": 1567.0, "end": 1672.04, "token_count": 294, "text": "Semaforer er et begrep som er mye brukt når det gjelder synkronisering. Og semaforer, de... Det er en slags teller. Så en binær semafor, altså en semafor som bare har 0 eller 1, det er akkurat som en mytex. En semafor kan ha flere verdier. Du kan f.eks. starte med Slake T. Da har man ti ressurser som man kan bruke opp før man må vente og synkronisere med andre. På en semafor har man to metoder som man bruker. Og SIGMO-S, det signaliserer nå... Nå er alt klart. Semaforer er jo et gammelt begrep som handler om flagg. At man bruker sånne tegn for flagg for å sende signaler over lange avstander. Så dette er semaforer som da brukes til å sende tegn prosesser imellom. Dijkstra, som er en nederlandsk professor som på 60-, 70-tallet... Han la grunnlag for mye av dette med synkronisering og den Dijkstra-algoritmen som vi skal se på i oppgavene. Og han fant på dette begrepet - semaforer.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0021", "start": 1637.72, "end": 1735.52, "token_count": 298, "text": "Så dette er semaforer som da brukes til å sende tegn prosesser imellom. Dijkstra, som er en nederlandsk professor som på 60-, 70-tallet... Han la grunnlag for mye av dette med synkronisering og den Dijkstra-algoritmen som vi skal se på i oppgavene. Og han fant på dette begrepet - semaforer. Hvis dette skal implementeres riktig, så må de være uninterruptable. Altså... De må være atomiske, sånn at det ikke kan komme en kontekst-switch midt inni her. Og det gjør man da ofte med hardware-støtte. Og de operasjonene man gjør... Her så ser vi at så lenge S er mindre enn lik 0, så venter man. Og så minsker man. La oss si at S i utgangspunktet er 5. Vil alle som går inn i vekt, de vil senke det nedover. Men når den når 0, da vil den ikke gå lenger ned. Da er det et signal til andre. Her må man stå på vente. Men hvis vi starter med S1, så vil en semafor se ut som en mytex. Så en binær semafor som enten er 0 eller 1,", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0022", "start": 1714.68, "end": 1805.32, "token_count": 294, "text": "Men når den når 0, da vil den ikke gå lenger ned. Da er det et signal til andre. Her må man stå på vente. Men hvis vi starter med S1, så vil en semafor se ut som en mytex. Så en binær semafor som enten er 0 eller 1, den er akkurat som en lokk eller som en mytex. Da kan man bruke semaforer akkurat som vi har gjort tidligere. Tidligere sa vi get mutex og release mutex, men her ville vi nå ta wait-s og signal-s. Men de har da den tilsvarende egenskapen. Da kan man kjøre et kritisk avsnitt inni, og da... Når man gjør wait-s, så setter man s lik 0. Det er da et signal til alle andre. At de må stå og vente. Ja, vi har sett... generelt med mutexer... Og hvis man gjør det med software, lager den type mutexer, så bruker man busy waiting. Og det er opplagt en ulempe. Operativstemme har den store fordelen at det kan styre prosesser og sette dem inn og ut av køer. Så dette er en... Dette er da en implementasjon av semafore reoperativsystemet.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0023", "start": 1787.0, "end": 1876.64, "token_count": 300, "text": "så bruker man busy waiting. Og det er opplagt en ulempe. Operativstemme har den store fordelen at det kan styre prosesser og sette dem inn og ut av køer. Så dette er en... Dette er da en implementasjon av semafore reoperativsystemet. Og da kan... Hvis vi starter med wait, så kan en... Hvis en ressurs er opptatt og man må vente, så kan operativsystemet blokkere den prosessen og legge det i en venteliste. Det fine med det er at da tas bare prosessen ut av ready-list. Og den vil ikke måtte stå og vente med en busy waiting, altså stå med en løkke og kjøre CPU-en om og om igjen. Den vil da bare legges på vent. Og så, når andre prosesser er ferdig, og gjør en signal, så kan operativstemaet se at OK, S økes med én. Ja, da kan vi vekke opp neste prosess fra ventelisten. Den prosessen opp som har ligget og ventet. På den måten får man en veldig ryddig og effektiv måte på å synkronisere prosesser. Og det er et viktig poeng at operativsystemet legger til rette", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0024", "start": 1854.56, "end": 1946.22, "token_count": 298, "text": "Ja, da kan vi vekke opp neste prosess fra ventelisten. Den prosessen opp som har ligget og ventet. På den måten får man en veldig ryddig og effektiv måte på å synkronisere prosesser. Og det er et viktig poeng at operativsystemet legger til rette for at programmerere kan synkronisere med sånn som signal await, mens det er programmereren som må skrive kvoten som gjør det. Så operativstemme synkroniserer ikke for programmererne. Det er programmererne som må gjøre dette, men operativstemme legger til rette ved f.eks. å kunne tilby semaforer. Vi skal se veldig kort på hvordan man kan bruke semaforerkritisk avsnitt.  For dette ligner da veldig på hvordan man bruker getmytex og releasemytex. Det er det samme systemet. Men vi ser her Prosess A. Den kjører da kode som ikke er kritisk. Og når du skal inn i kritisk kode, det er skrevet her K1, K2, K3, den er kritisk, så gjør man en wait, og etterpå signal som signaliserer da... ... nå er jeg ferdig. Og da må PB...", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0025", "start": 1926.92, "end": 2006.06, "token_count": 293, "text": "Men vi ser her Prosess A. Den kjører da kode som ikke er kritisk. Og når du skal inn i kritisk kode, det er skrevet her K1, K2, K3, den er kritisk, så gjør man en wait, og etterpå signal som signaliserer da... ... nå er jeg ferdig. Og da må PB... Og annen kode også gjøre det samme. Og allerede her så ser vi at når dette er overlatt til programmereren, så er det klart at programmereren fort kan gjøre feil. La oss si at programmereren glemmer å gjøre en wait-sr. Da kan begge komme inn i kritiske asyn samtidig. Så det er overlatt til programmereren å kode dette riktig. Så det kan fort bli feil. Men hvis man programmerer riktig... Så... Så kan det skje noe sånt som dette her. Du starter med B-en, og så sier den at den skal gå inn i kritisk avsnitt. Så kommer det en kontekst-switch, og da starter A-en. Og så ønsker A-en også å gå inn i kritisk avsnitt. Nå står det kontekst-switch her. Dette vil også fungere for...", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0026", "start": 1984.38, "end": 2063.38, "token_count": 290, "text": "Du starter med B-en, og så sier den at den skal gå inn i kritisk avsnitt. Så kommer det en kontekst-switch, og da starter A-en. Og så ønsker A-en også å gå inn i kritisk avsnitt. Nå står det kontekst-switch her. Dette vil også fungere for... Fordi her brukes også den samme mekanismen at bussen stenges av når man gjør weight- og signal på den fellesvarianten. Så med en gang prosessen her gjør weight, så ser vi at operativsystemet legger den da i kø. Den tar den ut av ready-list. Og så vil den ligge der og vente. Så følges den inn, så kommer den tilbake til ProsessB. Som kjører ferdig sitt kritiske avsnitt, signaliserer:\" Nå er jeg ferdig.\" Og så fortsetter han å kjøre sine vanlige instruksjoner. Før til slutt A kommer tilbake og kjører ferdig sitt kritiske avsnitt, og signaliserer da til alle andre prosesser:\" Nå er jeg ferdig.\" Så i dette tilfellet her så brukes semafor akkurat som en mytex.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0027", "start": 2041.28, "end": 2117.82, "token_count": 297, "text": "Nå er jeg ferdig.\" Og så fortsetter han å kjøre sine vanlige instruksjoner. Før til slutt A kommer tilbake og kjører ferdig sitt kritiske avsnitt, og signaliserer da til alle andre prosesser:\" Nå er jeg ferdig.\" Så i dette tilfellet her så brukes semafor akkurat som en mytex. Så i dette tilfellet her så er det ikke noen forskjell på en mytex og en semafor. Semaforen har bare... En semafor som er binær, som har enten verdi 0 eller 1. Det er det samme som en Mytex. Men en semafor kan også ha høyere verdi. En semafor kan f.eks. starte på 5 og så gå nedover til 0. Eller den kan starte på 1 og så kan man gå nedover til større negative verdier. Så semafor er... forskjellig fra Mytex på den måten. at den kan ha flere verdier. Vi kan også bruke semaforer til å synkronisere to prosesser. Det trenger ikke nødvendigvis ærlig et kritisk avsnitt, men det kan bare være sånn at du har en prosess B.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0028", "start": 2096.5, "end": 2178.64, "token_count": 294, "text": "at den kan ha flere verdier. Vi kan også bruke semaforer til å synkronisere to prosesser. Det trenger ikke nødvendigvis ærlig et kritisk avsnitt, men det kan bare være sånn at du har en prosess B. Den må vente til en prosess A er ferdig med noe i sin kode. Da er det den programmereren som gjør dette her. Etter kodelinje A3. Så skal Prosess A sende et signal til Prosess B. \"'Nå er jeg ferdig. Nå kan Prosess B ta over...' 'Kanskje bruke noe av det jeg har lagd.'\" Og så kjøres inn kode. Det kan oppnås med semaforer. Hvis man installerer den til null, så vil denne koden sørge for at A aldri går videre før B har kommet inn. Og igjen så kan vi se på det... Hvis B når frem først... Så da er ikke A klar, og da er det et signal S er lik 0. Og da senkes denne til minus 1. Og så kommer A fram til den er ferdig med sin kodedel. Og så sender den signal S ved at S økes det igjen. Og dermed kommer B inn.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0029", "start": 2149.58, "end": 2240.94, "token_count": 282, "text": "Og igjen så kan vi se på det... Hvis B når frem først... Så da er ikke A klar, og da er det et signal S er lik 0. Og da senkes denne til minus 1. Og så kommer A fram til den er ferdig med sin kodedel. Og så sender den signal S ved at S økes det igjen. Og dermed kommer B inn. Og hvis A når det først strømmer, så er det enda enklere. Da økes S til 1. Og det er et signal. Så når B kommer litt, bare minker den seg igjen og går rett videre med sin kode. Så på den måten kan semaforer brukes til å synkronisere mellom... Mellom prosesser. Ja, jeg skal se på noen eksempler på låsemekanismer som ble brukt i Linux-hjernen. For kjernen selv. Den må hele tiden bruke låser. Fordi kjernen kjører ikke bare på én CPU. Den kan kjøre på flere CPU-er samtidig, og den kan også kontekstfixes. Kjernen består av mange tråder som jobber uavhengig av hverandre.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0030", "start": 2216.5, "end": 2310.2, "token_count": 279, "text": "For kjernen selv. Den må hele tiden bruke låser. Fordi kjernen kjører ikke bare på én CPU. Den kan kjøre på flere CPU-er samtidig, og den kan også kontekstfixes. Kjernen består av mange tråder som jobber uavhengig av hverandre. Og dermed må de synkroniseres. Man bruker bl.a. atomiske operasjoner. Spinlocks er faktisk mye brukt på operativsystemnivå, for det er en veldig enkel metode. Man bare står og spinner på én verdi. Det er en enkel og sikker måte. Men det er klart, de må da kodes sånn at den ikke bruker veldig mye tid. Semaforer brukes også i Linux-hjernen. Og så er det noen sånne read-all-right-locks, som bruker for å koordinere hvor mange som skriver og leser på. Vi så forrige gang på Java-kode, som var litt tilsvarende til de P3-trådene. Det var en saldo, så hadde vi én tråd som hele tiden økte saldoen, Hele tiden minsket saldoen.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0031", "start": 2271.66, "end": 2365.36, "token_count": 286, "text": "som bruker for å koordinere hvor mange som skriver og leser på. Vi så forrige gang på Java-kode, som var litt tilsvarende til de P3-trådene. Det var en saldo, så hadde vi én tråd som hele tiden økte saldoen, Hele tiden minsket saldoen. Så sa vi at når de to trådene kjørte uavhengig av hverandre, så ble det kaos. Akkurat som i den figuren hvor jeg prøvde å tegne inn hva som skjer, så kunne det når som helst komme en context witch. Og vi så også på Java-koden at én oppdatering, saldo pluss alike én, den tilsvarte flere... Java bite-kode-instruksjoner. Sånn at der kunne det komme en Context-switch midt inni det kritiske avsnittet. Og dermed, selv om vi kjørte task-sett med Java-koden, så... Så ødela trådene for hverandre. Og da tilbyr heldigvis Java monitorer. Monitorer er en del av programmeringsspråket. Og det er på en måte enklere og sikrere å bruke", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0032", "start": 2346.16, "end": 2426.48, "token_count": 281, "text": "Og dermed, selv om vi kjørte task-sett med Java-koden, så... Så ødela trådene for hverandre. Og da tilbyr heldigvis Java monitorer. Monitorer er en del av programmeringsspråket. Og det er på en måte enklere og sikrere å bruke Semaforer eller metoder hvor du må ha get-mutex og release-mutex fordi... Fordi da programmereren ikke kan glemme å gjøre en get-mutex. Og det er fordi den synkroniserte metoden bruker en monitor som synkroniserer hele kodebiter-avgangen. Så dette gjør det enklere for programmereren. Og måten vi kan løse... Problemet vi hadde sist, er å... Én måte å gjøre det på er å synkronisere en kodeblokk. Da må vi først ha et static objekt. Jeg kaller det lokk. Dette er da låsen. Den er da felles for de to trådene. Og så, før et kritisk avsnitt, så kan vi bare si synchronized lock. Lage en kodeblokk rundt det avsnittet. Og hvis vi gjør det...", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0033", "start": 2405.4, "end": 2484.22, "token_count": 285, "text": "Da må vi først ha et static objekt. Jeg kaller det lokk. Dette er da låsen. Den er da felles for de to trådene. Og så, før et kritisk avsnitt, så kan vi bare si synchronized lock. Lage en kodeblokk rundt det avsnittet. Og hvis vi gjør det... Så sørger Java for resten. Da vil koden bli synkronisert. Og vi må gjøre synkronisert lokk. Det må vi gjøre for begge de kodeblokkene. Både den som øker med én, og den som minker med én. Og da vil vi se inni bite-koden... Vi så på det sist at hvis vi gir Java payments private, så kan vi se på bite-koden som genereres når vi kompilerer Java. Da får vi bite-kodet, og det er dette som Java-virtuellmaskinen ser. Og da så vi sist... Her er området hvor saldoen økes. Da henter man saldoen fra ram. Øker den med én... Nei, så legger man en konstant én på stacken. Og så i add vil da legge sammen de to verdiene øverst på stacken.", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0034", "start": 2461.74, "end": 2549.7, "token_count": 295, "text": "Og da så vi sist... Her er området hvor saldoen økes. Da henter man saldoen fra ram. Øker den med én... Nei, så legger man en konstant én på stacken. Og så i add vil da legge sammen de to verdiene øverst på stacken. Så hvis den henter inn saldo lik tid, så økes den med igjen. Og så skrives ut 11. Men da ser vi igjen... Her hentes først... GetStatic henter ut saldoen. Så hvis det kommer en kontekstvisj her, så kan det potensielt gå over til den andre tråden, som ødelegger. Akkurat på samme måte som tidligere. Men så ser vi... Når vi har lagt inn den synchronized lock-biten her, så dukker det opp en monitor enter og en monitor exit. Og da sørger Yawa i samarbeid med operativsystemet for at dette avsnittet er kritisk. Sånn at ved hjelp av samme mekanismer så låses da også bussen, sånn at dette fungerer selv om trådene kjører på forskjellige sepuer. Bussen låses sånn at den saldoverdien...", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0035", "start": 2532.5, "end": 2622.14, "token_count": 292, "text": "for at dette avsnittet er kritisk. Sånn at ved hjelp av samme mekanismer så låses da også bussen, sånn at dette fungerer selv om trådene kjører på forskjellige sepuer. Bussen låses sånn at den saldoverdien... Det er ingen andre som kan hente ut den fra Aram før monitor exit kommer. Før man når monitor exit. Og på denne måten så vil man da kunne synkronisere Java-kode. Så en løsning på det... En litt annen løsning som man også kunne Og det er oppgaver om dere denne uken. Det er å lage en synchronized metode. Istedenfor å bare ta en kodeblokk, så lager du en hel metode som er synchronized. Da er det viktig at det bare er akkurat det kritiske avsnittet her. For dette tar også tid. Ja... Det ser ut som vi har brukt mye tid her, så vi skal straks gi oss. Men det er et spørsmål her til slutt... Hvorfor er det viktig at denne metoden er static? Det er vel en oppgave som også går på dette her. Jo, det er viktig at denne metoden er static,", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0036", "start": 2597.96, "end": 2681.64, "token_count": 299, "text": "Ja... Det ser ut som vi har brukt mye tid her, så vi skal straks gi oss. Men det er et spørsmål her til slutt... Hvorfor er det viktig at denne metoden er static? Det er vel en oppgave som også går på dette her. Jo, det er viktig at denne metoden er static, for hvis ikke så vil jo hver tråd som startes, vil ha sin egen metode. Og da hjelper det ikke at den er synkronisert, for da er den bare synkronisert med seg selv. Denne metoden må være static, sånn at det er den samme metoden for alle trådene. Hvis ikke, så fungerer det ikke. Ja, helt til slutt, message passing er en litt annen måte å synkronisere på. Og som oftest brukes veldig mye distribuerte systemer, hvor man da ikke bare har CPU-er på samme maskin, men CPU-er på samme maskin. Og forskjellige servere rundt omkring i verden. Da er det opplagt at hvis man har felles ressurser, så kan man ikke sette på lokk. Det hjelper ikke å stenge Rambussen. Da må man kommunisere sånn at man sikrer", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0037", "start": 2660.06, "end": 2748.98, "token_count": 294, "text": "hvor man da ikke bare har CPU-er på samme maskin, men CPU-er på samme maskin. Og forskjellige servere rundt omkring i verden. Da er det opplagt at hvis man har felles ressurser, så kan man ikke sette på lokk. Det hjelper ikke å stenge Rambussen. Da må man kommunisere sånn at man sikrer at man f.eks. ikke endrer på noen fellesverdier. Så message-passing er en sånn generell måte for å kommunisere mellom prosesser på. Men den er litt mer tungvint. Da må du sende beskjeder frem og tilbake. Så det er ikke like kjapt som semaforer og montor. Ja... Jeg har et avsnitt om deadlock også, men da tenker jeg vi bare utsetter den biten om deadlock til neste uke. Og så... Så stopper vi her foreløpig. Og da er det som sagt... En masse oppgaver rundt dette her i... i oppgavene. Jeg fikk ikke gått inn på synkronisert og Java-koden, men hvis dere jobber med oppgavene, så kan dere se hvordan det gjøres. Da får dere det litt eksplisitt...", "source": "lecture"}
{"lecture_id": "os12time2", "chunk_id": "os12time2_0038", "start": 2717.7, "end": 2793.94, "token_count": 251, "text": "Og så... Så stopper vi her foreløpig. Og da er det som sagt... En masse oppgaver rundt dette her i... i oppgavene. Jeg fikk ikke gått inn på synkronisert og Java-koden, men hvis dere jobber med oppgavene, så kan dere se hvordan det gjøres. Da får dere det litt eksplisitt... Da kan dere teste ut og se hvordan Java-koden kan synkroniseres. Altså med task-sett er det forskjell om javatronene kjører på samme CPU eller ikke. Og det er... Vanligvis, hvis du ikke bruker task-sett, så settes de på hver sin CPU av operativstem. Men med task-sett så kan du se hva det er som skjer hvis de kjører på samme CPU. Og det er tross alt operativstemmen som styrer dette, så det kan jo være at de kjører på samme CPU. Men du kan ikke garantere det, med mindre du setter opp tasser. Så se på det i oppgaven.", "source": "lecture"}
{"lecture_id": "linux6del3", "chunk_id": "linux6del3_0000", "start": 0.0, "end": 109.2, "token_count": 283, "text": "Alle Linux-brukere er med i en gruppe. Og hvis man skal se hvilke grupper man er med i, så kan man bruke kommandoen groups. Hvis jeg bruker groups på group 100, så ser vi at groups er med i group 100 og i sudo. Og vi ser at default gruppe, det er group 100 for filer som... Lages av denne gruppen. Av denne brukeren. Så... Men det går an å endre gruppe som en fil er med i. Og det bruker man command change group eller chrp på. Og jeg kan da endre til en gruppe som denne brukeren er med i. Change group sudo for fil.tk. Hvis jeg nå lister filene på nytt... Så ser vi at denne filen er eid av sudogruppen. Eller det vil si, alle som er med i sudogruppen, har disse rettighetene til gruppen. Så hvis vi endrer rettigheter for fil.taxi til la oss si 775... Skal vi se at nå har de som er med i sudogruppen, har alle rettigheter, både read, write og execute, til denne filen, fil.tkc. Man marer ut for å lage nye grupper.", "source": "lecture"}
{"lecture_id": "linux6del3", "chunk_id": "linux6del3_0001", "start": 76.06, "end": 203.52, "token_count": 297, "text": "Så hvis vi endrer rettigheter for fil.taxi til la oss si 775... Skal vi se at nå har de som er med i sudogruppen, har alle rettigheter, både read, write og execute, til denne filen, fil.tkc. Man marer ut for å lage nye grupper. Så vi kan f.eks. lage med adgroup, så kan man lage en ny gruppe. Da sier jeg at vi lager en studgruppe. Og da må jeg oppi passord. Sånn. Nå har det blitt lagd en studgruppe på systemet med gruppe-id 1001. Og da kan vi grepe studg på et group. Da vil vi se at stut-gruppe nå har en linje i etc.-gruppe. Og så kan man da f.eks. legge til brukere til denne gruppen. Så jeg kan da ta... For å legge til brukere, så må jeg ha sudo-rettigheter. Add user. La oss si jeg ønsker å legge til nå... Group 100 til gruppen Stud... Gruppe, på den måten. Hvis jeg nå igjen ser i Etse-passord på Grepper etter Stud-gruppe, så ser vi at Group 100 har nå blitt medlem av den Stud-gruppen.", "source": "lecture"}
{"lecture_id": "linux6del3", "chunk_id": "linux6del3_0002", "start": 172.14, "end": 286.04, "token_count": 291, "text": "så må jeg ha sudo-rettigheter. Add user. La oss si jeg ønsker å legge til nå... Group 100 til gruppen Stud... Gruppe, på den måten. Hvis jeg nå igjen ser i Etse-passord på Grepper etter Stud-gruppe, så ser vi at Group 100 har nå blitt medlem av den Stud-gruppen. Så kan vi gi alle som er medlem av denne nye Stud-gruppen, rettigheter til... For eksempel fil.txt. Og det gjør vi da med Change Group. Skjeve GRP til Studgruppe for fil.txt. Men da ser vi... Dette får vi ikke lov til, og vi burde få lov til det. Så lenge vi er med i gruppen... I denne studiegruppen, så burde jeg få lov. Men vi ser, selv om det står at vi er med her, så dukker ikke den opp når vi gjør groups. Så det man da må gjøre, er bare å logge ut og inn igjen for at det skal tre i kraft. Hvis jeg nå skriver 'groups', så ser vi at nå er jeg med i studiegruppe. Og da kan jeg gå tilbake. 'Change group studiegruppe fil.tkc'. Da ser vi at jeg får lov.", "source": "lecture"}
{"lecture_id": "linux6del3", "chunk_id": "linux6del3_0003", "start": 263.76, "end": 331.2, "token_count": 222, "text": "Så det man da må gjøre, er bare å logge ut og inn igjen for at det skal tre i kraft. Hvis jeg nå skriver 'groups', så ser vi at nå er jeg med i studiegruppe. Og da kan jeg gå tilbake. 'Change group studiegruppe fil.tkc'. Da ser vi at jeg får lov. Og studiegruppe har endret seg til... Nei, gruppetilhørigheten har endret seg til studiegruppe. Så alle som er medlem av studiegruppe, får nå tilgang til fil.tkc. Med disse. Og man kan ikke tillegge noen grupper som man ikke er med i selv. Hvis jeg ser på Etsy Group... Hvis starten er Admo, f.eks. Hvis jeg prøver å legge til Adm, så ser du at jeg ikke får lov til det. Man får bare lov til å legge til grupper som man selv er med i. Ja.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0000", "start": 0.0, "end": 111.08, "token_count": 300, "text": "Jo, jeg har en if-main her. Jeg skal nå prøve å lage en liten rutine som utgjør en if-test. Det jeg tenkte å prøve på, var å skrive den fra scratch i Assembly, sånn at vi kan se litt mer detaljer av hva som foregår. Eller ta det bare sånn. Da kan jeg prøve å starte og lage den if-testen. Ja... Jeg kan kalle den min if fra skillen fra de andre. Det jeg trenger å vite, er at det skal være en ekstern funksjon if-test, så det navnet må jeg ha med. Og da begynner jeg fra scratch. Det jeg trenger å si, er at det er en global... Det definerer den funksjonen jeg skal lage, at den heter det. Sånn at C kan få tak i den. Og så er det en label-if-test. Det er en slags standard måte å starte en funksjon på. Og den koden jeg skal lage... Vi kan se... Ja. Har en... Skal vi se... Den koden ser sånn ut. Jeg kan ta med den... Dette her ønsker jeg nå å lage. Så jeg kan kanskje ta med den inn i koden her, sånn at vi har et utgangspunkt.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0001", "start": 84.16, "end": 188.3, "token_count": 294, "text": "Og den koden jeg skal lage... Vi kan se... Ja. Har en... Skal vi se... Den koden ser sånn ut. Jeg kan ta med den... Dette her ønsker jeg nå å lage. Så jeg kan kanskje ta med den inn i koden her, sånn at vi har et utgangspunkt. Sånn at de ser hva vi skal lage. Skal vi kommentere det... Sånn. Så tankene her er bare å illustrere hvordan man kan lage en if-test. Vi har lagd en foreloocker. Og med foreloocker så kan de også lage en vile. Det blir omtrent det samme. Så hvis vi kan lage en if-test nå, så vet vi omtrent hvordan alt som er av kode, lages i maskinkode. Det vi kan starte med, det er altså... Skal vi prøve å få dette til å virke? Det er å ha et lite dataavsnitt. Og der har jeg en variabel som jeg kaller svar. Det er den svar her oppe som er 32. Og da kan jeg si... Ja, jeg kan bruke koden. Sette av... 64 bit. Åtte bytes til en kode som... ja, som inneholder tallet 32.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0002", "start": 159.22, "end": 261.24, "token_count": 283, "text": "Og der har jeg en variabel som jeg kaller svar. Det er den svar her oppe som er 32. Og da kan jeg si... Ja, jeg kan bruke koden. Sette av... 64 bit. Åtte bytes til en kode som... ja, som inneholder tallet 32. Det definerer den. Og så kan jeg... Bare for å se at dette her virker, så kan jeg bare teste først... Flytt tallet én til rax, og så returner. Da vil jo denne... Den assembly-koden her nå, den gjør da ingenting. Den skal bare returnere én. Jeg tenker bare å gjøre det her nå... Først for å se om alt funker. Det kan være smart sånn at... Etterpå, når jeg skriver mer kode, så kan jeg være sikker på at det grunnleggende virker, i hvert fall. Da skal jeg lime den sammen med if main. Så... Den skal sammen med if main. Ja, der fikk jeg en warning... Ja, det er bare en warning. Jeg tror det er bare et linjeskift. Så vi kan se om den kjører. Ja, den kaller gif-test. Og så returnerer den svaret.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0003", "start": 231.26, "end": 365.2, "token_count": 295, "text": "Da skal jeg lime den sammen med if main. Så... Den skal sammen med if main. Ja, der fikk jeg en warning... Ja, det er bare en warning. Jeg tror det er bare et linjeskift. Så vi kan se om den kjører. Ja, den kaller gif-test. Og så returnerer den svaret. Så det var en god start. Det var ikke noe linjeskift her, så jeg tror da var det mer. Men da skal jeg prøve å lage kode som lager en if-test. For vi har en variabel svar her, som vi tenker oss er et eller annet tall. Og så skal vi... Den skal, hvis svaret er større enn 42, så skal den returnere 1, og ellers skal den returnere 0. Ja, hva skal vi gjøre da... Jo, vi kan starte med... Det er jo 42 som er liksom tallet vi skal sammenligne med. Så vi kan starte med å legge 42 i et register. Da kan vi bare velge hvilket register vi vil. La oss si jeg bruker RBEX. Så skal jeg nå sammenligne da svaret med dette tallet. Så... Og da må jeg ha en compare. Håper det er litt på egen hånd, det.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0004", "start": 313.38, "end": 448.4, "token_count": 296, "text": "Så vi kan starte med å legge 42 i et register. Da kan vi bare velge hvilket register vi vil. La oss si jeg bruker RBEX. Så skal jeg nå sammenligne da svaret med dette tallet. Så... Og da må jeg ha en compare. Håper det er litt på egen hånd, det. Jeg skal nå sammenligne RBX og svar. Og det kan rett og slett skrives sånn. En variabel kan bare skrives direkte sånn. Det vil da... Jeg ber nå... Dette er en institusjon som skal sammenligne de bitene som ligger her ute. Jeg sammenligner nå 42 med svar. Og så... så skal jeg hoppe. Da vil jeg hoppe hvis den er større igjen. Jg, det er jump greater than. Da kan jeg hoppe til et sted hvor det er større. Eller en linje hvor det er \"-greater\". Da husker vi fra simuleringen at da var det en sånn bransjekontroll, og den bransjekontrollen styrte dette her med hopping. Men da må jeg ha et eller annet sted en linje hvor det står -greater. Så her har jeg da en label som heter -greater. Og så vet jeg...", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0005", "start": 425.0, "end": 503.96, "token_count": 284, "text": "Da husker vi fra simuleringen at da var det en sånn bransjekontroll, og den bransjekontrollen styrte dette her med hopping. Men da må jeg ha et eller annet sted en linje hvor det står -greater. Så her har jeg da en label som heter -greater. Og så vet jeg... Hvis jeg hopper til greater, da er den større enn 42, da skal jeg returnere 1. Og det kan jeg jo få til ved at jeg tar tallet 1, at jeg har en dollar foran når jeg skal skrive tall... Jeg tar tallet 1, og så legger jeg det i rax. For rax, det er det som returnerer sluttverdien. Så da har jeg på en måte den biten riktig. Men... Så må jeg jo prøve å se hva det er som skjer hvis... Altså, jeg skal ha en elsker igjen også. If svarer 42, da skal jeg returnere igjen. Jo, men det jeg rett og slett kan gjøre da, da kan jeg bare gå inn etter jumpgrater. For hvis... Hvis testen slår til, og den er grater, så hopper den til grater.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0006", "start": 485.08, "end": 593.72, "token_count": 294, "text": "Altså, jeg skal ha en elsker igjen også. If svarer 42, da skal jeg returnere igjen. Jo, men det jeg rett og slett kan gjøre da, da kan jeg bare gå inn etter jumpgrater. For hvis... Hvis testen slår til, og den er grater, så hopper den til grater. Og hvis ikke, så vil den fortsette å bare utføre koden nedover her. For vi vet at når den ikke hopper, så utføres bare neste kodelinje. Neste kodelinje kan jo da være å putte null i prosent arrives. For da har vi fått til den elskeren. Men da blir det dumt hvis jeg nå hopper... Hvis jeg ikke gjør noe mer nå... Så kan vi se hva som skjer. Men det må jeg ha lenger ned her... Så må jeg ha en return. Og så return sånn. Og det som skjer her nå... Det er da verdi returneres i prosent av hex. Eller... Ja, liksom. Så... Vi kan se... Vi kan prøve å se hva som skjer... Når jeg kjører dette her... I dette tilfellet, når jeg har svaret er 32, så skal den jo helst returnere null.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0007", "start": 570.0, "end": 689.0, "token_count": 294, "text": "Eller... Ja, liksom. Så... Vi kan se... Vi kan prøve å se hva som skjer... Når jeg kjører dette her... I dette tilfellet, når jeg har svaret er 32, så skal den jo helst returnere null. Så vi kan prøve å komplere og se hva den returnerer. Da kompilerer jeg den sånn. Men den returnerer svar lik 1. Så det var ikke helt riktig, den koden jeg skrev. Men hva var det som var galt? Du har ikke fjernet den første returen... Kjempebra! Dette her skulle jo ikke med. Så da returnerte den den. Det var derfor den ble retur 1. Veldig bra. Da ser vi igjen. Og så ser vi kanskje for null nå. Nei. Det er fortsatt... ... får jeg svar 1. Er det noen som klarer å se hva som er galt i if-testen min nå? For at... Jeg kommer jo hit. Nei, den skal ikke slå til. Og dermed så skal jeg jo flytte null over RX. Nei, den er ikke lik, fordi jeg sammenligner 42 og 32. Altså... I sammenligningen her så sammenligner jeg RBE.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0008", "start": 648.76, "end": 790.04, "token_count": 300, "text": "hva som er galt i if-testen min nå? For at... Jeg kommer jo hit. Nei, den skal ikke slå til. Og dermed så skal jeg jo flytte null over RX. Nei, den er ikke lik, fordi jeg sammenligner 42 og 32. Altså... I sammenligningen her så sammenligner jeg RBE. Og svar er 32. Så... det som skjer... Jeg hopper ikke her, fordi den ikke er større. Og så går jeg hit, legger null i RX. Men så fortsetter den bare å gå ned til Grater. Så hvis jeg ikke gjør noe annet, så fortsetter man å kjøre linje for linje. Akkurat som den simuleringen. Og da går den til Grater, og så flytter den én til RX, og så går den til Return. Jo, det jeg må gjøre da, er at her må jeg jo legge inn... Her må jeg legge inn en jump. For jeg flytter null til rax, og da er jeg egentlig ferdig. Så jeg kunne lagt inn en return her, men jeg kan gjøre det eksplisitt og så se... OK, her vil jeg hoppe til return. Sånn, da. Jump return. Hvis jeg kommer hit, legger jeg null.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0009", "start": 758.46, "end": 878.16, "token_count": 298, "text": "Her må jeg legge inn en jump. For jeg flytter null til rax, og da er jeg egentlig ferdig. Så jeg kunne lagt inn en return her, men jeg kan gjøre det eksplisitt og så se... OK, her vil jeg hoppe til return. Sånn, da. Jump return. Hvis jeg kommer hit, legger jeg null. Og så hopper jeg over greater, sånn at ikke den blir satt. Og det er akkurat det en if-test gjør. Jeg bare sjekker først at det funker. Ja, og da ser vi. Nå returneres svarlig null. Helt riktig. Det var akkurat det jeg må gjøre. Det dere må sitte igjen med av dette, er at her ser vi hvordan en kompulator må tenke. Hvordan en kompulator da kan oversette en if-test som dette her. Her har vi en branching. Her er det en test som utføres. Og det kan alltid oversettes med denne type sammenligninger og jump statement. Det er spørsmål om man kan ha return to steder. Det er jeg ikke sikker på... Jeg kan teste. Da burde det i så fall gjøres sånn. Ja, ser ut som det går fint. Ja. Det går det an å gjøre.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0010", "start": 840.0, "end": 951.8, "token_count": 292, "text": "Og det kan alltid oversettes med denne type sammenligninger og jump statement. Det er spørsmål om man kan ha return to steder. Det er jeg ikke sikker på... Jeg kan teste. Da burde det i så fall gjøres sånn. Ja, ser ut som det går fint. Ja. Det går det an å gjøre. Så denne vil utføre det samme, for den returnerer da direkte. Men da må jeg bare dobbeltsjekke. Funker det nå hvis... Hvis svar er større enn 42? Altså hvis svar er 52? Da må jeg kompilere på nytt og så kjøre. Ja. Det ser ut til å funke fint. Og det er liksom... Det er poenget. Nå var svar 52. Og Jg hopp hvis hun er større. Og da hopper den til greater, og så flytter den movien her. Så kunne jeg teste Jg om den faktisk funker. Hvis tallet er 42, så skal den jo ikke hoppe til 1 her oppe. Da skal den returnere 0, så vi kan prøve det til slutt. Ja, da stemmer det. Den returnerer 0. Så den fungerer som den skulle.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0011", "start": 920.0, "end": 1009.78, "token_count": 282, "text": "Så kunne jeg teste Jg om den faktisk funker. Hvis tallet er 42, så skal den jo ikke hoppe til 1 her oppe. Da skal den returnere 0, så vi kan prøve det til slutt. Ja, da stemmer det. Den returnerer 0. Så den fungerer som den skulle. Så her ser vi hvordan... Hvordan man kan skrive... Dette vil egentlig si at man skriver maskinkode. For her... Assembleren, altså den GCC, når den lager maskinkode av denne, så bare oversetter den linje for linje. Den oversetter der... Move er institusjon nummer 112. Så skriver den 112, og så 42, og så adresse... RBX. Og så kodestøyen, akkurat som i simuleringen jeg har sett på tidligere. Pair blir en linje, dette blir en linje, move blir en linje osv. Så dette blir linje for linje. Det var spørsmål om hvilken verdi som reduseres når det bare står rett, og det er... RAX returneres alltid. Og det er en slags avtale med C-funksjoner.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0012", "start": 990.0, "end": 1079.98, "token_count": 296, "text": "Pair blir en linje, dette blir en linje, move blir en linje osv. Så dette blir linje for linje. Det var spørsmål om hvilken verdi som reduseres når det bare står rett, og det er... RAX returneres alltid. Og det er en slags avtale med C-funksjoner. C-funksjoner forventer å få returverdien i RAX. Nei, jeg kan ikke returnere noe som ikke er RAX. Men hvis jeg har en funksjon som... Nei, så jeg må legge den returverdien i RAX. Men hvis du kaller det en funksjon, så har du andre rutiner. Da tar funksjonen imot variabler. Hvis vi har en funksjon som har to int-variabler, men da legges de... Nå husker jeg ikke hva konvensjonen er, men da kan det være sånn at de innkomne variablene legges i rax og rbx, f.eks. Så hele tiden må man ha konvensjoner, sånn at man vet hva funksjonene skal returnere. Men når du først har det, så kan man skrive kode som dette her, og sende variabler frem og tilbake til funksjonen.", "source": "lecture"}
{"lecture_id": "os5del11", "chunk_id": "os5del11_0013", "start": 1060.12, "end": 1096.98, "token_count": 139, "text": "at de innkomne variablene legges i rax og rbx, f.eks. Så hele tiden må man ha konvensjoner, sånn at man vet hva funksjonene skal returnere. Men når du først har det, så kan man skrive kode som dette her, og sende variabler frem og tilbake til funksjonen. Men det som er viktig her, er at vi nå på en måte har en idé om hvordan enhver sånn konstruksjon som dette her, en forløkke eller en gif-test... Hvordan den produseres i maskinen.", "source": "lecture"}
{"lecture_id": "os9del11", "chunk_id": "os9del11_0000", "start": 0.0, "end": 82.0, "token_count": 242, "text": "I Windows er det en litt annen måte å starte prosesser på. Det fins ikke noe fork-kall der eller som det står her. Det har støtte for folk, men er ikke den vanlige måten å starte prosesser på. Den vanlige standardmetoden er å gjøre det kalt i create-prosess. Da sender du med ti forskjellige parametere som definerer den prosessen. Og da lanseres et nytt prosessobjekt. Windows er skrevet fra scratch som et objektorientert program. Så alt innen Windows er objekter. Det skal vi se på senere også. Når vi begynner med PowerShell, er også alt innen PowerShell objekter. Så Windows er i en veldig stor grad objektorientert. Det er ikke like sterk som det er under Linux. Da kan man lage en helt uavhengig prosess som ikke har noen kobling til parent i det hele tatt. I utgangspunktet kan man også ha en sånn kobling, men den er ikke like sterk.", "source": "lecture"}
{"lecture_id": "os14del13", "chunk_id": "os14del13_0000", "start": 0.0, "end": 95.48, "token_count": 285, "text": "Den første soft miss. Og det er en miss når page-referansen ikke er i TLB. Da må den hentes fra internminnet. Også kalt TLB-miss. Og så har vi en hard miss, eller det som er mer vanlig å kalle en major fault. Da er det en side som mangler i ram, altså i minnet, og også selvfølgelig i TLB. TLB er cash for minnereferanser, og den må hentes helt ut på disk. Og det samme... Det kalles også en major fault. En minor fault, det er når det mangler en side i pagetabellen. Da må du ikke ut på disk og hente den, men den må lages. Og vi så det. I det ene tilfellet så vi at vi skulle lage én million sider. Så da var det én million minor folts. Og selv om det går raskt, alt skjer bare i Ram og MMU, så tar det litt tid. En dirty page er en side som har blitt endret. Slik at hvis du da skal skrive ut en endetisk, så må den ut av... Hvis den skal ut av minnet og ut på disk, så må den faktisk skrives ut.", "source": "lecture"}
{"lecture_id": "os14del13", "chunk_id": "os14del13_0001", "start": 69.34, "end": 149.0, "token_count": 285, "text": "Og selv om det går raskt, alt skjer bare i Ram og MMU, så tar det litt tid. En dirty page er en side som har blitt endret. Slik at hvis du da skal skrive ut en endetisk, så må den ut av... Hvis den skal ut av minnet og ut på disk, så må den faktisk skrives ut. Hvis en side ikke er dirty, altså hvis den er akkurat som før, så kan man bare droppe den i ramm, for da ligger den allerede på såpeområdet på disken. 'Working set' er et Windows-begrep som betyr så å si akkurat det samme som Res. Eller Resident i Linux. Det er da de sidene som er i bruk, og som har vært i bruk nylig. Som ligger aktive i rom. Et segment har vi brukt noen ganger tidligere. Det er da en hel logisk del av et programs minne. Sånn som hele programteksten eller hele tag-segmentet eller heap. Altså et stort segment. Til slutt buffer cash. Det høres ut som det har noe med L1 og L2 cash osv., men det er da, som vi så, et filsystem.", "source": "lecture"}
{"lecture_id": "os14del13", "chunk_id": "os14del13_0002", "start": 127.16, "end": 157.96, "token_count": 99, "text": "Det er da en hel logisk del av et programs minne. Sånn som hele programteksten eller hele tag-segmentet eller heap. Altså et stort segment. Til slutt buffer cash. Det høres ut som det har noe med L1 og L2 cash osv., men det er da, som vi så, et filsystem. Så det er noen av de viktige minnebegrepene som dere må huske.", "source": "lecture"}
{"lecture_id": "linux4del2", "chunk_id": "linux4del2_0000", "start": 0.0, "end": 89.92, "token_count": 297, "text": "I Chellscript så er det veldig nyttig å kunne legge inn if-tester. Og vi skal nå se på syntaksen til if-tester. Aller først så skrives tester inne i klammeparanteser, sånn som dette her. Altså firkantparenteser. Så her kan jeg f.eks. skrive en test som er bare en tekststreng. Hvis jeg tar en tekststreng... F.eks. tekststrengen true, så vil denne testen her... Den vil være true. Nå ser vi... Det er vanskelig å se om vi får ikke noe resultat ut her. Men i Linux generelt så er det en returverdi... Dollar-spørsmålsdag... Og denne returverdien, den gir returverdien til programmet... Det kan man også bruke på tester. Vi ser at denne testen gir null. Og da er det faktisk sånn at... Det er på en måte motsatt av det man er vant til. Hvis alt har gått bra, så returnerer et program null. Men hvis det er noe feil eller det er falskt, så returneres én. Vi skal se senere at hvis det er falskt, så kan man også spesifisere en feilmelding med å returnere et annet tall.", "source": "lecture"}
{"lecture_id": "linux4del2", "chunk_id": "linux4del2_0001", "start": 72.8, "end": 148.86, "token_count": 292, "text": "Hvis alt har gått bra, så returnerer et program null. Men hvis det er noe feil eller det er falskt, så returneres én. Vi skal se senere at hvis det er falskt, så kan man også spesifisere en feilmelding med å returnere et annet tall. Så dette er en test som er falsk, så den vil returnere da tallet 1. Dette trenger man egentlig ikke vite for å kjøre if-tester, men det kan være en kjapp og enkel måte å teste ut det man ønsker å teste, på denne måten. Så når man skriver en if-test, så skriver man først if, og så skriver man det man ønsker å teste. Man kan f.eks. skrive if-true, sånn som dette her. Og så er syntaksen at da skal det komme et linjeskift. Og så skal det komme den, og så skal det komme hva vi ønsker å gjøre. F.eks. vi kan skrive ut ekkotru, og så slutter man med fi, altså den motsatte av if. Og så er konstruksjonen ferdig. Og da ser vi. Da ble den utført, og så skriver man ut true.", "source": "lecture"}
{"lecture_id": "linux4del2", "chunk_id": "linux4del2_0002", "start": 131.16, "end": 209.98, "token_count": 294, "text": "Og så skal det komme den, og så skal det komme hva vi ønsker å gjøre. F.eks. vi kan skrive ut ekkotru, og så slutter man med fi, altså den motsatte av if. Og så er konstruksjonen ferdig. Og da ser vi. Da ble den utført, og så skriver man ut true. Hvis jeg taster oppover tasten nå, oppover pil, så ser vi at vi får gjort denne testen om igjen. Så da kan jeg gjøre den fra kommandolinjen. Så kan jeg f.eks. teste nå det som er false. En tom streng slår ikke til, så da skjer det ingenting. Jeg kunne også prøve hva som skjer hvis jeg ikke har noe inni her. Det vil også returnere tilsvarende som false. Vi skal kjøre en sånn test. Hva blir toll-spørsmålstegn? Jo, det ble én, og den returnerer også Voss. Men med en gang jeg har noe inni parentessen, så får jeg ut null eller tru. Det vanlige er jo å sette en sånn konstruksjon inn i et skript. Så det skal vi se på nå. Vi skal se på hvordan vi...", "source": "lecture"}
{"lecture_id": "linux4del2", "chunk_id": "linux4del2_0003", "start": 185.84, "end": 274.44, "token_count": 292, "text": "Jo, det ble én, og den returnerer også Voss. Men med en gang jeg har noe inni parentessen, så får jeg ut null eller tru. Det vanlige er jo å sette en sånn konstruksjon inn i et skript. Så det skal vi se på nå. Vi skal se på hvordan vi... Skriv i et skript som bruker if-tester. Så da lager jeg en test som heter... Ja, jeg kan kalle den test.ch. Så vil jeg gjerne ha med en linje som sikrer oss at dette kjøres av Bean Bæsj. Hvis du alltid kjører deg til ubuntet, så trenger du ikke den linjen, for da vil den alltid kjøres i default-skjell. OK. Så da peiser jeg ut det jeg hadde i skjellet. Det kan være veldig nyttig å teste ting først. Så ser vi... Her står det semikolon, og det tilsvarer da et linjeskift. Så inn i et skript så er det mer naturlig å ha linjeskift. Det blir mer lesbart. Så jeg pleier å sette opp noe sånt. Så erstatter jeg samme kolon igjen med linjeskift,", "source": "lecture"}
{"lecture_id": "linux4del2", "chunk_id": "linux4del2_0004", "start": 259.04, "end": 343.2, "token_count": 284, "text": "Så ser vi... Her står det semikolon, og det tilsvarer da et linjeskift. Så inn i et skript så er det mer naturlig å ha linjeskift. Det blir mer lesbart. Så jeg pleier å sette opp noe sånt. Så erstatter jeg samme kolon igjen med linjeskift, sånn at vi får en if den, altså det som skjer, sofie-konstruksjon. Sånn. Nå har jeg det samme skriptet som jeg hadde ute i terminalvinduet, så jeg kan gå ut og prøve å kjøre den testen. Aller først kan jeg sette rettighetene sånn at jeg får kjørt den. Og så skal denne testen returnere, tru. Og det gjør den. Nå kan det jo være greit å kjøre noen tester som tester et eller annet fornuftig. La oss si jeg har en fil som heter fil.txe, og så kan jeg kanskje lage en mappe som heter Min mappe. Sånn. Og så kan jeg kjøre filtester på disse. Og da kan jeg prøve å utvide skriptet jeg hadde.", "source": "lecture"}
{"lecture_id": "linux4del2", "chunk_id": "linux4del2_0005", "start": 316.32, "end": 419.6, "token_count": 283, "text": "La oss si jeg har en fil som heter fil.txe, og så kan jeg kanskje lage en mappe som heter Min mappe. Sånn. Og så kan jeg kjøre filtester på disse. Og da kan jeg prøve å utvide skriptet jeg hadde. For å gjøre det litt realistisk, så kan jeg ta inn en fil. Vi kan lese fra første argument. Første argument er dollar én. Dollar-1 inneholder nå argumentet til dette programmet når du kjører det. Så da kan jeg f.eks. teste om dette er en fil. Det er en egen fil-test som heter \"-f\". Og dette vil nå være true hvis det finnes en fil som heter det samme som argumentet. Jeg kunne skrevet dollar-1 rett inn her, men det kan være oversiktlig for et program. Og så at man skriver hva man forventer å få som argument. Altså hva slags type argument dette er. Nå har jeg da en test som skriver... Her kan jeg kanskje skrive ut noe sånt som $fil er en fil. Sånn. Og da har jeg en fin if-test. Men kanskje jeg kan utvide den for å se på syntaksen.", "source": "lecture"}
{"lecture_id": "linux4del2", "chunk_id": "linux4del2_0006", "start": 395.16, "end": 500.44, "token_count": 289, "text": "Altså hva slags type argument dette er. Nå har jeg da en test som skriver... Her kan jeg kanskje skrive ut noe sånt som $fil er en fil. Sånn. Og da har jeg en fin if-test. Men kanskje jeg kan utvide den for å se på syntaksen. Da kan jeg sende med en elsker-en og så skrive 'els' og så 'els-klausulen'. Nå tok jeg fjernet linje med kontroll K og pester den ut med kontroll Y. En shortcut som kan være grei å kunne. Da kan jeg si at dette er jo alternativet, så dollar-fil er ikke en fil. Så da må vi legge med et argument. Så hvis jeg legger med argumentet fil.taxi, så får jeg som riktig er at fil.taxi, det er en fil. Og så la oss si jeg prøver med min mappe. Da blir filtesten falsk, og jeg får ut at min mappe er ikke en fil. Så kan jeg kanskje prøve å legge inn en test til, nemlig teste om det er en mappe. Og da er det en elsif. Man skulle tro at normalt så vil man skrive noe sånt, elsif, men det funker ikke.", "source": "lecture"}
{"lecture_id": "linux4del2", "chunk_id": "linux4del2_0007", "start": 470.28, "end": 582.2, "token_count": 290, "text": "Da blir filtesten falsk, og jeg får ut at min mappe er ikke en fil. Så kan jeg kanskje prøve å legge inn en test til, nemlig teste om det er en mappe. Og da er det en elsif. Man skulle tro at normalt så vil man skrive noe sånt, elsif, men det funker ikke. Syntaksen er ellif. Så elsif er da ellif. Så... Jeg kan igjen... Pøyse det sånn. Og da kan jeg skrive 'fil er en mappe'. Men nå glemte jeg at i LF så må det jo være en klausul. Og klausulen her, det er da at... Eller en test. Testen her må da være 'er det en mappe eller en directory?' Og det tester man med minus. Så -d. Hvis dette er en fil, så skal den nå skrive ut... Fil er en mappe. Og hvis det ikke er verken fil eller mappe, så skal den skrive ut... Ja, vi kan skrive... Er verken fil eller mappe. Sånn. Så kan vi prøve om det funker som det skal. Prøver vi først filtesten... Nei, da fikk jeg en syntakseerror.", "source": "lecture"}
{"lecture_id": "linux4del2", "chunk_id": "linux4del2_0008", "start": 555.44, "end": 645.92, "token_count": 298, "text": "så skal den skrive ut... Ja, vi kan skrive... Er verken fil eller mappe. Sånn. Så kan vi prøve om det funker som det skal. Prøver vi først filtesten... Nei, da fikk jeg en syntakseerror. Det kan være nyttig å se på, for da ser vi her på linje 10. Så er det en feil. Så kan vi gå inn i skriptet. Og så kan jeg med Escape G... Så får jeg en go to line, så kan jeg skrive 10. Og da ser vi... Her er det en feil. Og feilen er gjort at etter ellif så skal det være en den. Så... Hadde det vært gode feilmeldinger, så burde det kommet fram, men her gjør det ikke det. Men etter ellif så skal det være en den. Så da kan jeg rette det opp på den måten. Og så kan jeg prøve å kjøre på nytt. Og da ser vi da fake syntax-feil. Da funker det. Fil og tekst er en fil. Og så kan jeg teste på min mappe. Da ser vi at min mappe er en mappe. Så kan jeg f.eks. teste på et eller annet som jeg vet jeg ikke har.", "source": "lecture"}
{"lecture_id": "linux4del2", "chunk_id": "linux4del2_0009", "start": 622.4, "end": 652.0, "token_count": 101, "text": "Og så kan jeg prøve å kjøre på nytt. Og da ser vi da fake syntax-feil. Da funker det. Fil og tekst er en fil. Og så kan jeg teste på min mappe. Da ser vi at min mappe er en mappe. Så kan jeg f.eks. teste på et eller annet som jeg vet jeg ikke har. Og da får jeg beskjed om at dette er verken en fil eller en mappe.", "source": "lecture"}
{"lecture_id": "os3bdel1", "chunk_id": "os3bdel1_0000", "start": 0.0, "end": 75.28, "token_count": 275, "text": "Det første spørsmålet... Hvis input er lik 1, hva blir x og q? Først kan vi se på pollen at det er... Det ser veldig lovende ut hvis det er dette som er riktig svar. 80 % omtrent har svart x lik 0 q lik 1. Så kommer det en ener inn her. Hvis man går rett fram, kommer det en null inn i en orport. Det er det vanskelig å slutte noe av, men hvis man tar den eneren og følger den ned til den andre or-porten, så kommer det en ener inn i en or-port, og da vil det alltid gå en ener inn ut. For i en or-port er det bare en 0-0 som er i null. Så det kommer en ener her, den blir til en 0, og ganske riktig, da blir den X-en der lik 0. Og her kommer det en 0 inn i en or-port, og herfra så kommer det en ener som blir til en 0. Da går det null inn i nattporten, og dermed kommer den ene hit. Så veldig bra. Her ser vi at 71 av dere har funnet ut det. XR0 og Qlik1.", "source": "lecture"}
{"lecture_id": "os7del13", "chunk_id": "os7del13_0000", "start": 0.0, "end": 104.08, "token_count": 298, "text": "Ja... Her ser vi at jeg er på en server som heter AMDoc. Og det er den serveren som Linux-VM-ene deres kjører. Eller det vil si... Egentlig er det dokkercontainere. Dokker PC-er, så får jeg opp 100 forskjellige dokkercontainere. Som er de dere kjører. Men det jeg egentlig skulle se på, var... LSPU. Den gir litt informasjon om CPU-en. Og her så ser vi... Her står modellnavnet. AMD Epic. Og det... Epic er en... Eller Epic 7552. Det er da modellnavnet på denne prosessoren. Og den bruker Zen Z1-mikroarkitekturen, som er en mikroarkitekt... Og mikroarkitektur, det står litt om det i notatene i dag. Det er på en måte hvordan institusjonssettet er implementert av AMD. For instruksjonssettet, det er X86. Og Intel lager også CPU-er som implementerer dette institusjonssettet. Move og Ad og alle disse institusjonene er helt like. Sånn at kode som kjører på AMD, den kan også kjøres på Intel. Men hvordan dette her er implementert med LNCash", "source": "lecture"}
{"lecture_id": "os7del13", "chunk_id": "os7del13_0001", "start": 76.58, "end": 178.36, "token_count": 290, "text": "For instruksjonssettet, det er X86. Og Intel lager også CPU-er som implementerer dette institusjonssettet. Move og Ad og alle disse institusjonene er helt like. Sånn at kode som kjører på AMD, den kan også kjøres på Intel. Men hvordan dette her er implementert med LNCash og med mikrooperasjoner og med pipelining osv., det er forskjellig fra prosessor til prosessor. Og AMD og Intel har hatt helt forskjellig approach i mange tilfeller. Men vi ser dette er en 48-core prosessor. Men den har SMT, Simultaneous Multitredding. Og det er noe av det vi skal se på nå. Det er en helt annen type multitredding som foregår helt på prosessornivå. Men vi ser at den har 48 courses per socket. Og så har den... La oss se her, så står det... Så totalt sett så har den 96 uavhengige treads. Vi skal se litt nøyere hva det egentlig betyr. Men så kan vi også se da på cash. Her så ser vi det er ganske mye cash. LND er datakash. LNI er instruksjonscash. Og...", "source": "lecture"}
{"lecture_id": "os7del13", "chunk_id": "os7del13_0002", "start": 150.0, "end": 248.56, "token_count": 290, "text": "Så totalt sett så har den 96 uavhengige treads. Vi skal se litt nøyere hva det egentlig betyr. Men så kan vi også se da på cash. Her så ser vi det er ganske mye cash. LND er datakash. LNI er instruksjonscash. Og... Så LN-cash er på 3 MW. L2 er på 24 og eldre på hele 192. Og det er ganske mye mer enn det vi så på AMD K10, i den litt eldre versjonen vi hadde. OK. Så det var AMDoc som er serveren som dere kjører på. Så når dere er på... Når dere er inne på VM-ene og kjører LSCPU, så er det akkurat den samme LSCPU-en. For det er dockercontainere. De deler på den underliggende operativsystemet og da selvfølgelig også den underliggende serveren med serverscpuene. Til forskjell fra virtuelle maskiner, så kan du med dockercontainere... Når du lister, så vil du se den virkelige, fysiske serveren. Tettere på operativstemme enn det virtuelle maskiner gjør. Det kommer vi mer tilbake til senere.", "source": "lecture"}
{"lecture_id": "os8del6", "chunk_id": "os8del6_0000", "start": 0.0, "end": 87.92, "token_count": 290, "text": "Men hvordan kan OS effektivt kontrollere brukerprosesser? Jo, problemet er at vi kan ikke bare si til en prosess... OK, nå har du full kontroll på denne CPU-en. Gjør hva du vil. For da kan jo... Da får vi et problem hvis den prosessen da bare sier holdt, eller setter opp en løkke og bare står i en evig løkke og står og går. Operativsystemet skal kontrollere hver eneste instruksjon som brukerprosessen utfører. En slags emulering. Så gir det veldig mye system-overhead. Selv om det på en måte er litt det man kan se med virtuelle maskiner. Med virtualisering, sånn som KVM og WMW osv., men også med Java-virtuell maskin. Så finnes det systemer som på en måte kontrollerer alle... Men så igjen, da... For å få det effektivt så ofte så... Til syvende og sist så endrer det seg med at prosessene må få full kontroll på CPU-en. Må kunne gjøre hver institusjon uten et overhedd. F.eks. den fibonaccirekken. Hvis vi skal utføre den prosessen effektivt,", "source": "lecture"}
{"lecture_id": "os8del6", "chunk_id": "os8del6_0001", "start": 60.0, "end": 154.24, "token_count": 293, "text": "Men så igjen, da... For å få det effektivt så ofte så... Til syvende og sist så endrer det seg med at prosessene må få full kontroll på CPU-en. Må kunne gjøre hver institusjon uten et overhedd. F.eks. den fibonaccirekken. Hvis vi skal utføre den prosessen effektivt, Kontrollere hver enkelt institusjon og se at den ikke gjør noe galt i den koden. Så vi må prøve å finne en løsning på det problemet. Ja... Så... En effektiv løsning på dette problemet... Vi har allerede vært litt inne på det i prinsippet, men ikke hvordan det i praksis utføres. Men den effektive løsningen, den går da jo... Det går ut på at man bruker en hardwaretimer. I systemet så er det en hardwaretimer som da gir et begrenset tidsintervall til brukerprosessene. Og i den simuleringen som ligger ute, så bruker jeg en sånn kjøkkenklokke. Og der ringer hardwaretimeren hvert minutt. Så der er den. Men her, når vi snakker om OS-hardwaretimere,", "source": "lecture"}
{"lecture_id": "os8del6", "chunk_id": "os8del6_0002", "start": 129.22, "end": 231.0, "token_count": 286, "text": "som da gir et begrenset tidsintervall til brukerprosessene. Og i den simuleringen som ligger ute, så bruker jeg en sånn kjøkkenklokke. Og der ringer hardwaretimeren hvert minutt. Så der er den. Men her, når vi snakker om OS-hardwaretimere, så er det typisk et hundredels sekund. Veldig ofte så kommer det et sånt hardwaretimer-tick. Og da er det sånn... Ved hardware så når det kommer et tick fra timeren, så switches det til... Skal vi se... Nå må jeg se for meg det riktige her. Jo, hver gang hardware-timeren slår inn, så kommer operativsystemet inn. Da svisjes det til privilegert modus, eller kurl-mode, og så har kjernen kontrollen. Og så, i starten av... Så sier operativsystemet at nå skal den prosessen få lov å kjøre. Så da switcher operativsystemkjernen til brukmodus. Og så laster den inn den første instruksjonen. Det kan være set ice like 1. Det er typisk førsteinstruksjonen til koden som skal kjøre.", "source": "lecture"}
{"lecture_id": "os8del6", "chunk_id": "os8del6_0003", "start": 210.0, "end": 303.68, "token_count": 297, "text": "Så sier operativsystemet at nå skal den prosessen få lov å kjøre. Så da switcher operativsystemkjernen til brukmodus. Og så laster den inn den første instruksjonen. Det kan være set ice like 1. Det er typisk førsteinstruksjonen til koden som skal kjøre. Og så får den koden stå og kjøre i et hundredels sekund. Hele hovedpoenget da, uansett hva den prosessen gjør, så vil ikke den kunne ødelegge systemet, for den vil da kjøre i brukermodus, og det er helt ufarlig. Den kan ikke hvis en utfører holdt, så skjer det ingenting. Vi kan gå tilbake og se på den koden her. Tenk deg nå, timeren går på. Operativsystemkjernen. Det switches automatisk over til curlen mode, og første operativsystemkodelinje settes inn. Så operativsystem og kontroll. Det operativsystemet gjør da, er å laste inn alt som er nødvendig for at denne prosessen skal begynne å kjøre. Og så switcher operativsystemet, for når du er i curlen mode, Den er ikke motsatt. Så du er i kernemote,", "source": "lecture"}
{"lecture_id": "os8del6", "chunk_id": "os8del6_0004", "start": 280.68, "end": 357.96, "token_count": 282, "text": "Så operativsystem og kontroll. Det operativsystemet gjør da, er å laste inn alt som er nødvendig for at denne prosessen skal begynne å kjøre. Og så switcher operativsystemet, for når du er i curlen mode, Den er ikke motsatt. Så du er i kernemote, så switcher du til usemote, og så legger du denne instruksjonen inn i instruksjonsregisteret. Og så overlater du full kontroll til denne prosessen. Så løper den prosessen opp og ned, opp og ned, opp og ned her milliarder av ganger, lager kjempemange ledd i firmadachi-rekken, og så går det en timer. Da kommer hardware-timeren inn. Og idet hardware-timen kommer inn, så tar operativsystemet over kontrollen. Og på den måten så kan brukerprosesser kjøre i use-motes og utnytte CPU-en direkte veldig effektivt og så mye de vil, mens hvert hundredel av et sekund så kommer operativsystemet inn og tar over og sier OK, nå er det neste prosess som kjører. Så sånn kan...", "source": "lecture"}
{"lecture_id": "os8del6", "chunk_id": "os8del6_0005", "start": 338.28, "end": 430.04, "token_count": 298, "text": "Og på den måten så kan brukerprosesser kjøre i use-motes og utnytte CPU-en direkte veldig effektivt og så mye de vil, mens hvert hundredel av et sekund så kommer operativsystemet inn og tar over og sier OK, nå er det neste prosess som kjører. Så sånn kan... Apparativsystemet kontrollerer effektivt brukerprosessene på en sikker måte uten at brukerprosessene kan f.eks. skru av helmaskinen. Dette er et minnekart, altså det bildet av ramm på hvordan brukermodus og privilegertmodus, eller corner mode, ser ut på rammenivå. Her øverst har vi den delen av minnet som er tilgjengelig fra brukermodus. Det er typisk av brukerdata og vanlige programmer. Men så er det også noe av operativsystemkjernen. Nei, ikke operativsystemkjernen, men noe av operativsystemet. Altså den delen av operativsystemet som er utenfor kjernen. Det kan være system software som ikke nødvendigvis... som heldigvis trenger å gjøre privilegerte institusjoner. Som ikke trenger det, men som utfører en del jobb", "source": "lecture"}
{"lecture_id": "os8del6", "chunk_id": "os8del6_0006", "start": 406.64, "end": 502.76, "token_count": 284, "text": "Nei, ikke operativsystemkjernen, men noe av operativsystemet. Altså den delen av operativsystemet som er utenfor kjernen. Det kan være system software som ikke nødvendigvis... som heldigvis trenger å gjøre privilegerte institusjoner. Som ikke trenger det, men som utfører en del jobb akkurat som et vanlig program utfører. Men så har du den privilegerte delen av minnet som utgjør OS-kjernen. Og her kan ikke vanlige brukerprogrammer få aksess her inne. For da kunne de endre på operativstemme. Det vil være en hackers drøm å kunne få tilgang til OS-kjernen. For da kan du virkelig endre planen for alt. Så det må vi gå oss. Og da er det igjen sånn at når modusbytt switcher til brukermodus, Og en prosess prøver å endre på noe i denne adressen her, i RAM, så får den rett og slett ikke lov. Hvis en prosess prøver å endre på noe i RAM som tilhører en annen prosess, så får den heller ikke lov. Så dette ville være styrt.", "source": "lecture"}
{"lecture_id": "os8del6", "chunk_id": "os8del6_0007", "start": 480.0, "end": 521.0, "token_count": 132, "text": "Og en prosess prøver å endre på noe i denne adressen her, i RAM, så får den rett og slett ikke lov. Hvis en prosess prøver å endre på noe i RAM som tilhører en annen prosess, så får den heller ikke lov. Så dette ville være styrt. Men den privilegerte delen av mine, den er det helt umulig å touche. Og kontrollerer da operativsystemet, alle prosessene, både CPU og ram, ved hjelp av brukermodus og køllmodus.", "source": "lecture"}
{"lecture_id": "os12del14", "chunk_id": "os12del14_0000", "start": 0.02, "end": 72.6, "token_count": 180, "text": "Når vi kjørte en enkel institusjon sånn som det, så gir Tasset det samme svaret. Fordi da... Da blir det på en måte automisk. Den selv uten å bruke lokk, så får vi samme svar. Derimot... Derimot, hvis jeg bruker... Oi... Her. Hvis jeg bruker minimal to... Med tre instruksjoner... Vi kjører Tasset... Oi. Der brukte jeg minimal én. Minimal to. Komplirer med minimal to, og så kjører Tasset, så ser vi hver gang det blir forskjellig, og det er fordi... Og det er fordi verdiene overskriver hverandre. Fordi det der skjer en context switch på akkurat feil ferdsel.", "source": "lecture"}
{"lecture_id": "os4del1", "chunk_id": "os4del1_0000", "start": 0.0, "end": 87.0, "token_count": 278, "text": "Her. Her har jeg lagt ut en del demoer. Det tok litt tid denne gangen, men de har kommet sånn etter hvert. Det mangler vel kanskje én liten video her. Men tanken er at når dere jobber med oppgavene, så kan dere se på disse videoene, altså Uke 4-oppgaver. Gjerne begynn på oppgavene og så gå til videoene hvis det er noe dere lurer på. Det er lagt ut tema for neste uke innen Linux. Og de kommer jeg til å legge ut dette temaet og videosnutter av i morgen. I tillegg, av praktisk art, så... ... ser vi at Oblig1 kommer her. Og den har innleveringsfrist fredag 5. februar. Men det er viktig at det kun er uke fire som er inkludert i obligen. Så oppgavene til neste uke, uke fem, de er... De skal leveres først i oblig to her nede. Så når du er ferdig med ukesoppgaven denne uken, så kan du levere inn obligen. Og som sagt, alle må levere inn som en OS-gruppe i Canadas.", "source": "lecture"}
{"lecture_id": "linux11del13", "chunk_id": "linux11del13_0000", "start": 0.0, "end": 119.0, "token_count": 291, "text": "Det som er kanskje enda mer genialt, er at... Dette gjelder ikke bare for piler, men det gjelder også for alle andre kommandoer. For eksempel så har vi en kommando som ps. Som lister alle prosesser. Det er også da en... Det gir ikke bare tekst, men det gir også objekter. Så vi kan... Ja, for eksempel så har vi en... Prosess som heter Idol, som er den første prosessen på Windows. Akkurat som på Linux, som også har en Idol. Og PSIdol... Da kan vi på samme måte som tidligere sende den til get member. Og så kan vi se alle metoder og properties som PS har. Da ser vi f.eks. her... Her oppe. ID. Altså ID-en til den variabelen. Den kan vi da få ut ved å ta PSIdol. Vi kunne gjøre det sånn som jeg gjorde sist, at vi lagde en variabel PS. Og så kan vi si Aker PS sin ID. Det er ID-en r0. Dette kan vi også gjøre faktisk i én operasjon. Vi kan ta PSIdol sånn som det der. Og så kan vi plukke ut ID-en og så skrive ut det. Det...", "source": "lecture"}
{"lecture_id": "linux11del13", "chunk_id": "linux11del13_0001", "start": 82.4, "end": 221.0, "token_count": 297, "text": "Vi kunne gjøre det sånn som jeg gjorde sist, at vi lagde en variabel PS. Og så kan vi si Aker PS sin ID. Det er ID-en r0. Dette kan vi også gjøre faktisk i én operasjon. Vi kan ta PSIdol sånn som det der. Og så kan vi plukke ut ID-en og så skrive ut det. Det... Det går faktisk av til mannen å tabbe gjennom... Tabbe gjennom filene. Nei. Skriv ps.idl og så tabbe, for å finne ut de forskjellige... Ikke metodene, men propertiesene som PS er. Ja. Eller fungerer det... Jeg lurer på om akkurat det ikke fungerer så bra. Her derimot, så fungerer det. Ja, da... Hvis man har.ps, så vil man kunne gå gjennom alle de forskjellige propertyene. Og så skrive ut dem. Skal vi se... For eksempel... Starttime. Den fikk jeg ikke ut. Det kan ofte være mer fornuftig å se på alle metodene først. Sende etter mål. Her har vi alle metoder og properties for PR. Ja. Og da har vi f.eks. Start-info, start-treads skal vi nevne.", "source": "lecture"}
{"lecture_id": "linux11del13", "chunk_id": "linux11del13_0002", "start": 193.08, "end": 322.8, "token_count": 279, "text": "Den fikk jeg ikke ut. Det kan ofte være mer fornuftig å se på alle metodene først. Sende etter mål. Her har vi alle metoder og properties for PR. Ja. Og da har vi f.eks. Start-info, start-treads skal vi nevne. Ser hvilke threads den har. Pat sier hvilken pat den har. Ok. Da kan vi prøve oss å se på en annen... Ja, la oss si vi lager en... Notepadprosess. Her har jeg den. Sånn ja, der har jeg Notepad i bakgrunnen. Så kan jeg skrive PS Notepad. Så kan jeg bla gjennom. Alle properties. Altså la oss si jeg nå ønsker å se på starttime. Altså når den prosessen startes opp. Da kan jeg kjøre ps.notepad, og så kan jeg ta den sin... starttime. Den startet opp 11.58. Det var nå nettopp. Men det var det jeg prøvde å gjøre i stad. Hvis jeg nå tabber gjennom her... Så kan jeg få ut alle muligheter. Det er mulig den var... La oss si... Jeg husker at den begynte på... der.", "source": "lecture"}
{"lecture_id": "linux11del13", "chunk_id": "linux11del13_0003", "start": 300.0, "end": 377.8, "token_count": 243, "text": "Den startet opp 11.58. Det var nå nettopp. Men det var det jeg prøvde å gjøre i stad. Hvis jeg nå tabber gjennom her... Så kan jeg få ut alle muligheter. Det er mulig den var... La oss si... Jeg husker at den begynte på... der. Jo, det fungerer, det. Jeg tror det var spesielt med Idol at den ikke har noen starttegn. Jo... Idle er en veldig spesiell prosess, for den starter liksom i år null med Big Bang. Så Notepad har en starttime, og den kan man finne ut om. Og da er det akkurat samme opplegget. Starttime er en daytime. Så nå vet jeg allerede at den har et år. Ikke Idle. Den har ikke noe år. Så kan jeg enkelt trekke ut året som Nopad-prosessen ble startet. Og på den måten så kan jeg hente ut all mulig informasjon jeg ønsker av våre cellabrikker.", "source": "lecture"}
{"lecture_id": "os1del1", "chunk_id": "os1del1_0000", "start": 0.0, "end": 89.74, "token_count": 287, "text": "Ja, så dette er... Her kommer dere inn i Canvas. Det jeg kommer til å bruke i år, det er... Det står en link først i Canvas, og det er en link til en kurs i det. Som ser sånn ut. Og dette er egentlig et... Når dere ser det er litt sånn farger og design fra sent 90-tall... Dette er litt sånn retro websider, men de funker ganske bra, iallfall. Og... ja, så når dere ser opplegget, så er... all informasjon dere trenger, ligger på denne ene siden. Dere ser sånn som i dag, tirsdag 5.1, så er det første OS-forelesning. Og her har jeg lagt ut notater. Også en link til slides. Og her ligger all den infoen jeg kommer til å gå gjennom. Jeg prøver å legge ut det på forhånd, så dere kan se på. Og gjerne forberede dere på denne forelesningen også. Så står det noen F-er og D-er nedover her. Og det F betyr rett og slett forelesning, sånn som i dag. Og den kommer til å gå live hver tirsdag.", "source": "lecture"}
{"lecture_id": "os1del1", "chunk_id": "os1del1_0001", "start": 68.78, "end": 164.34, "token_count": 299, "text": "Jeg prøver å legge ut det på forhånd, så dere kan se på. Og gjerne forberede dere på denne forelesningen også. Så står det noen F-er og D-er nedover her. Og det F betyr rett og slett forelesning, sånn som i dag. Og den kommer til å gå live hver tirsdag. Etter hvert kanskje i forelesningssalen, hvis smittetallene tillater det. Men så ser du at det også står en D, og det står for digital. Og det vil på en måte være en slags digital forelesning. Der kommer jeg til å gå gjennom det som er pensum for dette området. Praktisk programmering osv. Det kommer jeg til å legge ut som videoer. Relativt korte videobiter for de forskjellige delene. Da er tanken at dere i løpet av denne uka går gjennom og ser på de videoene, eventuelt leser notatene som står der. Det som da står her, det er... De vil komme som oppgaver i neste uke igjen. Her er uke to, og da er det introduksjon til Linux' kommandolinje. Så det er oppgaver for neste uke.", "source": "lecture"}
{"lecture_id": "os1del1", "chunk_id": "os1del1_0002", "start": 132.16, "end": 230.72, "token_count": 289, "text": "Da er tanken at dere i løpet av denne uka går gjennom og ser på de videoene, eventuelt leser notatene som står der. Det som da står her, det er... De vil komme som oppgaver i neste uke igjen. Her er uke to, og da er det introduksjon til Linux' kommandolinje. Så det er oppgaver for neste uke. Men så er det hele tiden ukens oppgaver, det er fokus i dag. Så det er ikke så veldig mye oppgaver i dag. Vi starter ganske rolig. Det er jo rett etter nyttår, så ja. Alle trenger litt tid på å komme i gang, det gjør jeg også. Så vi har en relativt forsiktig start, men som Ine sa, det er ganske omfattende kurs. Så det er veldig lurt å prøve å ligge litt tidlig an i løypa. Og jobb gjerne med oppgavene for neste uke allerede nå. Vi kan se veldig kort på planen. Den... Du ser det er noen obligatoriske oppgaver her. De består rett og slett av å legge sammen enkeltoppgaver fra de første ukene.", "source": "lecture"}
{"lecture_id": "os1del1", "chunk_id": "os1del1_0003", "start": 193.84, "end": 289.2, "token_count": 295, "text": "Så det er veldig lurt å prøve å ligge litt tidlig an i løypa. Og jobb gjerne med oppgavene for neste uke allerede nå. Vi kan se veldig kort på planen. Den... Du ser det er noen obligatoriske oppgaver her. De består rett og slett av å legge sammen enkeltoppgaver fra de første ukene. Fra uke én, to, tre, fire typisk blir den første obligatoriske innleveringen. I dag er det bare tre oppgaver, men vi ser at alle er obligatoriske. Så det betyr at da skal dere, når dere skal levere obligg én, så skal dere levere en rapport hvor det er svart på alle de spørsmålene som er merket obligger. Og det jeg håper du oppnår på med det der, at ikke obliggene nødvendigvis blir en sånn stor skjau, men at dere ved å jobbe... Jevnt og trøtt. Så kan dere plukke ut her det som er obliger. Sånn som her er det neste uke. De første ni oppgavene kanskje er mer sånn øve og komme i gang. Og så kommer det noen obliger etter hvert nedover her.", "source": "lecture"}
{"lecture_id": "os1del1", "chunk_id": "os1del1_0004", "start": 265.62, "end": 345.84, "token_count": 298, "text": "en sånn stor skjau, men at dere ved å jobbe... Jevnt og trøtt. Så kan dere plukke ut her det som er obliger. Sånn som her er det neste uke. De første ni oppgavene kanskje er mer sånn øve og komme i gang. Og så kommer det noen obliger etter hvert nedover her. Så det er hovedsakelig strukturen på kurset. Vi møttes her hver tirsdag. Og da er det også fire timer mellom. Så det blir en veldig én intensiv dag, men dere må også regne med å jobbe mer med kurset, spesielt med det som ligger i Linux 1, 2, 3 osv. Hvor det står onsdag, men det betyr da kan dere se eller jobbe med det når som helst. Men det er viktig at dere begynner å jobbe med det denne uken, sånn at dere neste tirsdag er klare til å jobbe med det. Med disse oppgavene. Og det som også kan være veldig nyttig, er at dere da kan komme opp med spørsmål som dere lurer på fra dette stoffet. Så kan vi også ta opp det på forelesningen sånn direkte.", "source": "lecture"}
{"lecture_id": "os1del1", "chunk_id": "os1del1_0005", "start": 326.24, "end": 370.56, "token_count": 175, "text": "sånn at dere neste tirsdag er klare til å jobbe med det. Med disse oppgavene. Og det som også kan være veldig nyttig, er at dere da kan komme opp med spørsmål som dere lurer på fra dette stoffet. Så kan vi også ta opp det på forelesningen sånn direkte. Jeg syns det fungerer veldig mye bedre hvis dere kommer med spørsmål. Og det er ofte ting som jeg ikke tenker på i det hele tatt, som dere brenner inn med. Så... Det er litt lavere terskel å spørre studenter og studenter. Så gjør gjerne det på laben, men enda bedre hvis dere spør nå når vi møtes.", "source": "lecture"}
{"lecture_id": "os14del2", "chunk_id": "os14del2_0000", "start": 0.0, "end": 108.46, "token_count": 294, "text": "Det aller viktigste å ha med seg er at internmelding eller RAM, det er da bare en rekke med bite som ligger etter hverandre. Og RAM... Random Access Memory, det er random fordi det skal ta like lang tid å hente et hvilket som helst bitt. Spesielt pga. cash, så vil vi se at det tar forskjellig tid å hente forskjellig bit. Det skal vi se på i detalj i dag, i praksis. Videre så vi mye på MMU, Memory Management Unit. Og det er da en hardware-enhet som oversetter adresser. For alle prosesser har sitt eget adresseråk. Den starter fra null og går oppover. Og dette kalles da virtuelle adresser. Og de virtuelle adressene oversettes til fysiske adresser av MMU. Så inni selve prosessen tenker den bare på adresser fra null til én gigabyte. Men de oversettes til fysiske adresser i RAM.  Og da kan minneadressering nummer 1000 f.eks. Den kan ligge i 14 367 000 i ramm. Og dette gjør at operativsystemet da dynamisk kan laste inn og ut sider av ramm, og ikke minst laste inn og ut prosesser", "source": "lecture"}
{"lecture_id": "os14del2", "chunk_id": "os14del2_0001", "start": 87.04, "end": 174.1, "token_count": 289, "text": " Og da kan minneadressering nummer 1000 f.eks. Den kan ligge i 14 367 000 i ramm. Og dette gjør at operativsystemet da dynamisk kan laste inn og ut sider av ramm, og ikke minst laste inn og ut prosesser etter hvert som det kommer nye prosesser. Og dette er helt nødvendig for et moderne operativsystem. For å kunne håndtere minnene på en ordentlig måte. Så vi så mye på det, og på PageTableEnters, som var da den minste enheten som viser hvor en side ligger. Så det man gjorde, var istedenfor bare å se på bite for bite, så lagde man sider. Typisk 4K, 4000 bite. En sånn passe side, som er da den minste enheten som man tar inn og ut av, da. I tillegg så vi på TLB. Translation Look-Aside Buffer. Det er da cash for minneadressering, og som også har en stor effekt på hvor fort ting går. Heldigvis ligger stort sett minneofflag i TLB. Man får mye treff i cash, og dermed så går det veldig mye raskere enn det ellers ville gjort.", "source": "lecture"}
{"lecture_id": "linux6del14", "chunk_id": "linux6del14_0000", "start": 0.0, "end": 89.0, "token_count": 285, "text": "Det er nyttig å kunne komprimere fra kommandolinja. Vi skal se på noen vanlige kommandoer for å komprimere. Først skal vi bare hente hit passordfilen, sånn at du kan ha noe å komprimere. Legger vi på en h på ls minus l h, så skriver vi den ut i kilobytes. Så kan vi prøve å komprimere den med GZip. GZip er kanskje den vanligste kommandoen for å komprimere på Linux. Hvis jeg noe lister på nytt, så ser vi at jeg har fått en password.gz, som er på 86K. Så det er kanskje mindre enn en tredjedel av den opprinnelige sulten. Dette er da eksakt komprimering, så man får nøyaktig det samme ut igjen når man pakker ut. Og for å pakke ut så bruker man G unzip. Og da er jeg tilbake med den samme filen. Det er en annen kommando som heter bzip2, som også kan brukes til å komprimere. Og den komprimerer litt bedre. Hvis jeg setter på smslh igjen, så ser vi det er 64k, mens...", "source": "lecture"}
{"lecture_id": "linux6del14", "chunk_id": "linux6del14_0001", "start": 65.88, "end": 190.16, "token_count": 298, "text": "Og da er jeg tilbake med den samme filen. Det er en annen kommando som heter bzip2, som også kan brukes til å komprimere. Og den komprimerer litt bedre. Hvis jeg setter på smslh igjen, så ser vi det er 64k, mens... GSIP, lagd 86K, så den komprimerer faktisk en god del bedre. En annen måte å... En annen måte å komprimere på som er nyttig, som også brukes til å pakke sammen hele mapper, det er tar. Og også tar i sammenheng med komprimering. Da kan vi gå opp og se på mappen vi hadde, som heter TMP, med noen piler og mapper. Og da kan man lage en såkalt TAR-fil... La oss kalle den TMP.tar av mappen TMP. M4TMP.tar, som ikke er... Den er ikke komprimert, men bare pakket sammen. Så kan vi f.eks. flytte den til... Til der vi var, Zipp. Og så kan vi gå dit. Og så kan vi pakke den ut. Da legger jeg på opsjon X for X. Vi kan fjerne den igjen, for man ønsker noe lignende. Det er ikke så ofte man bare bruker tar på den måten.", "source": "lecture"}
{"lecture_id": "linux6del14", "chunk_id": "linux6del14_0002", "start": 164.48, "end": 279.12, "token_count": 290, "text": "Til der vi var, Zipp. Og så kan vi gå dit. Og så kan vi pakke den ut. Da legger jeg på opsjon X for X. Vi kan fjerne den igjen, for man ønsker noe lignende. Det er ikke så ofte man bare bruker tar på den måten. Det vanligste er å komme med noe lignende. Det er ikke så ofte man bare bruker tar på den måten. Det vanligste er å komme med noe lignende. Man kan kombinere og pakke sammen i en tarefil og sippe med Gsip. Og det man gjør da, det er i en createf-feil... Men også legge på en Z for sipping. Og da er standardnavnet... Er T... Eller standard extension er TGZ. Så hvis du finner en TGZ-fil, så er det en fil som er både taret og Gsip-et. Da lages det da en fil... tmp.z. Da kan vi gjøre det samme med den. Ta med den inn til Zipp. Og så kan vi pakke den ut. Og da bruker man i en XFZ. X for extract, file Zipped. Igjen så ser vi at vi har fått ut den mappen TMP, som inneholder da alle pilene.", "source": "lecture"}
{"lecture_id": "linux6del14", "chunk_id": "linux6del14_0003", "start": 247.12, "end": 295.0, "token_count": 130, "text": "Da kan vi gjøre det samme med den. Ta med den inn til Zipp. Og så kan vi pakke den ut. Og da bruker man i en XFZ. X for extract, file Zipped. Igjen så ser vi at vi har fått ut den mappen TMP, som inneholder da alle pilene. Men i dette tilfellet så ser vi at TMP.tg.z er veldig mye mindre. Den er også da zippet. Så dette er en sånn effektiv måte å pakke ned store filsystemer på og sende dem av gårde.", "source": "lecture"}
{"lecture_id": "os4del7", "chunk_id": "os4del7_0000", "start": 0.0, "end": 84.2, "token_count": 280, "text": "Bransjekontroll er de kablene som går bort hit, så ser vi her er det statusregister og \".load pc osv. Og det er ekstremt viktig for at man ikke bare skal fortsette nedover hele tiden. Og det går an å se at det skjer noe her. Skal ikke gå inn i altfor mye detalj, men jeg kan legge på en liten kabel her på den. Bransjekontrolledningen. Og da vil vi se at når det blir et hopp i koden, så vil denne bransjekontrollen her sende en ener. Vi kan prøve å se på det først. Vi kjører litt nedover i koden. Hvis man følger med på bransjekontrollen, den er null hele veien. Og så går vi nedover. Og så kommer vi et valg, og da ser vi... Her lyser det opp i bransjekontrollen. Og det er den forrige compere-instruksjonen. Den har slått til. Jump not equal. Og da kommer jump not equal etterpå. Og den instruksjonen gjør at det sendes en ener her.", "source": "lecture"}
{"lecture_id": "os4del7", "chunk_id": "os4del7_0001", "start": 63.2, "end": 149.96, "token_count": 299, "text": "Her lyser det opp i bransjekontrollen. Og det er den forrige compere-instruksjonen. Den har slått til. Jump not equal. Og da kommer jump not equal etterpå. Og den instruksjonen gjør at det sendes en ener her. Og så ser vi altså inne i... Her er statusregisteret. Det er et register. Og det har lagret resultatet fra forrige operasjon. Vi gjør en compare først, og etterpå sjekker vi om vi skal hoppe. Og da er det basert på det som er lagret i statusregisteret. I dette tilfellet så sendes det en ener. Og det betyr, hvis jeg går opp her til den PC-en som er program counter, den teller vanligvis bare nedover i instruksjoner. Sånn at den starter på null. Program counteren starter på null her oppe, så blir den én, så blir den to osv. Men akkurat her, når det kommer et hopp, så vil program counteren settes til den verdien som man skal hoppe til. Og den ligger inne i institusjonen. Man skal hoppe til linje nummer fire. Og da utfører maskinen et hopp. Og sånn...", "source": "lecture"}
{"lecture_id": "os4del7", "chunk_id": "os4del7_0002", "start": 126.02, "end": 160.0, "token_count": 100, "text": "Men akkurat her, når det kommer et hopp, så vil program counteren settes til den verdien som man skal hoppe til. Og den ligger inne i institusjonen. Man skal hoppe til linje nummer fire. Og da utfører maskinen et hopp. Og sånn... Og dette fører til at man ikke bare går rett gjennom programmet, men at man gjør en bransje.", "source": "lecture"}
{"lecture_id": "linux11del16", "chunk_id": "linux11del16_0000", "start": 0.0, "end": 116.9, "token_count": 295, "text": "Vi har sett at LS og PS, og også alle andre command lets, de er veldig kraftige ved at de ikke bare sender ut tekst som resultat, men hele objekter. Men det er kanskje først når man bruker disse objektene i small script og onlinere, at man virkelig kan se hvor kraftige de er. Da skal jeg bare lage ett eksempel eller et par eksempler. Hvis man bruker Foreach, så er syntaksen noe sånt som dette her. Foreach dollar LS in LS... For eksempel stjerne.tk. Da lister jeg alle filer med exception.tk. Vi ser at syntaksen ligner igjen veldig på bæsjsyntaks. Men den er litt annerledes. Men det kan gjøre... Dette vil nå være løkken, så inni her så kan jeg da ta f.eks. en variablesum. Og så kan jeg legge sammen lengden av... Denne one-lineren her, den vil da ta og gå gjennom alle filer, og så vil den legge sammen lengden av de filene. Vi kan jo først se hva man egentlig får. LS-stjerne.taxi - jo, vi får ut de filene her. Summen her nå skulle da være summen av alle de filene.", "source": "lecture"}
{"lecture_id": "linux11del16", "chunk_id": "linux11del16_0001", "start": 90.0, "end": 178.36, "token_count": 289, "text": "Denne one-lineren her, den vil da ta og gå gjennom alle filer, og så vil den legge sammen lengden av de filene. Vi kan jo først se hva man egentlig får. LS-stjerne.taxi - jo, vi får ut de filene her. Summen her nå skulle da være summen av alle de filene. Så den vil være summen av de tretallene her. 8020 bite er da sørgelsen på filmen. Vi ser med en gang hvor lett det er å plukke ut dette her. Hvis vi skulle gjøre det samme i et liningskjell, så måtte man behandle teksten her og plukke ut akkurat den strengen med kanskje noe cut osv. Og så legge sammen. Så dette er en veldig elegant måte å gjøre det på. På samme måten ville man lagt inn et... Neste uke skal vi drive masse med det. Jeg vil også vise en litt annen måte man kan gjøre mye av det samme på. Som er en powerful, enda mer kraftig måte å bruke pipes på. Der man kan sa... Vi kan gjenta det samme eksempelet. LS-stjerne.tk. Så kan jeg pipe det til en...", "source": "lecture"}
{"lecture_id": "linux11del16", "chunk_id": "linux11del16_0002", "start": 154.72, "end": 251.1, "token_count": 300, "text": "Jeg vil også vise en litt annen måte man kan gjøre mye av det samme på. Som er en powerful, enda mer kraftig måte å bruke pipes på. Der man kan sa... Vi kan gjenta det samme eksempelet. LS-stjerne.tk. Så kan jeg pipe det til en... En for each-konstruksjon. Ikke bare for each, men for each object. Da vil nå hvert objekt behandles inne i denne konstruksjonen. Og da gjør jeg litt av det samme som jeg gjorde der oppe. Jeg tar sum, og så skal jeg prøve nå å legge til for each object for hvert av de objektene. Som sendes ut av lsstjerne.xe. De blir nå pipet, og så blir de tatt imot her. Så ønsker jeg å øke lengden. Nå har jeg ikke definert noen dollar ls, men da er det en default variabel, også hentet fra Linux selv. Dollar underscore. Den vil da være... Etter hvert som løkka løper gjennom, så vil den dollar underscore være verdt objekt. For hver gang inne i løkka, så vil dollar underskår være en ny fil. Og da kan jeg legge sammen lengden på vannbåten.", "source": "lecture"}
{"lecture_id": "linux11del16", "chunk_id": "linux11del16_0003", "start": 220.8, "end": 321.0, "token_count": 283, "text": "men da er det en default variabel, også hentet fra Linux selv. Dollar underscore. Den vil da være... Etter hvert som løkka løper gjennom, så vil den dollar underscore være verdt objekt. For hver gang inne i løkka, så vil dollar underskår være en ny fil. Og da kan jeg legge sammen lengden på vannbåten. Og så kan jeg skrive summen. Det ser jo litt rart ut. Summen blir det dobbelte. Og det skyldes rett og slett at jeg ikke har initiert variabelen sum. Og det kan jeg også gjøre. I starten her så kan jeg si dollar sum er lik null. Så, som i bæsj, så vil semikolon gi skille i neste... Semikolon vil kunne skille mellom to kommandoer. Så vil de to kommandoene utføres etter hverandre. Nå får sum den rette verdien. Så kan jeg legge til summe til slutt. Da får jeg straks en liten one-liner, som regner ut lengden av alle doptex-trefilder og legger dem sammen. Så på denne måten skal vi se hvor kraftig forskjellen er.", "source": "lecture"}
{"lecture_id": "os11del9", "chunk_id": "os11del9_0000", "start": 0.0, "end": 96.6, "token_count": 289, "text": "Ok. Da skal vi se på Java-tråder på vinduer. Jeg har kopiert over den samme mappa. Det er prio.java. Så jeg kan kjøre den. Eneste forskjellen var at jeg... Ba den første tråden om å sove i 3000 millisekunder, altså i 3 sekunder. Vi kan se av kjøringen hva slags prioriteter vi har. Tråd nummer to starter med prioritet 10, så den har høyest prioritet. Etter tre sekunder starter tråd nummer én med prioritet 5. Men da ser vi Windows tar virkelig hensyn til prioriteten. Den kjører bare tråd nummer to fordi den har høyest prioritet. Men så ser vi at nå endrer vi prioritet for tråd nr. 2. Og så endres den til 4. Og da er det tråd nr. 1 som har prioritet 5. Den kjører hele tiden. Så vi ser en enorm forskjell i prioriteter. Hvis en tråd har høyere prioritet enn en annen, så tar den omtrent alt som er av... Vi ser på uttid. Mens Linux default ikke bryr seg om Java-prioritet,", "source": "lecture"}
{"lecture_id": "os11del9", "chunk_id": "os11del9_0001", "start": 66.26, "end": 162.28, "token_count": 284, "text": "Og så endres den til 4. Og da er det tråd nr. 1 som har prioritet 5. Den kjører hele tiden. Så vi ser en enorm forskjell i prioriteter. Hvis en tråd har høyere prioritet enn en annen, så tar den omtrent alt som er av... Vi ser på uttid. Mens Linux default ikke bryr seg om Java-prioritet, så tar Windows ekstremt stor hensyn til det. Hvis man ser på prioritet i Windows, så er den veldig sterk. Hvis man endrer prioritetsklasser, så får man en veldig stor effekt. Og det ser vi tydelig her. Tråden som hadde prioritet fire... Den var enerådende i praksis hele veien, mens tråden som hadde prioritet nummer fem, den måtte i praksis vente til den andre var ferdig. Og så fullførte den sin jobb. Så vi kan konkludere at implementasjonen av prioritet på Java den er plattformavhengig. Som også, som sagt, så skredulerer operativstemmen, altså både Windows og Linux, veldig bra med default prioritet.", "source": "lecture"}
{"lecture_id": "os11del9", "chunk_id": "os11del9_0002", "start": 133.72, "end": 215.0, "token_count": 204, "text": "Og så fullførte den sin jobb. Så vi kan konkludere at implementasjonen av prioritet på Java den er plattformavhengig. Som også, som sagt, så skredulerer operativstemmen, altså både Windows og Linux, veldig bra med default prioritet. Sånn at dette her er ikke opplevd som noe veldig stort problem. Man kan jo da også individuelt omprioritere med nice, f.eks. Eller på andre måter prioritere. Moderne operativsystemer er så gode på å gi respons til de som trenger det interaktivt, og gi da en litt saktere respons til prosesser som bruker mye CPU. Og dette gjør da operativsystemene dynamisk på en så bra måte at det som regel ikke er noe stort behov for programmereren å gi egne... Prioriteringer til prosesser.", "source": "lecture"}
{"lecture_id": "os10del4", "chunk_id": "os10del4_0000", "start": 0.0, "end": 100.72, "token_count": 281, "text": "Mens dere holder på, kan jeg gå gjennom spørsmålene ett for ett. Det første er hvor vil A.dot.out kjøre uten ferdigmeldinger? Da kopierer jeg det med GCCM på Linux med Interm. Det vil da være Exo til seks instruksjoner. Så kopierer jeg det over til alle de andre plattformene. Så er spørsmålet hvor... På hvilke av disse plattformene vil faktisk AdoptOut kunne kjøre? Spørsmål nummer to er tilsvarende med Odoplass. Så er det poeng at den er komplett med Java 11. Og som ikke er kompatibel med alle eldre versjoner av Java. Så her er Java-versjonen riktig. Hvis det ikke var for det, så er Javahelt plattform uavhengig. Og så er det Python. Man kjører Python LLOP. Eller man kopierer LLOP til alle plattformene, og hvor kjører de uten feilmelding? Og til slutt er det tilsvarende med hello.bash. Hvor kjører den uten feilmelding? Og da... er det et poeng at...", "source": "lecture"}
{"lecture_id": "os10del4", "chunk_id": "os10del4_0001", "start": 71.2, "end": 177.0, "token_count": 259, "text": "Og så er det Python. Man kjører Python LLOP. Eller man kopierer LLOP til alle plattformene, og hvor kjører de uten feilmelding? Og til slutt er det tilsvarende med hello.bash. Hvor kjører den uten feilmelding? Og da... er det et poeng at... Det var et spørsmål i chatten i pausen om spesifikke Python-versjoner. Da svarte jeg at... Ja, som dere ser... Java kompileres når man lager en klassefil. Men i Python kompileres den ikke eksplisitt. Med Python blir programmet kompilert all the flies. Så når du kjører et Python-program, så kompileres det til bytekode, sånn som Java, men man ser ikke hvem mellomleddet. Det er i prinsippet det samme som skjer på Java, men der har man en eksplisitt kompilering til Java-pitekode. Dermed kan du få den type problemstillinger med alltid forskjellige versjoner, hvor det da ikke fungerer.", "source": "lecture"}
{"lecture_id": "os5del1", "chunk_id": "os5del1_0000", "start": 0.0, "end": 102.28, "token_count": 300, "text": "Der er oversikten. Det kanskje viktigste denne uken er at det er frist for oblig-innlevering på fredag. Og oblig-en består i alle de deloppgavene som har vært fra de siste ukene, men da ikke fra uke fem. Altså ikke oppgavene denne uken. Det er vel til og med... Denne uken. Uke fire. Når du er ferdig med obliger denne uken, kan obligen leveres inn. Så alle oppgavene fra uke fire skal leveres inn her. Så det jeg håper dere gjør, er at dere jobber jevnt hver uke. Og da vet dere hva som er obligatorisk, så gjør dere de oppgavene. Ja, altså, Ine... Du hører meg? Ja. Vi har snakket litt med... Litt om de som av forskjellige grunner er alene på en gruppe. Spesielt nå er det ikke alltid så lett å få til samarbeid. Men uansett så tenker jeg det er fornuftig å så på en måte lempe litt på kravet til god kjærlighet. Ja. Det er gøy. Jeg tenker det er rimelig. For det kan være litt ekstra utfordrende.", "source": "lecture"}
{"lecture_id": "os5del1", "chunk_id": "os5del1_0001", "start": 77.8, "end": 164.56, "token_count": 289, "text": "Spesielt nå er det ikke alltid så lett å få til samarbeid. Men uansett så tenker jeg det er fornuftig å så på en måte lempe litt på kravet til god kjærlighet. Ja. Det er gøy. Jeg tenker det er rimelig. For det kan være litt ekstra utfordrende. Det er ganske mye oppgaver. Men det aller viktigste å gjøre etter kurset er å jobbe dere gjennom oppgavene. Jeg var jo alene selv da jeg leverte. Jeg husker jo det var ganske mye mer ekstra jobb. I beregningen. Ja. Altså når vi vurderer godkjent, ikke godkjent. Ja, men det høres veldig rimelig ut. Ja. Bra. Som vanlig så er det så har jeg lagt ut digitale videoer om Shellscript. Jeg ligger litt etter deg, så jeg har ikke fått ferdig de helt siste videoene jeg får i løpet av dagen eller i morgendagen. Og så skal jeg også legge ut flere videoer om bæsj-scripting. Så det er skjellscripting som er fokus nå. Og da blir det litt mer avanserte skjellscript.", "source": "lecture"}
{"lecture_id": "os5del1", "chunk_id": "os5del1_0002", "start": 140.88, "end": 212.98, "token_count": 254, "text": "Jeg ligger litt etter deg, så jeg har ikke fått ferdig de helt siste videoene jeg får i løpet av dagen eller i morgendagen. Og så skal jeg også legge ut flere videoer om bæsj-scripting. Så det er skjellscripting som er fokus nå. Og da blir det litt mer avanserte skjellscript. Og så fra neste uke, jeg tenker dere kanskje prøver å få til det i løpet av uken, så skal jeg dele ut virtuelle maskiner til alle, sånn at alle får en virtuell maskin som dere kan logge inn på med en publikk IP-adresse. Hvor dere kan styre alt selv. Lage webservere osv. Egentlig er det ikke virtuelle maskiner. Det er dokkerinstanser som ser ut som virtuelle maskiner. Men uansett så skal vi bruke de fra neste uke, og så uken etter der igjen så skal vi begynne å kjøre dokkercontainere på disse VM-ene. Egentlig er det... Men det kommer vi tilbake til.", "source": "lecture"}
{"lecture_id": "os13del13", "chunk_id": "os13del13_0000", "start": 0.0, "end": 89.98, "token_count": 249, "text": "Ja. Da skal vi se på... Veldig kort på Linux prosess segmentation. Dette er da... Dette er da slik Linux velger å gjøre det når det legger opp minnet i RAM. Og... Det er bare noen begreper her som er nyttige å ha med seg. Vi ser... Det brukes til lokale variabler. Og så her nede har vi tekst, eller koden. Og det er da typisk den maskinkoden som programmet bruker når det kjører. Og så har vi også noe som kalles heap. Og her lagres det globale variabler og data som... Som genereres dynamisk mens programmet kjører. Det ligger på heapen. Og vi ser at den kan vokse oppover. Sånn at vi kan mens programmet kjører, så kan vi legge til dynamisk mer og mer variabler, f.eks. Eller RA, som vi skal se på senere. Også MMApp. Det er en sånn minneavbildning av filer rett inn på ram, igjen sånn at ting skal gå raskere.", "source": "lecture"}
{"lecture_id": "os4del11", "chunk_id": "os4del11_0000", "start": 0.0, "end": 69.86, "token_count": 229, "text": "Det var også spørsmål om hva som er forskjellen på address out og data out i Datapath. Og det er også et godt og viktig spørsmål. Jo, adresse ut, den sender da de fire bitene til hvilken adresse i ramm vi skal skrive til. Mens dataene, de sender her... Data out, her sendes dataene som lagres. Så i det første tilfellet, når vi skulle lagre... R3, som inneholdt 6, inn i ramm, så ble tallet 6 kablet rett inn her, til data out. Mens adressen ut... Da brukte vi R-en, som var adresse nummer 1. Da ble de fire bitene koblet inn til adresse out. Og så ble det utført en skriving av resultatet. Så det er forskjell. Men akkurat som på alle institusjoner må man trykke på de riktige knappene for å få til nettopp det riktige.", "source": "lecture"}
{"lecture_id": "os7del8", "chunk_id": "os7del8_0000", "start": 0.0, "end": 98.28, "token_count": 299, "text": "Ellen og L2Cash. Denne figuren viser prinsippene for Cash og hvorfor man kan få til å kjøre programmet fortere ved å bruke Cash. Helt til venstre på figuren her så ser vi CPU-en. Og så her står det R0R1R2 etter det. Det kunne stått AXBXXX også. Det er da registrene inni CPU-en. Disse brukes hele tiden til å mate oss inn i aluen. Problemstillingen er at denne CPU-en kan kverne veldig fort institusjoner. Den kan kverne institusjoner fortere enn RAM kan levere det. Og dermed så legger vi til dette L1- og L2-cash. Som sagt, mange har L3-cash også inne på skipen, av moderne prosessorer. Prinsippet er det samme. Så LN-cash er litt mindre. Men vi ser her i stedet for de fire... Her er det ikke bite engang, men det er fire bit. La oss si det er bite som skal inn i registrene. De fire bitene, de får plass i registrene. Og da kunne det være at CPU-en gjør en instruksjon som sier hent bite nummer 2. Opprinnelig var CPU-en sånn at OK, bite nummer to.", "source": "lecture"}
{"lecture_id": "os7del8", "chunk_id": "os7del8_0001", "start": 72.56, "end": 149.6, "token_count": 285, "text": "La oss si det er bite som skal inn i registrene. De fire bitene, de får plass i registrene. Og da kunne det være at CPU-en gjør en instruksjon som sier hent bite nummer 2. Opprinnelig var CPU-en sånn at OK, bite nummer to. Da går vi ut i ram, og så henter vi bite nummer to, som er den 1101 som ligger her oppe, og så sender vi den inn igjen. Men på den tiden så var det ikke noe forskjell på CPU og ram av betydning, sånn at det fungerte greit. Men etter hvert så har CPU-en løpt ifra og blitt raskere enn ram. Og da, i stedet for å bare hente den ene, Den biten der ute i ram, så når man da henter noe i ram, så tar man like godt med et stort område i nærheten av den biten man skal hente. Og så legger man... Så legger man det i L2-cash, hele den, så mye man får plass til, og det varierer. Og cashing, det styres på Hardner-nivå. Så dette er ikke noe som operativsystemet...", "source": "lecture"}
{"lecture_id": "os7del8", "chunk_id": "os7del8_0002", "start": 129.48, "end": 206.14, "token_count": 294, "text": "man skal hente. Og så legger man... Så legger man det i L2-cash, hele den, så mye man får plass til, og det varierer. Og cashing, det styres på Hardner-nivå. Så dette er ikke noe som operativsystemet... Så vi kommer ikke til å se på i detalj nøyaktig hvordan algoritmene for dette er. Men det styres på hardware-nivå. Så som operativstem får du ikke gjort så mye med hvordan cash virker. Men iallfall i prinsippet så virker det sånn at du tar med en stor bit av gangen. Og så tar du med en litt mindre bit, som får plass i LN-cash. Og så, inntil sepund, så tar du de nærmeste bitene. Men statistisk sett så er det veldig ofte at man trenger bite, eller data som ligger i nærheten av hverandre. Dette kan f.eks. være institusjoner som ligger rett etter hverandre. Og da er det ofte at man hopper fra institusjon 1 til 2 til 3 til 4 osv. Og da, hvis man gjør det, så vil jo alle de institusjonene ligge her i LN Cash.", "source": "lecture"}
{"lecture_id": "os7del8", "chunk_id": "os7del8_0003", "start": 191.4, "end": 259.64, "token_count": 300, "text": "Dette kan f.eks. være institusjoner som ligger rett etter hverandre. Og da er det ofte at man hopper fra institusjon 1 til 2 til 3 til 4 osv. Og da, hvis man gjør det, så vil jo alle de institusjonene ligge her i LN Cash. Og da går det veldig kjapt å hente de over til SPU. andre gang. Noen ganger er det kanskje et stort RAI som ligger i RAM, de dataene du jobber med, og da er det den samme fordelen. Jo, da ofte så skal du ha neste RAI-element. Og når du henter ut det, så går det raskt fordi du har hentet det inn i LNCash. Og det skal vi teste ut senere når vi skal se på RAM. Hvordan er forskjellen på f.eks. hvordan man indekserer en matrise? For i noen tilfeller så hopper man rundt i RAM og henter. Man rammer data som ligger rett etter hverandre i ramm. Og det går alltid mye raskere. Så dette er hovedprinsippet for cash. Dette viser det man kan kalle mikroarkitekturen for L1- og L2-cash.", "source": "lecture"}
{"lecture_id": "os7del8", "chunk_id": "os7del8_0004", "start": 235.76, "end": 314.28, "token_count": 278, "text": "For i noen tilfeller så hopper man rundt i RAM og henter. Man rammer data som ligger rett etter hverandre i ramm. Og det går alltid mye raskere. Så dette er hovedprinsippet for cash. Dette viser det man kan kalle mikroarkitekturen for L1- og L2-cash. Igjen så er det som sagt vanlig å ha en eldre cash, men i prinsippet så er den tilsvarende som level 2-cash. Her ser vi at LN-Cash har en litt spesiell arkitektur. Her står det LN-dato og LN-instruksjoner. Det betyr at her er det to forskjellige veier inn til CPU-en. Det er dette som gjør at man kan si... Dette er egentlig ikke noen van Neumann-arkitektur, hvor både datainstruksjoner går på den samme bussen. Det er van Neumann-arkitektur inn hit. Den siste biten er Harvard-arkitekturen, hvor man deler opp. Institusjoner kommer inn på én buss eller rute til CPU-en, og data kommer inn på en annen.", "source": "lecture"}
{"lecture_id": "os7del8", "chunk_id": "os7del8_0005", "start": 293.2, "end": 359.8, "token_count": 237, "text": "hvor både datainstruksjoner går på den samme bussen. Det er van Neumann-arkitektur inn hit. Den siste biten er Harvard-arkitekturen, hvor man deler opp. Institusjoner kommer inn på én buss eller rute til CPU-en, og data kommer inn på en annen. Så ser vi altså at vi har en tredje bit. TLB Transplation Look-Aside Buffer. Og det er... Nå skal vi komme tilbake til senere. Det er minneadressering. Det er en... Det bruker MMU. Og MMU, den virtualiserer minneadressene, sånn at CPU-en ikke trenger å vite nøyaktig hvor i ram enhver bite ligger. Men det kommer vi tilbake til senere, men det er også veldig viktig for effektivitet at det er hurtig. Så derfor så er det en egen bit av LNCash som er satt av til TLB, eller minneadressering.", "source": "lecture"}
{"lecture_id": "os13del7", "chunk_id": "os13del7_0000", "start": 0.0, "end": 6.94, "token_count": 18, "text": "Adresserommet... Ja, så vi trenger da å kunne adressere...", "source": "lecture"}
{"lecture_id": "os7del2", "chunk_id": "os7del2_0000", "start": 0.0, "end": 95.38, "token_count": 281, "text": "Det jeg tenkte å se på da, var å prøve å regne på en regnejobb. Dette er et lite skript som bare står og regner tre millioner ganger, så legger den sammen i lik i pluss 1. En økning med 1, og så legger den sammen og lager en sum. Det er ikke så viktig akkurat hva den gjør, men det som er poenget her, Et sånt program, det vil bruke så mye CPU som det bare kan. Helt inn står det 'bruker CPU'. Den hviler aldri. Bruker helt inn CPU. Og da kan vi se på topp samtidig. Da ser vi toppen her, som står og går. Og hvis jeg nå kjører en... Time tar tiden på regnejobben. Da ser vi at øverste linje her toppsorterer default etter hvilke prosesser som bruker mest CPU. Og øverste linje her, det vil da være regnejobben. Da ser vi ikke... Nei, vi så ikke navnet på regnejobben. Men det er fordi jeg har et lite, litt lite topp. Hvis vi drar litt lenger bort her nå... Sånn.", "source": "lecture"}
{"lecture_id": "os7del2", "chunk_id": "os7del2_0001", "start": 74.74, "end": 154.8, "token_count": 291, "text": "Og øverste linje her, det vil da være regnejobben. Da ser vi ikke... Nei, vi så ikke navnet på regnejobben. Men det er fordi jeg har et lite, litt lite topp. Hvis vi drar litt lenger bort her nå... Sånn. Der kan vi se. Dette er regnejobben som står og kjører. Og den får 100 % CPU. Ved å taste én i topp så kan jeg se hvor mange CPU-er det er. Og da ser jeg denne maskinen her. Dette er egentlig en desktop. Min desktop som står nede på OsloMet. Den har to CPU-er. Iallfall... Senere så har den egentlig fire, eller faktisk åtte, hvis du regner med hypertrening, men jeg har skrudd av de andre CPU-ene. Så i dette tilfellet så ser dette nøyaktig ut som en CPU-ei, en desktop som har to CPU-er. I forelesningshotatene så har jeg et tilsvarende eksempel med den gamle Macen min, som også har to CPU-er. Men i prinsippet så vil det skje... Nøyaktig det samme. For det vi kan prøve å få til her,", "source": "lecture"}
{"lecture_id": "os7del2", "chunk_id": "os7del2_0002", "start": 135.4, "end": 220.2, "token_count": 292, "text": "en desktop som har to CPU-er. I forelesningshotatene så har jeg et tilsvarende eksempel med den gamle Macen min, som også har to CPU-er. Men i prinsippet så vil det skje... Nøyaktig det samme. For det vi kan prøve å få til her, det er hva skjer om vi nå kjører to regnejobber samtidig. Da kan jeg lage en liten løkke for i-inn 1-2. Og så inn i den løkka så kan jeg ta og time regnejobben. Og så kan jeg legge den i bakgrunnen, sånn at det som vil skje nå, er at to regnejobber startes helt samtidig. Don. Og da ser vi i topp at her er det to regnejobber som starter. Og siden denne serveren har to CPU-er, så ser vi at de jobber på hver sin CPU. Vi så kanskje sist på at det går an å se hvilken CPU som blir brukt. Nå tasses det F i topp, og da ser vi... Vi kan styre hvilke kolonner. Som brukes. Og hvis man blar nedover her, så vil man se... Her er det en kolonne som heter Last Used CPU.", "source": "lecture"}
{"lecture_id": "os7del2", "chunk_id": "os7del2_0003", "start": 198.78, "end": 291.76, "token_count": 290, "text": "Vi så kanskje sist på at det går an å se hvilken CPU som blir brukt. Nå tasses det F i topp, og da ser vi... Vi kan styre hvilke kolonner. Som brukes. Og hvis man blar nedover her, så vil man se... Her er det en kolonne som heter Last Used CPU. Hvis jeg nå taster Space her, så får jeg et merke på den. Og Escape går nå tilbake. Og da vil jeg se... Hvis jeg lager vinduet litt større... Så vil jeg se at ytterst her så kommer det en kolonne som... Det er en statistikk på hvilken CPU ble sist brukt av prosessene som listes. Hvis jeg nå starter regnejobben på nytt, så ser vi at da er det 29.351. Den kjører på CPU1. Og 29.352, den prosessen med den i den. Så kan vi se... Det hender de bytter om. Men stort sett sånn som nå, så kjører de hele tiden på samme SUPU-er. Så kan man spørre seg - hva er det som skjer hvis jeg nå kjører tre SUPU-er? For det som skjedde med to SUPU-er...", "source": "lecture"}
{"lecture_id": "os7del2", "chunk_id": "os7del2_0004", "start": 270.0, "end": 350.68, "token_count": 283, "text": "Så kan vi se... Det hender de bytter om. Men stort sett sånn som nå, så kjører de hele tiden på samme SUPU-er. Så kan man spørre seg - hva er det som skjer hvis jeg nå kjører tre SUPU-er? For det som skjedde med to SUPU-er... Kan ta det en gang til eksplosivt. Når jeg har to SUPU-er, så er på en måte ikke dette multitasking. De kjører på to forskjellige zippe-u-er. Så de kjører reelt sett samtidig. Multitasking er når de bytter på på samme zippe-u-er. Så dette er SMP - Simultaneous Multiprocessing. Vi skal gå gjennom de begrepene senere. Men SMP, da kjører man samtidig på to forskjellige enheter. To forskjellige kjerner. Eller core. Så én core er da én regneenhet. Jeg sier ofte CPU, så da mener jeg én ren enhet. Vi kan jo ha mange cours inne på én CPU, men hvis jeg sier CPU uten å spesifisere noe spesielt,", "source": "lecture"}
{"lecture_id": "os7del2", "chunk_id": "os7del2_0005", "start": 322.1, "end": 408.04, "token_count": 284, "text": "Men SMP, da kjører man samtidig på to forskjellige enheter. To forskjellige kjerner. Eller core. Så én core er da én regneenhet. Jeg sier ofte CPU, så da mener jeg én ren enhet. Vi kan jo ha mange cours inne på én CPU, men hvis jeg sier CPU uten å spesifisere noe spesielt, så tenker jeg på en core eller en enkelt regneenhet. Og det er det også OS og Topp rapporterer det som. Så da kan vi prøve å kjøre... Skal vi se hvor vi var... Ja, den forløkken. Én, to. Så kan vi prøve å øke den forløkken til tre. Sånn at vi kjører tre prosesser samtidig. Og da ser vi... Da får de plutselig ikke 75 %, men de får noe sånt som 67 %. Her er det i hvert fall én av prosessene som bytter helt inn. For noen ganger kjører begge på én, og andre ganger kjører begge på null. Og den måten å gjøre dette på, det er fair scheduling.", "source": "lecture"}
{"lecture_id": "os7del2", "chunk_id": "os7del2_0006", "start": 378.82, "end": 461.12, "token_count": 294, "text": "Og da ser vi... Da får de plutselig ikke 75 %, men de får noe sånt som 67 %. Her er det i hvert fall én av prosessene som bytter helt inn. For noen ganger kjører begge på én, og andre ganger kjører begge på null. Og den måten å gjøre dette på, det er fair scheduling. Linux-skeduleren, altså den som fordeler hvilke prosesser som kjører hvor, den heter fair scheduler, og den prøver å gi så lik CPU-tid til... Her er det tre stykker som hele tiden vil ha CPU. Da fordeler en det ved at hele tiden kjører en på hver av CPU-ene, men så bytter man på hvilken av de tredje som kjører. Det byttes ganske ofte, noen ganger i sekundet, men ikke hele tiden, for det koster en del å bytte fra én CPU til en annen. På den måten ser vi at alle de prosessene bruker omtrent like lang tid. 25 på den ene og 26,5 på den andre og 26,7 på den tredje. Men sånn røft sett så prøver man å gi like mye CPU til hver.", "source": "lecture"}
{"lecture_id": "os7del2", "chunk_id": "os7del2_0007", "start": 436.6, "end": 526.36, "token_count": 298, "text": "for det koster en del å bytte fra én CPU til en annen. På den måten ser vi at alle de prosessene bruker omtrent like lang tid. 25 på den ene og 26,5 på den andre og 26,7 på den tredje. Men sånn røft sett så prøver man å gi like mye CPU til hver. Og sånn kan vi fortsette. Vi kan prøve å se hvordan dette her ser ut på en CPU med... Nei, på en maskin med fire CPU-er. Og det jeg skal gjøre i bakgrunnen da, det er å... Jukse litt. Ved å da skru på noen CPU-er i bakgrunnen. På den Linux-maskinen så kan jeg gjøre det fra kommandolinja. Jeg må riktignok være Ruth, men jeg kan aktivere CPU-er. Så det jeg gjorde i bakgrunnen nå, det var... Jeg skal se på hvordan jeg gjør det senere. Det var å aktivere to til av CPU-ene. At jeg skulle ha fire. Da må jeg gå inn og ut igjen med topp. Hvis jeg taster én nå, så ser vi øverst her... Jeg tastet én, og da får jeg ut at nå har denne serveren her", "source": "lecture"}
{"lecture_id": "os7del2", "chunk_id": "os7del2_0008", "start": 504.8, "end": 603.52, "token_count": 297, "text": "Jeg skal se på hvordan jeg gjør det senere. Det var å aktivere to til av CPU-ene. At jeg skulle ha fire. Da må jeg gå inn og ut igjen med topp. Hvis jeg taster én nå, så ser vi øverst her... Jeg tastet én, og da får jeg ut at nå har denne serveren her fire sepuer. Hvis jeg nå kjører akkurat samme med tre regnejobber, De tre regnejobbene er i gang, og så får de nå hver sin CPU. Hvis jeg legger inn last used CPU igjen... Så starter vi på nytt, for det var ferdige. Så ser vi at nå så står de på 3, 2 og 1. Vi kan vel også se at de står fast der, stort sett. Den som slutter på 29, står på 3. Ja, 29, den er på 3 fortsatt. 29... Ja. Stort sett, hvis det ikke er noen grunn til det, så blir de stående og kjøre på den sammen. Men da kan vi gjøre tilsvarende. Hva skjer nå om vi kjører fem og kanskje seks sepuer? Nei. Vi kjører seks prosesser på denne maskinen. Har fire CPU-er.", "source": "lecture"}
{"lecture_id": "os7del2", "chunk_id": "os7del2_0009", "start": 581.16, "end": 670.04, "token_count": 276, "text": "så blir de stående og kjøre på den sammen. Men da kan vi gjøre tilsvarende. Hva skjer nå om vi kjører fem og kanskje seks sepuer? Nei. Vi kjører seks prosesser på denne maskinen. Har fire CPU-er. Og da ser vi at... Da blir det altså firedel på seks. Det blir to tredjedeler CPU-kapasitet på hver. Og det blir omtrent 67 %. Det varierer litt opp og ned, men sånn ca. 67 %. Og så bytter man hele tiden på prosessene. 25. Så får de noe sånt som... Ja, ca. 80 % burde det bli. Men her ser vi... Ja... Man kan se det varierer litt. Øverst er det alltid én med 98. Men den får liksom en boost. Hvis du ser på totaltiden, så blir den omtrent lik til slutt. Hvis du ser på totaltiden her, så ligger de rundt sånn 21... Litt forskjeller blir det. Men i utgangspunktet så prøver Operativstemme å fordele tiden likt.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0000", "start": 0.0, "end": 89.32, "token_count": 297, "text": "Så forelesningen blir tatt opp. Aller først, før vi starter, så skal vi få et lite innslag om studentutveksling. Og det er en som dere kanskje kjenner fra... Eller dere som har hatt diskré matematikk, kjenner Eva derfra. Hun er faktisk min kone. Så... Så hun kommer nå fysisk inn på forelesningen og tar over i fem minutter. Ja, hei. Nå er jo ikke jeg her i rollen som lærer, men jeg er her som fagkoordinator for utvekslingsstudier. Og dere har mulighet til å dra til utlandet i femte semester, de av dere som ønsker det. Og hvis dere har lyst til det, så kan dere gjøre det. Dere kan sende meg en mail, og så kan vi ta et Zoom-møte og snakke om det. Men jeg tenkte også at vi skulle nå bare vise dere den siden som dere kan gå inn på. Her ser dere denne utvekslingssiden hvor dere kan gå inn på det studiet dere holder på med. F.eks. bachelor i ingeniørfag. Nei, det var biokjemi. Skal vi se om vi finner ingeniørfagdata. Der kan dere lete dere ned.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0001", "start": 64.92, "end": 132.44, "token_count": 279, "text": "Men jeg tenkte også at vi skulle nå bare vise dere den siden som dere kan gå inn på. Her ser dere denne utvekslingssiden hvor dere kan gå inn på det studiet dere holder på med. F.eks. bachelor i ingeniørfag. Nei, det var biokjemi. Skal vi se om vi finner ingeniørfagdata. Der kan dere lete dere ned. Og se hvilke steder dere kan dra ut. Det er litt avhengig av hvilket semester dere er i. Så dere må kikke litt på det også. Men uansett så er det viktigste dere trenger å vite nå, er at fristen er 1.2. Så send meg en mail litt tid før det, hvis dere er interessert. Og så innen 1.2. må dere sende en søknad. Det står her på denne siden hvordan det gjøres. Og så sender dere også et motivasjonsbrev pluss en... Man vil kikke. Det er viktig at dere har de nødvendige studiepoengene for å reise ut, samtidig som dere noen steder krever en gjennomsnittskarakter på C eller bedre.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0002", "start": 108.18, "end": 192.3, "token_count": 292, "text": "Og så innen 1.2. må dere sende en søknad. Det står her på denne siden hvordan det gjøres. Og så sender dere også et motivasjonsbrev pluss en... Man vil kikke. Det er viktig at dere har de nødvendige studiepoengene for å reise ut, samtidig som dere noen steder krever en gjennomsnittskarakter på C eller bedre. Nå er det ikke 100 % sikkert at det blir noe av utvekslingsstudiene til høsten, nettopp fordi det er jo koronatider rundt om. Og hvordan denne pandemien vil se ut om et halvt år, det er noe usikkert. Det ble avlyst i fjor, men vi har et visst håp om at det skal skje. Det var alt jeg ville si. Gå inn på denne utvekslingssiden her. Se hvor dere kan dra, ut fra hvilket studiepoengprogram dere er på og hvilket semester det gjelder. Frist er 1.2. Flopp. Ha det bra. Unnskyld? Ja, kom igjen. Hører du meg? Ja. Jo, jeg lurte litt på hvordan er det med finansiering?", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0003", "start": 157.26, "end": 285.8, "token_count": 293, "text": "Se hvor dere kan dra, ut fra hvilket studiepoengprogram dere er på og hvilket semester det gjelder. Frist er 1.2. Flopp. Ha det bra. Unnskyld? Ja, kom igjen. Hører du meg? Ja. Jo, jeg lurte litt på hvordan er det med finansiering? Hjelper skolen deg med det? Nei, det er jo avvilga. Det er steder dere skal på. Noen er gratis, og andre steder er det studiepenger. I USA f.eks. så pleier det å koste penger. Men Lånekassen pleier å være behjelpelig med å kunne bidra og låne de. Det er noe man må se på i hvert enkelt tilfelle. Jeg vil oppfordre til de av dere som har tenkt å slukke, å sende meg en mail. Så kan vi ta et Zoom-møte og se på det aktuelle studiestedet dere er interessert i. Da overlater jeg ordet til Hårek igjen. Yes. Da skal vi fortsette med datamaskinarkitektur. Og da skal jeg først vise dere en liten krets. Denne her. Og så har jeg en poll med to spørsmål.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0004", "start": 233.02, "end": 359.0, "token_count": 298, "text": "Da overlater jeg ordet til Hårek igjen. Yes. Da skal vi fortsette med datamaskinarkitektur. Og da skal jeg først vise dere en liten krets. Denne her. Og så har jeg en poll med to spørsmål. Jeg skulle egentlig hatt to poller, men det første spørsmålet er til denne figuren. Så dere må se på den først, og så svare. Så skal jeg vise dere figur nummer to, og da kan dere svare på spørsmål nummer to. Så... denne figuren er da spørsmål én er til den figuren dere ser, med input D, og så er det en X og Q. Og spørsmålet er, hvis input D er lik 1, hva blir da den verdien X her inn til denne rapporten, og hva blir verdien...? Så se litt på den figuren, og så svar når dere har kommet frem til en løsning på det. Når dere er ferdige på spørsmål 1, så ikke begynn å se på spørsmål 2. For da kommer det en annen figur. Her er en controller input. Hvis du ser en lignende, men litt annerledes figur, hvor du har kontroller...", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0005", "start": 330.0, "end": 499.64, "token_count": 292, "text": "Så se litt på den figuren, og så svar når dere har kommet frem til en løsning på det. Når dere er ferdige på spørsmål 1, så ikke begynn å se på spørsmål 2. For da kommer det en annen figur. Her er en controller input. Hvis du ser en lignende, men litt annerledes figur, hvor du har kontroller... Men, ja... vi kan godt bruke et par minutter på hver av de, eller kanskje litt mer. Hvis dere trenger mer tid. Takk. Jeg ser... Ja. Kanskje du så det. Det er flere som har skrevet at du har litt dårlig nett. Men... vi kommer tilbake til det. Men til de som... Hos meg kommer ikke det opp, så... Nei, men til de som svarer, ikke svar på spørsmål nummer to, for der har dere ennå ikke fått oppgaven. Det er en annen figur til spørsmål nummer to. Så svar foreløpig bare på oppgave. Ja, tilbake til nettet. Jeg fikk en melding jeg sa om dårlig nett. Jeg kan kjøre en test og så se. Mens dere holdt på med quizen.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0006", "start": 465.38, "end": 635.12, "token_count": 296, "text": "Nei, men til de som svarer, ikke svar på spørsmål nummer to, for der har dere ennå ikke fått oppgaven. Det er en annen figur til spørsmål nummer to. Så svar foreløpig bare på oppgave. Ja, tilbake til nettet. Jeg fikk en melding jeg sa om dårlig nett. Jeg kan kjøre en test og så se. Mens dere holdt på med quizen. Takk for møtet. Ha det bra! Ja, jeg ser opplastningen er litt opp og ned. 17 megabit per sekund, det er kanskje i underkant. Men jeg ser det er litt variasjon, det går litt opp og ned, så... Ja, si ifra hvis... Si ifra hvis problemene fortsetter, så kan jeg f.eks. stenge av videoen, det kan hjelpe. OK. Det ser ut som det var vanskelige spørsmål, dette her. Vi kan uansett gå gjennom, men vi kan nå ta... Vi kan uansett ta oppgave to. Nå ser dere forhåpentligvis en figur med en D og en C som input. Input og kontroller. Da er spørsmål to, hvis input er lik null og kontroller input er lik én,", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0007", "start": 604.5, "end": 818.7, "token_count": 296, "text": "Vi kan uansett gå gjennom, men vi kan nå ta... Vi kan uansett ta oppgave to. Nå ser dere forhåpentligvis en figur med en D og en C som input. Input og kontroller. Da er spørsmål to, hvis input er lik null og kontroller input er lik én, hva blir nå exo queue? Hvor x er da input på denne overporten. Så er det fint å innom, du ser litt på eller sier ifra hvis det er noen nettproblemer. Ja, det er ingen som har skrevet noe hos meg, så er det ikke noe problem. Men det er en del som har skrevet i stad. Men det gjelder alle, bare si ifra hvis... Men hos meg er det fint, så.  Ja, nå ser jeg antall svar begynner å ta seg opp litt der. Så det er bra. Vi kan gi dere litt mer tid. Takk for møtet. Ha en god kveld. . Jeg har 80 % svart, så jeg tenker vi stopper der og så ser vi på svarene. Sånn. Kan dere se svarene nå? Ser du dem, Ine? Jeg ser dem. Du ser dem? De kommer opp hos meg. Det er i hvert fall en som skriver ja her også.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0008", "start": 755.0, "end": 881.72, "token_count": 278, "text": "Takk for møtet. Ha en god kveld. . Jeg har 80 % svart, så jeg tenker vi stopper der og så ser vi på svarene. Sånn. Kan dere se svarene nå? Ser du dem, Ine? Jeg ser dem. Du ser dem? De kommer opp hos meg. Det er i hvert fall en som skriver ja her også. OK. Da skal vi se på det første... Det første spørsmålet. Hva blir X og Q? Først kan vi se på pollen at det er... 80 % omtrent har svart X lik 0 Q lik 1. Hvis det kommer en ener inn her, så... Hvis man går rett fram, så kommer det en null inn i en or-port. Det er det vanskelig å slutte noe av. Men hvis man tar den eneren og følger den inn til den andre or-porten, så kommer det en ener inn i en or-port, og da vil det alltid gå en ener inn ut. For i en or-port er det bare en 0-0 som er i null. Den blir til 0, og ganske riktig, da blir den X-en der lik 0. Og her kommer det 0 inn i en or-port.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0009", "start": 861.34, "end": 957.0, "token_count": 296, "text": "så kommer det en ener inn i en or-port, og da vil det alltid gå en ener inn ut. For i en or-port er det bare en 0-0 som er i null. Den blir til 0, og ganske riktig, da blir den X-en der lik 0. Og her kommer det 0 inn i en or-port. Og herfra så kommer det en ener som blir til en 0, så da kommer det 0-0 inn der. Da går det 0 inn i nattporten, og dermed så kommer det en ener hit. Så veldig bra. Her ser vi at 71 av dere har funnet ut det. X er 0 og Kulik. Det var kjempebra. Da skal vi se på neste. Det er denne. Da har vi den latchen som vi har på en kontroller. Og da er spørsmålet hvis input d er lik null og controller input er lik én. Hva blir x og q? Ja, controller input én, det skal bety at da Da skal verdien settes til den innkomne. Så det bør bli kulik null. Men igjen så kan vi se... Hvis det er null, og så er jeg like enig. Hvis det er null, så kommer det en null inn her. Og da ser vi at X blir null.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0010", "start": 923.62, "end": 1039.9, "token_count": 291, "text": "Hva blir x og q? Ja, controller input én, det skal bety at da Da skal verdien settes til den innkomne. Så det bør bli kulik null. Men igjen så kan vi se... Hvis det er null, og så er jeg like enig. Hvis det er null, så kommer det en null inn her. Og da ser vi at X blir null. Men en null inn i en årport, da kan man ikke uten videre si hva som kommer ut. Men vi kan se på, det kommer en ener inn her. Og så kommer det null inn her. Da blir det to ener inn i den porten. Da kommer en ener inn i denne årporten. Og en ener i årporten, da kommer det alltid en ener ut, og den blir til null. Så q blir også null. Så igjen, veldig bra. 70 % av dere har svart x lik 0 q anlik 0. Og det er da det riktige svaret. Men dette er ganske komplisert, så kjempebra. Da har dere fått med mye. Ok. Da skal vi fortsette der vi slapp. Så nå tilbake til... Slidende... D-vippe. Dette er altså da en d-vippe,", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0011", "start": 990.0, "end": 1109.0, "token_count": 294, "text": "Og det er da det riktige svaret. Men dette er ganske komplisert, så kjempebra. Da har dere fått med mye. Ok. Da skal vi fortsette der vi slapp. Så nå tilbake til... Slidende... D-vippe. Dette er altså da en d-vippe, som er den endelige lagringsenheten for nullarenere i en CPU. Og den er satt sammen av to. D-låser, eller latcher. Måten vi har gjort det på, er at vi har én slave som hele tiden står og leser fra master. Og master er den som tar input utenfra. Så ser vi den stiplede linjen her. Det er de to latchene som da er slått sammen til en D-vippe. Denne måten å gjøre det på, er at vi har en klokke som vi skrur av og på systematisk hele tiden, med en viss frekvens. Det er dette som er den berømte CPU-klokka. Som moderne CPU-er, fra en typisk frekvens mellom 1 og 3, ofte 4 GHz. Men noe særlig høyere enn det kommer man ikke pga. fysiske begrensninger.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0012", "start": 1091.4, "end": 1180.02, "token_count": 282, "text": "Det er dette som er den berømte CPU-klokka. Som moderne CPU-er, fra en typisk frekvens mellom 1 og 3, ofte 4 GHz. Men noe særlig høyere enn det kommer man ikke pga. fysiske begrensninger. Da blir det altfor mye varmeutvikling. Derfor vet man at hvis man overklokker CPU-er, så må man begynne med vannavkjøling og i ekstreme tilfeller med flytende luft osv. for å få kjølt ned systemet. Men det er da mye mer effektivt og i stedet for høyere frekvens, da lager man flere CPU-er og fordeler de, sånn at man da har maskiner som har... Vi har fire, åtte... Og i servere 30 og 60 sånne CPU-er. Så helt uavhengige enheter som regner hver for seg. Men vi skal se på hvorfor dette her virker. Og i de simuleringene som vi gjorde i fjor med studenter på rekke osv., Jeg var klokke. Hvert andre sekund omtrent, så løftet jeg armen opp.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0013", "start": 1148.2, "end": 1243.84, "token_count": 286, "text": "Så helt uavhengige enheter som regner hver for seg. Men vi skal se på hvorfor dette her virker. Og i de simuleringene som vi gjorde i fjor med studenter på rekke osv., Jeg var klokke. Hvert andre sekund omtrent, så løftet jeg armen opp. Da er jeg celik 1, og da er det slavene som virker. Så tok jeg armen ned, og da blir det en ener som er sendt til master. Hele clouet er at disse her virker annenhver gang. Her har jeg satt opp systematisk, og vi ser på hver av de to fasene. I en CPU så deles tiden inn i små klokketick av CPU-klokken. Den går av og på hele tiden. Når klokken sender inn en null, da skal alle beregninger ferdigstilles. Det kretsen gjør, sånn som har D-er osv., det... Det skal gjøres ferdig, og så lagres det hos Master. Den lagringen må være ferdig før klokken switcher til. Når klokka er null her, kan vi tenke oss at dette er et register vi skal lagre noe i.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0014", "start": 1225.72, "end": 1301.52, "token_count": 295, "text": "Det kretsen gjør, sånn som har D-er osv., det... Det skal gjøres ferdig, og så lagres det hos Master. Den lagringen må være ferdig før klokken switcher til. Når klokka er null her, kan vi tenke oss at dette er et register vi skal lagre noe i. Da har vi kanskje en addisjon eller en subtraksjon eller noe som pågår. Og det tar tid. De må strømme fysisk gjennom den kretsen for å komme til et svar. Når klokka er null, så leser Master det som kommer inn. Altså kanskje sluttsvaret på den summen, dette bittet, blir da null. Og da lagres det hos Master. Og da er det viktig at før klokka ringer, før klokka skifter fra null til én, så må alle disse operasjonene være ferdige. Og det er det som gjør at noen komplekse operasjoner, som å dividere f.eks., Da må det tas med i beregningen at den blir ikke ferdig på én klokkesykkel. En addisjon kan typisk være ferdig på én klokkesyklus.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0015", "start": 1279.54, "end": 1362.46, "token_count": 295, "text": "så må alle disse operasjonene være ferdige. Og det er det som gjør at noen komplekse operasjoner, som å dividere f.eks., Da må det tas med i beregningen at den blir ikke ferdig på én klokkesykkel. En addisjon kan typisk være ferdig på én klokkesyklus. Og da kommer resultatet inn med en gang. Dette må være ferdig før klokka switcher over til 1. For da skrus lesingen fra master av. Når klokka switcher 1, så er det Slaven som begynner å lese. Og da er det smarte her, at da leser slaven verdien fra master. Men da er master skrudd av, så da har slaven god tid på å lese denne verdien. Og da er den sikker på at denne verdien er den endelige verdien som er ferdig. Og så leser den seg inn, og da får du en... I dette tilfellet så får vi en null her hos slaven. Og det er denne som er verdien som registeret inneholder. Som totalt sett utgjør en vippe. Når klokken slår én, slaven leser verdien fra master og lagrer den.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0016", "start": 1335.36, "end": 1428.24, "token_count": 280, "text": "Og så leser den seg inn, og da får du en... I dette tilfellet så får vi en null her hos slaven. Og det er denne som er verdien som registeret inneholder. Som totalt sett utgjør en vippe. Når klokken slår én, slaven leser verdien fra master og lagrer den. Men den begynner med en gang å sende ut dette resultatet. Som er det gjeldende resultatet ut i kretsen, som er koblet til utgang for nyberegninger. Og på denne måten så går klokka av og på, og... For hver klokkesyklus utføres det da én beregning. Denne CPU-klokken er helt essensiell for å synkronisere dataene. For hver tid av klokken kan man da utføre et nytt sett av beregninger. Det kan f.eks. hver dag å utføre en maskininstitusjon. En annen viktig ting som man trenger for å lage en hel CPU, nå har vi nesten fått med alt, det er tellere. Og det er da en enhet som er sånn her... Dette er et eksempel fra den simulatoren.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0017", "start": 1400.64, "end": 1486.88, "token_count": 278, "text": "Det kan f.eks. hver dag å utføre en maskininstitusjon. En annen viktig ting som man trenger for å lage en hel CPU, nå har vi nesten fått med alt, det er tellere. Og det er da en enhet som er sånn her... Dette er et eksempel fra den simulatoren. Dette er da en teller som starter på 0, 0, og så teller den 0, 1, 1, 0, 1, 1. Så starter den på nytt igjen. Så blir det 0, 0, 1, 1, 0, 1, 1. Så fortsetter den sånn iduettelig. Denne teller fra 0 til 3. For å lage større tall, så kan du bare... Så kan man faktisk bruke denne tilsvarende konstruksjonen. Bare legge på flere sånne, så vil man kunne se at da kan man lage... Teller det med 64-bit, f.eks. Men igjen, for å lage denne konstruksjonen... Her er en X-år-port, som er en år-port med en not etter.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0018", "start": 1458.92, "end": 1553.76, "token_count": 290, "text": "Så kan man faktisk bruke denne tilsvarende konstruksjonen. Bare legge på flere sånne, så vil man kunne se at da kan man lage... Teller det med 64-bit, f.eks. Men igjen, for å lage denne konstruksjonen... Her er en X-år-port, som er en år-port med en not etter. For å lage denne konstruksjonen. Igjen så setter man opp Sann-Isabel, for man vet hvordan en klokke skal virke. Og så kommer man fram til denne logikken her. Som er relativt enkel. Og ut fra det også tilsvarende, så kan man lage vilkårlig store tellere. Så nå har vi med dette så har vi fått egentlig alle de viktigste bitene som skal til for å lage en hel SIPU. Og da skal vi se litt på... Generelt på datamaskinarkitektur. Spesielt på van Neumann-arkitektur. Von Neumann-arkitektur. Den aller vanligste datamaskinarkitekturen som brukes, ble definert av en matematiker som het John von Neumann. Han var virkelig et universalgeni og hadde...", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0019", "start": 1526.64, "end": 1626.02, "token_count": 297, "text": "Spesielt på van Neumann-arkitektur. Von Neumann-arkitektur. Den aller vanligste datamaskinarkitekturen som brukes, ble definert av en matematiker som het John von Neumann. Han var virkelig et universalgeni og hadde... Sto bak veldig mye av konstruksjonen av en moderne datamaskin. Det vi har sett på nå, det er først og fremst aluen. Så dette er den sentrale beregningsenheten. I tillegg har vi registeret. Når man gjør beregninger, så kobler man registrene til input på aluen. Og så kommer man andre registeret til outputs, og så gjøres det beregninger. Og dette gjøres om og om igjen. Vi har en kontrollenhet som styrer alt dette. I tillegg så har man main memory, secondary memory, main memory, det er RAM, internminne. Og internminne går ut til en buss, en databuss, som sender data inn til kontrollenheten. Altså kommer data ut igjen til RAM. Og det som er spesielt med von Neumann-arkitektur, er at her i RAM så ligger De institusjonene som kontrollerer hva som skal gjøres.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0020", "start": 1598.68, "end": 1692.66, "token_count": 280, "text": "internminne. Og internminne går ut til en buss, en databuss, som sender data inn til kontrollenheten. Altså kommer data ut igjen til RAM. Og det som er spesielt med von Neumann-arkitektur, er at her i RAM så ligger De institusjonene som kontrollerer hva som skal gjøres. Og i tillegg så ligger data. Det er typisk variabler. Hvis du har en variabel i et program, så vil den variabelen lagres. Og så gjør du beregninger, og så lagrer du dataene i den variabelen. De ligger da i ramm, og da må hele tiden trafikken gå inn og ut til Søppel. Og det som er spesielt med von Neumann-arkitekturen, er at samme buss brukes til både instruksjoner og data. I den såkalte Harvard... Hva heter den? Hardford... Arkitekturen. Harvard. Universitetet Harvard. Arkitekturen. Så er det litt annerledes, for da er det to busser. Én buss som sender institusjoner, og en atskilt buss som sender data.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0021", "start": 1661.56, "end": 1760.8, "token_count": 293, "text": "I den såkalte Harvard... Hva heter den? Hardford... Arkitekturen. Harvard. Universitetet Harvard. Arkitekturen. Så er det litt annerledes, for da er det to busser. Én buss som sender institusjoner, og en atskilt buss som sender data. I virkeligheten, i moderne arkitektur, så brukes egentlig en slags blanding. Der har man Cash, som vi skal se på senere. Og LNCash, det har to... Én for data og én for instruksjoner. Så det er en sannhet med modifikasjoner, at alle bruker von Neumann-arkitektur, men i hovedsak så ligner det på denne arkitekturen. I tillegg så har man secondary memory, det er disk, og så har man en rekke forskjellige enheter som kommuniserer med dette. Men CPU og main memory er liksom hovedbiten som vi skal se på nå. De delene van Normann-arkitekturen består av, er som vi så på forrige figur, det er Ramm, så er det Alu, og så er det en kontrollenhet som henter inn instruksjoner fra Ramm.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0022", "start": 1735.72, "end": 1844.06, "token_count": 299, "text": "Men CPU og main memory er liksom hovedbiten som vi skal se på nå. De delene van Normann-arkitekturen består av, er som vi så på forrige figur, det er Ramm, så er det Alu, og så er det en kontrollenhet som henter inn instruksjoner fra Ramm. Så dekodes instruksjonene og sender signaler til Alun, sånn at riktige operasjoner blir utført. Sånn at Alun gjør en ad i det ene tilfellet og en sammenligning i det andre osv. Så er det registeret som vi har slitt med i dag og lagd. Det er det et internlager som lagrer alle instruksjonene og lagrer alle dataene som kommer ut av Alun. I tillegg så har vi InputUpput. Som... Beregningsenheter. Her er det listet opp en rekke forskjellige beregningsenheter. I dag har vi sett på Aldun, som er CPU-ens hjerne. Og CPU, Central Processing Units. Det er da den viktigste biten. Så har vi noen andre varianter. FPU, floating point units. Vanligvis er det integrert i CPU. Det er bare en spesiell alu", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0023", "start": 1814.96, "end": 1915.68, "token_count": 300, "text": "I dag har vi sett på Aldun, som er CPU-ens hjerne. Og CPU, Central Processing Units. Det er da den viktigste biten. Så har vi noen andre varianter. FPU, floating point units. Vanligvis er det integrert i CPU. Det er bare en spesiell alu som også kan brukes i floating point. Da trenger man mer komplekse og kompliserte kretser som utfører det. Tar typisk litt lengre tid å dele to floating points på hverandre i forhold til helt annet. GPU, Graphics Processing Unit, som brukes til grafikk og rendregrafikk. Å tegne ut alt som du skal se på skjermen. Det trengs mye prosessorkraft, og veldig mye gjøres i parallell. Så da har man typisk tusenvis av små aluer som gjør beregninger samtidig i parallell. Og alt dette sitter vanligvis i vanlige datamaskiner. Det er programmerbar logikk, sånn at man kan... Hvis man har et logisk diagram, så kan man programmere det inn i en FPGA, og det går veldig hurtig. Men det fine med den er at den brennes ikke engang for alle, den kan da reprogrammeres. ASIC derimot, Application Specific Integrated Circuit,", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0024", "start": 1890.0, "end": 1989.08, "token_count": 295, "text": "Det er programmerbar logikk, sånn at man kan... Hvis man har et logisk diagram, så kan man programmere det inn i en FPGA, og det går veldig hurtig. Men det fine med den er at den brennes ikke engang for alle, den kan da reprogrammeres. ASIC derimot, Application Specific Integrated Circuit, det er virkelig en integrert krets. Da tar du en logikk. Så sender du den til en fabrikk, og så lager du nøyaktig den kretsen som du har spesifisert. Det er da... det er da ekstremt hurtig. Hvis du har fulgt med på sånn som bitcoin, hvor man da... Så starter man gjerne med CPU, men etter hvert gikk man over til GPU for å kunne gjøre dette raskere. Men nå går det for sakte med både CPU-er og GPU-er, så man gikk over til FBGA. Og helt til slutt har man lagd ASIC, altså helt spesifikke integrerte kretser, som regner ut bitcoins hurtigst mulig. Et spørsmål i chatten om... Når man snakker om flere kjerner i NCPU, er det da snakk om flere aluer? Ja, det er et godt spørsmål.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0025", "start": 1969.24, "end": 2078.62, "token_count": 288, "text": "Og helt til slutt har man lagd ASIC, altså helt spesifikke integrerte kretser, som regner ut bitcoins hurtigst mulig. Et spørsmål i chatten om... Når man snakker om flere kjerner i NCPU, er det da snakk om flere aluer? Ja, det er et godt spørsmål. Ja, man har da... Man må da ha minst... Eller man har én alu per kår. Så når vi snakker om flere cors, så er det uavhengig rene enheter. Det... Men det hender det varierer. F.eks. er det noen versjoner av IMD som har 40 course. Men da... I noen tilfeller har den 20 course som er hypertrening. Man har 40 aluer, men så har man bare 20 FPU-er. Så det varierer litt. Men stort sett så kan du si at hver kår er en alu, altså en uavhengig, rene enhet. OK. Da skal vi til slutt i dag se litt på en simulering av en CPU. Dette skal dere studere i detalj. Vi skal kjøre simuleringen i simuleringsmaskinen for Windows som vi har.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0026", "start": 2040.0, "end": 2139.94, "token_count": 296, "text": "Så det varierer litt. Men stort sett så kan du si at hver kår er en alu, altså en uavhengig, rene enhet. OK. Da skal vi til slutt i dag se litt på en simulering av en CPU. Dette skal dere studere i detalj. Vi skal kjøre simuleringen i simuleringsmaskinen for Windows som vi har. Dette er arkitekturen til en komplett firebit CPU, som kan utføre programmet. Vi ser her... Her er Datapath. Det er den som inneholder Alun og registeret. Det som er på høyre side her, er registeret. R0 her står egentlig 0010, så det er tallet fire. Mens i R1 så står det tallet én. I tillegg har vi ram som er koblet til, sånn at man kan skrive ut resultater. Vi kommer ikke til å bruke den delen. Men det vi kommer til å bruke, er rom, som er her. Og inni her ligger instruksjonene. Det er maskinkode. Etter hvert skal vi se, når vi kompilerer høynivåkode, så får vi maskinkode. Og i vårt tilfelle så ligger den maskinkoden her i rom.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0027", "start": 2126.88, "end": 2204.8, "token_count": 287, "text": "Og inni her ligger instruksjonene. Det er maskinkode. Etter hvert skal vi se, når vi kompilerer høynivåkode, så får vi maskinkode. Og i vårt tilfelle så ligger den maskinkoden her i rom. Men her har vi ikke noen kompulator. Her må vi skrive maskinkode rett inn i rom. Som nuller og enere. Og det en maskininstruksjon gjør, det er å styre alle kontrollbitene til Datapath, sånn at operasjonen som den ønsker Vi ser det er... Vi ser det er masse nuller og enere som går inn her og styrer disse bitene. Med up-code, DR osv. Og spesielt up-code, den sier hvilken institusjon som skal utføres. Da kan vi f.eks. tenke oss at vi ønsker å ha dere to tall. Jobben instruksjonsdekoderen gjør, er at den dekoder instruksjonen, sånn at den skrur på de riktige bryterne her. F.eks. S0 og S1, det styrer Alun. Hvis den er der, så må S0 og S1 settes til", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0028", "start": 2190.0, "end": 2276.4, "token_count": 283, "text": "Jobben instruksjonsdekoderen gjør, er at den dekoder instruksjonen, sånn at den skrur på de riktige bryterne her. F.eks. S0 og S1, det styrer Alun. Hvis den er der, så må S0 og S1 settes til de verdiene som gir en addisjon inne i Alun. Skal se på det i litt mer detalj etterpå. Her er vi inne i datapath. Det er noen mux-er, eller multiplexere, de er et system for å velge hvilken kanal man sender inn i aluen. Her er en mux som kommer inn i aluen. Den kan velge mellom å sende noe fra et register eller å sende inn en konstant. Jo, enten fra registeret her eller fra den konstanten her. Og det velges ved det valgbyttet her. Og det er noe av det instruksjonsdekoderne gjør. Hvis det skal komme inn en konstant, så må den kanskje skrus på én. Hvis du skal få noe fra et register, så må den settes i null, sånn at det som kommer fra abusen, kommer inn.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0029", "start": 2260.52, "end": 2346.82, "token_count": 293, "text": "Og det er noe av det instruksjonsdekoderne gjør. Hvis det skal komme inn en konstant, så må den kanskje skrus på én. Hvis du skal få noe fra et register, så må den settes i null, sånn at det som kommer fra abusen, kommer inn. Til syvende og sist så kommer det da to tall inn i abusen. Det går ett resultat, det, ut. Og da ser vi at... her igjen så kan man velge enten å ha data inn her, som da kommer fra Ramm, eller så kan man ta resultatet fra Alun. Det som jeg har sett på tidligere i dag, er at man legger sammen to tall. At man tar to registre, la oss si R0 og R1, og så kobles verdien av de ved hjelp av de multiplexerne. De kobles sånn at R0 går inn i A, R1 går inn i B. Og så setter man en viktig bit her for å adere. Og så kommer resultatet i D. Og så kobles denne multiplexeren sånn at resultatet fra D sendes opp igjen i registerfilen. Avhengig av instruksjonen man gjør, kan man velge å legge resultatet i R0.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0030", "start": 2327.0, "end": 2404.5, "token_count": 282, "text": "Og så setter man en viktig bit her for å adere. Og så kommer resultatet i D. Og så kobles denne multiplexeren sånn at resultatet fra D sendes opp igjen i registerfilen. Avhengig av instruksjonen man gjør, kan man velge å legge resultatet i R0. Det man utfører da, er R0 er lik R0 pluss R1. Og på denne måten så... På denne måten så virker en datamaskin. Det er akkurat samme prinsippet i alle CPU-er. Ja. Da skal vi til slutt se på... Høynivåkode. For det er syvende og sist, når du skriver et program, så skriver du ikke maskinkode, men du skriver høynivåkode. Så det vi skal se litt på nå, er hvordan høynivåkode sånn som dette er... En liten forløkke som summerer. Den starter på I liker 1, så den går tre ganger. Altså er S lik 0. Så når vi har en sånn høynivåkode... Det vi ønsker av programmet... Det er de følgende tre operasjonene.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0031", "start": 2378.94, "end": 2459.92, "token_count": 293, "text": "Så det vi skal se litt på nå, er hvordan høynivåkode sånn som dette er... En liten forløkke som summerer. Den starter på I liker 1, så den går tre ganger. Altså er S lik 0. Så når vi har en sånn høynivåkode... Det vi ønsker av programmet... Det er de følgende tre operasjonene. Først starter vi med i lik 1, summen er 0 pluss 1 er lik 1 osv. Så øker verdien i til 2. Så legger vi til den summen 3. Og så til slutt får vi ut tallet 6, som blir summen. I oppgavene senere i dag så skal du prøve å overbevise deg om... At denne simuleringsmaskinen utfører nøyaktig dette. Så skal du etter hvert endre den litt, sånn at den løkka går til tre. Og da må du faktisk skrive maskinkode. Du må endre på maskinkoden for å få den til å gjøre nøyaktig dette. Vanligvis har man en kopulator som oversetter høynivåkode til maskinkode. Men for å virkelig se hva som skjer...", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0032", "start": 2441.92, "end": 2536.74, "token_count": 294, "text": "Og da må du faktisk skrive maskinkode. Du må endre på maskinkoden for å få den til å gjøre nøyaktig dette. Vanligvis har man en kopulator som oversetter høynivåkode til maskinkode. Men for å virkelig se hva som skjer... Så skal vi utføre dette selv. For å få til det, så trenger man å kjenne til instruksjonene for denne maskinen. Instruksjonssettet til maskinen utgjør arkitekturen, f.eks. Exo-86-arkitekturen, som er den vanligste arkitekturen i PC-reservere. Den har et gitt... Det er fastlåst, for det er definert av arkitekturen. Og det brennes fast i kretskortene som utgjør alu og CPU, og alle delene. Da har man bare bestemt, sånn som jeg bestemte for denne maskinen her, f.eks. addisjon. Den skal ha binært nummer 0100. Det er altså da fire. Institusjon nummer fire. Det skal være en add-institusjon. Og den skal addere operand 1. Og den skal legge til operand 2.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0033", "start": 2505.52, "end": 2620.0, "token_count": 293, "text": "Da har man bare bestemt, sånn som jeg bestemte for denne maskinen her, f.eks. addisjon. Den skal ha binært nummer 0100. Det er altså da fire. Institusjon nummer fire. Det skal være en add-institusjon. Og den skal addere operand 1. Og den skal legge til operand 2. Og det betyr at man da utfører DR er lik DR pluss SR. Og vi ser de fire første bitene her. Det er da de fire første bitene i institusjonen. Det definerer hvilken institusjon vi skal gjøre. De neste fire bitene definerer operand 1 og operand 2. Og det kan variere ut fra hvilken institusjon det er, nøyaktig hva disse operandene gjør. For å utføre en sånn oppgave som å kjøre den summen... Hvis man skal skrive maskinkode, så må man lage... Det enkleste før man skriver maskinkoden... Altså bruke et slags... Et språk som ligger tett opp mot maskinkoden, som er assemblykode. Det jeg har skrevet opp her, er assemblykode som utfører... Den utfører denne forløkken.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0034", "start": 2591.84, "end": 2683.56, "token_count": 293, "text": "Det enkleste før man skriver maskinkoden... Altså bruke et slags... Et språk som ligger tett opp mot maskinkoden, som er assemblykode. Det jeg har skrevet opp her, er assemblykode som utfører... Den utfører denne forløkken. Når man skriver maskinkode eller assemblykode, så må man tenke litt annerledes enn når man skriver høynivåkode. Men det viktigste man alltid må ha, det er enten en løkke eller en if-test.  Og for å utføre en Lucky eller Niff-test, så må man hoppe i koden. Vi kan se veldig raskt på hvordan denne maskinkoden her utføres. Så det vi gjør først i de fire første institusjonene, er bare å legge verdier i r0rnr2r3. r0rnr2r3, det er da registeret. Så første institusjon sier legg tallet tre i. Og så legg tallet 1 i R1. 0 i Auto og 0 i R3. Og så utfører jeg en addisjon, I pluss pluss. Jeg bestemmer meg da bare for at variabelen i, den lagres i Auto.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0035", "start": 2661.52, "end": 2739.64, "token_count": 287, "text": "Så første institusjon sier legg tallet tre i. Og så legg tallet 1 i R1. 0 i Auto og 0 i R3. Og så utfører jeg en addisjon, I pluss pluss. Jeg bestemmer meg da bare for at variabelen i, den lagres i Auto. Men det er noe jeg bestemmer når jeg skal skrive dette programmet. Og denne instruksjonen her, da, den tar verdien i Auto og så legger den til Auto. Tallet R1 vil alltid være 1, så dette vil da alltid bli en I++. Altså at man øker automen. Så utfører jeg summen. Jeg bare definerer da i hodet mitt at jeg velger da R3. Det vil jeg ha. Der vil jeg lagre S. Og det er derfor jeg legger 0 inn i det registeret først. Så denne institusjonen, det den utfører, den tar da... S, som er R3, og så legger den til I, som er R2, og så lagres det i R3. Og det vil da være S lik S pluss I. Og denne institusjonen, det kan datamaskinen min utføre.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0036", "start": 2719.32, "end": 2801.64, "token_count": 292, "text": "Så denne institusjonen, det den utfører, den tar da... S, som er R3, og så legger den til I, som er R2, og så lagres det i R3. Og det vil da være S lik S pluss I. Og denne institusjonen, det kan datamaskinen min utføre. Så kommer et veldig viktig stepp. Jeg sammenligner. Og det jeg sammenligner, det er... R2 og R0. For R0, det er maks. Jeg ønsker at løkka skal bare gå opp til tre. Så dette er maks. Og da sammenligner jeg R2, som er da på en måte variabelen i, har den blitt så stor som tre. Men foreløpig er jeg ille i gen, så det har den ikke. Og når jeg da gjør neste institusjon, jump not equal, så hopper jeg opp til fire igjen. Og den består av at man øker i med én. Så får jeg i lik 2. Så får jeg summen lik 1 pluss 2 er lik 3. Så gjør jeg dette en gang til. Her er i lik 2. Jeg hopper opp. Øker i lik 3. S er lik 3...", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0037", "start": 2778.74, "end": 2856.4, "token_count": 291, "text": "så hopper jeg opp til fire igjen. Og den består av at man øker i med én. Så får jeg i lik 2. Så får jeg summen lik 1 pluss 2 er lik 3. Så gjør jeg dette en gang til. Her er i lik 2. Jeg hopper opp. Øker i lik 3. S er lik 3... Det er 3 pluss 3, og da er summen 6. Og nå har i blitt 3, og da hopper jeg ikke opp igjen. Dermed er jeg ferdig, og jeg har fått resultatet 6. Programmet har blitt utført. Og det er nøyaktig sånn man går fra høynivåkode til assemblerkode eller maskinkode. Neste steppe nå er at jeg må kode inn denne maskinkoden eller denne asemblyen inn i maskinkode. Og det er veldig rett frem, for det er bare å oversette instruksjon for instruksjon. Og... Ja, hvis jeg bruker mye tid her nå... Jeg går litt over tiden. Håper dere holder ut. Selv om det er litt tungt, så dere får jobbe dere gjennom dette ved å se på oppgavene.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0038", "start": 2833.52, "end": 2915.88, "token_count": 298, "text": "Og det er veldig rett frem, for det er bare å oversette instruksjon for instruksjon. Og... Ja, hvis jeg bruker mye tid her nå... Jeg går litt over tiden. Håper dere holder ut. Selv om det er litt tungt, så dere får jobbe dere gjennom dette ved å se på oppgavene. Men hele clouet er nå at vi oversetter disse institusjonene én for én. For eksempel den første linjen... Altså legg tallet 3 inn i r0. Da må vi move i, det er institusjon nummer to, så da må vi skrive 00... R0 er destination. Source er det tallet vi skal legge inn. Her ser vi 11, det er tallet 3. Det skal legges i register 0. På samme måte, samme instruksjon, men nå skal vi legge 1 i R1. Da må det stå 1 der og 1 der. Etter hvert kommer vi ned til add. Da skal vi add R2 lik R2 pluss R1. Da må vi skrive inn her er instruksjon nummer fire, og så... Destination register, det er da R2, og da ser vi det står et 2-tall der.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0039", "start": 2895.04, "end": 2976.6, "token_count": 299, "text": "Da må det stå 1 der og 1 der. Etter hvert kommer vi ned til add. Da skal vi add R2 lik R2 pluss R1. Da må vi skrive inn her er instruksjon nummer fire, og så... Destination register, det er da R2, og da ser vi det står et 2-tall der. Det gir da R2 og 1. Det betyr R1. Så dermed utføres R2 lik R2 pluss R1. Hvis jeg f.eks. hadde skrevet 3 her i stedet, ville jeg utført R3 lik R3 pluss R1. Så på denne måten programmerer jeg maskinen med akkurat den koden jeg ønsker. Vanligvis, hvis du f.eks. har høynivåkode iC, så har man en kompulator. Du kompilerer høynivåkoden, og så lager kompulatoren denne maskinkoden. Og så kjøres den. Men i vårt tilfelle så gjør vi dette for hold. Helt til slutt, den viktigste biten i LANESAPOON, det er bransjekontroll. Hvis man ikke hadde bransjekontroll, så... Om man hadde et program på ti linjer, så ville man bare", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0040", "start": 2952.22, "end": 3029.68, "token_count": 286, "text": "Og så kjøres den. Men i vårt tilfelle så gjør vi dette for hold. Helt til slutt, den viktigste biten i LANESAPOON, det er bransjekontroll. Hvis man ikke hadde bransjekontroll, så... Om man hadde et program på ti linjer, så ville man bare kunne kjøre de ti linjene, og så var man ferdig. Bransjekontroll gjør at man kan hoppe i koden. Og det var det vi så vi gjorde hver gang vi kom til en test. Så hoppet vi som et resultat av resultatet av den testen. Hvis den var likt, så hoppet vi ikke. Hvis den var jump not equal, hvis det ikke var likt, så hoppet man. Dermed kan man konstruere for- og wirelucker og if-tester, og alle mulige slags konstruksjoner kan da konstrueres på den måten. Det helt avgjørende da er at man har en branch-kontroll her, som gjør at avhengig av resultatet... Ved en sammenligning så settes Z og C0 her nede. Så sendes det til branch-kontrollen.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0041", "start": 3008.46, "end": 3111.52, "token_count": 299, "text": "og alle mulige slags konstruksjoner kan da konstrueres på den måten. Det helt avgjørende da er at man har en branch-kontroll her, som gjør at avhengig av resultatet... Ved en sammenligning så settes Z og C0 her nede. Så sendes det til branch-kontrollen. Og da ser vi at branch-kontrollen sender et signal opp til counteren. Program counter teller seg nedover hvilke institusjoner man gjør. Og da endres den program counteren, sånn at man hopper i koden. Og det er hele clouet for... For hvordan en CPU kan programmeres til if-tester, få løkker og wildløkker. Og egentlig alt man trenger i en CPU. OK. Så jeg har brukt mye tid her. Men jeg tenker det... For å kunne gjøre oppgavene, så er det veldig... Jo, det er veldig viktig at dere kan kjøre de institusjonene i simulatoren. Så jeg tenkte jeg veldig raskt skulle helt til slutt vise dere hvordan man kjører simuleringen, sånn at dere kan komme i gang med det. Forhåpentligvis ved å prøve og feile litt.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0042", "start": 3082.56, "end": 3232.54, "token_count": 300, "text": "Jo, det er veldig viktig at dere kan kjøre de institusjonene i simulatoren. Så jeg tenkte jeg veldig raskt skulle helt til slutt vise dere hvordan man kjører simuleringen, sånn at dere kan komme i gang med det. Forhåpentligvis ved å prøve og feile litt. Så vil dere kunne forstå i detalj hvordan en datamaskin virker. Skal vi se... Da skal jeg dele en annen side med dere. Sånn. Da starter... Digital works. Her ser vi de fire fulladerne som er satt sammen for bl.a. å kunne legge sammen. Det er en sånn binary fullader som vi forrige gang konstruerte. Vi ser at dette er et stort byggverk hvor man hele tiden abstraherer og lager bokser. Dette er register file. Denne inneholder da registrene. Det er de små registrene som vi har brukt mye tid på å konstruere i dag. Og dette er da logikken i registrene, men vi ser hovedbiten er vippene. D-vippene. Så her er det fire D-vipper som lager fire-bit i fire-bitsregisteret. Helt til slutt skal jeg bare vise hvordan maskinen kjører.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0043", "start": 3202.58, "end": 3288.08, "token_count": 287, "text": "Det er de små registrene som vi har brukt mye tid på å konstruere i dag. Og dette er da logikken i registrene, men vi ser hovedbiten er vippene. D-vippene. Så her er det fire D-vipper som lager fire-bit i fire-bitsregisteret. Helt til slutt skal jeg bare vise hvordan maskinen kjører. Her inne i rom, hvis man høyre-klikker eller tar edit på den, så ser man det programmet. Dette er da maskinkode som viser det programmet som regner én få løkke. Og så kan man trykke på run og kjøre. Alternativet, som kanskje er bedre, er å trykke på step. Da tar man én instruksjon av gangen. Den første var å legge tallet tre i r0. Dette er en ener og det er en toer, så tallet tre har nå kommet i r0. Så trykker jeg på step en gang til. Dvs. to ganger må man trykke, for klokka går av og så på. Og så utføres instruksjonen. Og det som ble gjort nå, det var at én ble lagt i r1.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0044", "start": 3272.42, "end": 3364.12, "token_count": 293, "text": "Så trykker jeg på step en gang til. Dvs. to ganger må man trykke, for klokka går av og så på. Og så utføres instruksjonen. Og det som ble gjort nå, det var at én ble lagt i r1. Og så blir null lagt i r2, og null i r3. Men så adderer man. Så det man skal gjøre nå, er å ta R2 lik 0 pluss R1. Og da får man en ener i R2. Og så gjør man en test. Eller man øker R3 med én, det er telleren. Og så sjekker man om den er lik R0. Nei, den er ikke lik R0. Og det er jump not equal, så da hopper man opp hit og gjør en ny addisjon. Og det man gjør nå, er R2 lik R2 pluss den telleren R3. Så da... Da ser man... Da får man to i R2. Ja, i telleren R2 så er det R3. Det er her summen ligger. En pluss to ble nå tre. Så går man og tester, er vi ferdig med løkka? Nei, det er vi ikke, så vi gjør det en gang til.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0045", "start": 3335.72, "end": 3423.76, "token_count": 278, "text": "Så da... Da ser man... Da får man to i R2. Ja, i telleren R2 så er det R3. Det er her summen ligger. En pluss to ble nå tre. Så går man og tester, er vi ferdig med løkka? Nei, det er vi ikke, så vi gjør det en gang til. Da skal vi til slutt ta... Da vi teller R2, blir det nå tre. Så skal vi legge R3 lik R3 pluss R2. Da ser vi vi får seks, som er sluttresultatet. Så når nå R2 sammenlignes med R0, så... Er den equal? Og da fortsetter den rett frem. Og da har vi kjørt hele programmet. Og så kan... Nå kjører jeg programmet bare hurtig gjennom. Og da, om og om igjen, så utføres hele den samme operasjonen ved at man legger sammen. Helt til slutt så kan... Det er en oppgave. Som går ut på at dere skal endre... litt på koden. Og det dere må gjøre da, er å klikke her, og så kan man gå inn sånn, og så endre.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0046", "start": 3398.84, "end": 3496.76, "token_count": 299, "text": "Og da, om og om igjen, så utføres hele den samme operasjonen ved at man legger sammen. Helt til slutt så kan... Det er en oppgave. Som går ut på at dere skal endre... litt på koden. Og det dere må gjøre da, er å klikke her, og så kan man gå inn sånn, og så endre. Nå endret jeg verdi fra én til tre, og da vil programmet gjøre noe helt annet. Men etter at du har endret, så må du ikke bare trykke på OK. Du må endre først, og så trykke på neste. Og så kan programmet kjøre. Det enkleste er å krasje hele maskinen og ta ned simuleringen. Og så starte den på nytt, for da starter de et ferskt program. Sorry, jeg skal ikke gjøre til vannet og gå så mye over tiden. Men vi har la bedt på, så vi får... Dere kan jo slappe av litt før dere starter på laben. Lage breakout-rooms. Og så kan dere gå inn i breakout-rommene og snakke med meg eller med NA-studentpasientene og få hjelp til oppgavene. Men da stopper jeg der i hvert fall. Så får dere en liten pause.", "source": "lecture"}
{"lecture_id": "os3b", "chunk_id": "os3b_0047", "start": 3461.7, "end": 3511.76, "token_count": 124, "text": "Men vi har la bedt på, så vi får... Dere kan jo slappe av litt før dere starter på laben. Lage breakout-rooms. Og så kan dere gå inn i breakout-rommene og snakke med meg eller med NA-studentpasientene og få hjelp til oppgavene. Men da stopper jeg der i hvert fall. Så får dere en liten pause. Men nok en gang takk for bra oppmøte. Så ses vi i laben, og i hvert fall neste uke. Takk for i dag.", "source": "lecture"}
{"lecture_id": "os6del13", "chunk_id": "os6del13_0000", "start": 0.0, "end": 89.94, "token_count": 280, "text": "Ja... Multitasking i praksis... Vi skal se veldig kort på hvordan vi kan kjøre programmer. Og hvordan det ser ut når vi kjører såkalte CPU-intensive programmer. Veldig mange vanlige programmer bruker ikke noe særlig CPU. Det er ikke så mye de gjør. Ofte så venter de på... Noe input fra brukeren, f.eks. en... En teksteditor, f.eks. Den venter hele tiden på klikk fra brukeren. Så den bruker ikke veldig mye CPU. Men så fins andre CPU-avhengig-prosesser, f.eks. et regneprogram. Det vil bruke CPU-en hele tiden. Så noe som man utnytter i multitasking, er at veldig mange prosesser De står egentlig bare og venter på CPU. Det gjør ikke så veldig mye. Men vi skal først se på såkalte CPU-avhengige prosesser. Det er prosesser som da helt tiden står og regner. Her er et enkelt shellscript, som egentlig bare er en løkke, som står og legger sammen tall. Sum pluss er lik i. Det gjør dette scriptet om og om igjen.", "source": "lecture"}
{"lecture_id": "os6del13", "chunk_id": "os6del13_0001", "start": 64.18, "end": 157.8, "token_count": 287, "text": "Men vi skal først se på såkalte CPU-avhengige prosesser. Det er prosesser som da helt tiden står og regner. Her er et enkelt shellscript, som egentlig bare er en løkke, som står og legger sammen tall. Sum pluss er lik i. Det gjør dette scriptet om og om igjen. En typisk CPU-avhengig prosess, som hele tiden vil prøve å bruke så mye CPU-en bare kan, for å bli fortest mulig ferdig. Hvis du har flere sånne prosesser på én enkelt CPU, så må de da hele tiden bytte om på å bruke CPU-en. Vi skal straks se på det. Men aller først så har man også i tillegg prosesser som er IO-bound. Som hele tiden venter på og bruker input-output. Det er sånn som webbroser og teksteditorer og regneark som stort sett ikke gjør så veldig mye. Det fine med multitasking er at da kan man hele tiden kombinere den type programmer. For... Hvis man bare hadde en sekvensiell CPU som hele tiden måtte gjøre... Hvis man hadde to prosesser, så ville hele de oppgavene...", "source": "lecture"}
{"lecture_id": "os6del13", "chunk_id": "os6del13_0002", "start": 130.0, "end": 209.82, "token_count": 249, "text": "som stort sett ikke gjør så veldig mye. Det fine med multitasking er at da kan man hele tiden kombinere den type programmer. For... Hvis man bare hadde en sekvensiell CPU som hele tiden måtte gjøre... Hvis man hadde to prosesser, så ville hele de oppgavene... Her er det en prosess A, som først gjør CPU, så bruker den IO, og så CPU. Hvis vi skal gjøre det etter hverandre, så måtte de pent vente på hverandre. Men her så kan operativsystemet utnytte det at prosess A trenger CPU. Men så gjør den noe IO. Kanskje en skriver til RAM, eller leser fra DPU. Da kan prosess B bruke CPU-en. Da blir den prosessen kastet ut. Så hives prosess B inn i CPU-en, og så bytter de på sånn. Dette er multitasking, og det gjør at man selv på én CPU kan ha en rekke prosesser som står og kjører samtidig. Uten at den blir overbelastet.", "source": "lecture"}
{"lecture_id": "os3del3", "chunk_id": "os3del3_0000", "start": 0.0, "end": 81.68, "token_count": 282, "text": "Først en kort oppsummering av hva vi gjorde sist. Vi har startet ut med transistorer, som egentlig er bare veldig små brytere. Det kommer en ledning inn til bryteren som skrur den av og på. Hvis den er på, så leder transistoren strøm. Hvis den er av, så leder transistoren ikke strøm. Veldig enkelt. Og dette enkle prinsippet kan man da bruke til å lage logiske porter. Og med logiske porter så kan man implementere and or not. Og på den måten så kan man implementere alle logiske sammenhenger. Og dette brukes da i en datamaskin for å lage en maskin som gjør nøyaktig det vi ønsker den skal gjøre. Og det vi ønsker den skal gjøre, er forskjellige institusjoner. Legge sammen to tall, trekke fra hverandre tall, sammenligne to tall, osv. Og når man har klart for seg hvilken funksjon man skal gjøre... I forrige gang så vi på dette med å addere. Addere to tall. Og da så vi på algoritmen for å addere to tall.", "source": "lecture"}
{"lecture_id": "os3del3", "chunk_id": "os3del3_0001", "start": 60.0, "end": 140.84, "token_count": 288, "text": "Legge sammen to tall, trekke fra hverandre tall, sammenligne to tall, osv. Og når man har klart for seg hvilken funksjon man skal gjøre... I forrige gang så vi på dette med å addere. Addere to tall. Og da så vi på algoritmen for å addere to tall. Og da fant vi ut at en bit av den algoritmen, det kan vi ta ut og lage en logisk krets av. Og det første man gjør da, er bare å skrive ned en krets. Som viser logikken systemet skal ha. Og så så vi at ut ifra en sannhetstabell, så kan man skrive rett ned en krets med and or and not-porter. Det er en veldig rett frem metode for å gjøre det. Etter at man har gjort det, så kan det bli ganske komplekse kretser. Men da kan disse forenkles med Bolskalgebra. Og når man har gjort det, Man kan sende den til en produsent, og så kan man få et kretskort som gjør nøyaktig det man ønsker. Man lager som regel ikke et kretskort av bare en liten av dere, som vi gjorde sist.", "source": "lecture"}
{"lecture_id": "os3del3", "chunk_id": "os3del3_0002", "start": 113.84, "end": 215.84, "token_count": 300, "text": "Men da kan disse forenkles med Bolskalgebra. Og når man har gjort det, Man kan sende den til en produsent, og så kan man få et kretskort som gjør nøyaktig det man ønsker. Man lager som regel ikke et kretskort av bare en liten av dere, som vi gjorde sist. Men man har en litt større krets. Men prinsippet er akkurat det samme. Vi så på én liten boks. Hemmeligheten med å lage en hel CPU er at man tar mange Og setter sammen til en stor og kompleks enhet som gjør akkurat det man ønsker. Det vi laget sist, var en krets med... en logisk krets som aderer tall. Avdelingskrets. Så dette var på en måte sluttresultatet fra forrige time. Det vi har oppnådd, er at vi har lagd et lite kretssystem ved hjelp av logikk og enkle brytere av og på brytere, som er sånn at hvis vi sender inn fire bit A og fire bit B inn til denne maskinen, så uansett verdien på nullerne og enerne her, så får man ut summen C av. I dette eksempelet så står det tallet seks, både A og B.", "source": "lecture"}
{"lecture_id": "os3del3", "chunk_id": "os3del3_0003", "start": 189.12, "end": 280.0, "token_count": 297, "text": "og enkle brytere av og på brytere, som er sånn at hvis vi sender inn fire bit A og fire bit B inn til denne maskinen, så uansett verdien på nullerne og enerne her, så får man ut summen C av. I dette eksempelet så står det tallet seks, både A og B. Og det som kommer ut, det er en ener, toer, firer og en åtter. Så det er åtte pluss fire. Det er tolv som kommer ut. Og det er det riktige svaret i dette tilfellet. Det vi kanskje ikke sa så mye om sist, er at det er et opplagt problem her. Hva om man legger sammen et stort tall? La oss si vi har enere på alle her. Det blir 3 pluss 12, det blir 15. Hvis man legger sammen 15 pluss 15, så får man jo 30. Men det største tallet som kan lages eller vises med 4 bit, det er jo 15. Så her skjer det noe galt. Og da får man en såkalt overflow. Og det fører ofte til problemer. Sånn er det. Hvis man regner med 32-bitstall, f.eks., så kan de maks...", "source": "lecture"}
{"lecture_id": "os3del3", "chunk_id": "os3del3_0004", "start": 253.34, "end": 339.94, "token_count": 291, "text": "Men det største tallet som kan lages eller vises med 4 bit, det er jo 15. Så her skjer det noe galt. Og da får man en såkalt overflow. Og det fører ofte til problemer. Sånn er det. Hvis man regner med 32-bitstall, f.eks., så kan de maks... Hvis man tar med pluss og minus, så kan de maks representere 2 mrd. Hvis man da utfører et regnsyke i et C-program, eller et annet program hvor resultatet blir høyere enn 2 mrd., så får du en feil. Da kan man plutselig risikere å få et negativt tall. Når man... Man legger sammen to store tall. Dette gjelder for alle systemer, men man må bare ha nok bitt, sånn at man kan få representert så store tall som mulig, eller som man behøver. Så ser vi at vi egentlig bare trenger ett bitt til, så kan vi representere summen av alle firebits tall. Men nå kommer... Det vi trenger å gjøre videre, det er problemer at denne kretsen, den kan jo bare legges sammen. Og det er jo ikke alt vi skal legge sammen.", "source": "lecture"}
{"lecture_id": "os3del3", "chunk_id": "os3del3_0005", "start": 314.82, "end": 350.4, "token_count": 104, "text": "Så ser vi at vi egentlig bare trenger ett bitt til, så kan vi representere summen av alle firebits tall. Men nå kommer... Det vi trenger å gjøre videre, det er problemer at denne kretsen, den kan jo bare legges sammen. Og det er jo ikke alt vi skal legge sammen. Så derfor så lager man da heller en litt mer kompleks krets, som kan gjøre flere ting på en gang.", "source": "lecture"}
{"lecture_id": "os1del11", "chunk_id": "os1del11_0000", "start": 0.0, "end": 98.6, "token_count": 300, "text": "Hva er et operativsystem? Jo, som dere ser av dette bildet, så sitter operativsystemet mellom hardware. Her nede på hardware er det CPU, ram, disk osv. Så sitter operativsystemet da mellom den hardwaren og brukerprogrammene. Og så har vi deg eller flere som en bruker her på toppen. Som bruker disse brukerprogrammene. I hovedsak, da... Så det operativsystemet gjør, det er å sørge for at brukerprogrammene får tilgang til den hardwaren som er her nede. Så det er enkelt og greit hva et operativsystem er. Og det er jo også veldig viktig at operativsystemet er et software-grensesnitt. Altså det er ikke noe hardware... I operativsystemet. Riktignok så bruker det ganske ofte helt spesielle funksjoner i hardware, som vanlige programmer ikke bruker. Men OS er et... I bunn og grunn et svært... Softwareprogram. Det er bare et digert program. Hvor stort er et operativsystem? Det er egentlig ganske... Enormt. Hvis man ser på kildekoden til operativsystemer som Linux eller Windows, så kan det være noe sånt som", "source": "lecture"}
{"lecture_id": "os1del11", "chunk_id": "os1del11_0001", "start": 71.08, "end": 162.5, "token_count": 288, "text": "Men OS er et... I bunn og grunn et svært... Softwareprogram. Det er bare et digert program. Hvor stort er et operativsystem? Det er egentlig ganske... Enormt. Hvis man ser på kildekoden til operativsystemer som Linux eller Windows, så kan det være noe sånt som fem millioner linjer med kode. Og disse linjene med kode er bare operativsystemkjernen. Altså den viktigste delen av operativsystemet. Med Gui og biblioteker og system software osv., så blir det enda større enn dette. Men bare kjernen er så stor sånn at hvis man skriver ned dette i bøker, den koden, så får du noe sånn som 100 Tanbaum-bøker. Og Tanbaum, den som jeg sa, den er svær. 1000 sider. Så stabler de opp hverandre, så får du en fem meter høy stabel med kildekode. Og det er omtrent det største... Man har ikke særlig mange andre program som er større der ute. Det er veldig omfattende å generelt styre en hel datamaskin. Det første man må tenke på når man ser dette, er at dette gjør også at", "source": "lecture"}
{"lecture_id": "os1del11", "chunk_id": "os1del11_0002", "start": 134.2, "end": 229.36, "token_count": 285, "text": "Så stabler de opp hverandre, så får du en fem meter høy stabel med kildekode. Og det er omtrent det største... Man har ikke særlig mange andre program som er større der ute. Det er veldig omfattende å generelt styre en hel datamaskin. Det første man må tenke på når man ser dette, er at dette gjør også at et sånt system, det vil ikke fungere akkurat som det skal, hele tiden. Moderne operativsystemer er ganske så stabile, det er relativt sjelden det skjer feil. Umulig å programmere et perfekt operativsystem sånn at det alltid virker som det skal. Man skulle tro at det var mulig å få til, men når noe er så komplekst, så er det ikke mulighet for å gjennomteste et operativsystem. Man kan ikke forutse absolutt alle muligheter for input og for hva som skjer. Så at vi... For mindre programbiter, f.eks. hvis du har en klasse med noen metoder, så kan du teste denne koden for absolutt alle muligheter. Rett og slett alle mulige input, og så sjekker du om dette virker.", "source": "lecture"}
{"lecture_id": "os1del11", "chunk_id": "os1del11_0003", "start": 200.68, "end": 242.98, "token_count": 133, "text": "Man kan ikke forutse absolutt alle muligheter for input og for hva som skjer. Så at vi... For mindre programbiter, f.eks. hvis du har en klasse med noen metoder, så kan du teste denne koden for absolutt alle muligheter. Rett og slett alle mulige input, og så sjekker du om dette virker. For den gir alltid riktig kode, den krasjer aldri. Men i praksis er et operativsum så stort at det aldri kan gjøres helt perfekt. Det er veldig vanskelig.", "source": "lecture"}
{"lecture_id": "os4del21", "chunk_id": "os4del21_0000", "start": 0.0, "end": 78.0, "token_count": 261, "text": "Vi kan si til slutt at dette her med å assemble kode og sånn som dette er, det er veldig mye enklere enn å kompilere. For en assembler, som man ofte kaller det programmet som lager maskinkode fra assembly, en assembler bare oversetter direkte... Stort sett så er det bare direkte oversettelse av institusjon for institusjon til maskinkode. Og det er bare snakk om bokholderi. Ad er institusjon nummer fire. Compare er nummer 32. Så lager man ener og 001 osv. og tilsvarende med hvilket register det er. Så det er en veldig enkel prosess. Derimot, det å kompilere høynivåkode, det er en veldig kompleks prosess. Og det er veldig vanskelig å skrive en kompulator. Det er et... Et veldig avansert program som å kunne oversette enhver høynivåkode til maskinkode. Og det er komplisert. Og det har man kompulatorer til. Men en assembler kunne man relativt enkelt skrive.", "source": "lecture"}
{"lecture_id": "os5del12", "chunk_id": "os5del12_0000", "start": 0.0, "end": 67.06, "token_count": 185, "text": "Ja, det var et spørsmål om... Jo, om returverdien, hvorfor det står int i... I maine. Altså den int maine. Men maine har også en returverdi, så det... Her kan maine returnere tall. Og det er derfor du har en int-verdi på... Sånn at... Hvis jeg nå kompilerer den her... Og så kjører adotat, så vil jeg da se at... Da kan jeg lese ut returverdien fra det jeg kjørte programmet. Så den leverer et helt tall, og på den måten så kan program levere en feilkode når det kjøres. Feilkoden ligger i dollar-spørsmålstegn. Da får jeg ut akkurat den feilkoden i meg.", "source": "lecture"}
{"lecture_id": "linux6del7", "chunk_id": "linux6del7_0000", "start": 0.0, "end": 105.92, "token_count": 290, "text": "Skal nå se på screen, som er veldig nyttig å bruke når man jobber i et Linux-skjell. Screen er en kommando som setter i gang et skjell som vil stå i bakgrunnen og kjøre, selv etter at man har logget ut. Sånn at man kan logge ut og komme tilbake og gå inn og se på det man har gjort, og fortsette arbeidet der. Det er ikke screen installert på Linux-øvende, men da kan man installere det med apt-get... App-install kan man gjøre. Og så screen. Så... Ut passordet, så får man installert screen. Man kan starte screen ved å bare taste ordet screen på denne måten her. Da kommer det opp en gnuscreen, og så står det 'press space'... ... eller'return to end'. Da ser det ikke ut som det har skjedd så veldig mye her. Men egentlig så har vi nå startet opp et nytt skjell akkurat der vi var tidligere. Hvis jeg tar PS, så ser jeg heller ikke noe. Men jeg kan gjøre en screen minus LS. Den viser at det er en screen her nå, og den er attached. Og jeg er faktisk inni den screenen.", "source": "lecture"}
{"lecture_id": "linux6del7", "chunk_id": "linux6del7_0001", "start": 80.92, "end": 164.92, "token_count": 285, "text": "Men egentlig så har vi nå startet opp et nytt skjell akkurat der vi var tidligere. Hvis jeg tar PS, så ser jeg heller ikke noe. Men jeg kan gjøre en screen minus LS. Den viser at det er en screen her nå, og den er attached. Og jeg er faktisk inni den screenen. For å vise at jeg er i screenen, så har jeg lagd et lite skript, loop.shell. Og det eneste dette skriptet gjør, er å stå og loope wild true. Så får den en løkke, øker en arabermenn og skriver ut. Og så sover den i to sekunder. Så hvis jeg nå starter loop her inni denne screenen, så vil du se at den står og teller. Og for å gå ut av en screen så må man da gjøre en spesiell tastekombinasjon, og det er kontroll AD. Man holder da kontroll inne og taster så A. Først A. Og så det. Og da ser vi... Nå står det... Det er den forrige kommandoen jeg gjorde her ute. Og så står det nå melding... Og det er den screenen som jeg nå har.", "source": "lecture"}
{"lecture_id": "linux6del7", "chunk_id": "linux6del7_0002", "start": 146.0, "end": 230.68, "token_count": 290, "text": "Man holder da kontroll inne og taster så A. Først A. Og så det. Og da ser vi... Nå står det... Det er den forrige kommandoen jeg gjorde her ute. Og så står det nå melding... Og det er den screenen som jeg nå har. Så hvis jeg nå gjør screen minus LS, så vil jeg se... Jo, her er det en screen som står og kjører. Og hvis jeg skal koble meg til den screenen, så bruker jeg minus R og så navnet på screenen. Her holder det med OUS 100. Dette er liksom det hele navnet. Nei, det holder ikke. Vi må starte med starten. Jeg kan koble fra til og med den starten på navnet. Nå kommer jeg inn i screenen igjen, og her ser vi at loopen har fortsatt å gå etter at jeg kom inn. Så kan jeg gå ut igjen med ctrl-al-a og d. Så kan jeg f.eks. prøve å lage en ny screen. Så denne kan jeg kalle noe med opsjon minus s. F.eks. kan jeg kalle denne screen loop. Og det jeg har gjort nå, er at nå har jeg startet enda en ny screen.", "source": "lecture"}
{"lecture_id": "linux6del7", "chunk_id": "linux6del7_0003", "start": 206.44, "end": 295.24, "token_count": 287, "text": "Så kan jeg gå ut igjen med ctrl-al-a og d. Så kan jeg f.eks. prøve å lage en ny screen. Så denne kan jeg kalle noe med opsjon minus s. F.eks. kan jeg kalle denne screen loop. Og det jeg har gjort nå, er at nå har jeg startet enda en ny screen. Og screen minus LS vil si at den har en id, men den har også navnet loop. Og så kan jeg velge mellom etterpå hvilken screen jeg vil inn i. Inni loop her kan jeg starte en ny loop, og så kan jeg gå ut. Kontroll AD. Og så kan vi se... OK, nå har jeg to screens her. Men den jeg ønsker å koble meg til, det er loop. Og på den måten så kommer jeg inn i loopet, og da ser vi at den har gått relativt kort. andre jeg kan gå inn, Det er den her, som jeg ikke eksplisitt ga noe navn, men jeg kan bruke hele det navnet. Og den ser vi har kommet mye lenger. Og på den måten så kan jeg gå inn og ut av screen. Noe som også er veldig nyttig, er at hvis jeg nå logger helt ut,", "source": "lecture"}
{"lecture_id": "linux6del7", "chunk_id": "linux6del7_0004", "start": 270.0, "end": 365.0, "token_count": 292, "text": "Det er den her, som jeg ikke eksplisitt ga noe navn, men jeg kan bruke hele det navnet. Og den ser vi har kommet mye lenger. Og på den måten så kan jeg gå inn og ut av screen. Noe som også er veldig nyttig, er at hvis jeg nå logger helt ut, så når jeg er tilbake på Studio SOS og så går inn igjen, så vil begge disse screenene... Den vil fortsatt stå der. Og hvis jeg nå logger inn på loop igjen, så ser vi at den står der fortsatt og går. Så kan jeg gå ut med kontroll A, kontroll D. Ellers kan du se på hvordan du kan stoppe en screen. Hvis jeg nå går inn i screen loop igjen, og den står og går... Så hvis jeg i stedet taster kontroll A, kontroll D... Bare taster kontroll D, så tilsvarer det exit. Og da vil hele screen bli stoppet. Så når screenen minus 100, så ser vi at den loop-screenen er borte. Fortsatt så har vi den 29-screenen. Hvis det bare er én screen, den er entydig, så ser vi nå. Det har gått kjempelenge og godt.", "source": "lecture"}
{"lecture_id": "linux6del7", "chunk_id": "linux6del7_0005", "start": 339.68, "end": 436.2, "token_count": 299, "text": "Og da vil hele screen bli stoppet. Så når screenen minus 100, så ser vi at den loop-screenen er borte. Fortsatt så har vi den 29-screenen. Hvis det bare er én screen, den er entydig, så ser vi nå. Det har gått kjempelenge og godt. En annen ting som ikke er så lett, det er å scrolle opp og ned. Da er det igjen en spesiell tastekombinasjon, Control A, Escape. Da får man en modus hvor man kan gå med piltassene opp og se hva som har skjedd tidligere. Opp og ned igjen. Hvis man da taster Escape igjen... Så ser vi den copy mode abortet, og da... Da er det som vanlig å gjenta forrige kommandoer når man bruker pilltaster. Men altså... Kontroll A. Kontroll A og Escape. Den gjør at du kan scrolle opp og ned på den måten. Så Escape igjen. Da kommer man tilbake. Det hender man ikke husker om man er i en screen eller ikke. Det kan man sjekke ved en spesiell arabel, SDI. Hvis den gir en verdi, sånn som her, så betyr det at da er man i en screen.", "source": "lecture"}
{"lecture_id": "linux6del7", "chunk_id": "linux6del7_0006", "start": 414.52, "end": 466.6, "token_count": 157, "text": "Så Escape igjen. Da kommer man tilbake. Det hender man ikke husker om man er i en screen eller ikke. Det kan man sjekke ved en spesiell arabel, SDI. Hvis den gir en verdi, sånn som her, så betyr det at da er man i en screen. Hvis jeg nå går ut med kontroll og kontroll D, og så lister screens, så ser vi... OK, det var den jeg var i. Og her ute så vil ekkoet... Dollar SY vil da ikke gi noen ting. Men hvis jeg går inn i screenen, så ser vi at jeg da gir... Echo SY gir da en verdi. Mens ute gir det ingenting.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0000", "start": 0.0, "end": 108.52, "token_count": 300, "text": "Ja... Så vi har kommet ganske så langt. Det er nå tre uker fram til påske. Og i operativsystemer, i den teoretiske delen, så skal vi i dag se litt mer på prosesser, som vi har drevet mye med. Og vi skal egentlig fortsette med det neste uke også, hvor vi skal se på plattformavhengighet og threads. Og tråder, eller threads, det blir liksom det siste store temaet innen prosesser. Så vi jobber veldig mye med prosesser, men det er tross alt det man... Det er en veldig viktig del av et operativsystem og en veldig viktig del av hverdagen. Utviklere og programmerere og alle som jobber med data. Så vi bruker mye tid på det. På de digitale forelesningene så skal vi fortsette noe med dokker. Vi skal også se på regulære uttrykk. Og så skal vi begynne å se på virtuelle maskiner. Men vi får se hvor langt vi kommer kanskje etter påske. Eventuelt blir det etter påske. Det er spørsmål om... eksamen. På informasjonen om faget på Oslomedisinens side står det", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0001", "start": 79.36, "end": 179.96, "token_count": 299, "text": "Og så skal vi begynne å se på virtuelle maskiner. Men vi får se hvor langt vi kommer kanskje etter påske. Eventuelt blir det etter påske. Det er spørsmål om... eksamen. På informasjonen om faget på Oslomedisinens side står det at eksamenvurderingen er bestått, ikke bestått. Det må jeg undersøke, men jeg har søkt om at vi skal få bokstavkavle. Jeg trodde det egentlig var avgjort, men det er veldig fint dere spør. Da skal jeg sjekke ut det. Hvis dere ikke får beskjed snart, så... Så si ifra. For det er viktig å få avklart det med eksamen. I en digital eksamen, og så tilrettelegge det sånn at i hvert fall deler av eksamen blir individuell, sånn at ikke alle får samme spørsmål, sånn at det er veldig lett å samarbeide. Allerede i fjor hadde vi det med multiple choice-oppgaver, hvor man da fikk forskjellige typer oppgaver, eller veldig like oppgaver, men forskjellige tallverdier, da, f.eks., sånn at ikke...", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0002", "start": 160.36, "end": 246.64, "token_count": 293, "text": "sånn at ikke alle får samme spørsmål, sånn at det er veldig lett å samarbeide. Allerede i fjor hadde vi det med multiple choice-oppgaver, hvor man da fikk forskjellige typer oppgaver, eller veldig like oppgaver, men forskjellige tallverdier, da, f.eks., sånn at ikke... Man kunne bare kopiere fra en annen og samarbeide og levere inn sammen. Så det er planen. Derfor håper jeg også at det er mulig å få en noenlunde rettferdig bokstavkarakterfordeling. Men fint dere spør. Da skal jeg sjekke ut det. Og nå ser jeg Ine er her også. Hallo, Ine. Hei. Hei, hei. Der er du, ja. Har ikke fått deg ny laptop? Nei. Prøver å redde den fremdeles. Ja, det er bra. OK. Ja, jeg tror jeg har en du kan låne hvis det er skikkelig krise. Du bytter noen deler også, men vi får se hva du kan gjøre. Jeg må få en ny etter hvert. Ja, den er grei. Det var litt om fremover... Så i dag så...", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0003", "start": 210.0, "end": 309.92, "token_count": 297, "text": "Nei. Prøver å redde den fremdeles. Ja, det er bra. OK. Ja, jeg tror jeg har en du kan låne hvis det er skikkelig krise. Du bytter noen deler også, men vi får se hva du kan gjøre. Jeg må få en ny etter hvert. Ja, den er grei. Det var litt om fremover... Så i dag så... Er oppgavene. Handler om dockerfiles, TIX, systemtics... Nikes og folk. Det er stort sett det vi snakker om i dag. Men det er jo noen digitale forelesninger, og det var en som lurte på... Det kom kanskje ikke helt fram. Jeg har ikke fått delt opp alle disse dockerfile... Eller det vil si... De som kom nå forrige onsdag, de er deltatt på. Det er de oppgavene handler om. Det er disse her. Og det som er fokus her, er først og fremst docker files. Og hvordan man bruker det. For det er standardmåten man bruker docker på. At man definerer at man skal ha inn i en container i en docker file. Og når man skal kjøre, så bare bygger man den, og kjører i vei. I tillegg er det litt tema med volumes.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0004", "start": 288.76, "end": 383.4, "token_count": 300, "text": "Og hvordan man bruker det. For det er standardmåten man bruker docker på. At man definerer at man skal ha inn i en container i en docker file. Og når man skal kjøre, så bare bygger man den, og kjører i vei. I tillegg er det litt tema med volumes. Hvordan man kan mappe inn filsystemer inn i containere. For det er også den fordelen å ha containere som uavhengige enheter, som hele tiden kan stoppes og startes, og at man ikke da må save filer. Nå bruker de containere på en litt annen måte i deres tilfelle, Men det er da også egentlig konteinere. Men det er cysbox-konteinere som er av en spesiell art, som bruker virtualiseringsteknikker for å verne om eller for å øke sikkerheten for konteinerne. Vi kommer mer teoretisk tilbake til konteinere etter hvert. Nå i starten er det mest... Så er det mest... det praktiske. Hva med uka før? Skulle ikke de delen sin? Jo, jeg ligger et hakk etter, så jeg skal skikkelig ta en hard jobbøkt. Og så få delt inn alle videoene i mindre biter.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0005", "start": 360.0, "end": 449.92, "token_count": 286, "text": "Så er det mest... det praktiske. Hva med uka før? Skulle ikke de delen sin? Jo, jeg ligger et hakk etter, så jeg skal skikkelig ta en hard jobbøkt. Og så få delt inn alle videoene i mindre biter. For jeg vet at det er mye nyttigere for dere. Det er mye enklere hvis dere har en problemstilling dere ønsker å se på. Så det skal jeg få til i løpet av uka. Ok. Men det var én ting som var viktig her. Jo. Den første uklare autoriske oppgaven er spesielt viktig i år. Lagre et skip som først stopper alle kjørende dockcontainere. Og en sånn opprydding kan man... Når man har kommet i gang med dokkefiles, så er det greit å ha en sånn opprydding. For da har man ikke bygd et image som skal gjøre noe veldig spesielt. Hvis man skal ha i gang en konteiner, så bare bygger man fra den dokkefilen, og så har du konteineren. Og så setter du i gang i det. Og da blir også det meste mye ryddigere.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0006", "start": 429.88, "end": 516.44, "token_count": 287, "text": "For da har man ikke bygd et image som skal gjøre noe veldig spesielt. Hvis man skal ha i gang en konteiner, så bare bygger man fra den dokkefilen, og så har du konteineren. Og så setter du i gang i det. Og da blir også det meste mye ryddigere. For da kan du bare rydde bort alt, og da bruker man mindre ressurser. Og det som gjør at det er spesielt viktig i år, er at... Når vi kjøpte den serveren som vi bruker til dette her, så trodde vi at vi hadde et nettverksfilsystem som vi kunne bruke, men det visste jeg at vi ikke kunne, så derfor sitter vi igjen med en veldig liten disk på serveren, Den har faktisk ca. åtte ganger så mye ram som det er disk. Og det er ganske spesielt. Så masse ram, men lite disk. Og den begynte her for en uke siden og begynte å bli full. Så det er viktig å rydde bort image og containere, for de lagres sånn fortløpende. Hvis containeren deres stopper, eller blir stoppet,", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0007", "start": 488.92, "end": 569.96, "token_count": 293, "text": "Og det er ganske spesielt. Så masse ram, men lite disk. Og den begynte her for en uke siden og begynte å bli full. Så det er viktig å rydde bort image og containere, for de lagres sånn fortløpende. Hvis containeren deres stopper, eller blir stoppet, og vi starter den igjen, så vil dere fortsatt ha de samme filene der osv. Men dette lages på disken, og den begynner å fylles opp. Så det er viktig at dere gjør dette. Spesielt når du har begynt å komme i gang med dokkefiles. Så er det greit å bare ta en opprydding og fjerne alt. Ikke meningen vi skal gjøre det hver time, men sånn hver uke kanskje. Kjøre en opprydding. Så kan dere eventuelt spisse disse skriptene, sånn at dere ikke fjerner alpen... F.eks. ha en måte å spare noen av de imagene som dere bruker og har tenkt å bruke fremover. Ellers så er den viktigste oppgaven å gjøre det samme som i forrige ukes oppgaver igjen. Men denne gangen...", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0008", "start": 549.48, "end": 644.62, "token_count": 299, "text": "sånn at dere ikke fjerner alpen... F.eks. ha en måte å spare noen av de imagene som dere bruker og har tenkt å bruke fremover. Ellers så er den viktigste oppgaven å gjøre det samme som i forrige ukes oppgaver igjen. Men denne gangen... Med dokkefiles, som er en mer standard måte å gjøre det på enn å først bygge en Ubunter fra scratch og gå inn på den og installere osv. Det er mer den vanlige måten å gjøre det på en fysisk maskin eller en virtuell maskin. Men med containere så er det dokkefiles som gjelder, som er standardmåten å gjøre det på. Vi kommer mer tilbake til det teoretiske rundt dokker og virtuelle maskiner og fysiske maskiner. Men så det er en... Vi er egentlig... Vi ser på alle tre delene. Når jeg bruker den desktopen på jobben som heter Rex, og laptopen min som heter Lap, så er det fysiske maskiner. StudSSO, som dere bruker mye, det er en virtuell maskin. Mens dokker, det er containere oppå toppen der. Den viktigste forskjellen på virtuelle maskiner og containere,", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0009", "start": 619.88, "end": 713.26, "token_count": 293, "text": "som heter Rex, og laptopen min som heter Lap, så er det fysiske maskiner. StudSSO, som dere bruker mye, det er en virtuell maskin. Mens dokker, det er containere oppå toppen der. Den viktigste forskjellen på virtuelle maskiner og containere, er at virtuelle maskiner har sitt helt eget operativstem. Og dermed går det med veldig mye ressurser til det. Dokkekonteinere bruker det underliggende operativstemmet. Og dermed er det mye raskere å stoppe og starte. Og mye mer ressursbesparende. Så det er den største forskjellen. Men det kommer vi også enda mer tilbake til. OK. Da skal vi begynne å se på det vi skal gjøre i dag. Aller først skal vi se litt på systemkall og timertics. Vi kunne jo starte aller først med sist. Håper dere har fått med dere den forelesningen med vafler. Og jeg lager vaffelrøre og foreleser samtidig. Og det er langt fra bare på tull. Jeg håper at den illustrerer på en god måte hvordan et operativsystem virker.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0010", "start": 685.52, "end": 801.32, "token_count": 297, "text": "Vi kunne jo starte aller først med sist. Håper dere har fått med dere den forelesningen med vafler. Og jeg lager vaffelrøre og foreleser samtidig. Og det er langt fra bare på tull. Jeg håper at den illustrerer på en god måte hvordan et operativsystem virker. Og spesielt scheduleren som schedulerer mellom de prosessene som skal stå og kjøre. Jeg bruker en del referanser til dette, f.eks. dette med cornal mode. Med en gang en timer interrupt kommer, så setter jeg på hjelm. Og da kjører jeg i cornal mode. Og da er det kjernen som stiller. Og det er litt av det vi skal se på nå med systemkall. For som dere husker, for eksempel, når jeg skal knuse egg... Det var noe man ikke kan gjøre i UseMovds. Da må man inn og bruke hardware-ressurser, og da må man gjøre et systemcall. Så vi skal se litt i praksis på hvordan systemcall fungerer. Da skal vi se det i et terminalvindu. Her har jeg et C-program. getpid.c. Og det C-programmet... Det utfører et systemkall en rekke ganger.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0011", "start": 756.02, "end": 882.92, "token_count": 288, "text": "og da må man gjøre et systemcall. Så vi skal se litt i praksis på hvordan systemcall fungerer. Da skal vi se det i et terminalvindu. Her har jeg et C-program. getpid.c. Og det C-programmet... Det utfører et systemkall en rekke ganger. Så getpid... Det er faktisk et systemkall. Sånn at jeg kan utføre et systemcall direkte med en metode. Jeg har inkludert dette biblioteket der. Det er det mulig å kalle get paypay. Det er da get parent ID. Så vi skal ikke bruke den i den, men vi skal bare se hva som skjer når man utfører 10 mill. systemcall på... Så jeg kan da prøve å kompulere getpid. Og så kan jeg kalle det getpid. Sånn. Da får jeg et program som heter getpid. Og så kan jeg kjøre det. Da ser jo vi at det skjer ikke så mye. Men det som skjer i bakgrunnen... At vi kjører det 10 000 ganger. Men det jeg egentlig ønsker å se på, er... Hvor mye av dette foregår nå i UseMode, og hvor mye i Kölnmode?", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0012", "start": 863.08, "end": 966.66, "token_count": 285, "text": "Da ser jo vi at det skjer ikke så mye. Men det som skjer i bakgrunnen... At vi kjører det 10 000 ganger. Men det jeg egentlig ønsker å se på, er... Hvor mye av dette foregår nå i UseMode, og hvor mye i Kölnmode? Så da kan jeg åpne en annen fil som heter... Hva kalte jeg den? Sys. Og det de gjør, det prøver å telle opp antall tics som kjøres. Og da er det antall tics i use-involved og i curler-mode. Og vi har sett tidligere på Prock at her så ligger det informasjon dynamisk om hver prosess som kjøres. Og det dette programmet gjør, er at først så ser det på en linje som inneholder CPU3 i Proxat. Og denne linjen inneholder all informasjon om TIX som kjøres av CPU3. Og TIX, eller GIFIS, som det ofte omtales, det er... Det er den minste tidsenheten. Som typisk er et hundredels. Den kan varieres, men i praksis vil jeg si at den ofte er et hundredels sekund.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0013", "start": 943.2, "end": 1035.08, "token_count": 299, "text": "som kjøres av CPU3. Og TIX, eller GIFIS, som det ofte omtales, det er... Det er den minste tidsenheten. Som typisk er et hundredels. Den kan varieres, men i praksis vil jeg si at den ofte er et hundredels sekund. Og det er akkurat det samme som den kjøkkenklokka jeg hadde i vaffelsimuleringen, som bruker ett minutt, men i det virkelige tilfellet bruker den da et hundredels sekund. Og så er det i Proxats statistikk som teller opp hvor mange tics brukes i user mode. Og hvor mange tics brukes i curl-mode av systemet. Og det telles opp for hver prosess. Det er én oppgave denne uken som går ut på det. At dere skal se på hvor mange tics en regnejobb bruker. Og en regnejobb som regner hele tiden, den bruker da vanligvis 100 tics per sekund. Ca. 100 for hvert sekund. For den kjører bare beregnet i. Men her, når vi gjør den get paid pluss noen andre instruksjoner som ikke er systemkalt, så skal vi se at det blir litt forskjellig.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0014", "start": 1009.32, "end": 1115.36, "token_count": 298, "text": "Og en regnejobb som regner hele tiden, den bruker da vanligvis 100 tics per sekund. Ca. 100 for hvert sekund. For den kjører bare beregnet i. Men her, når vi gjør den get paid pluss noen andre instruksjoner som ikke er systemkalt, så skal vi se at det blir litt forskjellig. Så vi kan prøve å kjøre den SUS. Da ser vi... Den skriver ut linjen for CPU3. Get PPID. Og så skriver den ut linjene igjen. Og dermed så kan vi se hvordan tallene øker. Og da ser vi at det er to tall som øker. Det er den, den kolonnen, og så er det den. Og det kan være nyttig å finne ut... Å vite hvordan... Hvordan vet jeg hva disse tallene er? Det er altså nyttig i denne oppgaven. Men da kan man se på ManProk. ManProk er stor, men man kan søke på akkurat de feltene i Prok. Her kan vi søke på ProkStat. Under ProkStat så kan vi se at det står at det er linjer her. Her blir det veldig mye info. Vi kan ta med Proxtat, så skal vi se...", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0015", "start": 1087.64, "end": 1176.84, "token_count": 298, "text": "ManProk er stor, men man kan søke på akkurat de feltene i Prok. Her kan vi søke på ProkStat. Under ProkStat så kan vi se at det står at det er linjer her. Her blir det veldig mye info. Vi kan ta med Proxtat, så skal vi se... Første delen av Proxtat er ganske OK. Her er det et totalt oppsummert all-statistikk for alle CPU-ene. Og så ser vi det for hver enkelt CPU nedover her. Så det vi ser på nå, er CPU3. Og så må man også vite hva kolonnene betyr. Og vi ser første kolonne er User. Det er Time Spent in User Mode. Altså det er antall tics spent eller brukt i user-mode. Og så er det andre kolonne, And Nice. Det er det ikke så mange av. Men vi skal se på det senere i dag. Men så kommer den tredje kolonnen, som er time spent in system-mode. Fjerde kolonne, Idol, av den fjerdekolonnen er ofte veldig stor. Så denne er størst. For stort sett så ødelegger disse CPU-ene. Altså de gjør ingenting. Så summen of Idle er vanligvis størst.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0016", "start": 1152.48, "end": 1264.72, "token_count": 298, "text": "Men så kommer den tredje kolonnen, som er time spent in system-mode. Fjerde kolonne, Idol, av den fjerdekolonnen er ofte veldig stor. Så denne er størst. For stort sett så ødelegger disse CPU-ene. Altså de gjør ingenting. Så summen of Idle er vanligvis størst. Men vi ser da at du kan konstruere deg som user mode og system mode. Det er da antall tics som blir brukt av get prepaidet. Vi kan kjøre det en gang til. Og så... Ja... GPP i det. Den bare står og gjør systemcall. Men vi kan jo se hva den der gjør. Så først så grepper vi på CPU3. Og da ser vi... Da får vi ut den linjen her. Og det tallet her, 2 606 714, det er antall tics som er kjørt i... Og så ser vi... Forskjellen her er at den blir 7071. Ja, det var et spørsmål hvordan jeg søkte på ManPedge. Det er et godt spørsmål, så jeg kan ta det. Sånn. Og da står det en slash nederst til venstre. Og så skriver jeg ProkStat, og så kommer jeg dit.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0017", "start": 1224.92, "end": 1353.08, "token_count": 297, "text": "Og så ser vi... Forskjellen her er at den blir 7071. Ja, det var et spørsmål hvordan jeg søkte på ManPedge. Det er et godt spørsmål, så jeg kan ta det. Sånn. Og da står det en slash nederst til venstre. Og så skriver jeg ProkStat, og så kommer jeg dit. Hvis jeg skal finne neste, så taster jeg N. Ja, nå var det ikke noe neste, men... oi. Men la oss se på Stat, da. Så taster N. Så kan jeg bla meg nedover. Så det er veldig nyttig. Jo, vi så på det tallet her. Vi kan kjøre den en gang til, vel, så... Blir det litt lettere å se. Sånn, ja. Det var bare at den hoppet over fra 7000 her. Men her kan vi se... User-tricks 280920 minus user-tricks her 574. Og det... Det burde bli 354. Usertics. Og det betyr 354 hundredelssekunder. Er det ikke det? Kyss... Nei, vent litt. Det ble 26. Det er... 44 blir det vel. Nei, det kan det ikke bli. 46... Ja, det er litt tidlig for hoderegning.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0018", "start": 1326.76, "end": 1438.12, "token_count": 296, "text": "Usertics. Og det betyr 354 hundredelssekunder. Er det ikke det? Kyss... Nei, vent litt. Det ble 26. Det er... 44 blir det vel. Nei, det kan det ikke bli. 46... Ja, det er litt tidlig for hoderegning. Håper det ble riktig. 346 hundredeler. Det er forskjellen i user tics, og dette er antall hundredels sekunder som det programmet vi kjørte, brukte i user mode. Og så kan vi se på sys. Og det er her. Det ser vi blir litt færre. Kommet opp i 5000 der, minus dette tallet. Så det blir 136... 149, skulle det bli... 149 sånn. Det betyr 1,49 sekunder. Så kan man jo også... For å teste dette her så kunne man kjøre time. 3.56 er det en som sier det. Ja, da har du sikkert rett i det. Nei, 56. Blir det ikke for mye? Ja, det er ikke så farlig. Vi kan se på dette tilfellet i stedet. Nå kjører jeg i time på syst.so, og da kan vi se nøyaktig hva disse tallene er. For her kommer det opp noe tilsvarende.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0019", "start": 1419.1, "end": 1542.72, "token_count": 300, "text": "Nei, 56. Blir det ikke for mye? Ja, det er ikke så farlig. Vi kan se på dette tilfellet i stedet. Nå kjører jeg i time på syst.so, og da kan vi se nøyaktig hva disse tallene er. For her kommer det opp noe tilsvarende. Real-time 4,9 sekunder, user 3,5-3,1 og 1,4-18. Og disse skal da tilsvare hverandre. Og da kan vi forhåpentligvis se... Hvis vi nå prøver å trekke fra, da er det 180 pluss 172... Ja, det skulle bli... Tre... Roderegning... 3.52, ja. Det var en som hadde fått med seg det. 3.52 ble det riktige. Så kan vi ta antall tics i use mode minus antall tics... Nei, antall tics i kernel mode minus antall tics i kernel mode er 141. Og da ser vi... Dette stemmer med det som Time sier. Det gjør det, fordi det er den... Det er liksom den samme informasjonen som time-bruker for å få ut dette her. Så... Så her... Dette er hundredels sekunder. Så dette er 3,52.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0020", "start": 1517.6, "end": 1629.92, "token_count": 281, "text": "Og da ser vi... Dette stemmer med det som Time sier. Det gjør det, fordi det er den... Det er liksom den samme informasjonen som time-bruker for å få ut dette her. Så... Så her... Dette er hundredels sekunder. Så dette er 3,52. Så er det lite grann forskjell. Og så er det 1,41. Og da... 3,52 i Use-Mode og 1,41 i System-Mode. Alt i alt det dette betyr, det er at når vi kjører dette programmet... Get PPID... Så her gjør vi systemcall, og da ber vi systemkjernen gjøre dette her. Og da vil... I 1,41 sekunder så kjører vi i corner month. Oi, 3.52. Så gjør vi det. Hvis jeg hadde gjort det tilsvarende her med en reinjobb, så ville man sett at man bare kjørte i jusemot. Vi kunne jo teste det også. La meg da i stedet kjøre rein her. Da står vi og regner. Får håpe den ikke er altfor lang. Kanskje den tar litt for lang tid.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0021", "start": 1584.92, "end": 1716.8, "token_count": 297, "text": "Hvis jeg hadde gjort det tilsvarende her med en reinjobb, så ville man sett at man bare kjørte i jusemot. Vi kunne jo teste det også. La meg da i stedet kjøre rein her. Da står vi og regner. Får håpe den ikke er altfor lang. Kanskje den tar litt for lang tid. Den så ut til å ta litt lang tid, så jeg prøver på nytt med en kortere utgave. Og da ser vi. Da har det ikke skjedd noe. Her er statistikken den samme. Ingen tics har blitt utført i cullen mode. Mens her borte, her er alle ticsene kjørt. Så da står den og kjører i jusemode hele tiden. Man kjører time alene. Ja, det er riktig. Det blir bitte lite grann forskjell siden du skriver ut prokk også, for det gjør også noen tics. Men det er veldig få tics som går med til dette. Er dette fordi man må gå i curl-mode for å få gjort et suksesspall? Det er det. Så vi ser her når jeg kjører en regnejobb, sånn som dette, så kjører man i use mode hele tiden.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0022", "start": 1695.2, "end": 1787.68, "token_count": 283, "text": "Men det er veldig få tics som går med til dette. Er dette fordi man må gå i curl-mode for å få gjort et suksesspall? Det er det. Så vi ser her når jeg kjører en regnejobb, sånn som dette, så kjører man i use mode hele tiden. Da sier operativstemme at 'dette her er helt ufarlige greier'. 'Du trenger ikke old disk' eller noen ting. Så du skal bare regne. Så da kjører den prosessen i use mode hele tiden. Og dermed så ser vi at det er kun... Og vi vil jo også se det samme... Det har vi sett tidligere når vi kjører rein sånn, så ser vi at det er bare user modes. System 0,000. Kun user mode som kjører. Mens når vi ser på denne get PPPID, så er dette et systemkall. Og da går man inn i kjernen. Og det er kjernen. OK. Det var nok om systemkall. Kom gjerne med andre spørsmål, så kan vi ta det etter pausen eventuelt. Da skal vi ikke hoppe rett på nice, men vi skal si litt om prioritet.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0023", "start": 1760.08, "end": 1868.92, "token_count": 292, "text": "Og da går man inn i kjernen. Og det er kjernen. OK. Det var nok om systemkall. Kom gjerne med andre spørsmål, så kan vi ta det etter pausen eventuelt. Da skal vi ikke hoppe rett på nice, men vi skal si litt om prioritet. Å ha mellom prosesser, dvs. det er viktig å kunne skille prosesser på prioritet. Vi så i forrige uke at Linux opererer med noe sånt som 140 prioritetsklasser. Fra lav prioritet opp til høy. Og i utgangspunktet, det Linux-scheduleren gjør, er å gi mange tics... En lang time-slice til prosesser med høy prioritet. Og så velger man alltid den med høyest prioritet når man skal kjøre. Dvs. når scheduler kommer inn og skal gjøre en vurdering av hvilken prosess som skal settes i gang. Men grovt sett så er det Rollin' Robin. Man bare bytter på de som kjører. For selv en prosess som har høy prioritet og kommer først inn, når den er ferdig med sine tics i epoken, så vil den hoppe til neste. Og det er det som er Ron-Robin.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0024", "start": 1845.84, "end": 1921.78, "token_count": 287, "text": "Men grovt sett så er det Rollin' Robin. Man bare bytter på de som kjører. For selv en prosess som har høy prioritet og kommer først inn, når den er ferdig med sine tics i epoken, så vil den hoppe til neste. Og det er det som er Ron-Robin. Og dynamisk så vil den Linux-scheduleren, den vil da gjøre det sånn at interaktive brukerprosesser, de får høyere prioritet, sånn at med en gang de skal gjøre noe, så... Men de bruker gjerne ikke mye SUPU, så med en gang de er ferdige, så hopper de ut igjen. Mens batchjobber som står og bruker SUPU hele tiden, de har da lav prioritet. Men de jobber da hele tiden når ingen andre vil jobbe. Og det skal vi se på etterpå med nice, og det kan vi gjøre enda mer ekstremt. Vi kan velge å være nice og være enda mer batchjobb. Så er det forskjell på systemprosesser. Spesielt er det en del kjerneprosesser som jobber De kommer rett inn i køen, og de kan ikke kjøre Roan Robin,", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0025", "start": 1900.32, "end": 1974.52, "token_count": 286, "text": "Og det skal vi se på etterpå med nice, og det kan vi gjøre enda mer ekstremt. Vi kan velge å være nice og være enda mer batchjobb. Så er det forskjell på systemprosesser. Spesielt er det en del kjerneprosesser som jobber De kommer rett inn i køen, og de kan ikke kjøre Roan Robin, for de må da fullføre før noen andre kan kjøres. Det er typisk veldig korte prosesser som blir raskt ferdig, men de kommer inn, og så utfører de alt de skal, og så avslutter de. Så det er en litt annen måte å prioritere på. Og tilsvarende er det for andre operativsteammer. Alle har en type prioritering sånn som dette her. Generelt så finnes det mange scheduling- eller scheduleringsalgoritmer. Og den vi har sett på med Linux, er Ron Robin. Da bytter prosesser på å kjøre. Og tar litt tid hver runde. Og det finnes jo mange andre tilfeller hvor man bruker schedulering. Og alle disse metodene her brukes også i andre sammenhenger. Det er alle sammenhenger hvor man har ressurser.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0026", "start": 1953.16, "end": 2028.18, "token_count": 281, "text": "Og den vi har sett på med Linux, er Ron Robin. Da bytter prosesser på å kjøre. Og tar litt tid hver runde. Og det finnes jo mange andre tilfeller hvor man bruker schedulering. Og alle disse metodene her brukes også i andre sammenhenger. Det er alle sammenhenger hvor man har ressurser. Som regel er det tidsressurser, men det kan også være andre ressurser. First come, first served. Det som navnet sier, så er den første prosessen som kommer inn. Det er den som setter i gang uansett. FIFO er first in, first off. Det er en annen betegnelse på first come, first served. Først som kommer inn, er den første som blir ferdig, og første som sendes ut. Det er en litt annen måte å gjøre det på. Da er det den prosessen som tar kortest tid, som er den neste som kjøres. F.eks. hvis man skal printe ut ting, så kan det være en smart måte. Hvis det er fem sections som skriver ut én side, så gjør man det først. Og så kommer den som skal ha 150 sider. Den kommer til slutt.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0027", "start": 2010.14, "end": 2099.92, "token_count": 297, "text": "som er den neste som kjøres. F.eks. hvis man skal printe ut ting, så kan det være en smart måte. Hvis det er fem sections som skriver ut én side, så gjør man det først. Og så kommer den som skal ha 150 sider. Den kommer til slutt. Det er ikke alltid så lett å få til det, for da må man vite lengden på... Og det vet man generelt ikke når det gjelder prosesser. Så for prosesser så er det ikke så vanlig å ha den type skeduler. Nice. Nice er som ordet sier, å være snill med andre. Det er betydningen av ordet. Og det er akkurat det vi skal se på nå. Vi skal se hvordan vi kan endre på prioritering selv. På egne prosesser. Hvis vi ikke bruker NICE og ikke gjør dette eksplisitt, så er det jo operativsystemet som dynamisk endrer på prioriteten til prosesser. Og gir de forskjellig prioritet i forhold til hvor mye CPU de bruker. Interaktive prosesser som ikke bruker CPU, de får høy prioritet. Mens det motsatte med rene jobber. Men... nice irline... En kommando som eksplisitt nedprioriterer seg selv.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0028", "start": 2071.64, "end": 2160.54, "token_count": 296, "text": "så er det jo operativsystemet som dynamisk endrer på prioriteten til prosesser. Og gir de forskjellig prioritet i forhold til hvor mye CPU de bruker. Interaktive prosesser som ikke bruker CPU, de får høy prioritet. Mens det motsatte med rene jobber. Men... nice irline... En kommando som eksplisitt nedprioriterer seg selv. Så en Linux-prosess kan nedprioritere seg selv. Og da er det sånn at høyere nice-verdi gir mindre seputi. Det høres litt rart ut, men egentlig så er det logisk. For hvis du har en høy nice-verdi, den går opp til 19, som er maks, så er du ekstremt snill mot andre. Da er du veldig beskjeden, som lua i hånda bare tar seputix Defolt nice-verdi er null. Da ligger du på midten. Og du kan også ha negative nice-verdier. Og hvis du er negativ nice, da er du bad. Så de prosessene er slemme og tar ekstra CPU-tid fra de andre. Og det er da typisk noen sånne RUT-prosesser som har negativ nice-verdi. Det kommer noen oppgaver om dette også.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0029", "start": 2132.14, "end": 2254.4, "token_count": 292, "text": "Og hvis du er negativ nice, da er du bad. Så de prosessene er slemme og tar ekstra CPU-tid fra de andre. Og det er da typisk noen sånne RUT-prosesser som har negativ nice-verdi. Det kommer noen oppgaver om dette også. Litt av clouen da er at for å sette negative nice-verdier, så må du være roots, ellers får du ikke lov til det. Men vanlige brukere kan sette vanlige nice-verdier. Så... Ja, vi kan starte og så se litt på det. Jeg starter med regn, og så kan jeg sette... Oi! Nå skal vi gå på Nice, og da må jeg ha med dere. Der var vi. Ja, vi skal nå se på Nice og... Hvordan vi kan bruke Nice til å endre på prioriteten. Den jobben står og kjører lenge, sånn at jeg kan endre på nice-verdien. Så jeg kan ta... Først kan vi vise hvordan det brukes. Vi kan f.eks. starte nice minus N9 og så regn. Den starter da... En regnejobb med nice verdi 9. Og det kan vi se her når vi kjører topp. Så se her...", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0030", "start": 2227.0, "end": 2347.08, "token_count": 289, "text": "Så jeg kan ta... Først kan vi vise hvordan det brukes. Vi kan f.eks. starte nice minus N9 og så regn. Den starter da... En regnejobb med nice verdi 9. Og det kan vi se her når vi kjører topp. Så se her... Her står det 9. Det er da nice verdi 9. Men det som da er litt rart, er... Oi... Nå ser jeg at jeg står litt i veien her. Sånn.  Det som er litt rart, er at her oppe så ser vi... Denne jobben bruker jo 100 % CPU. Selv om den er nice. Så det var litt rart. La oss si jeg prøver å sette i gang en ting. Jo, den er veldig nice, men... Den bruker fortsatt så å si 100 % separatitet. Så skal vi se hvordan man også kan renice. Jeg kan renice og så si pluss 19 på den paydayen der, den som hadde 9. Og da setter vi Old Priority 9, New Priority 19... Vi kan sjekke om den er absolutt. Er det minus 3...? Nei, jeg får ikke lov til å sette minus 3. Da får jeg permission denied.", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0031", "start": 2319.44, "end": 2431.48, "token_count": 286, "text": "Jeg kan renice og så si pluss 19 på den paydayen der, den som hadde 9. Og da setter vi Old Priority 9, New Priority 19... Vi kan sjekke om den er absolutt. Er det minus 3...? Nei, jeg får ikke lov til å sette minus 3. Da får jeg permission denied. That's a minus... Det betyr bare z til... Nei, pluss skal altså... Jeg får ikke lov til å være negativ. Pluss 18 betyr... Sett verdien til pluss 18... Men hvorfor fikk jeg...? Ikke la være å renisse den... Gjør jo sånn, ja. Der fikk jeg prioritert 19 på den prosessen. Men likevel... Fortsatt er problemet her... Det høres ikke ut som noe av det jeg har sagt, er riktig i det hele tatt. De er jo ikke nice. De tar alle steppene. Du kan kanskje ikke gjøre den lavere? Ja, det var et godt spørsmål... Det skulle være mulig å gjøre det lavere. Det må jeg undersøke. Men det kan jeg ta pausen å gjøre. Og så kan dere også da... I pausen kan dere tenke på...", "source": "lecture"}
{"lecture_id": "os9time1", "chunk_id": "os9time1_0032", "start": 2395.72, "end": 2490.48, "token_count": 257, "text": "De er jo ikke nice. De tar alle steppene. Du kan kanskje ikke gjøre den lavere? Ja, det var et godt spørsmål... Det skulle være mulig å gjøre det lavere. Det må jeg undersøke. Men det kan jeg ta pausen å gjøre. Og så kan dere også da... I pausen kan dere tenke på... Hva er det som gjør at nice ikke ser ut til å ha noen effekt der? Hvorfor fortsetter de å kjøre i 100 % disse jobbene? Selv om de har en høy nice-verdi. Jeg ser for øvrig et par ruteprosesser. Det vil si den høyeste prioriteten du kan gitt i noen prosess med nice minus 20. Men de jobber ikke så mye, men med en gang de ønsker seg pus, så får de det. Og så blir det prioritert fremfor alle andre. Tenk litt på i pausen... Hva kan dette skyldes? Så kan vi se på om det går an å ri nese nedover. Da tar vi en liten pause der, så stopper jeg recordingen.", "source": "lecture"}
{"lecture_id": "os4del3", "chunk_id": "os4del3_0000", "start": 0.0, "end": 114.12, "token_count": 294, "text": "Der starter simuleringen, og så åpner jeg opp selve maskinen. Inni her, som vi har sett tidligere, så sitter alle maskininstruksjonene. Så... Når vi skal la denne maskinen kjøre, så kan vi f.eks. steppe gjennom. Da ser vi... Her gjorde vi den første instruksjonen, som var å legge tallet 3, som er de to siste bitene i denne første instruksjonen. I R0, som var det, bit nummer tre... Eller nummer fem og seks, blir det. Der er det to nuller. De to der. Det står for R0. De to siste bitene er det tretallet som legges inn i R0. Og de fire første bitene, det... Det er et tall som sier at nå skal vi gjøre institusjon nummer to. Og alt dette med hvordan de bitene er satt sammen, og hva som skjer når de gjøres, det er definert av maskinarkitekturen. Og den maskinarkitekturen er på en måte brent inn her. I instruksjonsdekoderen og i Datapath. Inni Datapath er alt som skjer av beregninger osv.", "source": "lecture"}
{"lecture_id": "os4del3", "chunk_id": "os4del3_0001", "start": 96.72, "end": 178.36, "token_count": 292, "text": "og hva som skjer når de gjøres, det er definert av maskinarkitekturen. Og den maskinarkitekturen er på en måte brent inn her. I instruksjonsdekoderen og i Datapath. Inni Datapath er alt som skjer av beregninger osv. Og vi ser i denne maskinen så ligger instruksjonene i rom. Og da er det ledninger som går fra rom og inn i institusjonsdekoderen. Og det er ledninger som sender alle disse åtte bitene som en institusjon gjør, inn til institusjonsdekoderen. Så oversetter institusjonsdekoderen denne koden til alle de bitene som må trykkes på, alle de rette bitene som må trykkes på, for at Datapath skal gjøre nøyaktig det som skjer. Senere... Senere så skal vi se at... Eller vi har sett tidligere at andre institusjoner her nede, det er sånn som den. Det er en ad-institusjon. Og ad har et annet nummer. Den er 0100. Så den er nummer fire. Det betyr at når det kommer en ad-institusjon, så overser...", "source": "lecture"}
{"lecture_id": "os4del3", "chunk_id": "os4del3_0002", "start": 156.58, "end": 227.14, "token_count": 254, "text": "Eller vi har sett tidligere at andre institusjoner her nede, det er sånn som den. Det er en ad-institusjon. Og ad har et annet nummer. Den er 0100. Så den er nummer fire. Det betyr at når det kommer en ad-institusjon, så overser... Det oversettes disse åtte tallene, eller dvs. UPP-koden her, som definerer hvilken instruksjon det er. De oversettes, så trykker man på de riktige knappene på Datapath, sånn at Alun legger sammen to tall. I tillegg kommer da de andre som sier hvilke registre man skal lagre i. De sier hvilket register skal jeg da legge sammen, sånn som R0 pluss R1. Og så resultatet legges i R0. Og dette er nok det samme som i X86, bare at enkelttallene er annerledes. Nummereringen av institusjoner er annerledes. Men i prinsippet er alt akkurat det samme.", "source": "lecture"}
{"lecture_id": "os3del10", "chunk_id": "os3del10_0000", "start": 0.0, "end": 105.28, "token_count": 284, "text": "Så skal vi prøve å bruke disse fire delåsene for å gjøre noe praktisk med det. For det oppstår faktisk fortsatt et problem. Selv etter at vi har lagd den fine devicen her, så har vi fortsatt et problem. Ja, og det er et litt mer komplekst problem. Men vi ser... Dette er måten man setter sammen biter på. Her ønsker jeg å lage et såkalt skiftregister, hvor vi har lagret 1-0-1-0. Og så ønsker vi at... Ved å skru på den bryteren her, så ønsker jeg å flytte alle bitene til høyre. Sånn at den nullen kommer inn her. Sånn at vi utfører da operasjonen ved å gå fra 1.01.0 til 0.101. Og denne operasjonen er faktisk da å dele på to, hvis man tenker på dette som et tall. Og denne konstitusjonen ser jo helt fin ut, fordi vi husker at q er det som lagres. Så hvis vi f.eks. ser på den siste enheten her, som har lagret en null, så ser vi at den leser en ener, verdien på...", "source": "lecture"}
{"lecture_id": "os3del10", "chunk_id": "os3del10_0001", "start": 69.04, "end": 162.88, "token_count": 297, "text": "Og denne operasjonen er faktisk da å dele på to, hvis man tenker på dette som et tall. Og denne konstitusjonen ser jo helt fin ut, fordi vi husker at q er det som lagres. Så hvis vi f.eks. ser på den siste enheten her, som har lagret en null, så ser vi at den leser en ener, verdien på... På den latchen, den låsen som står til venstre, det er en ener. Og den kommer inn som input på det. Og så lenge c er lik 1, så vil den da lese den verdien. På samme måte så vil denne her lese den nullen og få en null. Denne vil lese eneren og få en én. Denne leser null og får en null der. Og da vil det etterpå så vil det stå 0, 1, 0, 1. Og så kan vi da tenke oss at nøyaktig når vi har gjort det, så skrur vi av C, setter den til null, og dermed har vi utført den skiftoperasjonen. Men så er det et problem, og det som er problemet, er timing. Jeg sa at vi etter en stund så skrur vi av den eneren her.", "source": "lecture"}
{"lecture_id": "os3del10", "chunk_id": "os3del10_0002", "start": 136.96, "end": 225.0, "token_count": 298, "text": "Og så kan vi da tenke oss at nøyaktig når vi har gjort det, så skrur vi av C, setter den til null, og dermed har vi utført den skiftoperasjonen. Men så er det et problem, og det som er problemet, er timing. Jeg sa at vi etter en stund så skrur vi av den eneren her. Men da er... Setter den til null. Men da er spørsmålet hvordan får vi riktig timing her? Hvordan får vi skrudd av den i rett tid? Og det er en del av problemet. Fordi at... Dette er jo fysiske komponenter. Så når man skrur på den eneren og får denne til å virke, så vil det ta bitte litt tid, kanskje i underkant av et nanosekund, når disse komponentene er ekstremt små. Men likevel litt tid. Fra denne nullen propagerer... For det er jo strøm... Bitte små strømmer som strømmer. Propagerer sånn at den blir til en null. Og det tar litt tid. Og dermed så kan det være litt forskjell i hvor lang tid det tar. Og dette kan være enda større forskjeller hvis disse enhetene ikke er like.", "source": "lecture"}
{"lecture_id": "os3del10", "chunk_id": "os3del10_0003", "start": 196.52, "end": 292.96, "token_count": 291, "text": "Fra denne nullen propagerer... For det er jo strøm... Bitte små strømmer som strømmer. Propagerer sånn at den blir til en null. Og det tar litt tid. Og dermed så kan det være litt forskjell i hvor lang tid det tar. Og dette kan være enda større forskjeller hvis disse enhetene ikke er like. Da kan det virkelig være en avgjørende forskjell i tid på hvor lang tid det tar, før den strømmer herfra hit. Og med en gang det skjer, så får man et problem med at Denne leser jo en ener. Men hva om den nullen har propagert hit før den her har rukket å lese eneren? Da vil den jo lese null. Og hvis man har en liten usikkerhet i tiden her, så vil ikke dette her fungere. I tidligere år hvor vi hadde fysiske forelesninger, så prøvde jeg å... Ved at dere som studenter ble stilt opp i en rekke, sånn som dette. Med jenter og gutter. Jeg fant ingen gode studentillustrasjoner, så det ser jo ikke akkurat sånn ut. Men ideen var da at man setter opp åtte menneskelige dayloser på rad.", "source": "lecture"}
{"lecture_id": "os3del10", "chunk_id": "os3del10_0004", "start": 261.64, "end": 358.06, "token_count": 293, "text": "I tidligere år hvor vi hadde fysiske forelesninger, så prøvde jeg å... Ved at dere som studenter ble stilt opp i en rekke, sånn som dette. Med jenter og gutter. Jeg fant ingen gode studentillustrasjoner, så det ser jo ikke akkurat sånn ut. Men ideen var da at man setter opp åtte menneskelige dayloser på rad. En arm opp, sånn som de to her. Det betyr en ener. Og en arm ned. Det betyr en null. Og ideen var da at disse menneskene skulle virke som vipper. Og opplegget var da sånn at hun som står sist her, hun skal da se på den personen som står foran seg. Nei, det var faktisk motsatt. Han som står her, han skal se... Se på hun som står til høyre for seg. For dette skal også være et skifteregister. Og så her er det null. Hun har armen nede, og da skal han ta armen ned. Hun ser på han, så hun skal fortsette å holde armen opp. Han skal se på henne og skal løfte opp hånden, sånn at man får et skift. Altså at de to enerne går til venstre.", "source": "lecture"}
{"lecture_id": "os3del10", "chunk_id": "os3del10_0005", "start": 335.58, "end": 431.74, "token_count": 287, "text": "Og så her er det null. Hun har armen nede, og da skal han ta armen ned. Hun ser på han, så hun skal fortsette å holde armen opp. Han skal se på henne og skal løfte opp hånden, sånn at man får et skift. Altså at de to enerne går til venstre. Det viser seg når man setter opp dette og gjør det i praksis, så fungerer det veldig dårlig. Det er fordi det alltid er litt forskjell, når et menneske gjør noe sånt, i hvor lang tid man bruker. Det som hele tiden oppstår da, er sånn som her. Det er to enere, og så plutselig blir det tre enere, for du får en ener til. Det kan være fordi det er forskjell i hvor fort hun som står her, ser den hånden her. Så hvis han løfter den hånden veldig fort opp fordi han ser hunda-hånden i været, så vil hun plutselig ta hånden opp. Og dermed så oppstår det en bitt som kommer ut fra ingenting. Og dette er opplagt... Dette er opplagt ikke bra for en sånn enhet.", "source": "lecture"}
{"lecture_id": "os3del10", "chunk_id": "os3del10_0006", "start": 400.34, "end": 469.96, "token_count": 194, "text": "Så hvis han løfter den hånden veldig fort opp fordi han ser hunda-hånden i været, så vil hun plutselig ta hånden opp. Og dermed så oppstår det en bitt som kommer ut fra ingenting. Og dette er opplagt... Dette er opplagt ikke bra for en sånn enhet. Dette gjør at man overhodet ikke kan stole på et sånt skifteregister. Så da kommer den siste fiksen som gjør at man får en enhet man kan stole på. Og det er en såkalt debippe. Det man gjør da, er at man setter sammen to låser. Dette er master og slave. Det er to låser som man setter sammen til en såkalt vippe. Og dette er da den endelige enheten som man lagrer på.", "source": "lecture"}
{"lecture_id": "os3del5", "chunk_id": "os3del5_0000", "start": 0.0, "end": 103.48, "token_count": 274, "text": "Ja, nå er vi ferdig med en viktig del av aluen. Men den neste viktige nå er å kunne lagre dataene. Hvis vi går tilbake her, så ser vi... Jeg har ikke sagt noe om hvordan man lager disse bitene her. Men opplagt så trenger vi i en CPU utenpå aluen lagerenheter. Det kan også representere en bokstav, men vi må ha en lagerenhet som lagrer en rekke med bit. Det kalles et register. Og det er en veldig viktig komponent i NCPU. I tillegg at denne må kunne lagre tall, så må den være veldig rask. Disse logiske portene, de er ekstremt raske, så... Så den beste løsningen er å lage disse registrene av samme teknologi som man lager enda våre porter, nemlig med transistorer. Og det er det mulig å få til. Man kan i prinsippet... Det enkleste er måten å tenke seg Er å lagre en liten mengde med ladning, med elektrisk ladning. Akkurat som du gnir på en ballong, så har den positiv ladning.", "source": "lecture"}
{"lecture_id": "os3del5", "chunk_id": "os3del5_0001", "start": 74.68, "end": 157.8, "token_count": 282, "text": "som man lager enda våre porter, nemlig med transistorer. Og det er det mulig å få til. Man kan i prinsippet... Det enkleste er måten å tenke seg Er å lagre en liten mengde med ladning, med elektrisk ladning. Akkurat som du gnir på en ballong, så har den positiv ladning. Og så kan du ta på den, så får du et lite støt, og da lader du ut ballongen. Og da kunne du tenke deg at en ballong med ladning én, den er en ener. Og ladning null er en null. Det er noen problemer med ramm. For det første at det ikke er like hurtig som porter. Og for det andre så må de refreshes. Man må lade dem opp kanskje ti ganger i sekundet hvis du skal beholde den ene. Derfor bruker man ikke dette i CPU-er. Men man bruker i stedet såkalte vipper, eller flip-flops på engelsk. Og det er en konsesjon som ved hjelp av porter... gjør at man kan lagre nuller og enere. Vi skal se på i detalj hvordan man gjør det.", "source": "lecture"}
{"lecture_id": "os3del5", "chunk_id": "os3del5_0002", "start": 133.58, "end": 207.16, "token_count": 255, "text": "i sekundet hvis du skal beholde den ene. Derfor bruker man ikke dette i CPU-er. Men man bruker i stedet såkalte vipper, eller flip-flops på engelsk. Og det er en konsesjon som ved hjelp av porter... gjør at man kan lagre nuller og enere. Vi skal se på i detalj hvordan man gjør det. Og det er mye raskere enn RAM. Det er ikke ekstremt. Det er i hvert fall en faktor ti. Og kanskje mer i nå tilfelle. Men det er faktisk mye. Og et 64-bitteregister, for eksempel, det består da av 64 vipper. Så en vippe er én. Det er ikke så enkelt å bare lage en lagringsenhet av porter. Men noe som vi må få til, er å lage en lukket krets. Det er eneste måten vi kan lagre noe på, ellers er port bare input og output. Men vi ønsker å lagre det. Dermed må vi sette opp en...", "source": "lecture"}
{"lecture_id": "linux8del3", "chunk_id": "linux8del3_0000", "start": 0.0, "end": 87.96, "token_count": 284, "text": "Som dere ser så er det... Her har jeg mange konteinere som faktisk er oppe og kjører. Jeg har seks konteinere som står og kjører. Men det viser seg at det tar ikke så veldig mye ressurser. Hvis jeg kjører topp her nå, så... Ja, det... Vi har ikke all verden med minne her. Vi har en gigabyte, har brukt alt av det. Vi kan også se på... vi ser det er en del overlay som er i dokkerinstansene. Men hvis vi ser på den minnebruken, så tar imagene litt plass. Men ikke så voldsomt. Men det som er fint, er at når jeg har seks containere som kjører her, så er det egentlig seks fullverdige. De kjører webservere. Det er fullverdige systemer, men de bruker lite diskplass. Og relativt lite minne også. Det hadde ikke vært mulig å kjøre seks sånne VM-er på. På denne VM-en her. Vi sier også kjøre VM på VM, men det går faktisk an. Det er ganske vanlig å kjøre konteinere inni VM-er. Man kan også kjøre VM-er inne.", "source": "lecture"}
{"lecture_id": "linux8del3", "chunk_id": "linux8del3_0001", "start": 69.76, "end": 164.58, "token_count": 293, "text": "Og relativt lite minne også. Det hadde ikke vært mulig å kjøre seks sånne VM-er på. På denne VM-en her. Vi sier også kjøre VM på VM, men det går faktisk an. Det er ganske vanlig å kjøre konteinere inni VM-er. Man kan også kjøre VM-er inne. Det er klart. Det går med en gang litt... litt saktere. Men det er generelt hardway-støtte for å gjøre akkurat det. Ja. Det jeg tenkte å gjøre først, var å se på hvordan man kan rydde opp i alt dette her. Vi var vel inne på det litt sist, men hvis jeg tar PC minus A, så ser vi... Enda flere. Det er også da konteinere som er stoppet. Så... Generelt så vi sist på noen metoder for å stoppe... Ikke for å stoppe, men for å fjerne containere som ikke kjører. Og bl.a. Docker Prune kan man bruke. I oppgavene denne uken så er det en oppgave som går ut på å lage et script. Som sletter alt som er av konteinere som kjører og som ikke kjører. Jeg kan vise en teknikk som vi bruker for å få til det.", "source": "lecture"}
{"lecture_id": "linux8del3", "chunk_id": "linux8del3_0002", "start": 140.14, "end": 238.02, "token_count": 280, "text": "som ikke kjører. Og bl.a. Docker Prune kan man bruke. I oppgavene denne uken så er det en oppgave som går ut på å lage et script. Som sletter alt som er av konteinere som kjører og som ikke kjører. Jeg kan vise en teknikk som vi bruker for å få til det. Hvis jeg tar Dokker container... LS... Man kan bruke både LS og PS. Så lister jeg jo alle. Så ser vi at jeg får ut... bare ID-en. Dette kan jeg bruke i et skript eller fra kommandolinje til å stoppe enkeltcontainere. Så jeg kan... Hvis jeg eksplisitt skal stoppe en container... La oss si jeg stopper den øverste her. Så... kopiere ID-en, og så... Sånn. Så stoppes containeren. Hvis jeg lister nå, så ser vi at vi har fått én container mindre. Hvis vi har masse containere, kan det være greit å skripte det. En måte man kan gjøre det på, er da rett og slett å skrive forløket. Får se inn for container i... Og så kan jeg ta...", "source": "lecture"}
{"lecture_id": "linux8del3", "chunk_id": "linux8del3_0003", "start": 214.8, "end": 339.56, "token_count": 299, "text": "Hvis jeg lister nå, så ser vi at vi har fått én container mindre. Hvis vi har masse containere, kan det være greit å skripte det. En måte man kan gjøre det på, er da rett og slett å skrive forløket. Får se inn for container i... Og så kan jeg ta... Og så faktisk gjøre den kommandoen der, for den gir oss da hver idé. Så nå kan jeg for hver... For hver konteiner så kan jeg do. Og så kan jeg stoppe. Dere konteiner, stopp. Og da dollar det. Her gjorde jeg tydeligvis en feil. Ja, jeg tipper den feilen jeg gjorde, var... Nei. Noen gode forslag i chatten på... Ja, hva gjorde jeg feil? Jeg skrev for C, og så skrev jeg dollar D her. Så da var det ikke så klart det ikke gikk. Så da kan man gjøre et nytt forsøk. Stopp container. Får se inn dere i containeren. Stopp container. Da ser det litt bedre ut, men det tar litt tid å stoppe. Så stopper etter hvert de andre. Så dette er første del av skriptet. Så kan man stoppe alle konteinere.", "source": "lecture"}
{"lecture_id": "linux8del3", "chunk_id": "linux8del3_0004", "start": 306.44, "end": 440.52, "token_count": 285, "text": "Stopp container. Får se inn dere i containeren. Stopp container. Da ser det litt bedre ut, men det tar litt tid å stoppe. Så stopper etter hvert de andre. Så dette er første del av skriptet. Så kan man stoppe alle konteinere. Og når alle er stoppet, da er det enklere å slette alle. Da kan man... Ja, jeg tror en dokkersystem prune. Den vil... Den vil stoppe alle konteinere. Det tok litt lengre tid enn jeg hadde trodd å stoppe alle. Men da skulle det i hvert fall ikke være noen som kjører. Men hvis jeg har LSMSA, så vil fortsatt de som er exited, fortsatt være der. En dokker-system. Prune. Legg på en minus A-F. Det er for alle og Force. Da får man ikke noe spørsmål engang. Da ble det slettet en masse. Og så kan vi også se... Det var ikke så mye space som ble spart, men en god del. En halv gigabyte hjelper. Så... Hvis jeg lister nå, så vil jeg se jeg har ingen containere. Men det er fortsatt her. Det er... Nei. Det fjerner faktisk også alle image.", "source": "lecture"}
{"lecture_id": "linux8del3", "chunk_id": "linux8del3_0005", "start": 407.2, "end": 492.96, "token_count": 223, "text": "Da ble det slettet en masse. Og så kan vi også se... Det var ikke så mye space som ble spart, men en god del. En halv gigabyte hjelper. Så... Hvis jeg lister nå, så vil jeg se jeg har ingen containere. Men det er fortsatt her. Det er... Nei. Det fjerner faktisk også alle image. Ja. OK. Da fikk jeg faktisk... Ja, jeg tror det var den som gjorde at alt ble slettet. Eller så kan man gjøre tilsvarende hvis man eksplisitt bare vil... fjerne image. Så kan man kjøre den kommandoen. Men nå ser vi... Alt er rensket opp. Hvis jeg nå ser på disk... DF viser diskbruk. Så ser vi at... Det er ikke enormt mye jeg har fått til. Men nå har jeg 1,6 giga. Så det var noe sånn 0,7 giga eller noe sånt som...", "source": "lecture"}
{"lecture_id": "os13del9", "chunk_id": "os13del9_0000", "start": 0.0, "end": 86.0, "token_count": 248, "text": "Jeg ser Ina har kommet opp med et godt svar her. Det er Graphic DDR, ja. Så det er typisk sånt som brukes i GPU-er, som er da prosessoren som prosesserer grafikk. Og GPU-er, de har typisk veldig mange uavhengige kjerner. De har små kjerner med relativt lite ramp. Men de kan kanskje ha 4096 uavhengige kjerner som kan jobbe i parallell. Og det er opplagt nyttig når man jobber på grafikkenheter. Hvis man skal vri om på et 3D-bilde med enormt mange bits, så kan de operasjonene da gjøres i parallell. 4096 operasjoner gjøres helt samtidig. Det tilsvarer parallelle CPU-er, men de er mindre, og så gjør de akkurat denne operasjonen som er spesifisert for dem. Og GDDR er da den type ramme som GPU-ene bruker. Altså de grafiske prosessorenhetene.", "source": "lecture"}
{"lecture_id": "os8del4", "chunk_id": "os8del4_0000", "start": 0.0, "end": 94.3, "token_count": 294, "text": "Ok. Da skal vi se litt mer teoretisk på... Dette med scheduling og samtidige prosesser og hvordan et operativsystem da styrer det. Det store bildet av hvordan et operativ styrer. Ja, vi har allerede snakket mye om at det er viktig at to prosesser ikke må ødelegge for hverandre. To programmer som står og kjører samtidig på samme CPU... Må også delvis kjøre på hver sin CPU. Så må de f.eks. ikke skrive til samme del av minnet. For med multicore CPU-er så har vi jo samme minne. Så det må ikke være sånn at én prosess overskriver minnet for en annen. Så må det heller ikke være sånn at én prosess, hvis den ønsker det, Den setter opp en løkke og bare jobber og jobber og andre prosesser ikke får gjort noe. Og så kan det ikke være sånn at enkeltprosesser tar over hele CPU-en. At de f.eks. får hele systemet til å fryse. I verste fall kjører kommandoen holdt og stopper hele systemet. Sånn kan det opplagt ikke være. Det har vært mange løsninger opp gjennom tiden.", "source": "lecture"}
{"lecture_id": "os8del4", "chunk_id": "os8del4_0001", "start": 68.08, "end": 154.7, "token_count": 288, "text": "Og så kan det ikke være sånn at enkeltprosesser tar over hele CPU-en. At de f.eks. får hele systemet til å fryse. I verste fall kjører kommandoen holdt og stopper hele systemet. Sånn kan det opplagt ikke være. Det har vært mange løsninger opp gjennom tiden. En tidlig Windows-løsning, så var det sånn at man... Det var jo sånn Windows 95, hvor man begynte med multitasking. Så var det litt sånn at man hadde en frivillig operativstemme, bare overlot hele CPU-en til en prosess, men så måtte da prosessen frivillig gi den fra seg. Hvis det var bug i en sånn prosess og et eller annet galt, så kunne hele systemet låse seg. Så etter hvert så har alle moderne operativstemmer gått over til den beste løsningen, som er all makt til operativstemme, og som ofte kalles for preemptive multitasking. Og preemptive, det er... Opprinnelig så var det sånn i England at man skulle dele ut landområder til folk. Og det er på samme måte som Operativstemme gjør det.", "source": "lecture"}
{"lecture_id": "os8del4", "chunk_id": "os8del4_0002", "start": 131.32, "end": 224.28, "token_count": 292, "text": "til den beste løsningen, som er all makt til operativstemme, og som ofte kalles for preemptive multitasking. Og preemptive, det er... Opprinnelig så var det sånn i England at man skulle dele ut landområder til folk. Og det er på samme måte som Operativstemme gjør det. Den deler ut rettigheter til innbyggerne i landet, som da er prosessene. Og hver får sin del, og hver får sin del av ramm av minne og sin del av CPU. Så det vi skal se på nå, er hvordan kan Operativstemme i praksis få til dette. Ett prinsipp som er viktig... Operativstøtten må ha litt hjelp fra Hardware for å kunne få til dette. Og en viktig bestanddel i den hjelpen er prosessormodus. Og alle moderne prosessorer har et modusbitt som er 0 eller 1, og som begrenser hva som er lov å gjøre. Og det modusbittet switcher imellom, det er da brukermodus. Og privilegert-modus, eller cornal-mode, som det heter på engelsk. User-mode og cornal-mode. Dette kalles også ofte protection hardware.", "source": "lecture"}
{"lecture_id": "os8del4", "chunk_id": "os8del4_0003", "start": 202.1, "end": 289.92, "token_count": 300, "text": "og som begrenser hva som er lov å gjøre. Og det modusbittet switcher imellom, det er da brukermodus. Og privilegert-modus, eller cornal-mode, som det heter på engelsk. User-mode og cornal-mode. Dette kalles også ofte protection hardware. Og det er helt nødvendig for å kunne kjøre multitasking i det hele tatt. Hvis du ikke har noen forskjell på brukermodus og privilegert-modus,  Så vil da i prinsippet enhver prosess kunne ta over kontrollen på systemet. Og da... da vil alt avhenge av at den prosessen gjør ting riktig, og ikke fryser systemet. Det finnes systemer som er sånn. Vi skal se på unicurnals senere, og da er det typisk at du har en kjerne som bare gjør én bestemt ting, f.eks. bare er webserver. Da har man ikke brukere og andre prosesser osv. Da er det full kontroll til denne prosessen. Men den må da selvsagt ikke ødelegges i systemet. Men dette med prosessormodus er veldig viktig i et generelt operativsystem som skal kjøre mange prosesser samtidig. Vi kommer ofte til å bruke ordet use mode,", "source": "lecture"}
{"lecture_id": "os8del4", "chunk_id": "os8del4_0004", "start": 269.48, "end": 354.32, "token_count": 290, "text": "Da er det full kontroll til denne prosessen. Men den må da selvsagt ikke ødelegges i systemet. Men dette med prosessormodus er veldig viktig i et generelt operativsystem som skal kjøre mange prosesser samtidig. Vi kommer ofte til å bruke ordet use mode, altså den engelske betegnelsen på brukermodus. Det er begrenset aksess til ram og til instruksjoner. Så når CPU-en er switchet til use mode, så kan ikke alle instruksjoner utføres. F.eks. hvis du er i use mode og prøver å gjøre institusjonen holdt, eller stoppe maskinen, så blir den bare ignorert. Da skjer det ingenting. Og det er hovedhensikten med use mode. Man får ikke tilgang til alt som er i minnet. I cornal mode, eller privilegert modus, så kan alt... Alle institusjoner kan utføres, alt minne og alle registre. Alt kan gjøres. Og det er opplagt her, i cornal mode, der kjører operativsystem kjernen. Og det er hele ideen. Fra cornal mode så kontrollerer operativsystemkjernen alt som skjer.", "source": "lecture"}
{"lecture_id": "os13del20", "chunk_id": "os13del20_0000", "start": 0.0, "end": 62.72, "token_count": 175, "text": "Ja... Men hva om prosessen bruker mer enn Patients adresse? Ja... Da... Hvis... Ja, det... Et program vil alltid ha... Det hender man får sånn segmentation-folk, og det er typisk... Et program vil alltid ha... Det hender man får sånn segmentation fault, og det er typisk hvis et program her inne snakker om en adresse som ikke er sin. Så hvis den er utenfor sine sider, så vil du typisk få en page fault. Så en av de delene som operativstemaet må gjøre, er å sørge for at ingen programmer kan skrive over i andres minne. Men med paging så kan operativsystemet styre dette totalt, sånn at det sikrer at ingen overskriver forhånd.", "source": "lecture"}
{"lecture_id": "os11del3", "chunk_id": "os11del3_0000", "start": 0.0, "end": 106.76, "token_count": 295, "text": "Sånn. Da skal vi se på... Kalkmani. Det er et trådprogram implementert i Java, som implementerer en rekke tråder... Det var noen oppgaver i forrige uke som gikk ut på at man skulle se på hvor mange tråder som kjøres av operativsystemet når man kjører to tråder. Og da var det overraskende nok så var det veldig mange tråder som kjøres. Og det var en masse sånne workertreads som operativsystemet setter opp. Og som operativsystemet skredulerer. Så det er hjelpetråder som står klare til å gjøre alle slags forskjellige oppgaver. Det koster ikke så mye å ha disse ekstra trådene, så derfor er det veldig mange programmer, sånn som Java og Chrome og andre applikasjoner, som kjører en rekke tråder. Det koster ganske lite for operativsystemet å ha de trådene kjørende når de ikke brukes i PU. Men her er da et eksempel på... Et eksempel som kjører med mange tråder. Så vi kan gå ned til klassen Calcmanny her, som er main.", "source": "lecture"}
{"lecture_id": "os11del3", "chunk_id": "os11del3_0001", "start": 82.0, "end": 189.32, "token_count": 285, "text": "Det koster ganske lite for operativsystemet å ha de trådene kjørende når de ikke brukes i PU. Men her er da et eksempel på... Et eksempel som kjører med mange tråder. Så vi kan gå ned til klassen Calcmanny her, som er main. Og det som skjer her, er at vi definerer en intreds som er 20. Så det vi skal gjøre, er å starte 20 uavhengige tråder. Her opprettes et nytt trådobjekt, menu. Her opprettes en ny tråd. Og så skriver jeg bare ut at vi starter... At vi starter 20.30. Og så går jeg inn i forløkket. Her starter jeg da tråd nummer null... ... and new calcthread. Og så når college én, så starter jeg tråd nummer én osv. Og så kaller jeg på startmetoden for tråden. Så dette skjer da 20 ganger. Og hvis vi går opp her, så ser vi hva som skjer når calchtread... kalles. Da... Når Calcred startes opp, så kjøres denne Inject-metoden her.", "source": "lecture"}
{"lecture_id": "os11del3", "chunk_id": "os11del3_0002", "start": 162.76, "end": 275.1, "token_count": 298, "text": "Og så kaller jeg på startmetoden for tråden. Så dette skjer da 20 ganger. Og hvis vi går opp her, så ser vi hva som skjer når calchtread... kalles. Da... Når Calcred startes opp, så kjøres denne Inject-metoden her. Count pluss-pluss. Da er det viktig å huske at... Count er definert som static. Og det betyr at det finnes bare én av den for alle trådene. En variabel som ikke blir deklarert som static, som int id, den har vi da 20 stykker av. Når vi har en maks her, så kunne også den vært static. For den skal være en samme for alle. Men her lager vi også 20 maks. Men det viktigste her er konto id. Så hver gang vi gjør... Så økes den felles variabelen. Og dermed så teller den opp fra én og opp til 20. Og så setter ID en leak count, så da får vi en ID på hver. Og så sier jeg tredd nummer først én i starting, så tredd... Nummer én calculated work. Og her ser vi at den tråden gjør... La oss se bort fra den som er kommentert bort her.", "source": "lecture"}
{"lecture_id": "os11del3", "chunk_id": "os11del3_0003", "start": 252.6, "end": 352.66, "token_count": 299, "text": "Og så setter ID en leak count, så da får vi en ID på hver. Og så sier jeg tredd nummer først én i starting, så tredd... Nummer én calculated work. Og her ser vi at den tråden gjør... La oss se bort fra den som er kommentert bort her. Men det som skjer inneni work, er at 15 ganger så regner det ut en kjempelang løkke. Java er såpass rask at selv om man står og regner sånn som dette her, så kan man gjøre det 900 millioner ganger. Hvis man lager et høyere tall der, så blir det høyere enn en int. Så da får man trøbbel. Dette er ekstremt mange ganger den går. Men likevel så regner det mange ganger. Og det som er hovedpoenget her nå, med tråder, er at når vi setter i gang de, så kjører de samtidig. Så vi kan... Vi kan kompilere. Og... Ja, vi kan kjøre det her kanskje. Bare i sidevinduet, så vi kan se på trådene mens vi kjører. Jeg ser det starter veldig kjapt, så startes det opp 20 tråder.", "source": "lecture"}
{"lecture_id": "os11del3", "chunk_id": "os11del3_0004", "start": 330.0, "end": 433.08, "token_count": 296, "text": "Vi kan kompilere. Og... Ja, vi kan kjøre det her kanskje. Bare i sidevinduet, så vi kan se på trådene mens vi kjører. Jeg ser det starter veldig kjapt, så startes det opp 20 tråder. Så kan vi se på det i topp. I utgangspunktet så ser vi at... Det er én prosess som kjører. Men hvis vi legger på... Hvis vi velger ut 'number of threads', så ser vi at den ene prosessen som kjører, den har 37 tråder. Vi ser også at faktisk de fleste andre prosesser også har en rekke... Sånn som Zoom. Jeg har 64 tråder. Ops, har 27. Men det som er spesielt med våre tråder nå, er at 20 av de er de regnetrådene som vi har startet. Hvis vi taster H, stor H, så får vi se alle trådene. Da ser vi at det er 20 tråder som står og kjører. Så kunne vi også ta og... Se på Last Use CPU. Hvis jeg velger den også... Så ser vi da at trådene er skredulert på forskjellige CPU-er.", "source": "lecture"}
{"lecture_id": "os11del3", "chunk_id": "os11del3_0005", "start": 403.0, "end": 465.0, "token_count": 187, "text": "Hvis vi taster H, stor H, så får vi se alle trådene. Da ser vi at det er 20 tråder som står og kjører. Så kunne vi også ta og... Se på Last Use CPU. Hvis jeg velger den også... Så ser vi da at trådene er skredulert på forskjellige CPU-er. Noen er da så klart på mange, for her er det bare 0 til 7 av CPU-er. Men vi ser da hvordan det er operativsystemet som skredulerer alle trådene. Og så blir de skedulert av OS. Og akkurat det samme er det med alle de andre programmene. De starter en rekke tråder, men de blir skedulert som helt uavhengige enheter.", "source": "lecture"}
{"lecture_id": "linux9del5", "chunk_id": "linux9del5_0000", "start": 0.0, "end": 117.88, "token_count": 290, "text": "Da er jeg i ferd med å lage et skript som automatiserer oppgaven med å kompilere kode og teste ut hvor lang tid det tar i en docker container. Det jeg nå gjorde, var å... Teste ut koden her i Linux-VM. Men jeg vil få en del feil her. Jeg tror ikke jeg vil ha plass engang hvis jeg prøvde å installere det i tillegg til containerne. Det samme gjelder piten. Så forhåpentligvis så funker det. Men dette kan vi nå sjekke. Så vi lagrer den zoom.shell. Og så må vi da endre på dokkefeil. At den sum.shell legges inn i... I dokker-imaget. Da kan vi prøve oss å se på hvordan vi gjorde det forrige gang. Jeg hadde en dokk feil der. Og da ser vi... Dette her... Det skulle... Hvis jeg tar en copy litt tilsvarende den... Så burde dokkefeilen min også gjøre det. Det er ofte lurt å ta utgangspunkt i det man hadde tidligere. Så nå har jeg på filen... Eller ved siden av... Dokkefilen. Så har jeg en fil som heter summe.shell.", "source": "lecture"}
{"lecture_id": "linux9del5", "chunk_id": "linux9del5_0001", "start": 96.24, "end": 191.78, "token_count": 278, "text": "Så burde dokkefeilen min også gjøre det. Det er ofte lurt å ta utgangspunkt i det man hadde tidligere. Så nå har jeg på filen... Eller ved siden av... Dokkefilen. Så har jeg en fil som heter summe.shell. Og så vil jeg at den skal kopieres inn i... slash... sum. For når jeg gjør giktplanen her oppe, så lages en mappe som heter... ... sum øverst i filsystemet på dockercontaineren. Sånn. Så da har jeg en ny dockerfile. Så kan jeg save den. Og så må jeg gå ut av dockercontaineren, for nå skal jeg stoppe den og lage en ny. Og så kan jeg ta en dokker, container... Den stopper generelt alle konteinerne. Så kan jeg bygge på nytt. Sist tok dette åtte minutter, men nå ser vi. Nå tar det to sekunder. For nå er det bare den copperbiten der som jeg gjør på nytt. Alt det andre, det ligger i cash, og leses da fra cash, sånn at man slipper å komplere alt på nytt. Og da kan jeg...", "source": "lecture"}
{"lecture_id": "linux9del5", "chunk_id": "linux9del5_0002", "start": 169.2, "end": 291.92, "token_count": 300, "text": "Sist tok dette åtte minutter, men nå ser vi. Nå tar det to sekunder. For nå er det bare den copperbiten der som jeg gjør på nytt. Alt det andre, det ligger i cash, og leses da fra cash, sånn at man slipper å komplere alt på nytt. Og da kan jeg... Da kan jeg kjøre dere containerøyne igjen, minus IT akkurat samme måte som sist. Så kan vi se om dette har fungert. Da går jeg inn i sum, og så ser jeg... Ja, nå har jeg fått inn... Men jeg ser... Jeg burde gjøre en endring. Jeg burde også sette rettigheter på denne her. Sånn at... Med seomod. Da kan jeg kjøre en kommando. La oss si 7.55 på Sum... Sum.shell. Dette er da for å kunne automatisere i enda større grad. Så gjør jeg det interaktivt også. Så kan jeg prøve å kjøre, da. Da ser vi Shellscripte kjører, men som sagt... Det er ikke sikkert Shellscripte er riktig selv om det kjører. Men vi ser... Ja, vi får noen feil her. Ja, what could man not find? Oi, det var mye fælt.", "source": "lecture"}
{"lecture_id": "linux9del5", "chunk_id": "linux9del5_0003", "start": 270.0, "end": 382.8, "token_count": 283, "text": "Da ser vi Shellscripte kjører, men som sagt... Det er ikke sikkert Shellscripte er riktig selv om det kjører. Men vi ser... Ja, vi får noen feil her. Ja, what could man not find? Oi, det var mye fælt. Men noen av dem kjører. Skal vi se. Det var kanskje sånn jeg burde gjort opprinnelig. Utvikle denne... dette her. Den kjører, men... Ja, jeg har startet Java med stor J. Det fungerer ikke. Så... Da kan jeg rette opp den. Der skal det være liten J. I tillegg så var det kanskje... Kanskje Python... Command not fun... Det var... Ja, jeg har kanskje ikke installert Python. Jo. Jeg har installert Python 3. Ja, hvordan kommer jeg ut der? Jeg vet ikke hvordan jeg kommer ut av Python. Men da var det å kjøre kontroll P, kontroll Q. Da kom jeg ut av skjellet. Så kan jeg rette opp. Jeg installerte vel Python 3, sånn at da kjører jeg Python 3 i stedet. Skal vi se her. Ja, der står det Python 3.", "source": "lecture"}
{"lecture_id": "linux9del5", "chunk_id": "linux9del5_0004", "start": 354.2, "end": 500.12, "token_count": 300, "text": "Ja, hvordan kommer jeg ut der? Jeg vet ikke hvordan jeg kommer ut av Python. Men da var det å kjøre kontroll P, kontroll Q. Da kom jeg ut av skjellet. Så kan jeg rette opp. Jeg installerte vel Python 3, sånn at da kjører jeg Python 3 i stedet. Skal vi se her. Ja, der står det Python 3. Men nå så ser vi... Nå kan vi raskt stoppe konteinerne igjen. Og så kan jeg raskt starte den på nytt. Og der er jeg allerede inni konteineren. Så vi ser at hvis man bare gjør små endringer på dockerfile helt mot slutten her, så er det veldig raskt å gå inn og ut og få det til å virke som man skal. Da trenger man ikke åtte minutters kopulering. Det ser ut som den... I hvert fall ikke den CMOD-kommandoen fungerte. Men vi kan se om selve skriftet fungerer nå. Litt lengre tid der. Det var merkelig. Det ser ikke ut som jeg fikk... Lagt inn endringene. Ja, det er vel et generelt problem. Skal vi se. Da må jeg se. Gjorde jeg endringer her? Jo.", "source": "lecture"}
{"lecture_id": "linux9del5", "chunk_id": "linux9del5_0005", "start": 450.0, "end": 639.08, "token_count": 290, "text": "Litt lengre tid der. Det var merkelig. Det ser ikke ut som jeg fikk... Lagt inn endringene. Ja, det er vel et generelt problem. Skal vi se. Da må jeg se. Gjorde jeg endringer her? Jo. Dette er nytt. Og jeg har Python 3. Men det ser ikke ut som dette hadde en effekt. Da prøver jeg å gå ut igjen. Så prøver jeg å stoppe. Skal vi se hva jeg gjør her, egentlig? Ja, for det som kunne være, er at jeg ikke brukte cash. Eller at jeg brukte cash. Den kopieringen her, den ser ut til å bli gjort på nytt. Så da prøver jeg å gå inn igjen. Da er jeg inne i konteineren. Men iallfall nå ser vi at... Nå har Seomod blitt utført. For den kommandoen har tydeligvis blitt utført her. Hvis jeg nå ser på zoom.chell, så ser vi at Java står med liten bokstav og Python 3. Så dermed skulle jeg kunne kjøre zoom.chell her inne. Ja. Vi ser på denne måten, så kan man da utvikle en dokkefeil.", "source": "lecture"}
{"lecture_id": "linux9del5", "chunk_id": "linux9del5_0006", "start": 613.16, "end": 708.12, "token_count": 296, "text": "Hvis jeg nå ser på zoom.chell, så ser vi at Java står med liten bokstav og Python 3. Så dermed skulle jeg kunne kjøre zoom.chell her inne. Ja. Vi ser på denne måten, så kan man da utvikle en dokkefeil. Og raskt gjøre endringer og kjøre den på nytt, starte og stoppe konteineren. Neste stepp, i hvert fall i ukens utfordring, blir å gjøre dette her helt automatisk. Og da endre dokkefeilen, legge til det som vi hadde i forrige uke. Med å sette opp en webserver. Og så utvikle dette programmet som regner ut tidene. Og så til slutt kjøre det programmet sånn at output kommer til indeks.8ml i webserveren. Så da kan man bare sette i gang en container. Og så etter ti minutter har man da ferdig resultater. Uten at man løfter en finger. Så kan man enkelt teste ut hvordan dette fungerer i Ubuntu 1604 eller i RedHat. Men hvis du begynner med RedHat, så vil det straks være... Man måtte gjøre noen forskjeller. For da har RedHat ikke effektivitet.", "source": "lecture"}
{"lecture_id": "linux9del5", "chunk_id": "linux9del5_0007", "start": 681.66, "end": 774.0, "token_count": 280, "text": "Og så etter ti minutter har man da ferdig resultater. Uten at man løfter en finger. Så kan man enkelt teste ut hvordan dette fungerer i Ubuntu 1604 eller i RedHat. Men hvis du begynner med RedHat, så vil det straks være... Man måtte gjøre noen forskjeller. For da har RedHat ikke effektivitet. Men iallfall Debian og andre Ubuntu-varianter kan man med samme script teste ut. Uten å gjøre noe særlig arbeid selv. Eller manuelt arbeid. Men av resultatene så ser vi at det er litt forskjell, fordi f.eks. Python bruker dobbelt så lang... Eller de fleste bruker lengre tid. Men bortsett fra Shell-skriptet. Så i Dockery-konteineren så kommer Shell-skriptet litt bedre ut. Antall ganger i skriptene, sånn at alle gir 5,5 sekunder. Så typisk her, bare halverer du antall sepp, og så får du alle til å ta like lang tid. Og da får man et tall på hvor mye raskere de forskjellige programmene er enn selvskripte.", "source": "lecture"}
{"lecture_id": "linux6del11", "chunk_id": "linux6del11_0000", "start": 0.0, "end": 105.28, "token_count": 292, "text": "Vi har sett hvordan vi kan kopiere over mapper med SEP. La oss nå gjenta det eksempelet her. Her har jeg en mappe TMP på Linux VM på IS100. Og på Studio SSO så har jeg ikke noen sånn mappe. Men da kan jeg prøve å kopiere over den mappen ved å... Gjøre SEP. Group 100... 100 at os.100.vlab.cs.joa.no. Sånn. Og så må jeg si hvor den skal ligge, kolon. Og det er TMP som jeg ønsker å kopiere over. Og jeg ønsker å kopiere den hit. Og så ønsker jeg hele mappen med unde mapper og filer. Og da må jeg ha med minus r. Da vil den kopieres over hit. Og jeg ser jeg har TMP der. Men hvis jeg gjør dette på nytt, så ser vi - igjen så vil alle filene kopieres over. Og da fins det en annen kommando. Rsynk. Så ser vi. Igjen vil alle filene kopieres over. Og da fins det en annen kommando. Rsync. Som er litt mer intelligent. Den sjekker hvilke filer som finnes. Og så kopierer den over bare de som ikke finnes. Så hvis jeg nå fjerner TMP-en...", "source": "lecture"}
{"lecture_id": "linux6del11", "chunk_id": "linux6del11_0001", "start": 85.2, "end": 194.36, "token_count": 294, "text": "Og da fins det en annen kommando. Rsynk. Så ser vi. Igjen vil alle filene kopieres over. Og da fins det en annen kommando. Rsync. Som er litt mer intelligent. Den sjekker hvilke filer som finnes. Og så kopierer den over bare de som ikke finnes. Så hvis jeg nå fjerner TMP-en... Og så kan vi teste ut RSYNC i stedet på samme mappe. Hvis man får en sånn fernmelding, så betyr det at man ikke har installert RSYNC på begge sider. Så det betyr her, så... På LinningsVM-en så har jeg ikke installert RSYNC. Så da må jeg ta en app-dinsal på RSYNC. Så har jeg installert den. Så kan jeg prøve igjen, og da... ... kan vi se om det har fungert. Da kan vi sjekke TMP. Ja, da har vi fått over tre filer. Så kan vi prøve å lage en ny fil her. Og så gjør vi Arsing på nytt. Og da... Hvis vi da ser på temp, så ser vi at da har ny fil kommet over. Vi kan ikke se det, men det som skjer i bakgrunnen, er", "source": "lecture"}
{"lecture_id": "linux6del11", "chunk_id": "linux6del11_0002", "start": 165.28, "end": 263.88, "token_count": 270, "text": "Så kan vi prøve å lage en ny fil her. Og så gjør vi Arsing på nytt. Og da... Hvis vi da ser på temp, så ser vi at da har ny fil kommet over. Vi kan ikke se det, men det som skjer i bakgrunnen, er at ingen av de eksisterende filene kopies over. Så dette er veldig nyttig hvis man skal ta backup fra et system til et annet. Så kan man også legge på... Jo, en liten detalj her er at... Hvis jeg nå sletter én fil... Sånn. På Os100. Og så gjør en ny Rsynk. Så vil vi se at den filen i TMP, den er der fortsatt. Så her er det ikke én til én. Men hvis man ønsker at filer som slettes på det originale CD-et der man kopierer fra, også skal slettes dit man kopierer til, så kan man legge på minus, minus, delete. Sånn. Og da vil man se at det slettes nye filer. Det er ikke sikkert det alltid at man ønsker det. Hvis det er backup,", "source": "lecture"}
{"lecture_id": "linux6del11", "chunk_id": "linux6del11_0003", "start": 246.58, "end": 272.72, "token_count": 95, "text": "også skal slettes dit man kopierer til, så kan man legge på minus, minus, delete. Sånn. Og da vil man se at det slettes nye filer. Det er ikke sikkert det alltid at man ønsker det. Hvis det er backup, Eller på dette stedet, så ønsker du kanskje at den fortsatt skal være der. Men det er da et valg.", "source": "lecture"}
{"lecture_id": "linux1del7", "chunk_id": "linux1del7_0000", "start": 0.0, "end": 89.72, "token_count": 295, "text": "Nå skal vi se på hvordan vi lager Shellscript. Å lage Shellscript er veldig enkelt. Det er bare å åpne en editor og skrive inn tekst linje for linje med kommandoer. Og så save den og kjøre den. Så vi skal se helt konkret på hvordan vi gjør det. For det første så trenger vi en editor. Eller jeg kan først si - jeg er jo nå i en mappe mappe, og den mappen er tom. Så ser vi at det ikke ligger noen ting der. Så dermed må jeg lage et skript fra scratch. Jeg kan bruke en enkel editor som heter Nano, som kanskje er den enkleste å starte med. I mange av eksemplene bruker jeg gjedd. Vi kan se på det etterpå. Men jeg starter med Nano, og så kaller jeg skriptet mitt... Det kan hete hva som helst. Og så tar jeg på extension.sh, Så åpner jeg editoren, og da er det bare å starte å skrive her. Det er standard å bruke noen besvergelser i starten av et versskript. Og det dette her betyr, det er herstein utropstein. Det betyr at dette skriptet skal tolkes av...", "source": "lecture"}
{"lecture_id": "linux1del7", "chunk_id": "linux1del7_0001", "start": 60.0, "end": 148.4, "token_count": 281, "text": "Så åpner jeg editoren, og da er det bare å starte å skrive her. Det er standard å bruke noen besvergelser i starten av et versskript. Og det dette her betyr, det er herstein utropstein. Det betyr at dette skriptet skal tolkes av... Dette er da selve skjellet. Det er et binært program som ligger i mappen bind. Og dette programmet heter bæsj. Og det er da det programmet som tolker alle kommandoene som kommer nedover her. Så her kan jeg begynne å skrive skjellkommandoer som pd2d, ls kanskje, ls-l osv. Og dermed har jeg allerede et skript. Så det jeg trenger å gjøre nå, er å save det og gå ut. Så det kan jeg gjøre ved å bruke noen av de kommandoene som er her nede. Kontroll O... Den hakken der betyr kontroll. Hvis jeg tasser nå kontroll O, så skriver jeg, lagrer... dette skriptet. Fine line to write, script and chell, det er greit. Nå har jeg savet skriptet.", "source": "lecture"}
{"lecture_id": "linux1del7", "chunk_id": "linux1del7_0002", "start": 132.0, "end": 199.28, "token_count": 285, "text": "Kontroll O... Den hakken der betyr kontroll. Hvis jeg tasser nå kontroll O, så skriver jeg, lagrer... dette skriptet. Fine line to write, script and chell, det er greit. Nå har jeg savet skriptet. Hvis jeg er ferdig og har lyst til å gå ut og kjøre det, taster jeg Ctrl-X, som er Exit. Og dermed er jeg ute. Da kan jeg aller først liste opp og så se... Ja, nå har jeg lagd dette skriptet. Jeg kan se på innholdet i skriptet med CAT. Det ser sånn ut. Det ser bra ut. Og så kan jeg prøve å kjøre det. Det jeg typisk prøver på da, det er å bare skrive navnet. Men da ser vi... Nei. Da får jeg en command not found. Og det er av sikkerhetshensyn. Man må spesifisere hvor skriptet som jeg skal kjøre, ligger. Det går an å sette opp systemet sånn at man kan kjøre skripts fra hvor som helst. Da ville det bare ha startet. Men her må jeg eksplisitt si hvor dette skriptet ligger.", "source": "lecture"}
{"lecture_id": "linux1del7", "chunk_id": "linux1del7_0003", "start": 182.72, "end": 265.46, "token_count": 286, "text": "Man må spesifisere hvor skriptet som jeg skal kjøre, ligger. Det går an å sette opp systemet sånn at man kan kjøre skripts fra hvor som helst. Da ville det bare ha startet. Men her må jeg eksplisitt si hvor dette skriptet ligger. Og da kan jeg skrive full path til mappen det ligger i. Så jeg kunne kjørt det ved å skrive hele denne... Hele denne strengen her, og så script.shell. Da sier man hvor det ligger. Men noe som er enklere, er å si... Prikk, det er den mappen jeg står i. Så jeg kan si at det skriptet jeg skal kjøre, det ligger i prikk-slæsj. Her ligger dette skriftet. Og så kan jeg kjøre det. Men da ser vi... Jeg får på Mission United, og det er fordi Vi skal se på dette i detalj senere, men... Rettighetene er de som står her. Rw dash. Eller rw-strek. Dette er rettighetene for programmet. Og det betyr read and write. Men så burde det stått en x der. For den x-en må man ha for å kunne kjøre det.", "source": "lecture"}
{"lecture_id": "linux1del7", "chunk_id": "linux1del7_0004", "start": 240.0, "end": 323.6, "token_count": 298, "text": "Vi skal se på dette i detalj senere, men... Rettighetene er de som står her. Rw dash. Eller rw-strek. Dette er rettighetene for programmet. Og det betyr read and write. Men så burde det stått en x der. For den x-en må man ha for å kunne kjøre det. Og det kan vi få til ved å bruke en annen kommando. Vi skal se mer på dette seinere, men den kommanden heter comod. Change-modus. Og så bruker jeg en kode for å endre den. Jeg bruker 700. Vi skal se hva det betyr også. Og så navnet på skriptet. Jeg skriver comod 700 skrift.dachel. Hvis jeg nå lister, så vil jeg se at nå står det rwx. Og det betyr at jeg som bruker, har rettighet til... Til å lese, skrive og kjøre dette skriptet. Så nå kan jeg på nytt prøve å kjøre det. Nå kan jeg altså taste tab. Det jeg gjorde nå, var at jeg skrev.slash essay, og så tastet jeg tab. Og da ser du at skjellet fullfører den kommandoen, så lenge den er entydig.", "source": "lecture"}
{"lecture_id": "linux1del7", "chunk_id": "linux1del7_0005", "start": 305.96, "end": 383.16, "token_count": 289, "text": "Så nå kan jeg på nytt prøve å kjøre det. Nå kan jeg altså taste tab. Det jeg gjorde nå, var at jeg skrev.slash essay, og så tastet jeg tab. Og da ser du at skjellet fullfører den kommandoen, så lenge den er entydig. Og dermed kan jeg taste return og kjøre skriptet. Det som skjedde nå, var at scriptet kjørte, og det utførte kommandoene én for én. Først pwd, som ga denne linjen her, så ls, som ga linjen med script og skjell, og så ls minus l, som ga hele denne utscripten. Og dermed har vi laget og kjørt et script, og den prosessen er egentlig så enkel. Det eneste man må passe på, er at scriptet må være Og rettigheter til å kjøre for at man skal få kjørt det. Jeg nevnte at jeg ofte bruker Jed, og det er også en veldig enkel editor. Men den er litt mer kryptisk på den måten at kommandoene står ikke som om man lærer seg noen få kommandoer for å lagre, blant annet.", "source": "lecture"}
{"lecture_id": "linux1del7", "chunk_id": "linux1del7_0006", "start": 360.0, "end": 442.16, "token_count": 272, "text": "Og rettigheter til å kjøre for at man skal få kjørt det. Jeg nevnte at jeg ofte bruker Jed, og det er også en veldig enkel editor. Men den er litt mer kryptisk på den måten at kommandoene står ikke som om man lærer seg noen få kommandoer for å lagre, blant annet. Så jeg kan vise kjapt hvordan den virker også. Jed... JDD... Da ser det ganske likt ut som ellers. Kan skrive inn nye kommandoer her. Det jeg trenger å vite da, er hvordan saver jeg, og hvordan går jeg ut. Save er en tastekombinasjon kontroll-x-s. Nå taster jeg kontroll-x og så s, og da saver man den. Kontroll-x og C, da går man ut. Fortsatt er det de to mannene trenger. Så er jeg ute, og så kan jeg kjøre det på nytt. Og da ser vi skriptet kjørte som før. Eneste tillegget var at jeg fikk denne linjen her, som viser output fra uname minus a. Uname ber meg si hva slags OS jeg kjører.", "source": "lecture"}
{"lecture_id": "os7del6", "chunk_id": "os7del6_0000", "start": 0.0, "end": 88.96, "token_count": 288, "text": "Vi skal fortsatt se på mikroarkitektur og datamaskinarkitektur og hvordan multitasking foregår. Men for å forstå multitasking er det viktig å forstå hva cash er, og hvordan internminnet opererer sammen med CPU-en. Vi har sett på internminnet tidligere. I simulerings-CPU-en vår så vi hvordan vi hadde Både egne instruksjoner som flytter data fra registeret og ut i internminnet. Og da er den store problemstillingen med RAM og CPU at RAM er relativt tregt. En CPU utfører instruksjoner veldig mye raskere enn det kan hentes fra RAM. Det er kanskje en faktor ti. Og hvis man ikke gjorde noe med det, så måtte Sippune så vente hele tiden på data. For instruksjoner må hentes fra RAM. Et program som kjøres. Alle instruksjonene ligger i RAM. Og for å kjøre dem, så må de hentes én og én fra RAM. Og hvis det går mye saktere enn den tiden det tar å utføre en instruksjon, så hoper det seg opp med instruksjoner, og det går ikke så fort...", "source": "lecture"}
{"lecture_id": "os7del6", "chunk_id": "os7del6_0001", "start": 71.8, "end": 159.36, "token_count": 281, "text": "Et program som kjøres. Alle instruksjonene ligger i RAM. Og for å kjøre dem, så må de hentes én og én fra RAM. Og hvis det går mye saktere enn den tiden det tar å utføre en instruksjon, så hoper det seg opp med instruksjoner, og det går ikke så fort... Og det er der cash kommer inn. Cash er egentlig fransk og betyr et hemmelig lager. Så cash er et mellomlager mellom ram og CPU. Og cash er et veldig hurtig-ram, så vi skal se er det S-ram? Det er akkurat samme teknologi som det er i registrene. På et digert lager med ekstra registre. Men de er ikke registre i den betydning at CPU-en oppfatter dem som registre. De er bare en mellomlagring av data fra RAM på vei inn til CPU-en og på vei ut fra CPU-en. Og hele prinsippet med at det hjelper å få et hurtiglager mellom RAM og CPU, Statistisk sett, når man utfører institusjoner, så bruker man bare en liten del av minnet.", "source": "lecture"}
{"lecture_id": "os7del6", "chunk_id": "os7del6_0002", "start": 135.84, "end": 233.8, "token_count": 299, "text": "på vei inn til CPU-en og på vei ut fra CPU-en. Og hele prinsippet med at det hjelper å få et hurtiglager mellom RAM og CPU, Statistisk sett, når man utfører institusjoner, så bruker man bare en liten del av minnet. Det er en liten del av institusjonene som statistisk sett utføres om og om igjen. Og ofte er det også sånn at man bruker om og om igjen data i ram som ligger ved siden av hverandre, f.eks. i et ærøy. Så dermed er det mye tid å spare hvis man henter mange biter av gangen. I cash. Vi skal se på etterpå hvordan det ser ut sånn rent fysisk. Minnepyramiden er et viktig prinsipp. Og prinsippet er at vi har forskjellige enheter som lagrer data, og som er koblet til en CPU. Her er det veldig stor forskjell på hvor lang tid det tar å hente dataene. Vi har registrene øverst i minnepyramiden. De er de raskeste, og de bruker kortest tid på å hente data til aluen. For det er jo registrene som er koblet til aluen, så der går det lynkjapt.", "source": "lecture"}
{"lecture_id": "os7del6", "chunk_id": "os7del6_0003", "start": 210.0, "end": 290.4, "token_count": 292, "text": "Her er det veldig stor forskjell på hvor lang tid det tar å hente dataene. Vi har registrene øverst i minnepyramiden. De er de raskeste, og de bruker kortest tid på å hente data til aluen. For det er jo registrene som er koblet til aluen, så der går det lynkjapt. Og så har man noen lag med cash. Her har jeg L1-cash og L2-cash. De fleste moderne superviraer har L3-cash også i tillegg, som da går litt saktere, men teknologien her er den samme. Dette er S-ram. De er veldig hurtige, men det er større mengde. Så vi har flere megabyte med L2-cash, og det tar da litt tid å frakte det inn til registrene. Så derfor går det litt lenger tid. Så kommer man ned til ram, som er 4-8 gigabyte. Men hovedpoenget er at det går omtrent en faktor ti saktere å hente inn data fra RAM. Så det er derfor man bruker det mellomlageret her med cash. For å mellomlagre det som må hentes fra RAM, sånn at det kommer raskere inn til reaserne.", "source": "lecture"}
{"lecture_id": "os7del6", "chunk_id": "os7del6_0004", "start": 270.0, "end": 359.68, "token_count": 293, "text": "Men hovedpoenget er at det går omtrent en faktor ti saktere å hente inn data fra RAM. Så det er derfor man bruker det mellomlageret her med cash. For å mellomlagre det som må hentes fra RAM, sånn at det kommer raskere inn til reaserne. Vi skal se på etterpå nøyaktig hvordan det kommer raskere inn. Senere i kurset skal vi se på harddisker også. Her er HDD-disk... Hardware Drive, som er en tradisjonell disk. Og den er et platelager med disker som fysisk snurrer rundt, sånn som CD-er. Og her har vi SSD, Solid State Disk, som vi ser røfflig, En vilkårlig... En vilkårlig bite på disken. Riktignok henter du gjerne 512 av gangen, men når du skal hente vilkårlig bite på disken, så går SSE-disk mye raskere. For her er det ikke noen fysiske plater som snurrer rundt. Det er mer som sånn minne på minnepinner. Men likevel så er det en factor 1000 saktere ramme, så det går fortsatt veldig sakte.", "source": "lecture"}
{"lecture_id": "os7del6", "chunk_id": "os7del6_0005", "start": 340.24, "end": 396.04, "token_count": 211, "text": "vilkårlig bite på disken, så går SSE-disk mye raskere. For her er det ikke noen fysiske plater som snurrer rundt. Det er mer som sånn minne på minnepinner. Men likevel så er det en factor 1000 saktere ramme, så det går fortsatt veldig sakte. For vesentlig raskere enn fra harddisk. Ja, det er noen spørsmål om SSD-disken, om det... Ja, vi kommer tilbake til det senere. Men det er en del andre begrensninger med SSD. Altså hvordan du kobler den opp til maskinen. Hva slags buss du har ut til SSD-en. Det har også en del å si. Men med sånn optimal tilkobling på begge, så kan det være en... En fakta på 1000. Men mer om det senere når vi skal snakke om disker.", "source": "lecture"}
{"lecture_id": "os7del15", "chunk_id": "os7del15_0000", "start": 0.0, "end": 104.92, "token_count": 299, "text": "Her er jeg nå på den Rex desktop. Den ser vi her når jeg taster én i topp, så får jeg opp at den har fire Sippu-er. Men her ser vi at jeg har en løkke som endrer på noe i Systevise System Sippu Online. Og den kan sette de forskjellige Sippu-ene. Så det er åtte CPU-er her. Så det jeg gjør nå, er at jeg setter de resterende fire online. Sånn at hvis jeg nå taster topp og én, så ser vi - vips! Så kommer det fire CPU-er til. Så nå er denne en server eller en desktop med fire... Nei, med åtte CPU-er. Så ser vi også at dette her er one line sippu-list. 0 til 7. Åtte sippu-er. Men så ser vi at det står 2 treads per core og core per sockets. Og vi ser også at dette er en Intel Core E7. Hvis man slår opp på det, så vil man finne ut at denne her bruker hypertrening. Det eneste påstandet nå er at dette er hypertrødning. Den er faktisk... Det er egentlig ikke åtte helt uavhengige course. Sånn som operativsystemet fremstiller det.", "source": "lecture"}
{"lecture_id": "os7del15", "chunk_id": "os7del15_0001", "start": 81.24, "end": 178.68, "token_count": 288, "text": "Hvis man slår opp på det, så vil man finne ut at denne her bruker hypertrening. Det eneste påstandet nå er at dette er hypertrødning. Den er faktisk... Det er egentlig ikke åtte helt uavhengige course. Sånn som operativsystemet fremstiller det. Og sånn som det ser ut når man kjører topp eller hot-topp. Så ser man... Her er det åtte super. Men vi skal nå se på hvordan det ser ut når vi faktisk kjører prosess. Eller er det egentlig fire? Det er problemstillingen her nå. Er dette åtte helt selvstendige CPU-er? Eller er det fire CPU-er som kjører hyper-trading og på en måte lurer OS til å tro at det er åtte? Så det første vi kan gjøre da, det er jo også prøve å kjøre mange... Mange prosesser. Så ser jeg hvordan det ser ut. Og vi hadde en fåløkke med reine... Ja, da ble det veldig mange. Det man kan gjøre litt enklere, er å si noe sånt. La oss si jeg har én til åtte prosesser. Så kjører jeg topp her samtidig.", "source": "lecture"}
{"lecture_id": "os7del15", "chunk_id": "os7del15_0002", "start": 150.0, "end": 275.42, "token_count": 294, "text": "Mange prosesser. Så ser jeg hvordan det ser ut. Og vi hadde en fåløkke med reine... Ja, da ble det veldig mange. Det man kan gjøre litt enklere, er å si noe sånt. La oss si jeg har én til åtte prosesser. Så kjører jeg topp her samtidig. Oi. Nå ser jeg jeg har feil vindu. Rop ut. Ja vel. Jeg kan gjøre det på nytt. Det jeg gjorde, var at jeg startet åtte regnprosesser. Og så ser vi... Nå er det åtte CPU-er som står og kjører her. Vi kan i grunnen... Bare for å få det veldig eksplisitt, så kan vi sette på den... Last Used CPU her nede. Så kan vi prøve å få med den. Så må jeg få... Oi... Utvide topp lite grann. Der, ja. Der har vi LASJus CPU. Så kjører jeg nå åtte prosesser. Og vi ser da 01628 osv. De kjører i parallell på disse åtte CPU-ene. Sånn sett så ser det jo vel da bra ut. Men... Da er spørsmålet... Hvordan kan jeg finne ut nå...", "source": "lecture"}
{"lecture_id": "os7del15", "chunk_id": "os7del15_0003", "start": 244.88, "end": 343.5, "token_count": 300, "text": "Så kjører jeg nå åtte prosesser. Og vi ser da 01628 osv. De kjører i parallell på disse åtte CPU-ene. Sånn sett så ser det jo vel da bra ut. Men... Da er spørsmålet... Hvordan kan jeg finne ut nå... Er dette 100 %... Kjører de 100 % på helt uavhengige regneenheter? Eller er det hypertraining? Sånn som man kan lese at det faktisk er. Og hvordan ser man i så fall forskjell på det?  Jo, for å gjøre en lang, stor rekord, så kan man jo... Hvis det er hypertrening, så betyr det at da er det fire aluer. Og hvis det da er åtte jobber som står og jobber, så er det klart, da har operativsteamet satt inn to stykker på hver av CPU-ene, og de må da bytte på og... De må da dele på den aluen, og det vil jo ikke da gå like fort å kjøre. Så det vi kan gjøre, er å prøve å ta noen eksperimenter. Først så kan jeg prøve å kjøre fire jobber. Nå er de på hver sine CPU. Og kjører full rulle på dem.", "source": "lecture"}
{"lecture_id": "os7del15", "chunk_id": "os7del15_0004", "start": 320.28, "end": 413.18, "token_count": 296, "text": "De må da dele på den aluen, og det vil jo ikke da gå like fort å kjøre. Så det vi kan gjøre, er å prøve å ta noen eksperimenter. Først så kan jeg prøve å kjøre fire jobber. Nå er de på hver sine CPU. Og kjører full rulle på dem. Og så kan vi se hvor lang tid tar egentlig det. Så dette er på en måte litt sånn som... Hvis man har potetskrellere, altså personer som skreller poteter, som står inne i hver sin bod, så kan man jo teste... Hvis det er to personer som står inne der og deler en potetskreller. Akkurat som de deler en alu. Så vil det måtte gå dobbelt så lang tid å skrelle poteter. Så det er potetskrelling jeg nå egentlig holder på med her. Vi ser... Da jeg kjørte åtte... Nei, når jeg kjørte fire, så tok dette her realtime 18,5 sekunder, usertime 18,5... Jo, det betyr at disse prosessene, de fikk tilgang til 100 % av CPU. Og da skulle også realtiden, den totale realtiden, da være...", "source": "lecture"}
{"lecture_id": "os7del15", "chunk_id": "os7del15_0005", "start": 384.98, "end": 474.42, "token_count": 297, "text": "Da jeg kjørte åtte... Nei, når jeg kjørte fire, så tok dette her realtime 18,5 sekunder, usertime 18,5... Jo, det betyr at disse prosessene, de fikk tilgang til 100 % av CPU. Og da skulle også realtiden, den totale realtiden, da være... Så dette er riktig. Sånn bør det være. Men vi kan begynne å ane nå at dette tar mye lengre tid. Og vi ser faktisk... Jo, dette tok nesten dobbelt så lang tid. Vi ser 18 sekunder tok det for én CPU. En prosess på én enkel CPU. Men når vi delte inn i åtte prosesser... Så tok det 35,7 sekunder. Altså... 37 ville vært det dobbelte. Så vi kan se her at vi har hatt en ørliten effekt av hypertreding. Men stort sett så ser vi disse to prosessene her. De måtte faktisk dele på samme aliu. Og det er derfor det tok mye lengre. Nesten dobbelt så lang tid å regne ut. Men det er også litt forvirrende, for det står fortsatt 99 %. Men dette er på en måte sånn som...", "source": "lecture"}
{"lecture_id": "os7del15", "chunk_id": "os7del15_0006", "start": 455.94, "end": 557.74, "token_count": 295, "text": "Men stort sett så ser vi disse to prosessene her. De måtte faktisk dele på samme aliu. Og det er derfor det tok mye lengre. Nesten dobbelt så lang tid å regne ut. Men det er også litt forvirrende, for det står fortsatt 99 %. Men dette er på en måte sånn som... Men i virkeligheten så switcher de lynhastig frem og tilbake. Da kan man jo lure på hvorfor dette... Hvorfor er dette hypertrening så viktig i det hele tatt? Men da har vi et... Skal vi se... Jeg har et... Dette her. Det er da et program som bruker et RA, og så gjør den en masse RA-operasjoner. Så den leser masse inn og ut fra RAM. Og da vil sånn som hypertraining kunne ha en effekt. Så hvis jeg nå kompilerer dette RAM2-programmet, og så kjører det i stedet... Vi kan gjøre den samme testen. Vi kan kjøre én til fire. Nei... Det var... Det var feil. Sorry. Vi skulle ikke kjøre regnvann. Nå skulle vi kjøre ADOTAT. Sånn. Nå kjører jeg fire av de RAM-programmene samtidig.", "source": "lecture"}
{"lecture_id": "os7del15", "chunk_id": "os7del15_0007", "start": 534.98, "end": 624.9, "token_count": 284, "text": "Vi kan kjøre én til fire. Nei... Det var... Det var feil. Sorry. Vi skulle ikke kjøre regnvann. Nå skulle vi kjøre ADOTAT. Sånn. Nå kjører jeg fire av de RAM-programmene samtidig. Og de vil da kjøre på hver sin CPU. Og de bruker det i fire sekunder. Og så setter jeg i gang åtte av dem. Hvis hypertraining ikke er noe effektivt nå, så ville dette tatt åtte sekunder. Men vi ser... Her hadde hypertraining plutselig en veldig stor effekt. For nå brukte vi realtid 4,3 sekunder. Mens her så brukte vi bare 4. Og dette viser hypertraining på... Med sitt største potensial. Her så klarte operativstemme å sette inn to prosesser på én og samme CPU med samme alu. Men siden her er det mye snakk med minnet... Man må hele tiden vente for å... Her oppe så klarer ikke én prosess å utnytte CPU-en fullstendig. For den må hele tiden vente på ting fra ram. Så derfor er hypertrening veldig effektivt. For da kan...", "source": "lecture"}
{"lecture_id": "os7del15", "chunk_id": "os7del15_0008", "start": 609.34, "end": 651.02, "token_count": 183, "text": "Man må hele tiden vente for å... Her oppe så klarer ikke én prosess å utnytte CPU-en fullstendig. For den må hele tiden vente på ting fra ram. Så derfor er hypertrening veldig effektivt. For da kan... Så kan disse to stå og bytte på å gjøre de institusjonene de trenger på SPU-en, og så får de gjort jobben veldig mye raskere. Men dette var de to ekstreme tilfellene. En regnejobb kan ikke utnytte hypertrening, men en rammejobb kan utnytte det veldig godt. Ofte så er det litt imellom, men i snitt så kan du kanskje få en sånn 30-40 % forbedring med hypertrening.", "source": "lecture"}
{"lecture_id": "linux6del10", "chunk_id": "linux6del10_0000", "start": 0.0, "end": 96.8, "token_count": 282, "text": "Vi skal nå se på SEP, eller Secure Copy, som er en veldig nyttig kommando for å kopiere filer mellom Linux hosts, eller mellom hosts som har installert SSH. Og SEP, den krypterer alt som sendes, så det er også en trygg måte å kopiere på. Ja, her kan vi se... Her er jeg på en Linux-VM, eller en container, gruppe 100. Og så har jeg her nede en server, Nexus, som jeg har SSO-tilgang til. Det jeg kan gjøre da, er... La oss si jeg ønsker å kopiere over én fil, én fil.tkd, til Nexus, den andre serveren. Da må jeg skrive først brukernavnet at Nexus. Og så må jeg ha med hele domenenavnet. Hioa.no. Og så må det være et kolon. Og da skal det stå hvor på det andre systemet jeg vil legge filen. Hvis jeg ikke skriver noe her, så kommer det øverst i hjemmemappa. Men jeg kan også spesifisere hvor jeg vil ha det. Så den mappa jeg skal ha til, er... Mappe der nede. Så Return. Og så må jeg skrive passord.", "source": "lecture"}
{"lecture_id": "linux6del10", "chunk_id": "linux6del10_0001", "start": 74.64, "end": 171.56, "token_count": 291, "text": "Og da skal det stå hvor på det andre systemet jeg vil legge filen. Hvis jeg ikke skriver noe her, så kommer det øverst i hjemmemappa. Men jeg kan også spesifisere hvor jeg vil ha det. Så den mappa jeg skal ha til, er... Mappe der nede. Så Return. Og så må jeg skrive passord. Og så overføres filen. Da kan vi gå ned hit og se at... Jo, her har enfil.tkst blitt overført. Så kan man også overføre tilbake. Men det vi kanskje kan se på først, er... Hvis jeg står her, så kan jeg... Nå har jeg overført en fil til Nexus. Men jeg kan også ta... Hvis jeg vet om en fil på Nexus... F.eks. dinfil.tk, så kan jeg kopiere den hit. Og da må jeg kopiere til prikk, som er her jeg står. Og spesifisere et nytt navn på filen. Men da ser vi - da har jeg fått over dinfil.tekstet hit. Så kan jeg gå ned hit. Så kan man også kopiere andre veien. Og så kan jeg f.eks. da kopiere over hele mapper.", "source": "lecture"}
{"lecture_id": "linux6del10", "chunk_id": "linux6del10_0002", "start": 150.0, "end": 239.92, "token_count": 292, "text": "Og spesifisere et nytt navn på filen. Men da ser vi - da har jeg fått over dinfil.tekstet hit. Så kan jeg gå ned hit. Så kan man også kopiere andre veien. Og så kan jeg f.eks. da kopiere over hele mapper. Minus R er recursive. Så hvis jeg skal kopiere Dir1 til da Group 100... Ett os100.svelab.cs.joa.no. Sånn. Så må jeg også si hvor jeg ønsker å legge den. Nå ønsker jeg å legge den i TMP, som jeg står i der oppe. Sånn. Nå ble den kopiert over uten at jeg skrev passord. Det er det fordi jeg allerede har satt opp SSO-nøkler. Så hvis du har det, så kan man... Automatisk kopier over. Og da ser vi her oppe... Vi ser 3 her, så ser jeg at jeg har fått over... Og 3... Ja, nå har jeg ikke 3 her nede, men vi kan se at Dir 1 inneholder filer og tekster. Så da har vi fått over mappe med undermappe. Så dette er en veldig nyttig kommando for å kopiere filer og mapper.", "source": "lecture"}
{"lecture_id": "linux6del10", "chunk_id": "linux6del10_0003", "start": 216.56, "end": 244.12, "token_count": 96, "text": "Vi ser 3 her, så ser jeg at jeg har fått over... Og 3... Ja, nå har jeg ikke 3 her nede, men vi kan se at Dir 1 inneholder filer og tekster. Så da har vi fått over mappe med undermappe. Så dette er en veldig nyttig kommando for å kopiere filer og mapper. Frem og tilbake mellom Hosts.", "source": "lecture"}
{"lecture_id": "os2del14", "chunk_id": "os2del14_0000", "start": 0.0, "end": 83.32, "token_count": 286, "text": "Det vi så på, var hvordan kan denne kretsen forenkles. Da kom det en spoiler-alert. At denne kretsen er bare lik B. I første omgang kan vi se dette sånn som jeg gjorde fra Sandnes-stabellen. Hvis vi ser på F lik A B her, så er jo det akkurat det samme som B. Det er å bruke Bolskalgebra og forenkle. Da er det noen sånne identiteter i Bolskalgebra som er enkle å skrive ned. For i Bolskalgebra er det bare to muligheter. Enten A er 0 eller 1, så vil alltid dette være 1. Hvis X er 0, så er 1 og 0 er 0. Hvis X er 1, så er 1 og 1 1. Så dette er identiteter. Så kan man forenkle sånn som dette. Som jeg gjorde, man kan sette B utenfor, i en parentes. Og ikke A pluss A, det er én. Og dermed får man én og B. Én og B er alltid B, så dette er B. Og dermed så kan denne kompliserte kretsen forenkles til bare en direkte kobling mellom B og F.", "source": "lecture"}
{"lecture_id": "os2del14", "chunk_id": "os2del14_0001", "start": 60.0, "end": 122.6, "token_count": 218, "text": "Som jeg gjorde, man kan sette B utenfor, i en parentes. Og ikke A pluss A, det er én. Og dermed får man én og B. Én og B er alltid B, så dette er B. Og dermed så kan denne kompliserte kretsen forenkles til bare en direkte kobling mellom B og F. Og det er klart... Det er klart at dette er... Det er viktig å gjøre den type forenklinger for at kretsene ikke skal bli så kompliserte. Men i prinsippet kunne man bare levert inn de tegningene på den opprinnelige stabellen. Men da vil man ikke kunne ha like høy klokke på CPU-en man lager. Så dette er mer en sånn ingeniørmessig ting. At man forenkler først, før man tegner og brenner kretsen, for at den skal bli mer. Effektivt.", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0000", "start": 0.0, "end": 89.86, "token_count": 277, "text": "Men først må vi spørre som alltid om hvorfor virtualisering? Hvorfor begynte man med dette i det hele tatt? Generelt så må vi gå kanskje 20 år tilbake hvor det typiske var at man hadde fysiske servere. Og da hadde man gjerne én stor fysisk server med mange CPU-er. Og den kjørte da gjerne mange forskjellige tjenester. Du kunne ha én fysisk server som kunne ha en webserver for én bedrift, og den kunne ha en database for en annen, osv. Og da var det mange driftsproblemer som dukket opp pga. denne metoden. F.eks. hvis det var noe feil i hardware, så ville alt gå ned. Hvis man skulle oppgradere, En av tjenestene så måtte man kanskje ta ned de andre også. Spesielt hvis man skulle sette inn mer ram fordi en database trengte mer ram. Så måtte hele serveren tas ned. Og da begynte man å eksperimentere med virtuelle maskiner. På den måten at man kunne fordele ressursene for de fysiske maskinene på mange...", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0001", "start": 67.02, "end": 171.74, "token_count": 285, "text": "Spesielt hvis man skulle sette inn mer ram fordi en database trengte mer ram. Så måtte hele serveren tas ned. Og da begynte man å eksperimentere med virtuelle maskiner. På den måten at man kunne fordele ressursene for de fysiske maskinene på mange... Da er det noen punkter vi skal gå gjennom her, som viser hvilke fordeler virtualisering gir. Det er isolasjon, ressurssparing, fleksibilitet, programvareutvikling og skytjenester. Alt dette gjelder også for containere og dokker, som vi har sett på. Dokker og konteinere har generelt blitt en mer vanlig måte å fordele tjenester og servere på, enn å bare bruke rene VM-er. Eller mer vanlig. Begge brukes mye, men konteinere har økt veldig i bruk de siste årene. Men jeg sier, bortsett fra din første, isolasjon og sikkerhet, som... Som jeg sa, der har dokker et større problem. Det er... En dokkecontainer er ikke like godt isolert som en virtualmaskin. Ja... Isolasjon. En fordel ved virtualisering er", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0002", "start": 135.2, "end": 238.96, "token_count": 299, "text": "Begge brukes mye, men konteinere har økt veldig i bruk de siste årene. Men jeg sier, bortsett fra din første, isolasjon og sikkerhet, som... Som jeg sa, der har dokker et større problem. Det er... En dokkecontainer er ikke like godt isolert som en virtualmaskin. Ja... Isolasjon. En fordel ved virtualisering er at da kan man enkelt sette opp tjenester som kjører bare på én V. Og kun på den VM-en. Dermed unngår man at de forskjellige tjenestene ødelegger for hverandre. Man kan gjøre dette med fysiske servere også. Man kan tenke seg at det gjorde man til en viss grad. Man setter opp én dedikert server for en webtjeneste, f.eks. Og så får den webserveren alle ressursene. Men da får man straks et ressursproblem, for da må man fordele veldig mye ressurser på den ene webserveren. Men man får opplagt en fordel med isolasjon. Men dette får man samtidig med virtualisering, for da får man isolasjon, samtidig som man bruker mindre ressurser. Men så kan man spørre om seg", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0003", "start": 210.0, "end": 305.12, "token_count": 300, "text": "Men da får man straks et ressursproblem, for da må man fordele veldig mye ressurser på den ene webserveren. Men man får opplagt en fordel med isolasjon. Men dette får man samtidig med virtualisering, for da får man isolasjon, samtidig som man bruker mindre ressurser. Men så kan man spørre om seg Er ikke det et stort problem med virtualisering? Det viser seg at det meste av nedetid skyldes ikke hardware, at det går noe galt med hardware, men heller software. Software for en hypervisor er generelt mindre komplekst enn all programvaren som kjører på en maskin. Du har kompliserte applikasjoner. Avhengigheter av databaser og eksterne programmer osv. Så er det mye mer komplekst enn en hypervisor. En hypervisor er relativt enkelt og relativt stabilt. Sikkerhet er viktig her. Hvis én tjeneste blir hacket, så vil det ikke påvirke de andre tjenestene. Man har ganske vanntette skott mellom to virtuelle maskiner som kjører på den samme serveren. Det er fordi, som jeg nevnte, at operativsel med applikasjonen", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0004", "start": 283.02, "end": 374.6, "token_count": 294, "text": "Sikkerhet er viktig her. Hvis én tjeneste blir hacket, så vil det ikke påvirke de andre tjenestene. Man har ganske vanntette skott mellom to virtuelle maskiner som kjører på den samme serveren. Det er fordi, som jeg nevnte, at operativsel med applikasjonen kommuniserer kun mot det virtuelle hardware-API-et som HyperWise gir dem tilgang til, og ikke noe annet. Så de har på en måte overhodet ikke tilgang til det underliggende hardwaren. De kan kun snakke med API-et og bare be om akkurat det HyperWise ønsker å tilby. Ressurssparing er et veldig viktig moment for virtualisering. Man kan oppnå isolasjon og sette én fysisk server for hver tjeneste, men det gir store driftskostnader. Med virtualisering så kan man oppnå det samme på én enkelt server. For da kan du ha mange VM-er som kjører på den samme serveren. Og de kan dele på CPU og minne og alt annet. Man kan også enkeltkonsolidere. Det vil si... Hvis man har en fysisk server som man ser at...", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0005", "start": 348.2, "end": 449.94, "token_count": 292, "text": "Med virtualisering så kan man oppnå det samme på én enkelt server. For da kan du ha mange VM-er som kjører på den samme serveren. Og de kan dele på CPU og minne og alt annet. Man kan også enkeltkonsolidere. Det vil si... Hvis man har en fysisk server som man ser at... Oi, her er det mye plass og ressurser. Så kan man flytte Wemer til den serveren. Det er umulig uten virtualisering. Når jeg snakker om virtualisering, så kommer jeg til å nevne en del... Vi har en mastergrad som tidligere het Nettverk og systemarbeidersadministrasjon ved HiOA. Den heter nå Croll Computing. Hvor det har vært tidligere studenter som har jobbet med oppgaver relatert til virtuelle maskiner. På Teaching Materials ligger det en oversikt over Hvis dette er noe som dere finner interessant, så sjekk gjerne ut hva som er gjort her. Og sjekk ut Asit, som er den nymasteren som kjører på Oslo Nett. Skybaserte tjenester er det vel hett generelt. Neste punkt er fleksibilitet. Det er...", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0006", "start": 420.0, "end": 509.8, "token_count": 281, "text": "Hvis dette er noe som dere finner interessant, så sjekk gjerne ut hva som er gjort her. Og sjekk ut Asit, som er den nymasteren som kjører på Oslo Nett. Skybaserte tjenester er det vel hett generelt. Neste punkt er fleksibilitet. Det er... Alt blir veldig mye mer fleksibelt når man bruker VM-er. Hvis man da bruker container i tillegg, så blir det enda mer fleksibelt. Men når man kjører VM-er, så kan man dynamisk tildele CPU-er og internminer til VM-er. F.eks. de Linux-VM-ene som dere har. I tidligere år så hadde de ofte én enkel CPU. Men nå har dere fire CPU-er. Det er virtuelle CPU-er som er tildelt VM-ene. Så når dere kjører et Java-program med fire tråder, så vil de effektivt kjøre i parallell på fire forskjellige CPU-er. Da bruker de de underliggende CPU-ene som den fysiske serveren har. Da er det også lagt opp sånn at da kan det f.eks. være...", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0007", "start": 485.8, "end": 574.84, "token_count": 294, "text": "som er tildelt VM-ene. Så når dere kjører et Java-program med fire tråder, så vil de effektivt kjøre i parallell på fire forskjellige CPU-er. Da bruker de de underliggende CPU-ene som den fysiske serveren har. Da er det også lagt opp sånn at da kan det f.eks. være... Åtte VM-er på én server, og hver av de har fire virtuelle CPU-er. Og det blir 32 til sammen. Mens de fysiske maskinene har kanskje bare 16. Men de deler hele tiden dynamisk på CPU-ene. Så det kan også bety at hvis absolutt alle grupper er inne og kjører og bruker 100 % CPU, så vil ting faktisk gå saktere. Det vil se ut som du har 100 % CPU, men i virkeligheten så deler du CPU med andre grupper og andre VM-er. Det samme gjelder i clouden. Hvis du leier VM-er på Amazon eller i Google, så vil den samme effekten kunne oppstå, at ting faktisk går saktere. Fordi du deler CPU med andre VM-er. Ja, det har kanskje noen av dere sett også hvis en VM...", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0008", "start": 545.24, "end": 635.56, "token_count": 297, "text": "med andre grupper og andre VM-er. Det samme gjelder i clouden. Hvis du leier VM-er på Amazon eller i Google, så vil den samme effekten kunne oppstå, at ting faktisk går saktere. Fordi du deler CPU med andre VM-er. Ja, det har kanskje noen av dere sett også hvis en VM... Noen av dere har fått ødelagt en VM eller kompromittert. Det var faktisk en gruppe her som hadde lagd en testjuicer. En bruker som het Testjuicer, og sannsynligvis et litt dårlig passord på det. Så de fikk straks besøk fra SSO og innlogging fra et par stykker fra USA. Og en fra Tyskland. Og maskinen var blitt kompromittert. Det som var fint da, var at da kunne vi bare ta ned maskinen og bygge den opp på nytt. Sånn at alt av det gamle var slettet. Generelt, hvis man først har hatt noen inne på en server, så er det veldig vanskelig å garantere seg mot at noe har blitt liggende der, eller at de har med hensikt lagt igjen bakdører. Den eneste måten er å bygge på nytt.", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0009", "start": 617.04, "end": 718.76, "token_count": 298, "text": "Generelt, hvis man først har hatt noen inne på en server, så er det veldig vanskelig å garantere seg mot at noe har blitt liggende der, eller at de har med hensikt lagt igjen bakdører. Den eneste måten er å bygge på nytt. Det er veldig enkelt hvis man bruker virtuelle maskiner. Da kan man ta det tidligere imaget man hadde, eller bygge et nytt image. Og så bude opp det. Så har man en ny server på ti minutter. Det kan være pga. avhengighet fra operativsystemet eller andre programmer. Hvis du nå utvikler alt på en VM, så kan hele VM-en flyttes over. Litt på samme måte som vi har sett på med dokkercontainere. En annen ting man kan gjøre med VM-er, det er å flytte de levende. Man kan ha en virtuell maskin som kjører en tjeneste, som en webserver. Og så kan man da, mens webserveren kjører, så kan man flytte den virtuelle maskinen fra én fysisk server til en annen. Og måten man får den til å være oppe helt inne på, er at man starter med å kopiere det meste.", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0010", "start": 690.0, "end": 802.02, "token_count": 295, "text": "Man kan ha en virtuell maskin som kjører en tjeneste, som en webserver. Og så kan man da, mens webserveren kjører, så kan man flytte den virtuelle maskinen fra én fysisk server til en annen. Og måten man får den til å være oppe helt inne på, er at man starter med å kopiere det meste. Og så er det et lite øyeblikk til slutt hvor man kopierer akkurat de siste bitene. Det kan gå på millisekunder. Man kan ha flytting av hele fysiske VM-er. Nei, ikke fysiske. Flytting av virtuelle maskiner. Det kan gjøres med nedetid på 10-50 millisekunder. Tidligere masterjunter som har jobbet med... Altså med live migration av virtuelle maskiner. Ja, dette er fra... Ja, dette er... Den neste grafen er fra oppgaven til Bilal. Skalering. Vertikal og horisontal skalering. Det betyr at man da legger til både flere VM-er, men også flere CPU-er og mer minne til en enkelt VM. Så det han gjorde, var altså at han satte opp en webtjeneste.", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0011", "start": 771.48, "end": 875.92, "token_count": 297, "text": "Ja, dette er... Den neste grafen er fra oppgaven til Bilal. Skalering. Vertikal og horisontal skalering. Det betyr at man da legger til både flere VM-er, men også flere CPU-er og mer minne til en enkelt VM. Så det han gjorde, var altså at han satte opp en webtjeneste. Hvis responstiden økte, så var systemet sånn at den la til flere CPU-er. Oppover her så ser du antall CPU-er. Vi kan bare veldig kort se på antall CPU-er for webserver 1. Her ser vi responstiden ligger under en grense, kanskje 500 millisekunder. Men når responstiden begynner å komme opp mot den grensen og så går over, så ser du at dynamisk så legger systemet til flere CPU-er. Hele tiden mens responstiden går oppover, så legges det til CPU-er. Helt til man har kommet så høyt at responstiden går ned igjen. Så går responstiden opp enda en gang, at man får enda mer pågang på webserveren. Og da er systemet dynamisk på den måte at den legger til en ny webserver,", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0012", "start": 851.76, "end": 940.02, "token_count": 291, "text": "Hele tiden mens responstiden går oppover, så legges det til CPU-er. Helt til man har kommet så høyt at responstiden går ned igjen. Så går responstiden opp enda en gang, at man får enda mer pågang på webserveren. Og da er systemet dynamisk på den måte at den legger til en ny webserver, som også får flere CPU-er. Sånn at disse to webserverne til sammen kan håndtere trafikken her. Og en fleksibilitet som dette vil være helt umulig med fysiske maskiner. Programvareutvikling, det har vi sett på med dere. Det er mye å gjøre. Man kan enkelt sette opp nøyaktig det miljøet man ønsker å kjøre i. Og så kan man teste ut, feilteste osv. Så det er veldig enkelt og raskt å sette opp akkurat det miljøet man ønsker. De av dere som tar skytjenester og nettverkskurset, har jo sett dette i praksis. Man kan da kjøpe seg en VM med et gitt antall CPU-er, gitt diskstørrelse og størrelse på minnet.", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0013", "start": 911.36, "end": 1029.22, "token_count": 275, "text": "Så det er veldig enkelt og raskt å sette opp akkurat det miljøet man ønsker. De av dere som tar skytjenester og nettverkskurset, har jo sett dette i praksis. Man kan da kjøpe seg en VM med et gitt antall CPU-er, gitt diskstørrelse og størrelse på minnet. Det koster typisk mer jo flere CPU-er og mer ramme du har. Veldig store besparelser, og gjør at dette kan være en effektiv måte å selge servertid til alle som ønsker å kjøre tjenester. Og at Amazon er store skytjenester, det skyldes opprinnelig at de var en bokhandel, opprinnelig, som solgte bøker. Da måtte de kjøpe inn masse fysiske maskiner for å kunne ta unna alle request fra kunder. Men da opplevde jeg at de andre elleve månedene i året sto de der med en masse fysiske maskiner som ingen brukte, som bare ble til overs. I mellomtiden, når det ikke var jul, kunne vi ikke leie ut disse fysiske serverne.", "source": "lecture"}
{"lecture_id": "linux10del2", "chunk_id": "linux10del2_0014", "start": 990.02, "end": 1056.34, "token_count": 192, "text": "Da måtte de kjøpe inn masse fysiske maskiner for å kunne ta unna alle request fra kunder. Men da opplevde jeg at de andre elleve månedene i året sto de der med en masse fysiske maskiner som ingen brukte, som bare ble til overs. I mellomtiden, når det ikke var jul, kunne vi ikke leie ut disse fysiske serverne. Å leie ut fysiske servere er ikke så lett, men ved hjelp av virtualisering og skytjenester så kunne vi sette opp et opplegg hvor de da leide ut ressurser som var tilgjengelige resten av året. Så var på en måte sånn kommersielle skytjenester startet. Det er fantastisk å se hvordan folk oppfører seg og hvordan de oppfører seg.", "source": "lecture"}
{"lecture_id": "linux4del8", "chunk_id": "linux4del8_0000", "start": 0.0, "end": 122.92, "token_count": 288, "text": "Skal vi se kort på noen konstruksjoner som kan være nyttige å bruke i script? Kanskje ikke den beste programmeringsmåten, men script er også litt dirty. Så det vi skal se på, er break og continue. For å teste det skal jeg lage en liten løkke. Får en varabel i, inn... Men det går også an å bare løpe gjennom femtall på denne måten her. Så kan vi starte med en løkke hvor vi bare skriver ut areablnavnet. Så er vi ferdig. Så kan vi bare teste ut den for å se om det funker som skal. Men så kan vi... Her inne så kan vi sette inn tester. For eksempel så kan jeg teste hvis dette tallet... La oss si det er lik tre. Nei, la oss si det er to. Da kan vi be om å hoppe over det tallet ved å si... Den kan vi si continues. Da betyr det at dette tallet skal vi hoppe over i løkken. Så kan vi se hvordan det fungerer. Da ser vi at I er 2. Så hopper vi over. Så kan vi også prøve... Kan jeg bruke en litt annen... ... metode å sammenligne.", "source": "lecture"}
{"lecture_id": "linux4del8", "chunk_id": "linux4del8_0001", "start": 95.76, "end": 201.92, "token_count": 295, "text": "Da betyr det at dette tallet skal vi hoppe over i løkken. Så kan vi se hvordan det fungerer. Da ser vi at I er 2. Så hopper vi over. Så kan vi også prøve... Kan jeg bruke en litt annen... ... metode å sammenligne. Vi har sett tidligere at hvis vi bruker to parenteser på denne måten, så får vi mer javalik-syntaks i testen. Men det vi kan teste ut nå, er... Det betyr det samme. Det er break. Hvis tallet er fire, da skal vi breake. Det betyr at da skal vi hoppe helt ut av løkka. Tilsvarende er det da på... For vailøkker. Kjør deg nå. Så jeg fikk en syntaksfeil. I linje 13. Da kan vi se på hvordan vi kan gå til linje 13. Gjedd, så er det SKFG, linje 13. Da er det tydeligvis en... Hvis den kontinuer... Ja, vi har glemt en fi her. Så feilmeldingen er, som du ser, ikke alltid så enkel å se. Så man må gjerne gå inn og se feilmelding. Komme her nede ved 13.", "source": "lecture"}
{"lecture_id": "linux4del8", "chunk_id": "linux4del8_0002", "start": 172.84, "end": 225.52, "token_count": 152, "text": "Da er det tydeligvis en... Hvis den kontinuer... Ja, vi har glemt en fi her. Så feilmeldingen er, som du ser, ikke alltid så enkel å se. Så man må gjerne gå inn og se feilmelding. Komme her nede ved 13. Men da kan feilen ha skjedd høyere oppe. Så hvis vi får syntaksen riktig, så kan vi gå over. Og da ser vi... Da går det som før, at vi først går én og tre. Så kommer testen på fire, og da gjør vi break, og da hopper vi helt ut av løkken.", "source": "lecture"}
{"lecture_id": "os7del5", "chunk_id": "os7del5_0000", "start": 0.0, "end": 96.24, "token_count": 300, "text": "Her kjører jeg topp i gruppe 100. Det er ikke så mange prosesser her. Men det er alle prosessene som kjøres på den lokale containeren. Her er innsommer ut også, så jeg kjører noen RUT-prosesser. Men LSAPU viser hvor mange... Eller viser litt info. Og her vil vi se at vi har 96 CPU-er. Men hver enkelt VM, eller hver enkelt container, får ikke tilgang til alle CPU-ene. Det kunne i prinsippet gjort, men sånn som jeg har startet opp, så har jeg gitt hver VM tilgang til det som tilsvarer to CPU-er. Hvis dere kjører to regnprosesser, så vil det si at de får 100 % CPU. Hvis du kjører tre, så får de bare to tredjedels CPU. Akkurat som på en fysisk maskin med to CPU-er. Men dette blir fordelt av Docker Engine, og den gjør det litt annerledes. Så hvis man lister hvilke prosessorer de kjører på, f.eks., så... så vil man se at de ligger på forskjellige prosesser. Hvis du kjører tre stykker, så ligger de på tre forskjellige.", "source": "lecture"}
{"lecture_id": "os7del5", "chunk_id": "os7del5_0001", "start": 78.12, "end": 132.6, "token_count": 209, "text": "og den gjør det litt annerledes. Så hvis man lister hvilke prosessorer de kjører på, f.eks., så... så vil man se at de ligger på forskjellige prosesser. Hvis du kjører tre stykker, så ligger de på tre forskjellige. Men det er da Dukker Engine som fordeler tiden. Vi kommer litt mer tilbake til det etter hvert også, men dette er en oppgave òg. Men den kan... Dere har jo ikke full oversikt siden dere ikke ser den fysiske serveren. Så den oppgaven er litt vanskelig, og så ser vi hva som egentlig skjer. Hvor mye suppe får jeg? Hvor lang tid tar de forskjellige jobbene? Men ha det i bakhodet at dette er litt mer komplisert enn om det var på en fysisk maskin.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0000", "start": 0.0, "end": 192.92, "token_count": 300, "text": "Ja, hallo, alle sammen. Da skal jeg først teste om dere hører meg i dag. Så da får dere forhåpentligvis opp en liten pollen òg. Ja, jeg ser det er fire stykker som ikke hører meg. I chatten hører dere ingen lyd. Dere som ikke hører... Sånt generelt så kan jeg foreslå å prøve å gå ut og inn igjen. Det kan man generelt prøve. Men da ser det ut som de fleste hører meg. Ja... Jeg bare tester. Nå deler jeg poler over 17. Kanskje vi kan få til noen flere poller med spørsmål underveis. OK. Ja, som dere ser, bruker Zoom i dag. Så det er nok et verktøy for meg også. Jeg bruker Zoom fordi det var litt problemer med konferanser sist. Lyden fattet blant annet. Men... ja. Vi kan starte med... Skal jeg bare teste at dere får opp... vinduet mitt her? Ja. Så er det fint generelt om dere skriver i chatten og spør underveis. Som dere ser, det vi skal holde på med i dag, er dok... Vi skal fortsette med dokker, og vi skal spesielt se på dokkefiles.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0001", "start": 155.74, "end": 268.78, "token_count": 297, "text": "Skal jeg bare teste at dere får opp... vinduet mitt her? Ja. Så er det fint generelt om dere skriver i chatten og spør underveis. Som dere ser, det vi skal holde på med i dag, er dok... Vi skal fortsette med dokker, og vi skal spesielt se på dokkefiles. Forrige gang så vi på hvordan vi kunne bruke dokker til å sette opp systemer. Vi satte opp webservere, blant annet. Og så på hvordan vi kunne kjøre dem. Det vi gjorde da, var at vi til en stor grad startet opp et image. Altså et blankt image, sånn som en ubuntu-installasjon. Da får man opp et helt ubuntu operativsystem. Men så gikk vi inn på det operativsystemet, sånn som vi er vant til fra VM-er og fysiske maskiner. Og konfigurerte det, installerte Apache osv. Det går an å sette opp ting på den måten, men det som er mer effektivt, eller iallfall er lettere å automatisere, det er å sette opp systemet ved hjelp av en fil, en såkalt dokkerfil. Og når man gjør det, så kan man sette opp all konfigurasjonen og alt man trenger.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0002", "start": 245.14, "end": 337.0, "token_count": 286, "text": "Det går an å sette opp ting på den måten, men det som er mer effektivt, eller iallfall er lettere å automatisere, det er å sette opp systemet ved hjelp av en fil, en såkalt dokkerfil. Og når man gjør det, så kan man sette opp all konfigurasjonen og alt man trenger. Og så bygger man et image ut fra det. Da kan denne dokkefilen definere hele systemet og kan lett deles med andre. Som da kan bygge det for å få sitt eget image. Det er da et alternativ til å dele et helt image. Det kan man også gjøre. Man kan gå inn på dokkecontaineren, konfigurere akkurat som man ønsker. Så kan man dele et image med andre. Vi skal se på det også. Hvis vi får tidligere i dag, kan vi prøve å legge inn et image på Dokkerhub. Men det kommer vi tilbake til. Så det er også noen oppgaver denne uken. Vi kan ta en rask kikk. De fleste av oppgavene går på scheduling og det vi holdt på med på... En del av disse spørsmålene blir forhåpentligvis lettere", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0003", "start": 312.4, "end": 419.92, "token_count": 276, "text": "Men det kommer vi tilbake til. Så det er også noen oppgaver denne uken. Vi kan ta en rask kikk. De fleste av oppgavene går på scheduling og det vi holdt på med på... En del av disse spørsmålene blir forhåpentligvis lettere hvis dere har sett simuleringen hvor jeg lager vaffelrøre og foreleser samtidig. Hovedideen med det var at dere skulle få helt konkrete begreper av hvordan schedulering foregår. Så det er en del spørsmål rundt dette. Oppgaver rundt dokker og dokkefeil. Men det er én oppgave. Så hvis dere får til den, så bør dere være fornøyd med dagen. Hvis dere har høyere ambisjoner, så bør dere få med dere ukens utfordring. Som igjen går ut på å sette opp ni containere, men denne gangen med dokkerfeil.  OK. Da er planen at vi går gjennom flere slides fra Mike Long. Som vi fortsetter med de slidene vi hadde forrige gang. Jeg skal vise et par slider om hvorfor vi bruker dokker.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0004", "start": 373.94, "end": 492.94, "token_count": 300, "text": "Hvis dere har høyere ambisjoner, så bør dere få med dere ukens utfordring. Som igjen går ut på å sette opp ni containere, men denne gangen med dokkerfeil.  OK. Da er planen at vi går gjennom flere slides fra Mike Long. Som vi fortsetter med de slidene vi hadde forrige gang. Jeg skal vise et par slider om hvorfor vi bruker dokker. Det var et veldig godt spørsmål sist om eksempler på dokkebruk. Og egentlig hvorfor man trenger å vite om dette. Da skal jeg prøve å dele en annen... et annet vindu. Skal vi se. Sånn. Da ser dere forhåpentligvis... Et par slider. Hvorfor dere? Jo, for det første så gjør det det enkelt å sette opp og kopiere et helt driftsmiljø. Man kan da, hvis man har en applikasjon som man skal utvikle, så... Så kan man sette opp hele det miljøet med nøyaktig riktige versjoner av kompulator, bibliotek osv. Og så kan man sikre... Altså, den som skriver koden, kan da enkelt teste ut koden, at den virker som den skal,", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0005", "start": 466.42, "end": 557.08, "token_count": 292, "text": "Man kan da, hvis man har en applikasjon som man skal utvikle, så... Så kan man sette opp hele det miljøet med nøyaktig riktige versjoner av kompulator, bibliotek osv. Og så kan man sikre... Altså, den som skriver koden, kan da enkelt teste ut koden, at den virker som den skal, i en kopi av det miljøet som faktisk skal kjøre koden. Man kan ikke teste i produksjon direkte. For da kan du risikere å stoppe hele produksjonsmiljøet. Men samtidig er det veldig ofte problemer med at når en utvikler testekoden sin, så kjøres den i et miljø som ikke er helt lik driftsmiljøet. Og da blir det mye vanskeligere å teste, og det blir en mye større prosess å komme inn til kode. Vi har ikke sett så mye på dem, men vi skal se litt mer på det kanskje allerede neste uke. Virtuelle maskiner og VM-er. Men dere har jo fått virtuelle maskiner som dere kjører, Linux-VM-er. Og mange av dere har også installert Windows-VM-er", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0006", "start": 522.02, "end": 621.02, "token_count": 295, "text": "Og da blir det mye vanskeligere å teste, og det blir en mye større prosess å komme inn til kode. Vi har ikke sett så mye på dem, men vi skal se litt mer på det kanskje allerede neste uke. Virtuelle maskiner og VM-er. Men dere har jo fått virtuelle maskiner som dere kjører, Linux-VM-er. Og mange av dere har også installert Windows-VM-er med version-boks. Det er på en måte... En annen måte å sette opp et helt stort miljø, som kan være nøyaktig likt driftsmiljø. Men dette krever mye ressurser, for da må du ha for hver maskin så må du ha hele operativsystemet. Og det er veldig omfattende. Det er digert i forhold til containere. Containere er små og raske å starte og stoppe. At hvis du kjører ti Ubuntu-konteinere på én maskin, sånn som oppgaven denne og forrige uke går ut på, så bruker alle de ti konteinerne det samme underliggende operativsystemet. Da sparer man masse ressurser i forhold til om man skulle kjøre ti virtuelle maskiner.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0007", "start": 593.82, "end": 699.8, "token_count": 285, "text": "At hvis du kjører ti Ubuntu-konteinere på én maskin, sånn som oppgaven denne og forrige uke går ut på, så bruker alle de ti konteinerne det samme underliggende operativsystemet. Da sparer man masse ressurser i forhold til om man skulle kjøre ti virtuelle maskiner. Det krever veldig mye mer ressurser i form av både minne og... spesielt minne. En av de viktigste grunnene til at dokker har blitt så populært og så mye brukt, er at det er en viktig del av continuous delivery og continuous development. Historisk så var det sånn at for ca. 20 år siden, rundt år 2000, så ble alt driftet på fysiske servere. Da hadde man serverrom hvor fysiske servere hadde applikasjoner som så kjørte. Da kunne det være både webservere og databaser på samme fysiske server. Men felles for alle var at det var veldig... Hvis man skulle oppgradere eller vedlikeholde, så var det en stor prosess. Typisk så kom man med oppdateringer en gang i halvåret, maks en gang i måneden.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0008", "start": 674.1, "end": 773.18, "token_count": 296, "text": "som så kjørte. Da kunne det være både webservere og databaser på samme fysiske server. Men felles for alle var at det var veldig... Hvis man skulle oppgradere eller vedlikeholde, så var det en stor prosess. Typisk så kom man med oppdateringer en gang i halvåret, maks en gang i måneden. Kanskje noen kom en gang i året med oppdateringer av applikasjoner. Fordi det var en stor prosess å sette det opp og teste osv. Og gjøre reelle tester av programmene. Men så kom... Så har det på en måte kommet en revolusjon med DevOps, som er et tettere samarbeid mellom Development Operations. Altså mellom de som utvikler og de som drifter programmene våre. For 20 år siden var det sånn at de var to helt atskilte... Programmererne var fornøyd når de hadde fått ferdig koden, og så sendte den til drift som så skulle drifte. Men det førte med seg en enorm rekke med problemer når man deployer, setter i gang nye systemer og skal kjøre det. Og dermed så kom det et nytt mantra, som var på at man skulle kunne committe kode.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0009", "start": 749.92, "end": 851.94, "token_count": 281, "text": "og så sendte den til drift som så skulle drifte. Men det førte med seg en enorm rekke med problemer når man deployer, setter i gang nye systemer og skal kjøre det. Og dermed så kom det et nytt mantra, som var på at man skulle kunne committe kode. Ti ganger om dagen var liksom det første målet som man hadde. For 20 år siden var det nærmest utenkelig, men i dag så er dette hverdagen i veldig mange bedrifter, og spesielt store, moderne bedrifter som Google, Facebook osv. De bruker dette hele tiden. At hver gang en utvikler, lager noe nytt, Så blir det automatisk testet i driftsmiljø. Men da er det en kopi av driftsmiljøet. Så er det en lang kjede. KUA er også en del av det, Quality Assurance. Alt foregår automatisk. Og da er dokker, eller containere, en veldig viktig del av det. Hele det løpet med å levere kode kontinuerlig. Noe annet som er vanlig, eller som også er en del av dette, det er å sette opp store, komplekse systemer med Kubernetis.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0010", "start": 822.36, "end": 934.2, "token_count": 298, "text": "Alt foregår automatisk. Og da er dokker, eller containere, en veldig viktig del av det. Hele det løpet med å levere kode kontinuerlig. Noe annet som er vanlig, eller som også er en del av dette, det er å sette opp store, komplekse systemer med Kubernetis. Og Kubernetis er en måte å orkestrere, eller da sette opp komplekse systemer ved hjelp av dokker og containere. I en cubernetis kalles det pods. Det er et system av én eller flere dokkecontainere som kjører innen samme miljø. Og dette ble også mye brukt, eller nærmest eksplodert, i bruk av containere, og spesielt cubernetis. Et eksempel på dette, som jeg nevnte sist, er finn.no. Og neste slide er hentet fra en bloggpost fra en som jobber i Finn. Og vi ser at det er et ganske komplekst system som de har i Finn. De bruker en rekke forskjellige verktøy. Og vi ser nederst her infrastrukturen, hvor de bruker både Cloud, men også... Men det som er kjernen i det hele, som vi ser her, er container runtime.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0011", "start": 903.1, "end": 1010.8, "token_count": 287, "text": "Og vi ser at det er et ganske komplekst system som de har i Finn. De bruker en rekke forskjellige verktøy. Og vi ser nederst her infrastrukturen, hvor de bruker både Cloud, men også... Men det som er kjernen i det hele, som vi ser her, er container runtime. Så utviklerne som sitter her oppe og bruker alle disse verktøyene. Den typiske strømmen er at de committer til GitHub, og så både testes og kjøres konen deres i dockercontainere. Alt dette her er da typisk orkestrert med Kybernetis. Så... Allerede i dag så er det ganske vanlig å komme ut i bedrifter som bruker dere, og det kommer helt sikkert til å øke kontinuerlig. Så det var den lange forklaringen på hvorfor vi snakker om dere. Men der... Det er generelt fornuftig å stille den type spørsmål. Hvorfor holder vi på med akkurat det vi gjør? OK. Da skal vi bli mer konkrete og gå inn og se på dokker. Og da vil jeg... Ja, jeg vil gå inn i et dokkervindu.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0012", "start": 983.84, "end": 1124.96, "token_count": 300, "text": "Det er generelt fornuftig å stille den type spørsmål. Hvorfor holder vi på med akkurat det vi gjør? OK. Da skal vi bli mer konkrete og gå inn og se på dokker. Og da vil jeg... Ja, jeg vil gå inn i et dokkervindu. Og så fortsette litt der vi slapp forrige gang. Skal vi se... Da skal jeg i stedet dele... dette vinduet. Oi. Sorry. Det var litt... litt trøbbel der. Jeg prøver en gang til. Sånn. Da ser dere forhåpentligvis... Et vindu med... i OS70 Linux-V. Det er fint hvis dere har problemer med å se vinduet eller et eller annet faller ut, at dere sier det ifra i chatten. Så har jeg et øye på chatten, så kan dere si fra der. Det går også an å... Det er helt OK hvis dere har spørsmål, å bare koble på lyd. Så kan dere stille spørsmål direkte. Det er bare hyggelig hvis dere gjør det. Jeg tror til og med det er et opplegg hvor man kan rekke opp hånden. Jeg er ikke helt sikker på om jeg får til å se det, men jeg prøver.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0013", "start": 1096.3, "end": 1192.74, "token_count": 288, "text": "Det går også an å... Det er helt OK hvis dere har spørsmål, å bare koble på lyd. Så kan dere stille spørsmål direkte. Det er bare hyggelig hvis dere gjør det. Jeg tror til og med det er et opplegg hvor man kan rekke opp hånden. Jeg er ikke helt sikker på om jeg får til å se det, men jeg prøver. Uansett, still veldig gjerne spørsmål i poden... Nei, i poden. I chatten. OK! Som dere ser her, så startet jeg med å liste konteinerne som står og kjører. Og i dag så skal vi jobbe litt med å sette opp den type konteinere. Men da ved hjelp av en dockerfile. I stedet for å konfigurere dockercontaineren direkte. Men jeg tenkte vi skulle... Starter med å repetere litt fra forrige gang. For dere som er godt inn i det, så må dere gjerne fortsette med å gjøre oppgaver i den github-dokker-repositorien som vi holdt på med sist, hvor vi... Oppgavene i forrige uke var hentet derfra. Så planen er å fortsette med...", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0014", "start": 1168.5, "end": 1268.26, "token_count": 291, "text": "For dere som er godt inn i det, så må dere gjerne fortsette med å gjøre oppgaver i den github-dokker-repositorien som vi holdt på med sist, hvor vi... Oppgavene i forrige uke var hentet derfra. Så planen er å fortsette med... Og fortsette å gjøre oppgaver i dockergithub-oppgavene. Så de som har kommet litt lenger, kan gjerne bare fortsette med det. Eventuelt starte med den obligatoriske oppgaven. Jeg kommer til å ta det ganske rolig, og så kommer jeg til å mer eller mindre prøve å løse i hvert fall noen av de oppgavene som er gitt. OK. Som dere ser så er det... her har jeg mange containere som faktisk er oppe og kjører. Jeg har seks containere som står og kjører. Men det viser seg at det tar ikke så veldig mye ressurser. Hvis jeg kjører topp her nå, så... Jeg har riktignok brukt alt av det, men CPU, f.eks., er ikke så mye i bruk. Vi kan også se på... Vi ser det er en del overlay som er i dokkerinstansene.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0015", "start": 1236.98, "end": 1332.2, "token_count": 292, "text": "Jeg har seks containere som står og kjører. Men det viser seg at det tar ikke så veldig mye ressurser. Hvis jeg kjører topp her nå, så... Jeg har riktignok brukt alt av det, men CPU, f.eks., er ikke så mye i bruk. Vi kan også se på... Vi ser det er en del overlay som er i dokkerinstansene. Men hvis vi ser på den minnebruken, så tar imagene litt plass. Men ikke så voldsomt. Men det som er fint, er at... Når jeg har seks konteinere som kjører her, så er det seks fullverdige operativsystemer. I det tilfellet så kjører de webservere. Så det er fullverdige systemer, men de bruker veldig lite diskplass. Og relativt lite minne også. Det hadde ikke vært mulig å kjøre seks sånne VM-er på denne VM-en her. Og vi sier også kjøre VM på VM, men det går faktisk an. Man kan også kjøre VM-er inne i VM-er. Det er klart, det går med en gang litt saktere. Men det er generelt hardway-støtte for å gjøre akkurat det.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0016", "start": 1301.38, "end": 1413.82, "token_count": 281, "text": "Det hadde ikke vært mulig å kjøre seks sånne VM-er på denne VM-en her. Og vi sier også kjøre VM på VM, men det går faktisk an. Man kan også kjøre VM-er inne i VM-er. Det er klart, det går med en gang litt saktere. Men det er generelt hardway-støtte for å gjøre akkurat det. Ja. Det jeg tenkte å gjøre først, var å se på hvordan man kan rydde opp i alt dette. Men hvis jeg tar PC-A, så ser vi at da har jeg enda flere... Det er også da konteinere som er stoppet. Så generelt så så vi sist på noen metoder for å stoppe... Ikke for å stoppe, men for å fjerne konteinere som ikke kjører. Blant annet Docker Prune kan man bruke. Denne uken er det en oppgave som går ut på å lage et script som sletter alt som er av containere som kjører og som ikke kjører. Jeg kan vise en teknikk som vi bruker for å få til det. Hvis jeg tar tokke container... Hvis jeg tar minus Q for quiet, så ser vi at jeg får ut bare ID-en.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0017", "start": 1373.82, "end": 1492.26, "token_count": 296, "text": "Denne uken er det en oppgave som går ut på å lage et script som sletter alt som er av containere som kjører og som ikke kjører. Jeg kan vise en teknikk som vi bruker for å få til det. Hvis jeg tar tokke container... Hvis jeg tar minus Q for quiet, så ser vi at jeg får ut bare ID-en. Dette kan jeg bruke i et skript eller fra kommandolinje til å stoppe enkeltkonteinere. Hvis jeg eksplisitt skal stoppe en konteiner, la oss si jeg stopper den øverste her. Og så... sånn. Så stoppes containeren. Hvis vi ser lister nå, så ser vi at vi har fått én container mindre. Hvis vi har masse containere, så kan det være greit å skripte dette. En måte man kan gjøre det på, er da rett og slett å skrive forløket. Inn... for konteiner i... Og så kan jeg ta... Og så faktisk gjøre den kommandoen der, for den gir oss da hver idé. Så nå kan jeg for hver konteiner... Så kan jeg du... Og så kan jeg stoppe. Dere konteiner, stopp. Og da dollar del.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0018", "start": 1463.82, "end": 1581.54, "token_count": 288, "text": "Inn... for konteiner i... Og så kan jeg ta... Og så faktisk gjøre den kommandoen der, for den gir oss da hver idé. Så nå kan jeg for hver konteiner... Så kan jeg du... Og så kan jeg stoppe. Dere konteiner, stopp. Og da dollar del. Ops. Her gjorde jeg tydeligvis en feil. Ja, jeg tipper den feilen jeg gjorde, var... Nei. Noen gode forslag i chatten på... Ja, hva gjorde jeg feil? Jeg skal jeg få se. Og så skrev jeg dollar d her. Så da var det ikke så klart det ikke gikk. Så da kan man gjøre et nytt forsøk. Stopp container. Får se inn dokkekonteineren. Stopp konteiner. Da ser det litt bedre ut, men det tar litt tid til å stoppe. Her ser vi den første av de stopper. Så stopper etter hvert de andre. Så dette er første del av skriptet. Så kan man stoppe alle containere og sånn. Og når alle er stoppet, da er det enklere å slette alle. Da kan man... Ja, jeg tror en dokker system prune.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0019", "start": 1553.82, "end": 1675.1, "token_count": 293, "text": "Her ser vi den første av de stopper. Så stopper etter hvert de andre. Så dette er første del av skriptet. Så kan man stoppe alle containere og sånn. Og når alle er stoppet, da er det enklere å slette alle. Da kan man... Ja, jeg tror en dokker system prune. Den vil stoppe alle containere som ikke kjører. Så vi kan teste ut det. Det tok litt lengre tid enn jeg hadde trodd å stoppe alle. Men da skulle det i hvert fall ikke være noen som kjører.  Men hvis det er LS minus A, så vil fortsatt de som er exited, de vil fortsatt være der. Men det kan man... Da kan man bruke en dokker system. Prune, legger på en minus A, F... Der får alle og force. Da får man ikke noe spørsmål engang. Da ble det slettet en masse. Det kan vi også se... Det var ikke så mye space som ble spart, men en god del. En halv gigabyte hjelper jo. Så hvis jeg lister nå, så vil jeg se jeg har ingen containere. Men det er fortsatt her. Det er... Nei. Det fjerner faktisk også alle image. Ja... OK. Da fikk jeg faktisk...", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0020", "start": 1647.7, "end": 1765.9, "token_count": 291, "text": "En halv gigabyte hjelper jo. Så hvis jeg lister nå, så vil jeg se jeg har ingen containere. Men det er fortsatt her. Det er... Nei. Det fjerner faktisk også alle image. Ja... OK. Da fikk jeg faktisk... Ja, jeg tror det var den som gjorde at alt ble slettet, var... Minus A der... Eller så kan man gjøre tilsvarende hvis man eksplisitt bare vil... fjerne image. Så... så kan man kjøre den kommandoen. Men nå ser vi alt er rensket opp. Hvis jeg nå ser på disk, DF viser diskbruk. Så ser vi at... ja. Det er ikke enormt mye jeg har fått til, men nå har jeg 1,6 giga. Det var noe sånn 0,7 giga eller noe sånt som ble brukt. OK. Det var litt om å renske opp. Bak dokker og dokkerfiler. Ja, nå så jeg at jeg fikk... Et spørsmål her. Jeg var like nederst i kjøtten, men nå ser jeg det. Ja, det er et godt spørsmål. Hva er forskjellen på image og container? Ja... Ett image er selve det imaget som...", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0021", "start": 1737.8, "end": 1843.5, "token_count": 294, "text": "Ja, nå så jeg at jeg fikk... Et spørsmål her. Jeg var like nederst i kjøtten, men nå ser jeg det. Ja, det er et godt spørsmål. Hva er forskjellen på image og container? Ja... Ett image er selve det imaget som... Som konteineren bygges fra. Eller som den starter fra. Så det er på en måte litt sånn som... Med en virtuell maskin så har du et disk-image som er den virtuelle maskinen.  Men når du starter opp dette imaget, så har du en instanse av imaget som kjører. Og det er en virtuell maskin. Det kaller du en VM. Tilsvarende er det for containere. Du har et image som du starter opp. Og da, med en gang du har startet det imaget, har et image som kjører, så er det en container. Det er kanskje ikke helt presist svar. Du kan jo liste konteinere. Og da... og da er på en måte det en konteiner... Når den er stoppet, så er den fortsatt en konteiner. Når du starter opp den igjen, så har du en konteiner. Men det er en instanse som er frosset ned på den.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0022", "start": 1807.34, "end": 1940.08, "token_count": 298, "text": "så er det en container. Det er kanskje ikke helt presist svar. Du kan jo liste konteinere. Og da... og da er på en måte det en konteiner... Når den er stoppet, så er den fortsatt en konteiner. Når du starter opp den igjen, så har du en konteiner. Men det er en instanse som er frosset ned på den. Så... jeg vet ikke om det var et fullgodt svar. Men jeg kan prøve å svare på det litt når vi gjør et nytt eksempel. Spørsmålet er om det legges ut på Kanvas. Ja, det gjør det. Jo. Jeg tar opp sånn at... det går ikke an med Zoom å ta opp i skyen, men jeg har sett at jeg kan ta opp lokalt. Så jeg tar nå opp og lagrer. Jeg kan dobbeltsjekke om jeg har fått det til.  Ja... Vi ser... Her er det en mappe. Og her lagres da fortløpende... en video som jeg skal legge ut. Vi kan se... Et annet Linux-triks. Det eneste er å bruke watch. Hvis man tar watch på... Oi. Var kanskje ikke så godt triks. Skal vi bare se om den øker.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0023", "start": 1919.0, "end": 2044.76, "token_count": 295, "text": "Og her lagres da fortløpende... en video som jeg skal legge ut. Vi kan se... Et annet Linux-triks. Det eneste er å bruke watch. Hvis man tar watch på... Oi. Var kanskje ikke så godt triks. Skal vi bare se om den øker. Må kanskje gjøre sånn. Sånn, ja. Jo, da kan vi se fortløpende at den filen her... Den øker. Så kan jeg konvertere den til en videofil. Og så kommer jeg til å legge ut en iCam. OK. Tilbake til image... Så jeg finner riktig vindu. Image og hva forskjell på image og container. Generelt, container er da den kjørende enheten. Image er filen som inneholder... Vi kan starte en konteiner. Det er for å interaktive og tette y. Det er for å starte en terminal. Ønsker jeg å kjøre et bæsjvindu når den starter opp. Og da ser vi... Nå hentes det et image... Ikke fra github, men fra Dokker. Da ble det lastet ned, og så ser vi at nå fikk vi opp et prompt der. Det betyr at nå er jeg inne i dokker-imaget.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0024", "start": 2015.96, "end": 2124.38, "token_count": 287, "text": "Ønsker jeg å kjøre et bæsjvindu når den starter opp. Og da ser vi... Nå hentes det et image... Ikke fra github, men fra Dokker. Da ble det lastet ned, og så ser vi at nå fikk vi opp et prompt der. Det betyr at nå er jeg inne i dokker-imaget. Nå er dette en konteiner, for det er et image som er startet opp. En instanse har jeg nå fått opp. Jeg kan starte flere instanser av det samme imaget. Så hvis jeg tar PVD her, så vil du se at jeg er inni et Linux fyllesystem. Og se hva slags distribusjon det er. Og vi ser at dette er 1804. Og så så vi sist at... Hvordan er det hvis jeg tar Exit nå? Så vil... Vi kan prøve det. Sier vi Exit. Så vil konteineren stoppe. Hvis jeg nå tar dokkekonteiner PS... Så ser vi at vi har en... ingen container som kjører. Men PS-A, der vil jeg se at jeg har en container som det ble gjort exit på. For tolv sekunder siden. Men da er det mulig å starte den på nytt.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0025", "start": 2101.5, "end": 2228.98, "token_count": 298, "text": "Hvis jeg nå tar dokkekonteiner PS... Så ser vi at vi har en... ingen container som kjører. Men PS-A, der vil jeg se at jeg har en container som det ble gjort exit på. For tolv sekunder siden. Men da er det mulig å starte den på nytt. Så da kan jeg si dokker container start. Så container ID. Så ser vi at da starter konteineren. Og der har vi en konteiner som kjører i syv sekunder. Eller som har kjørt i syv sekunder. Så vi ser... Konteineren er liksom selve instansen. Og imaget er det imaget som instansen er startet fra. Men nå er vi på en måte ute av konteineren igjen. Vi så også sist på hvordan vi kan koble oss til. Og det kan vi gjøre med... Det er et par måter å gjøre det på. Den beste måten er kanskje å bruke execute. For da kan man si at man ønsker å eksekutere på... I denne konteineren så ønsker jeg å kjøre bæsj. Så... Ops. Mulig det var en litt feil syntaks. Kanskje jeg ikke trenger IT her. Prøve å gi det her, da.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0026", "start": 2191.74, "end": 2354.4, "token_count": 290, "text": "For da kan man si at man ønsker å eksekutere på... I denne konteineren så ønsker jeg å kjøre bæsj. Så... Ops. Mulig det var en litt feil syntaks. Kanskje jeg ikke trenger IT her. Prøve å gi det her, da. Nei, da må jeg sjekke ut hvordan det var i brukt eksekutt. Skal jeg se om jeg har gjort det her før. Skal vi se... Dette her burde virke. Ja. Jeg lurer på hva jeg gjorde feil sist, men... skal vi se. Det var bare rekkefølgen på IT. Jeg måtte ha IT... må komme etter execut. Sånn, så da har jeg koblet meg inn i containeren igjen. Da kan jeg se. Jeg ser til og med at jeg har historie, så jeg kan bla tilbake her. Så er det en annen måte å gå ut av containere på. Det er kontroll P, kontroll Q. Da kommer jeg ut. Og da vil jeg se at det fortsatt er siste termin PS. Så står den fortsatt der og kjører. OK. Da skal vi prøve. Vi skal begynne å se litt på det vi skal gjøre i dag.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0027", "start": 2325.28, "end": 2416.84, "token_count": 286, "text": "Det er kontroll P, kontroll Q. Da kommer jeg ut. Og da vil jeg se at det fortsatt er siste termin PS. Så står den fortsatt der og kjører. OK. Da skal vi prøve. Vi skal begynne å se litt på det vi skal gjøre i dag. Først og fremst skal vi se på dokkefiles. Men før det så skal vi prøve å se litt på volumes. Og generelt hvordan man får dokkefilene... Nei, får konteinerne til å få volumes. Og koble seg opp mot det lokale filsystemet. For da kan man, hvis man kobler en dockerfil til det lokale filsystemet, så kan man da på en måte koble løs containeren. Sånn at den er en uavhengig enhet som raskt kan startes og stoppes. For hele tiden så ønsker man å ha containere uavhengige. De skal gjerne gjøre så lite som mulig. Typisk så kjører en container én prosess. F.eks. én webserver. Eller én applikasjon som skal testes og kjøres. Men vi vil gjerne kunne stoppe og starte den, og gjerne kaste den også.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0028", "start": 2399.32, "end": 2511.44, "token_count": 287, "text": "De skal gjerne gjøre så lite som mulig. Typisk så kjører en container én prosess. F.eks. én webserver. Eller én applikasjon som skal testes og kjøres. Men vi vil gjerne kunne stoppe og starte den, og gjerne kaste den også. Bygge den på nytt uten at innholdet blir kastet. Så derfor skal vi nå begynne å se litt på volumer, og hvordan man kobler til eksterne filer til en dokkerinstans. Dokkerinstans er da det samme som en container. Så det er en annen måte å si container på. Da skal jeg... I stedet dele slidene til Mike Long, som vi så på sist. Vi ser vi har en ca. 20 slider til. Da skal vi se på volumer. Ja. Dukkevolum, det er da som jeg sa, det er en mappe eller en fil som man bruker for å koble opp hva man vil. ... varige filer til en dokkerinstans, sånn at man kan... Sånn at den... Selv om man da dreper og til og med avslutter og fjerner en container, så kan man bruke de samme filene senere.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0029", "start": 2486.3, "end": 2586.44, "token_count": 299, "text": "som man bruker for å koble opp hva man vil. ... varige filer til en dokkerinstans, sånn at man kan... Sånn at den... Selv om man da dreper og til og med avslutter og fjerner en container, så kan man bruke de samme filene senere. Ved å bygge en ny container fra et nytt image og koble opp mot de samme filene. Så kan de også deles mellom containere. Det er et par-tre måter å gjøre dette på. Bind-mode kobler direkte... Det er som en link. Du kan ha en fil eller mappe i containeren som peker direkte på en mappe på filsystemet på hosen du kjører container. Da kan du endre på filene på hosen, og så endres det i containeren. Og foretrukket metode er volum. Og da... Et volum, det defineres av docker-demon. Så da er det på en måte dokker som står og styrer dette her. Og dette kan i større grad gjøre at containere kan dele data med hverandre også. Så dette er en litt mer abstrakt måte å styre filer på, som også da er styrt av docker-demon. At det er dokker som styrer dette.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0030", "start": 2562.42, "end": 2654.78, "token_count": 288, "text": "Så da er det på en måte dokker som står og styrer dette her. Og dette kan i større grad gjøre at containere kan dele data med hverandre også. Så dette er en litt mer abstrakt måte å styre filer på, som også da er styrt av docker-demon. At det er dokker som styrer dette. Så kan man altså montere direkte minne, og det kommer ikke vi til å se på. Da er det to måter... De to måtene vi skal se på, er bind-mounts. Det er da direkte å binde posen. Da har man... Når man starter en container... Så legger man på den opsjonen, minus V. Og slash house dir er da filsystemet her på hosen. I vårt tilfelle så er det på Linux V. Og så slash app. Det er da filsystemet i konteineren. Så det vi skal gjøre etterpå, er altså koble det til vår WWW hotml på konteineren. Koble det til et filsystem her, sånn at vi kan endre innholdet på. Webserveren mens den kjører. Dette gjør det samme med et volum, men da må vi først i docker", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0031", "start": 2624.32, "end": 2767.22, "token_count": 285, "text": "Og så slash app. Det er da filsystemet i konteineren. Så det vi skal gjøre etterpå, er altså koble det til vår WWW hotml på konteineren. Koble det til et filsystem her, sånn at vi kan endre innholdet på. Webserveren mens den kjører. Dette gjør det samme med et volum, men da må vi først i docker kreere et volum med docker volume crates, og så navnet på volumet. Men det er fortsatt litt tilsvarende. Den vil da i praksis ligge på i fyllsystemet her, men den kan da styres av. Vi skal straks ta en pause, men vi ser her... Hvis dere har lyst til å prøve på dette i pausen, så kan dere gå til disse slidene. Og starte å gjøre oppgaver. Før vi tar pause... Unngå direktører fra verten i produksjonen. Dette er hvordan det er brukt i Kates. K8S er da en forkortelse for Kubernetes. Men det vi skal se på i dag, er hvordan vi faktisk monterer pilsystemer fra Hosen inn i containeren. Så vil man se at man får en error.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0032", "start": 2733.36, "end": 2949.78, "token_count": 275, "text": "Dette er hvordan det er brukt i Kates. K8S er da en forkortelse for Kubernetes. Men det vi skal se på i dag, er hvordan vi faktisk monterer pilsystemer fra Hosen inn i containeren. Så vil man se at man får en error. Man må da legge på en null foran, så kommer man til riktig sted. Ja, sorry. Nå så ikke dere hva jeg holdt på med. Men hvis du klikker her, så kommer du til for using volumes. Så må du legge på en null foran sekstallet for å komme til pilen. Ellers kan det gå dit fra oppgavetekst. Men da tar vi et kvarters pause. 15 min pause. Tenk gjerne ut spørsmål, og still spørsmål i pausen. ... og det er veldig vanskelig å forstå hva som skjer. Og det er veldig fint å se hvordan folk oppfører seg på skolen. Det er veldig vanskelig å forstå hva som er sant og hva som er sant. Det er veldig vanskelig å forstå hva som skjer under en slik situasjon. Ja, da er jeg tilbake igjen, så nå starter vi.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0033", "start": 2853.36, "end": 3083.66, "token_count": 292, "text": "Og det er veldig fint å se hvordan folk oppfører seg på skolen. Det er veldig vanskelig å forstå hva som er sant og hva som er sant. Det er veldig vanskelig å forstå hva som skjer under en slik situasjon. Ja, da er jeg tilbake igjen, så nå starter vi. Kom gjerne med spørsmål i chatten hvis det er noen som har spørsmål hos Stopp også. Det går også an å koble opp med lyd og stille spørsmål. OK. Da... Hvor var vi? Jo, vi skulle begynne å se på volumer. Eller det vil si, vi skulle prøve å koble til volumer. Jeg tror jeg kan begynne å teste... gjøre noen eksempler. Ikke nødvendigvis gjøre akkurat som i den gjennomgangen som ligger på Github. Men vi kan prøve å lage en webserver. Ja. Det er spørsmål om det blir noen endring på eksamen i år med tanke på koronautbruddet. Det blir det. Og vi har ikke helt... Jeg vet ikke hvordan det blir til slutt. Men det blir nok vanskelig å gjennomføre en tradisjonell eksamen selv i Inspera.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0034", "start": 3023.18, "end": 3166.64, "token_count": 300, "text": "Men vi kan prøve å lage en webserver. Ja. Det er spørsmål om det blir noen endring på eksamen i år med tanke på koronautbruddet. Det blir det. Og vi har ikke helt... Jeg vet ikke hvordan det blir til slutt. Men det blir nok vanskelig å gjennomføre en tradisjonell eksamen selv i Inspera. Men jeg vet foreløpig ikke. En mulighet som jeg kunne tenke meg, var rett og slett å ha en Inspera. Men som er helt åpent. Hvor det da i praksis kan ha med bøker og... Men... Jeg vet som sagt ikke. Men det kommer jeg tilbake til. OK. Dere kan tegne PS. Da kan vi se... Jo, der har vi en konteiner som står og kjører. Jeg lurer på om vi kanskje skal... Hoppe litt frem og tilbake. Kanskje vi skal prøve å... Først bygge en konteiner med dokkefarts. Og så etterpå gå tilbake til volumer og se på det. For det med volumer er ikke like viktig. Det viktigste vi skal se på. Så jeg tror vi starter med å gjøre det. En dokkefil er da i prinsippet en fil", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0035", "start": 3140.02, "end": 3238.02, "token_count": 280, "text": "Først bygge en konteiner med dokkefarts. Og så etterpå gå tilbake til volumer og se på det. For det med volumer er ikke like viktig. Det viktigste vi skal se på. Så jeg tror vi starter med å gjøre det. En dokkefil er da i prinsippet en fil som inneholder alt det en dokkecontainer trenger. Det vi gjorde forrige gang, var at... Nå før pause så gikk jeg inn på denne... Det vi gjorde forrige gang, var at nå er jeg inne på konteineren, og da kan jeg kjøre apps. App install osv. Og så installere den programvaren jeg trenger, f.eks. en webserver. Men det vi skal se på nå, på vei ut med Exit... Da ser jeg for øvrig at den, når jeg går inn med Execute og kobler meg opp, Så vil den fortsatt stå og gå etterpå. Men det vi skal gjøre nå, er å bygge en container som allerede har Apasje installert før vi starter. Og det er da Dockefiles kommer inn i bildet. Og det man gjør da, er at man lager en mappe.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0036", "start": 3213.38, "end": 3310.44, "token_count": 281, "text": "Så vil den fortsatt stå og gå etterpå. Men det vi skal gjøre nå, er å bygge en container som allerede har Apasje installert før vi starter. Og det er da Dockefiles kommer inn i bildet. Og det man gjør da, er at man lager en mappe. Jeg vil lage en webserver her. Så jeg lager en mappe som heter Webserver. Så går jeg til den mappen. Og så lager jeg inni den mappen en fil som rett og slett skal hete dokkerfile. Den kan ha andre navn, men hvis man bruker navnet dokkerfile, sånn som det, så kan man bygge den... Og da vil default dokker forvente at filen heter dokkerfile. Så jeg kaller den dokkerfile. Og da... I gjennomgangen i Github vil dere se at det er en rekke kommandoer eller instruksjoner som gjør at man definerer hvordan konteineren skal se ut. Det første og viktigste er from. Det sier hvilket image man skal velge. For eksempel så velger jeg her... Siste bunteversjon, som jeg default får da.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0037", "start": 3273.36, "end": 3405.56, "token_count": 297, "text": "I gjennomgangen i Github vil dere se at det er en rekke kommandoer eller instruksjoner som gjør at man definerer hvordan konteineren skal se ut. Det første og viktigste er from. Det sier hvilket image man skal velge. For eksempel så velger jeg her... Siste bunteversjon, som jeg default får da. Etterpå saver jeg denne filen, så skal jeg kjøre meg en dokkebilde. Og da vil man starte med å laste ned bunte-imaget. Så kan man etterpå kjøre kommandoer inne inne i bildet. Inni det imaget. Når man bygger imaget, så vil disse kommandoene kjøres før man starter. På denne måten kan jeg starte med å si run app update, og så kan jeg ta istedenfor update, så kan jeg ta install. Og da kan jeg installere webserveren. Ja, vi kan jo kanskje gjøre dette i første omgang. Vi kan ta én ting til. Vi kan ta... Det jeg gjør nå, er altså å kopierer en fil som heter index.8ml. Da må jeg lage den inne i den mappen som jeg har her. Og så vet jeg at i en Apache-sølver...", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0038", "start": 3377.84, "end": 3506.52, "token_count": 286, "text": "Vi kan ta én ting til. Vi kan ta... Det jeg gjør nå, er altså å kopierer en fil som heter index.8ml. Da må jeg lage den inne i den mappen som jeg har her. Og så vet jeg at i en Apache-sølver... Så ligger indeksfilen i VAR og BWWHTMF. Da kopierer jeg den filen din, sånn at når dette imaget starter, så vil jeg få en container som inneholder en webserver. Da kunne jeg selvsagt lagt opp et svært filsystem der med masse statiske sider som kunne serves. Ok, vi kan stoppe der i første omgang. Og så kan vi prøve å bygge en container ut fra den dokkefilen. Og da bruker man dokkebild. Dokkebild... Ja, altså... Det er noen... Det er noen opsjoner man kan bruke på bild. Skal vi se... Ja... Minus T kan man i hvert fall ha med. Generelt, hvis man har en kommando som man lurer på, så kan man alltid legge på minus hell, sånn som her. Og da får man hjelp til akkurat den kommandoen dere vil. Minus T er greit.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0039", "start": 3483.36, "end": 3609.2, "token_count": 295, "text": "Ja... Minus T kan man i hvert fall ha med. Generelt, hvis man har en kommando som man lurer på, så kan man alltid legge på minus hell, sånn som her. Og da får man hjelp til akkurat den kommandoen dere vil. Minus T er greit. Det kan være nyttig, for da kan man legge på en... Eller gi konteineren et navn. Så vi kan bruke det. La oss si jeg kaller den Web, Apache, hva det er sånt. Blir et tydelig navn. Og så, nå ligger det en dokkefil her i mappa, så da bare legger jeg på en prikk som betyr... Og da ser vi at den begynner å bygge. Jeg hadde allerede hentet inn et ubundet image. Men så begynner den som step to og fire å legge inn apt-get-update. Dette blir da en rekke steg nedover. Og nå begynner den å isolere Apache. Men det fine med denne lagdelingen er at det faktisk er en lagdeling også i imager. Sånn at hver del kan lages til en egen image. Øyeblikket før jeg begynte å installere Apache, det kan bli et image.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0040", "start": 3584.42, "end": 3673.88, "token_count": 289, "text": "Dette blir da en rekke steg nedover. Og nå begynner den å isolere Apache. Men det fine med denne lagdelingen er at det faktisk er en lagdeling også i imager. Sånn at hver del kan lages til en egen image. Øyeblikket før jeg begynte å installere Apache, det kan bli et image. Da vil det være Appget-update, men ikke Apache-innstilt. Så man får den type lagdeling. Og hvis man da endrer på noe, f.eks. endrer litt på hva som kopieres inn, så er det bare en liten endring. Når jeg da bygger et nytt image, så brukes alle de. De er akkurat som før. Installasjon av Apache og Hentu, Buntu osv. alt er det samme. Så må man legge på en endring, så kommer den på toppen av det nye. Så trenger man ikke å gå gjennom hele den byggeprosessen fra start til slutt. Det holder med den siste biten. Nå fikk jeg en feil her. Copy. Det er ikke så rart jeg fikk en feil på det. Fordi copy, den indeks.dot.hemmelen, den hadde jeg ikke laget.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0041", "start": 3648.2, "end": 3756.6, "token_count": 292, "text": "Så trenger man ikke å gå gjennom hele den byggeprosessen fra start til slutt. Det holder med den siste biten. Nå fikk jeg en feil her. Copy. Det er ikke så rart jeg fikk en feil på det. Fordi copy, den indeks.dot.hemmelen, den hadde jeg ikke laget. Så det er et godt eksempel på at da kan jeg rette opp det og bygge på nytt. Men vi kan før vi gjør det, så kan vi se om vi har fått et nytt image her. Ja. Det ser ut som det ikke har blitt ferdig siden den... Siden den feilet. Så jeg kan prøve å rette opp det her først. Her inne så trenger jeg da en inex-fil. Da kan jeg bare... Skrive inn noen her. Sånn. Da har jeg en fil her. Så kan jeg prøve å bygge på nytt. Da ser vi. Da... vil de tre første steppene... Der har man allerede et image som er ferdig. Så det går veldig fort. Da ser vi... Da... vil de tre første steppene... Der har man allerede et image. Så det er bare det siste steppet der.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0042", "start": 3729.52, "end": 3843.28, "token_count": 276, "text": "Da ser vi. Da... vil de tre første steppene... Der har man allerede et image som er ferdig. Så det går veldig fort. Da ser vi... Da... vil de tre første steppene... Der har man allerede et image. Så det er bare det siste steppet der. Det gjør en liten endring på imaget, og så bygger man imaget. Så nå... Nå ser vi at vi har et ferdig image her. Web Apartheid. Og da er det klart. Da kan jeg starte The Image som tidligere, Og da heter det Apasje. Så kan jeg kanskje kjøre bæsj der også. Sånn. Da er jeg inne i containeren. Og her er nå Apasje installert. Det er flere måter å starte Apasje på. Men jeg ser at den er installert. Ved at nå er det lagt inn muligheter for å starte Apasje-tjenesten. Et problem med dette er at den Apasje-tjenesten ikke har startet opp. Det kunne vært nyttig at den startet automatisk. Men... Så det går alltid an å gå inn sånn som jeg gjør nå.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0043", "start": 3818.52, "end": 3914.96, "token_count": 289, "text": "Ved at nå er det lagt inn muligheter for å starte Apasje-tjenesten. Et problem med dette er at den Apasje-tjenesten ikke har startet opp. Det kunne vært nyttig at den startet automatisk. Men... Så det går alltid an å gå inn sånn som jeg gjør nå. Og så gå ut igjen. Når jeg går ut, så bruker jeg kontroll-p, kontroll-q. Hvis ikke, så stopper hele serveren. Sånn. Så kan jeg liste igjen med PS. Og da ser vi at jo, jeg har en Veb-aparse nå som er oppe og kjører. Og den kjører da en Aparse. Men vi ser vi har et annet problem her. Og det er at vi har ikke tilordnet noen port. Og dermed så vil ikke... vil den neppe gi noe. Vi kan prøve... Den vil nok gi noe, men det er fra den lokale serveren som står her og kjører. Så vi fikk ikke den hei fra dere-fil. Hvordan kan vi endre det? Jo, det er... Da kan vi rett og slett stoppe konteineren. Dokumentstopp. Og så ser vi den starter på 6A.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0044", "start": 3890.86, "end": 3998.66, "token_count": 288, "text": "Den vil nok gi noe, men det er fra den lokale serveren som står her og kjører. Så vi fikk ikke den hei fra dere-fil. Hvordan kan vi endre det? Jo, det er... Da kan vi rett og slett stoppe konteineren. Dokumentstopp. Og så ser vi den starter på 6A. Så det holder faktisk bare å skrive 6A. Så lenge det er entydig hvilken idé den er, så vil den stoppe. Så nå stoppet jeg WebApache. Så kan jeg prøve å starte den igjen med... Og så kan jeg ta minus P... La oss si vi tar 8081 til 80. Det betyr nå at... Innkomne forespørsler til Local Host på port 8081, skal forwardes sendes videre til port 80 på containeren. Så da... Jeg prøver å kjøre den sånn i stedet. Så kan jeg se her... Nei, det ser ikke ut som den webserveren kjører her. For vi stoppet jo hele containeren. Men da kan jeg prøve å starte webserveren. Da starter den. Så går jeg ut med kontroll P, kontroll Q.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0045", "start": 3963.36, "end": 4106.42, "token_count": 296, "text": "Jeg prøver å kjøre den sånn i stedet. Så kan jeg se her... Nei, det ser ikke ut som den webserveren kjører her. For vi stoppet jo hele containeren. Men da kan jeg prøve å starte webserveren. Da starter den. Så går jeg ut med kontroll P, kontroll Q. Så lister jeg konteineren igjen. Og nå ser jeg at... Nå ser vi port 8081. Blir nå sendt til port 80 på konteineren. Så hvis jeg nå kjører curl local host på 8081... Så ser vi at jeg får opp hilsenen fra Dockyfile. Så nå fungerer det sånn som det skal. Og da vil jeg også kunne se, hvis jeg nå går i en broser, så vil jeg også kunne se at den vil synes utenifra. Hvis jeg går til 8081 på OS71. Skal vi se. Gjøre et eksperiment der. Så skal jeg prøve å dele hele skjermen i stedet. Altså hele min bestoff. Sånn. Nå ser dere forhåpentligvis hele min desktop. Men da er det et spørsmål om... Ser dere bra nok det jeg skriver? Skal vi se...", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0046", "start": 4060.12, "end": 4223.28, "token_count": 296, "text": "Så skal jeg prøve å dele hele skjermen i stedet. Altså hele min bestoff. Sånn. Nå ser dere forhåpentligvis hele min desktop. Men da er det et spørsmål om... Ser dere bra nok det jeg skriver? Skal vi se... Ja. Det er en som sier ja her i hvert fall. Hvis det er noen som... Hvis denne skjermen er for liten, så si gjerne fra. Så kan jeg heller prøve å... Så kan jeg prøve å gå tilbake til å dele bare ett vindu. Ser et svart vindu til høyre for terminalen, bare. Det var rart. Vi kan se om vi får løst det på en annen måte. Men i hvert fall i første gang, så vil jeg bare demonstrere. Hvis jeg nå går inn på OUS70. Her er øredelen til den. Ja, så var det fort 80, 80, 81. Da ser vi, da kommer... Nei. Da kom det en annen... Da må du ha full screen. Da er spørsmålet hvorfor får jeg... Hvorfor får jeg nå en annen hilsen? Da må jeg gå tilbake hit, og så må jeg se dokker, container, PS...", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0047", "start": 4167.34, "end": 4330.12, "token_count": 300, "text": "Ja, så var det fort 80, 80, 81. Da ser vi, da kommer... Nei. Da kom det en annen... Da må du ha full screen. Da er spørsmålet hvorfor får jeg... Hvorfor får jeg nå en annen hilsen? Da må jeg gå tilbake hit, og så må jeg se dokker, container, PS... Nei, jeg har bare én... Én container. PS... Mulig at dette her er... At det er cash. Vi kan prøve å gjøre et eksperiment. Så kan vi da ta dokker container og så stoppe den her. Dokker container, stopp. 2F. Kan stoppe den andre der også. Da har jeg bare én container som kjører. Ja, og da, når jeg går her nede og prøver å... ... starte den på nytt, så ser vi at jeg ikke har noen kontakt. Så jeg tror kanskje at det bare var noe som lå i cash. Men det kan vi finne ut ved å kjøre ringen, så kan jeg starte på nytt. Du har den jeg kjørte. Og så må jeg... Starte Apache 2 igjen. Start. Sånn. Og da får jeg den riktige. Som jeg hadde her oppe da jeg kjørte curl lock-closed.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0048", "start": 4281.68, "end": 4411.16, "token_count": 300, "text": "Men det kan vi finne ut ved å kjøre ringen, så kan jeg starte på nytt. Du har den jeg kjørte. Og så må jeg... Starte Apache 2 igjen. Start. Sånn. Og da får jeg den riktige. Som jeg hadde her oppe da jeg kjørte curl lock-closed. Da fikk jeg hilsen fra dockerfile og hilsen fra dockerfile-containere. Så det som vi skal prøve å få til nå, som er problemstillingen, det er... Hvordan kan vi lage eller endre dockerfile sånn at Apache 2 starter direkte? Det kunne vært veldig nyttig. Så hvis jeg nå går ut her, så ser vi da stoppet den filen. Nei, det er imaget. Men så skal jeg gå inn i dokkerfeil og prøve å gjøre en endring. Og da er det... Det man kan gjøre, er å legge på en kommando. Og da trenger man å legge på en kommando som starter apasje. Det kan jeg legge på her. CMD, så få kommando. Og da kan... Og da er det en slags sånn... Hva heter det? Jason-syntaks. For å få til dette her, så... Man kan ikke kjøre direkte den inn hit.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0049", "start": 4376.42, "end": 4482.2, "token_count": 283, "text": "Og da trenger man å legge på en kommando som starter apasje. Det kan jeg legge på her. CMD, så få kommando. Og da kan... Og da er det en slags sånn... Hva heter det? Jason-syntaks. For å få til dette her, så... Man kan ikke kjøre direkte den inn hit. Men det er en biner i Apache som heter Apache-kontroll. Den bineren kan man starte. Hvis man prøver å gjøre dette direkte, så vil det ikke fungere. Og det er fordi dette starter arrangen en bakgrunnsjobb, den kommandoen. Og den, for å få Apache til å starte, så må den kjøres i foreground. Og da er det en liten besvergelse. Det er en demon som da starter. Hvis jeg har fått det her riktig, så skal det nå bygges en Aparche-container som starter direkte. Så da må jeg prøve en bilde igjen. Da vil jeg nok få en feilmelding om at den allerede er bygget. Nei, det er feil. Det gikk fort å gjøre endringen, for da var det bare kommandoen som ble endret.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0050", "start": 4460.6, "end": 4586.92, "token_count": 282, "text": "som starter direkte. Så da må jeg prøve en bilde igjen. Da vil jeg nok få en feilmelding om at den allerede er bygget. Nei, det er feil. Det gikk fort å gjøre endringen, for da var det bare kommandoen som ble endret. Så kan vi prøve å starte konteineren igjen. Det er samme... Ja, det skulle funke, det. Så kan jeg se... Nei, jeg kan ikke se om den... si at den kjører her. Det skulle jeg ha sett her nede. Nei. Det ser faktisk ut som den ikke har startet. Da var det tydeligvis noe som ikke virket... Skal vi se... Det er ett spørsmål her. Kan man ha flere dokkerfiler i container? Nei. I utgangspunktet så har man én dokkerfil. Og den bygger da én container. Men man kan jo starte flere instanser av den containeren. Men skal vi se. Hva var problemet her? Jo... Skal vi se om vi har noen konteinere å kjøre. Den står og kjører. Men... Den svarer ikke på port 8081.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0051", "start": 4553.56, "end": 4712.46, "token_count": 293, "text": "Men man kan jo starte flere instanser av den containeren. Men skal vi se. Hva var problemet her? Jo... Skal vi se om vi har noen konteinere å kjøre. Den står og kjører. Men... Den svarer ikke på port 8081. Så det betyr nok at Apache ikke kjører inni konteineren. Da må vi gå tilbake til dokkefilmen. Og så se om jeg har fått syntaksen helt riktig. Det er mulig det gjør en forskjell om man starter den interaktivt. Tanken er at man skal starte den i bakgrunnen. Det gjør man med minus d. Sånn som det. Men her får jeg en melding om... Da skyldes det kanskje... at det allerede... Oi. Ja. Jeg glemte å stoppe den her, ja. Da må jeg stoppe den først. Sånn. Så prøver jeg å starte containeren i bakgrunnen. Da ser vi. Når jeg starter med minus D, så får jeg ikke opp et skjell, for da har jeg ikke bedt om det. Da startes denne i bakgrunnen. Nå ser vi... Den er oppe og kjører. Da ser vi også...", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0052", "start": 4683.36, "end": 4799.96, "token_count": 300, "text": "Sånn. Så prøver jeg å starte containeren i bakgrunnen. Da ser vi. Når jeg starter med minus D, så får jeg ikke opp et skjell, for da har jeg ikke bedt om det. Da startes denne i bakgrunnen. Nå ser vi... Den er oppe og kjører. Da ser vi også... Nå virket det faktisk som det skulle. Nå startet den filen... Imaget startet, containeren startet. Og den startet da også automatisk webserveren. Så nå har vi på en måte fått et veldig kraftig verktøy. Jeg kan stoppe den her. B5. Ja, det var faktisk flere med B5. Eksplisitt stopp en sånn, da. Nå stopper jeg den konteineren. Og da ser vi... Ved å bygge denne konteineren med... Så har vi nå en konteiner som tar det innholdet vi ønsker. Installerer Apache 2 og kjører den i forgrunnen. Så det vi gjorde var bare å bygge den sånn. Nå er den ferdigbygd. Og her har vi da en fiks ferdig oppskrift, så nå er det bare for den som måtte ønske det.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0053", "start": 4781.88, "end": 4890.44, "token_count": 289, "text": "Installerer Apache 2 og kjører den i forgrunnen. Så det vi gjorde var bare å bygge den sånn. Nå er den ferdigbygd. Og her har vi da en fiks ferdig oppskrift, så nå er det bare for den som måtte ønske det. På omtrent no time så har vi da en kjørende konteiner. Da sa vi at nå er det veldig mye lettere å starte en til. Som kjører på 80-82. Sånn som det. Eller tre stykker for den saks skyld. Hvis jeg går til 8082, så ser vi at der har jeg også en container som kjører. 8083. Har jeg en annen webserver osv.? 84. Den hadde jeg ikke startet. Så vi ser på denne måten at det er ekstremt hurtig å starte å kjøre containere. Men... neste problemstilling blir da hvordan kan man endre på innholdet. I utgangspunktet så må man da gå inn i konteineren og endre på innholdet. Vi kan jo prøve det, altså. Sånn generelt så kan jeg gå inn i en konteiner, f.eks. denne her.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0054", "start": 4863.36, "end": 5016.62, "token_count": 295, "text": "Men... neste problemstilling blir da hvordan kan man endre på innholdet. I utgangspunktet så må man da gå inn i konteineren og endre på innholdet. Vi kan jo prøve det, altså. Sånn generelt så kan jeg gå inn i en konteiner, f.eks. denne her. Går jeg inn i den på... 81 er det vel jeg går inn i nå. Og så kan jeg gå til hit. Her ligger indekshvila. Så kan jeg legge til fra 8081, f.eks. Så kan det gå ut igjen. Da har vi fortsatt tre konteinere som kjører. Så kan vi se om... Ja, da ser vi her. Nå får vi en spesiell melding fra 8081. Fra 8082. Så får vi den samme gamle meldingen. En konteiner bygges opp av flere image, som er på en måte lagdelt. Men hvis man tenker på det grunnleggende imaget, så har man bare ett image. Det er da i dokkefylen. Øverst i dokkefylen så står det 'from a bunte'. Det betyr hent et bunte-image. Men så, ja... Det du henter da, er alt som skal til", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0055", "start": 4990.92, "end": 5114.44, "token_count": 296, "text": "Men hvis man tenker på det grunnleggende imaget, så har man bare ett image. Det er da i dokkefylen. Øverst i dokkefylen så står det 'from a bunte'. Det betyr hent et bunte-image. Men så, ja... Det du henter da, er alt som skal til for å gjøre det underliggende Linux-operativsystemet til en Ubuntu 1804. Hvis jeg hadde... Her så er det jo ikke... Vi kan se... VM-en her... Det er jo en... Det er jo Debian. Det er Debbian versjon 10.3. Så... Så når jeg kjører from Ubuntu, så det imaget inneholder alt som skal til for at dette Debbian-operativstemmet ser nøyaktig ut som Ubuntu 1804. Og så, når jeg installerer Apache 2, så kommer det et nytt lag på det imaget. Alt som gjør det opprinnelige buntimaget forskjellig fra det. På den måten er det en lagdeling som gjør at man til slutt får et image som inneholder alt det man trenger. OK... Skal vi se. Jo, da er det to problemstillinger som står igjen. Men den første problemstillingen... Eller det er vel egentlig bare én", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0056", "start": 5078.48, "end": 5272.82, "token_count": 298, "text": "På den måten er det en lagdeling som gjør at man til slutt får et image som inneholder alt det man trenger. OK... Skal vi se. Jo, da er det to problemstillinger som står igjen. Men den første problemstillingen... Eller det er vel egentlig bare én problemstilling som står igjen. Og det er å kunne få en fil lokalt til å vise innholdet i dokkecontaineren. Vi kan prøve å få det til. Skal vi se. Dette her ville jo... starte en konteiner på 8084. Så kan vi prøve å legge til et volum. Da kan jeg prøve å... Skal vi se... Jeg kan prøve å legge til ruteområdet her. Og så kan jeg kopiere... Kan lage en fil... Veldig kort. Som inneholder... hei. Og så kan jeg prøve å kjøre den kommandoen her. Men jeg kan ta og legge på et volum. Ruth skal peke til VAR... WWW HTML. Tror det er sånn det skal kjøres. Jeg sjekker noen gamle kommandoer. Jeg gjør et forsøk. Her var det en port som allerede var i bruk. Vi tar 85. Sånn.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0057", "start": 5223.36, "end": 5376.56, "token_count": 294, "text": "Ruth skal peke til VAR... WWW HTML. Tror det er sånn det skal kjøres. Jeg sjekker noen gamle kommandoer. Jeg gjør et forsøk. Her var det en port som allerede var i bruk. Vi tar 85. Sånn. Straks ferdig. Så bare gjøre ett forsøk på dette her. Hva henter vi nå fra...? Ja, det så ikke så godt ut. Ja, vi fikk det nok ikke helt til. Men det var fordi... ja. Mappen her skulle mappes over på... På webserveren. Men jeg kan... Vi har holdt på lenge nå. Så jeg kan ta en liten pause, så kan jeg komme tilbake om et kvarter. Og så kan jeg pose her hvordan... Den riktige kommandoen for å få til dette. Fra filsystemet inn i dokker i Misjøen. Sånn at når vi etterpå laster inn webfilen, så skal den i den som ligger på hosen. Men jeg ser klokka er min nå, så vi tar 15 minutters pause der. Så er planen etter pausen at dere kan gå inn i såkalte breakout rooms. Litt sånn som vi gjorde forrige fredag.", "source": "lecture"}
{"lecture_id": "linux8", "chunk_id": "linux8_0058", "start": 5353.2, "end": 5469.44, "token_count": 269, "text": "så skal den i den som ligger på hosen. Men jeg ser klokka er min nå, så vi tar 15 minutters pause der. Så er planen etter pausen at dere kan gå inn i såkalte breakout rooms. Litt sånn som vi gjorde forrige fredag. Da vil Ine og Pedran være i hvert sitt rom. Jeg vil også være i ett til å begynne med. Men så har Ine et opplegg for å lage en kø. For det ble en del trøbbel sist med at mange kom inn i samme rommet. Det ble litt kaos. Så Ine kommer til å gi en beskjed på i chatten om hvordan dere skal komme inn. Men først tar vi en pause til... Ja, i hvert fall til 12.30. Kom gjerne med spørsmål til forelesningen i chatten. Så kan jeg prøve å gi ut generelle svar etter pausen. Ok. Men da takker jeg foreløpig for i dag. Det er veldig vanskelig å forstå hva som er skjedd, og hvordan det er. Hva er det som er så spesielt med denne filmen?", "source": "lecture"}
{"lecture_id": "os4del9", "chunk_id": "os4del9_0000", "start": 0.02, "end": 96.38, "token_count": 277, "text": "En C-versjon av Hello World. Og alle C-programmer... For å kunne få til å skrive ut noe, så trenger vi det Standard In-Out, STD-IO. Dette er et bibliotek som vi inkluderer. Og så har alle C-program en main, altså en hovedfunksjon eller hovedmetode. Og i praksis så kan man kjøre alt inn i Maine. Og i dette enkle programmet så er det eneste som jeg gjør, er å skrive tell all world med funksjon printf. Og for å få dette her til å kjøre, så må vi kopilere. Og da gjør vi den operasjonen om å oversette fra høydenivåkode til maskinkode. Så... For å kjøre dette programmet så bruker jeg kompulatoren GCC, en standard Linux-kompulator. Og det som skjer da, er at det lages en exequerbar-fil med maskinkode som heter adotal. Og når jeg kjører den, så skrives Hello World ut. Da må vi vite at... Eller vi kan se på adotal. Og vi ser den er ganske stor. Den er på 8600 bytes.", "source": "lecture"}
{"lecture_id": "os4del9", "chunk_id": "os4del9_0001", "start": 71.1, "end": 163.14, "token_count": 297, "text": "Og det som skjer da, er at det lages en exequerbar-fil med maskinkode som heter adotal. Og når jeg kjører den, så skrives Hello World ut. Da må vi vite at... Eller vi kan se på adotal. Og vi ser den er ganske stor. Den er på 8600 bytes. Så dette er tydeligvis mye mer enn bare akkurat kode for å skrive ut den. Og det er bl.a. fordi det inkluderes et bibliotek her oppe. Så den inneholder masse kommunikasjon med... Med operativsystemet, f.eks. Man kan også... Som vi skal gjøre etter hvert. Man kan også kalle dette noe annet enn AdaptOut. La oss si jeg ønsker å kalle det Hello. Da får jeg en FeelHello, som er nøyaktig den samme som AdaptOut. Og så, når jeg skal kjøre det, så kjører jeg det med Hello. Så dette skal vi gjøre en masse nå. Vi skal lage C-programmer og kompilere det. Vi skal studere at i bakgrunnen så lages maskinkode. Og vi skal se på hvordan denne maskinkoden, som da faktisk lages når vi kompilerer C-programmer på en Linux-maskin,", "source": "lecture"}
{"lecture_id": "os4del9", "chunk_id": "os4del9_0002", "start": 140.64, "end": 169.16, "token_count": 95, "text": "Så dette skal vi gjøre en masse nå. Vi skal lage C-programmer og kompilere det. Vi skal studere at i bakgrunnen så lages maskinkode. Og vi skal se på hvordan denne maskinkoden, som da faktisk lages når vi kompilerer C-programmer på en Linux-maskin, den er så å si identisk med den maskinkoden som vi lagde til simulering.", "source": "lecture"}
{"lecture_id": "os1del7", "chunk_id": "os1del7_0000", "start": 0.0, "end": 82.36, "token_count": 285, "text": "Ja, mer om kurset. Dette har jeg vist fram, kurssiden. Som Ine også sa, det er veldig viktig å jobbe med oppgaver. Det er derfor jeg også har gjort en endring på hele kurset. I fjor og tidligere så har jeg pleid å ha fire timer forelesninger, altså to deler. Og praktisk bruk. Den delen med praktisk bruk tror jeg det er aller viktigst å jobbe hands on, altså jobbe med oppgavene. Og da tror jeg det kanskje er like bra å bruke... Å starte med oppgavene. Sette deg ned, prøve å løse oppgavene og gjøre det. For ofte er det ikke noe sånt ekstremt vanskelig hvert enkelt delt spørsmål. Men det er mye. Det er mange detaljer. Og da tror jeg man får det beste inn i fingrene, bokstavelig talt, ved å sette seg ned ved tastaturet og jobbe gjennom oppgaven. Ja. Et par ting med dette kurset er også at det er et grunnlag for et valgfag vi har i nettverks- og systemadministrasjon.", "source": "lecture"}
{"lecture_id": "os1del7", "chunk_id": "os1del7_0001", "start": 60.0, "end": 142.84, "token_count": 240, "text": "Og da tror jeg man får det beste inn i fingrene, bokstavelig talt, ved å sette seg ned ved tastaturet og jobbe gjennom oppgaven. Ja. Et par ting med dette kurset er også at det er et grunnlag for et valgfag vi har i nettverks- og systemadministrasjon. Som det er veldig nyttig å kunne linje godt for å ta det. Vi har også en masse... Som jeg også underviser på i parallell dette semesteret. Noe som tidligere het Network and System Administration. Men dette handler om infrastruktur, og hvordan sette opp virtuelle maskiner. Konteinere, sette opp systemer for utviklere og alle andre til å bruke. Og hvis dere tenker på å ta en massegrad, spesielt denne massegraden, så er dette kurset veldig nyttig. Hvis dere liker dette kurset, spesielt den praktiske delen, så bør dere absolutt ta en titt på den ACIT-massegraden.", "source": "lecture"}
{"lecture_id": "os8del9", "chunk_id": "os8del9_0000", "start": 0.0, "end": 71.98, "token_count": 243, "text": "Og det var et godt spørsmål i pausen om at man kan switche fra kernel mode til use mode. Det går an. Da kan man gjøre en institusjon som switcher. For i kernel mode så har man allmakt. Men fra use mode så kan man ikke switche til kernel mode. Men det switcher jo til kernel mode. Men den switchen foregår i det øyeblikket. At timeren går på, sender et signal, og så switches det til kernel mode. Og da kommer operativsystemet inn og tar over. Men det som jeg mente med at man ikke kan switche fra user mode til kernel mode, det er... Det fins ingen instruksjon, sånn som står her... Det fins ingen instruksjon switch to kernel mode som en vanlig brukerprosess kan utføre. For hvis den fantes, så kunne den bare i prosessen gjøre sånn i curl mode, og så vips, så var den i curl mode og kunne gjøre hva den ville. Og da kunne den ta over og alle problemene gjenoppstå.", "source": "lecture"}
{"lecture_id": "linux9del6", "chunk_id": "linux9del6_0000", "start": 0.0, "end": 111.72, "token_count": 298, "text": "Det jeg tenkte å gjøre først... hvis jeg deler et annet vindu med dere... Det er altså å se på en tekstversjon av dette. For til nå har vi bare sett på CPU-intensive prosesser. Så hva nå om... Vi ser på tekst. Og da er det en... En annen oppgave denne uken går ut på å laste ned denne filen med VGT. Det er en TAR-fil som inneholder en rekke programmer som... Som gjør noe av det samme, men vi kan se hva de gjør. Vi har nå et perskript. I denne mappen som du får når du pakker ut TAR-filen, Oppgaven til dette programmet er å lage en ny fil, som vi ser øverst her. Så leser man inn linje fra linje fra den store filen. Før man begynner å kjøre dette skriptet, må man kopiere filen stor til slash temp. stor. Så leser hver linje i den store filen linje for linje. Med et tall først på linjen til en annen pil. Så dette er da en helt annen type oppgave enn å stå og regne. Her er det tekstbehandling og skriving til pil. Og det tar ofte litt tid, det å skrive til pil.", "source": "lecture"}
{"lecture_id": "linux9del6", "chunk_id": "linux9del6_0001", "start": 79.52, "end": 187.8, "token_count": 280, "text": "til slash temp. stor. Så leser hver linje i den store filen linje for linje. Med et tall først på linjen til en annen pil. Så dette er da en helt annen type oppgave enn å stå og regne. Her er det tekstbehandling og skriving til pil. Og det tar ofte litt tid, det å skrive til pil. Da vil du se en veldig stor forskjell på hastigheter. Da er det ikke de samme forskjellene som tidligere. Vi kan nå se på field.cpp. Det er da et C++-program som gjør akkurat det samme som Shell-skriptet. Her har jeg juksa litt og lagd en round.shell som kopilerer og kjører og timer og så videre. Så...  Før jeg gjør dette litt raskt, så kan jeg bare starte Rundot Shell. Og så ser vi... Jo. Det vi ser nå, er... Det siste tallet her var så lang tid Shell-skriptet brukte. Og dette var tiden for de andre. Det som er interessant, er at nå er det faktisk noen time. Det vil si at alle programmene utfører den samme oppgaven.", "source": "lecture"}
{"lecture_id": "linux9del6", "chunk_id": "linux9del6_0002", "start": 167.62, "end": 249.26, "token_count": 287, "text": "Jo. Det vi ser nå, er... Det siste tallet her var så lang tid Shell-skriptet brukte. Og dette var tiden for de andre. Det som er interessant, er at nå er det faktisk noen time. Det vil si at alle programmene utfører den samme oppgaven. Og da ser vi at Shell-skriptet bruker nå 5,5 sekunder som før. Mens Yaway, f.eks., bruker 0,8 sekunder. Så det betyr at Yaway i dette tilfellet er bare åtte ganger så raskt. Mens i regnejobben så var Javar 20 000 ganger raskere. Så vi ser en enorm forskjell i hvor mye raskere programmene er. Av en eller annen grunn så er Pøl veldig raskt på akkurat dette her. Nei, til og med raskere enn C++-programmene. Begge er mer enn ti ganger raskere enn Shell-skriptet. Men hvis vi husker tilbake... Så var C-programmet noe sånt som var der 48 000 ganger raskere enn Skjellskriptet. Så vi ser en enorm forskjell i hastighet.", "source": "lecture"}
{"lecture_id": "linux9del6", "chunk_id": "linux9del6_0003", "start": 221.48, "end": 307.68, "token_count": 285, "text": "Nei, til og med raskere enn C++-programmene. Begge er mer enn ti ganger raskere enn Shell-skriptet. Men hvis vi husker tilbake... Så var C-programmet noe sånt som var der 48 000 ganger raskere enn Skjellskriptet. Så vi ser en enorm forskjell i hastighet. Det er en enorm forskjell i forskjellen i hastighet. Avhengig av hvilken arbeidsoppgave man skal gjøre. Typisk så er resultatene ekstreme hvis det gjelder CPU-bruk. Mens hvis det gjelder å... Og skrive til filer og ting som systemet bruker en del tid på, så er ikke forskjellene så store. Her med Shellscript er det veldig mange systemkall som går med. Kjernen bruker mye tid. Ja. En kommentar til til resultatene i hastighet. Vi så f.eks. at Python bare var 40 ganger raskere enn Shell. Mens... C pluss, pluss var 40 000 ganger raskere. Så det er en veldig stor forskjell der. Til det må man si at hvis man skulle gjort noe tilsvarende i Python...", "source": "lecture"}
{"lecture_id": "linux9del6", "chunk_id": "linux9del6_0004", "start": 283.44, "end": 361.04, "token_count": 290, "text": "Ja. En kommentar til til resultatene i hastighet. Vi så f.eks. at Python bare var 40 ganger raskere enn Shell. Mens... C pluss, pluss var 40 000 ganger raskere. Så det er en veldig stor forskjell der. Til det må man si at hvis man skulle gjort noe tilsvarende i Python... Så finnes det en rekke biblioteker i Python, og de er ofte skrevet i C og C pluss, pluss. Så det betyr at hvis man har noen regneoppgaver i Python, så brukes ofte biblioteker som er mye raskere. Sånn at... Det er ikke sånn at Python alltid er ekstremt tregt, men med de rette bibliotekene så kan Python også være veldig effektiv. Og det er en stor fordel med Python, at det fins veldig mange biblioteker som man kan bruke til å løse de problemene man har. Uansett, hvis man går på en større programmeringsoppgave hvor effektivitet spiller en rolle, så kan det være verdt... Og ta en liten sjekk på forhånd før man velger programmeringsspråk.", "source": "lecture"}
{"lecture_id": "linux9del6", "chunk_id": "linux9del6_0005", "start": 341.82, "end": 374.96, "token_count": 129, "text": "som man kan bruke til å løse de problemene man har. Uansett, hvis man går på en større programmeringsoppgave hvor effektivitet spiller en rolle, så kan det være verdt... Og ta en liten sjekk på forhånd før man velger programmeringsspråk. Og se hvor effektivt programmeringsspråket er på akkurat den type oppgaver som programmet stort sett skal gjøre. Det er kanskje den viktigste lærdommen å ta med fra dette.", "source": "lecture"}
{"lecture_id": "linux10del4", "chunk_id": "linux10del4_0000", "start": 0.0, "end": 113.04, "token_count": 291, "text": "Grunnen til at det er et problem med privilegerte institusjoner, er at det finnes sensitive institusjoner som ikke er privilegerte. Det kan vi se her. For når vi har en virtuell maskin... Den kjører oppå en hypervisor. Og hypervisor, det er på en måte... Det vi har tenkt på som OS-tjernen tidligere. Den kjører i curlen mode. Og så kjører det en eller flere VM-er oppå Hypervisor. Og de vil da være prosesser, og de vil kjøre i use mode. Og da får man et problem. Hvis Gjeste-OS, som egentlig tror at det er et ekte operativsystem, som kjører på ordentlig hardware... Det vil de forvente, at når GjestOS gjør en privilegert institusjon, eller en sensitiv institusjon, som bare kan gjøres i curlen mode, så forventer GjestOS at det faktisk skjer noe. La oss si Gjest-OS utfører en popf for å skru av på et interrupt. OS-kjernen må jo ha lov til å gjøre det. Men hvis POPF da ikke er en sensitiv... Ops, feil vei. Hvis da POPF...", "source": "lecture"}
{"lecture_id": "linux10del4", "chunk_id": "linux10del4_0001", "start": 79.88, "end": 188.72, "token_count": 293, "text": "så forventer GjestOS at det faktisk skjer noe. La oss si Gjest-OS utfører en popf for å skru av på et interrupt. OS-kjernen må jo ha lov til å gjøre det. Men hvis POPF da ikke er en sensitiv... Ops, feil vei. Hvis da POPF... Det er en privilegert institusjon. Dvs. hvis POP utføres og ingenting skjer, så vil jo ikke dette gjestehuset her kunne fungere. Derfor er det tvingende nødvendig at alltid når man gjør en sensitiv institusjon her, en institusjon som bare kan gjøres i cernon vault, så må den trappe til hypervisor. Sånn at hypervisor kan behandle dette sånn som den bør. Da må Hypervisor finne ut at det er GjestOS som ønsker å fjerne interrups. Da fjerner Interrupts for GjestOS. Hvis det derimot var en brukerprosess som gjorde det, så vil Naso trappe. Men da vil Hypervisor avgjøre at nei, dette er en brukerprosess, den får ikke lov til det. Helt nødvendig for at virtualisering skal kunne gjennomføres på en effektiv måte.", "source": "lecture"}
{"lecture_id": "os1del14", "chunk_id": "os1del14_0000", "start": 0.0, "end": 111.0, "token_count": 298, "text": "Da skal vi bruke litt tid på å snakke om et veldig sentralt begrep, nemlig prosess. Hvis man leser diverse operativstemmebøker, som jeg har gjort, så finner man også diverse definisjoner på prosess. Det enkleste er bare at en prosess er et program som kjører. En annen er arbeidsoppgavene en prosessor gjør på et program. Litt mer spesifikt, men fortsatt relativt enkelt. En tredje som er litt mer å oppfatte, er at en prosess er delt inn i tre deler. For det første er det et kjørbart program. Men så er det også programmets data, variable filer osv. Men også den konteksten programmet er i, den tilstanden. For eksempel om... Oi, unnskyld. Om den venter på noe, eller om... Eller om den bruker CPU-en, eller... Hva er det problemet med lynet? Hva slags prioritet den har, hvilke prosessorregistre den bruker, osv. Selve tilstanden til prosessen. Og så så jeg også en enda mer... høytsvevende definisjon. Nemlig et programs ånd eller sjel. Og dette er...", "source": "lecture"}
{"lecture_id": "os1del14", "chunk_id": "os1del14_0001", "start": 78.84, "end": null, "token_count": 128, "text": "Hva er det problemet med lynet? Hva slags prioritet den har, hvilke prosessorregistre den bruker, osv. Selve tilstanden til prosessen. Og så så jeg også en enda mer... høytsvevende definisjon. Nemlig et programs ånd eller sjel. Og dette er... Når jeg så den definisjonen, så prøvde jeg å trekke dette litt lengre.  Så det jeg har prøvd å gjøre, er å lage en analogi til hva en prosess er.", "source": "lecture"}
{"lecture_id": "os4del16", "chunk_id": "os4del16_0000", "start": 0.0, "end": 117.96, "token_count": 299, "text": "Men vi har da gått denne lange veien for å... For å kunne se på hva som egentlig er innholdet i... I sumfunksjon. Så skal vi kanskje hoppe litt i... I fremstillingen her. Og så kan vi prøve å be kompilatoren om å lage... Såkalt assembly-kode. Og måten man gjør det på, er at man... I stedet for sånn som her... At jeg bruker minus C. Minus C sie, lag maskinkode av denne funksjonen. I stedet så kan jeg be GCC-kompulatoren om å lage assembly-kode. Så lages det en fil med assemblerkode som heter sumfunksjon.s. Og den ser vi. Den er ganske liten. Og vi kan se på den her... Hvordan... Hvordan ser den ut? Jo, den er ikke større enn dette her. Og her ser vi... Her begynner det å ligne på noe vi har sett. Her er det \"... Og dette her er såkalt assembly-kode. Og denne koden kan man skrive for hånd selv. Så tidligere i de tidligste datamaskinene var det veldig vanlig å skrive i assembly. I dag også så skriver man assembly i noen få tider.", "source": "lecture"}
{"lecture_id": "os4del16", "chunk_id": "os4del16_0001", "start": 90.0, "end": 197.72, "token_count": 293, "text": "Her er det \"... Og dette her er såkalt assembly-kode. Og denne koden kan man skrive for hånd selv. Så tidligere i de tidligste datamaskinene var det veldig vanlig å skrive i assembly. I dag også så skriver man assembly i noen få tider. Noen tilfeller hvor man ønsker å få ting til å gå veldig fort for å optimalisere. Men det har blitt mindre og mindre vanlig å skrive assembly. Kanskje litt vanligere for ARM, for der er det veldig viktig at ting er effektive. Mobile devices. Men... For det vi ser her, det er nå da assembly-versjonen av den maskinkoden som GCC vil lage hvis jeg legger på minus C i stedet for minus S. Så det jeg ba GCC om nå, var vis meg assembly-versjonen av den maskinkoden du vil lage. Og da ser vi at fra høynivåspråket så er det kompilatoren som da bestemmer nøyaktig Hvordan denne loopen skal være, osv. Og vi ser her, for eksempel, så har vi en jump less equal. Det er hopp hvis... Hvis de to tallene, altså tallet tre og dette her,", "source": "lecture"}
{"lecture_id": "os4del16", "chunk_id": "os4del16_0002", "start": 172.16, "end": 265.88, "token_count": 289, "text": "Og da ser vi at fra høynivåspråket så er det kompilatoren som da bestemmer nøyaktig Hvordan denne loopen skal være, osv. Og vi ser her, for eksempel, så har vi en jump less equal. Det er hopp hvis... Hvis de to tallene, altså tallet tre og dette her, som er en referanse til ram, hvis... Jeg tror det er sånn at hvis denne er mindre enn tre, så skal det hoppe. Metoden som kompulatoren har valgt for å få til å lage en løkke. Da skal vi hoppe til L3, og det er opp her igjen. Den utfører da akkurat den helt tilsvarende kode som vi lagde. Da skal vi se litt mer på den koden. Men før vi gjør det, så kan det være greit å kjenne litt mer til X86. Assembly, og hva de forskjellige tingene her... hva de gjør. Så det vi skal se på nå, er hvordan man skriver assembly-kode direkte. Men det som kan være greit å ta med videre, er denne konsesjonen her. Den ser litt rar ut. Og... dette er et register. Så...", "source": "lecture"}
{"lecture_id": "os4del16", "chunk_id": "os4del16_0003", "start": 240.0, "end": 333.06, "token_count": 296, "text": "Assembly, og hva de forskjellige tingene her... hva de gjør. Så det vi skal se på nå, er hvordan man skriver assembly-kode direkte. Men det som kan være greit å ta med videre, er denne konsesjonen her. Den ser litt rar ut. Og... dette er et register. Så... Denne konstruksjonen er en referanse til ram. Og det er en referanse til den adressen i ram som ligger da inn i dette registeret RBP. Så akkurat som i simuleringen. Hvis inni RBP ligger tallet 2, så er dette en referanse til byte nummer 2 i ram. Men så er det litt en sånn minus 4 her etter, og det betyr at... Det er egentlig ikke bite nummer to, men det er minus fire, så det blir da... Ja, la oss si RBP var åtte, da. Så blir denne adressen egentlig til bite nummer fire. For det er åtte minus fire. Du trekker fra fire bite. Eller du trekker fra adressen med fire bite. Og dette kan være... Det ser jo ganske gresk ut til å begynne med, men vi skal bruke litt tid på å se på assembly. Forstå hva som foregår.", "source": "lecture"}
{"lecture_id": "os4del16", "chunk_id": "os4del16_0004", "start": 310.88, "end": 398.68, "token_count": 292, "text": "For det er åtte minus fire. Du trekker fra fire bite. Eller du trekker fra adressen med fire bite. Og dette kan være... Det ser jo ganske gresk ut til å begynne med, men vi skal bruke litt tid på å se på assembly. Forstå hva som foregår. Det er også veldig nyttig senere, i andre sammenhenger, å kunne forstå hva assembly-koden er. Og så er dette på en måte linken fra transistorene og opp til høynivåkode. Så litt må vi forstå av registeret og hvordan de brukes. Når jeg snakker om registeret, og da ser vi EAX... Det er etter registeret. Sånn tradisjonelt i X86 så er det fire viktige registre. AX, BX, X og DX. Og E, det betyr at det er et 32-bitsregister. Og Move L, det betyr at vi skal flytte en long. Og en long det er da 32-bit. Så Movel, Adel og disse her, de opererer på 32-bit. Jeg skal skrive litt assemblykode, da skal vi bruke i stedet... Og det er en utvidet versjon. Det er 64-bits-registeret.", "source": "lecture"}
{"lecture_id": "os4del16", "chunk_id": "os4del16_0005", "start": 378.24, "end": 488.76, "token_count": 300, "text": "Og en long det er da 32-bit. Så Movel, Adel og disse her, de opererer på 32-bit. Jeg skal skrive litt assemblykode, da skal vi bruke i stedet... Og det er en utvidet versjon. Det er 64-bits-registeret. Men vi kan gå tilbake og så kan vi se litt på... Vi kan se litt på det som står i notatene om Assembly. Jeg har lagt inn et par referanser. Det er et company fra Erik Hjelmås som ligger i Canvas. Det inneholder litt om assembly. Og så er det masse referanser på nettet også, sånn som denne her. Så vi skal ikke gå veldig dypt i assembly-programmering. Enkle sammenhenger. Men det som er viktig å vite, er at nøyaktig som i den simulerte maskinen, så fins det assembly-institusjoner. Og det er ikke noe annet enn at i X86, når det finnes en institusjon MOVE, så har den bare et nummer i rekken. Det er en rekke institusjoner. Kanskje MOVE er institusjon nummer 24. Av en X86-maskin står tallet 24 der, og da er det kodet akkurat som i vår simulering.", "source": "lecture"}
{"lecture_id": "os4del16", "chunk_id": "os4del16_0006", "start": 462.28, "end": 561.5, "token_count": 296, "text": "Og det er ikke noe annet enn at i X86, når det finnes en institusjon MOVE, så har den bare et nummer i rekken. Det er en rekke institusjoner. Kanskje MOVE er institusjon nummer 24. Av en X86-maskin står tallet 24 der, og da er det kodet akkurat som i vår simulering. Tallet 24 betyr - legg sammen. Og så er det da en syntaks for alle instruksjoner, sånn som for Move. Så angir man... Man starter med en assemblelinje med Move, og så angir man Source og destination. Så Move... Hvis jeg da her skriver \".move ax til bx\", så betyr det rett og slett... Ta det som ligger i register ax, og legg i bx. Og så er assembly lagd av en masse sånne institusjoner som tilsvarer alle maskininstitusjoner. Så når maskinen er lagd, så definerer den alle institusjoner. Det betyr da... Hvis jeg så nå ad AXBX, så vil det bety... Legge sammen det som ligger i BX med AX, og lagre det i Destination, nemlig BX. Og tilsvarende for andre instruksjoner.", "source": "lecture"}
{"lecture_id": "os4del16", "chunk_id": "os4del16_0007", "start": 540.0, "end": 613.6, "token_count": 223, "text": "Det betyr da... Hvis jeg så nå ad AXBX, så vil det bety... Legge sammen det som ligger i BX med AX, og lagre det i Destination, nemlig BX. Og tilsvarende for andre instruksjoner. Det vi trenger for å gjøre akkurat den samme løkken som vi hadde i simuleringen, er disse instruksjonene. Compare, som er akkurat den samme som vi hadde i simuleringen. Sammenlign verdien av de to registrene. Og så etterpå har vi en jump not equal. Den finnes også i Exo 86. Og da jump not equal, den hopper da til den riktige linjen i... i programmet. Og da må vi ha med det. Så vet vi... Da vet vi omtrent hva som skal til for å skrive en sånn summeringsfunksjon. Så da kan vi prøve å gå inn og se på hvordan det ser ut.", "source": "lecture"}
{"lecture_id": "os9del7", "chunk_id": "os9del7_0000", "start": 0.0, "end": 66.0, "token_count": 163, "text": "Prioritet i Windows... På helt samme måte så kan man prioritere jobber i Windows. De har også dynamisk prioritet som endres på noe av den samme måten. Med admin-rettigheter, så hvis man har administrativ prioritet, så kan man endre prioriteten. Men man kan ikke gjøre det som vanlig bruker, som i Linux. Hvis man tester ut det, vil man se at det er veldig hard prioritering. Det er enorme forskjeller når du gjør disse prioritetene. Men på samme måte så vil Windows-kjernen dynamisk prioritere prosesser etter mye av de samme prinsippene. Hvorfor er det så vanskelig å forstå hverandre?", "source": "lecture"}
{"lecture_id": "os2del5", "chunk_id": "os2del5_0000", "start": 0.0, "end": 103.52, "token_count": 300, "text": "Så kommer hele poenget. Hvordan kan man bygge logiske porter ved hjelp av transistor? Som vi så på tidligere, så kan alle logiske operasjoner, de kan utføres hvis man har and or or not-porter. Så hvis vi kan bygge dem med de transistorene, så kan vi bygge hva som helst. Her ser vi et eksempel på hvordan man kan bygge en notport av to NMOS- og PMOS-transistorer. Det sitter en PMOS her. PMOS var den med en liten runding på. Og så sitter det en NMOS her nede. Her ser vi hele koblingsskjemaet. En notport, det vet vi har en sannhetstabell som dette her. Hvis det kommer en spenning null inn, så skal det komme spenning én ut. Det kan vi se at vi får til med disse transistorene. Hvis det kommer null her, hva skjer da? Da sendes det null spenning opp her til denne P-mossen her oppe. Da vil den virke. Den vil skru på bryteren. Og dermed kommer det en positiv spenning ut her. Samtidig, når det kommer en null inn her i NMOS-transistoren her nede,", "source": "lecture"}
{"lecture_id": "os2del5", "chunk_id": "os2del5_0001", "start": 78.12, "end": 160.48, "token_count": 294, "text": "Da sendes det null spenning opp her til denne P-mossen her oppe. Da vil den virke. Den vil skru på bryteren. Og dermed kommer det en positiv spenning ut her. Samtidig, når det kommer en null inn her i NMOS-transistoren her nede, så vil den stenge. Altså den stenger av denne her. Så hvis den ikke stengte av den, så ville det bli en spenningsforskjell, og det ville gå strøm gjennom. Og det er akkurat de spenningsforskjellene som man unngår, Når man bruker to transistorer, så gjør man at det momentant skifter. Hvis man bytter om fra 0 til 1 her, så skifter det momentant om fra 1 til 0. Og det går veldig lite strøm i kretsen. Og så tilsvarende, hvis vi nå switcher, og så setter på en spenning her. Så ser vi, der vil det gå en ener ned hit. Denne vil åpnes. Skru på den bryteren. Og du får en positiv spenning ut her. Tilsvarende en ener inn her vil lukke denne transistoren.", "source": "lecture"}
{"lecture_id": "os2del5", "chunk_id": "os2del5_0002", "start": 136.84, "end": 225.08, "token_count": 282, "text": "Og så tilsvarende, hvis vi nå switcher, og så setter på en spenning her. Så ser vi, der vil det gå en ener ned hit. Denne vil åpnes. Skru på den bryteren. Og du får en positiv spenning ut her. Tilsvarende en ener inn her vil lukke denne transistoren. Sånn at du ikke går strøm ut hit. Uansett så har vi nå laget en port som er sånn at... Kommer det null spenning inn, så går det én positiv spenning ut. Kommer det positiv spenning inn, så kommer det null spenning ut. Og dette er den aller minste byggescenen i en datamaskin. Ved hjelp av sånne brytere så kan man da bygge hva som helst. Det vil si, man kan ikke bygge hva som helst med en nattport. Man trenger også or og and. Og or og and er litt mer kompliserte. Begge to trenger... Da trenger man seks transistorer for å lage den riktige logikken. Her blir det litt mer infløkt. Men hvis man setter seg ned og ser på dette,", "source": "lecture"}
{"lecture_id": "os2del5", "chunk_id": "os2del5_0003", "start": 200.04, "end": 292.9, "token_count": 299, "text": "Man trenger også or og and. Og or og and er litt mer kompliserte. Begge to trenger... Da trenger man seks transistorer for å lage den riktige logikken. Her blir det litt mer infløkt. Men hvis man setter seg ned og ser på dette, så er det ganske enkelt å overbevise om alle mulighetene. A og B skal da være 0, 0, 0, 1, 0 og 1, 1. Så kan man se på hver av de. B er 0. Da stenges denne bryteren. Og hvis A er 1, så åpnes denne, osv. Og så kan man finne ut at den virker akkurat som den skal. Hvis det kommer 0-0 inn her, så kommer det 0 ut der. Hvis det kommer 0-1, hvis én av disse er 1, så vil det alltid komme én ut her som resultatet ku. Så ser vi da, med seks transistorer, så kan vi da bygge en sånn or-port fysisk. Og den blir da brent inn... Man lager transistorene, og så brenner man dette inn i små kretskort. Og så får man ut akkurat det man ønsker.", "source": "lecture"}
{"lecture_id": "os2del5", "chunk_id": "os2del5_0004", "start": 260.64, "end": 306.02, "token_count": 141, "text": "Hvis det kommer 0-1, hvis én av disse er 1, så vil det alltid komme én ut her som resultatet ku. Så ser vi da, med seks transistorer, så kan vi da bygge en sånn or-port fysisk. Og den blir da brent inn... Man lager transistorene, og så brenner man dette inn i små kretskort. Og så får man ut akkurat det man ønsker. Tilsvarende har man for ran-porten. At man får dens virkemåte ved å sette sammen... Som da gir en annen port.", "source": "lecture"}
{"lecture_id": "linux8del8", "chunk_id": "linux8del8_0000", "start": 0.0, "end": 127.48, "token_count": 294, "text": "Det som vi skal prøve å få til nå, som er problemstillingen, det er hvordan kan vi lage eller endre dockerfile sånn at Apache 2 starter direkte. Det kunne vært veldig nyttig. Så hvis jeg nå går ut her... Så ser vi da stoppet den filen. Nei, det imaget. Men så skal jeg gå inn i... Da er det... Det man kan gjøre, er å legge på en kommando. Da trenger man å legge på en kommando som starter apasje. Det kan jeg legge på her. CMD som får kommando. Hva heter det? Jason Syntax. For å få til dette her, så... Man kan ikke kjøre direkte den inn i Aparche 2 Start. Men det er en biner i Aparche som heter Aparche Kontroll. Den bineren kan man starte. Hvis man prøver å gjøre dette her... Det er fordi dette starter arrangementen en bakgrunnsjobb. For å få Apache til å starte, må den kjøres i foreground. Da er det en liten besvergelse man må legge til her. Og det er minus det foreground. Så det er en demon som da starter. Så skal det nå bygges en Aparche-container som starter direkte.", "source": "lecture"}
{"lecture_id": "linux8del8", "chunk_id": "linux8del8_0001", "start": 100.76, "end": 217.22, "token_count": 291, "text": "For å få Apache til å starte, må den kjøres i foreground. Da er det en liten besvergelse man må legge til her. Og det er minus det foreground. Så det er en demon som da starter. Så skal det nå bygges en Aparche-container som starter direkte. Så... da må jeg prøve en bilde igjen. Da vil jeg nok få en feilmelding om at den allerede er bygget. Nei, det får jeg ikke. Så vi så nå gikk det veldig fort å gjøre den endringen, for da var det bare den kommandoen der som ble endret. Så kan vi prøve å starte. Det er samme... Ja, det skulle funke, det. Så kan jeg se... Nei, jeg kan ikke se om den... Se at den kjører her. Det skulle jeg jo se her nede. Nei, det ser faktisk ut som den ikke har startet. Da var det tydeligvis noe som... ikke virket. Skal vi se... Det er ett spørsmål her. Kan man ha flere dokkerfiler i konteiner? Nei. I utgangspunktet så har man én dokkefil, og den bygger da én konteiner.", "source": "lecture"}
{"lecture_id": "linux8del8", "chunk_id": "linux8del8_0002", "start": 180.02, "end": 356.18, "token_count": 295, "text": "Da var det tydeligvis noe som... ikke virket. Skal vi se... Det er ett spørsmål her. Kan man ha flere dokkerfiler i konteiner? Nei. I utgangspunktet så har man én dokkefil, og den bygger da én konteiner. Men man kan jo starte flere instanser av den konteineren. Man har gjerne én dokkefil som definerer én konteiner. Men skal vi se. Hva var problemet her? Jo... Men den svarer ikke på port 8081. Så det betyr nok at Apache ikke kjører inn i konsernet. Da må vi gå tilbake til dokkefilmen. Og så se om jeg har fått... Syntaksen... helt riktig. Om man starter den interaktivt. Tanken er at man skal starte den i bakgrunnen. Og det gjør man med minus D. Sånn som det. Men her får jeg en melding om port is already allocated. Da skyldes det kanskje at jeg allerede... Oi. Ja, jeg glemte å stoppe den her, da. Da må jeg stoppe den først. Sånn. Så prøver jeg å starte konteineren i bakgrunnen.", "source": "lecture"}
{"lecture_id": "linux8del8", "chunk_id": "linux8del8_0003", "start": 316.2, "end": 398.18, "token_count": 206, "text": "Men her får jeg en melding om port is already allocated. Da skyldes det kanskje at jeg allerede... Oi. Ja, jeg glemte å stoppe den her, da. Da må jeg stoppe den først. Sånn. Så prøver jeg å starte konteineren i bakgrunnen. Da ser vi. Når jeg starter med minus D, så prøver jeg å starte conteineren i bakgrunnen. Nå får jeg ikke opp et skjell, for da har jeg ikke bedt om det. Da startes denne her i bakgrunnen. Og nå ser vi... Den er oppe og kjører. Og da ser vi også... Her nede... Nå virket det faktisk som det skulle. Nå startet den filmen... Imaget startet. Konteineren startet, og den startet da også automatisk webserveren.", "source": "lecture"}
{"lecture_id": "linux4del11", "chunk_id": "linux4del11_0000", "start": 0.0, "end": 106.4, "token_count": 286, "text": "Violed looker er en nyttig konstruksjon, og vi skal se på det nå. Jeg starter med et skript som heter Violet shell. Og violet-konstruksjonen ser sånn u. Violet do don. Og så skal alt som skjer, komme inni her. Da har man typisk en test her. Teste det ut ved å se på argumenter. Det man kan teste på da, er hvis antall argumenter er... Eller så lenge antall argumenter er større enn null, kan man teste. Da skulle man tro at man fortsetter å kjøre en loop hele veien. Det vi kan gjøre, er å gjøre en operasjon som flytter på argumentene. Vi skal se. La oss si jeg bare nå skriver ut for å se at jeg har orden på dette her. ARG, kolon, og som vanlig er argumentet i... Eller det vi skriver ut, er det første argumentet. Vi skriver ut ARG$1. Så gjør vi et triks. Vi gjør en operasjon. Skift. Operasjon Skift, den kaster ut det første argumentet og legger dollar to inn i dollar én. På den måten kan vi løpe gjennom argumenter med en wild locke.", "source": "lecture"}
{"lecture_id": "linux4del11", "chunk_id": "linux4del11_0001", "start": 79.98, "end": 176.3, "token_count": 291, "text": "Eller det vi skriver ut, er det første argumentet. Vi skriver ut ARG$1. Så gjør vi et triks. Vi gjør en operasjon. Skift. Operasjon Skift, den kaster ut det første argumentet og legger dollar to inn i dollar én. På den måten kan vi løpe gjennom argumenter med en wild locke. Så kan vi prøve å kjøre det skriptet med én og to... Nei, det var feil skript. Vi kjører det skriptet vi lager. Hva er det som skjer med to argumenter, én og to? Da ser vi at det løper gjennom argumentene. Så ved første runde så er, som vanlig, dollar én lik første argument. Men det skiftoperasjonen gjør, er at den gir en skift på alle variablene,  Dollar to blir... Vil inneholde tre. Og dollar én vil inneholde to. Så de to variablene skyves på en måte fremover i køen. Noen ganger så er dette faktisk en bedre måte å løpe gjennom variabler på. For vi så på den forrige Argdot Shell. Den fungerer fint her, men den får...", "source": "lecture"}
{"lecture_id": "linux4del11", "chunk_id": "linux4del11_0002", "start": 152.28, "end": 241.8, "token_count": 293, "text": "Dollar to blir... Vil inneholde tre. Og dollar én vil inneholde to. Så de to variablene skyves på en måte fremover i køen. Noen ganger så er dette faktisk en bedre måte å løpe gjennom variabler på. For vi så på den forrige Argdot Shell. Den fungerer fint her, men den får... Problemer hvis man har et argument som har space i seg, sånn som det. Da ser vi... Da gikk det ikke helt bra. Den teller antall argumenter. Men når Forløkka går gjennom én og to og to, så blir det sett på som to argumenter, og så får vi ut det. Derimot så vil... While... Den vil... Den ser at dette er to argumenter, og sier at andre argumentet er to-tre. Så i de litt spesielle tilfellene hvor man har med space i argumentene, så kan dette være en smart måte å løpe med argumenter på. Noen man kan bruke Wile til, er å lage en evig løkke. Kan f.eks. bare skrive én. Én vil returnere true. Det ville du godt. Man kan skrive sånn også for å være veldig eksplisitt.", "source": "lecture"}
{"lecture_id": "linux4del11", "chunk_id": "linux4del11_0003", "start": 219.24, "end": 315.92, "token_count": 290, "text": "så kan dette være en smart måte å løpe med argumenter på. Noen man kan bruke Wile til, er å lage en evig løkke. Kan f.eks. bare skrive én. Én vil returnere true. Det ville du godt. Man kan skrive sånn også for å være veldig eksplisitt. Så kan vi si OK... Når jeg kjører ned løkken, så kan jeg skrive ut et tall. Kanskje jeg skal ta... Øke med 1... I pluss, pluss... Med doble parenteser. Og så bare skrive ut I er lik... Tolv er i. Hvis jeg bare kjører den sånn, vil den bare rasende fort skrive ut verdier. Så jeg kan sove to sekunder. Og på den måten så kan jeg lage en wireløkke som skriver ut tall fortløpende. Det er en såkalt demon. Så hvis vi saver den nå og kjører den... uten argumenter... Så ser det sånn ut. Løkken går og går. Det blir jo en evig løkke helt til den... Helt til man stopper, da. Dette skriptet kan også brukes til å vise et par andre variabler", "source": "lecture"}
{"lecture_id": "linux4del11", "chunk_id": "linux4del11_0004", "start": 287.86, "end": 398.8, "token_count": 298, "text": "Så hvis vi saver den nå og kjører den... uten argumenter... Så ser det sånn ut. Løkken går og går. Det blir jo en evig løkke helt til den... Helt til man stopper, da. Dette skriptet kan også brukes til å vise et par andre variabler som vi kan skrive ut. Vi kan skrive ut... Navnet på skriptet. Script.dollar.0 har... Altså kan vi skrive ut payday-en. Dollar, dollar. Den gir ut payday-en. Så det fins mange den type dollarvariabler som er satt av systemet. Dette er to eksempler på det. Så hvis vi nå kjører scriptet, så ser vi at dollar.0 inneholder navnet på skriptet. Wild og Chell. Det er da prosess-ideen til skriptet. Kjører PSA her, så ser vi... Nei, vi ser det ikke her. Fordi dette er et annet skjell. Men vi kan greppe PSA-ox på Mile. Og da vil vi se at... Jo, her har jeg et PSA-skripte. Som da... Den skriver ut sin egen PD, som da ligger i dollar, dollar. Så kan jeg herfra prøve å kille det skriptet.", "source": "lecture"}
{"lecture_id": "linux4del11", "chunk_id": "linux4del11_0005", "start": 370.56, "end": 403.88, "token_count": 91, "text": "Fordi dette er et annet skjell. Men vi kan greppe PSA-ox på Mile. Og da vil vi se at... Jo, her har jeg et PSA-skripte. Som da... Den skriver ut sin egen PD, som da ligger i dollar, dollar. Så kan jeg herfra prøve å kille det skriptet. Sånn. Da ser vi det stopper.", "source": "lecture"}
{"lecture_id": "os11del8", "chunk_id": "os11del8_0000", "start": 0.0, "end": 113.96, "token_count": 290, "text": "Aller først før vi gjør det, så var det et spørsmål om hvordan å kopiere filer fra Windows til Studie-SSH. Da fins et par måter å gjøre det på. Det beste som vi kommer tilbake til etter påske når vi skal se på Windows, er å installere OpenSSH på Windows. Så kopierer man med SEP. Sånn som dette. Bare seprio.java eller tilsvarende på Studiesesong. Og så skriv passord. Så kopierer man... Så blir filen kopiert over direkte. Det er mulig å sette opp passordnøkler også. Da kan man få enda mer direkte over. Et alternativ er å installere VINN-SVP. Hvis man søker på VINN-SVP, så er det første siten man kommer til. Så kan man installere derfra. Og det er et gueprogram som ser ut som noe sånt som dette her. Hvor jeg da har logget meg inn på denne serveren, StudySSO i deres tilfelle. Og så kan man ta bare filer og kopiere frem og tilbake sånn som dette er. Ved å peke og klikke. Men fra kommandolinja så kan man gjøre dem som sagt med SP,", "source": "lecture"}
{"lecture_id": "os11del8", "chunk_id": "os11del8_0001", "start": 79.24, "end": 130.0, "token_count": 137, "text": "Så kan man installere derfra. Og det er et gueprogram som ser ut som noe sånt som dette her. Hvor jeg da har logget meg inn på denne serveren, StudySSO i deres tilfelle. Og så kan man ta bare filer og kopiere frem og tilbake sånn som dette er. Ved å peke og klikke. Men fra kommandolinja så kan man gjøre dem som sagt med SP, hvis man installerer åpen SSO på Windows. Installere tror man faktisk bare kan aktivere det, at det er en modul som kan aktiveres.", "source": "lecture"}
{"lecture_id": "os5del15", "chunk_id": "os5del15_0000", "start": 0.0, "end": 83.88, "token_count": 280, "text": "Pipelining. Jeg nevnte at en i instruksjonen... Deles opp i flere biter. Man klarer ikke å gjøre den på én klokkesyklus. Det er rett og slett for mange operasjoner som skal gjennomføres, så man har funnet ut at det er bedre å dele opp instruksjonene i små biter enn å ha en... Veldig lang syklus. Så i de aller første mikkelproseksjonene var det bare én syklus, sånn som i vår simulering. Så begynte man ganske snart med to sykler, altså fetch og execute. Først hente instruksjonen, og så utføre den. Etter hvert ble det en sånn standard som hadde de viktigste operasjonene. Det er instruksjonsdekoderen som da finner ut hvilke knapper man skal trykke på i Alu datapapp for å utføre den kommende instruksjonen. Og det må dekodes. Og så kommer execute. Det er virkelig å utføre instruksjonen. Hvis det er å legge sammen to tall, så skjer dette inni Alu.", "source": "lecture"}
{"lecture_id": "os5del15", "chunk_id": "os5del15_0001", "start": 60.0, "end": 144.16, "token_count": 283, "text": "Det er instruksjonsdekoderen som da finner ut hvilke knapper man skal trykke på i Alu datapapp for å utføre den kommende instruksjonen. Og det må dekodes. Og så kommer execute. Det er virkelig å utføre instruksjonen. Hvis det er å legge sammen to tall, så skjer dette inni Alu. Og så skrive resultatet deres om. Det er jo ikke alltid alle deler som utføres. Det er én måte å dele opp instruksjoner på. Men Moderne CPU-er har enda flere stages enn dette her. 14 stages, eller 14 deler, da, er vanlig. Og da deles da det som vi har tenkt på som én instruksjon, en ad f.eks., det deles da opp i 14 små biter. Så på en måte... Det er detaljer av den institusjonen som skal utføres. Og denne inndelingen gjøres for at alt skal gå fortere, og at man sparer tid. For det man kan gjøre når man har delt opp, når man har den type pipelining, det er at institusjonene kan gjøres samtidig.", "source": "lecture"}
{"lecture_id": "os5del15", "chunk_id": "os5del15_0002", "start": 120.0, "end": 202.58, "token_count": 272, "text": "Det er detaljer av den institusjonen som skal utføres. Og denne inndelingen gjøres for at alt skal gå fortere, og at man sparer tid. For det man kan gjøre når man har delt opp, når man har den type pipelining, det er at institusjonene kan gjøres samtidig. Altså det vi kan tenke hvis vi har fetch og execute. Hvis vi bare har to stages. Det utføres to stadier, er det vel på norsk. Så har vi første stadiet å hente institusjonen. Og andre er å utføre. Da kan vi tenke oss at når vi er i gang med å utføre den første institusjonen, så kan neste institusjon hentes av Fetch. For da slipper vi å vente på at den hentes. Det er det som er pipelining. Operasjoner samtidig. Så hvis vi har fire stadier, så kan vi tenke oss at uten pipelining, så er den første illustrert her. Den blå er en institusjon, den røde er en annen. Så går klokka bortover sånn. Så kan vi tenke oss...", "source": "lecture"}
{"lecture_id": "os5del15", "chunk_id": "os5del15_0003", "start": 180.0, "end": 265.32, "token_count": 296, "text": "Operasjoner samtidig. Så hvis vi har fire stadier, så kan vi tenke oss at uten pipelining, så er den første illustrert her. Den blå er en institusjon, den røde er en annen. Så går klokka bortover sånn. Så kan vi tenke oss... Da er vi sånn som i vår simulering, så gjør vi jo én institusjon på hvert klokkesyklus. En CPU som må ha fire sykler for å utføre en institusjon, så ser vi at den første fetch, decode, execute og så wright. Og så kommer neste institusjon, fetch, decode, execute og right. Men pipelining vil si at man gjør to operasjoner samtidig. Man begynner på den neste institusjonen før den første er ferdig. Da får vi denne rekkefølgen istedenfor åtteklokkesykler. Da henter vi først den første institusjonen, og så på neste syklus dekodes den første institusjonen. Men samtidig så hentes den neste, og så videre. Og det er opplagt at da går ting raskere. Ja, her ser vi noen sånne mikroarkitekturer for Intel.", "source": "lecture"}
{"lecture_id": "os5del15", "chunk_id": "os5del15_0004", "start": 240.0, "end": 314.98, "token_count": 209, "text": "Da henter vi først den første institusjonen, og så på neste syklus dekodes den første institusjonen. Men samtidig så hentes den neste, og så videre. Og det er opplagt at da går ting raskere. Ja, her ser vi noen sånne mikroarkitekturer for Intel. Som jeg sa, de aller første... 1986 var en av de første CPU-ene for PC-er. Da var det en pipeline med to stages. Så ser vi at den har økt en del oppover. Noen 54-knyttblader hadde enormt mange stages. Men så har man gått litt tilbake, og i de mer moderne er det 14 stages som er vanlige. Så dette er pipelining. Det gjør at vi gjør på en måte én og én institusjon, men at man tjuvstarter på neste institusjon før den første.", "source": "lecture"}
{"lecture_id": "linux11del10", "chunk_id": "linux11del10_0000", "start": 0.0, "end": 118.78, "token_count": 284, "text": "Variabler. Variabler defineres nesten på samme måte som et linoskjell. Hvis man husker et linoskjell, så gjør man noe sånn. Men det fungerer ikke. Da tror Pårskjell at det er en kommando. Derimot må man alltid bruke en dollar foran variabellovene. Og i tillegg så må man... Så fungerer det ikke uten avførselsstein. Så på den måten så kan man lage varabler. Men det spiller ingen rolle om man har mellomrom eller ikke. Man kan lage varabler på den måten. Så kan jeg skrive ut verdien av varablen. Men som nevnt så kan man også droppe ekko hvis man bare skriver variabelnavnet. Så får man ut verdi. Men det ligner da veldig på... på Linux. Hvis man skal finne alle variabler som er definert, så kan man kjøre command get variable. Da får vi en rekke variater som er definert. Og en av dem er f.eks.... home. Så hvis jeg bare skriver... home, så får jeg ut den hver dag. Eller Ekko home, som vi gjør nylig.", "source": "lecture"}
{"lecture_id": "linux11del10", "chunk_id": "linux11del10_0001", "start": 79.0, "end": 177.9, "token_count": 212, "text": "Hvis man skal finne alle variabler som er definert, så kan man kjøre command get variable. Da får vi en rekke variater som er definert. Og en av dem er f.eks.... home. Så hvis jeg bare skriver... home, så får jeg ut den hver dag. Eller Ekko home, som vi gjør nylig. Environment-variabler, og de kan man få ut ved å taste LSN. Det er en rekke variabler som er definert som environment-variabler. Da ser vi forut bl.a. en del... Eller en del andre variabler. Som f.eks. path. Og da... For å kunne skrive path... Vi kunne jo tenke oss at vi kunne skrive det sånn, men det fungerer ikke. Når det er en environment-varabel, så må vi legge på n-en foran. Så n-path, det gir path-varabelen tilsvarende som i Linux.", "source": "lecture"}
{"lecture_id": "linux5del6", "chunk_id": "linux5del6_0000", "start": 0.0, "end": 93.22, "token_count": 276, "text": "I Linux Shellscript og i kommandolinjen, så trenger man ofte å kunne plukke ut deler av en streng. Og da er kommandoen cut nyttig å bruke. Så hvis man f.eks. har en streng abc, sånn som den her, så kan man prøve å plukke ut... La oss si andre element. Da skal man prøve å plukke ut b. Men her ser vi... Her skjer ikke dette. Og det er fordi til folk så splitter cut opp på tab, altså tabulator. Og det er det ikke så ofte man har. Så som oftest må man angi hva man ønsker å få cut til å splitte opp på. Og her ønsker vi et mellomrom. En skillelinje mellom elementene. Hvis jeg gjør det, ser vi at det plukkes element to ut. Eller hvis jeg tar element én, så får jeg et annet. Ofte så kan man bruke Cut til å gå gjennom en tabell og så plukke ut det man ønsker. Man kan f.eks. bruke Head til å ta ut de første elementene av ads password. Dette er de tre første linjene.", "source": "lecture"}
{"lecture_id": "linux5del6", "chunk_id": "linux5del6_0001", "start": 67.8, "end": 167.4, "token_count": 294, "text": "Eller hvis jeg tar element én, så får jeg et annet. Ofte så kan man bruke Cut til å gå gjennom en tabell og så plukke ut det man ønsker. Man kan f.eks. bruke Head til å ta ut de første elementene av ads password. Dette er de tre første linjene. Og la oss si jeg nå ønsker å plukke ut UiD, som er det tredje elementet. Da kan jeg gjøre det ved å sende til Cut. Og så må jeg se her er tabellen splittet opp på kolon. Og så ønsker jeg element nummer tre. Da ser vi. Da får vi ut 012, som er... Element nummer tre. La oss si jeg vil ta ut element nummer én. Det fungerer faktisk utenmellom her. Da plukker jeg ut det første elementet. Og så kan jeg også gå videre. La oss si... Av det første elementet så ønsker jeg å plukke ut den første bokstaven. R, D, B. Da kan jeg legge på... En cut med opsjon minus C. Den plukker ut characters, enkelttegn. Her ser vi jeg har plukket ut det aller første tegnet. Dette kan man bruke i oppgaver.", "source": "lecture"}
{"lecture_id": "linux5del6", "chunk_id": "linux5del6_0002", "start": 140.6, "end": 197.2, "token_count": 166, "text": "Av det første elementet så ønsker jeg å plukke ut den første bokstaven. R, D, B. Da kan jeg legge på... En cut med opsjon minus C. Den plukker ut characters, enkelttegn. Her ser vi jeg har plukket ut det aller første tegnet. Dette kan man bruke i oppgaver. Så er det en oppgave hvor man skal plukke ut en streng og se om den begynner med path. Da kan man bruke cut minus C igjen. Og tegn 1 til 3. Da var det de tre første. Det kan jeg også gjøre sånn. Bare si alle tegn fra starten av og til tegn nummer 3.", "source": "lecture"}
{"lecture_id": "os3del2", "chunk_id": "os3del2_0000", "start": 0.0, "end": 93.56, "token_count": 297, "text": "I dag så skal vi, som det står her, se på vipper og registeret. Det er altså hvordan lagre bits i en CPU. Så skal vi se på CPU-arkitektur. Og det som egentlig er ganske fantastisk, er at vi skal bygge... Vi skal ikke bygge, men vi skal se på hele arkitekturen til en CPU. Hvordan den virker helt fra transistornivå og... Og oppover! Det betyr at vi skal være i stand til å implementere høynivåkode. Det vi implementerer, er en liten fåløkke. Men i prinsippet så gjelder akkurat det samme for all mulig kode. Så all mulig kode kan i prinsippet implementeres på den simuleringen vi har. Tema fra digitale forelesninger i forrige uke, som da ukens oppgaver handler om. Det er litt diverse Linux-kommandoer. Også noen små sånne triks for å jobbe raskere i skjellet. Det er det viktig å få med seg. Kan se kjapt på de òg. Her er det tidsbesvarende triks i et Linux-skjell. For å kunne jobbe litt raskere og mer effektivt.", "source": "lecture"}
{"lecture_id": "os3del2", "chunk_id": "os3del2_0001", "start": 68.66, "end": 148.86, "token_count": 299, "text": "Det er litt diverse Linux-kommandoer. Også noen små sånne triks for å jobbe raskere i skjellet. Det er det viktig å få med seg. Kan se kjapt på de òg. Her er det tidsbesvarende triks i et Linux-skjell. For å kunne jobbe litt raskere og mer effektivt. Så er det litt diverse... rundt Linux-skjellet. Mye filbehandling. Litt om orientering osv. Og så er det ett punkt som er viktig her, og det med filrettigheter. Det er det viktig å kunne sette på et Linux-system. Som vanlig så la jeg på onsdag ut diverse demoer rundt disse temaene. Så her kan dere jobbe som dere vil. Enten kan dere gå inn og se på demoene først, og så gjøre oppgaver, eller så kan dere kanskje starte på oppgavene. Hvis dere står fast, så kan dere gå tilbake og se hvordan jeg gjør det her. Men det aller viktigste er at dere faktisk gjør disse oppgavene, og får til det praktiske. For dette er stoff som du trenger å øve og prøve og feile litt for å få det inn i fingeren.", "source": "lecture"}
{"lecture_id": "linux2del6", "chunk_id": "linux2del6_0000", "start": 0.0, "end": 88.9, "token_count": 286, "text": "Jeg skal nå se litt mer på det å slette mapper og filer. Så hvis vi tar utgangspunkt i det filset vi har her, så kan vi f.eks. prøve å slette mappen dir1 med kommandoen rmdir. Men det får vi ikke lov til, for den mappen er ikke tom. Så rmdir kan bare brukes til å slette tomme mapper. F.eks. så kan jeg... Jeg skal slette mappen Katt med rmdir. Den blir borte. Hvis jeg skal slette alt under... eller dir1 med alt innhold, så må jeg bruke rm minus r. Dir1. Sånn som det. Hvis jeg gjør det, så blir alt slettet. Så kan jeg jo da slette også enkelte filer. Hvis jeg f.eks. går inn... Her ligger det en fil.taxe. Da kan jeg ta RM på den. Så kan jeg også legge til minus I som en opsjon på RM, som da spør om du er sikker på at du skal slette den. Og da må jeg svare ja hvis jeg skal få slettet den. Ja... Noen andre kommandoer som er nyttig å kunne, det er... Ja, for det første...", "source": "lecture"}
{"lecture_id": "linux2del6", "chunk_id": "linux2del6_0001", "start": 65.86, "end": 160.12, "token_count": 289, "text": "Så kan jeg også legge til minus I som en opsjon på RM, som da spør om du er sikker på at du skal slette den. Og da må jeg svare ja hvis jeg skal få slettet den. Ja... Noen andre kommandoer som er nyttig å kunne, det er... Ja, for det første... Da er det nyttig å kunne finne filer. Og det finnes en kommando som heter locate, som finner filer på hele systemet. Her finner den alle filer som heter fil.takec. Hvis jeg f.eks. prøver å finne et password, som jeg vet finnes på systemet, så ser vi at den leter også overalt. Og databasen er ganske rask, Skal vi se. Men la meg lage en fil under dir2, som heter fil.txc. Så kan jeg prøve å finne den. En annen kommando for å finne, det er find. Den fungerer uavhengig av den locate-databasen. Så den bruker ganske mye tid, for den leter da etter rekkertskifte. Men jeg kan f.eks. si finn i dir.2, og så ønsker jeg å finne navnet fil.taxe.", "source": "lecture"}
{"lecture_id": "linux2del6", "chunk_id": "linux2del6_0002", "start": 140.92, "end": 233.9, "token_count": 293, "text": "Den fungerer uavhengig av den locate-databasen. Så den bruker ganske mye tid, for den leter da etter rekkertskifte. Men jeg kan f.eks. si finn i dir.2, og så ønsker jeg å finne navnet fil.taxe. Da ser du at jeg finner den. Mer vanlig er kanskje å si finn. Altså finn her og under denne filen. Noe som også nyttig er å legge på en stjerne for å finne alle filer som har filer. Hva er noe med.il. f.eks.? Da finner jeg også denne, siden her står det.il. på den måten. En generell nyttekommando, det er grep. Og det kan vi bruke for å finne... For eksempel... La oss si jeg ønsker å finne alle brukernavnene som har strengen 1234 i mappen... Nei, i filen. Det kan jeg gjøre sånn med grep. Det var ingen, men hvis jeg prøver med 123, så ser vi at der var det straks ganske mange. Og det vil si grep 123, den vil da finne alle linjer med forekomsten 123 i filen hetsepassord.", "source": "lecture"}
{"lecture_id": "linux2del6", "chunk_id": "linux2del6_0003", "start": 205.24, "end": 296.6, "token_count": 275, "text": "som har strengen 1234 i mappen... Nei, i filen. Det kan jeg gjøre sånn med grep. Det var ingen, men hvis jeg prøver med 123, så ser vi at der var det straks ganske mange. Og det vil si grep 123, den vil da finne alle linjer med forekomsten 123 i filen hetsepassord. En annen ting som er nyttig, er å kunne telle. Hvis jeg ønsker å telle antall linjer i ett passord, så kan jeg gjøre det sånn med Word count, dobbelt c, minus l. Den gir linjene. Hvis jeg ikke har med minus l, så vil du se at den også teller ord og tegn. Så dette betyr at det er 4830 linjer i ett passord. Det kan være nyttig å kunne kombinere denne type kommandoer. Hvis jeg først tar grep 123, så så vi at det var ganske mange linjer der. Hvis jeg ønsker å telle det, så kan jeg pipe og sende det til WC min selv. Da teller jeg 30 linjer i 1C-passord som inneholder tegnene 123.", "source": "lecture"}
{"lecture_id": "os2del13", "chunk_id": "os2del13_0000", "start": 0.0, "end": 49.02, "token_count": 114, "text": "Er det slik at den siste kretsen er en forenkling av den foregående, siden begge kunne forenkles til F eller B? I forhold til den vi antar spørsmålet er, gjelder denne... Denne kretsen.Og den forenkler seg også. Men det er egentlig mer tilfeldig. Altså det er ikke... Det er en forskjellig krets, men den... Tilfeldigvis forenkles den til den samme verdien.", "source": "lecture"}
{"lecture_id": "os7del3", "chunk_id": "os7del3_0000", "start": 0.0, "end": 129.7, "token_count": 295, "text": "Ja... Det er noen spørsmål i chatten her. Fungerer ikke for meg med å taste F. Topp oppdaterer seg ikke. Hva kan være årsaken? Det er litt vanskelig å si. Men hvis man prøver å kjøre dette her på Linux-VM-en, f.eks.... Så skulle det gå. Vi kan... Vi kan prøve. Hvis jeg nå går inn som... Group 99 at OS... Nei, jeg er ikke 99. 100 er jeg. Group 100. Hvis jeg taster F der, så ser det ut som det... Så ser det ut som det fungerer. Selv om jeg nå ikke ser... ... Last used CPU... Jo, den var her.  Og... ja. Og her ser vi at det er mange CPU-er. 48 står det her. Den har faktisk 42... eller 92? 96 CPU-er. Men hver container får ikke full tilgang til CPU-ene. Det skal vi se på litt senere. Men opplegget er det samme. Her er det dockercontainere. Så det er et nivå til. Så de kan fordeles CPU-tid av docker engine, som styrer disse containerne. Men iallfall... Det ser ut som på VM-en så kan man taste F og så få opp...", "source": "lecture"}
{"lecture_id": "os2del1", "chunk_id": "os2del1_0000", "start": 0.0, "end": 101.44, "token_count": 300, "text": "Sånn. Og da ser vi... Vi er nå i uke to, tirsdag 12. Og det vi skal snakke om i dag, er transistorer, porter og en krets som av dere er tall. Så når dere ser her hvor det står F, så er det forelesninger, sånn som nå, live. Mens for det andre temaet denne uken... Hver uke er det første tema. Og det andre er mer hands on, praktisk. Mye i starten er Linux og Kommandoer. Her står den D for digital, så her er det digitale forelesninger som er spilt inn på forhånd. Den digitale forelesningen fra forrige uke, som jeg la ut stort sett på onsdag, Temaet derfra er det oppgaver om denne uken. Som dere ser, så har jeg også lagt ut oppgaver til uke tre. Så de som ligger litt foran, de kan se på det nye temaet fra onsdag 13.11, med Linux filsystemer osv., og gjøre oppgaver fra uke tre. Og da kommer jeg til å legge ut noen tilsvarende opptak hvor jeg diskuterer... ... ja, i løpet av denne halvdagen. Du kan bare se kjapt hvordan det ser ut.", "source": "lecture"}
{"lecture_id": "os2del1", "chunk_id": "os2del1_0001", "start": 71.36, "end": 166.78, "token_count": 294, "text": "Så de som ligger litt foran, de kan se på det nye temaet fra onsdag 13.11, med Linux filsystemer osv., og gjøre oppgaver fra uke tre. Og da kommer jeg til å legge ut noen tilsvarende opptak hvor jeg diskuterer... ... ja, i løpet av denne halvdagen. Du kan bare se kjapt hvordan det ser ut. Hvis man går inn på de de-forelesningene, så er det notater der. Litt mer utfyllende enn slides. Og så har jeg da lagd noen små demoer... F.eks. av hvordan man flytter seg ut i Linux' kildesystem. Sånn er tanken, at dere skal kunne gå inn og se på det dere ønsker. Det som er fint med at dere har alt direkte, alt er jo... Det kan bli mye frihetsgrader, men da har dere mulighet til å jobbe litt sånn som dere selv syns er best. Se gjennom alt på en gang, eller så kan dere begynne å jobbe med oppgavene. Hvis alt går greit, så går det greit. Spesielt i den praktiske delen er det snakk om å få det inn i fingrene og øve på det og få det til.", "source": "lecture"}
{"lecture_id": "os2del1", "chunk_id": "os2del1_0002", "start": 147.56, "end": 226.3, "token_count": 280, "text": "litt sånn som dere selv syns er best. Se gjennom alt på en gang, eller så kan dere begynne å jobbe med oppgavene. Hvis alt går greit, så går det greit. Spesielt i den praktiske delen er det snakk om å få det inn i fingrene og øve på det og få det til. Du må ikke se alle videoene for å få det til. En måte å jobbe på kan være å prøve å jobbe med oppgavene. Hvis dere står fast, så kan dere gå inn og se en video eller lese en slide. Les dere opp på akkurat det, og så gå tilbake til oppgavene. Så vil dere også se... Jo, på denne... Nei, litt frem og tilbake her. På den digitale forelesningen så ser vi også at jeg har... Siste demon her er litt om oppgavene til denne uken, altså i uke to. Da kan det være lurt å prøve på oppgaven først, hvis dere står fast og ikke skjønner helt hva jeg mener. Så kan dere prøve å gå inn der og se på en mer detaljert forklaring.", "source": "lecture"}
{"lecture_id": "os2del1", "chunk_id": "os2del1_0003", "start": 206.74, "end": 252.68, "token_count": 167, "text": "til denne uken, altså i uke to. Da kan det være lurt å prøve på oppgaven først, hvis dere står fast og ikke skjønner helt hva jeg mener. Så kan dere prøve å gå inn der og se på en mer detaljert forklaring. Ja, det er én kommentar om at det er gode videoer, og det er jo kjempebra. Takk for den tilbakemeldingen. Og kom gjerne med andre tips. Gi tilbakemeldinger også hvis det er noe som mangler eller noe dere ikke forstår eller et eller annet med videoene som ikke er bra, lyd, bilde, hva som helst. Så gi tilbakemelding.", "source": "lecture"}
{"lecture_id": "os14del3", "chunk_id": "os14del3_0000", "start": 0.0, "end": 88.44, "token_count": 284, "text": "Der. Dynamisk allokering. Som dere sikkert har prøvd selv, så kan man be om mer ram mens man kjører et program. Altså, man kan deklarere alt som er av variabler og så videre, i starten av programmet, og så bare bruke det. Men man kan også, sånn som Java... Og ha statements om dette her. PCB er en ny prosess, midt inn i programmet. Og da vet jo ikke operativsystemet eller noen andre om at dette her kommer til å skje. F.eks. så kan man gi input underveis til et RA hvor langt det skal være. Og da må det lages underfly. Altså man må... Det må sette seg plass i minnet. Og det er da... Da er det veldig fint å ha paging. Da kan operativselskapet sette av nye sider til denne prosessen dynamisk. Og da får prosessen, når den gjør noe sånt som dette, så får den page for page med minne. Det kan jo være en sånn... Det kan jo være... Dette krever mange megabyte med minne. Og lag et nytt objekt. Så... Men da får prosessen tildelt så mye.", "source": "lecture"}
{"lecture_id": "os14del3", "chunk_id": "os14del3_0001", "start": 67.56, "end": 149.98, "token_count": 299, "text": "Og da får prosessen, når den gjør noe sånt som dette, så får den page for page med minne. Det kan jo være en sånn... Det kan jo være... Dette krever mange megabyte med minne. Og lag et nytt objekt. Så... Men da får prosessen tildelt så mye. I Cs C pluss pluss så må man... Når man allokerer minnet på denne måten... Vi skal se et seeksempel etterpå. Så må man etterpå slette sånne objekter som er i bruk. Hvis man hele tiden allokerer mer og mer minne uten å frigjøre det, så får man det som man kaller en minnelekkasje. Det er et sånt vanlig program. Et vanlig problem i programmering, altså i store servere osv.... Det er et eller annet som gjør at når du kjører programmet lenger og lenger, så bruker det mer og mer minne, og så går det tregere og tregere. Og det er en typisk minnelekkasje. Det vil bare si at man allokerer mer og mer minne som ikke blir frigjort. Så programmereren må sørge for at man frigjør minne hele tiden.", "source": "lecture"}
{"lecture_id": "os14del3", "chunk_id": "os14del3_0002", "start": 131.72, "end": 216.2, "token_count": 298, "text": "så bruker det mer og mer minne, og så går det tregere og tregere. Og det er en typisk minnelekkasje. Det vil bare si at man allokerer mer og mer minne som ikke blir frigjort. Så programmereren må sørge for at man frigjør minne hele tiden. Det er en av de store fordelene med mange moderne... Med mange nyere programmeringsspråk, sånn som Java. Dere tenker kanskje ikke på Java. Supernytt. Men i forhold til COC++, så er det relativt nytt. Og det utfører da denne oppryddingen automatisk. Såkalt garbage collection, som skjer hele tiden bak kulissene. Så hvis dere har et RAI eller noen objekter som ikke brukes lenger, så fjernes det fra minnet, sånn at minnet blir frigjort til andre programmer eller andre variabler i samme program. Den delen av ramm som kan øke og minke i størrelse, det kalles heap. Vi så forrige gang et minnekart i Linux, der dere hadde én del som var heapen. Det er her... Legges alt som er av RY og sånn, som øker og minsker i størrelse.", "source": "lecture"}
{"lecture_id": "os14del3", "chunk_id": "os14del3_0003", "start": 194.62, "end": 238.0, "token_count": 133, "text": "Den delen av ramm som kan øke og minke i størrelse, det kalles heap. Vi så forrige gang et minnekart i Linux, der dere hadde én del som var heapen. Det er her... Legges alt som er av RY og sånn, som øker og minsker i størrelse. Mens vi har stacken også. Den inneholder f.eks. alt som har med å hoppe til og fra metoder å gjøre. Så det er litt sånn organisering i... En organisering av ramm som operativstemme sørger for.", "source": "lecture"}
{"lecture_id": "linux5del13", "chunk_id": "linux5del13_0000", "start": 0.0, "end": 117.98, "token_count": 293, "text": "Vi skal se på assosiative ri, som er ri som er indeksert med tekststrenger i stedet for tall med vanlige ri. Og for å bruke assosiative ri, så må vi deklarere dem. Så de deklarerer vi på følgende måte, declare, minus a, og så navnet på ri. Nå vil jeg ha et rr-e som heter mann. Og dette rr-et skal da definere f.eks. hvem som er mannen til Eva. Det er da typisk Adam. Kan man f.eks. ha mannen til Kari er Per, osv. Så kan man også ha strenger som inneholder mellomrom, f.eks. mann til kun Kari på den måten. Da må man bruke apostrofer. Det kan f.eks. være Per Olav som er mannen til Kari. Sånn. Av et terrøy, altså av mann, så kunne man tenke seg at man kunne skrive det sånn. Mann av Eva. Men det fungerer ikke helt. Igjen, assosiativære har kommet i ettertid. Så igjen må man bruke denne konstruksjonen for å få ut mann av Eva. Og også... Man skriver nå Gunn Karison. Så fungerer det faktisk.", "source": "lecture"}
{"lecture_id": "linux5del13", "chunk_id": "linux5del13_0001", "start": 90.92, "end": 198.64, "token_count": 288, "text": "at man kunne skrive det sånn. Mann av Eva. Men det fungerer ikke helt. Igjen, assosiativære har kommet i ettertid. Så igjen må man bruke denne konstruksjonen for å få ut mann av Eva. Og også... Man skriver nå Gunn Karison. Så fungerer det faktisk. Men det fungerer uten å ha anførsel til Per Olav i begge tilfellene. Så har man da igjen de vanlige konstruksjonene med at hvis man skriver mann av alfakrønn på den måten, så får man ut alle... Så får man ut alle verdiene. Det er som vanlig Røy. Alle verdiene og alle indeksene får man også, som for vanlig Røy, med et utropstegn foran. Da er verdiene Kari, Eva og Gunn Kari. Men dette er da ett element. Så kan man også se på antall. Som er hashtag mann. Og da ser vi at dette er tre elementer. Vi kan teste ved å løpe gjennom alle elementene. Så kan vi se om vi får ut en riktig forløper. For da vil man løpe gjennom i form av rabbel i, inn...", "source": "lecture"}
{"lecture_id": "linux5del13", "chunk_id": "linux5del13_0002", "start": 170.8, "end": 292.94, "token_count": 298, "text": "Så kan man også se på antall. Som er hashtag mann. Og da ser vi at dette er tre elementer. Vi kan teste ved å løpe gjennom alle elementene. Så kan vi se om vi får ut en riktig forløper. For da vil man løpe gjennom i form av rabbel i, inn... Og så ønsker vi da å løpe gjennom... Disse, det er indeksene. For alle disse indeksene, så kan vi f.eks. skrive ut mannen til... Og så må vi da ha... Jo, mannen til I er da... Og mannen til I vil være denne. Sånn. Og på den måten så ser vi at vi løper gjennom alle indeksene. Det vil si nesten... Den... Det her fungerte ikke helt. Og det vi må gjøre da, er at vi må sette... Oi. Inn den vi løper gjennom. Da fungerer det som vi skal, for da kommer Gunn og Kari. Det kommer som ett enkeltelement, siden det settes i anfølgelsestegn. Hvis man ikke gjør det, så ser vi at Gunn og Kari får bli to elementer i forløkken. Så det er viktig å ta med de anfølgelsestegnene.", "source": "lecture"}
{"lecture_id": "linux5del13", "chunk_id": "linux5del13_0003", "start": 265.02, "end": 299.36, "token_count": 101, "text": "Da fungerer det som vi skal, for da kommer Gunn og Kari. Det kommer som ett enkeltelement, siden det settes i anfølgelsestegn. Hvis man ikke gjør det, så ser vi at Gunn og Kari får bli to elementer i forløkken. Så det er viktig å ta med de anfølgelsestegnene. Løpe gjennom en løkke på den nå.", "source": "lecture"}
{"lecture_id": "os9del9", "chunk_id": "os9del9_0000", "start": 0.0, "end": 57.88, "token_count": 141, "text": "Vi så et par nye sheddling-begreper. En queuer er den delen av scheduleren som legger i kø, og beregner prioriteten skal få dynamisk. Dispatcher er den delen som velger prosesser fra redelist. Den velger ut hvilken av de som skal kjøre. Det kan være en ganske komplisert affære. Det gjorde altså at den 2.6-kjerneskeduleren som vi har sett på, ble oppgradert til en scheduler som heter Completely Fair Scheduler. Så her skjer det hele tiden utvikling for å få bedre og bedre schedulere.", "source": "lecture"}
{"lecture_id": "os12del10", "chunk_id": "os12del10_0000", "start": 0.0, "end": 118.2, "token_count": 292, "text": "Vi kan raskt se på hva vi gjorde forrige gang. Først og fremst hadde vi ett program, eller to program, 3d.c, som en rekke ganger, ti millioner ganger allerede... Hundre millioner ganger. Så utfører det én linje. Den én-linje-operasjonen. Det eneste den gjør, er at den øker verdien på en fellesvariabel-svar med én. Og i dette Main-programmet så ser vi at vi har to tråder. Og de to trådene, de utfører den INK-operasjonen. 100 mill. ganger øke trådverdien med én. Og det man skulle tro da, det var at... Denne tråden, eller de to trådene, til slutt da skulle få den feltsvariabelen til å være 200 mill. Men vi kan se hvordan det ser ut. Hvis vi kompilerer... 30 og c sammen med e. Og så kjører vi ADOT-out. Så ser vi at... Og dette så vi forrige gang. Resultatet blir aldri 200 000, sånn som vi ønsket det skulle bli. Og da... Det vi gjorde da, var at vi...", "source": "lecture"}
{"lecture_id": "os12del10", "chunk_id": "os12del10_0001", "start": 83.78, "end": 194.24, "token_count": 291, "text": "Hvis vi kompilerer... 30 og c sammen med e. Og så kjører vi ADOT-out. Så ser vi at... Og dette så vi forrige gang. Resultatet blir aldri 200 000, sånn som vi ønsket det skulle bli. Og da... Det vi gjorde da, var at vi... Jo, vi var... For det første så var vi ikke sikre på om denne institusjonen ble utført bare som én linje. Fordi det var jo en sånn svar pluss, pluss. Så det kunne føre til flere linjer. Så for å være helt sikker på det, Kompilerte vi 3d.c sammen med denne assembly-linjen... Det er denne assembly-koden som bare øker... Hvor du har én linje som øker svar med én. Så hvis vi gjør det om igjen... Kompilerer den sammen med min Moldates... Så så vi fortsatt at likevel... Så ble svaret forskjellig hver gang. Men det er da vi kan komme inn med en... Med instruksjon lokk. Denne instruksjonen låser minnebussen, sånn at neste gang så er det kun én tråd som kan endre på den verdien.", "source": "lecture"}
{"lecture_id": "os12del10", "chunk_id": "os12del10_0002", "start": 168.36, "end": 262.4, "token_count": 283, "text": "Så så vi fortsatt at likevel... Så ble svaret forskjellig hver gang. Men det er da vi kan komme inn med en... Med instruksjon lokk. Denne instruksjonen låser minnebussen, sånn at neste gang så er det kun én tråd som kan endre på den verdien. Så hvis vi da kompilerer den på nytt og kjører... Så ser vi nå så tar det litt lengre tid. Det foregår noe synkronisering, og minnebussen blir låst. Men heldigvis så blir svaret riktig hver eneste dag. Men... Det vi da ikke så på sist, vare hva skjer om vi kjører dette her på...  Jo, vi så også på det sist. Hva skjer om vi setter disse her på samme CPU? Tasset minus 0, den gjør nå at begge må kjøre på samme CPU. Og da ser vi... Jo, det fungerer fortsatt som det skal, selv om de kjører på samme CPU. Selv om det da kan komme en konflikt-switch. Og det at vi kjører på samme CPU, det kan vi også se med... Hvis det tar tid...", "source": "lecture"}
{"lecture_id": "os12del10", "chunk_id": "os12del10_0003", "start": 244.64, "end": 358.44, "token_count": 286, "text": "Og da ser vi... Jo, det fungerer fortsatt som det skal, selv om de kjører på samme CPU. Selv om det da kan komme en konflikt-switch. Og det at vi kjører på samme CPU, det kan vi også se med... Hvis det tar tid... Hvis det tar tid når de kjører på hver sin CPU, så ser vi her... Her er det 189 % CPU-tid. Og det er et tydelig tegn på at jo, de kjører faktisk på hver sin CPU. Mens når jeg kjører Tasset, når jeg setter dem med Tasset, så ser vi at de kjører på samme CPU og får bare 100 %. Det med time... Det var bare for å vise eksplisitt at typisk, hvis du setter i gang to tråder, så kjører de på hver sin CPU. De deler ikke på CPU-en til. Skal vi se... Men det vi skal se på nå... Det er... Hva om vi skriver kode som... Som gjør denne endringen i to operasjoner? Så... Her er det... Dette er assembly-kode som er generert av GCC. Genererer GCC kode som utfører den økningen av svar", "source": "lecture"}
{"lecture_id": "os12del10", "chunk_id": "os12del10_0004", "start": 313.14, "end": 405.04, "token_count": 234, "text": "Skal vi se... Men det vi skal se på nå... Det er... Hva om vi skriver kode som... Som gjør denne endringen i to operasjoner? Så... Her er det... Dette er assembly-kode som er generert av GCC. Genererer GCC kode som utfører den økningen av svar i én enkel instruksjon, eller er det flere? Her har jeg skrevet kode som eksplisitt gjør dette her i tre operasjoner, sånn som man kan risikere. Så dette her er da tre operasjoner for å endre svar. Man flytter først svarvarabelen over i... Og så flytter man svaret ut igjen. Og hvis vi kjører denne koden, så skal vi se at da... Da kan man også få problemer hvis man... Hvis man har en contex-witch. Altså hvis man med Tasep tvinger begge til å kjøre på samme suppu, men likevel kan man...", "source": "lecture"}
{"lecture_id": "os9del2", "chunk_id": "os9del2_0000", "start": 0.0, "end": 89.94, "token_count": 298, "text": "Det var litt om fremover, så... I dag så... er oppgavene. Handler om dokkefiles, TIX, systemtics, Nikes og folk. Det er stort sett det vi snakker om i dag. Men det er jo noen digitale forelesninger, og det var en som lurte på... Det kom kanskje ikke helt fram. Jeg har ikke fått delt opp alle disse dokkefile... Forelesningene, eller det vil si... De som kom forrige onsdag, de er deltatt på. Det er de oppgavene handler om. Det er disse her. Og det som er fokus her, er først og fremst dokker-files. Og hvordan man bruker det. For det er standardmåten man bruker dokker på. At man definerer at man skal ha inn i en container. Når man skal kjøre det, så bare bygger man den, og kjører i vei. I tillegg er det litt tema med volumes. Hvordan man kan mappe inn filsystemer inn i containere. Det er også den fordelen å ha containere som uavhengige enheter, som hele tiden kan stoppes og startes, og at man ikke da må save filer. Nå bruker de containere på en litt annen måte i deres tilfelle.", "source": "lecture"}
{"lecture_id": "os9del2", "chunk_id": "os9del2_0001", "start": 71.12, "end": 160.56, "token_count": 288, "text": "Hvordan man kan mappe inn filsystemer inn i containere. Det er også den fordelen å ha containere som uavhengige enheter, som hele tiden kan stoppes og startes, og at man ikke da må save filer. Nå bruker de containere på en litt annen måte i deres tilfelle. Men det er da også egentlig containere. Men det er sysbokskonteinere, som er av en spesiell art, som bruker virtualiseringsteknikker for å verne om eller for å øke sikkerheten for konteinerne. Vi kommer mer teoretisk tilbake til konteinere etter hvert. Nå i starten er det mest Så er det mest... det praktiske. Hva med uka før skulle ikke de deles inn? Jo, jeg ligger et hakk etter. Så jeg skal skikkelig ta en hard jobbøkt. Og så få delt inn alle videoene i mindre biter. For jeg vet at det er mye nyttigere for dere. Eller det er mye enklere hvis dere har en problemstilling dere ønsker å se på. Så kan dere bare gå inn på den i stedet for å lete seg gjennom hele videoen.", "source": "lecture"}
{"lecture_id": "os9del2", "chunk_id": "os9del2_0002", "start": 137.96, "end": 216.64, "token_count": 288, "text": "Og så få delt inn alle videoene i mindre biter. For jeg vet at det er mye nyttigere for dere. Eller det er mye enklere hvis dere har en problemstilling dere ønsker å se på. Så kan dere bare gå inn på den i stedet for å lete seg gjennom hele videoen. Så det skal jeg få til i løpet av uka. Ok. Men det var én ting som var viktig her. Jo. Og den første autoriske oppgaven, den er spesielt viktig i år. Lagre et skript som først stopper alle kjørende dockcontainere. Og en sånn opprydding kan man... Når man har kommet i gang med dokkefiles, så er det veldig greit å ha en sånn opprydding. For da har man ikke bygd et image som skal gjøre noe veldig spesielt. Hvis man skal ha i gang en konteiner, så bare bygger man fra den dokkefilen, og så har du konteineren, og så setter du i gang i det. Og det meste mye ryddigere, for da kan du bare rydde bort alt, og da bruker man mindre ressurser.", "source": "lecture"}
{"lecture_id": "os9del2", "chunk_id": "os9del2_0003", "start": 199.96, "end": 288.08, "token_count": 296, "text": "så bare bygger man fra den dokkefilen, og så har du konteineren, og så setter du i gang i det. Og det meste mye ryddigere, for da kan du bare rydde bort alt, og da bruker man mindre ressurser. Og det som gjør at det er spesielt viktig i år, er at når vi kjøpte den serveren som vi bruker til dette her, så trodde vi at vi hadde et nettverksfilsystem som vi kunne bruke, men det visste vi at vi ikke kunne, så derfor sitter vi igjen med en veldig liten disk på serveren, Som kjører rocker for dere. Den har faktisk ca. åtte ganger så mye ram som det er disk. Og det er ganske spesielt. Så masse ram, men lite disk. Og den begynte her for en uke siden og begynte å bli full. Så det er viktig å rydde bort image og containere. For de lagres sånn fort. Hvis containeren deres stopper, eller blir stoppet, og vi starter den igjen, så vil dere fortsatt ha de samme filene der osv. Men dette lagres da på disken, og den begynner å fylles opp.", "source": "lecture"}
{"lecture_id": "os9del2", "chunk_id": "os9del2_0004", "start": 261.7, "end": 336.36, "token_count": 290, "text": "Så det er viktig å rydde bort image og containere. For de lagres sånn fort. Hvis containeren deres stopper, eller blir stoppet, og vi starter den igjen, så vil dere fortsatt ha de samme filene der osv. Men dette lagres da på disken, og den begynner å fylles opp. Så det er viktig at dere gjør dette, spesielt når du har begynt å komme i gang med dokkefiles. Så er det greit å bare ta en opprydding og fjerne alt, og så bare bygge på nytt. Det tar jo litt tid å bygge opp. Så ikke meningen vi skal gjøre det hver time, men sånn hver uke kanskje, kjøre en opprydding. Så kan dere eventuelt spisse disse skriptene, sånn at dere ikke fjerner alt, men f.eks. har en måte å spare noen av de imagene som dere bruker og har tenkt å bruke fremover. Ellers så er den viktigste oppgaven å gjøre det samme som i forrige ukes oppgaver igjen. Men denne gangen med dokkefiles. Som er da en mer standard måte å gjøre det på", "source": "lecture"}
{"lecture_id": "os9del2", "chunk_id": "os9del2_0005", "start": 316.68, "end": 409.72, "token_count": 297, "text": "noen av de imagene som dere bruker og har tenkt å bruke fremover. Ellers så er den viktigste oppgaven å gjøre det samme som i forrige ukes oppgaver igjen. Men denne gangen med dokkefiles. Som er da en mer standard måte å gjøre det på enn å først bygge en Ubunt fra scratch, og gå inn på den og installere og så videre. Det er mer den vanlige måten å gjøre det på en fysisk maskin eller en virtuell maskin. Men med containere så er det dokkefiles som gjelder, som er standardmåten å gjøre det på. Vi skal komme mer tilbake til det teoretiske rundt dokker og virtuelle maskiner og fysiske maskiner. Men så det er en... Vi er egentlig... Vi ser på alle tre delene. Når jeg bruker den desktopen på jobben som heter Rex, og laptopen min som heter Lap, så er det fysiske maskiner. Studd SSO, som dere bruker mye, Virtuell maskin, mens dokker, det er containere oppå toppen der. Den viktigste forskjellen på virtuelle maskiner og containere, er at virtuelle maskiner har sitt helt eget operativsystem.", "source": "lecture"}
{"lecture_id": "os9del2", "chunk_id": "os9del2_0006", "start": 384.16, "end": 429.54, "token_count": 154, "text": "så er det fysiske maskiner. Studd SSO, som dere bruker mye, Virtuell maskin, mens dokker, det er containere oppå toppen der. Den viktigste forskjellen på virtuelle maskiner og containere, er at virtuelle maskiner har sitt helt eget operativsystem. Og dermed så går det med veldig mye ressurser til det. For dere skal kjøre et helt eget operativsystem. Dokkecontainere bruker det underliggende operativsystemet. Og mye mer ressursbesparende. Så det er den største forskjellen. Det kommer vi også enda mer tilbake til.", "source": "lecture"}
{"lecture_id": "linux6del9", "chunk_id": "linux6del9_0000", "start": 0.0, "end": 79.76, "token_count": 285, "text": "Vi har sett hvordan screen kan brukes til å sette i gang prosesser i bakgrunnen, slik at de står og kjører etter at man har logget ut. Det er mulig å gjøre det ved å legge det eksplisitt i bakgrunnen og logge ut også, men det man kan få problemer med da, er hvis man har standard R og standard out, og ikke tar seg av det på en ordentlig måte. Det samme gjelder når man prøver å starte tjenester remotely, altså starte en... Jobb på en annen server med SSH. Så vi skal se kortere på det. Nå er jeg på StudySSH, og så logger jeg inn på Linux-VM-en. Og her tenker jeg at jeg har et lite skript som skriver både til standardoppdrett hver runde, og så skriver det en feilmelding også til standard error. I tillegg kan man tenke seg at denne... Dette skriptet får input. Så det jeg ønsker å gjøre nå, er å prøve å starte det remotely fra Studio SSO. Så det jeg kan starte med da, er å se bare at det funker. Ja, jeg kan kjøre én enkel kommando.", "source": "lecture"}
{"lecture_id": "linux6del9", "chunk_id": "linux6del9_0001", "start": 60.0, "end": 143.5, "token_count": 291, "text": "Dette skriptet får input. Så det jeg ønsker å gjøre nå, er å prøve å starte det remotely fra Studio SSO. Så det jeg kan starte med da, er å se bare at det funker. Ja, jeg kan kjøre én enkel kommando. Men så ønsker jeg å prøve å kjøre en litt mer komplisert kommando, nemlig loop.shell. Og så ønsker jeg å legge... dataen fra loop.shell i loop.log, f.eks. På den måten. Kanskje jeg ønsker å overskrive dataene, sånn at denne bare øker loggfilen etter hvert. Så... Til slutt så ønsker jeg typisk å legge den i bakgrunnen. Og så prøver jeg å starte skriptet på denne måten. Det første problemet som dukker opp, er en fin seer command not found, og det er fordi da må jeg angi full path. Fordi det sendes ikke med SSH. Og det jeg følger med path, og så må jeg ha tilsvarende full path her. Group 100... Sånn. Så kan jeg prøve å kjøre da. Da ser jeg at det blir litt feil, for da kommer standard R ut her.", "source": "lecture"}
{"lecture_id": "linux6del9", "chunk_id": "linux6del9_0002", "start": 120.0, "end": 232.98, "token_count": 292, "text": "Fordi det sendes ikke med SSH. Og det jeg følger med path, og så må jeg ha tilsvarende full path her. Group 100... Sånn. Så kan jeg prøve å kjøre da. Da ser jeg at det blir litt feil, for da kommer standard R ut her. Så dette fungerer ikke helt som jeg skulle ønske. Så da stopper jeg den. Så det jeg kan gjøre da, er altså... Enten kan jeg legge standard-eier til samme sted som standard-out. Eller så kan jeg si eksplisitt at jeg vil ha standard-eier til home...group100, f.eks. r.txt. På denne måten. Alt fungerer som det skal. Jeg får prompt tilbake. Så kan jeg gå inn på hosten og se hva som foregår her. Det jeg kan se da, er på loop.log. Den står og går fint der. Og så på loop... er r.taxd. Der ser vi at vi for hver runde får feilmeldinger. Sånn... Og hvis vi går ut og inn igjen, så ser vi at... Det skriptet som vi startet, det står fortsatt og kjøler. For en liten ting til som man kan gjøre for helt sikkert,", "source": "lecture"}
{"lecture_id": "linux6del9", "chunk_id": "linux6del9_0003", "start": 210.02, "end": 261.8, "token_count": 141, "text": "Der ser vi at vi for hver runde får feilmeldinger. Sånn... Og hvis vi går ut og inn igjen, så ser vi at... Det skriptet som vi startet, det står fortsatt og kjøler. For en liten ting til som man kan gjøre for helt sikkert, det er hvis det skulle komme noe input. Da kan man gjøre følgende. Man kan si... Del 0, sende det inn til input. Da må man helt skuddsikker måtte og starte script eller program på en annen server... Fra en server og starte det på en annen server.", "source": "lecture"}
{"lecture_id": "os2del16", "chunk_id": "os2del16_0000", "start": 0.0, "end": 81.08, "token_count": 292, "text": "For å få til da den fysiske boksen, den lille logiske kretsen, som gjør den ene operasjonen, så kan man da skrive ned sannhetsstabellen for en sånn addisjonskrets. En full adder kalles det, en sånn boks. Og det er da ganske rett frem å skrive ned sannhetsstabellen. For det er denne operasjonen vi skal gjøre om og om igjen. Vi skal legge sammen X og Y, og så har vi en mente fra før, Z. Så disse tre bitene er da input X, Y og Z. Og så får vi et svar S her, ett siffer, med en mente C. Og da er det ganske enkelt for hver av tilfellene å se hva S og Z er. Det første tilfellet vi hadde, var at Z var 1, og Y var 1, og X var 0. Det er det leddet her. Z1, I1 og X0. Hva skal vi få ut da? Jo, da får vi 2, så det blir 1-0. Da skal S være 0 og C være 1. Så da får vi en 0 her og en 1 der. Det var den operasjonen vi hadde tidligere.", "source": "lecture"}
{"lecture_id": "os2del16", "chunk_id": "os2del16_0001", "start": 60.0, "end": 94.2, "token_count": 134, "text": "Det er det leddet her. Z1, I1 og X0. Hva skal vi få ut da? Jo, da får vi 2, så det blir 1-0. Da skal S være 0 og C være 1. Så da får vi en 0 her og en 1 der. Det var den operasjonen vi hadde tidligere. Og tilsvarende kan vi lett sette opp alle de andre. F.eks. hvis alle er 0, da blir det både 0 her og 0 der. Den første linja. Og så kan man gå videre og sånn.", "source": "lecture"}
{"lecture_id": "os3bdel7", "chunk_id": "os3bdel7_0000", "start": 0.0, "end": 85.92, "token_count": 292, "text": "Da skal vi til slutt se litt på en simulering av en CPU. Dette skal dere studere i detalj. Og faktisk kjøre denne simuleringen i simuleringsmaskinen for Windows. Dette er arkitekturen til en komplett firepint CPU. Som kan utføre programmet skrevet i maskinkode. Og vi ser her... Ja... Her er datapath, og det er den som inneholder Alun og registeret. Det som er på høyre side her, er registeret. Fire biter i registeret. Så for eksempel R0 her, der står det egentlig 0010. Så det er tallet fire. Mens i R1 så står det tallet én. I tillegg har vi ram som er koblet til, sånn at man kan skrive ut resultater. Vi kommer ikke til å bruke den delen. Men det vi kommer til å bruke, er rom, som er her. Og inni her så ligger instruksjonene. Og instruksjonene, det er da maskinkode. Og etter hvert skal vi se, når vi komplerer høynivåkode, så får vi maskinkode. Og i vårt tilfelle så ligger den maskinkoden her i rom.", "source": "lecture"}
{"lecture_id": "os3bdel7", "chunk_id": "os3bdel7_0001", "start": 71.8, "end": 156.8, "token_count": 298, "text": "Og inni her så ligger instruksjonene. Og instruksjonene, det er da maskinkode. Og etter hvert skal vi se, når vi komplerer høynivåkode, så får vi maskinkode. Og i vårt tilfelle så ligger den maskinkoden her i rom. Men her har vi ikke noen kompulator. Her må vi skrive maskinkode rett. Det en maskininstruksjon gjør, det er å styre alle kontrollbitene til Datapath, sånn at operasjonen som den ønsker å utføre, faktisk blir utført. Vi ser det er... Masse nuller og enere som går inn her og styrer disse bitene. Oppcode sier hvilken institusjon som skal utføres. Da kan vi f.eks. tenke oss at vi ønsker å ha dere to tall. Og da er institusjonsdekoderen, den jobben den gjør, er at den dekoder institusjonen sånn at den skrur på de riktige bryterne her. F.eks. S0 og S1, det styrer Alun. Hvis den er der, så må S0. Settes til de verdiene som gir en addisjon inne i Alun.", "source": "lecture"}
{"lecture_id": "os3bdel7", "chunk_id": "os3bdel7_0002", "start": 133.32, "end": 209.92, "token_count": 287, "text": "Og da er institusjonsdekoderen, den jobben den gjør, er at den dekoder institusjonen sånn at den skrur på de riktige bryterne her. F.eks. S0 og S1, det styrer Alun. Hvis den er der, så må S0. Settes til de verdiene som gir en addisjon inne i Alun. Skal se på det i litt mer detalj etterpå. Her er vi inne i datapath. Her nede er Alun, som vi har konstruert tidligere i dag. Vi ser det er noen sånne mux-er, eller multiplex-ere. Og de er ganske enkelt et system for å velge hvilken kanal. Man sender inn i aluen. Her er en mux som kommer inn i aluen. Den kan velge mellom å enten sende noe fra et register, eller å sende inn en konstant. Da kan man, hvis man velger... Nei, ikke å... Jo, enten fra registeret her, eller fra den konstanten her. Det velges ved det valgbyttet her. Det er noe av det instruksjonsdekoderne gjør, hvis det skal komme inn en konstant.", "source": "lecture"}
{"lecture_id": "os3bdel7", "chunk_id": "os3bdel7_0003", "start": 185.68, "end": 269.86, "token_count": 300, "text": "Den kan velge mellom å enten sende noe fra et register, eller å sende inn en konstant. Da kan man, hvis man velger... Nei, ikke å... Jo, enten fra registeret her, eller fra den konstanten her. Det velges ved det valgbyttet her. Det er noe av det instruksjonsdekoderne gjør, hvis det skal komme inn en konstant. Så må den kanskje skrus på én, sånn at konstanten kommer inn. Hvis du skal få noe fra et register, så må den settes til null, sånn at det som kommer fra A-bussen, kommer inn. Til syvende og sist så kommer det da to tall inn i A-lun. A og B. Og så ser vi det går ett resultat det ut. Og da ser vi at... Her igjen så kan... Det går ett resultat det ut. Man kan velge enten å ha data inn her, som da kommer fra ramm, eller så kan man ta resultatet fra Alu. Det vi har sett på tidligere i dag, er at man legger sammen to tall. Det foregår ved at man tar to registre, la oss si R0 og R1. Så kobles verdien av de ved hjelp av multiplexerne sånn at R0 går inn i A.", "source": "lecture"}
{"lecture_id": "os3bdel7", "chunk_id": "os3bdel7_0004", "start": 248.02, "end": 307.34, "token_count": 222, "text": "eller så kan man ta resultatet fra Alu. Det vi har sett på tidligere i dag, er at man legger sammen to tall. Det foregår ved at man tar to registre, la oss si R0 og R1. Så kobles verdien av de ved hjelp av multiplexerne sånn at R0 går inn i A. R1 går inn i B. Og så setter man en viktig bit her for å addere. Og så kommer resultatet i D. Og så kobles denne multiplexeren, sånn at resultatet fra D sendes opp igjen i registerfilen. Og avhengig av instruksjonen man gjør, så kan man f.eks. velge å legge resultatet i R0. Det man utfører da, er R0 er lik R0 pluss R1. Og på denne måten så... På denne måten så virker en datamaskin. Det er akkurat samme prinsippet i alle sider.", "source": "lecture"}
{"lecture_id": "linux2del4", "chunk_id": "linux2del4_0000", "start": 0.0, "end": 107.08, "token_count": 297, "text": "Vi skal nå se på begrepet absolutt og relativ path. Path, eller bane, det er det samme som stien som da fører til et sted i Linux-filsystemet. Og det som er viktig, er at man, når man er inni et filsystem, sånn som her, så er man alltid på et eller annet sted i filsystemet. Og alle baner som begynner med en slash, de har en såkalt absolut path, for da spesifiserer vi nøyaktig hvor i filsystemet du er i forhold til roten av filsystemet. Hvis du ikke har en sånn slash foran, så er det relativ path. ETC med absolut path, så kan jeg gjøre sånn. CD slash ETC. Og da kommer jeg dit uansett hvor jeg måtte være på forhånd. Hvis jeg nå går til roten av filsystemet, sånn, så kan jeg gå til ETC med relativ path. For da skriver jeg CD, altså ETC. Så ligger jo ETC nå... Rett under meg her, så da kan jeg gå rett ned dit. Men hvis jeg f.eks. går hjem... Hvis jeg bare tar cd, så kommer jeg alltid hjem. Ops... Ikke PEFF, men PWD.", "source": "lecture"}
{"lecture_id": "linux2del4", "chunk_id": "linux2del4_0001", "start": 84.06, "end": 172.84, "token_count": 280, "text": "For da skriver jeg CD, altså ETC. Så ligger jo ETC nå... Rett under meg her, så da kan jeg gå rett ned dit. Men hvis jeg f.eks. går hjem... Hvis jeg bare tar cd, så kommer jeg alltid hjem. Ops... Ikke PEFF, men PWD. Hvis jeg nå er i hjemmekanalogen og så prøver å gå til ETC med Relativ Path, så går det dårlig. For da finnes jo ikke det. Så... Den enkleste måten å gå til ettestedet på er å bruke absolutt mapp. Så kan man jo... Hvis jeg nå er i mappen, så kan jeg gå en møysommelig lang vei. Jeg kan begynne å gå oppover. Så kan jeg gå to hakk oppover av gangen. Enda et hakk oppover. Når jeg tar cd., så beveger jeg meg med relativ paff. Så kan jeg gå ned til ECC. Så... igjen, hvis jeg f.eks. skal til Userbin, så kan jeg alltid gå dit med full paff, sånn som det. Alternativt, hvis jeg er i... Hvis jeg er oppe i roten,", "source": "lecture"}
{"lecture_id": "linux2del4", "chunk_id": "linux2del4_0002", "start": 150.0, "end": 196.04, "token_count": 139, "text": "Så kan jeg gå ned til ECC. Så... igjen, hvis jeg f.eks. skal til Userbin, så kan jeg alltid gå dit med full paff, sånn som det. Alternativt, hvis jeg er i... Hvis jeg er oppe i roten, så kan jeg gå med RelativPath Userbin. Så det som er forskjellen, er alltid... At hvis du angir en path med slash i starten, så er det absolutt path. Hvis det ikke er en slash i starten, sånn som her, så er det relativ path i forhold til der du står.", "source": "lecture"}
{"lecture_id": "linux9del4", "chunk_id": "linux9del4_0000", "start": 0.02, "end": 127.3, "token_count": 276, "text": "Da skal vi gå tilbake til dere og se hvordan det går der. Da ser vi nederst i vinduet her at det ser ut som alt har kjørt. Alt er ferdig. Og vi ser de brukte 514 sekunder. Man har vent åtte minutter på å bygge alt. Men da skulle det være mulig å starte. Og da kan man kjøre dokkeren. Nei... Dokker, konteiner... Skal vi se... Hvis man ikke husker all syntaksen, så kan man bla... Ja. Sånn har jeg startet denne tidligere. Og det skulle stemme. Docker-containeren minus IT for interaktivt. Sum er navnet som jeg ga til dette prosjektet. Ja... Det som jeg ga til dette prosjektet da jeg bygget. Så dermed kan jeg starte det med containeren minus IT. Og så bæsj der for å få opp et bæsjel. Og da ser vi. Nå har jeg fått opp... Konteineren. Og da skulle det være... Ja, da er det en mappe som heter Sum her. Og her ser vi at alt har fungert som det skulle. Alle programmene er kopiert inn.", "source": "lecture"}
{"lecture_id": "linux9del4", "chunk_id": "linux9del4_0001", "start": 101.24, "end": 208.76, "token_count": 295, "text": "Og så bæsj der for å få opp et bæsjel. Og da ser vi. Nå har jeg fått opp... Konteineren. Og da skulle det være... Ja, da er det en mappe som heter Sum her. Og her ser vi at alt har fungert som det skulle. Alle programmene er kopiert inn. Og da kan vi bare håpe på at det f.eks. virker å kompilere med GSSN. Ja, det gjør det. Og da kan man begynne å kjøre. Tilsvarende så har vi også installert både Java og Python. Så da skulle det også være mulig å komplere Java-filen. Og kjøre den. Så... Dermed kan man... I Dockerfield så kan man gjøre alle disse operasjonene. Og så kan man teste ut om resultatet... De bruker litt lengre tid, det kan være naturlig, for det er en annen CPU som kjører på denne maskinen. Men man ser også at det er litt forskjell i forhold til det jeg hadde tidligere. Så tanken i oppgaven er at dere nå skal tilpasse disse tidene. Og få de til å kjøre like lenge, sånn at dere kan finne ut hvor mange ganger raskere", "source": "lecture"}
{"lecture_id": "linux9del4", "chunk_id": "linux9del4_0002", "start": 187.12, "end": 227.14, "token_count": 136, "text": "på denne maskinen. Men man ser også at det er litt forskjell i forhold til det jeg hadde tidligere. Så tanken i oppgaven er at dere nå skal tilpasse disse tidene. Og få de til å kjøre like lenge, sånn at dere kan finne ut hvor mange ganger raskere Programmeringsspråkene er en ett-bær-skript i dokkekonteineren. OK. Men nå trenger vi en pause, så da kan vi komme tilbake til disse resultatene og ikke minst til dokkekonteineren etter pause.", "source": "lecture"}
{"lecture_id": "os6del2", "chunk_id": "os6del2_0000", "start": 0.0, "end": 84.38, "token_count": 291, "text": "Og her står det Linux-VM-er. Så det er nyttig og viktig i dag. Så jeg skal bruke litt tid helt i starten og se på de Linux-VM-ene, sånn at dere kan komme i gang med dem. Og dere har kanskje merket at dere har fått en annonsement i OS-gruppene. Og der står det et passord. Det står ikke så mye annet, men det er det passordet trenger. For å kunne bruke Linux-VM-ene. Og mer om dette står øverst i uke seks. Her står det litt om multiple choice-testen. Og så står det her om Linux-VM-ene. Jeg kaller det Linux-VM-er. Virtuelle maskiner. Men egentlig er det faktisk dokkercontainere. Men det er på en måte halvveis virtuelle maskiner. Bruker et opplegg som heter Sysbox, som er et slags system som isolerer dokkecontainerne i større grad. Vi kommer tilbake til dokkecontainere senere i kurset. Da skal dere kjøre dokkecontainere og starte og stoppe og bygge osv. Så da skal vi snakke mer om hvordan det henger sammen.", "source": "lecture"}
{"lecture_id": "os6del2", "chunk_id": "os6del2_0001", "start": 63.62, "end": 159.44, "token_count": 298, "text": "som er et slags system som isolerer dokkecontainerne i større grad. Vi kommer tilbake til dokkecontainere senere i kurset. Da skal dere kjøre dokkecontainere og starte og stoppe og bygge osv. Så da skal vi snakke mer om hvordan det henger sammen. Men generelt så er det et problem med dokkecontainere at de... De kjører direkte på operativstemme og har tilgang til operativstemme på serveren som de kjører, i motsetning til virtuelle maskiner. Men disse dokkencontainerne som kjører Sysbox, er containet enda sterkere. De er isolert mer fra serveren under. Dermed får man en look-og-file som om det var en virtuell maskin, som Studio SSO. Som kjører på en fysisk server. De tingene er viktig å ha med i denne ukens oppgaver. Hvor det er... Jo, det er i denne ukens oppgaver hvor dere skal kjøre prosesser. Kjøre mange prosesser på samme VM eller på Study SOSA, for å se hvordan serverne... Tildeler CPU-er. Eller operativsystemet tildeler CPU-er til prosessene. Skredulerer. Og det skal vi snakke masse om.", "source": "lecture"}
{"lecture_id": "os6del2", "chunk_id": "os6del2_0002", "start": 133.14, "end": 212.46, "token_count": 243, "text": "Hvor det er... Jo, det er i denne ukens oppgaver hvor dere skal kjøre prosesser. Kjøre mange prosesser på samme VM eller på Study SOSA, for å se hvordan serverne... Tildeler CPU-er. Eller operativsystemet tildeler CPU-er til prosessene. Skredulerer. Og det skal vi snakke masse om. Men aller først så skal vi se litt i praksis på disse Linux-VM-ene. Og det første og viktigste er at for å få tilgang til en Linux-VM, så må dere være i en OS-gruppe. I OS-gruppe 13 så kan dere da logge dere inn med SSO. På tilsvarende måte som dere gjør til StudSSO, med Putty eller på andre måter. Med et skjell fra MacLinux eller fra en Linux-laptop. Eller fra StudSSO, hvis dere er der inne. Med SSO på denne måten. Så OS13, det er da hosten. Det er navnet på VM-en. Bruker navnet.", "source": "lecture"}
{"lecture_id": "os6del15", "chunk_id": "os6del15_0000", "start": 0.0, "end": 69.2, "token_count": 240, "text": "Da er spørsmålet... Dette var en CPU-avhengig prosess. Kunne du gjentatt noen prosesser som ikke er så avhengige av CPU-er? Ja, det er egentlig de fleste prosesser er ikke avhengige av CPU-er. De står bare og venter på at noe skal skje, sånn som en teksteditor. Hvis du skriver veldig fort, så får den kanskje hvert ti tegne sekund. Men det er en evighet for en CPU. At noe skjer hvert tiendedels sekund... Da kan man gjøre en million instruksjoner i mellomtiden. For eksempel en web browser også. Selv om det er en del prosessering, så bruker den ikke 100 % CPU. Og det kan man se på topp her. På den Linux-maskinen som kjører. De aller fleste CPU-er, sånn som R-server, bruker nesten... En gang iblant kommer det opp noen programmer som bruker litt seppe.", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0000", "start": 0.0, "end": 99.54, "token_count": 295, "text": "Og da... En dokkefil er da i prinsippet en fil som inneholder alt det en dokkecontainer trenger. Det vi gjorde forrige gang, var at... Skal vi se... Nå før pause så gikk jeg inn på denne containeren her. Og det vi gjorde forrige gang, var at nå er jeg inne på containeren. Jeg kan kjøre apps... App Install og så videre. Og så installere den programvaren jeg trenger, f.eks. en webserver. Men det vi skal se på nå... Nå går jeg ut med Exit. Da ser jeg for øvrig at den, når jeg går inn med Execute og cobler meg opp, så vil den fortsatt stå og gå etterpå. Men det vi skal gjøre nå, er å bygge... Jeg skal lage en container som allerede har Apache installert før vi starter. Og det er da dokkefiles kommer inn i bildet. Det man gjør da, er at man lager en mappe. Jeg vil lage en webserver her. Så jeg lager en mappe som heter webserver. Så går jeg til den mappen. Jeg lager en fil som skal hete dockerfile. Kan ha andre navn, men hvis man bruker navnet dockerfile, sånn som det,", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0001", "start": 74.68, "end": 187.3, "token_count": 297, "text": "Det man gjør da, er at man lager en mappe. Jeg vil lage en webserver her. Så jeg lager en mappe som heter webserver. Så går jeg til den mappen. Jeg lager en fil som skal hete dockerfile. Kan ha andre navn, men hvis man bruker navnet dockerfile, sånn som det, så kan man bygge den. Og da vil default dokker forvente at filen heter dokkerfile. Så jeg kaller den dokkerfile. Og da, hvis dere ser i... ikke slidene, men i gjennomgangen... så vil dere se at det er en rekke kommandoer eller instruksjoner som gjør at man definerer hvordan containeren skal se ut. Det første og viktigste kanskje er from. Det sier hvilket image man skal velge. Det er akkurat som å kjøre dokker, containeren, bunte. Siste bunteversjon, som jeg default får da. Etterpå, når jeg saver denne finnen, så kjører man dokkebild. Og da vil man starte med å laste ned bunte-imaget. Så kan man etterpå kjøre kommandoer inne i... Når man bygger imaget, så vil disse kommandoene kjøres", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0002", "start": 150.0, "end": 284.42, "token_count": 300, "text": "Siste bunteversjon, som jeg default får da. Etterpå, når jeg saver denne finnen, så kjører man dokkebild. Og da vil man starte med å laste ned bunte-imaget. Så kan man etterpå kjøre kommandoer inne i... Når man bygger imaget, så vil disse kommandoene kjøres før man starter. På denne måten kan jeg f.eks. starte med å si... Og så kan jeg ta... Istedenfor update, så kan jeg ta install. Og da kan jeg installere... Ja, vi kan jo kanskje gjøre dette i første omgang. Vi kan ta én ting til. Vi kan ta... Det jeg gjør nå, er altså at jeg kopierer en fil som heter index.hotml. Da må jeg lage den inne i den mappen som jeg har her. Så vet jeg at i en Apache-server så ligger indeksfilen i VAR og BWWHTML. Da kopierer jeg den filen din, sånn at når dette imaget starter, så vil jeg få en container som inneholder en webserver med innhold indeks.hottime. Lagt opp et svært filsystem der med masse statiske sider som kunne serves. OK. Vi kan stoppe der i første omgang, og så kan vi prøve å", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0003", "start": 256.16, "end": 375.12, "token_count": 282, "text": "Da kopierer jeg den filen din, sånn at når dette imaget starter, så vil jeg få en container som inneholder en webserver med innhold indeks.hottime. Lagt opp et svært filsystem der med masse statiske sider som kunne serves. OK. Vi kan stoppe der i første omgang, og så kan vi prøve å bygge en container ut fra den dokkefilen. Så... Da har jeg den dokkefilen. Og da bruker man dokkebild. Dokkebilde... Ja, altså... Det er noen... Det er noen opsjoner man kan bruke på bilde. Skal vi se... Om jeg husker det. Ja... Minus T kan man i hvert fall ha med. Generelt, hvis man har en kommando som man lurer på, så kan man alltid legge på minus hell, sånn som her. Og da får man hjelp til akkurat den kommandoen dere vil. Minus T taglist. Det kan være nyttig, for da kan man legge på en kommando. Eller gi konteineren et navn, så vi kan bruke det. La oss si jeg kaller den Web, Apache, hva er det som blir et tydelig navn.", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0004", "start": 345.36, "end": 472.38, "token_count": 292, "text": "Og da får man hjelp til akkurat den kommandoen dere vil. Minus T taglist. Det kan være nyttig, for da kan man legge på en kommando. Eller gi konteineren et navn, så vi kan bruke det. La oss si jeg kaller den Web, Apache, hva er det som blir et tydelig navn. Nå ligger det en dockerfil her i mappa, så da bare legger jeg på en prikk som betyr bygg fra den mappa som jeg står i. Ja. Must be a love case. Så jeg må faktisk gjøre det sånn. Det blir en rekke steg nedover. Nå begynner han å installere Apasje. Men det fine med denne lagdelingen er at det er en lagdeling i imager òg. Sånn at hver del kan lages til en eget image. Øyeblikket før jeg begynte å installere Apasje, det kan bli et image. Da vil det være App-get-update, men ikke Apache-innstilt. Så man får den type lagdeling. Og hvis man da endrer på noe, f.eks. endrer litt på hva som kopieres inn, så er det bare en liten endring. Når jeg da bygger et nytt image,", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0005", "start": 450.02, "end": 551.44, "token_count": 300, "text": "Da vil det være App-get-update, men ikke Apache-innstilt. Så man får den type lagdeling. Og hvis man da endrer på noe, f.eks. endrer litt på hva som kopieres inn, så er det bare en liten endring. Når jeg da bygger et nytt image, så brukes alle de andre lagene, for de er akkurat som før. Alt det er det samme. Så må man legge på en endring. Så kommer den på toppen av det nye. Som vi skal se etterpå, så trenger man ikke å gå gjennom hele den byggeprosessen fra start til slutt. Det holder med den siste biten. Ja, så ser vi... Nå fikk jeg en feil her. Copy. Det var ikke så rart jeg fikk en feil på det. Fordi copy den indeks.dot-hemmelen, den hadde jeg ikke laget. Så det er et godt eksempel på at da kan jeg rette opp det og bygge på nytt. Men vi kan før vi gjør det, så kan vi se om vi har fått et nytt image her.  Ja... Det ser ut som det ikke har blitt ferdig siden den... Siden den feilet. Så jeg kan prøve å rette opp det her først.", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0006", "start": 514.92, "end": 633.1, "token_count": 290, "text": "Så det er et godt eksempel på at da kan jeg rette opp det og bygge på nytt. Men vi kan før vi gjør det, så kan vi se om vi har fått et nytt image her.  Ja... Det ser ut som det ikke har blitt ferdig siden den... Siden den feilet. Så jeg kan prøve å rette opp det her først. Her inne så trenger jeg da en ineksfil. Da kan jeg bare... skrive inn noen her. Hilsen fra docker file container, for eksempel. Sånn. Da har jeg en fil her, og så kan jeg prøve å bygge på nytt. Da ser vi. Da... vil de tre første steppene... Der har man alle. Det er allerede et image som er ferdig. Det går veldig fort. Det er bare det siste steppet der. Det gjør en liten endring på imaget. Og så bygger man imaget. Så nå... Nå ser vi at vi har et ferdig image her. Da er det klart. Da kan jeg starte The Image som tidligere med dokkecontainer. Rønn minus IT... Og da heter det Apache. Så kan jeg kanskje kjøre bæsj der også.", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0007", "start": 596.4, "end": 705.6, "token_count": 276, "text": "Det er allerede et image som er ferdig. Det går veldig fort. Det er bare det siste steppet der. Det gjør en liten endring på imaget. Og så bygger man imaget. Så nå... Nå ser vi at vi har et ferdig image her. Da er det klart. Da kan jeg starte The Image som tidligere med dokkecontainer. Rønn minus IT... Og da heter det Apache. Så kan jeg kanskje kjøre bæsj der også. Sånn. Da er jeg inne i containeren. Og her er nå Apache installert. Det er flere måter å starte Apasje på. Jeg ser at den er installert. Ved at nå er det lagt inn muligheter for å starte Apasje-tjenesten. Et problem med dette er at den ikke har startet opp. Det kunne vært nyttig at den startet automatisk. Gå inn sånn som jeg gjør nå, og start den opp. Og så gå ut igjen. Når jeg går ut, så bruker jeg kontroll-p, kontroll-q. Hvis ikke, så stopper hele serien. Sånn. Så kan jeg liste igjen med PS.", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0008", "start": 681.8, "end": 785.64, "token_count": 300, "text": "Gå inn sånn som jeg gjør nå, og start den opp. Og så gå ut igjen. Når jeg går ut, så bruker jeg kontroll-p, kontroll-q. Hvis ikke, så stopper hele serien. Sånn. Så kan jeg liste igjen med PS. Og da ser vi at jo, jeg har en webbapasje nå som er oppe og kjører. Den kjører da en Apasje-server. Men vi ser vi har et annet problem her. Og det er at vi har ikke tilordnet noen port. Og dermed så vil ikke... Vil ved den neppe gi noe. Vi kan prøve... Den vil nok gi noe, men det er fra den lokale serveren som står her og kjører. Hvordan kan vi endre det? Jo, da kan vi rett og slett stoppe konteineren. Dere konteinerer stopp, og så ser vi den starter på 6A. Så det holder faktisk bare å skrive 6A. Så lenge det er entydig hvilken idé den er, så vil den stoppe. Så nå stoppet jeg WebApache. Og så kan jeg prøve å starte den igjen. Og så kan jeg ta minus P... La oss si vi tar 80-81 til 80.", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0009", "start": 756.0, "end": 875.32, "token_count": 290, "text": "Så det holder faktisk bare å skrive 6A. Så lenge det er entydig hvilken idé den er, så vil den stoppe. Så nå stoppet jeg WebApache. Og så kan jeg prøve å starte den igjen. Og så kan jeg ta minus P... La oss si vi tar 80-81 til 80. Det betyr nå at innkomne forespørsler til Local Hosts på port 80-81, det skal forwardes, sendes videre til port 80 på containeren. Da prøver jeg å kjøre den sånn SAD. Så kan jeg se her... Nei, det ser ikke ut som den webserveren kjører her. For vi stoppet jo hele containeren. Men da kan jeg prøve å starte webserveren. Sånn som det. Da starter den, så går jeg ut med kontroll P, kontroll Q. Så lister jeg konteineren igjen. Nå ser jeg at port 8081 blir sendt til port 80. Hvis jeg nå kjører curl local host på 8081, så ser vi at jeg får opp... Så nå fungerer det sånn som det skal. Og da vil jeg også kunne se... Hvis jeg nå går i en browser,", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0010", "start": 839.66, "end": 990.46, "token_count": 296, "text": "Så lister jeg konteineren igjen. Nå ser jeg at port 8081 blir sendt til port 80. Hvis jeg nå kjører curl local host på 8081, så ser vi at jeg får opp... Så nå fungerer det sånn som det skal. Og da vil jeg også kunne se... Hvis jeg nå går i en browser, så vil jeg også kunne se at den vil synes utenfra. Hvis jeg går til 8081 og OS... Skal vi se... Vi gjør et eksperiment der. Så skal jeg prøve å dele hele skjermen i stedet. Altså hele min desktop. Sånn. Nå ser dere forhåpentligvis hele min desktop. Men da er det et spørsmål om... Ser dere bra nok det jeg skriver? Skal vi se. Ja... Det er en som sier ja i hvert fall. Hvis det er noen som... Hvis denne skjermen er for liten, så si gjerne fra. Så kan jeg heller prøve å... Så kan jeg prøve å gå tilbake til å dele bare ett vindu. Ser et svart vindu til høyre for terminalen, bare. Det var rart. Vi kan se om vi får løst det på en annen måte.", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0011", "start": 961.24, "end": 1116.44, "token_count": 297, "text": "Hvis denne skjermen er for liten, så si gjerne fra. Så kan jeg heller prøve å... Så kan jeg prøve å gå tilbake til å dele bare ett vindu. Ser et svart vindu til høyre for terminalen, bare. Det var rart. Vi kan se om vi får løst det på en annen måte. Men i hvert fall i første omgang, så vil jeg bare demonstrere. Hvis jeg nå går inn på OL70. Her er delen til den. Og da ser vi... Da kommer... Nei. Da er spørsmålet... Hvorfor får jeg nå en annen hilsen? Da må jeg gå tilbake hit, og så må jeg se dokker, container, PS... Nei, jeg har bare én... Én konteiner her. Mulig at dette her er... At det er cash. Vi kan prøve å gjøre et eksperiment. Så kan vi da ta dokker container og så stoppe den her. Dokker container, stopp. 2F. Kan stoppe den andre der også. Da har jeg bare én container som kjører. Ja. Og da, når jeg går her nede og prøver å... ... og starte på nytt, så ser vi at jeg ikke har noen kontakt.", "source": "lecture"}
{"lecture_id": "linux8del7", "chunk_id": "linux8del7_0012", "start": 1089.08, "end": 1175.0, "token_count": 191, "text": "Dokker container, stopp. 2F. Kan stoppe den andre der også. Da har jeg bare én container som kjører. Ja. Og da, når jeg går her nede og prøver å... ... og starte på nytt, så ser vi at jeg ikke har noen kontakt. Så jeg tror kanskje at det bare var noe som lå i cash. Men det kan vi finne ut ved å... nå kjører ringen, så kan jeg starte på nytt. Det var den jeg kjørte. Og så må jeg... starte Apars 2 igjen. Start. Sånn. Da får jeg den riktige. Så... Det er den samme som jeg hadde her oppe. Da jeg kjørte curl low-closed. Da fikk jeg hilsen fra Dockenfield, og hilsen.", "source": "lecture"}
{"lecture_id": "os7del12", "chunk_id": "os7del12_0000", "start": 0.0, "end": 102.7, "token_count": 297, "text": "Multitasking og multiprosessing. Det er mange begreper som man må forholde seg til. Her er en liten oppsummering av noen av begrepene. Multitasking, eller multiprogramming, det er det som vi har sett på når operativsystemet fordeler tid på samme CPU. Ved å kappe opp tiden i små biter, og så dele ut tid til hver prosess. Det er multitasking. Multiprosessing er når to eller flere CPU-er samtidig kjører flere prosesser. I samme datamaskin kan du f.eks. ha fire CPU-er. Og hver av de kan da jobbe på én prosess helt samtidig. Og det er multiprosessing. Så har du det som kalles symmetrisk multiprosessing. Da... er det... Jo, den vesentlige forskjellen her er at da deler de på samme internmine. I multiprosessing så trenger du ikke å dele på samme internmine engang. SMP er det som er vanlig når du kjører i en server, sånn som de eksemplene... Da er alle prosessorene koblet til samme internminer. Og så kjører de helt samtidig, i virkeligheten, i sanntid samtidig.", "source": "lecture"}
{"lecture_id": "os7del12", "chunk_id": "os7del12_0001", "start": 78.8, "end": 169.16, "token_count": 293, "text": "I multiprosessing så trenger du ikke å dele på samme internmine engang. SMP er det som er vanlig når du kjører i en server, sånn som de eksemplene... Da er alle prosessorene koblet til samme internminer. Og så kjører de helt samtidig, i virkeligheten, i sanntid samtidig. Men det vi har sett på eksempler på hele tiden, er at vi har SMP samtidig som vi har multitasking. For operativstemme fordeler da mange prosesser på samme CPU, men samtidig så er det mange som kjører i parallell. Og så har vi multi-core multiprosessing. En liten forskjell der er at da... Når du sier multi-core, så sitter da flere prosesser på samme brikke. Altså multi-core. Core er en kjerne eller en regneenhet. De sitter da på samme brikke og deler også cash, og kjører prosesser samtidig. Regnes også som SMP. Her er det heller ikke så store forskjeller. I praksis vil du ikke merke noen forskjell om det er SMP eller Multicore. Du kan også ha en kobling av dette. Altså at du har...", "source": "lecture"}
{"lecture_id": "os7del12", "chunk_id": "os7del12_0002", "start": 150.0, "end": 249.4, "token_count": 298, "text": "Regnes også som SMP. Her er det heller ikke så store forskjeller. I praksis vil du ikke merke noen forskjell om det er SMP eller Multicore. Du kan også ha en kobling av dette. Altså at du har... En CPU-brikke med fire kjerner. Og så har du to sånne CPU-brikker inne i den samme maskinen. Men de ville dele inn interne mine. Så det var noen begreper. Skal vi se på noen eksempler på disse begrepene? Ja. Her ser vi, fra venstre mot høyre... For det første singelprosessor, sånn som det var i gamle dager. Nå er det nesten umulig å oppdrive noen som helst prosessor Som bare har én CPU, med LN og AltoCash og koblet til ramme. Dette er en duel-prosessor. Da ser vi at det er to separate brikker. Og man merker ikke så veldig stor førsel på det og den ved siden av, som er duel-core. Men her er det to separate fysiske brikker som du kan ta inn og ut av maskinen. Men begge er da koblet til samme ramme. Men de har hver sin cash. Og så har vi to eksempler på multicore-prosessorer.", "source": "lecture"}
{"lecture_id": "os7del12", "chunk_id": "os7del12_0003", "start": 227.12, "end": 311.44, "token_count": 297, "text": "som er duel-core. Men her er det to separate fysiske brikker som du kan ta inn og ut av maskinen. Men begge er da koblet til samme ramme. Men de har hver sin cash. Og så har vi to eksempler på multicore-prosessorer. Dette er en dual-core AMD-prosessor. Her ser vi CPU, eller regneenheten, ALU og registeren og alt dette her, sitter inni CPU, og så har vi to atskilte L1- og L2-cash. Og så har du en dual-core Intel-prosessor, som er like. Det er litt annerledes. Der har du CPU med L1-cash, men så ser vi at L2-cash er felles. Og hva som er best av disse arkitekturene, det varierer litt. Som sagt så er det vanlig at man legger på en L3-cash her også, som f.eks. kan være felles. Men hva som er best, det kan variere litt med hva slags load du har på prosessoren. Og hva den skal kjøre, altså på den serveren. Noen ganger, så hvis det er veldig mange like prosesser som deler veldig mye, så kan det være en fordel å ha mye felles cash.", "source": "lecture"}
{"lecture_id": "os7del12", "chunk_id": "os7del12_0004", "start": 293.5, "end": 376.2, "token_count": 247, "text": "Men hva som er best, det kan variere litt med hva slags load du har på prosessoren. Og hva den skal kjøre, altså på den serveren. Noen ganger, så hvis det er veldig mange like prosesser som deler veldig mye, så kan det være en fordel å ha mye felles cash. Men hvis de hele tiden gjør helt forskjellige ting, så kan det være en fordel å ha hvert sitt cash på den måten her. Så der er det ikke noen fasit på hva som er best av det. Ikke helt nye CPU-er, men de fleste ser ganske like ut som disse i dag. Dette er en fire-core CPU. Intel Core E7 har denne arkitekturen her. Så her ser vi... Det er fire CPU-er. Hver har L1-cash og L2-cash. Separat. Og så har de en felles L3 cash. Så AMD K10 er ganske lik, bare at den har litt mer L2-cash. Ellers så er de ganske, ganske like.", "source": "lecture"}
{"lecture_id": "os8del11", "chunk_id": "os8del11_0000", "start": 0.02, "end": 105.08, "token_count": 291, "text": "Da skal vi se litt på... litt spesifikt på Linux-sheduling. Og i den simuleringen av å lage vaflerør og forelese så er det denne scheduling-algoritmen som jeg tar utgangspunkt i. Men det finnes mange andre scheduling-algoritmer. Windows har en annen. Linux-kjerner er en litt annen kjerne... En litt annen scheduler. Skedulerer, eller tidsfordeler. Og den heter Completely Fair Scheduler, CFS. Den tok over for den som var i Linux 2.6-kjernen, som var i mange 10-15 år. Og det var fordi at den ikke alltid var helt fair. Det var noen da i... I Linux-kjerneutviklergruppa, som kom opp med et forslag til en ny scheduler. Så etter mye testing og feiling og prøving, erstattet den den gamle scheduleren. Det er en O1 scheduler, som betyr at den skalerer sånn at det går like raskt om det er 200 prosesser, eller om det er 10 prosesser som skal scheduleres. Det er det jernmannen forbinder med ordet scheduling. Det er å fordele ressurser blant en rekke enheter som trenger disse ressursene.", "source": "lecture"}
{"lecture_id": "os8del11", "chunk_id": "os8del11_0001", "start": 75.1, "end": 171.44, "token_count": 279, "text": "Det er en O1 scheduler, som betyr at den skalerer sånn at det går like raskt om det er 200 prosesser, eller om det er 10 prosesser som skal scheduleres. Det er det jernmannen forbinder med ordet scheduling. Det er å fordele ressurser blant en rekke enheter som trenger disse ressursene. Scheduling kan brukes i mange tilfeller, men dette er da CPU-scheduling som operativsystemet utfører, som vi ser på nå. Og da... Hver prosess som skal kjøre, tildeles et time count. Og dette time count-et er da målt i jikfis eller tics. Og det er disse hundredelssekundene, eller ti mellisekunder, som vi snakker om. Det er liksom det minste tidsintervallet. Hver gang timeren slår, så er det minste tidsintervallet. Da går det ett tics. Vi har sett på det så vidt i Progstat. Så er det en sånn liste over tics. Da kan man f.eks. se at siste sekund så har man kjørt 80 tics i user mode og 2 tics i curl mode.", "source": "lecture"}
{"lecture_id": "os8del11", "chunk_id": "os8del11_0002", "start": 140.56, "end": 234.56, "token_count": 282, "text": "Hver gang timeren slår, så er det minste tidsintervallet. Da går det ett tics. Vi har sett på det så vidt i Progstat. Så er det en sånn liste over tics. Da kan man f.eks. se at siste sekund så har man kjørt 80 tics i user mode og 2 tics i curl mode. Med denne prosessen. Da betyr det at denne prosessen har hatt CPU-en omtrent hele tiden. Eller TIKK eller Jiffy. Det er den viktige minste tidsenheten. Men så kommer det en epoke... Det er da en annen og større tidsenhet. Man gir da hver prosess et time count. F.eks. så kan en prosess få 20 enheter med tid i form av TIKS. Så kan da operativstemme prioritere, altså gi en annen enhet... Nei, gi en annen prosess - 40-tics. Og da betyr det at da vel den som får 40-tics, vil da kjøre i snitt dobbelt så lenge som den andre. Og det skal vi se på senere, hvordan vi kan gjøre med nice-kommandoen i Linux.", "source": "lecture"}
{"lecture_id": "os8del11", "chunk_id": "os8del11_0003", "start": 215.46, "end": 306.08, "token_count": 293, "text": "Nei, gi en annen prosess - 40-tics. Og da betyr det at da vel den som får 40-tics, vil da kjøre i snitt dobbelt så lenge som den andre. Og det skal vi se på senere, hvordan vi kan gjøre med nice-kommandoen i Linux. Etter at alle prosessene har fått tildelt sitt time-kontum, En liten bit med tid, så kjører operativsystemet Rovn Robin scheduling. Det betyr at... Rovn Robin, det betyr at man sitter rundt et bord, og så får alle litt tid. Men da er det ikke sånn at bare hver prosess får etikk. Man avbryter det ikke hele tiden. Det kan være effektivt. Og ikke ha for mange avbrudd. For det er litt overhead med en context switch, altså å switche over til en annen prosess. Så dette systemet sørger for at da, hvis det ikke skjer noe spesielt, altså hvis det ikke kommer noe og interrupter, så vil den prosessen som er tildelt 20 tics, den vil fullføre de 20 ticsene i denne epoken. Får den litt fred og ro til å kjøre ferdig.", "source": "lecture"}
{"lecture_id": "os8del11", "chunk_id": "os8del11_0004", "start": 283.84, "end": 364.4, "token_count": 293, "text": "Så dette systemet sørger for at da, hvis det ikke skjer noe spesielt, altså hvis det ikke kommer noe og interrupter, så vil den prosessen som er tildelt 20 tics, den vil fullføre de 20 ticsene i denne epoken. Får den litt fred og ro til å kjøre ferdig. Det blir jo noen sånn 0,2 sekunder, da. Som den... 20 hundredeler, så kjører den. Og så, etterpå, så kommer kanskje den prosessen som har fått ti triks. Så kanskje ikke er flere som har lyst til å kjøre i den epoken. Og da starter en ny epoke. Og så fortsetter det sånn. Og dermed kan operativstøtten avgjøre prioritering av de forskjellige prosessene. Så dette er en måte å dele inn tiden på på en litt mer dynamisk måte enn å bare gi annenhver tics til hver eneste prosess. Den måten ville ha gitt litt mye overhead. Så må vi også huske på at timeticsene er definert av operativsystemet. Man har testet ut i noen skeduer... I 26-kjernen kan man programmere den lengden.", "source": "lecture"}
{"lecture_id": "os8del11", "chunk_id": "os8del11_0005", "start": 340.28, "end": 440.52, "token_count": 297, "text": "enn å bare gi annenhver tics til hver eneste prosess. Den måten ville ha gitt litt mye overhead. Så må vi også huske på at timeticsene er definert av operativsystemet. Man har testet ut i noen skeduer... I 26-kjernen kan man programmere den lengden. Så det går an å sette 1 ms eller 100 ms, men da oppfører systemet seg litt forskjellig. Etter hvert timertick så sjekkes det om den prosessen som kjører, har flere tics igjen, altså om telleren til prosessen er større enn null. Så kaller man ikke scheduleren. Da bare fortsetter den å kjøre til den er ferdig med sin epoke. Altså da typisk med sine 20 tics. Og så er epoken over når alle prosesser har brukt opp sin tid. Og da counter er null for alle prosesser. Og da starter man på nytt. Og så deler scheduleren ut tics til alle prosesser. Som ønsker å kjøre. Det er da en variabel som kalles priority, eller prioritet. Og den bestemmer da hvor mye CPU-tid prosessene skal få. Og en prosess kan faktisk senke sin egen prioritet.", "source": "lecture"}
{"lecture_id": "os8del11", "chunk_id": "os8del11_0006", "start": 413.84, "end": 504.56, "token_count": 291, "text": "Og så deler scheduleren ut tics til alle prosesser. Som ønsker å kjøre. Det er da en variabel som kalles priority, eller prioritet. Og den bestemmer da hvor mye CPU-tid prosessene skal få. Og en prosess kan faktisk senke sin egen prioritet. Den kan be om lavere prioritet. I Linux gjør man det med command og nice, og da får den prosessen mindre prioritet. Vanligvis prøver operativstemma å være så fair som bare mulig. Alle som ønsker CPU, tildeles omtrent like mye mange tics. Og det er dette vi ser, som vi så på i forrige uke, da vi kjørte fire og åtte prosesser på samme CPU. Det operativstemma gjør, er å tildele tics. Og den tildeler da i utgangspunktet like mange tics til hver av prosessene. En time-countum vil da kunne variere, sånn statistisk. For dette er en dynamisk schedulering. For hver epoke så deles det ut nye tics. Og her er en sånn statistikk i Linux kjerne 2.4, som var gjennomsnittlig time-countum på 210 millisekunder.", "source": "lecture"}
{"lecture_id": "os8del11", "chunk_id": "os8del11_0007", "start": 480.0, "end": 571.44, "token_count": 292, "text": "En time-countum vil da kunne variere, sånn statistisk. For dette er en dynamisk schedulering. For hver epoke så deles det ut nye tics. Og her er en sånn statistikk i Linux kjerne 2.4, som var gjennomsnittlig time-countum på 210 millisekunder. Altså man måler og ser hvor langt er time-countum-en når du kjører en masse prosesser på... Og i 2006 var det omtrent 100 millisekunder. Hva var en epoke igjen? Jo, en epoke, det er liksom... Det er ikke en fast tid, men det er... Ved starten av en epoke, så har operativsummet, så sjekker den en ready-liste, altså en liste over alle prosesser  Det kan jo være noen som ligger i vektstilling eller venter på input og upput, eller av en eller annen grunn ikke ønsker å kjøre. Men alle prosesser som en ønsker å kjøre, de blir da tildelt et time-kontum. Da kan det være at Prosess A får 30 tics. Prosess B får 20 tics. Prosess C får 10 tics. Så setter man i gang og kjører.", "source": "lecture"}
{"lecture_id": "os8del11", "chunk_id": "os8del11_0008", "start": 550.32, "end": 631.32, "token_count": 299, "text": "eller venter på input og upput, eller av en eller annen grunn ikke ønsker å kjøre. Men alle prosesser som en ønsker å kjøre, de blir da tildelt et time-kontum. Da kan det være at Prosess A får 30 tics. Prosess B får 20 tics. Prosess C får 10 tics. Så setter man i gang og kjører. Epoken defineres da av det tidsrommet 30 pluss 20 pluss 10. Og hvis ikke noe spesielt skjer, så kjøres de 60 ticsene, og så starter man på nytt igjen. Men da kan det være litt avhengig om prosessen faktisk har brukt opp sine tics.  Så kan Operativstemme dynamisk da tildele tics etter hvor mange man har brukt. Det typiske er at hvis man ikke bruker noe særlig med tics, så får man flere neste gang, sånn at man får høyere prioritet. Det er en del oppgaver denne uken, og så kan man også se på den vaffelrør-skreduleringen. Der bruker jeg akkurat dette her. Nå evaluerer de forskjellig. Vaffelprosessen og forelesningsprosessen har litt forskjellig prioritet.", "source": "lecture"}
{"lecture_id": "os8del11", "chunk_id": "os8del11_0009", "start": 611.72, "end": 643.12, "token_count": 110, "text": "Det er en del oppgaver denne uken, og så kan man også se på den vaffelrør-skreduleringen. Der bruker jeg akkurat dette her. Nå evaluerer de forskjellig. Vaffelprosessen og forelesningsprosessen har litt forskjellig prioritet. Men hvis det kommer et time-tick, så kan det være at den samme prosessen fortsetter litt til. Og det er for å gjøre det mer effektivt.", "source": "lecture"}
{"lecture_id": "os9del12", "chunk_id": "os9del12_0000", "start": 0.0, "end": 105.58, "token_count": 300, "text": "Avslutte prosesser... Det er mange måter å stoppe prosesser på. Vi kan ha en normal avslutning, frivillig. I et chell kan jeg skrive 'exit'. Da stopper vi, eller i C - exit. Så kan vi ha en avslutning med feil. Det er også frivillig. Men så kan man ha fatale feil. At det er en ufrivillig situasjon hvor det er vanskelig for operativstøtten å gå videre. F.eks. deling med null. Hvordan skal du da kunne gå videre? Da kan hele programmet krasje. Også hvis et program prøver å skrive til en del av minnene som en ikke har lov til, eller gjøre noe virkelig galt. Da får du gjerne en sånn segmentation fault. Og det betyr at det er et eller annet minneprogram. Fatal feil som programmet gjør, og at det da vil avsluttes. Så kan du bli drept av andre prosesser. I Linux har vi sett for eksempel kjørekill eller terminert prosess i Windows. I motsetning til Unix, som er hva... Jo... Unix er så mangt, men hvis vi ser på Linux, så er Linux stort sett skrevet i C.", "source": "lecture"}
{"lecture_id": "os9del12", "chunk_id": "os9del12_0001", "start": 73.36, "end": 178.04, "token_count": 296, "text": "Så kan du bli drept av andre prosesser. I Linux har vi sett for eksempel kjørekill eller terminert prosess i Windows. I motsetning til Unix, som er hva... Jo... Unix er så mangt, men hvis vi ser på Linux, så er Linux stort sett skrevet i C. Det er noen ganger i uken når du skal se på alle kodelinjene i kildekoden. Dere vil da se at de aller fleste linjene er C. Ikke objektorientert. Det vil si at Linus-jern er da ikke bygd opp av objekter. Men den er jo veldig modulær. Hvis man har et objektorientert språk, så er man fullstendig tvunget til å skrive objekter og gjøre det modulært med objekter og metoder osv. Men det går også an å skrive programmer i programmeringsspråk som ikke er objektorienterte, på en veldig ryddig, modulær og systematisk måte. Det kan man jo si Linux er, men i utgangspunktet så er da Linux ikke objektorientert. Det har ikke... Rett og slett fordi ser programmeringsspråkets krefter ikke er objektorienterte.", "source": "lecture"}
{"lecture_id": "os9del12", "chunk_id": "os9del12_0002", "start": 157.8, "end": 254.98, "token_count": 283, "text": "som ikke er objektorienterte, på en veldig ryddig, modulær og systematisk måte. Det kan man jo si Linux er, men i utgangspunktet så er da Linux ikke objektorientert. Det har ikke... Rett og slett fordi ser programmeringsspråkets krefter ikke er objektorienterte. Men at det ikke er objektorientert, betyr ikke at det ikke er metoder og funksjoner osv. Det har det. Så det er veldig systematisk oppbygd, men det har ikke en eksplisitt objektorientering. Signaler... Ja, det har vi. Sett på tidligere... Jeg hadde et script som... Som jeg kjørte, og som brukte en kommando som heter trapp til å fange opp signaler. Det er ikke den trappen man har i kjernen, men den... En Shell-kommando som kan ta ut mot et kill-signal. F.eks. kontroll C er vel kill-signalet 2. Og så kan den behandle... Alle prosesser kan ta imot signaler og beholde dem. Et unntak er kill-minus-ni. Det er en sånn sure kill, så den vil drepe prosessen.", "source": "lecture"}
{"lecture_id": "os9del12", "chunk_id": "os9del12_0003", "start": 229.44, "end": 281.0, "token_count": 163, "text": "En Shell-kommando som kan ta ut mot et kill-signal. F.eks. kontroll C er vel kill-signalet 2. Og så kan den behandle... Alle prosesser kan ta imot signaler og beholde dem. Et unntak er kill-minus-ni. Det er en sånn sure kill, så den vil drepe prosessen. Jeg kjørte en liten demo av den i en tidligere forelesning, så jeg kan legge inn en link tilbake dit. Så kan man studere hvordan man kan sende signaler til prosesser. Det er måten prosesser kommuniserer på. Det er ikke nødvendigvis kill, men man kan sende signaler om andre ting også.", "source": "lecture"}
{"lecture_id": "linux6del2", "chunk_id": "linux6del2_0000", "start": 0.0, "end": 93.8, "token_count": 277, "text": "Brukere i Linux er definert ut ifra en linje i passordfilen. Så hvis vi tar en titt på passordfilen, så er dette hele passordfilen på Linux V med alle brukerne. Og vi ser den første brukeren er RUT-brukeren. Så hvis man gjør sudo su, så blir man RUT. Det kan man da se ved... Sudo SU..\"Who am I?\" Da ser vi... Jo, jeg er Ruth. Og det kan være greit å bruke 'who am I' når man går inn og ut i rollen som Ruth, og i rollen som andre brukere. Igjen, hvis vi ser på passordfilen, så er det da flere brukere definert nedover her. Sys og Synk, som er sånne systembrukere. WWW Data, f.eks., som... Brukeren som kjører webserveren når du starter opp den. Nederst kommer de mer menneskelige brukerne. Group 100 ligger her. Det er da en vanlig bruker på systemet. I etcpassword ligger da alle brukerne definert. Og her er det også definert hjemmemappen. Homegroup100. Det er hjemmemappen for denne brukeren.", "source": "lecture"}
{"lecture_id": "linux6del2", "chunk_id": "linux6del2_0001", "start": 64.84, "end": 162.88, "token_count": 289, "text": "Nederst kommer de mer menneskelige brukerne. Group 100 ligger her. Det er da en vanlig bruker på systemet. I etcpassword ligger da alle brukerne definert. Og her er det også definert hjemmemappen. Homegroup100. Det er hjemmemappen for denne brukeren. Og så er det definert defaults passord og hvilken gruppe som brukeren er medlem av. Og i tillegg en UID. Dette er UID-en. 1000. Bruker-ID. 998 er gruppe-ID-en som denne brukeren er med. Alle brukere har en UID, og alle brukere er med i minst én gruppe. Være med i flere grupper. Og flere grupper... Eller hvilken gruppe man er med i, det kan man se i med kommandoen 'groups'. Så denne brukeren er med i group 100, som er en default gruppe for denne brukeren. Og i tillegg er den med i sudogruppen. Alle grupper kan man se i en fil som heter Etsgroup. Her ser vi det er en rekke grupper, f.eks. Group 100, som er de forholdt, Krontab osv. Så kan vi se om vi ser sudo her. Her ser vi en linje for sudo.", "source": "lecture"}
{"lecture_id": "linux6del2", "chunk_id": "linux6del2_0002", "start": 142.48, "end": 238.8, "token_count": 289, "text": "Alle grupper kan man se i en fil som heter Etsgroup. Her ser vi det er en rekke grupper, f.eks. Group 100, som er de forholdt, Krontab osv. Så kan vi se om vi ser sudo her. Her ser vi en linje for sudo. Denne linja betyr at sudo er gruppe nummer 27, og Group 100 er med i sudo. Det at Group 100 er med i sudo, gjør at denne brukeren får sudorettigheter. Ved å se i filen... Den har jeg ikke lov til å se på når jeg ikke er Ruth, så da kan jeg ta Sudo. Og her står det en linje som sier at alle medlemmer av gruppen Sudo har alle disse rettighetene. Og det betyr at de kan gjøre hva som helst og bli Ruth med Sudo SU. Så kan man... Med ruterettigheter så kan man legge til nye brukere. Så jeg kan f.eks. si at jeg ønsker å legge til en bruker. Da kan jeg bruke kommandoen add user. Så la oss si jeg ønsker å legge til en bruker med navn S123456. Da blir jeg bedt om å gi denne brukeren et passord.", "source": "lecture"}
{"lecture_id": "linux6del2", "chunk_id": "linux6del2_0003", "start": 210.0, "end": 298.68, "token_count": 293, "text": "Så kan man... Med ruterettigheter så kan man legge til nye brukere. Så jeg kan f.eks. si at jeg ønsker å legge til en bruker. Da kan jeg bruke kommandoen add user. Så la oss si jeg ønsker å legge til en bruker med navn S123456. Da blir jeg bedt om å gi denne brukeren et passord. Og da er det veldig viktig å lage et godt passord som er langt nok, bruker litt forskjellige tegn, gjerne store bokstaver, tall osv. Men hvis man har et vanskelig brukernavn, eller et spesielt brukernavn, så gjør det også sjansen mindre for at noen skal hacke seg inn med Brute Force Attack. Den informasjonen som kommer her, det er bare å trykke på 'enter' hele tiden. Man trenger ikke å legge inn en informasjon. Man kan legge inn hvis man vil med fullt navn osv., men man må ikke. Så jeg bare svarte blankt på alle spørsmålene. Og'return' her, da svarte jeg egentlig 'ja'. Når jeg har gjort det, så kan du se at i passordfilen der, så skal det ha kommet...", "source": "lecture"}
{"lecture_id": "linux6del2", "chunk_id": "linux6del2_0004", "start": 279.44, "end": 381.16, "token_count": 286, "text": "med fullt navn osv., men man må ikke. Så jeg bare svarte blankt på alle spørsmålene. Og'return' her, da svarte jeg egentlig 'ja'. Når jeg har gjort det, så kan du se at i passordfilen der, så skal det ha kommet... Og det ser vi nederst her. Så har det kommet en ekstrabruker med UD 1001 og gruppe nummer 1000. Denne brukeren er i utgangspunktet ikke-studiouser. Så hvis du lager en ny bruker, så blir den brukeren ikke-studiouser. Men man kan gjøre brukeren til studiouser ved å bruke... En kommando som heter ADD GROUP. Oi... ADD GROUP. Sånn. Og jeg ønsker å gjøre S1-2-3-4-5-6 til sudo-user. Så da må jeg adde denne brukeren til gruppen sudo på den måten. Da ser vi... Adding user til sudo. Og da kan vi se at... S123. Nå vil ha... Nå vil også være tilføyd i en linje i ettertidsgruppe S12356. Så det kan man også sjekke ved Groups SN2356.", "source": "lecture"}
{"lecture_id": "linux6del2", "chunk_id": "linux6del2_0005", "start": 346.84, "end": 394.98, "token_count": 122, "text": "Så da må jeg adde denne brukeren til gruppen sudo på den måten. Da ser vi... Adding user til sudo. Og da kan vi se at... S123. Nå vil ha... Nå vil også være tilføyd i en linje i ettertidsgruppe S12356. Så det kan man også sjekke ved Groups SN2356. Da får man beskjed om at jo, denne brukeren er med i sudogruppen. Gjøre sudo-SU og bli rundt og gjøre installasjoner osv.", "source": "lecture"}
{"lecture_id": "os11del2", "chunk_id": "os11del2_0000", "start": 0.0, "end": 89.36, "token_count": 282, "text": "Forrige gang så vi på plattformavhengighet aller først. Hva som skjedde når man flytter programmet rundt på plattformer. Og hovedkonklusjonen er at programmer som er kompilert, sånn som C og C pluss, som kompileres til maskinkode, de er helt plattformavhengig. Det betyr at de kan... Man bare kjører der de er kopilert på den plattformen de er kopilert. De fleste moderne språk, sånn som Java og Python, CSharp også, de kjører virtuelle maskiner. Sånn at da kompilerer man til en eller annen type bite-kode. Og så kjøres de i en virtuell maskin. Så da går det an å flytte komplisert kode fra en plattform til en annen. Men det kan ha litt avhengighet av versjoner, som vi så sist. Så begynte vi å se på tråder. Vi så litt teoretisk på tråder, men vi fikk ikke sett så veldig mye på det rent praktisk. Så vi skal ta en kjapp rekapitulering av Java-tråder.", "source": "lecture"}
{"lecture_id": "os11del2", "chunk_id": "os11del2_0001", "start": 66.76, "end": 97.04, "token_count": 102, "text": "Men det kan ha litt avhengighet av versjoner, som vi så sist. Så begynte vi å se på tråder. Vi så litt teoretisk på tråder, men vi fikk ikke sett så veldig mye på det rent praktisk. Så vi skal ta en kjapp rekapitulering av Java-tråder. Så se på spesielt mange samtidige tråder, så vi kan starte med det...", "source": "lecture"}
{"lecture_id": "os13del6", "chunk_id": "os13del6_0000", "start": 0.0, "end": 88.76, "token_count": 293, "text": "Minnepyramiden. Den har vi også sett på videre. Dette er det veldig viktig å hamse i. Vi starter helt innerst her med registeret. Og her... Registrene er ekstremt hurtige. Og så er det altså med avstand. Registrene ligger inne i CPU-en. Når man kopierer mellom registrene på mindre enn et nanosekund... Altså typisk på én eller to klokkesykler... Så kan man kopiere mellom registrene. Mens LNCash er da fortsatt SRAM. Det er på en måte samme teknologi, men det ligger litt lenger ut, så det tar litt lengre tid. Og så kommer det enda lenger ut El2Cash. El3Cash er gjerne hakket utenfor der igjen også. Så kommer man ut til ramme- eller internminet, og der ser vi at det er en fakta på minst ti inn til registrene. Det er denne forskjevnen som gjør at cash er så viktig. Man klarer rett og slett ikke å få inn data fort nok til CPU-en uten å bruke cash. Så kommer vi et hakk ut til disker. SolidState-disker. Skal se mer på det senere.", "source": "lecture"}
{"lecture_id": "os13del6", "chunk_id": "os13del6_0001", "start": 69.68, "end": 154.94, "token_count": 289, "text": "Det er denne forskjevnen som gjør at cash er så viktig. Man klarer rett og slett ikke å få inn data fort nok til CPU-en uten å bruke cash. Så kommer vi et hakk ut til disker. SolidState-disker. Skal se mer på det senere. Har random axs på samme måte som ram. At du kan ta like lang tid å hente en hvilken som helst bite, men det går mye saktere. Det er en fakta på i hvert fall 1000 i forhold til ram. Og så har du kanskje grovt sett en fakta på 1000 til igjen ut til fysiske harddisker som spinner rundt. Så der går det veldig mye saktere.  Internminnet er... Eller RAM er egentlig bare et kjempesvært array av bites med en nummerering. Så vi ser her nede, adresse 0... Her er det 8-bit som utgjør én bite. Og så er det adresse 1 osv. oppover. Og her ser du 42... Dette er to i 32. Så dette er... Fire giga med adresser. Og dermed har du fire gigabyte med ram i dette RI-et.", "source": "lecture"}
{"lecture_id": "os13del6", "chunk_id": "os13del6_0002", "start": 130.94, "end": 201.0, "token_count": 209, "text": "Her er det 8-bit som utgjør én bite. Og så er det adresse 1 osv. oppover. Og her ser du 42... Dette er to i 32. Så dette er... Fire giga med adresser. Og dermed har du fire gigabyte med ram i dette RI-et. Så det er viktig å huske... Det er bare ett stort RI som programmerer, så kan vi tenke på det. Og med bites som ligger etter hverandre. Så har vi sett tidligere hvordan f.eks. vi har lagret en... En 64-bit... Så vi lager det som en integer som trenger da fire bite. Og da setter man typisk av de fire bitene etter hverandre til en variabel. Det er en litt sånn teknikalitet. Men i virkeligheten så er det bare bite som ligger etter hverandre i et svært ærøy.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0000", "start": 0.0, "end": 87.72, "token_count": 290, "text": "Ja, aller først så er det veldig hyggelig. Fortsatt veldig hyggelig å se at det er så mange som står opp tidlig om morgenen. Dessverre så ser det jo ikke så lyst ut med tanke på fysiske forløsninger. Og i hvert fall ikke noe før påske. Så kanskje først blir det noe vi tar noen, så en sånn... Prøveeksamen... i mai. Da kan vi kanskje få til... Det ser litt dårlig ut nå foreløpig, men vi får bare prøve å holde ut, alle sammen. Temaet i dag er plattformavhengighet og treads. Plattformavhengighet er ganske morsomt, og det er veldig sånn konkret. Vi skal bare se på hvordan tar det seg ut når man... Kopierer programmer mellom forskjellige plattformer. Stort sett så skal vi se det praktisk an. Jeg har en litt større demo hvor jeg kopierer masse programmer og på en masse plattformer. Og plattformer er typisk et gitt operativsystem på en gitt type CPU. Linux på Intel eller Windows på AMD, f.eks. Det er én plattform.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0001", "start": 65.12, "end": 160.5, "token_count": 289, "text": "Stort sett så skal vi se det praktisk an. Jeg har en litt større demo hvor jeg kopierer masse programmer og på en masse plattformer. Og plattformer er typisk et gitt operativsystem på en gitt type CPU. Linux på Intel eller Windows på AMD, f.eks. Det er én plattform. Og plattformuavhengige programmer, det skal man ha. Man kunne da kopiere fra en plattform til en annen, og så skal de kunne kjøre uten videre. I tillegg så skal vi se på treads, eller tråder. Spesielt så skal vi se på javatråder i dag. Men vi skal ha en generell innledning, sånn teoretisk, om tråder og hva det er. Og så skal vi som vanlig gjøre en del praktisk. Det er det samme prinsippet bak Petrads tråder. Ja, så det er planen. Jeg tenkte aller først å se litt på det som er på en måte litt... Eldre notater, som er fra et eksperiment som jeg kjørte for noen år siden. Men i prinsippet så ligner det på det vi skal gjøre nå. Men det kan være greit å få en litt bredere forståelse for...", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0002", "start": 134.28, "end": 227.08, "token_count": 288, "text": "Jeg tenkte aller først å se litt på det som er på en måte litt... Eldre notater, som er fra et eksperiment som jeg kjørte for noen år siden. Men i prinsippet så ligner det på det vi skal gjøre nå. Men det kan være greit å få en litt bredere forståelse for... En litt bredere forståelse for plattformavhengighet. Men kanskje aller først det vi holdt på med sist. Da så vi på... Ja, det siste vi så på, var systemkald. Og hvordan det i praksis ser ut... Når man måler tiden på programmer, så kjøres en god del instruksjoner i curl-mode. Og da spesielt med systemcall. En default, hvis det ikke er noe spesielt som skjer, hvis du bare regner, f.eks., så kjøres alt i use-mode. Og det kan vi se med time. Så så vi på prioritet, og spesielt på nice. Hvordan man da... Da kan man prioritere ved å tildele tics til prosesser. Og nice kunne gjøre sånn at man var veldig snill med andre og tildelte... Bare si 'Jeg vil ha veldig få tics'.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0003", "start": 206.16, "end": 291.72, "token_count": 279, "text": "Så så vi på prioritet, og spesielt på nice. Hvordan man da... Da kan man prioritere ved å tildele tics til prosesser. Og nice kunne gjøre sånn at man var veldig snill med andre og tildelte... Bare si 'Jeg vil ha veldig få tics'. Og det kan f.eks. være nyttig sånn... Ja, når jeg editerer videoer på laptopen min, så den har åtte super-UR, Og kjører kanskje 16 sånne videoredigeringsjobber i parallell. Da kan det være nyttig å sette 'nice' på de, for da fungerer laptopen fortsatt ok. Og de prosessene som står og heltingen skal jobbe, de bare tar seg selv på utid når ingen andre ber om det. Og da fungerer systemet fortsatt bra. At alle prosesser som kjører, de skal få sippe ut dit når de trenger det. Så så vi også litt på prosessforløp, som vi begynner å bli ganske gode på nå. Hva som skjer med prosesser i et system. Og til slutt på OS-arkitektur.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0004", "start": 270.0, "end": 357.74, "token_count": 295, "text": "At alle prosesser som kjører, de skal få sippe ut dit når de trenger det. Så så vi også litt på prosessforløp, som vi begynner å bli ganske gode på nå. Hva som skjer med prosesser i et system. Og til slutt på OS-arkitektur. Hvordan selve arkitekturen av et operativsystem ser ut. Selve operativsystemprogrammet. I dag så skal vi... I første omgang så tenkte jeg bare å vise hvordan det ser ut når man mer teoretisk kjører JavaC og Bæsj-programmer under forskjellige OS. Og de eksemplene jeg har i utgangspunktet, er da Linux på vanlig PC, eller en laptop, som kjører X86-institusjoner. Den kjører... det er kanskje ikke en pency man kjører, det er vel en Seon som jeg har på laptopen nå. Men uansett, den kjører og forstår Exo 86-instruksjoner. Akkurat som det vi har sett på heltiden. I dag skal vi se på noen andre instruksjonssett. Men i tillegg har jeg en Windows-maskin som kjører på i dette tenkte eksperimentet,", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0005", "start": 337.78, "end": 433.98, "token_count": 299, "text": "Men uansett, den kjører og forstår Exo 86-instruksjoner. Akkurat som det vi har sett på heltiden. I dag skal vi se på noen andre instruksjonssett. Men i tillegg har jeg en Windows-maskin som kjører på i dette tenkte eksperimentet, Og kjører den på akkurat den samme Intel-PC-en. Det er bare sånn dual-boot. Så en booter da opp på den helt samme Intel-PC-en, og har de samme X86-institusjonene sånn underliggende. Men det tredje eksempelet er operativsystemet Solaris. Og det er et Sun operativsystem. Sun var et Unix-firma som da, som typisk Unix-firmaer flest på 90-tallet og 2000-tallet, de bygde sin egen hardware og hadde sitt eget operativsystem som de kjørte alle institusjonene på. Og da hadde Sun kjørt på en Spark-prosessor, og den... Den maskinen hadde da bare Spark maskininstruksjoner, som var helt forskjellige fra X86-maskininstruksjoner. Like forskjellige som X86 er fra de maskininstruksjonene som vi hadde i det simulerte ZPU.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0006", "start": 410.44, "end": 492.68, "token_count": 294, "text": "Og da hadde Sun kjørt på en Spark-prosessor, og den... Den maskinen hadde da bare Spark maskininstruksjoner, som var helt forskjellige fra X86-maskininstruksjoner. Like forskjellige som X86 er fra de maskininstruksjonene som vi hadde i det simulerte ZPU. Etterpå, når vi skal kjøre en demo av plattformen uavhengig, så skal vi da se på et tredje instruksjonssett, nemlig ARM-instruksjonssettet. Som er verdens vanligste institusjon sett, for det er det som kjører på alle mobiltelefoner. Men det kan også brukes på servere. Vi skal kjøre på noen servere og sammenligne med hvordan det ser ut i forhold til Intel. Men det viktigste å ha med her er at dette er institusjoner som er helt forskjellige fra X86-institusjoner, som er det vi er vant til. Hvis du logger inn på laptoper eller servere, så finner du X86-institusjoner i CPU-en. Men det kan da være forskjellig operativstemme på toppen av det. Og den sammenkoblingen kaller vi en plattform.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0007", "start": 474.2, "end": 572.48, "token_count": 297, "text": "som er det vi er vant til. Hvis du logger inn på laptoper eller servere, så finner du X86-institusjoner i CPU-en. Men det kan da være forskjellig operativstemme på toppen av det. Og den sammenkoblingen kaller vi en plattform. Så... Dette er det samme eksempelet som vi skal bruke senere. Hello.java. Det er bare et javaprogram som skriver ut Hello World. Og når vi kompilerer det på Linux, så kompilerer vi sånn... Og da lages en Java class-fil. Og den inneholder da Java bite-kode. Og det er kode som er for en JVM eller en Java virtuell maskin. Så vi kan se på bildet her nede. Det ser ut som noe sånt som dette. Så vi kompilerer, og så får vi en hello.class-fil. Og da er det helt essensielt at dette er helt forskjellig fra A.out, som vi har sett på tidligere, som inneholder maskinkode. Som er da instruksjoner for X86. X86-instruksjoner... A.out kjører på en måte direkte på X86. Men Hello.class kjører inne i en JVM, en Java-virtuell maskin.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0008", "start": 547.26, "end": 629.54, "token_count": 278, "text": "fra A.out, som vi har sett på tidligere, som inneholder maskinkode. Som er da instruksjoner for X86. X86-instruksjoner... A.out kjører på en måte direkte på X86. Men Hello.class kjører inne i en JVM, en Java-virtuell maskin. Og da er hele poenget som gjør Java plattform uavhengig, at på Linux er det en egen Linux-JVM, på Windows er det en annen Windows-JVM, og på Solaris er det en Solaris-JVM. Så på den måten så kan Hello.class kjøres på alle disse plattformene,  Og man kan til og med ta Hello Let Class herfra, kopiere over på en Windows-maskin og få den til å kjøre. Og så kan den kopiere over på en sparkmaskin. Og så kjører den likevel fordi den har en JVM som tolker instruksjonene. Det blir litt overhead. Ting går litt saktere. Men Java er veldig god på overhead. Opp gjennom årene så er den klar... Og har klart å optimalisere veldig, sånn at det faktisk går nesten like raskt", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0009", "start": 602.8, "end": 699.76, "token_count": 293, "text": "Og så kjører den likevel fordi den har en JVM som tolker instruksjonene. Det blir litt overhead. Ting går litt saktere. Men Java er veldig god på overhead. Opp gjennom årene så er den klar... Og har klart å optimalisere veldig, sånn at det faktisk går nesten like raskt å kjøre Java som å kjøre kopilert C-kode. Det skal vi se på senere. Det er det en del om i onsdagsforelesningene, de digitale forelesningene, og noen oppgaver denne uken som går på akkurat det, å sammenligne tider. Og se hvor fort ting går. Med Java og Python og andre produksjoner. Men igjen, det vesentlige her... Hello, the class... Det er en helt egen... Man kan si at det er et maskinspråk, dette også, men det er for en virtuell maskin. Så vi skal se på det i detalj senere, hvordan instruksjonene i Bite-koden til Java ser ut. Og det er faktisk mulig å lage hardware... Java virtuell maskin, men man kaller det Java reell maskin. Det har blitt laget reell hardware som kjører Class-kode direkte.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0010", "start": 669.44, "end": 773.24, "token_count": 298, "text": "men det er for en virtuell maskin. Så vi skal se på det i detalj senere, hvordan instruksjonene i Bite-koden til Java ser ut. Og det er faktisk mulig å lage hardware... Java virtuell maskin, men man kaller det Java reell maskin. Det har blitt laget reell hardware som kjører Class-kode direkte. Med prinsippet er det samme. Dette med virtuelle maskiner gjelder også sånn som Python og Csharp og Pearl. De kjører på virtuelle maskiner på denne måten. En tradisjonell, sånn som C og C pluss, kompileres det, så kjører man direkte på hardware. Så plattformuavhengighet er at man kan ta Hello.class-filer og kopiere over til andre plattformer og kjøre de der som om ingenting skulle ha skjedd. Så kom vi til hello.c, og dette er da et program som er i høyeste grad plattform avhengig av. For når vi komplerer hello.c, sånn som vi har gjort mange ganger, så ser vi at så får vi en adopt-out, og den vil inneholde X86-instruksjoner. Sånn som denne her. Move X til X. Og det er klart.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0011", "start": 749.88, "end": 846.52, "token_count": 296, "text": "som er i høyeste grad plattform avhengig av. For når vi komplerer hello.c, sånn som vi har gjort mange ganger, så ser vi at så får vi en adopt-out, og den vil inneholde X86-instruksjoner. Sånn som denne her. Move X til X. Og det er klart. Instruksjonene forstås bare av en X86-CPU. Altså en CPU som har innebygd, brent inn X86-instruksjoner fra bunnen av. Den kan ikke forstå spark-instruksjoner, f.eks. Så her, med object dump fra en ADA-doktal, så kan du se hvilke instruksjoner som... Det Object Dump gjør her, er på en måte det motsatte av Assembly. I tillegg har vi sett på en Assembly hvor vi går fra Assembly-kode til maskinkode. Men denne her på en måte viser hva maskinkodene inneholder. Og hvis vi gjør dette her på Solaris... Dette er et eksperiment vi gjorde det på Solaris. Så vil vi rett og slett se at her er det andre institusjoner. Det har faktisk ad og sub, men du ser... Ad har tre argumenter. Her oppe har det to.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0012", "start": 822.2, "end": 913.04, "token_count": 300, "text": "Og hvis vi gjør dette her på Solaris... Dette er et eksperiment vi gjorde det på Solaris. Så vil vi rett og slett se at her er det andre institusjoner. Det har faktisk ad og sub, men du ser... Ad har tre argumenter. Her oppe har det to. Så fins det en del andre... Det fins noen andre instruksjoner også, sånn som TST og LOD. Så dette er helt fundamentalt forskjellige maskininstruksjoner. ... så fungerer det dårlig. Så hvis jeg tar adopt-out, som er komplert for en Linux-maskin, og flytter over på Windows og prøver å kjøre det, så enten så skjer det ingenting, eller så får man en feilmelding om wrong binary eller et eller annet sånt. Og det til tross for at X86-institusjonene i bunnen er akkurat de samme. Så her er det move i, x, b, x osv. X86-institusjoner. Men et program må også snakke med operativsystemet. Og hvis du flytter over adopt-out hit, så kommer du inn på Windows, og så begynner du å snakke med Linux-biblioteket for å printe ut noe.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0013", "start": 894.28, "end": 971.76, "token_count": 294, "text": "Så her er det move i, x, b, x osv. X86-institusjoner. Men et program må også snakke med operativsystemet. Og hvis du flytter over adopt-out hit, så kommer du inn på Windows, og så begynner du å snakke med Linux-biblioteket for å printe ut noe. Og da er det klart at det fungerer dårlig. Da vil programmet ikke virke. Hvis vi tar adopt-out og så flytter over hit på Solaris, så... Vil dobbelt ikke fungere. Først prøver du å snakke med Linux-operativsystemet. Det går veldig dårlig. I tillegg prøver du å utføre X86-institusjoner på en helt annen arkitektur. Det er dømt til å mislykkes å prøve å kjøre alt og tapt på en plattform som har både et annet operativsystem og et annet instruksjonssett. For at man kan oppnå plattformuavhengighet ved å bruke virtuelle maskiner som da tolker koden her. Men det har også en pris, at ting går litt saktere. Men veldig mange programmeringsspråk har valgt det.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0014", "start": 951.16, "end": 1038.48, "token_count": 284, "text": "og et annet instruksjonssett. For at man kan oppnå plattformuavhengighet ved å bruke virtuelle maskiner som da tolker koden her. Men det har også en pris, at ting går litt saktere. Men veldig mange programmeringsspråk har valgt det. Men hvordan kan man kjøre et C-program på Windows eller Solaris? Jo, det som da er clouet, er at da må du gjøre ett stepp til. Du må kompilere. Du må ha en kompulator for den plattformen. Og da kan vi kompulere og få en A.xe, og så kan den kjøre på Windows. Eller en s.out, som man fikk til folk med GCC på Spark, på Solaris. Og da kan man kjøre C-programmet på denne plattformen. Men da er hele forskjellen... Du må kompilere og laste inn maskinkoden, og så kan du kjøre den. Og dermed er det da... Og dermed sier vi da at C-kode er ikke plattformavhengig. Nei, hva sier jeg nå? C-kode ER plattformavhengig. Viktig forskjell. Ikke der.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0015", "start": 1019.78, "end": 1124.32, "token_count": 300, "text": "Og dermed er det da... Og dermed sier vi da at C-kode er ikke plattformavhengig. Nei, hva sier jeg nå? C-kode ER plattformavhengig. Viktig forskjell. Ikke der. Det finnes ikke lenger, og det er en ganske utdøende rase, sånn de gamle typen Unix-maskiner. Det kjører sikkert en del sånne rundt omkring, akkurat som det fortsatt kjører i BEM stormaskiner, men de blir færre og færre. Det meste nå går på X86. Men det fins også servere som kjører på Arm. Det går også med Hello.bæsj. Altså kjøre et bæsjprogram på de forskjellige plattformene her. Det går fint på Linux og Spark, men da igjen... Da må du installere bæsj, og så kjøre det. Det ligner jo litt på en virtuell maskin, det også, for da må du tolke det. På Window går det ikke i utgangspunktet. Men hvis du f.eks.... Du kan installere Linux på Windows. Og da kjører Linux rett på X86. Og i tillegg så kan du da installere et bæsjel.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0016", "start": 1095.16, "end": 1187.54, "token_count": 277, "text": "Det ligner jo litt på en virtuell maskin, det også, for da må du tolke det. På Window går det ikke i utgangspunktet. Men hvis du f.eks.... Du kan installere Linux på Windows. Og da kjører Linux rett på X86. Og i tillegg så kan du da installere et bæsjel. Det kan du på andre måter òg. Så det er mulig å installere Vers på Windows. Sånn at du kan kjøre skript der. Det var en lang innledning om plattformavhengighet. Og så skal vi se på dette i praksis. Da skal jeg gjøre en demo hvor jeg kjører på de følgende fem plattformer her. For det første så har jeg laptopen min, som er en Linux ubundet 1804. Det har jeg kjørt eksempler på i hele vår. Og den har da X86-institusjoner. Så det er viktig å ha klart for seg. Intel og AMD, de CPU-ene, begge de har X86-institusjoner. Så har jeg noen forskjellige Java-versjoner. Java 11 og Python 36 på denne.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0017", "start": 1164.3, "end": 1262.08, "token_count": 296, "text": "Det har jeg kjørt eksempler på i hele vår. Og den har da X86-institusjoner. Så det er viktig å ha klart for seg. Intel og AMD, de CPU-ene, begge de har X86-institusjoner. Så har jeg noen forskjellige Java-versjoner. Java 11 og Python 36 på denne. Og det er et viktig poeng etter hvert, når vi kjører på andre Java-versjoner. Java er til dels avhengig av versjoner. Så spesielt så er det noen ganger gamle Java-programmer ikke virker på... Eller eldre Java-programmer virker på nyere, men hvis man kompilerer på en nyere Java-versjon, så virker det ikke alltid på de gamle. Men det skal vi se på. Så neste plattform jeg har, er en gammel Mac, en gammel Macbook Pro. Med Darwin-kjerne. Den ligner litt på... Det er en Unix av art. Men det er en variant av Unix. Derfra har man typisk et bachel i Pine Mac. Men det er samtidig en del forskjeller. Men... CPU-en er... En Intel-korduo som da også kjører X86-institusjoner. Så er Java6 og Python26...", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0018", "start": 1224.3, "end": 1333.16, "token_count": 282, "text": "Med Darwin-kjerne. Den ligner litt på... Det er en Unix av art. Men det er en variant av Unix. Derfra har man typisk et bachel i Pine Mac. Men det er samtidig en del forskjeller. Men... CPU-en er... En Intel-korduo som da også kjører X86-institusjoner. Så er Java6 og Python26... Python er en forskjell på Python3 og Python2, men vi skal se at Python er i større grad uavhengig av versjoner. Og så har jeg en DelServer med en AMD-CPU. Det er en svær server med 48 CPU-er. Men den også kjører på X86. Altså i tillegg er jeg vant til Python 2.7. Så kom vi inn noe som er faktisk en nyhet av året, selv om det ikke er helt nytt, og det er... Dette er en Linux ubundet 2004, men den kjører på en Arm CPU. Det er en Arm CPU som er lagd for servere. Vanligvis brukes Arm i mobiler. Derfor er de konstruert sånn at de bruker mindre strøm. Er ganske sånn lettvekt når det gjelder drift.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0019", "start": 1308.56, "end": 1394.32, "token_count": 291, "text": "Dette er en Linux ubundet 2004, men den kjører på en Arm CPU. Det er en Arm CPU som er lagd for servere. Vanligvis brukes Arm i mobiler. Derfor er de konstruert sånn at de bruker mindre strøm. Er ganske sånn lettvekt når det gjelder drift. Men tradisjonelt så har man alltid kjørt Exo 86, ikke alltid, de siste 10-15 årene har Exo 86 vært dominerende i serverrommet. Har det også begynt å komme arm-baserte servere. Dette er en sånn arm-basert server. Den kjører i Amazon... Elastic Cloud. Så dette er en cloud-server. Som jeg har kjøpt en VM på. Så dette er VM-er som man betaler per måned. Koster ikke veldig mye for én, men kjøper du en stor en, så koster det en del. Plattformen er en Windows Server 2019, som også er S2. Også Amazon Cloud. Men den kjører på en Intel Zeon Sippu. Altså den samme Sippuen som her oppe. Ikke helt samme, men samme Sippu-familie", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0020", "start": 1367.8, "end": 1470.6, "token_count": 291, "text": "Koster ikke veldig mye for én, men kjøper du en stor en, så koster det en del. Plattformen er en Windows Server 2019, som også er S2. Også Amazon Cloud. Men den kjører på en Intel Zeon Sippu. Altså den samme Sippuen som her oppe. Ikke helt samme, men samme Sippu-familie og igjen X86, Java 8 og Python 39. Så dette er de forskjellige plattformene, og så skal jeg nå prøve å gå inn på de. Så jeg kompilerer alt på denne. Fire programmer. Hello.c, hello.java, hello.python og hello.bash. Så kopierer jeg de til alle fire plattformene. Og så skal vi se hva som fungerer hvor. Jeg håper du har fått til en... Etter pause altså få til en liten... Så det er viktig å følge godt med hva som skjer. Men da skal vi gå over og se på... Håper dere er i stand til å se dette. Her er jeg nå i en mappe som heter Hello. Og i denne mappen har jeg... For det første så har jeg de fire programmene. Skal ta de først.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0021", "start": 1441.28, "end": 1576.0, "token_count": 300, "text": "Men da skal vi gå over og se på... Håper dere er i stand til å se dette. Her er jeg nå i en mappe som heter Hello. Og i denne mappen har jeg... For det første så har jeg de fire programmene. Skal ta de først. Hello.c. Det er da et c-program. Hello.java. Det er et Java Hello World. Og så har jeg hello.python. Og til slutt hello.special. Så tanken er nå å kopiere disse. Over til de andre plattformene. For å gjøre det har jeg et skjedskrift som heter dist.shell. Og det det gjør, er å kopiere hele denne mappen som jeg nå står i, den hello, til de andre plattformene. Dette er AMD-serveren. Dette er MacWoodson. De to siste kjører da på Amazon Cloud. Men før jeg gjør det, så er da hele ideen at jeg skal kompilere og kjøre programmene her. Og da har jeg et lite skrift som heter Compile. Det er bare C-programmet og Java-programmet som må kopieres først. Det har vi sett mange ganger. Java er sånn man kompilerer... Java-filler på Linux. Og når man gjør det, så lages det en hello.class. Så det er den vi da sender over.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0022", "start": 1540.72, "end": 1653.68, "token_count": 295, "text": "Og da har jeg et lite skrift som heter Compile. Det er bare C-programmet og Java-programmet som må kopieres først. Det har vi sett mange ganger. Java er sånn man kompilerer... Java-filler på Linux. Og når man gjør det, så lages det en hello.class. Så det er den vi da sender over. Så hvis jeg kjører compile, så kompilerer jeg altså hello.c. Så jeg får en ny versjon. Adopt-adt her. Og tanken nå er at nå skal jeg kopiere alle disse over til de andre plattformene. Der har jeg satt opp SSO-nøkler, sånn at du ser at de kopierer over til alle plattformene. Også på Windows har jeg satt opp SSO-nøkler. Det går an. Så gå inn på Windows med SSO også. Vi skal se på det senere. Det er litt mer knot å sette opp SSO-nøkler på Windows, men det er mulig å få til. Og så kan vi gå rundt på de andre plattformene og se hvordan det ser ut å kjøre de fire programmene. Da hopper vi først ned hit til... AMD-serveren. Altså det er en server som kjører Linux buntus 1604", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0023", "start": 1625.88, "end": 1739.96, "token_count": 297, "text": "men det er mulig å få til. Og så kan vi gå rundt på de andre plattformene og se hvordan det ser ut å kjøre de fire programmene. Da hopper vi først ned hit til... AMD-serveren. Altså det er en server som kjører Linux buntus 1604 på en AMD Oppdron. Ops. Skal vi prøve å få det vinduet... Nei. Ikke gjør noe helt galt her. Oi. Ja, forklar meg med det lille vinduet. Jeg trodde jeg skulle ha fått litt større. Nei, OK. Jeg skal kjøre i... Jeg kan ta det én av gangen. Jeg kan først starte med Adopt. Nå har jeg kompilert her oppe på Linux med Intel. Så har jeg kopiert det over hit. Og så kjører jeg det her på AMD-serveren. Og... og... ja... eh... dette var ikke så rart. For her kjører jeg out and out, men jeg står jo i... Jeg har ikke gått inn i mappen, så jeg må inn i Hello. Så dette beviser ikke så veldig mye. Men nå er jeg inne i mappen. Alt er kopiert over hit. Så nå kan jeg prøve å kjøre av dataet.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0024", "start": 1716.88, "end": 1809.36, "token_count": 285, "text": "For her kjører jeg out and out, men jeg står jo i... Jeg har ikke gått inn i mappen, så jeg må inn i Hello. Så dette beviser ikke så veldig mye. Men nå er jeg inne i mappen. Alt er kopiert over hit. Så nå kan jeg prøve å kjøre av dataet. Og da så jeg faktisk... Det fungerer. Det betyr ikke at C er plattform uavhengig. For hele poenget er at dette er samme plattform. Det er Linux på X86. Så selv om det er en annen Ubuntu-versjon og det er en annen prosessor, AMD, i stedet for Intel... Så vi har begge X86-institusjoner. Og da fungerer det å bare kopiere over alltid-og-talt på den måten. Ja, jeg kan kjøre eksplisitt, så vi kan ta JavaHello også. Når jeg kjører JavaHello, så ser vi at jeg får noen feilmeldinger. Man skulle tro dette fungerte, men det er en sånn... Et versjonsproblem. Denne versjonen av Java RunTime gjenkjenner bare ClassFives versjoner opp til 52.0.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0025", "start": 1771.92, "end": 1900.74, "token_count": 292, "text": "Ja, jeg kan kjøre eksplisitt, så vi kan ta JavaHello også. Når jeg kjører JavaHello, så ser vi at jeg får noen feilmeldinger. Man skulle tro dette fungerte, men det er en sånn... Et versjonsproblem. Denne versjonen av Java RunTime gjenkjenner bare ClassFives versjoner opp til 52.0. Uavhengig. Litt plattformavhengighet ser vi at det er. Men jeg kan kjøres og teste Python. Det fungerer fint. Og... Og Bæsj fungerer også fint. Det er ikke så overraskende. Så oppsummert, hvis jeg kjører... Python og Bæsj og AdultOut fungerer, men ikke... OK, da. Da kan vi hoppe til MacOS. Så kan jeg prøve å huske å gå inn her. Nå er jeg inne i riktig mappe i MacOS. Jeg har kopiert over alle de samme filene. Så kan jeg prøve å kjøre Adataut her. Og det går dårlig. Jeg får cannot execute binary file. Og det er ikke så rart når man tenker seg om, fordi... Selv om dette er en Intel-CPU med X86-institusjoner,", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0026", "start": 1867.26, "end": 1973.02, "token_count": 299, "text": "Nå er jeg inne i riktig mappe i MacOS. Jeg har kopiert over alle de samme filene. Så kan jeg prøve å kjøre Adataut her. Og det går dårlig. Jeg får cannot execute binary file. Og det er ikke så rart når man tenker seg om, fordi... Selv om dette er en Intel-CPU med X86-institusjoner, så er det et annet operativstem. Det er MacOST. Og A.out prøver å snakke med Linux-tjernen. Og dermed så går dette dårlig. Og så har vi samme problemet. Dette er Java 6, en eldre Java-versjon, så den kjenner ikke igjen den nyere Java 11-klassfilm. Python derimot... Den går fint. Men hva så med bæsjere? Ikke så helt opplagt. Det er bare en standard kommandolinje. Jo, Macbook har bæsjer installert, så den kjører helt fint. Ok. Da skal vi over på ARM. Etter pausen kan vi kanskje se litt mer på ARM i detalj, men hovedpoenget her er at de underleggende maskininstruksjonene her... CPU-ene som vi kjører på, den er helt forskjellig.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0027", "start": 1952.12, "end": 2073.48, "token_count": 299, "text": "Ok. Da skal vi over på ARM. Etter pausen kan vi kanskje se litt mer på ARM i detalj, men hovedpoenget her er at de underleggende maskininstruksjonene her... CPU-ene som vi kjører på, den er helt forskjellig. Et helt annet instruksjonssett. Så hvis jeg prøver å kjøre adat der, så ser vi at jeg får en... I serven så kjører ikke ADOT-AT. Og det er rett og slett fordi her er det ARM-instruksjoner. Det er helt annerledes. Jeg har et eksempel på hvordan disse hører ut i mappen over her. En SUM.s som er kompilert her. Her er en institusjon. Det er ikke så veldig forskjellig... Dette er bare én institusjon. Men vi har andre navn på registeret. Og det er andre institusjoner. Dermed er det umulig å ta en ADAT-fil. Eller hvilket som helst annet program som er kompilert med CSR++. Det kan man ikke bare kopiere over og kjøre på en maskin som har en arm-plattform. Derimot så kan vi prøve Java. Og Java funkerer fint her.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0028", "start": 2048.94, "end": 2159.08, "token_count": 293, "text": "Dermed er det umulig å ta en ADAT-fil. Eller hvilket som helst annet program som er kompilert med CSR++. Det kan man ikke bare kopiere over og kjøre på en maskin som har en arm-plattform. Derimot så kan vi prøve Java. Og Java funkerer fint her. Og det er fordi at her er det Java 14, så den er såpass ny at den... Den er faktisk nyere enn Java 11, så den tolker fint. Og... det er jo upuntu, så... hva heter det... Nei... jeg har holdt opp bæsj. Og bæsjgreitet kjører også fint. Så til slutt skal vi over på vindoss. Og her har vi også kopiert over alle fillene. Eller har dere merket at jeg kjører... Det er fordi dette er Windows PowerShell, som vi skal se på etter påske. Her fins alias for veldig mange Linux-kommandoer, sånn at man kan bruke Linux-kommandoer når man jobber med PowerShell. Så her har vi sammen med Love og Udre alt er kopiert over. Men da kan jeg prøve å kjøre Odd-out. Prikk, backslash... er det i stedet for prikk, slash?", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0029", "start": 2131.56, "end": 2242.76, "token_count": 291, "text": "Her fins alias for veldig mange Linux-kommandoer, sånn at man kan bruke Linux-kommandoer når man jobber med PowerShell. Så her har vi sammen med Love og Udre alt er kopiert over. Men da kan jeg prøve å kjøre Odd-out. Prikk, backslash... er det i stedet for prikk, slash? Prøver jeg å kjøre det, så ser jeg... Jeg får ingenting. Men jeg får i hvert fall ikke ut... Hello, Word. Jeg kunne prøvd å gjøre noe sånt som... Kalad.exe, for Windows er veldig sånn... I institusjonsnett... Nei, avhengig av extension på fillene. Men... Det eneste jeg får beskjed om, er at Adolt.exi ikke filtrer den... Man kan ikke kjøre den... Man klarer ikke å kjøre den filen. Og det er da fordi Adolt.no snakker med Linux-operativsystemet. Så da er det ikke så rart at den ikke kjører. Det er da ikke så rart at... ... at dette ikke fungerer. Og det til tross for at det er akkurat samme CPU. Det er en Intel CON CPU. Så maskininstitusjonene er de riktige.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0030", "start": 2204.1, "end": 2319.36, "token_count": 291, "text": "Så da er det ikke så rart at den ikke kjører. Det er da ikke så rart at... ... at dette ikke fungerer. Og det til tross for at det er akkurat samme CPU. Det er en Intel CON CPU. Så maskininstitusjonene er de riktige. Her er problemet igjen at A.no prøver å snakke med Linux-åpnet tidsstemme, så treffer den Windows-server, og da fungerer ingenting. Så dermed vil det ikke fungere. Java, derimot, kunne man i prinsippet tenke fungerte, men igjen så er det den run-time-problemet. Når vi går fra versjon 11 ned til versjon 8, så fungerer det. Pyton, derimot... Den fungerer fint. Den kjører på... ja, er det Pyton 3936, så det er ikke så rart at den kjører, men den oppfører seg fint. Så helt til slutt... hva med LOL-dukt-bæsj? Det skjer ikke noe der, men hvis jeg eksplisitt kjører sånn som... ... så ser vi at det faktisk fungerer. Men det er fordi her har jeg isolert den Linux-modulen.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0031", "start": 2289.76, "end": 2428.54, "token_count": 293, "text": "men den oppfører seg fint. Så helt til slutt... hva med LOL-dukt-bæsj? Det skjer ikke noe der, men hvis jeg eksplisitt kjører sånn som... ... så ser vi at det faktisk fungerer. Men det er fordi her har jeg isolert den Linux-modulen. Sånn at jeg har... sånn at jeg har et perser. Så jeg kan starte perser her og kjøre Linux-kommandoer som LS-minus. Men det som er interessant nå, er hva om jeg prøver... Det har jeg faktisk ikke testet. Hva om jeg prøver å kjøre a.alt her? Inne i Linux-modulen. Jo, det fungerer faktisk. Så her er det på en måte native Linux som kjører direkte på X86. Når jeg starter perset her inne, så får jeg opp et ekt... Eller... Det er faktisk en Linux-kjerne som kjører. Det er vel en... Jeg er ikke sikker på detaljene, om det er en virtuell maskin, men det er iallfall en ekte Linux-kjerne som kjører, sånn at man kan kjøre native Linux-programmer på denne videoen. Spørsmål i 17. Begge Linux-serverne.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0032", "start": 2369.32, "end": 2513.32, "token_count": 284, "text": "Eller... Det er faktisk en Linux-kjerne som kjører. Det er vel en... Jeg er ikke sikker på detaljene, om det er en virtuell maskin, men det er iallfall en ekte Linux-kjerne som kjører, sånn at man kan kjøre native Linux-programmer på denne videoen. Spørsmål i 17. Begge Linux-serverne. Hvis vi oppsummerer, så... Den fungerte her... Og her. Og også på Mac fungerte den. Ja, her kjørte jeg opp. Så... Ingen har forstått spørsmålet? Hei, heter du så. Jeg tenkte jeg skulle si ifra. Flott. Nei, det var denne her. Det var bare at jeg skrev feil. Så det var ikke Linux sin feil. Det var min feil som skrev noe feil. Kjørte Adotat mellom dem? Skal vi se... Ja, faktisk. Det var jeg litt... Det er ikke helt opplagt. Men her har vi bare tatt en Adotat, så kopiert rett over fra Linux-sipput på Intel, komplert for Intel Sipput, og så kopiert over hit. Det er fordi alt er likt.", "source": "lecture"}
{"lecture_id": "os10time1", "chunk_id": "os10time1_0033", "start": 2496.0, "end": 2552.28, "token_count": 159, "text": "Det er ikke helt opplagt. Men her har vi bare tatt en Adotat, så kopiert rett over fra Linux-sipput på Intel, komplert for Intel Sipput, og så kopiert over hit. Det er fordi alt er likt. Så om du kopierer her og kopierer tilbake, så får du også en samme effekt. Ja, det er riktig konkludert. Begge er X86-prosesser. Ok, da tar vi et kvarters pause. Og så skal vi legge opp en liten pause, sånn at vi med spørsmål... Så kan vi se litt mer på dette etter pause før vi begynner på tråder.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0000", "start": 0.02, "end": 110.52, "token_count": 280, "text": "Da skal vi begynne å jobbe med oppgave tolv. Den går ut på å sammenligne hastigheten til programmeringsspråk. I oppgaven skal vi sette opp en docker container som installerer alle programmeringsmiljøene. Som er nødvendig for å kjøre alle disse programmene. Kompilere og kjøre det. Det man først og fremst trenger, er disse verktøyene. Så kan man etterpå gå inn og kompilere og kjøre. I første omgang skal vi bare bygge en container som installerer alt som er nødvendig. Skal vi gå inn interaktivt og kjøre koden. Men det som er tanken, og som dere kan gjøre, inkludert i neste oppgave, det er å prøve å automatisere dette i enda større grad. Sånn at til slutt, i ukens største utfordring, så blir dere bedt om å gjøre alt dette her. Og automatisere det, sånn at man til slutt alt går automatisk. Og man setter opp en webserver som legger ut resultatene av kjøringene. På webserveren. Da vil det være lett å gjenta det samme", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0001", "start": 78.4, "end": 208.44, "token_count": 287, "text": "Sånn at til slutt, i ukens største utfordring, så blir dere bedt om å gjøre alt dette her. Og automatisere det, sånn at man til slutt alt går automatisk. Og man setter opp en webserver som legger ut resultatene av kjøringene. På webserveren. Da vil det være lett å gjenta det samme for andre versjoner. F.eks. se hvordan forskjellen blir med Ubuntu 1604. Så skal vi nå lage en dockercontainer som installerer disse miljøene. Bill Essential er for GCC for å kompilere CO-kode. JDK er for Java. Og i tillegg installerer vi Python. Programmene som skal brukes, de ligger på Github. Så jeg har et repository der som heter Zoom.git. Git er veldig enkelt å bruke fra kommandolinjen. Det er veldig nyttig å kunne bruke det fra kommandolinjen. For da kan man automatisere alt som har med å pushe og pulle kode osv. En OS-gruppe på Linux-VM går til OS70. Så da skal jeg dele et annet vindu med dere. Sånn. Og da er vi i deres land. Som dere ser her, så er jeg...", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0002", "start": 158.5, "end": 280.16, "token_count": 284, "text": "Det er veldig nyttig å kunne bruke det fra kommandolinjen. For da kan man automatisere alt som har med å pushe og pulle kode osv. En OS-gruppe på Linux-VM går til OS70. Så da skal jeg dele et annet vindu med dere. Sånn. Og da er vi i deres land. Som dere ser her, så er jeg... Jeg har nettopp kjørt et script, stop and remove, som sletter alt som er av dokker. Imager, containere osv. Stopper alt og sletter alt. Det kan være lurt å gjøre en gang iblant, når dere tester ut dette på Linux UM, for det er relativt lite plass. Som dere ser, har jeg 1,5 gigabyte nå. Så... Så nå som jeg har slettet alt, så må jeg også bygge alt fra scratch. Jeg tenkte jeg kunne ta... Kanskje aller først så kunne jeg vise hvordan... Skal vi se om jeg har en mappe som heter Sum. Nei. Så skal jeg vise hvordan... Oi. Da må jeg ha den kopien som jeg hadde. Jeg skal klone fra Gits. Da kopierer jeg strengen fra oppgave 12.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0003", "start": 246.08, "end": 352.3, "token_count": 290, "text": "Jeg tenkte jeg kunne ta... Kanskje aller først så kunne jeg vise hvordan... Skal vi se om jeg har en mappe som heter Sum. Nei. Så skal jeg vise hvordan... Oi. Da må jeg ha den kopien som jeg hadde. Jeg skal klone fra Gits. Da kopierer jeg strengen fra oppgave 12. Og så kloner jeg. Og da lages det en mappesum. Hvis jeg går inn i den mappen og ser, så ligger det en rekke... En rekke skript og programmeringsspråk der. Utgangspunktet er da bæsjskriptet, som vi ser... Som regner ut en løkke 50 000 ganger. Og de andre programmene regner da ut disse... Dette programmet, eller denne arbeidsoppgaven, X ganger. Så det vi skal finne ut, er hvem klarer flest sånne oppgaver på like lang tid. Dette må vi da få til å gjøre inni dokkercontaineren. Det jeg tenkte å gjøre da, er å ta utgangspunkt i det vi gjorde forrige gang. Skal vi se om jeg har... Da hadde jeg en mappe som het webserver.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0004", "start": 322.44, "end": 432.92, "token_count": 300, "text": "Så det vi skal finne ut, er hvem klarer flest sånne oppgaver på like lang tid. Dette må vi da få til å gjøre inni dokkercontaineren. Det jeg tenkte å gjøre da, er å ta utgangspunkt i det vi gjorde forrige gang. Skal vi se om jeg har... Da hadde jeg en mappe som het webserver. Det jeg tenkte, var bare å kopiere webserver. Til en mappe som heter Sum. Så går jeg inn i summappa, og så starter jeg... Oi. Nei, det ble feil. Da hadde jeg lagd en mappesum allerede. Så hvor endte den opp, da? Jo, da ble den vel kopiert inn der. For å rydde opp litt. Så tar jeg bort sum. Og så kopiere. Sånn. Nå har jeg en mappesum. Og så vil jeg i den mappa lage en dockyfile som gjør akkurat det jeg ønsker. Vi kan starte på samme måte som tidligere i forrige uke. Vi kan laste inn fra Ubuntu. Så kan vi kjøre Aptcat. Det er viktig å ha med minus Y, for dette må skje automatisk. Men da skal vi ikke installere Apasje denne gangen.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0005", "start": 404.46, "end": 518.44, "token_count": 298, "text": "som gjør akkurat det jeg ønsker. Vi kan starte på samme måte som tidligere i forrige uke. Vi kan laste inn fra Ubuntu. Så kan vi kjøre Aptcat. Det er viktig å ha med minus Y, for dette må skje automatisk. Men da skal vi ikke installere Apasje denne gangen. Og vi trenger heller ikke dette her. Men det vi trenger å installere, det er det som ble oppgitt på oppgaveteksten. Så da kopierer jeg litt derfra. De linjene under står det i oppgaveteksten at vi trenger. Da kan jeg tilpasse de til dokkefilen ved å passe på å legge til en Y. På de linjene så skulle det bli det samme. Men vi hopper over Apasje. Sånn. Og til slutt så installerer vi piten. Som vi husker fra forrige gang, så vil dette gjøres linje for linje. Så... Hvis jeg først har fått den første delen til å virke, og lagt inn de, så vil det gå raskt å legge på neste. I tillegg så må vi... Ingenting er gitt. Ingenting ligger i konteineren i utgangspunktet.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0006", "start": 494.78, "end": 608.44, "token_count": 285, "text": "Så... Hvis jeg først har fått den første delen til å virke, og lagt inn de, så vil det gå raskt å legge på neste. I tillegg så må vi... Ingenting er gitt. Ingenting ligger i konteineren i utgangspunktet. Den er så tom som bare mulig. Så vi må installere gits. Og så etterpå... Nei, jo... Så må vi også... Etter at vi har installert gits, så må vi gjøre en git-klov. Da må jeg gå ut i oppgaveteksten igjen og finne repositoriet. Det ligger da på Gitube. Og det er linjen til repositoriet. Så dette ser da ut som en OK dokkefeil. Så går jeg ned i vinduet under, hvor jeg fortsatt er på samme sted. Det vil si, jeg må gå inn i sum. Og så må jeg da bygge Dockify. Hvis man ikke husker helt hvordan syntaksen var på Bilt, hvis du har bygget før, så kan det være greit å så blå. Da bruker jeg kontroll R. Da ser vi dokkebilde. Her har jeg satt på en time også.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0007", "start": 580.52, "end": 671.88, "token_count": 295, "text": "Og så må jeg da bygge Dockify. Hvis man ikke husker helt hvordan syntaksen var på Bilt, hvis du har bygget før, så kan det være greit å så blå. Da bruker jeg kontroll R. Da ser vi dokkebilde. Her har jeg satt på en time også. Det er fordi at det tar ganske lang tid å bygge dette her. Med dokkebilde minus til sum, det gir jeg da et navn til imaget. Prikk betyr at jeg bygger den dokkefilen som jeg ser over, som er i samme mappe. Sånn. Da begynner dere å jobbe og henter først imaget. Så ser vi det er syv stepp her. Det tilsvarer de syv steppene her oppe. Hvert av disse steppene vil legge på et nytt lag. Så hvis noe går galt underveis, så kan man gå tilbake og gjøre det på nytt. Og da slipper man å gjøre steppene på nytt. Eller f.eks. hvis det er noe feil med Og alt det andre er riktig, så kan man bare rette opp git clone. Og så få det til å kjøre. Men som sagt, dette tar ganske lang tid.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0008", "start": 648.92, "end": 770.54, "token_count": 290, "text": "Så hvis noe går galt underveis, så kan man gå tilbake og gjøre det på nytt. Og da slipper man å gjøre steppene på nytt. Eller f.eks. hvis det er noe feil med Og alt det andre er riktig, så kan man bare rette opp git clone. Og så få det til å kjøre. Men som sagt, dette tar ganske lang tid. For det er mye kode å hente. Det tar omtrent åtte minutter. Så i mellomtiden så tenkte jeg å gjøre noe annet. Nemlig å teste ut dette interaktivt på en standard Linux-maskin. Da vil jeg dele et annet vindu med dere. Det som jeg etterpå har tenkt å gjøre i dokker. Først kloner jeg disse filene. Så går jeg ned i mappen. Her ligger alle filene. Så tanken er nå at jeg skal teste hvor lang tid dette tar. Dette tar. Og da skal jeg teste... Ja, vi kan... Aller først så kan jeg teste bæsjskriptet. Jeg kjører det. Disse skriptene og programmene har jeg tilpasset til denne maskinen, sånn at de tar omtrent like lang tid.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0009", "start": 744.02, "end": 847.32, "token_count": 288, "text": "Dette tar. Og da skal jeg teste... Ja, vi kan... Aller først så kan jeg teste bæsjskriptet. Jeg kjører det. Disse skriptene og programmene har jeg tilpasset til denne maskinen, sånn at de tar omtrent like lang tid. Det kan være forskjellig på andre maskiner, som f.eks. hvis man kjører det i dokker på Linux-V. Så sum.vers... Den ser sånn ut. Og den regnet ut denne summen ferdig på 15,5 sekunder. Så gjør jeg tilsvarende med... Vi kan starte øverst. GCC sum.c. Da lages det, som vi vet, en A-dot-out. Så kan vi ta tiden på det. Og da ser vi, den tar også ca. 5,5 sekunder. Og sånn har jeg gjort tilsvarende med alle programmene. Det neste vi må gjøre, det er å kompilere Java. Og da trenger man å installere Java sånn som jeg nå gjør. På docketcontaineren. Med app-get-install-JK. Så først kompilerer jeg Java. Det er sånn man kjører Java fra Linux-kommandolinja.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0010", "start": 824.46, "end": 927.2, "token_count": 289, "text": "Det neste vi må gjøre, det er å kompilere Java. Og da trenger man å installere Java sånn som jeg nå gjør. På docketcontaineren. Med app-get-install-JK. Så først kompilerer jeg Java. Det er sånn man kjører Java fra Linux-kommandolinja. Med Javak-kompilerte først. Og så kjører jeg med Javasum. Men jeg glemte å ta tiden. Den tar også omtrent fem sekunder. Sånn fortsetter vi. Pøl er som regel installert i polt på Ubuntu. Pøl er et språk som ble brukt veldig mye tidligere i Linux-sammenheng. Tidligere var det en del av pensum med operatørstemmer. Etter hvert har Pearl blitt mindre brukt, og spesielt Python har tatt over det som er Pearls roller. Vi kan også ta tiden på Python. Nå ser det kanskje litt rart ut hva grunnen til at jeg kjører dette her, for alt tar jo bare like lang tid. Men det skal vi se nærmere på snart. Det var Python. Vi kan ta... Helt til slutt kan vi ta tiden på php også.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0011", "start": 902.38, "end": 1020.16, "token_count": 297, "text": "Vi kan også ta tiden på Python. Nå ser det kanskje litt rart ut hva grunnen til at jeg kjører dette her, for alt tar jo bare like lang tid. Men det skal vi se nærmere på snart. Det var Python. Vi kan ta... Helt til slutt kan vi ta tiden på php også. De oppgavene dere får, så tar jeg ikke med php. Delvis fordi det kan bli et plassproblem med å få isolert alt. Sånn. Så alt tar omtrent fem og et halvt skudd. Men så kommer selve clouet. I denne koden her så vil det være forskjell på hvor mange ganger Hver av de klarer å kjøre gjennom løkken på 5,5 sekunder. Så nå kommer spørsmålet til dere, og det er... Det er hvilket av disse språkene tror dere er raskest. Så jeg har lagd noen... noen pols til dere. Så... Det første jeg spør om, er... Hvilket spørsmål tror dere er raskest av disse seks programmeringsspråkene? Så svar i vei. Og jeg tror jeg har klart å få den til å være anonym. Ja, jeg ser at 40 av dere har...", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0012", "start": 984.0, "end": 1152.02, "token_count": 300, "text": "Så... Det første jeg spør om, er... Hvilket spørsmål tror dere er raskest av disse seks programmeringsspråkene? Så svar i vei. Og jeg tror jeg har klart å få den til å være anonym. Ja, jeg ser at 40 av dere har... 40 av dere har svart. Ja, vi kan stoppe der. De fleste av dere er svarte, så kan jeg vise resultatene. Sånn. Ja, vi ser at flertallet går for C. Da ser jeg raskest. Noen går for Python. Faktisk en del av dere går for bæsj. For skjellet. At det går raskest å kjøre der. Så det... Ja, så det kan bli interessant å se hvem av dere har faktisk... Hvem av dere har faktisk rett. Vi kan ta... Jeg tenkte å spørre om nummer to. Men det blir kanskje... Ja... Siden det er såpass stor variasjon, så tror jeg bare jeg spør om... Oi... Jeg tenkte jeg skulle stille neste spørsmål, men... Det ser ikke ut som jeg klarer å få til å stille et nytt spørsmål. Det ser ikke ut som jeg klarer å få til å stille et nytt spørsmål.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0013", "start": 1110.46, "end": 1260.88, "token_count": 291, "text": "Siden det er såpass stor variasjon, så tror jeg bare jeg spør om... Oi... Jeg tenkte jeg skulle stille neste spørsmål, men... Det ser ikke ut som jeg klarer å få til å stille et nytt spørsmål. Det ser ikke ut som jeg klarer å få til å stille et nytt spørsmål. Et lite øyeblikk. Det er ikke så viktig. Hovedpoenget her var i hvert fall at dere er... De fleste av dere mente'se' var raskest, men det varierte ganske mye. Da kan vi prøve å se her, og så komme opp med fasiten. Skal vi se om... Der i hvert fall. Der har vi resultatene. Så kan vi prøve å se på fasiten. Og da kan vi for eksempel starte med... Vi kan starte med PØL. ... bare for å forklare hvordan dette ser ut. Ja, her ser vi... Nei, dette var POP. Her ser vi POP-koden. Så denne POP-koden gjør dette, som er nøyaktig det samme som Shell-koden, bæsj-scriptet, gjør. Den har faktisk klart å gjøre dette 400 ganger på samme tid.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0014", "start": 1233.6, "end": 1341.88, "token_count": 286, "text": "Ja, her ser vi... Nei, dette var POP. Her ser vi POP-koden. Så denne POP-koden gjør dette, som er nøyaktig det samme som Shell-koden, bæsj-scriptet, gjør. Den har faktisk klart å gjøre dette 400 ganger på samme tid. Så det betyr at POP-koden er 400 ganger så raskt som skjellskriftet. Så... Så POP seiler faktisk opp som en kandidat til å være raskest. Men vi kan prøve å ta alle under én kam. Skal vi se... Så jeg kan prøve å greppe på times alike. Og da får vi på en måte opp en resultatliste, hvis vi nå sorterer etter det største tallet. Og da ser vi... ja, vi kan komme tilbake til den. Av de som vi har kjørt, så er Java det raskeste programmet. Det er kanskje ganske overraskende. Det var bare fire av dere som trodde det. Java er 20 000 ganger raskere enn skjellskriftet. Så det viktigste å ta med seg fra dette, er at det er en ekstrem forskjell i regnekraft.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0015", "start": 1314.0, "end": 1415.72, "token_count": 284, "text": "Av de som vi har kjørt, så er Java det raskeste programmet. Det er kanskje ganske overraskende. Det var bare fire av dere som trodde det. Java er 20 000 ganger raskere enn skjellskriftet. Så det viktigste å ta med seg fra dette, er at det er en ekstrem forskjell i regnekraft. Og programmeringsspråk som Javar og C sammenlignet med et chelleskript. Chelleskript er ekstremt trege til denne type oppgaver. På andreplass her så ser vi C-programmet kommer. Og... på... skal vi se... på tredjeplass så kommer PHP med 400, som vi så. Ganske overraskende så ser vi at Pyton også er vesentlig tregere enn f.eks. C. Vi ser at det er en faktor på 100 her. Så å kjøre dette i C og Java går mer enn 100 ganger så fort som i Pyton. En Spurl er omtrent like rask som Pyton. Så... Det kommer jeg tilbake til. Så... Det første vi kan lære her, er at det er veldig stor forskjell.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0016", "start": 1382.34, "end": 1484.2, "token_count": 296, "text": "enn f.eks. C. Vi ser at det er en faktor på 100 her. Så å kjøre dette i C og Java går mer enn 100 ganger så fort som i Pyton. En Spurl er omtrent like rask som Pyton. Så... Det kommer jeg tilbake til. Så... Det første vi kan lære her, er at det er veldig stor forskjell. Delvis skyldes dette at språk som Python, POP og Pearl er interpretert. Det betyr at de tolkes, så de kjører ikke kode direkte på CPU. Det er det i utgangspunktet bare C som gjør, men også Java. Så vil Java kunne optimalisere, sånn at den i praksis kjører kode rett på CPU-en. Det vil si at det ikke er noen virtuell maskin imellom som først tolker koden, og så kjører den. Dette gjør at disse programmene er ganske mye tregere. Ja... Da kommer jeg tilbake til... Som vi så, så gikk faktisk sånn default, så gikk C-programmet saktere enn jeg var. Det er det mange som stusser på, med god grunn. For man har alltid hørt at C og C++ er det raskeste som fins.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0017", "start": 1459.24, "end": 1568.36, "token_count": 281, "text": "Ja... Da kommer jeg tilbake til... Som vi så, så gikk faktisk sånn default, så gikk C-programmet saktere enn jeg var. Det er det mange som stusser på, med god grunn. For man har alltid hørt at C og C++ er det raskeste som fins. Det stemmer faktisk også. Men det vi har glemt å tenke på her, er når jeg kompilerer Så er GCC optimalisert for å kompilere raskt. Og det er ikke optimalisert for å gi rask kode. Derfor har jeg lagd en sum o, hvor o står for optimalisert. Det er da samme koden. Hvis man kompilerer den, og kjører, En optimalisert ferdig kode som går raskest mulig. Den gikk da litt under fem sekunder, men hovedpoenget med dette var at der kom tallet 28 000, som faktisk skulle vært litt større. Vi ser at vi kunne kanskje kommet opp i 35 000 med denne her. C er faktisk den... Det aller raskeste språket. Vi ser her i kommentarene at det er nesten sju ganger raskere med minus O.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0018", "start": 1539.5, "end": 1643.56, "token_count": 282, "text": "der kom tallet 28 000, som faktisk skulle vært litt større. Vi ser at vi kunne kanskje kommet opp i 35 000 med denne her. C er faktisk den... Det aller raskeste språket. Vi ser her i kommentarene at det er nesten sju ganger raskere med minus O. Så det jeg kan... Ja. Og i oppgaven denne uken så blir dere bedt om å tilpasse disse programmene til å kjøre på dokker. Det kommer tilbake til dokker. Men tanken er da at hvis tiden ikke er helt den samme som her, så må dere prøve å tilpasse tallene sånn at dere får et antall ganger i dokker på Linux-VM. For det vil være litt forskjell på dette her. Hvis vi bare kjører det rett over, så skal vi se at ikke alle går på samme tid. Vi ser at dette programmet burde kjørt litt flere ganger. For det skal opp i 5,5 sekunder. Man kan regne ut tiden det tok på skjellskriftet, som er ca. 5,5. Og så kan man dele på 3,69. Som er 5,5.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0019", "start": 1614.0, "end": 1727.72, "token_count": 292, "text": "Vi ser at dette programmet burde kjørt litt flere ganger. For det skal opp i 5,5 sekunder. Man kan regne ut tiden det tok på skjellskriftet, som er ca. 5,5. Og så kan man dele på 3,69. Som er 5,5. Nå er tiden seerprogrammet bruker. Da ser vi at jeg får 1,5. R er for øvrig litt shell script, som gjør at det kan regne i kommandolinjen. Jeg får nå 1,5, og det betyr at da kan faktisk dette programmet klare å kjøre 1,5 ganger fortere. Så jeg kan ta 1,5 ganger 28 000. Så tanken er da ok, da går jeg inn i sumo.c og så endrer jeg den til 42 000. Sånn. Så tar jeg og kompilerer på nytt med GCC. Og så kjører jeg på nytt med av og ta. Da ser vi. Nå har jeg endret times sånn at også denne tar 5,5 sekunder. Så... Den riktige fasiten nå er at optimalisert C-kode er 42 000 ganger raskere enn et skjellskritt.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0020", "start": 1693.72, "end": 1830.8, "token_count": 298, "text": "Og så kjører jeg på nytt med av og ta. Da ser vi. Nå har jeg endret times sånn at også denne tar 5,5 sekunder. Så... Den riktige fasiten nå er at optimalisert C-kode er 42 000 ganger raskere enn et skjellskritt. Og det er ganske enorm forskjell. Så... Og dette er det viktig å ha med seg når man ser på... Når man vurderer. Hvilke språk skal jeg velge for å gjøre denne oppgaven? Med en gang det har noe med regning å gjøre, man kverner tall eller lignende, så er det fornuftig å velge C eller C pluss pluss. C pluss pluss er omtrent like raskt som C. OK. Hvis vi går og ser på det dere svarte i utgangspunktet, så er det opplagt Men det er en veldig stor forskjell, så det er det greit å huske og ha med videre. Vi skal se etterpå, etter pausen, at resultatene er veldig forskjellige hvis det gjelder tekstbehandling. Så man kan ikke ta dette resultatet og bruke som det er. Kun for CPU-intensive jobber. OK.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0021", "start": 1794.02, "end": 1931.44, "token_count": 292, "text": "Men det er en veldig stor forskjell, så det er det greit å huske og ha med videre. Vi skal se etterpå, etter pausen, at resultatene er veldig forskjellige hvis det gjelder tekstbehandling. Så man kan ikke ta dette resultatet og bruke som det er. Kun for CPU-intensive jobber. OK. Kom gjerne med spørsmål eller kommentarer i pausen hvis dere har det. Da skal vi gå tilbake til dere og se hvordan det går der. At det ser ut som alt har kjørt. Alt er ferdig. Og vi ser det brukte 514 sekunder, så det er vel omtrent 8 minutter på å bygge alt. Men da skulle det være mulig å starte. Og da kan man kjøre dokkerønn. Nei... Dokker, konteiner... Skal vi se... Hvis man ikke husker all syntaksen, så kan man bla bakover. Ja... Så nå har jeg startet denne tidligere. Og det skulle stemme. Dokker, konteineren, minus IT for int. Sum er navnet som jeg ga til dette prosjektet. I... ja, det som jeg ga til dette prosjektet da jeg bygget.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0022", "start": 1903.86, "end": 2022.06, "token_count": 285, "text": "Ja... Så nå har jeg startet denne tidligere. Og det skulle stemme. Dokker, konteineren, minus IT for int. Sum er navnet som jeg ga til dette prosjektet. I... ja, det som jeg ga til dette prosjektet da jeg bygget. Så dermed kan jeg starte det med konteineren minus IT, og så bæsj der for å få opp et bæsjer. Og da ser vi... Nå har jeg fått opp... Konteineren. Og da skulle det være... Ja, da er det en mappe som heter Sum her. Og her ser vi at alt har fungert som det skulle. Alle programmene er kopiert inn. Og da kan vi bare håpe på at det f.eks. virker å kompilere med GCC. Ja, det gjør det. Og da kan man begynne å kjøre. Tilsvarende så har vi også installert både Java og Python. Så da skulle det også være mulig å komplere Java-pilen. Og kjøre den. Så... Dermed kan man... I Dockyfield så kan man gjøre alle disse operasjonene. Og så kan man teste ut om resultatene blir de samme som jeg viser nå.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0023", "start": 1982.26, "end": 2083.72, "token_count": 286, "text": "Tilsvarende så har vi også installert både Java og Python. Så da skulle det også være mulig å komplere Java-pilen. Og kjøre den. Så... Dermed kan man... I Dockyfield så kan man gjøre alle disse operasjonene. Og så kan man teste ut om resultatene blir de samme som jeg viser nå. Vi ser her at de bruker litt lengre tid. Det kan være naturlig, for det er en annen CPU som kjører på denne maskinen her.  Men man ser også at det er litt forskjell i forhold til det jeg hadde tidligere. Så tanken i oppgaven er at dere nå skal tilpasse disse tidene. Og få de til å kjøre like lenge. Sånn at dere kan finne ut hvor mange ganger raskere de forskjellige programmeringsspråkene er enn ett bærskript i dokkercontaineren. OK. Men nå ser jeg vi trenger en pause, så da kan vi komme tilbake til disse... Og ikke minst i dokkecontaineren etter pause. Ja, før vi avslutter, så er det et spørsmål om hvordan eksamen blir. Og det er ikke helt bestemt ennå, men...", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0024", "start": 2051.28, "end": 2150.44, "token_count": 291, "text": "enn ett bærskript i dokkercontaineren. OK. Men nå ser jeg vi trenger en pause, så da kan vi komme tilbake til disse... Og ikke minst i dokkecontaineren etter pause. Ja, før vi avslutter, så er det et spørsmål om hvordan eksamen blir. Og det er ikke helt bestemt ennå, men... Det kommer til å bli en eller annen form for hjemmeeksamen. Tanken er at dere får oppgavene hjemme og besvarer det på samme måte som dere ville gjort i Silje Ulvein. Men det er detaljer som ikke er bestemt. F.eks. er det diskusjoner om det skal være bestått, ikke bestått eller bokstavelige karakterer. Det er en litt spesiell situasjon når man da må sitte hjemme og gjøre... Men som sagt, ingenting er helt bestemt der, men i hvert fall sånn det ser ut, så kommer eksamensdatoer og eksamenstid til å være det samme som opprinnelig bestemt. For operativsystemer er det en tretimerseksamen. Hvis det blir bestått eller ikke bestått, så får man fortsatt ti studiepoeng.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0025", "start": 2122.24, "end": 2259.64, "token_count": 285, "text": "Men som sagt, ingenting er helt bestemt der, men i hvert fall sånn det ser ut, så kommer eksamensdatoer og eksamenstid til å være det samme som opprinnelig bestemt. For operativsystemer er det en tretimerseksamen. Hvis det blir bestått eller ikke bestått, så får man fortsatt ti studiepoeng. Hvis det blir det, så vil det også være mulig da... Hvis man føler at man har jobbet veldig mye med et kurs og vil kunne få en god karakter, så vil det da være mulig å gå opp til eksamen til neste år for å få en karakter. Men ingenting er avgjort ennå, så jeg kan ikke svare noe mer enn det. OK. Da tar vi... 15 minutter pause. Ja. Da er jeg i ferd med å lage et skript som automatiserer oppgaven med å kompilere kode og teste ut hvor lang tid det tar i en docker container. Jeg vil få en del feil her, for jeg har ikke installert Java i Linux VM. Jeg tror ikke jeg vil ha plass engang hvis jeg prøvde å installere det i tillegg til containerne. Det samme gjelder Python.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0026", "start": 2227.24, "end": 2351.04, "token_count": 295, "text": "med å kompilere kode og teste ut hvor lang tid det tar i en docker container. Jeg vil få en del feil her, for jeg har ikke installert Java i Linux VM. Jeg tror ikke jeg vil ha plass engang hvis jeg prøvde å installere det i tillegg til containerne. Det samme gjelder Python. Så forhåpentligvis så funker det. Men dette kan vi nå sjekke. Så... Vi lagrer den sundet sjøl. Og så må vi da endre på dokkefeil på en sånn måte at den sum.dot-skjell legges inn i... I dokker-imaget. Da kan vi prøve å se på hvordan vi gjorde det forrige gang. Jeg hadde en dokkefeil der. Da ser vi... Dette her, det skulle... Kopiere en fil. Så hvis jeg tar en copy litt tilsvarende den, så burde dokkefeilen min også gjøre det. Det er alltid lurt bare å ta utgangspunkt i det man hadde tidligere. Så nå har jeg på filen... Eller ved siden av... Jeg har en fil som heter sum.shell. Den skal kopieres inn i sum. Da lages en mappe som heter sum øverst i filsystemet.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0027", "start": 2315.2, "end": 2420.68, "token_count": 287, "text": "så burde dokkefeilen min også gjøre det. Det er alltid lurt bare å ta utgangspunkt i det man hadde tidligere. Så nå har jeg på filen... Eller ved siden av... Jeg har en fil som heter sum.shell. Den skal kopieres inn i sum. Da lages en mappe som heter sum øverst i filsystemet. Sånn. Så da har jeg en ny dockerfile. Så kan jeg save den. Av den dokkerkonteineren, for nå skal jeg stoppe den og lage en eat. Så jeg går ut, og så kan jeg ta en dokker, konteiner... Den stopper generelt alle konteinerne. Så kan jeg bygge på nytt. Sist så tok dette åtte minutter, men nå ser vi... Da tar det to sekunder. For nå er det bare den copperbiten der som jeg gjør på nytt. Alt det andre, det ligger i cash. Og leses da fra cash, sånn at man slipper å kompilere alt annet. Og da kan jeg... Da kan jeg kjøre dokker, container og øyne igjen. Minus IT, akkurat samme måte som sist. Så kan vi se om dette har fungert.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0028", "start": 2398.16, "end": 2515.92, "token_count": 286, "text": "som jeg gjør på nytt. Alt det andre, det ligger i cash. Og leses da fra cash, sånn at man slipper å kompilere alt annet. Og da kan jeg... Da kan jeg kjøre dokker, container og øyne igjen. Minus IT, akkurat samme måte som sist. Så kan vi se om dette har fungert. Da går jeg inn i sum. Og så sier jeg ja, nå har jeg fått inn sum.chell. Men jeg ser... Jeg burde gjøre en endring, men jeg burde også sette rettigheter på denne her. Sånn at... Med semod. Da kan jeg kjøre en kommando. Jeg kan egentlig bare kjøre rønn. Rønn, se om mot... La oss si 255, og sum, sum.dot, skjell. Dette er da for å kunne automatisere i enda større grad. Så gjør jeg det interaktivt også. Og så kan jeg prøve å kjøre, da. Da ser vi Shellscripte kjører, men som sagt, det er ikke sikkert Shellscripte er riktig selv om det kjører. Men vi ser... Ja, vi får noen feil her. Skal vi se...", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0029", "start": 2482.24, "end": 2630.46, "token_count": 296, "text": "Og så kan jeg prøve å kjøre, da. Da ser vi Shellscripte kjører, men som sagt, det er ikke sikkert Shellscripte er riktig selv om det kjører. Men vi ser... Ja, vi får noen feil her. Skal vi se... Der skal det være en liten J. I tillegg så var det kanskje... Python... Det var... Ja, jeg har kanskje ikke installert Python. Jo. Jeg har installert Python 3. Ja, hvordan kommer jeg ut her...? Jeg vet ikke hvordan jeg kommer ut av Python interaktivt. Men det jeg gjorde nå, var å kjøre kontroll P, kontroll Q. Så kan jeg rette opp. Jeg installerte vel Python 3, sånn at da kjører jeg Python 3 i settet. Skal vi se her... Ja, der står det Python 3. Men nå ser vi... Nå kan vi raskt stoppe konteineren igjen. Og så kan jeg raskt starte den på nytt. Og der er jeg allerede inni konteineren. Så vi ser at hvis man bare gjør små endringer på docker file helt mot slutten... Så er det veldig raskt å gå inn og ut og få det til å virke.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0030", "start": 2609.88, "end": 2795.32, "token_count": 289, "text": "Og så kan jeg raskt starte den på nytt. Og der er jeg allerede inni konteineren. Så vi ser at hvis man bare gjør små endringer på docker file helt mot slutten... Så er det veldig raskt å gå inn og ut og få det til å virke. Da trenger man ikke åtte minutters populering. Det ser ut som den... I hvert fall ikke den semod-kommandoen fungerte. Men vi kan se om selve scriptet fungerer nå. Ja, det tar litt lengre tid... Litt lengre tid her. Men ser det ikke ut som jeg fikk lagt inn endringene? Ja, det er vel et generelt problem. Skal vi se. Da må jeg se. Gjorde jeg endringer her? Jo. Dette er nytt. Og jeg har python 3. Men det ser ikke ut som dette hadde en effekt. Da prøver jeg å gå ut igjen. Så prøver jeg å stoppe. Stoppe konteineren. Og bulke på nett. Ja, for det som kunne være, er at jeg ikke brukte cash. Eller at jeg brukte cash, men vi ser... Rungid Clone, den bruker cash. Men den kopieringen her,", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0031", "start": 2748.68, "end": 2874.92, "token_count": 286, "text": "Så prøver jeg å stoppe. Stoppe konteineren. Og bulke på nett. Ja, for det som kunne være, er at jeg ikke brukte cash. Eller at jeg brukte cash, men vi ser... Rungid Clone, den bruker cash. Men den kopieringen her, den ser ut til å bli gjort på nytt. Så da... Prøver jeg å gå inn igjen. Deg inni konteineren. Jeg vet ikke helt hva jeg gjorde feil. Mulig jeg ikke starter den på nytt. Eller bygger den på nytt. Men nå ser vi at... Nå har Seomod blitt utført. For... Den kommandoen har tydeligvis blitt utført her. Hvis jeg ser på Sunn.shell, så ser vi at Java står med liten bokstav og Python 3. Skulle jeg kunne kjøre Sum.chen her inne. Ja. Så vi ser på denne måten, så kan man da utvikle en dokkefeil og raskt gjøre endringer og kjøre den på nytt, starte og stoppe konteineren. Neste step, i hvert fall i ukens utfordring, blir også å gjøre dette her helt automatisk.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0032", "start": 2851.04, "end": 2950.4, "token_count": 298, "text": "Ja. Så vi ser på denne måten, så kan man da utvikle en dokkefeil og raskt gjøre endringer og kjøre den på nytt, starte og stoppe konteineren. Neste step, i hvert fall i ukens utfordring, blir også å gjøre dette her helt automatisk. Og da endre dokkefilen, legge til det som vi hadde i forrige uke, med å sette opp en webserver. Og så utvikle dette programmet som regner ut tidene. Og så til slutt kjøre det programmet sånn at output kommer til indeks 88ml. Da kan man bare sette i gang en container. Etter ti minutter har man da ferdige resultater, uten at man løfter en finger. Så kan man enkelt teste ut hvordan dette fungerer i Ubuntu 1604 eller i RedHat. Men hvis du begynner med RedHat, så vil det straks være man måtte gjøre noen forskjeller. Men iallfall Debbian og andre varianter kan man med samme skript teste ut uten å gjøre noe særlig arbeid selv. Eller manuelt arbeid. Men av resultatene så ser vi at det er litt forskjell, fordi f.eks. Python bruker", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0033", "start": 2916.18, "end": 3015.32, "token_count": 297, "text": "Men hvis du begynner med RedHat, så vil det straks være man måtte gjøre noen forskjeller. Men iallfall Debbian og andre varianter kan man med samme skript teste ut uten å gjøre noe særlig arbeid selv. Eller manuelt arbeid. Men av resultatene så ser vi at det er litt forskjell, fordi f.eks. Python bruker dobbelt så lang... eller de fleste bruker lengre tid der. Men... Bortsett fra Shell-skriptet. Så i Docker-konteineren så kommer Shell-skriptet litt bedre ut. Men det dere da må gjøre, er å endre time. Antall ganger. I skriptene, sånn at alle gir 5,5 sekunder. Så typisk her, bare halverer du antall sepp, og så får du alle til å ta like lang tid. Og da får man et tall på... Og hvor mye raskere de forskjellige programmene er enn skjellskriptet. OK... Hvis det ikke er noen spørsmål til noe av dette her, så tenker jeg vi går videre. Ja, altså... Det jeg tenkte å gjøre først... Hvis jeg deler et annet vindu med dere...", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0034", "start": 2986.32, "end": 3093.86, "token_count": 288, "text": "Og hvor mye raskere de forskjellige programmene er enn skjellskriptet. OK... Hvis det ikke er noen spørsmål til noe av dette her, så tenker jeg vi går videre. Ja, altså... Det jeg tenkte å gjøre først... Hvis jeg deler et annet vindu med dere... Det er å så... se på en tekstversjon av dette. Til nå har vi bare sett på CPU-intensive prosesser. Så hva nå om... Vi ser på tekst. Og da er det en annen oppgave denne uken, som går ut på å laste ned denne filen med Vgets. En tar-fil som inneholder en rekke programmer som... Som gjør noe av det samme. Men vi kan se hva de gjør. Vi har nå et perskript. I denne mappen som du får når du pakker ut tar-filen, ligger det en stor fil. Og oppgaven til dette programmet her er å lage... Så leser man inn linje fra linje fra den store filen. Før man begynner å kjøre dette skriptet, må man kopiere filen stor til slash temp stor. Så får hver linje i filen, i den store filen,", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0035", "start": 3070.44, "end": 3182.74, "token_count": 295, "text": "Og oppgaven til dette programmet her er å lage... Så leser man inn linje fra linje fra den store filen. Før man begynner å kjøre dette skriptet, må man kopiere filen stor til slash temp stor. Så får hver linje i filen, i den store filen, så leser du linje for linje. Og skriver da ut en ny linje med et tall først på linjen, til en annen fil. Så dette er da en helt annen type oppgave enn å så og regne. Her er det tekstbehandling og skriving til pil. Og det tar ofte litt tid, det å skrive til pil. Og da vil du se en veldig stor forskjell på hastigheter. Da er det ikke de samme forskjellene som tidligere. Vi kan nå se på fil.cpp. Det er da et C++-program som gjør akkurat det samme. Her har jeg juksa litt og lagd en run.shell som kopilerer og kjører. Før jeg gjør dette litt raskt, så kan jeg bare starte run.shell. Jo. Det vi ser nå, er... Det siste tallet her var så lang tid Shellscript brukte. Og dette var tiden for de andre.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0036", "start": 3136.34, "end": 3242.16, "token_count": 283, "text": "Her har jeg juksa litt og lagd en run.shell som kopilerer og kjører. Før jeg gjør dette litt raskt, så kan jeg bare starte run.shell. Jo. Det vi ser nå, er... Det siste tallet her var så lang tid Shellscript brukte. Og dette var tiden for de andre. Og det som er interessant her, er at nå er det faktisk noen time. Det vil si at alle programmene utfører den samme oppgaven. Og da ser vi at Shell-skriptet bruker nå 5,5 sekunder som før. Mens Java, f.eks., bruker 0,8 sekunder. Så det betyr at Java i dette tilfellet er bare... Åtte ganger så raskt omtrent som Shell-skriptet. Mens i regnejobben så var Java 20 000 ganger raskere. Så vi ser en enorm forskjell i hvor mye raskere programmet er. Av en eller annen grunn er Pørl veldig raskt på akkurat dette her. Det er til og med raskere enn C++-programmet. Begge er mer enn ti ganger raskere enn Skjellscriptet.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0037", "start": 3221.54, "end": 3316.3, "token_count": 299, "text": "Så vi ser en enorm forskjell i hvor mye raskere programmet er. Av en eller annen grunn er Pørl veldig raskt på akkurat dette her. Det er til og med raskere enn C++-programmet. Begge er mer enn ti ganger raskere enn Skjellscriptet. Men hvis vi husker tilbake, så var C-programmet noe sånt som... Var der 48 000 ganger raskere enn Skjellscriptet. Så vi ser en enorm forskjell. Det er en enorm forskjell i forskjellen i hastighet, avhengig av hvilken arbeidsoppgave man skal gjøre. Typisk så er resultatene ekstreme hvis det gjelder CPU-bruk. Mens hvis det gjelder å skrive til piler og ting som systemet bruker en del tid på, så er ikke forskjellene så store. Kjernen bruker mye tid. Ja... En kommentar til til resultatene i hastighet. Vi så f.eks. at Python bare var 40 ganger raskere enn Shell. Mens C++ var 40 000 ganger raskere. Så det er en veldig stor forskjell der. Til det må man si at hvis man skulle gjort noe tilsvarende i Python...", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0038", "start": 3291.14, "end": 3370.0, "token_count": 280, "text": "Ja... En kommentar til til resultatene i hastighet. Vi så f.eks. at Python bare var 40 ganger raskere enn Shell. Mens C++ var 40 000 ganger raskere. Så det er en veldig stor forskjell der. Til det må man si at hvis man skulle gjort noe tilsvarende i Python... Så finnes det en rekke biblioteker i Python, og de er ofte skrevet i C og Z pluss. Så det betyr at hvis man har noen regneoppgaver i Python, så brukes ofte biblioteker som er mye raskere. Så det er ikke sånn at Python alltid er ekstremt tregt. Men med de rette bibliotekene så kan Python også være veldig effektivt. Og det er en stor fordel med Python. Det fins veldig mange biblioteker som man kan bruke til å løse de problemene man har. Uansett, hvis man går på en større programmeringsoppgave hvor effektivitet spiller en rolle, så kan det være verdt jobben å ta en liten sjekk på forhånd før man velger programmeringsspråk.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0039", "start": 3351.46, "end": 3473.82, "token_count": 287, "text": "til å løse de problemene man har. Uansett, hvis man går på en større programmeringsoppgave hvor effektivitet spiller en rolle, så kan det være verdt jobben å ta en liten sjekk på forhånd før man velger programmeringsspråk. Se hvor effektivt programmeringsspråket er på akkurat den type oppgaver som programmet Det er kanskje den viktigste lærdommen å ta med fra dette. Ok. Da har vi ikke så mye tid igjen til regulære uttrykk. Men vi skal se litt på det. Og det dere kan gjøre, er altså...  Er å bruke regulære... Eller bruke forelesningsnotatene. Og slå opp i dem og gjøre oppgaver. Men vi kan... Vi starter litt. Skal vi se. Da tenkte jeg kanskje å dele hele skjermen. Sånn at du kan jobbe litt med forelesningsnotatene. Et øyeblikk. Sånn. Da ser dere forhåpentligvis hele skjermen. Ops. Oi, enda sørere. Der. Sånn. Det jeg tenkte å se litt på nå, var regulære uttrykk.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0040", "start": 3434.18, "end": 3556.92, "token_count": 283, "text": "Et øyeblikk. Sånn. Da ser dere forhåpentligvis hele skjermen. Ops. Oi, enda sørere. Der. Sånn. Det jeg tenkte å se litt på nå, var regulære uttrykk. Det jeg tenkte å gjøre nå, var å teste ut noen regulære uttrykk i kommandolinjen. Vi kan først prøve... Lage en mappe her. Vi kan først... Jeg skal prøve å teste ut et eksempel på hvordan man kan bruke regulært uttrykk. Dette skriptet her, hvis jeg kaller det reg.chel. Det skriptet her lager et regulært uttrykk her oppe. Og så er det en vilelucky som leser inn. Og så ser vi her. Er lik til det. Det er operatoren som bæsj bruker for å teste regulære uttrykk. Det er det samme som Pølle bruker. Vi tar én og én linje i dette programmet. Og tester mot det regulære uttrykket. Dette er syntaks som har kommet senere. Som har kommet sent, så derfor trenger vi en sånn doble klamme parentes.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0041", "start": 3520.6, "end": 3636.72, "token_count": 299, "text": "Er lik til det. Det er operatoren som bæsj bruker for å teste regulære uttrykk. Det er det samme som Pølle bruker. Vi tar én og én linje i dette programmet. Og tester mot det regulære uttrykket. Dette er syntaks som har kommet senere. Som har kommet sent, så derfor trenger vi en sånn doble klamme parentes. Og dette skriptet sier det har match hvis vi får en match. Så vi kan bare prøve å kjøre det. Så hvis... Hvis jeg nå skriver inn Osol... Så ser vi at vi får en match. Hei, så får jeg ikke noe match. Hva med en O? Nei, ingenting. Men hvis jeg skriver 'hallo', så ser vi at vi får match, for da matcher jeg den biten der. Og RegX-ben så sånn ut. Ok. Så det er generelt en måte man kan gå på. Jeg tenkte vi skulle se noen flere eksempler. Da kan jeg prøve å gjøre det interaktivt, sånn som det er gjort i notatene. Hvis jeg har en linje som heter Hei og ho, så ønsker jeg å kjøre et litt mer avansert, regulært.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0042", "start": 3610.6, "end": 3713.2, "token_count": 293, "text": "Jeg tenkte vi skulle se noen flere eksempler. Da kan jeg prøve å gjøre det interaktivt, sånn som det er gjort i notatene. Hvis jeg har en linje som heter Hei og ho, så ønsker jeg å kjøre et litt mer avansert, regulært. Vi kan starte fra starten her. Her ser vi at vi matcher linje. Den sier match med det regulære uttrykket, som kommer her. Dette er da det regulære uttrykket. Og prikk betyr... Den prikken som står der, det betyr match med... Match hvilket som helst tegn. Og stjerne betyr null eller flere. Jeg har listet opp noen av de viktigste regulære uttrykkene. For de av dere som har programmert til Java, så har dere kanskje brukt regulære uttrykk der. Og det er stort sett de samme regulære uttrykkene. Dette bygger delvis på PØL-regulære uttrykk. Det er koder som er vanlige regulære uttrykk, som man ikke kan bruke i bæsjel. Det er sånn som f.eks. siffer. Så har dere kanskje brukt de regulære uttrykk.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0043", "start": 3691.66, "end": 3800.74, "token_count": 298, "text": "Dette bygger delvis på PØL-regulære uttrykk. Det er koder som er vanlige regulære uttrykk, som man ikke kan bruke i bæsjel. Det er sånn som f.eks. siffer. Så har dere kanskje brukt de regulære uttrykk. Men i utgangspunktet så kan man ikke gjøre det i skjellregulære uttrykk. Man må bruke klammeparentes og null til ni for å matche et siffer. Det som er nyttig, er å kunne trekke ut noe av det man matcher. Hvis jeg setter parentes rundt det i det regulære uttrykket jeg vil matche, så legges det som er inni parentesen og matches, inn i en variabel som heter batch rematch. Hvis jeg kjører den der... Så får jeg en match, for det matcher jo Hei Å Ho. Og så ser vi at den matchen jeg fikk inn, er Hei Åg. For det var det som sto inni parentesen her. Det er match én eller flere vilkårlige tegn. Og den matcher da Hei Åg i det uttrykket her. Ja. Jeg ser det kommer et par spørsmål her. Skiller den på store og små bokstaver?", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0044", "start": 3772.1, "end": 3902.7, "token_count": 295, "text": "For det var det som sto inni parentesen her. Det er match én eller flere vilkårlige tegn. Og den matcher da Hei Åg i det uttrykket her. Ja. Jeg ser det kommer et par spørsmål her. Skiller den på store og små bokstaver? Det er et godt spørsmål. Ja, den skiller på store og små bokstaver. Hvis jeg prøver å matche O her, da. Så ser vi. Da får vi ingen match. Du er nødt til å ha... Du er nødt til å ha direkte match. Oi, hva klarte jeg der nå? Ja, det ser ut som jeg klarte å... Stoppe hele skjermen. Jeg kan hoppe over her. Prøver en gang til. Linje hei og ho. Og så matcher jeg med denne. Men som du ser, med en gang jeg prøver en stor bokstav, så får jeg ikke noe bæsj. Men med en gang jeg prøver en solbokstav, så får jeg ikke noe bæsj. Et annet spørsmål er arbeidskrav avlyst i OS. Det vet jeg ikke helt hva det blir til. Men... det kan jeg komme tilbake til. Vi har fått noen signaler om at...", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0045", "start": 3874.66, "end": 3976.72, "token_count": 299, "text": "Men med en gang jeg prøver en solbokstav, så får jeg ikke noe bæsj. Et annet spørsmål er arbeidskrav avlyst i OS. Det vet jeg ikke helt hva det blir til. Men... det kan jeg komme tilbake til. Vi har fått noen signaler om at... At alle skal kunne gå opp til eksamen uansett. Men jeg er ikke sikker. Uansett så er det veldig nytt... Oi! Unnskyld. Uansett så er det veldig nyttig å jobbe med obligatorene for å lære seg faget. Det jeg prøver med obligatoriske, er å gjøre de mest sentrale oppgavene obligatorisk. Men jeg kommer tilbake til det. OK. Et problem som dukket opp faktisk da jeg hadde forelesning i fjor, men som jeg da ikke skjønte helt hva kom av, er hvis man prøver å gjøre en sånn match som det her, og så legger en inn et mellomrom, så vil du se at jeg får en feilmelding. Og det betyr at denne måten å skrive regulære uttrykk på i skjellet ikke er helt safe. Det er noen ganger det ikke funker, og det er det viktig å ha med seg.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0046", "start": 3950.4, "end": 4061.8, "token_count": 300, "text": "er hvis man prøver å gjøre en sånn match som det her, og så legger en inn et mellomrom, så vil du se at jeg får en feilmelding. Og det betyr at denne måten å skrive regulære uttrykk på i skjellet ikke er helt safe. Det er noen ganger det ikke funker, og det er det viktig å ha med seg. Så en bedre måte å gjøre dette her på er følgende. Vi kan først se på hvorfor. Jo, som dere har sett, så er skjellet ofte... Veldig hårsort når det gjelder mellomrom osv. Og et problem her er at dette blir da tolket av skjellet. Man får en syntaksfeil. Så måten man løser det på, er da i stedet å alltid skrive... Definere et regulært uttrykk i en variabel på denne måten her. Mellom to enkeltapostrofer. Så hvis jeg skal ha med et mellom... ... på mange måter er det en mer ryddig måte å skrive en match på. Vi ser det er et mellomrom der, så det burde virke. Vi kan f.eks. se... Hvis jeg gjør det, så får jeg ikke noen match.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0047", "start": 4012.9, "end": 4127.96, "token_count": 294, "text": "Mellom to enkeltapostrofer. Så hvis jeg skal ha med et mellom... ... på mange måter er det en mer ryddig måte å skrive en match på. Vi ser det er et mellomrom der, så det burde virke. Vi kan f.eks. se... Hvis jeg gjør det, så får jeg ikke noen match. Da kan man stille seg spørsmål om hvorfor man ikke får noen match her. Hvorfor får jeg ikke en hei òg? Jo, fordi regulære uttrykk er veldig presise. Du er nødt til å matche nøyaktig det som står. Og vi ser at i linje her oppe, så er det ikke to mellomrom. Så om vi derimot går inn, skriver to mellomrom, så ser vi. Da får vi en match. Da matcher hi-og inni her. Så kommer det to mellomrom, så kommer ho. Så generelt så må man være veldig nøyaktig med å matche akkurat det som står. Ja. Da tenker jeg vi overlater til oppgavene å bruke noen av disse regulære uttrykkene. Det er et par oppgaver. Prøv å gjøre de nå i laben etterpå.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0048", "start": 4100.96, "end": 4220.48, "token_count": 300, "text": "Så generelt så må man være veldig nøyaktig med å matche akkurat det som står. Ja. Da tenker jeg vi overlater til oppgavene å bruke noen av disse regulære uttrykkene. Det er et par oppgaver. Prøv å gjøre de nå i laben etterpå. Et par oppgaver som er relatert til regulære uttrykk. Så ta dette, denne typen matcher som utgangspunkt. Og så er det da egentlig bare å Sett inn de passende regulære uttrykkene. OK. Da er det klart for lab. Så dette er oppgavene denne uken. Vi ser det starter med noen oppgaver som har med nice å gjøre. Så et par... Så er det oppgaver med regulære uttrykk. Og til slutt er det disse oppgavene med å sammenligne hassel på program og å bruke dokker til å løse dette, eller til å automatisere det. Så vi kommer til å komme en gang iblant innom dokker senere Neste uke kommer vi til å snakke om virtuelle maskiner. Hvis det ikke er noen spørsmål i chatten, så tenker jeg vi slutter der. Eller vi tar en pause på 15 minutter.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0049", "start": 4189.6, "end": 4389.7, "token_count": 278, "text": "Så vi kommer til å komme en gang iblant innom dokker senere Neste uke kommer vi til å snakke om virtuelle maskiner. Hvis det ikke er noen spørsmål i chatten, så tenker jeg vi slutter der. Eller vi tar en pause på 15 minutter. Og så etter pausen så organiserer vi breakout rooms. Sånn at... Det er mulig for dere å gå inn i rom og snakke med Studentholdssenteret eller meg hvis dere står fast på noen problemer. Så... 15 minutters pause, og så kom inn og sjekk ut Breakout-roms etter pausen. Og det er veldig viktig at vi har gode kompetanser og gode kompetanser til hverandre. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0050", "start": 4318.92, "end": 4659.7, "token_count": 300, "text": "... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0051", "start": 4588.92, "end": 4929.7, "token_count": 300, "text": "... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen.", "source": "lecture"}
{"lecture_id": "linux9", "chunk_id": "linux9_0052", "start": 4858.92, "end": 4955.26, "token_count": 94, "text": "... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. ... og det er vanskelig å forstå hvordan det er å være døv og rød i halsen. Det er veldig vanskelig å forstå hva som skjer og hva som skjer.", "source": "lecture"}
{"lecture_id": "linux5del5", "chunk_id": "linux5del5_0000", "start": 0.0, "end": 105.76, "token_count": 295, "text": "Head og tail er to nyttige kommandoer som man kan bruke til å se starten og slutten av filer. F.eks. hvis man ønsker å se de første fem linjene av et passord. Så kan man gjøre det på den måten. Head plukker da ut de fem første linjene. Hvis man bare vil se den første linjen, så legger du til opsjon. Bare vis første linje. Tilsvarende, hvis du da ønsker å se siste linje. Siste fem linjer, så kan du gjøre det på den måten, for du vil se de fem siste linjene av It's a Password. Man kan alltid... altså gjøre det motsatt. Man kan enten med en strøm av data... Så kan man pipe den til head. Eller hente et tail. Så kan vi se de siste tre linjene. Så kan jeg gjøre det på den måten. Og hett og telt kan jeg finne og kombinere med sort. La oss si jeg ønsker å sortere possordfilm på UiD. UiD er den... Altså user ID. Det er det tredje elementet. 1, 2, 3. Demon er én, Bind er to, osv.", "source": "lecture"}
{"lecture_id": "linux5del5", "chunk_id": "linux5del5_0001", "start": 75.96, "end": 189.52, "token_count": 295, "text": "Og hett og telt kan jeg finne og kombinere med sort. La oss si jeg ønsker å sortere possordfilm på UiD. UiD er den... Altså user ID. Det er det tredje elementet. 1, 2, 3. Demon er én, Bind er to, osv. Og UiD0 er veldig spesielt, for det er Root. Så hvis du lager en... Man kan lage flere Root-brukere, men da vil de ha UiD0. Hvis noen har lagd en skjult rute, kan det være nyttig å se alle som har null, som UiD. Så det vi kan prøve å gjøre da, er å prøve å sortere hele postordfilen etter den UiD-en. Men vi ser i utgangspunktet at så er den delvis sortert etter... Vi kan se på Tail. Her er det litt mer hulter og bulter. 1000 kommer først, og så 1001. Så la oss prøve å sortere, og så sende til Tail. Vi har sett at vi kan sortere passordfilmen på denne måten. Bruker bare sort. Da sorteres det bare på det første elementet. Vi ønsker å sortere på det tredje.", "source": "lecture"}
{"lecture_id": "linux5del5", "chunk_id": "linux5del5_0002", "start": 156.36, "end": 247.62, "token_count": 277, "text": "Her er det litt mer hulter og bulter. 1000 kommer først, og så 1001. Så la oss prøve å sortere, og så sende til Tail. Vi har sett at vi kan sortere passordfilmen på denne måten. Bruker bare sort. Da sorteres det bare på det første elementet. Vi ønsker å sortere på det tredje. Det vi kan gjøre da, er å bruke en opsjon på sort som er minus T, kolon. Det betyr sorter et med kolon som merke. Og så ønsker vi kolonne 3. Da sier vi som tidligere minus K3. Så nå sorterer vi med kolonne 3. Så sender vi det til så de får de fem siste. Men vi ser her er det et eller annet som ikke går helt bra. For dette ser ikke sortert ut. Og det er fordi vi sorterer alfabetisk. Så default sorterer sort alfabetisk, så vi må legge på en N for å få numerisk sort. Og den N-en må ligge foran K-en, hvor den er minus K. Sånn. Da sorterer vi numerisk, og da ser vi vi får de siste UID-ene.", "source": "lecture"}
{"lecture_id": "linux5del5", "chunk_id": "linux5del5_0003", "start": 220.6, "end": 318.08, "token_count": 290, "text": "For dette ser ikke sortert ut. Og det er fordi vi sorterer alfabetisk. Så default sorterer sort alfabetisk, så vi må legge på en N for å få numerisk sort. Og den N-en må ligge foran K-en, hvor den er minus K. Sånn. Da sorterer vi numerisk, og da ser vi vi får de siste UID-ene. Vanlige brukere starter typisk på 1000, så når jeg har lagt til en bruker her, S123456, får da UID 1001. Og nobody har den høyeste UID-en. Men vi ønsker å se i den andre enden, og da kan vi bruke Head. En Ruth-bruker som har UD0. Så... På denne måten ser vi hvordan Sort og Head og Tail kan brukes sammen. En annen veldig nyttig måte å bruke Tail på, det er å legge på minus F. Da vil den følge filen. Hvis man endrer på en fil mens man bruker Tail minus F, Vise det som blir lagt til i filen. Det kan være nettopp på loggfiler. Vi kan se på en fil som heter authotlog, og som viser innlogginger. Men man må være Harud rett etter for å se på den.", "source": "lecture"}
{"lecture_id": "linux5del5", "chunk_id": "linux5del5_0004", "start": 290.76, "end": 375.96, "token_count": 292, "text": "Da vil den følge filen. Hvis man endrer på en fil mens man bruker Tail minus F, Vise det som blir lagt til i filen. Det kan være nettopp på loggfiler. Vi kan se på en fil som heter authotlog, og som viser innlogginger. Men man må være Harud rett etter for å se på den. Så vi kan ta Sudhotel, og da... Nå har jeg nylig tastet inn passord. Ellers måtte jeg taste inn passordet for gruppe 100. Dette er nå live forsøk på å logge seg inn, som da vises i denne loggfilen. Og med TailminsF så ber vi Tael om å følge denne loggfilen og vise alt som kommer inn fortløpende. Og da ser vi her er det en masse sånne fail password from 159... Dette er da en IP. Som prøver å logge seg inn som bruker Ruth, og så prøver den et tilfeldig passord. Typisk er dette et script som har en liste med passord. Sånne vanlige, brukte RUT-passord. RUT-RUT blir testet først. Så ser vi den samme IP-en som om og om igjen prøver ut", "source": "lecture"}
{"lecture_id": "linux5del5", "chunk_id": "linux5del5_0005", "start": 354.04, "end": 402.56, "token_count": 156, "text": "Som prøver å logge seg inn som bruker Ruth, og så prøver den et tilfeldig passord. Typisk er dette et script som har en liste med passord. Sånne vanlige, brukte RUT-passord. RUT-RUT blir testet først. Så ser vi den samme IP-en som om og om igjen prøver ut en rekke RUT-passord for å komme inn på denne Linux-VM-en. Det er derfor dere må være spesielt forsiktige med å sette god passord på konto. Men altså... Taleminus-f. Det gjør at man kan følge en fil og så se live hvordan den oppdateres.", "source": "lecture"}
{"lecture_id": "os4del20", "chunk_id": "os4del20_0000", "start": 0.0, "end": 82.68, "token_count": 294, "text": "Ja... Det er spørsmål om hvordan vet du hva som returnerer bare ved å skrive rett, og det er et godt spørsmål. Men det er bare en konvensjon. Og konvensjonen er at verdien i r-a-x, det er den som returneres. Så hvis... Hvis jeg her f.eks. bare skriver inn... Move 42... 43... 42 til... Da må jeg komme til... Hvor var det jeg skulle? RAX. Sånn. Så kan vi se at etter programmet er ferdig, så er det en konvensjon som bare returnerer det som er i RAX. Sånn. Så kan vi se at etter programmet er ferdig, så er det en konvensjon som bare returnerer det som er i RAX. sånn. Så kan vi se at etter programmet er ferdig, så er det en konvensjon som bare returnerer det som er i RAX. Så da må vi kompilere på nytt. Og kjøre. Så ser vi... Da kommer sum 42. Nå har jeg jo ødelagt hele programmet. Men det er det jo da veldig fort å gjøre. Så hvis jeg f.eks. skriver en syntaksfeil, sånn som dette her...", "source": "lecture"}
{"lecture_id": "os4del20", "chunk_id": "os4del20_0001", "start": 60.0, "end": 101.0, "token_count": 130, "text": "Så da må vi kompilere på nytt. Og kjøre. Så ser vi... Da kommer sum 42. Nå har jeg jo ødelagt hele programmet. Men det er det jo da veldig fort å gjøre. Så hvis jeg f.eks. skriver en syntaksfeil, sånn som dette her... Nei, det var ikke til den. Der kompilerer jeg. Så ser vi. Her får jeg en beskjed fra assembleren. Her har du gjort noe feil. Og det er rett og slett en syntaksfeil.", "source": "lecture"}
{"lecture_id": "os14del11", "chunk_id": "os14del11_0000", "start": 0.0, "end": 89.96, "token_count": 277, "text": "Vi kan se litt mer i detalj på det. For vi har da et program som heter Perf. Som jeg kan bruke til å se nøyaktig hva som skjer når jeg kjører programmet. Så vi kan ta den enkleste... enkleste versjonen først. Sette i den som går raskest. Her ligger det pent etter hverandre, så dette kan pustes i store biter ut i cash. Da går det kjapt. Det er den der. 0,02 sekunder. Men så kan jeg kjøre en... Altså, jeg har kjørt den før. Det er en kommando som heter perf, og den gir statistikk med antall... Her er jeg bedt eksplisitt om å skrive ut antall sykler, antall instruksjoner, Cash references. Det er hvor mange ganger du har en cash-referanse. Hvor mange ganger du henter ut noe for cash. Og så, ikke minst, cash misses. Major faults og minor faults. Major faults, det er når man må ut på disken og hente. Og det skjer ikke her. Det er når du får en virkelig page fault. Minor faults, det er når man må... Når man ikke har...", "source": "lecture"}
{"lecture_id": "os14del11", "chunk_id": "os14del11_0001", "start": 66.36, "end": 154.44, "token_count": 293, "text": "Hvor mange ganger du henter ut noe for cash. Og så, ikke minst, cash misses. Major faults og minor faults. Major faults, det er når man må ut på disken og hente. Og det skjer ikke her. Det er når du får en virkelig page fault. Minor faults, det er når man må... Når man ikke har... Lagd en side i MMU. Og det skal vi se, det må vi gjøre ganske ofte. Så... Jeg tar og kjører den først. Og da får vi statistikken for dette programmet. Igjen ser vi det går lynras. 0,02 sekunder. Likevel ser vi... Utfør 63 millioner sykler. Og du gjør 71 millioner institusjoner. Men omtrent da en institusjon per sekund. Så... så ser vi... Cash Misses. Ja, den bommer ganske ofte på cash. Og det er fordi at den... den tar jo nå ut bit for bit. Men ganske ofte så må den hoppe videre til neste... neste del av cashen. Må fylle ut cash på nytt. Men fordelen når de ligger etter hverandre, er at den fyller hele cash. Med elementene som ligger etter hverandre.", "source": "lecture"}
{"lecture_id": "os14del11", "chunk_id": "os14del11_0002", "start": 129.36, "end": 225.36, "token_count": 299, "text": "Og det er fordi at den... den tar jo nå ut bit for bit. Men ganske ofte så må den hoppe videre til neste... neste del av cashen. Må fylle ut cash på nytt. Men fordelen når de ligger etter hverandre, er at den fyller hele cash. Med elementene som ligger etter hverandre. Men vi ser her minor falts. 10 000 minor falts. Og det passer ganske bra med... Hvis at det er 10K. En side er omtrent på 1000 bytes. Vanligvis er den på 4K. Så det går ikke helt opp. Men... Det er omtrent 10 000 K. Og vi ser at vi får 10 000 minor folts. Og det er fordi at en minor folts er når man ikke har referert til denne delen av minnet. Og da lages det en adressering i MMU. Og det gjøres 10 000 ganger. Så det tar også litt tid. Men alt i alt så går dette lynraskt. Så prøver jeg å sette J like. Nei, vi setter inn RA av J, og da hopper vi rundt i 4 GB. Og dette tar da mye lengre tid. Komplerer. Og kjører det samme.", "source": "lecture"}
{"lecture_id": "os14del11", "chunk_id": "os14del11_0003", "start": 191.92, "end": 287.28, "token_count": 291, "text": "Og da lages det en adressering i MMU. Og det gjøres 10 000 ganger. Så det tar også litt tid. Men alt i alt så går dette lynraskt. Så prøver jeg å sette J like. Nei, vi setter inn RA av J, og da hopper vi rundt i 4 GB. Og dette tar da mye lengre tid. Komplerer. Og kjører det samme. Og nå ser vi... Nå får vi først og fremst... Så burde vi egentlig kunne sammenligne. Sånn, ja. Det tar 1,6 sekunder mye lengre tid. Og det er opplagt mange flere cycles. Og vi ser vi har veldig mange flere cash references, og nesten alle bommer. Jeg har på en måte konstruert dette sånn at det skal bomme. Vi hopper med 100 hver gang. Det er veldig uvanlig at man gjør det på denne måten her. Men dette er bare for å illustrere hvordan cash virker. Å være klar over det. Så vi får 75 millioner cash misses i stedet for 800 000 her oppe. Det er først og fremst det som gjør at det tar mye lengre tid.", "source": "lecture"}
{"lecture_id": "os14del11", "chunk_id": "os14del11_0004", "start": 261.56, "end": 372.48, "token_count": 289, "text": "Vi hopper med 100 hver gang. Det er veldig uvanlig at man gjør det på denne måten her. Men dette er bare for å illustrere hvordan cash virker. Å være klar over det. Så vi får 75 millioner cash misses i stedet for 800 000 her oppe. Det er først og fremst det som gjør at det tar mye lengre tid. Men det tar også tid å bygge opp MMU, for her ser du vi... Her trengs det én million sider. For det r-e-et er på fire. Fire G, fire gigabyte. Og med en sidestørrelse på fire K, så så trenger man én million sider. Ja, så det går pent opp. Jeg glemte det at en integr er på fire. Så dette, det tilsvarer da... I det første tilfellet trengte vi bare 10 000 sider i MMU, men her trenger vi 1 million sider for å kunne adressere 4 gigabyte. Og dette tar også mye tid å bygge opp MMU. Og da ser vi at det er oppe i 1,6 GB. Det kan vi også se på... Når jeg tar Time Out-Out, så kan vi se på hva tiden går bort til.", "source": "lecture"}
{"lecture_id": "os14del11", "chunk_id": "os14del11_0005", "start": 341.28, "end": 455.8, "token_count": 291, "text": "men her trenger vi 1 million sider for å kunne adressere 4 gigabyte. Og dette tar også mye tid å bygge opp MMU. Og da ser vi at det er oppe i 1,6 GB. Det kan vi også se på... Når jeg tar Time Out-Out, så kan vi se på hva tiden går bort til. Vi ser user, det er 0,4, men veldig mye brukes av system. Cornal Tid. Og det er da for å bygge opp MMU-sidene. Så det er også en faktor her. Det er ikke bare cash, Hvis vi nå kjører... Hvis vi ser på det samme med Adatat, så ser vi... Jo, det er en andel system her også som er ganske stor. Den er faktisk litt større, for her også må de sidene bygges opp. Så ser vi at kjernen er inne og hjelper til med å... Bygge opp, da, i dette tilfellet 1 million pages. Og det tar litt tid. Spørsmål om hvorfor det var så mange cash misses i prog 1. Jo, det skyldes at tross alt, selv om man går etter hverandre, så går man veldig langt. Her ser vi det er 10 millioner...", "source": "lecture"}
{"lecture_id": "os14del11", "chunk_id": "os14del11_0006", "start": 427.32, "end": 547.96, "token_count": 298, "text": "Bygge opp, da, i dette tilfellet 1 million pages. Og det tar litt tid. Spørsmål om hvorfor det var så mange cash misses i prog 1. Jo, det skyldes at tross alt, selv om man går etter hverandre, så går man veldig langt. Her ser vi det er 10 millioner... 10 millioner bite, eller da 10 000 kilobite. Og hvis du regner med INT, så er det da 40 000 kilobite. Og det krever jo da... At man lager de 10 000 sidene... her oppe. Men spørsmålet var kanskje hvorfor det var så mange cashministers som 801? Jo... Cash er da mindre enn 4K, så selv om du... Selv om du treffer veldig ofte, så er det jo med en gang du kommer utenfor, i første omgang, LN-cash-størrelsen, så vil du måtte hoppe over på... Så vil LN-cash måtte reflushes. Og den vil da reflushes 800 000 ganger når det går oppover. Først med opptil 100, og så... Men du ser du skal helt opp til 10 millioner. Så derfor vil du ha flere cashmisses enn der...", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0000", "start": 0.0, "end": 96.4, "token_count": 281, "text": "Ja, før vi starter i dag, så er det noen praktiske ting som vi skal se på først. Ja. Brunch Prediction, det er det vi skal holde på med i dag. Men aller først til oversikten over kurset. Da er vi kommet. Vi er nå i uke seks. Det er et par ting som er nytt her. Først og fremst er det MC1. Som er da en obligatorisk multiple choice-test. Det har tatt litt tid å få ut den også, fordi det har vært problemer med SSH-innlogging på studentserverne. Ikke StudioSSH, men en annen server. Så... Men det er relaterte problemer. Så hvis det skulle være noen problemer med innlogging, så si ifra med en gang. Det har vært litt problemer tidligere, men jeg håper det fungerer som det skal nå. Det er delvis av historiske årsaker at vi har dette multipurpose-systemet, men jeg har bygd opp en svær database med spørsmål der. Og også mot slutten så skal vi ha en... Så er det en World of Operating Systems. Som er en slags konkurranse hvor man kan oppnå levels ved å svare på i dette systemet.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0001", "start": 74.84, "end": 161.64, "token_count": 295, "text": "Det er delvis av historiske årsaker at vi har dette multipurpose-systemet, men jeg har bygd opp en svær database med spørsmål der. Og også mot slutten så skal vi ha en... Så er det en World of Operating Systems. Som er en slags konkurranse hvor man kan oppnå levels ved å svare på i dette systemet. Men uansett... Så tidlig som mulig, gå gjennom og gjør denne flervalgstesten. Først og fremst så er det en tilbakemelding på hvor dere sår, hva dere har fått med dere av pensum. I tillegg kan det være ganske nyttig fram til eksamen, for vanligvis så dukker det opp noen spørsmål fra disse full price-spørsmålene. Noen ganger helt de samme, andre ganger en variant som ligner. Oppgavene er fra kursets fire uker. Den første oblingen er det mest om Linux og verskommandoer. Du må svare på minst syv av ti riktige spørsmål. Du må ha syv av ti riktige. Og så kan du være litt uheldig med spørsmålene. Noen er vanskeligere enn andre. Men ikke for tidlig hvis du ikke får det til.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0002", "start": 140.24, "end": 227.58, "token_count": 296, "text": "Den første oblingen er det mest om Linux og verskommandoer. Du må svare på minst syv av ti riktige spørsmål. Du må ha syv av ti riktige. Og så kan du være litt uheldig med spørsmålene. Noen er vanskeligere enn andre. Men ikke for tidlig hvis du ikke får det til. Da er tanken at du skal ta kontakt med en student og sånt. Og nå, typisk, så må du da gå inn i et break-off-room hvis du er på en lab-dag. Bruk labdagen til å gå inn i breakover-room, snakke med studentassistent, og se på spørsmålene. Så gir studentene deres mulighet til å få en ny sjanse. Ja, så i tillegg... Det var noe annet fornuftig jeg skulle si om disse testene. Jo, dere får nye sjanser. Men det er viktig å... Gjør de så snart som mulig, sånn at dere får tid til å få nye sjanser. Hvis det er én type spørsmål dere bommer på, så er det kanskje fornøyd å jobbe litt mer med oppgavene rundt de. Så kan dere, før dere begynner på de nye sjansene...", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0003", "start": 206.36, "end": 300.86, "token_count": 297, "text": "Gjør de så snart som mulig, sånn at dere får tid til å få nye sjanser. Hvis det er én type spørsmål dere bommer på, så er det kanskje fornøyd å jobbe litt mer med oppgavene rundt de. Så kan dere, før dere begynner på de nye sjansene... Ok, det var multiple choice. Var det noe annet... Ja, Oblique 2 står og lyser her nede i det fjerne. Det er ikke så lenge til. Den har da frist... skal vi se... fredag 5. mars. Så det er en stund til, men alle oppgavene til Oblikk 2 ligger nå ute. Så Oblikk 2 består av fem-, seks- og syvoppgavene herfra. Så vil det da etter påske komme en Oblikk 3 med oppgaver fra de fire. Sånn er det standardopplegget. En annen ting... Oppgavene denne uken, de har ligget ute en uke. Men disse, oppgavene til neste uke, som er uke syv... Det er da de siste som inneholder obligoppgaver. Men temaet derfra har vi ikke snakket om ennå.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0004", "start": 266.36, "end": 360.08, "token_count": 290, "text": "Sånn er det standardopplegget. En annen ting... Oppgavene denne uken, de har ligget ute en uke. Men disse, oppgavene til neste uke, som er uke syv... Det er da de siste som inneholder obligoppgaver. Men temaet derfra har vi ikke snakket om ennå. Det snakker vi delvis om i neste uke og delvis denne uken. Og her står det Linux-VM-er. Så det er nyttig og viktig i dag. Så jeg skal bruke litt tid helt til starten å se på de Linux-VM-ene, sånn at dere kan komme i gang med dem. Jeg har kanskje merket at dere har fått en annonsement i OS-gruppene. Der står det et passord. Det står ikke så mye annet. Men det er det passordet dere trenger for å kunne bruke Linux-VM-ene. Mer om dette står øverst i uke seks. Her står det litt om multiple-soice-testen. Og så står det her om Linux-VM-ene. Jeg kaller det Linux-VM-er. Virtuelle maskiner. Egentlig er det faktisk dokkecontainere,", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0005", "start": 340.28, "end": 422.92, "token_count": 290, "text": "Mer om dette står øverst i uke seks. Her står det litt om multiple-soice-testen. Og så står det her om Linux-VM-ene. Jeg kaller det Linux-VM-er. Virtuelle maskiner. Egentlig er det faktisk dokkecontainere, men det er på en måte halvveis virtuelle maskiner. Fordi de dokkecontainerne bruker et opplegg som heter Sysbox, som er et slags system som isolerer dokkecontainerne i større grad. Vi kommer tilbake til dokkecontainerne senere i kurset, og da skal dere kjøre dokkekonteinere og starte og stoppe og bygge osv.. Vi skal snakke mer om hvordan det henger sammen, men sånn foreløpig så... Eller generelt så er et problem med dokkecontainere at de kjører direkte på operativstemme og har tilgang til operativstemme på serveren som de kjører. I motsetning til virtuelle maskiner. Men disse dokkecontainerne som kjører Sysbox, de er containet enda sterkere. Altså de er isolert mer fra serveren under. Så... Dermed får man en look and feel som om det var en virtuell maskin.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0006", "start": 402.6, "end": 492.32, "token_count": 290, "text": "I motsetning til virtuelle maskiner. Men disse dokkecontainerne som kjører Sysbox, de er containet enda sterkere. Altså de er isolert mer fra serveren under. Så... Dermed får man en look and feel som om det var en virtuell maskin. Sånn som StudySSO. StudySSO er en ekte virtuell maskin som kjører KVM, og som kjører på en fysisk server. Og de tingene her er det litt viktig å ha med i... Skal vi se... Er det denne ukens oppgaver? Hvor det er... Jo, det er i denne ukens oppgaver hvor dere skal kjøre... Kjøre mange prosesser på samme VM eller på Studio SSO for å se hvordan disse serverne tildeler CPU-er... Eller operativsystemet tildeler CPU-er til prosessene. Skredulerer. Og det skal vi snakke masse om. Men aller først så skal vi se litt i praksis på disse Linux-VM-ene. at for å få tilgang til en Linux-VM, så må dere være i en OS-gruppe. Hvis dere f.eks. er i OS-gruppe 13, så kan dere da logge dere inn med SSO.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0007", "start": 462.72, "end": 574.26, "token_count": 290, "text": "Skredulerer. Og det skal vi snakke masse om. Men aller først så skal vi se litt i praksis på disse Linux-VM-ene. at for å få tilgang til en Linux-VM, så må dere være i en OS-gruppe. Hvis dere f.eks. er i OS-gruppe 13, så kan dere da logge dere inn med SSO. På tilsvarende måte som dere gjør til Study SSO, med Putty eller på andre måter med et skjell fra Mac Linux. Eller fra en Linux-laptop. Eller fra Study SSO, hvis dere er der inne. OS13 er da hosten. Det er navnet på VM-en. Og Group 13 er brukernavnet. Så jeg kan ta og se på hvordan det ser ut i praksis. Hvis jeg nå går til riktig vindu i... Skal vi se... Litt mange under her. Her har jeg et vindu i Studio SSO. Så kan vi tenke oss at dere enten er i Studio SSO, eller at dere logger direkte inn med putt-id. Begge deler går. Det skal gå an å logge seg inn hjemmefra også. Denne her er ikke innenfor Dere må ikke bruke... Hva heter det... VPN.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0008", "start": 547.4, "end": 642.52, "token_count": 293, "text": "Så kan vi tenke oss at dere enten er i Studio SSO, eller at dere logger direkte inn med putt-id. Begge deler går. Det skal gå an å logge seg inn hjemmefra også. Denne her er ikke innenfor Dere må ikke bruke... Hva heter det... VPN. Dere må ikke bruke Oslo-mette-VPN for å komme inn til disse. Så jeg har tatt en gruppe som er nummer 100. Så jeg må da logge meg på som group 100. Dere må gjerne prøve dette her nå. Passordet dere skal ha for group 100, eller group 13, På OS-gruppen. Så hvis dere er OS100... Hvis dere var OS100, så vil dere gå inn i den gruppen og se på en navnsvenn som ligger der. Da kan dere plukke ut passordet. Dette er felles for alle som er på gruppen. Og så er urlenvelab.cs.joa.no... Tror ikke OsloMet funker, men Joa skal funke. Så må dere skrive passordet som dere har fått. Se om jeg husker passordet jeg har fått... ja. Og da kommer dere inn på VM-en. Og da er det plutselig et Linux-shell", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0009", "start": 614.34, "end": 719.32, "token_count": 281, "text": "Og så er urlenvelab.cs.joa.no... Tror ikke OsloMet funker, men Joa skal funke. Så må dere skrive passordet som dere har fått. Se om jeg husker passordet jeg har fått... ja. Og da kommer dere inn på VM-en. Og da er det plutselig et Linux-shell på samme måte som... Ja, ligner veldig på Studies også. Det kjører... Det er en helt ny versjon av Umuntu. Mulig den er nyere enn den på StudeSOS. Og her kan dere da gjøre alt mulig som dere har gjort hittil på StudieSOS, men dere kan da gjøre enda mer. Og det er det viktig å være klar over. Her er dere... Dere har RUT-aksess, så dere kan gjøre Sudo-SU. Og så skrive passordet på nytt. Da ser du... Vips, så er det RUT på systemet. Og da kan dere gjøre alt dere måtte ønske. For eksempel å installere. Kjøre AppGetUpdate før dere installerer. Så kan dere installere hva som helst som dere... Eller som dere trenger i oppgavene.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0010", "start": 691.18, "end": 816.46, "token_count": 293, "text": "Da ser du... Vips, så er det RUT på systemet. Og da kan dere gjøre alt dere måtte ønske. For eksempel å installere. Kjøre AppGetUpdate før dere installerer. Så kan dere installere hva som helst som dere... Eller som dere trenger i oppgavene. Tvert i oppgavene kommer det noen instruksjoner om å installere screen og Kron og en del forskjellig annet. Det er også en oppgave... Er det denne uken eller kanskje neste uke? Hvor dere blir bedt om å installere en webserver. Og det... Jeg tror jeg har gjort det allerede her, så vi kan kikke på det. Hvis jeg... Skal vi se... Hvis jeg skriver inn nå OS100 her... Dere kan endre på å styre som dere vil. Legg merke til at dette er jo en... Dette er nå en public IP. Så ifconfig... Oi, nå må jeg tilbake. Nå er jeg inne på OS100 igjen. Ifconfig viser... Info om nettet. Og her ser vi at dette er en public IP. Hvis du er OS1, så har du public ippe 13120.101 og 102 for OS2 osv.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0011", "start": 787.4, "end": 890.96, "token_count": 287, "text": "Så ifconfig... Oi, nå må jeg tilbake. Nå er jeg inne på OS100 igjen. Ifconfig viser... Info om nettet. Og her ser vi at dette er en public IP. Hvis du er OS1, så har du public ippe 13120.101 og 102 for OS2 osv. Og det er veldig viktig å være klar over at denne ippen her, den nås av alle. Sånn at her er det helt tiden folk som prøver å... Prøver å logge seg på. Vi kan se om... Den kjører autodelog... Det kan vi se på senere. Men uansett... Alle har tilgang herfra, og det vil foregå hele tiden en del... Eller - SSH-skanning foregår det hele tiden. Dvs. at man prøver å logge seg på og gjette passordet til... Så det betyr at hvis du lager en konto med brukernavn test og passordtest, ikke gjør det, for da vil veldig snart noen hacke seg inn, ta over maskinen din, VM-en din, og kanskje knytte den opp til et botnett. Og ikke minst når den begynner å skanne utover,", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0012", "start": 866.36, "end": 965.6, "token_count": 294, "text": "Så det betyr at hvis du lager en konto med brukernavn test og passordtest, ikke gjør det, for da vil veldig snart noen hacke seg inn, ta over maskinen din, VM-en din, og kanskje knytte den opp til et botnett. Og ikke minst når den begynner å skanne utover, og da får vi masse problemer med Uninett og gud vet hva. Veldig forsiktig med brukernavn og passord. Neste uke er det en oppgave hvor dere skal lage et brukernavn. Eller dere skal lage tilsvarende brukernavn som dere har på studio SSO, og sette passord. Det hjelper veldig å ha sære brukernavn som S123456. Men sett også et godt passord. Og for all del, ikke bruk brukernavn som Linux eller Rubunto Da er det straks noen... i hvert fall i Bayani i løpet av timer noen som kommer inn og tar over IP-en. Så vær generelt obs, for den vemen er ute i den store verden og har veldig lite beskyttelse. Ok... Noen spørsmål til disse vemene? Nei... Men prøv det ut. Si gjerne fra i chatten eller i pausen", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0013", "start": 931.8, "end": 1037.82, "token_count": 290, "text": "noen som kommer inn og tar over IP-en. Så vær generelt obs, for den vemen er ute i den store verden og har veldig lite beskyttelse. Ok... Noen spørsmål til disse vemene? Nei... Men prøv det ut. Si gjerne fra i chatten eller i pausen hvis dere ikke får ting til å funke. Vi skal se på det på laben i dag også. Ja, så test det ut. Ja... Det er et spørsmål om det er... at det ikke er noen OS-grupper nå, ja. Jo, det er sant... Alle OS-gruppene fram til OS8 ble fulgt opp. Men nå har jeg lagd noen ekstra OS-grupper. Det er i hvert fall 16 til opp til OS96. Så hvis du ikke er med i en OS-gruppe, f.eks. hvis du ikke leverer obliger, tar faget om igjen, så meld deg da inn i en OS-gruppe, en av de ledige. Bruk VM-en som er tilordnet deg. Alle de 96 første har allerede fått en VM. Dette er et helt nytt eksperiment. I fjor hadde vi virtuelle maskiner og noen fysiske servere, men de serverne begynte å bli gamle", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0014", "start": 1011.28, "end": 1111.96, "token_count": 294, "text": "så meld deg da inn i en OS-gruppe, en av de ledige. Bruk VM-en som er tilordnet deg. Alle de 96 første har allerede fått en VM. Dette er et helt nytt eksperiment. I fjor hadde vi virtuelle maskiner og noen fysiske servere, men de serverne begynte å bli gamle og begynte å knekke. Derfor har vi en ny server. Og så har jeg bygd dette opplegget som er helt nytt. Vi har ikke testet det live. Så vær obs på at ting kan gå galt, og si gjerne fra. Men vi håper det fungerer som det skal. Ok, da... tror jeg har fått med meg det meste av det praktiske. Så da skal vi hoppe til... Dagens tema... Og i dag så skal vi snakke om branch prediction. Vi skal fortsette litt der vi slapp sist, men først og fremst skal vi se på multitasking. Først skal vi ha en generell innføring om multitasking, hva det er, og hvordan det teoretisk sett fungerer. Og til slutt i dag så skal vi se på multitasking på forskjellige servere Dette med multitasking skal vi fortsette med i neste uke,", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0015", "start": 1090.38, "end": 1186.68, "token_count": 283, "text": "Først skal vi ha en generell innføring om multitasking, hva det er, og hvordan det teoretisk sett fungerer. Og til slutt i dag så skal vi se på multitasking på forskjellige servere Dette med multitasking skal vi fortsette med i neste uke, og se på en del forskjellige praktiske problemer og løsninger relatert til multitasking. Aller først lite gram om hva vi holdt på med sist. En linje høynivåkode kan gi mange linjer assembly- eller maskinkode. Det trenger vi nå når vi i dag skal begynne med multitasking. For da må vi multitaske mellom kodelinjer fra forskjellige prosesser. Generelt er kompilering av høynivåkode til maskinkode en veldig komplisert prosess. Det er vanskelig å skrive en kompulator som kan kompilere alle... Derimot er kompulering av assembler til maskinkode veldig rett frem. Det er bare linje for linje å oversette. Så alle kan skrive en assembler, men ikke alle kan skrive en kompulator. I hvert fall ikke uten videre. Det tar et halvt år.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0016", "start": 1162.02, "end": 1268.16, "token_count": 298, "text": "Det er vanskelig å skrive en kompulator som kan kompilere alle... Derimot er kompulering av assembler til maskinkode veldig rett frem. Det er bare linje for linje å oversette. Så alle kan skrive en assembler, men ikke alle kan skrive en kompulator. I hvert fall ikke uten videre. Det tar et halvt år. I tillegg så vi på sist at én enkelt assemblerinstitusjon, én maskininstitusjon, er delt opp i mikrooperasjoner. Det gjøres faktisk parallelt i pipelines. Og det er akkurat det vi skal se litt på i dag. Aller først... Branch prediction. Og branch prediction er en slags konsekvens av... Av det vi så på forrige gang, at vi bruker for det første... Pipelining er at man deler én institusjon. Da tenker vi på en institusjon som ADD-AX til svar. Altså legge til verdien i registeret AX til svar i ram. Denne operasjonen, i maskinkode, så er det én maskininstitusjon. Men denne deles opp i mange mikroinstruksjoner. Først hentes den inn, så deles den opp i små deler og utføres.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0017", "start": 1243.12, "end": 1339.08, "token_count": 292, "text": "Altså legge til verdien i registeret AX til svar i ram. Denne operasjonen, i maskinkode, så er det én maskininstitusjon. Men denne deles opp i mange mikroinstruksjoner. Først hentes den inn, så deles den opp i små deler og utføres. For det er flere ting som skal gjøres. Man må hente inn verdien fra RAM inn i et temporært register. Så må man legge til, og så må det resultatet legges ut igjen. Vi må på et eller annet tidspunkt ta verdien i et register og legge ut en ramm. Alt dette brytes ned i mange små mikrooperasjoner. Som tippes for Intel kan det være 14 sånne operasjoner. Pipelining er at vi, når vi starter på en institusjon som har 14 deler, så venter vi ikke med å få gjort alle de 14 delene ferdig. Vi begynner på. Med en gang den første instruksjonen er gjort, så begynner vi på første instruksjon for den instruksjonen som kommer etter i pipelinen. Sånn at i praksis så kjøres ting delvis parallelt.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0018", "start": 1310.52, "end": 1398.82, "token_count": 285, "text": "så venter vi ikke med å få gjort alle de 14 delene ferdig. Vi begynner på. Med en gang den første instruksjonen er gjort, så begynner vi på første instruksjon for den instruksjonen som kommer etter i pipelinen. Sånn at i praksis så kjøres ting delvis parallelt. I tillegg så har man superskalærarkitektur. Faktisk virkelig går parallelt. Og da kan det være flere samtidige institusjoner som kommer i en pipeline delt opp i 14 biter. Men så vil da hver av de små bitene, de kan kjøres helt samtidig. Altså institusjonen som er fem institusjoner etter den første, den kan kjøres samtidig. Og dette går veldig fint hvis institusjonene er avhengige. ... uavhengig av hverandre. Hvis det ikke er direkte sammenheng. Men i noen tilfeller er det en sammenheng. Det viktigste tilfellet er en if-test, som du har i Fawlucker og Viole og hele tiden. Hele tiden har man branching. Typiskvis av en if-test, så er det en branch.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0019", "start": 1380.9, "end": 1465.32, "token_count": 289, "text": "Men i noen tilfeller er det en sammenheng. Det viktigste tilfellet er en if-test, som du har i Fawlucker og Viole og hele tiden. Hele tiden har man branching. Typiskvis av en if-test, så er det en branch. Hvis svaret er true, så går det den ene veien. Hvis det er få, så går det den andre veien. Det vet man ikke før man kommer dit. Det blir da plutselig et problem med en sånn bransjing når systemet allerede er i gang med å utføre neste institusjon. Det største problemet er at man kunne løst det ved å... Hvis man kom til branch, så bare stoppet man helt. Pipelining og superskalærere... Altså å kjøre mikroinstitusjoner. I reell parallellitet. Med parallellitet. Altså kjører de helt samtidig. Man kunne skru det helt av. Men da ville ting gå mye saktere. Så det man prøver på da, er å gjette. Man gjetter hvilken bransje som skal kjøres, og så bare sier man sånn... Tidligere så har det ofte... Har disse testene blitt true?", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0020", "start": 1442.52, "end": 1540.68, "token_count": 288, "text": "Man kunne skru det helt av. Men da ville ting gå mye saktere. Så det man prøver på da, er å gjette. Man gjetter hvilken bransje som skal kjøres, og så bare sier man sånn... Tidligere så har det ofte... Har disse testene blitt true? Så hiver man alle institusjonene i den bransjen som om den testen skulle slå til. Hvis da testen ikke slår til, og man har gjettet feil, hva skjer da? Jo, det er ikke katastrofe, for da må man rett og slett bare glemme hva som skjedde, og hoppe tilbake. Og så må man kjøre opp. Om igjen den andre bransjen. Det er klart, dette gir en masse ekstra logikk og overhead å få til dette her. Men igjen - alt er gjort for at ting skal gå raskere. Vi skal se på det i praksis, men vi kan ta med ett eksempel som gjorde at dette med pipeline i bransjen Og ikke minst parallellitet i mikroinstruksjoner, altså superskalærarkitektur, som alle moderne CPU-er etter 2000 har.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0021", "start": 1507.68, "end": 1628.48, "token_count": 287, "text": "Men igjen - alt er gjort for at ting skal gå raskere. Vi skal se på det i praksis, men vi kan ta med ett eksempel som gjorde at dette med pipeline i bransjen Og ikke minst parallellitet i mikroinstruksjoner, altså superskalærarkitektur, som alle moderne CPU-er etter 2000 har. Det var Melton og Specter som var to sikkerhetshull som ble funnet i 2018. Det var noe så spesielt som et hardware-sikkerhetshull. Og Meltov utnyttet nettopp dette her, at kode blir utført i parallell. Så... Men det var virkelig et hack. Men det utnyttet det at når man kommer til en bransje, så går man inn og... Og man kan også gjøre tester, f.eks.: Er det lov å lese data fra den andre prosessen? Dette systemet fungerer helt fint hvis systemet er sikkert på at CPU utfører én og én institusjon. Men med parallellitet... Med pipelining og med at institusjoner faktisk utføres i parallell. Så begynner man noen ganger å utføre en institusjon", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0022", "start": 1601.68, "end": 1694.16, "token_count": 297, "text": "Dette systemet fungerer helt fint hvis systemet er sikkert på at CPU utfører én og én institusjon. Men med parallellitet... Med pipelining og med at institusjoner faktisk utføres i parallell. Så begynner man noen ganger å utføre en institusjon som å sjekke om man har lov til å lese ram, samtidig som en annen prosess legger noen av sine data i ram. Og det dette sikkerhetsrullet utnyttet, var at en prosess da kunne ved en feil lese ram for en annen prosess. F.eks. kunne det brukes til at en prosess kunne lese passord som en annen prosess skrev inn. Det som var spesielt, var at dette brukte de hardware-effektene. Sånn at for å rette opp i denne feilen, så måtte både CPU-ene endres for å sikre seg mot denne feilen, og operativsystemet. Det er nyttig å vite litt om hva som foregår enda lenger ned. Stort sett når det gjelder sikkerhetssøl, så skjer det på operativsystemnivå. Altså med kode. Men i dette tilfellet så skjedde det altså med hardware.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0023", "start": 1676.36, "end": 1791.22, "token_count": 289, "text": "Det er nyttig å vite litt om hva som foregår enda lenger ned. Stort sett når det gjelder sikkerhetssøl, så skjer det på operativsystemnivå. Altså med kode. Men i dette tilfellet så skjedde det altså med hardware. Vi skal nå se på et konkret eksempel på dette med branch prediction. En kode som... ser ganske vanlig ut, men som har en veldig spesiell oppførsel. Og det er et C++-program. Vi kan ta det først. Vi ser det heter b.cpp. Og det er et C++-program. Det kopieres da ikke med GCC, men med B.cpp på den måten her. Det kjøres med.a.. akkurat som for GCC. Så veldig forskjellig er det ikke. Men... Dette kunne også vært kjørt i C, men jeg gjør det i C++. Det er litt enklere å operere med Array. Så et C++-program ligner veldig på C. Den store forskjellen på C++ og C er at C++ er objektorientert, mens C ikke er objektorientert. Men det er ikke det som er fokus her. Fokus her er dette litt enkle,", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0024", "start": 1766.36, "end": 1882.04, "token_count": 296, "text": "Så et C++-program ligner veldig på C. Den store forskjellen på C++ og C er at C++ er objektorientert, mens C ikke er objektorientert. Men det er ikke det som er fokus her. Fokus her er dette litt enkle, ikke så veldig smarte programmet, men det er lagd for å... Illustrere dette med branch prediction. Og... Det er et ganske enkelt program. Vi ser vi har et stort ra som har 32 000 elementer. Ra-sizen er her. Man deklarerer dette som et ra med 32 768 elementer. Og så er det i første omgang bare... En enkel forløkker som initialiserer alle disse 32 000 r-elementene. Variabelen c løper gjennom alle tall opp til 32 000. Og så er det kode her... Her står det RAND. Det er en funksjon som trekker ut et tilfeldig tall. Og så ser vi at det prosent, det er... Det er en heltallsdivisjon. Så... Og den prosent, den gir da resten. Sånn at... Det eneste du trenger å vite, er at resultatet av denne her, det er et tilfeldig tall mellom 0 og 255.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0025", "start": 1861.8, "end": 1940.96, "token_count": 292, "text": "Det er en heltallsdivisjon. Så... Og den prosent, den gir da resten. Sånn at... Det eneste du trenger å vite, er at resultatet av denne her, det er et tilfeldig tall mellom 0 og 255. Det er da resten. Hvis du tar et tall og deler på 256, så får du... Så går det opp. Du får rest 0, eller så får du 1 i rest. Da blir tallet 1, eller så får du helt opp til 255 i rest. Hvis tallet er ett større, så går det opp igjen. Så rad gir et tilfeldig svært heltall. Og dette gir da tilfeldige tall mellom 0 og 255. Så det er utgangspunktet. Vi har et sånt r-ei. Så går vi litt lenger ned i programmet, så ser vi liksom... Hovedprogrammet hva det utfører. Og det er her som det skjer rare ting. For det første så skriver vi bare ut de ti første verdiene for å se om R-øyet er sortert eller ikke. I utgangspunktet er det ikke sortert, men etterpå skal vi skru på sortering. Og det er da rare ting skjer.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0026", "start": 1920.24, "end": 1999.44, "token_count": 286, "text": "Og det er her som det skjer rare ting. For det første så skriver vi bare ut de ti første verdiene for å se om R-øyet er sortert eller ikke. I utgangspunktet er det ikke sortert, men etterpå skal vi skru på sortering. Og det er da rare ting skjer. Så det dette litt naive programmet gjør, Vi legger sammen alle tall større enn 127. Og det gjør vi inni den indre løkka her. Så ser vi at jeg har lagt på en ytre løkke. Ikke tenk så mye på den. Det er bare lagt til for at dette skal ta litt tid. CPU-er er utrolig kjappe, så hvis vi bare hadde gjort én kjøring, så ville det å bare starte opp programmet tatt så mye tid. For vi skal se på forskjell i tiden. Det er den som er spesiell. Så vi gjør dette 50 000 ganger. Men hovedpoenget er hva vi gjør inni løkka her. Der sier vi at hvis dette tilfeldige tallet mellom 0 og 255 er større enn 127, så skal det summeres. Så det betyr bare...", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0027", "start": 1976.36, "end": 2071.72, "token_count": 285, "text": "Det er den som er spesiell. Så vi gjør dette 50 000 ganger. Men hovedpoenget er hva vi gjør inni løkka her. Der sier vi at hvis dette tilfeldige tallet mellom 0 og 255 er større enn 127, så skal det summeres. Så det betyr bare... Vi tar alle tall større enn 127 og legger sammen. Så skriver vi ut summen. Så har det jo ikke noe merkelig skjedd med det... Vi kan ta det ut og... kompilere det. Og så kan vi kjøre det, men vi må da ta tiden på det når vi kjører. Og så ser vi... Dette er starten av æreiet. Så jeg har skrevet ut de ti første elementene. Det kommer helt tilfeldig. Og vi ser at dette programmet tok noe 20 sekunder. RIL her, det er hvor lang totaltid det tok. User, det er hvor mye CPU som ble brukt i use mode. Det skal vi snakke om i neste uke. Men kort sagt er det vanlige kommandoer som brukerprogrammet utfører. ... er hvor mye tid som ble brukt av dette programmet i current modes.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0028", "start": 2047.32, "end": 2143.6, "token_count": 299, "text": "RIL her, det er hvor lang totaltid det tok. User, det er hvor mye CPU som ble brukt i use mode. Det skal vi snakke om i neste uke. Men kort sagt er det vanlige kommandoer som brukerprogrammet utfører. ... er hvor mye tid som ble brukt av dette programmet i current modes. Typisk for et regneprogram som dette her, så bruker man veldig lite operativstemkjernen. Stort sett er det bare programmet selv som står og kjører. Men så skal vi se på det som er litt mystisk... Vi går nå inn i programmet igjen og så gjør jeg én liten endring. Det er en sånn sort-metode som har den syntaksen der. Det eneste dere trenger å vite, er at dette funksjonsskallet sorterer RE-data. Det er den eneste forskjellen jeg gjør. Ellers så skjer nøyaktig det samme her nede. Går gjennom like mange løkker. Det er klart, det ville ikke være noen forskjell på... Summen bør bli den samme. Det er bare at her ligger tallene i rekkefølge i dataeiere. Så kompilerer jeg på nytt. Og så tar tiden på hvor lang tid det tar.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0029", "start": 2123.36, "end": 2225.04, "token_count": 300, "text": "Det er klart, det ville ikke være noen forskjell på... Summen bør bli den samme. Det er bare at her ligger tallene i rekkefølge i dataeiere. Så kompilerer jeg på nytt. Og så tar tiden på hvor lang tid det tar. Og nå ser vi at nå er de første elementene sortert, med null først. Alle elementene med null i kommer først. Og så kommer... Men da ser vi... Her gikk plutselig programmet veldig mye fortere. Du brukte 17 sekunder her oppe og 11 sekunder her nede. Og det er... Det er det som er det store spørsmålet. Er det noen som kan se hva dette kan komme av? Hvorfor i all verden går plutselig programmet fortere bare fordi man sorterte RA? For... Nå må vi begynne å se på hva i all verden som skjer her. Random array er det samme i begge tilfeller. Så sorterer man det. Og så hopper man hit. Her skriver du ut de ti første. I det andre tilfellet var det bare nuller. Men den indre løkken her... Her skjer jo akkurat det samme. Den eneste forskjellen er at data-r-et er sortert.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0030", "start": 2193.72, "end": 2299.04, "token_count": 293, "text": "Random array er det samme i begge tilfeller. Så sorterer man det. Og så hopper man hit. Her skriver du ut de ti første. I det andre tilfellet var det bare nuller. Men den indre løkken her... Her skjer jo akkurat det samme. Den eneste forskjellen er at data-r-et er sortert. Og hva vil det si i praksis? Jo, det... I praksis så vil... ... vil man først gå gjennom en masse elementer hvor denne testen ikke står til. Og så går man gjennom en masse elementer, altså ca. 15 000, hvor dette slår til. Det kommer noen forslag... Mer effektiv pipelining. Ja, det... Det k... Absolutt det kan man si. At pipeliningen er mer effektiv. Men på hvilken måte? Går inn i flere ganger, den som foreslår. Men det gjør man. Dette vil slå til akkurat like mange ganger. Så antall institusjoner som utføres, er faktisk den samme. Kanskje den bare sjekker if-testen én gang? Nei, den vil måtte sjekke if-testen hver eneste gang.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0031", "start": 2276.36, "end": 2374.36, "token_count": 286, "text": "Dette vil slå til akkurat like mange ganger. Så antall institusjoner som utføres, er faktisk den samme. Kanskje den bare sjekker if-testen én gang? Nei, den vil måtte sjekke if-testen hver eneste gang. For selv om r-er er sortert, så vet ikke operativsystemet eller noen andre... Så det må sjekkes hver gang. Er ikke dette speculative execution? Jo, nettopp! Dette er speculative execution. For når programmet kjøres, så... Så lærer... CPU-en lærer da hva som har skjedd ved forrige gang. Føre statistikk over hva som skjer, når man kommer til denne IF-testen i maskinkoden. Og når RAI-et er sortert, så vil systemet da lære at... Ja, denne testen her, den slår ikke til. Så her er det bare å... Her satser vi på at den ikke slår til. Og da bruker man speculative execution, så man begynner å utføre den insesjonen man tror det er. Og da går det mye fortere, for da har man... Når det ikke er større enn 127, så hopper man over.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0032", "start": 2357.56, "end": 2435.96, "token_count": 286, "text": "Og da bruker man speculative execution, så man begynner å utføre den insesjonen man tror det er. Og da går det mye fortere, for da har man... Når det ikke er større enn 127, så hopper man over. Og etterpå så kommer det masse RAI-data som er større enn 127. Og da vil hver gang så gjetter da systemet, eller CPU-en, gjetter da på at nå skal vi legge sammen. Og da utføres den addisjonen hver gang. Og den gjetter riktig hver gang. Og det er ganske mange ganger. 32 000 elementer. Så hver eneste gang den kommer til gift-testen, så gjetter den riktig. Så blir det en bom, kanskje noen bommer, helt til den skjønner... OK. Her. Herfra og ut. Så gjetter den riktig. Og dermed går det mye fortere. Derimot, når r1 er hulter til bulter, så ville omtrent annenhver gang så ville dette her skifte. Det er typisk at branch prediction bare bommer hele tiden. Så det er riktig som oppsummert her.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0033", "start": 2411.26, "end": 2503.48, "token_count": 284, "text": "OK. Her. Herfra og ut. Så gjetter den riktig. Og dermed går det mye fortere. Derimot, når r1 er hulter til bulter, så ville omtrent annenhver gang så ville dette her skifte. Det er typisk at branch prediction bare bommer hele tiden. Så det er riktig som oppsummert her. Branch prediction gjetter da veldig ofte korrekt, og systemet går mye raskere. Det er spørsmål om hvorfor det går så fort å sortere R-øyet. Ja, dette kommer jo egentlig i tillegg. Det er et godt spørsmål. Denne operasjonen er veldig rask. I tillegg ser vi at den utføres før løkkene. Så jeg sorterer ikke 50 000 ganger. Hvis jeg hadde lagt inn sorteringen der, så hadde det ikke vært så stor effekt. Men i forhold til å kjøre den løkka 50 000 ganger, hvor man går gjennom 32 000 rA i biter, så er denne operasjonen veldig rask. Det tar litt tid, men det har ikke noe særlig effekt for totaltiden.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0034", "start": 2473.28, "end": 2612.66, "token_count": 206, "text": "så hadde det ikke vært så stor effekt. Men i forhold til å kjøre den løkka 50 000 ganger, hvor man går gjennom 32 000 rA i biter, så er denne operasjonen veldig rask. Det tar litt tid, men det har ikke noe særlig effekt for totaltiden. Ok. Da ser jeg at klokka har blitt mye, så vi tar et kvarters pause der. ... i pausen og komme med spørsmål. Etter pausen skal vi starte på multitasking. Men da tar vi en kort pause der. Ikke en kort pause... Vi tar en kvarters pause til... Hva blir det? 10.33 kan vi starte. ......... Det er veldig vanskelig å forstå hva som skjer i denne situasjonen. Det er veldig vanskelig å forstå hva som er sant og hva som er sant.", "source": "lecture"}
{"lecture_id": "os14del8", "chunk_id": "os14del8_0000", "start": 0.0, "end": 113.04, "token_count": 283, "text": "Ja... Det var ett spørsmål til da vi kjørte... Ops... her... da vi kjørte dette programmet... Hvordan Birt kan være 4516 før man har sagt hva Sertson Perez skal være. Det er et godt spørsmål. Men vi kan da se på... Vi ser på bare selve programmet. Og vi ser det er i utgangspunktet ganske stort. Så hvis jeg... Skal vi se. Her har jeg ikke noe. Nei. Her er det helt tomt. Så hvis jeg nå kjører programmet før jeg begynner å... Så spørsmålet er... Hvordan kan det være 4500 K før vi i det hele tatt begynner å kjøre? Og da kan vi først se på det jeg prøvde å gjøre. Hva jeg ser på størrelsen på A.out. Når vi ser størrelsen på A.out, er utgangspunktet 8,3... Sånn at... Sånn at jeg begynner å kjøre det, så er det ikke så rart at... At det virtuelle adresserommet er 4516. Skulle nesten tro det var større. Siden det er 8K her oppe.", "source": "lecture"}
{"lecture_id": "os14del8", "chunk_id": "os14del8_0001", "start": 90.0, "end": 181.0, "token_count": 258, "text": "Sånn at... Sånn at jeg begynner å kjøre det, så er det ikke så rart at... At det virtuelle adresserommet er 4516. Skulle nesten tro det var større. Siden det er 8K her oppe. For her har jeg jo ikke begynt å definere noe ennå. Men i hvert fall... Uten at jeg kan si detalj om hver eneste bite der, så er hovedpoenget at Adopt-Out er et stort program. Det linker sammen en masse biblioteker osv. Blant annet for å kunne skrive ut. Og selv om man selv bare... Hello world ic... tar mange kilobite med plass. Så alt dette er all infrastrukturen som skal til for å sette opp et program i det hele tatt. Den biten vil også ta mye ram. Og det er utgangspunktet. Men så ser vi etterpå. Det vi gjorde, var når vi legger på 4K. Så ser vi i et RA, så blir den biten bare skjøtet direkte på det eksisterende. Det er veldig fint.", "source": "lecture"}
{"lecture_id": "os2del8", "chunk_id": "os2del8_0000", "start": 0.0, "end": 106.56, "token_count": 293, "text": "Sannhetstabell er viktig for det vi skal jobbe med. En sannhetstabell er en tabell som sier nøyaktig hvordan en logisk funksjon er. Denne skal vi bruke når vi f.eks. skal legge sammen tall. Så har vi noen ideer om hvordan skal A-ne og B-ene kobles sammen. Hva skal vi ha ut? Denne FAB-en her er bare et eksempel. Det er et eksempel på en logisk funksjon. Da er det rett og slett spesifisert på den måten at man setter opp alle mulige verdier for A og B, og så må man spesifisere i hvert tilfelle hva den funksjonen skal bli. F.eks. hvis A er lik 0 og B er lik 0, altså ikke kommer spenning inn på noen av portene, da skal det være en positiv spenning ut. Og tilsvarende for de andre linjene. Logisk uttrykk... Så det vi som regel gjør, er at vi vet... Vi vet hva vi ønsker å få til, hva vi ønsker å skape med den logiske kretsen vår. Men så trenger vi å kunne tegne det med and or not-porter.", "source": "lecture"}
{"lecture_id": "os2del8", "chunk_id": "os2del8_0001", "start": 73.72, "end": 172.82, "token_count": 284, "text": "Og tilsvarende for de andre linjene. Logisk uttrykk... Så det vi som regel gjør, er at vi vet... Vi vet hva vi ønsker å få til, hva vi ønsker å skape med den logiske kretsen vår. Men så trenger vi å kunne tegne det med and or not-porter. Det er her de logiske uttrykkene kommer inn. Gitt en sannhetsstabell... Vi ser nå på to variabler, men vi kan også ha mange... Da kan man helt tilsvarende sette opp sandnesstabeller. Med fire variabler blir det 16 forskjellige linjer i sandnesstabellen. Med to så blir det fire linjer. Men uansett så kan man på samme måte ut ifra sandnesstabellen, så kan man skrive ned et logisk uttrykk. Det er en systematisk måte å gjøre det på. Det man gjør... Den teknikken man bruker for å få til det, er at man ser på at et sånt som et produkt A ganger B... Det vil kun være lik 1 hvis både A og B er like 1. I alle andre tilfeller så vil det produktet være lik 0. Så hvis man da tar en...", "source": "lecture"}
{"lecture_id": "os2del8", "chunk_id": "os2del8_0002", "start": 150.02, "end": 239.96, "token_count": 299, "text": "Det man gjør... Den teknikken man bruker for å få til det, er at man ser på at et sånt som et produkt A ganger B... Det vil kun være lik 1 hvis både A og B er like 1. I alle andre tilfeller så vil det produktet være lik 0. Så hvis man da tar en... Så plukker man ut alle linjene i sannhetstabellen som skal være 1. Og så... Og så lager man det produktet, det logiske produktet, som er sånn at det blir lik én i dette tilfellet. Det blir litt teoretisk, men vi kan se på f.eks. den... Skal vi se hvilket eksempel bruker jeg her. Jo, den første. I dette tilfellet så er det to ledd i sandelstabellen som er igjen. Og da tar vi det hvis A og B skal bli lik 1, altså hvis A ganger B skal bli lik 1. Da må vi gange sammen ikke A, gange ikke B. Altså vi setter en not på A og en not på B. Da får vi 1, og da får vi ut produktet 1. Så det vi da må gjøre, er å ha med dette leddet. Det er det første leddet man må ha med.", "source": "lecture"}
{"lecture_id": "os2del8", "chunk_id": "os2del8_0003", "start": 220.4, "end": 299.56, "token_count": 295, "text": "Da må vi gange sammen ikke A, gange ikke B. Altså vi setter en not på A og en not på B. Da får vi 1, og da får vi ut produktet 1. Så det vi da må gjøre, er å ha med dette leddet. Det er det første leddet man må ha med. I den summen som skal utgjøre hele det logiske uttrykket. Hvis du har med dette leddet her, så er du sikker på at det leddet... Hvis A er 0 og B er 0, så blir dette leddet 1. I alle andre tilfeller så blir det 0. Det smarte da er at da kan man starte med dette leddet, og så kan man legge til eller ta med en pluss eller en logisk li. Man tar med pluss og legger til alle de andre leddene i Sandnes-stabellen som skal bli 1. I vårt tilfelle er det bare ett annet ledd som skal bli 1. Det er dette leddet her. Og for å få med et produkt som alltid gir 1, så må dette bare være A ganger B. A ganger B er alltid 1 hvis A og B er 1. I alle andre tilfeller blir det 0.", "source": "lecture"}
{"lecture_id": "os2del8", "chunk_id": "os2del8_0004", "start": 282.36, "end": 367.36, "token_count": 295, "text": "Det er dette leddet her. Og for å få med et produkt som alltid gir 1, så må dette bare være A ganger B. A ganger B er alltid 1 hvis A og B er 1. I alle andre tilfeller blir det 0. Så hvis vi legger til A ganger B til dette leddet her, så vil vi få... Som vi ser her nede, så får vi dette uttrykket, som da er hele det logiske uttrykket for hele denne sannhetsstabellen. Så dette oppsummerer hva vi gjør. Vi skriver ned tilsvarende uttrykk for alle linjer som gir 1 i sannhetsstabellen. I vårt tilfelle så var det to sånne. Og så, til slutt, så legger vi sammen alle disse med o-er. Og da blir det riktig for at... Ikke sant, sånn som a ganger b? Det er bare hvis a liker 1 og b liker 1 at denne gir en logisk ener. I alle andre tilfeller så gir dette null. Men det å legge til null endrer ikke uttrykket. Hvis du har en variabel A pluss null, det gir A. Så det endrer ikke noe på uttrykket.", "source": "lecture"}
{"lecture_id": "os2del8", "chunk_id": "os2del8_0005", "start": 343.0, "end": 408.82, "token_count": 229, "text": "Det er bare hvis a liker 1 og b liker 1 at denne gir en logisk ener. I alle andre tilfeller så gir dette null. Men det å legge til null endrer ikke uttrykket. Hvis du har en variabel A pluss null, det gir A. Så det endrer ikke noe på uttrykket. Og dermed vil vi oppnå at denne logiske funksjonen her alltid er riktig. De detaljene her er ikke så ekstremt viktige, men det som er veldig viktig, det er, hvis vi går tilbake til sandelstabellen, at gitt en sandelstabell så kan vi bare Skrive ned, med de enkle reglene jeg viste til, et logisk uttrykk. Og det er det logiske uttrykket som vi trenger. For nå skal vi ta det logiske uttrykket og så skal vi tegne en krets. Og da er vi på en måte i mål.", "source": "lecture"}
{"lecture_id": "linux11del12", "chunk_id": "linux11del12_0000", "start": 0.0, "end": 118.48, "token_count": 293, "text": "Ja. Hvis jeg gjør en LS, så ser vi... Jeg får ut en masse tekst her. Og jeg kan f.eks. ta LS av fil.kr. Da får jeg ut en hel fil. Så kan jeg, som jeg har gjort tidligere, så kan jeg si OK, jeg vil at fil skal være lik LS-fil. Jeg kan faktisk gjøre det uten parenteser også. Jeg tror det skal tilsvare helt om jeg gjør det på denne måten. Det gir samme resultatet. Så jeg kan også tilordne en kommando på den måten. Men det som er det store klubbet med Powershaw, er at den variabelen fil som jeg får ut nå... Det ser jo ut som bare en tekstterreng, men i virkeligheten så er dette et helt objekt. Og hvordan kan jeg finne ut at dette er et objekt? Hvordan vet jeg det? Jo, jeg kan ta output fra... Jeg kan ta det objektet. Jeg kan sende en pipe til getmember. Getmember er en kommandelett som viser hvilke objekter... Nei, hvilke metoder og hvilke properties et objekt har. Jeg sender nå dollarfee til getmember, og da får jeg en lang liste av properties og metoder som...", "source": "lecture"}
{"lecture_id": "linux11del12", "chunk_id": "linux11del12_0001", "start": 90.0, "end": 201.24, "token_count": 287, "text": "Jeg kan sende en pipe til getmember. Getmember er en kommandelett som viser hvilke objekter... Nei, hvilke metoder og hvilke properties et objekt har. Jeg sender nå dollarfee til getmember, og da får jeg en lang liste av properties og metoder som... Dette objektet, dollar-feel, det har en rekke metoder og properties. Det er et stort og omfattende objekt. Det er ikke bare den lille teksten der som det ville vært i Linux. Og dette er veldig nyttig, for da kan jeg straks se at OK, dollar-feel har en metode, nei, en property name. Da kan jeg se... OK, da... Hva skjer hvis jeg skriver ut... dollarfeet.name? Jo, da får jeg ut akkurat den propertyen. Og f.eks. lengd. Det gir størrelsen på filen. Og dette er veldig nyttig, for da kan man veldig enkelt trekke ut all informasjon som har med denne... Hvis vi ser på andre properties her, så kan du ha last access time. Det er da sist noen aksesserte denne filen. Eller last right time. Det er sist noen skrev til denne filen.", "source": "lecture"}
{"lecture_id": "linux11del12", "chunk_id": "linux11del12_0002", "start": 163.2, "end": 280.96, "token_count": 294, "text": "Og f.eks. lengd. Det gir størrelsen på filen. Og dette er veldig nyttig, for da kan man veldig enkelt trekke ut all informasjon som har med denne... Hvis vi ser på andre properties her, så kan du ha last access time. Det er da sist noen aksesserte denne filen. Eller last right time. Det er sist noen skrev til denne filen. En annen fin ting er at man kan begynne med å skrive last, så kan man igjen tabbe. Så kan jeg løpe gjennom de forskjellige propertyene. F.eks. last right time. Men så ser vi at last right time det ser også ut som bare en dato. Men det er ikke bare en dato. Det er faktisk et objekt, det også. Så alt i PowerCell er i utgangspunktet objekter. Så dette er et datetime-objekt. Og det kan vi igjen få ved å sende... Nei. Sorry. Get number. Det kan også forkortes med game. Hvis jeg sender det til get number, så vil jeg se at dette er en type system datetime. Det kan være nyttig hvis du kan ta en daytime og legge til en time. Eller en uke. Og en rekke andre metoder og properties.", "source": "lecture"}
{"lecture_id": "linux11del12", "chunk_id": "linux11del12_0003", "start": 240.0, "end": 337.22, "token_count": 225, "text": "Nei. Sorry. Get number. Det kan også forkortes med game. Hvis jeg sender det til get number, så vil jeg se at dette er en type system datetime. Det kan være nyttig hvis du kan ta en daytime og legge til en time. Eller en uke. Og en rekke andre metoder og properties. Sånn som day, day og week, kind, minute, month osv. Så... Da kan du se igjen på get member. Det var bare et eksempel på at GetMember har et alias som GM. Så kan jeg få ut filen sitt bård, f.eks. Hva da? Dette er da en veldig nyttig konstruksjon. At du kan plukke ut properties, og så er det et objekt igjen. Og så kan du plukke ut properties ved det objektet kommer ut. Og så kan du veldig effektivt plukke ut all den informasjonen du trenger, fra filer.", "source": "lecture"}
{"lecture_id": "linux11del14", "chunk_id": "linux11del14_0000", "start": 0.0, "end": 135.28, "token_count": 287, "text": "OK. Én ting som kan være litt forvirrende i starten, er informasjon som LS. Vi ser jo at dette gir flere filer. Så hvis jeg gir ls file.txt, da får jeg ut et objekt som er ganske enkelt et filobjekt. Vi kan se hva det heter. Men når jeg gjør LS, så ser jo egentlig så er det... Det er jo filinfo, men det ser jo på en måte ut som et r-e også. Og det kan jeg finne ut hvis jeg ikke bare sender til getnumber, men hvis jeg plukker ut... Hvis jeg bruker en funksjon... Så vil jeg se at det oppet egentlig er fra LS, det er et array. Jeg får egentlig ut et array av fileinfo-objekter. Hvis man undersøker det nærmere, så er dette et system array. Dette er en av de klassene som er definert. Nå kan han slå opp definisjonen på det og hva slags metoder det har osv. Men det som er viktig i praksis, er at LS vil ha... Det vil være et r'a. Det er den første mappa som lisses. LSA1... Det vil da være nummer to som lisses. Fil og tekster.", "source": "lecture"}
{"lecture_id": "linux11del14", "chunk_id": "linux11del14_0001", "start": 90.0, "end": 163.4, "token_count": 149, "text": "Nå kan han slå opp definisjonen på det og hva slags metoder det har osv. Men det som er viktig i praksis, er at LS vil ha... Det vil være et r'a. Det er den første mappa som lisses. LSA1... Det vil da være nummer to som lisses. Fil og tekster. På den måten så ser vi at vi har et r-rei av filer. På samme måte er det med PS. Vi kan se på PS av... PCA-4 vil være den femte prosessen som listes i prosesslisten. PCA-0 er den første vi ser. De listes alfabetisk.", "source": "lecture"}
{"lecture_id": "linux4del9", "chunk_id": "linux4del9_0000", "start": 0.0, "end": 94.96, "token_count": 295, "text": "Nå skal vi se på nummerik i skjell og i skjellskrept. Og vi har sett før at vi kan tilordne variabler på denne måten her - x er lik 1. Og da kan vi skrive ut x på denne måten her. Men hvis vi nå ønsker å f.eks. øke x med 1, og så prøve å skrive noe sånt x er lik x... Pluss én, så går det dårlig. Og tradisjonelt i skjell, så i bornskjell og også i bærskjell, så er det... Ganske tungent syntaks for å legge sammen tall. Så det jeg vil anbefale, er å bruke denne syntaksen her. Så er det litt kryptisk med doble parenteser. Men hvis man gjør det... Så kan man bruke Java-lignende syntaks. Så dette her vil da øke X-verdien med én. Så kan man gjøre det tilsvarende. Og da går det også an å blande litt... Altså bruke Dollar-X og tilordne den. Det funker også. Men det er ikke alt som går. Hvis jeg bruker Dollar-X her... Så ser vi... Da får vi en feilmelding.", "source": "lecture"}
{"lecture_id": "linux4del9", "chunk_id": "linux4del9_0001", "start": 70.88, "end": 166.18, "token_count": 289, "text": "Så kan man gjøre det tilsvarende. Og da går det også an å blande litt... Altså bruke Dollar-X og tilordne den. Det funker også. Men det er ikke alt som går. Hvis jeg bruker Dollar-X her... Så ser vi... Da får vi en feilmelding. Men bortsett fra det så kan man gjøre det meste med den metoden der. Så kan du sette et nytt tall lik dette her, for eksempel. Og så skrive ut... Skriv ut tall. Så det er den enkleste formen, nemlig å sette uttrykk inn i parentester. Da kan man også gjøre sånn som å teste... La oss si teste om tallet er mindre enn seks punkter. Det vil være da en gyldig test. Den kan vi sjekke med tolv spørsmålstegn. Og som vi husker, null betyr tru. Så denne slår til når testen er sann. Hvis vi sjekker om tallet er mindre enn tre, så er det folds. Én er folds. Litt bakvendt, men sånn er det. Så generelt, hvis du skal gjøre nummerikk i et shell eller et chellscript,", "source": "lecture"}
{"lecture_id": "linux4del9", "chunk_id": "linux4del9_0002", "start": 141.56, "end": 175.52, "token_count": 114, "text": "Og som vi husker, null betyr tru. Så denne slår til når testen er sann. Hvis vi sjekker om tallet er mindre enn tre, så er det folds. Én er folds. Litt bakvendt, men sånn er det. Så generelt, hvis du skal gjøre nummerikk i et shell eller et chellscript, så bruk denne syntaksen. Litt ekstra å skrive. Litt stygt, men da funker det bra.", "source": "lecture"}
{"lecture_id": "linux7del14", "chunk_id": "linux7del14_0000", "start": 0.0, "end": 106.04, "token_count": 299, "text": "Deleting... skal ikke bruke så veldig mye tid på det. Men konteinere er en veldig kast å bruke. Det gjelder også virtuelle maskiner. For dere som kjører skytjenester, så er dere vant til at dere bare kan starte på en ny VM. Og hvis et eller annet galt skjer, så kan man ta et nytt image og starte en ny VM. Men i enda høyere grad. Det er kast og bruk. Ja, her er det litt om... vekt for å se på... Jeg tror vi hopper over det. Dere kan jo se på det på egen hånd. Vi kan ta litt hvordan man... Man sletter konteinere. Generelt, hvis du ikke sletter konteinerne, så ligger alle der når du lister dockercontainer-LS. Det er ikke noe stort problem, for det tar ikke veldig mye plass. Men det kan bli rotete, så det kan være greit å rydde opp på det. Dockercontainer-RM, det sletter da tegnerne. Dokker image RM sletter image. Image kan ta litt plass. Dere har ikke så voldsomt mye plass på VM-ene, men dere har noen gigabyte. Men hvis dere kjører veldig mange forskjellige dokker-imager,", "source": "lecture"}
{"lecture_id": "linux7del14", "chunk_id": "linux7del14_0001", "start": 85.12, "end": 127.76, "token_count": 122, "text": "Dockercontainer-RM, det sletter da tegnerne. Dokker image RM sletter image. Image kan ta litt plass. Dere har ikke så voldsomt mye plass på VM-ene, men dere har noen gigabyte. Men hvis dere kjører veldig mange forskjellige dokker-imager, dokker-images og spesielt store, så kan det ta mye plass. Og da kan det være lurt å slette... Det vil da gjerne alle. I hvert fall de som ikke er aktive.", "source": "lecture"}
{"lecture_id": "linux5del8", "chunk_id": "linux5del8_0000", "start": 0.0, "end": 115.24, "token_count": 294, "text": "Vi skal nå se på hvordan du kan bruke read til å lese filer og annen input inn til en valløkke, sånn at man kan gå gjennom én og én linje. Så vall read linje. Da kjøres read linje-kommandoen rid linje om og om igjen. Og man leser linje for linje. Så har man som vanlig... Rundt hver. Og her inne så kan man da behandle linje. Så kan vi f.eks. for å skrive ut linjenummer... Så kan vi øke en varabel i med én. Og så kan vi skrive ut linje nummer... nummer i. Så kan vi skrive ut linje. Inni løkka så har dollar linje har da innhold av hele linjen. Sånn. Og så kan vi prøve å kjøre den. La oss si vi da har en fil som heter fil.txd, som er på fire linjer. Nå kan vi sende den til Readline. Catfield.exe. Og så sender vi da den til Wild.shell, som er skriptet til venstre. Den må vi ha med prikk-slush. Sånn. Da ser vi det har kommet en syntaxfeil i linje seks. Wildreadline.", "source": "lecture"}
{"lecture_id": "linux5del8", "chunk_id": "linux5del8_0001", "start": 80.82, "end": 195.2, "token_count": 299, "text": "som er på fire linjer. Nå kan vi sende den til Readline. Catfield.exe. Og så sender vi da den til Wild.shell, som er skriptet til venstre. Den må vi ha med prikk-slush. Sånn. Da ser vi det har kommet en syntaxfeil i linje seks. Wildreadline. Hvis jeg mangler et anfallstegn, så kjører jeg på nett, sender filen til meg, og da ser vi. Da skrives det på linjenummer foran hver linje. Så på den måten så kan man gå gjennom en fil og behandle linje for linje. Så kan man også sende filen... Man kan ta hver dodgell og så kjøre den Det fungerer ikke helt med å eksplisitt sende inn med med mindre 1. Da vil den gjennomgå hver linje, én for én. Så kan man også eksplisitt sende filen inn til denne Vildan-løsningen. På denne måten. Man kan si fil.taxi... Be om at den sendes inn. Så kan jeg da kjøre... Uten argumenter kan jeg kjøre Vile-skriftet, og da skjer akkurat det samme som om han sendte det eksplisitt inn.", "source": "lecture"}
{"lecture_id": "linux5del8", "chunk_id": "linux5del8_0002", "start": 174.88, "end": 209.0, "token_count": 118, "text": "På denne måten. Man kan si fil.taxi... Be om at den sendes inn. Så kan jeg da kjøre... Uten argumenter kan jeg kjøre Vile-skriftet, og da skjer akkurat det samme som om han sendte det eksplisitt inn. En annen måte man kan gjøre dette på, er å sende en pipe med fil.tkd til Vile-konstruksjonen på denne måten. Og igjen så skjer nøyaktig det samme.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0000", "start": 0.0, "end": 79.22, "token_count": 291, "text": "Oppgavene denne uken... er ikke sånn veldig mange. Vi tar det litt forsiktig denne uken. Vi har kommet ganske langt i pensum, sånn at vi har råd til å ta det litt rolig nå før påske. Så det er ikke sånn veldig mange obligatoriske oppgaver. Noen litt teoretiske, og det er mer... Det kan være veldig nyttig å gjøre de også, sånn at du tenker igjennom hva det egentlig er vi holder på med. Disse kan man da også se løsningsforslag på. Men jeg anbefaler veldig ikke å gå rett på løsningsforslaget når du jobber med de oppgavene her. Prøv å komme opp med svar, og så sammenlign med løsningsforslaget. Det er absolutt å anbefale. Og så er det noen oppgaver etter hvert om det vi skal se på nå. I forelesningen prioritering Java og kjøring av Java-tråder. Og ikke minst så kommer det etter hvert en oppgave her med Java-tråder og synkronisering. Og vi skal se hvor viktig det er å synkronisere når du har", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0001", "start": 54.78, "end": 148.96, "token_count": 290, "text": "Og så er det noen oppgaver etter hvert om det vi skal se på nå. I forelesningen prioritering Java og kjøring av Java-tråder. Og ikke minst så kommer det etter hvert en oppgave her med Java-tråder og synkronisering. Og vi skal se hvor viktig det er å synkronisere når du har en felles variabel. Men det er det som egentlig er hovedtemaet i dag. Spørsmål? Et par ukens nøtter. Ja. Om eksamen blir med karakter eller ikke, vet du om det er avklart ennå? Ja, kjempebra. Det har jeg fått avklaring på nå, at det blir med ATLF-karakterer. Så bra. Jeg kan legge ut en kunngjøring om det etterpå også, kanskje. Så alle får det med seg. Jeg bare glemte det. Så kjempefint. Det kommer et par dokkeroppgaver. Det er litt endring på planen her. Vi syns det passer fint å starte med Windows PowerShell etter påske. Så blir det i hvert fall to runder med PowerShell digitalt. Så kommer det litt om dokker og DokkerHub denne uken.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0002", "start": 120.0, "end": 219.8, "token_count": 295, "text": "Det kommer et par dokkeroppgaver. Det er litt endring på planen her. Vi syns det passer fint å starte med Windows PowerShell etter påske. Så blir det i hvert fall to runder med PowerShell digitalt. Så kommer det litt om dokker og DokkerHub denne uken. Det blir en sånn påskespesial med bare litt innhold. En kvarter-halvtime innhold, så ikke så veldig mye. Og oppgaver til dette vil da komme etter påske. Men uansett, jeg kan prøve å kanskje få lagt ut dette om Windows og Poshell og oppgaver, sånn at de som ønsker å ligge litt foran, vi kan jobbe. Og har lyst til å jobbe litt i påsken. De kan jobbe med jobb med det. Ok, andre spørsmål eller karakterer... Nei, eller karakterer! Kommentarer! Jeg har ikke fått noen hos meg, i hvert fall. Nei. Ok... Ja, oi... Og jeg hadde helt glemt å si at det er veldig hyggelig å se så mange av dere. Det er kjempebra. Vi har 75 stykker i chatten her nå. Veldig godt at dere står opp og jobber videre.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0003", "start": 193.84, "end": 287.94, "token_count": 297, "text": "Jeg har ikke fått noen hos meg, i hvert fall. Nei. Ok... Ja, oi... Og jeg hadde helt glemt å si at det er veldig hyggelig å se så mange av dere. Det er kjempebra. Vi har 75 stykker i chatten her nå. Veldig godt at dere står opp og jobber videre. Jeg skjønner at det kan være veldig tungt for mange av dere som sitter alene og jobber og ikke får besøke venner osv. Og ikke minst det jeg tror dere savner, er å kunne sitte sammen med andre studenter og samarbeide. Prøv gjerne, spesielt hvis dere jobber i gruppe, å få til litt jevnlig kontakt. Lag SOM-møter osv. Bruk screen når dere jobber med kommandolinje. Det er mulig å få til å samarbeide, også om dere sitter på hvert deres sett. Så prøv mest mulig å få til det. Hvor mange forsøk har vi på MC2? Dere har flere forsøk. I praksis så kan dere få... Ikke uvennlige forsøk, men dere kan få mange forsøk. Men... Og det er også derfor vi har lagt opp opplegget,", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0004", "start": 260.68, "end": 342.96, "token_count": 295, "text": "Så prøv mest mulig å få til det. Hvor mange forsøk har vi på MC2? Dere har flere forsøk. I praksis så kan dere få... Ikke uvennlige forsøk, men dere kan få mange forsøk. Men... Og det er også derfor vi har lagt opp opplegget, sånn at man ikke bare kan få nye og nye forsøk hele tiden. For da er det mange som bare klikker i vei. Så tanken er at hvis du ikke får det til første gang, Så må du ta kontakt med en studentassistent, ikke minst... eller meg. Og så må du få diskutere... Finn ut hva det var du gjorde feil. Og kanskje hva må du jobbe litt mer med før du tar et nytt forsøk. Så jobb skikkelig med den responsen du får først, og så tar du et nytt forsøk. Men dette er ikke noen sånn straffedom. Det er først og fremst ment som et tilbud. Altså at dere skal få tilbakemeldinger på... Det er også viktig at MC2 er nok litt vanskeligere enn MC1. Og du kan også være litt uheldig. Det trekkes fra 30 spørsmål kanskje.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0005", "start": 323.22, "end": 419.96, "token_count": 292, "text": "Men dette er ikke noen sånn straffedom. Det er først og fremst ment som et tilbud. Altså at dere skal få tilbakemeldinger på... Det er også viktig at MC2 er nok litt vanskeligere enn MC1. Og du kan også være litt uheldig. Det trekkes fra 30 spørsmål kanskje. Så du kan være litt uheldig og få noen som er spesielt vanskelig, som ikke er så lett å ta på ett minutt. Men fristen er, som det står her... Det blir vel litt vanskelig. 9. april, som er fristen for MC2. Så prøv absolutt å få gjort den denne uken, sånn at du får flere sjanser. Hvis dere ikke klarer den. Ok... Forrige gang så så vi på Plattformaget, aller først. Hva som skjedde når man flytter programmet rundt på plattformer. Hovedkonklusjonen er at programmer som er kopilert, sånn som C og C++, som kopieres til maskinkode, er helt plattformavhengig. Det betyr at de kan bare kjøre der på den plattformen de er kopilert. De fleste moderne språk, sånn som...", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0006", "start": 396.02, "end": 517.1, "token_count": 298, "text": "Hovedkonklusjonen er at programmer som er kopilert, sånn som C og C++, som kopieres til maskinkode, er helt plattformavhengig. Det betyr at de kan bare kjøre der på den plattformen de er kopilert. De fleste moderne språk, sånn som... Java og Python, CSharp også, de kjører virtuelle maskiner. Sånn at da komplerer man til en eller annen type bytekode. Og så kjøres det i en virtuell maskin. Det betyr at det er en virtuell maskin for hver plattform. Så da går det an i prinsippet å flytte kompliert kode fra en plattform til en annen. Men det kan ha litt avhengighet av versjoner, som vi så sist. Så begynte vi å se på tråder. Vi så litt teoretisk på tråder, men vi fikk ikke sett så veldig mye på det rent praktisk. Så vi skal ta en kjapp rekapitulering av Java-tråder, og så se på spesielt mange samtidige tråder. Så vi kan starte med det. Det var eksempelet. Trådprogram implementert i Java, som implementerer en rekke tråder...", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0007", "start": 464.4, "end": 572.02, "token_count": 286, "text": "Så vi skal ta en kjapp rekapitulering av Java-tråder, og så se på spesielt mange samtidige tråder. Så vi kan starte med det. Det var eksempelet. Trådprogram implementert i Java, som implementerer en rekke tråder... Jeg tror jeg kjører noe sånt som 20 tråder i det eksempelet her. Det var noen oppgaver i forrige uke som gikk ut på at man skulle se på hvor mange tråder som kjøres av operativsystemet når man kjører to tråder. Og da var det overraskende nok veldig mange tråder. Borti 20 tråder. Og det var en masse sånne workertreads som operativsystemet setter opp. Oi! Eller som JVM starter opp, og som operativsystemet skredulerer. Så det er hjelpetråder som står klare til å gjøre alle slags forskjellige oppgaver. Det koster ikke så mye å ha disse ekstra trådene, så derfor er det veldig mange programmer, sånn som Java... Chrome og andre applikasjoner som kjører en rekke tråder.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0008", "start": 553.42, "end": 639.26, "token_count": 265, "text": "Så det er hjelpetråder som står klare til å gjøre alle slags forskjellige oppgaver. Det koster ikke så mye å ha disse ekstra trådene, så derfor er det veldig mange programmer, sånn som Java... Chrome og andre applikasjoner som kjører en rekke tråder. Det koster ganske lite for operativseiere å ha de trådene kjørende når de ikke bruker CPU. Men her er da et eksempel på... Et eksempel som kjører med mange tråder. Så vi kan gå ned til klassen Calcmanny her, som er main. Og det som skjer her, er at vi definerer en intreds som er 20. Så det vi skal gjøre, er å starte 20 uavhengige tråder. Og her så kalles... Er opprettet et nytt trådobjekt, med new. Så her opprettes en ny tråd.  Og så skriver jeg bare ut at vi starter... At vi starter 20.30. Og så går jeg inn i forløkket.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0009", "start": 608.44, "end": 713.5, "token_count": 293, "text": "Og her så kalles... Er opprettet et nytt trådobjekt, med new. Så her opprettes en ny tråd.  Og så skriver jeg bare ut at vi starter... At vi starter 20.30. Og så går jeg inn i forløkket. Ja, og her starter jeg da tråd nummer null. A new caltred. Og så når collegue 1, så starter jeg tråd nummer 1, osv. Så bare skriver jeg ut at jeg starter tråd nummer 1. Og så kaller jeg på startmetoden for tråden. Så dette skjer da 20 ganger. Og hvis vi går opp her, så ser vi hva som skjer når calc3d kalles. Da... Når calc3d startes opp, så kjøres denne in-hit-metoden her. Count pluss pluss... Da er det viktig å huske at... Count er definert som static. Og det betyr at det finnes bare én av den for alle trådene. Vi har 20 tråder, men bare én enkelt count-variabel. Mens en variabel som ikke blir deklarert som static, sånn som int id... Den har vi da 20 stykker av.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0010", "start": 691.2, "end": 788.06, "token_count": 291, "text": "Og det betyr at det finnes bare én av den for alle trådene. Vi har 20 tråder, men bare én enkelt count-variabel. Mens en variabel som ikke blir deklarert som static, sånn som int id... Den har vi da 20 stykker av. Når vi har en maks her, så kunne også den vært static. For den skal være den samme for alle. Men her lager vi også 20 maks. Men det viktigste her er konto ID. Så hver gang vi øker konto, så økes den felles variabelen. Og dermed så teller den opp fra 1 og opp til 20. Og så setter ID en leak count, så da får vi en ID på hver. Og så sier jeg 3d nummer først 1 i starting... Så 3d nummer 1 Calculated Work. Og her ser vi at den tråden gjør et arbeid. Men det som skjer inneni work, er at 15 ganger så regner det ut en kjempelang løkke. Java er såpass rask at selv om man står og regner sånn som dette her, så kan man gjøre det... Hvor mange ganger kjører vi det her?", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0011", "start": 764.7, "end": 867.02, "token_count": 281, "text": "Men det som skjer inneni work, er at 15 ganger så regner det ut en kjempelang løkke. Java er såpass rask at selv om man står og regner sånn som dette her, så kan man gjøre det... Hvor mange ganger kjører vi det her? 900 millioner ganger. Det er så mange ganger... Så blir det høyere enn en int. Så da får man trøbbel. Så dette er ekstremt mange ganger den går, men likevel så regner det mange ganger. Og det som er hovedpoenget her nå, med tråder, er at når vi setter i gang de, så kjører de samtidig. Så vi kan... Vi kan kompilere. Og så kjører vi her, kanskje. I sidevinduet, så vi kan se på trådene mens vi kjører. Jeg ser det starter veldig kjapt, så startes det opp 20 tråder. Så kan vi se på det i topp. I utgangspunktet så ser vi at det er én prosess som kjører. Men hvis vi legger på... Hvis vi velger ut 'number of threads',", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0012", "start": 830.48, "end": 929.94, "token_count": 299, "text": "I sidevinduet, så vi kan se på trådene mens vi kjører. Jeg ser det starter veldig kjapt, så startes det opp 20 tråder. Så kan vi se på det i topp. I utgangspunktet så ser vi at det er én prosess som kjører. Men hvis vi legger på... Hvis vi velger ut 'number of threads', så ser vi at den ene prosessen som kjører, den har 37 tråder. Vi ser også at faktisk de fleste andre prosesser også har en rekke tråder. Sånn som Zoom har 64 tråder. Ops, har 27. Men det som er spesielt med våre tråder nå, er at 20 av de er de regnetrådene som vi har startet. Så kan vi også, hvis vi taster H, så får vi se alle trådene. Og da ser vi at det er 20 tråder som står og kjører. Så kunne vi også ta og se på Last Use CPU. Hvis jeg velger den... Så ser vi da at trådene er skredulert på forskjellige CPU-er. Noen er da så klart på mange, for her er det bare 0 til 7 av CPU-er.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0013", "start": 900.36, "end": 1033.68, "token_count": 299, "text": "Og da ser vi at det er 20 tråder som står og kjører. Så kunne vi også ta og se på Last Use CPU. Hvis jeg velger den... Så ser vi da at trådene er skredulert på forskjellige CPU-er. Noen er da så klart på mange, for her er det bare 0 til 7 av CPU-er. Men vi ser da hvordan det er operativsystemet som skredulerer alle trådene. Java bare setter i gang en masse tråder, og så blir det skredulert av OS. Og akkurat det samme er det med alle de andre programmene. De starter en rekke tråder, men de blir skredulert som helt uavhengige enheter. Ok... Da skal vi se på et annet eksempel. Og prioritet i Java er... Det vi skal se, er at prioritet er litt merkelig implementert, på en måte, i Java. Det er implementert forskjellig i Linux og i Windows, f.eks. Men i dette eksempelet skal vi se at det faktisk ikke er det. Men før vi diskuterer det, så kan vi se på... Skal vi se... Jeg har et Java-program som heter Prior.java. Dette programmet implementerer da prioritet.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0014", "start": 998.66, "end": 1111.14, "token_count": 283, "text": "Det er implementert forskjellig i Linux og i Windows, f.eks. Men i dette eksempelet skal vi se at det faktisk ikke er det. Men før vi diskuterer det, så kan vi se på... Skal vi se... Jeg har et Java-program som heter Prior.java. Dette programmet implementerer da prioritet. Det ligner ganske på de andre programmene vi har sett på. I dette tilfellet så startes det to tråder. Prioritredd én som jeg kaller S1, og én som jeg kaller S2. Jeg kaller det prioritredd fordi jeg bruker prioritering. Og så setter jeg prioriteten til S1 til 5. Det er faktisk default-prioritet, så hvis jeg ikke hadde gjort det, så ville den likevel vært 5. Og så er det noen variabler. SN Norm Priority. Jeg skriver ut den for å få frem hva som er normal prioritet, eller standard. Og så skriver jeg ut maks prioritet og min prioritet. Maksprioritet er ti, hvis jeg husker riktig, og min er én. Så dette er motsatt av nice, for nice er jo hvor snill man er med andre. Så det er ti prioritetsklasser.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0015", "start": 1092.16, "end": 1176.18, "token_count": 289, "text": "Og så skriver jeg ut maks prioritet og min prioritet. Maksprioritet er ti, hvis jeg husker riktig, og min er én. Så dette er motsatt av nice, for nice er jo hvor snill man er med andre. Så det er ti prioritetsklasser. Ja, min er null. Vi starter på null, og så er maks ti. Så... Nei... Sorry, glem det jeg sa. Dette er ikke prioriteten. Det som jeg sender med der, er antall millisekunder som tråden skal sove før den starter. Vi ser begge starter med en gang. Men jeg setter prioriteten for tråd nummer to. Den setter jeg til 10. Så vi starter én tråd med prioritet 5 og én med prioritet 10. 10 er det aller høyeste, så da burde man forvente at et eller annet... Det skjer sånn at tråd nummer to kjører mer. Vi har jo bedt om at den skal få høyere prioritet. Vi kan se kjapt øverst her hva vi gjør. Det vi gjør, ligner veldig på det vi gjorde tidligere. Vi har en tellecount og en ID, så de får ID 1 og 2.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0016", "start": 1158.86, "end": 1240.5, "token_count": 297, "text": "Vi har jo bedt om at den skal få høyere prioritet. Vi kan se kjapt øverst her hva vi gjør. Det vi gjør, ligner veldig på det vi gjorde tidligere. Vi har en tellecount og en ID, så de får ID 1 og 2. Og så i tillegg så er det millisekunder. Det skal vi bruke på Windows etterpå når vi skal kjøre det der. Gi tråden noen millisekunder før den starter. Men vi gir den null millisekunder her, sånn at det er lettere å se hva som skjer i vårt tilfelle. Så vi kan jo også se hvordan vi behandler to forskjellige tråder. For de kjører i utgangspunktet samme kode, men så ser vi... Her er Rønn-metoden, som sier tråd nummer én sover først, null millisekunder, og så starter den. Men så ser vi... Her har jeg en if-test hvor jeg da tester hvis Ida er lik to, så setter jeg prioritet til én. Så på den måten kan man da behandle tråder og gjøre forskjellige ting, selv om trådene i utgangspunktet er like. Så vi kan se...", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0017", "start": 1220.54, "end": 1330.14, "token_count": 292, "text": "Her har jeg en if-test hvor jeg da tester hvis Ida er lik to, så setter jeg prioritet til én. Så på den måten kan man da behandle tråder og gjøre forskjellige ting, selv om trådene i utgangspunktet er like. Så vi kan se... Hvordan dette ser ut når vi kompilerer og... ... kjører denne tråden. Så da ser vi. Vi starter default prioritet fem. Vi starter nummer én med prioritet fem. Og så starter nummer to med prioritet... ti. De kjører annenhver gang. Det går akkurat like fort med nr. 1 som med nr. 2. Så går vi ned her og setter prioriteten for tråd nr. 2. Den setter vi til 1, så da burde den ha minst prioritet. 1 er da det minste. Men likevel så ser vi at disse to jobber akkurat like fort. Hvis vi prøver å se på topp når de jobber, så... Så får begge 100 % CPU. Vi har ikke noe nice eller noe sånt der. Men vi har jo også sett tidligere at hvis man har nice-prosesser, så... Så vil de ikke være nice i forhold til hverandre.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0018", "start": 1300.54, "end": 1419.98, "token_count": 300, "text": "Hvis vi prøver å se på topp når de jobber, så... Så får begge 100 % CPU. Vi har ikke noe nice eller noe sånt der. Men vi har jo også sett tidligere at hvis man har nice-prosesser, så... Så vil de ikke være nice i forhold til hverandre. Det jeg kunne prøve å gjøre, var å starte trådene med TaskSet. Det har jeg faktisk ikke tenkt på tidligere, men vi kan gjøre et forsøk. Hvis jeg nå ser på Last Use TPU... Og så kan jeg prøve å starte Java med TaskSet minus 1.0. Sånn. Og så H. Da ser vi begge trådene kjører på tråd 0. Men vi ser at de deler helt broderlig. Selv om den ene tråden nå har prioritet 5. Og den andre har prioritert 10. Så tråd nr. 2 har prioritert 10, men dette gir ikke utslag på hvor mye CPU de får. Og vi kan ikke annet enn konkludere med at Linux faktisk ikke bryr seg om den prioriteten. Om du setter prioritet 1 eller 10, spiller ingen rolle. Men vi overlater til oppgavene.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0019", "start": 1400.98, "end": 1490.54, "token_count": 292, "text": "hvor mye CPU de får. Og vi kan ikke annet enn konkludere med at Linux faktisk ikke bryr seg om den prioriteten. Om du setter prioritet 1 eller 10, spiller ingen rolle. Men vi overlater til oppgavene. I oppgavene denne uken så blir dere bedt om å... Prøve å få Linux til å ta hensyn til Java-prioriteten. Og det er mulig hvis du kjører Java på en spesiell måte med et spesielt flagg. Men det virker ikke da hvis du kjører som vanlig bruker. Du må faktisk kjøre som Ruth, og i tillegg må du ha et spesielt flagg. Implementerer JVM dette her med NICE? At man setter NICE på Java-trådene, sånn at de har prioritet i forhold til hverandre. For å se dette eksplisitt, så må du gjøre sånn som jeg gjorde nå, og bruke tastet ditt, sånn at de eksplisitt kjører på samme CPU. Hvis ikke, så ser du ikke effekten, med mindre du har veldig mange... Har veldig mange tråder. Flere tråder enn Sepur. Ok. Da tenkte jeg å...", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0020", "start": 1464.7, "end": 1557.34, "token_count": 282, "text": "For å se dette eksplisitt, så må du gjøre sånn som jeg gjorde nå, og bruke tastet ditt, sånn at de eksplisitt kjører på samme CPU. Hvis ikke, så ser du ikke effekten, med mindre du har veldig mange... Har veldig mange tråder. Flere tråder enn Sepur. Ok. Da tenkte jeg å... Ja, jeg tenkte egentlig også å kjøre trådene på... Kjøre trådene på Windows. Men skal vi se... Ja, det tar litt tid å sette opp de Windows-trådene. Hvis vi gjør det etter pausen, så kan vi heller se på... Nå gå til litt flere slides om tråder. Så vi skal se litt mer teoretisk på tråder. Og aller først skal vi se på blokkerende systemkall. Men før vi avslutter demoen her... Vi skal se etter pause at hvis vi gjør dette samme på Windows... kjører det samme programmet, så vil vi se at Windows faktisk tar hensyn til prioriteten. Og den tar kraftig hensyn. Så hvis du er i tråd med prioritet 4,", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0021", "start": 1534.3, "end": 1659.48, "token_count": 293, "text": "Vi skal se etter pause at hvis vi gjør dette samme på Windows... kjører det samme programmet, så vil vi se at Windows faktisk tar hensyn til prioriteten. Og den tar kraftig hensyn. Så hvis du er i tråd med prioritet 4, så får den mye lavere prioritet enn en tråd med prioritet 5. Mens Linux da ikke tar hensyn i det hele tatt. Ok... At man ønsker å lese noe fra en disk. Og da er det jo naturlig at programmet ikke går videre før den har lest det som den har på disken. Og i alle denne type systemkall hvor man må vente på resultatet før programmet kan gå videre, det er da representert ved et blokkerende systemkall. For da gjør man et systemkall, og så blokkerer det prosessen. Og det kan være veldig uheldig. For du ønsker gjerne at en applikasjon skal være responsiv, selv om den leser noe fra disk eller gjør noe annet som krever IO. Og derfor så... Det var på en måte en av hovedideene for å få inn tråder. Nemlig at programmereren kan da... Ved hjelp av IO...", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0022", "start": 1637.7, "end": 1736.54, "token_count": 300, "text": "For du ønsker gjerne at en applikasjon skal være responsiv, selv om den leser noe fra disk eller gjør noe annet som krever IO. Og derfor så... Det var på en måte en av hovedideene for å få inn tråder. Nemlig at programmereren kan da... Ved hjelp av IO... Programmet trenger da ikke å vente på blokkerende systemkall. Noen eksempler på den type systemkall er sånn som read and write, await og opplagt når du venter på andre til to år, og sleep er også opplagt blokkerende, for der venter du eksplisitt. Det mest typiske er sånn som read, hvor du leser noe fra disk, Og vente på å få resultatet før du kan kjøre videre. Så fins en del ikke-blokkerende systemkall også, eller veldig mange, sånn som GetPayDay og GetTimeOfDay f.eks. De eksekverer ferdig veldig raskt, og de blokkerer da ikke prosessen. Trådmodeller. Det finnes mange implementasjoner av tråder, og dette er de tre vanligste og mest brukte trådmodellene. Og den som er aller vanligst med en gang, det er én til én.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0023", "start": 1716.7, "end": 1804.08, "token_count": 281, "text": "Trådmodeller. Det finnes mange implementasjoner av tråder, og dette er de tre vanligste og mest brukte trådmodellene. Og den som er aller vanligst med en gang, det er én til én. Det er denne modellen her, hvor for hver tråd brukeren starter, f.eks. vi starter et Java-program, JVM starter 20 tråder... Tilsvarende være 20 kjernetråder. Det betyr i praksis at du har 20 tråder som skreduleres som 20 uavhengige enheter. 20 uavhengige regneoperasjoner. I tillegg så har vi én til mange. Vi kan se litt på neste slide hvor disse blir beskrevet. Én til mange, det... Betyr at alle trådene skeduleres som én prosess. Det er ikke så veldig vanlig lenger. Tidligere fantes en del sånne implementasjoner. Det kalles ofte green threats. Den aller første implementasjonen på Linux av JVM var til green threats. Men det er jo litt upraktisk, for det som skjer da, er at programmeren selv må skedulere.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0024", "start": 1786.96, "end": 1866.5, "token_count": 295, "text": "Tidligere fantes en del sånne implementasjoner. Det kalles ofte green threats. Den aller første implementasjonen på Linux av JVM var til green threats. Men det er jo litt upraktisk, for det som skjer da, er at programmeren selv må skedulere. Vi har f.eks. en metode som kalles yield, som sier OK, nå vil jeg gi fra meg SFP-en. Og GIL er en sånn... Er ikke så mye i bruk når man overlater til operativsystemet å skredulere. Men dette er da den trådmodellen. Så har vi 1-1, som er den mest vanlige, hvor alle tråder skreduleres uavhengig av hverandre av operativsystemet. Det er det som vi har i Java, og etter pausen skal vi se på noe Post-X-Treads. De skreduleres også på denne måten. Så har man en tredje måte, mange-til-mange. Og da skreduleres de som én-til-én, hvis det ikke er altfor mange tråder. Men så har det vært en del operativsystemer som har man implementert mange-til-mange for tilfeller hvor det er ekstremt mange tråder.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0025", "start": 1844.1, "end": 1945.3, "token_count": 295, "text": "Så har man en tredje måte, mange-til-mange. Og da skreduleres de som én-til-én, hvis det ikke er altfor mange tråder. Men så har det vært en del operativsystemer som har man implementert mange-til-mange for tilfeller hvor det er ekstremt mange tråder. Altså mange hundre eller mange tusen tråder. Kan det være uheldig at alle disse trådene skreduleres hver for seg? Så lager man grupper, sånn at én kjernetråd tar hånd om et sett av tråder. Når det er snakk om mange, kan det være 50 tråder som skreduleres av denne, og 50 av denne tråden. Da får de en intern skredulering seg imellom. Synkronisering. Ja, da er vi over på et helt nytt tema, men som ligger tett opp til dette med tråder og problemer man kan få når man kjører tråder samtidig. Kommunikasjon og kommunikasjon er generelt viktig når man har felles ressurser eller felles data som flere prosesser samtidig behandler. Og dette kommer til å være tema resten av dagen.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0026", "start": 1917.56, "end": 2007.22, "token_count": 283, "text": "men som ligger tett opp til dette med tråder og problemer man kan få når man kjører tråder samtidig. Kommunikasjon og kommunikasjon er generelt viktig når man har felles ressurser eller felles data som flere prosesser samtidig behandler. Og dette kommer til å være tema resten av dagen. Vi skal se på noen konkrete eksempler på hva som kan gå galt hvis prosesser prøver å endre på felles data samtidig. Da kan det bli en skikkelig krasj. Og de prinsippene vi følger, er at prosesser må ikke endre felles data samtidig. Vi har et eksempel med et billettsystem. Og hvis den ene prosessen da tar en billett og oppdaterer... Og deler ut den billetten samtidig som en annen gjør det samme... Da kan vi få problemer. Det er en såkalt race condition. Det har noe å si hvem som kommer først frem. Databasen kan ødelegges. Den variabelen kan få en feil verdi hvis man ikke synkroniserer. Det er derfor synkronisering er så viktig.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0027", "start": 1987.5, "end": 2085.38, "token_count": 300, "text": "Da kan vi få problemer. Det er en såkalt race condition. Det har noe å si hvem som kommer først frem. Databasen kan ødelegges. Den variabelen kan få en feil verdi hvis man ikke synkroniserer. Det er derfor synkronisering er så viktig. Og dette er altså noe som praktisk dukker opp med en gang man har prosesser som jobber mot noe felles. Og det er veldig vanlig. Nå som man har masse distribuerte systemer som kobler seg opp mot samme database, så er det veldig viktig å synkronisere disse tilgangene til data. Et andre prinsipp vi har, er at en prosess ikke bør lese fellesdata mens en annen endrer dem. Den må også kunne vente på resultater fra en annen prosess. Det er en annen måte å synkronisere på, som vi skal se på senere. Da må prosessene seg imellom synkroniseres. Serialisering er det temaet vi først og fremst skal se på i dag. Da ser vi på prosesser eller tråder som aksesserer felles data. Det kan være bare én enkelt variabel. Men det som er viktig, er at de har felles.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0028", "start": 2057.86, "end": 2142.6, "token_count": 294, "text": "Da må prosessene seg imellom synkroniseres. Serialisering er det temaet vi først og fremst skal se på i dag. Da ser vi på prosesser eller tråder som aksesserer felles data. Det kan være bare én enkelt variabel. Men det som er viktig, er at de har felles. Med jawatråder vil det være en static... Når vi definerer en variabel som static, så er den felles. Vi skal se noen eksempler med at dette er en saldo. Det er opplagt at når man gjør endringer på saldo, så må det gjøres systematisk. Og da må én av gangen jobbe på de dataene. Problemet er typisk at man leser av en saldo. Det kan være fra en database, men det kan også være fra en felles variable ramm. Men som vi har sett tidligere, når SEP 1 skal regne på det, så vil den verdien lastes inn i registrene. Og der kan det fort bli krøll hvis to prosesser ikke er synkronisert, eller serialisert, når de gjør dette. Det vi selv realiserer, er at vi sier at én av gangen får tilgang til denne fellesvarerabelen.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0029", "start": 2122.86, "end": 2196.02, "token_count": 290, "text": "så vil den verdien lastes inn i registrene. Og der kan det fort bli krøll hvis to prosesser ikke er synkronisert, eller serialisert, når de gjør dette. Det vi selv realiserer, er at vi sier at én av gangen får tilgang til denne fellesvarerabelen. Hele denne problemsiden kalles 'of the race condition', altså konkurranse om en felles ressurs. Den race condition vil da være sånn at utfallet av å kjøre programmene er forskjellig avhengig av hvilken prosess som kommer først fram til den felles ressursen. Og sånn kan det absolutt ikke være. Alt programmet bør være sånn at... Hvis du kjører de med akkurat samme randbetingelser, akkurat samme forutsetninger, så bør resultatet bli det samme. Men det skal vi se. Hvis man ikke serialiserer, så skal vi se flere eksempler på at da går det virkelig galt, og data ødelegges. Så er det også et viktig poeng at det er programmereren selv som må serialisere prosesser. Men som vi skal se, operativsystemet legger til rette for det.", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0030", "start": 2175.2, "end": 2281.66, "token_count": 293, "text": "Men det skal vi se. Hvis man ikke serialiserer, så skal vi se flere eksempler på at da går det virkelig galt, og data ødelegges. Så er det også et viktig poeng at det er programmereren selv som må serialisere prosesser. Men som vi skal se, operativsystemet legger til rette for det. Muligheter som programmereren har for å selvrealisere. Ja, men da tar vi en pause der. Men jeg skal bare først ta... Det var et interessant spørsmål i chatten her. Hvis det ikke har så mye å si hvordan prosessene kjøres... Jeg antar tanken her da... Sånn som Java. Java på Linux, hvis den ikke tar hensyn til prioriteten... Vel, det... Vanligvis så har alle tråder samme prioritet. Og det fungerer i de aller fleste tilfeller helt greit. Fordi operativsystemet er så bra. De fordeler ressurser, og operativstemme er veldig bra til å gi respons til prosesser som ønskerespons fra et tastetrykk f.eks. Så får den lynraskt den responsen. Hovedgrunnen til at man ikke har tatt så nøye på implementering av prioritet,", "source": "lecture"}
{"lecture_id": "os11time1", "chunk_id": "os11time1_0031", "start": 2257.5, "end": 2333.14, "token_count": 230, "text": "De fordeler ressurser, og operativstemme er veldig bra til å gi respons til prosesser som ønskerespons fra et tastetrykk f.eks. Så får den lynraskt den responsen. Hovedgrunnen til at man ikke har tatt så nøye på implementering av prioritet, som i Java, er at operativstemme gjør den jobben veldig bra. Likevel mange fordeler. En av de største er at prosessen slipper å vente. Du kan ha en tråd som står og venter på input og oppputt, og ikke minst så kan du utnytte flere CPU-er. Hvis du har en server med 48 CPU-er, så er det helt strålende å kunne sette i gang 48 tråder som jobber i parallell på dem og utnytter ressursene. Ja, OK. Men da tar vi en pause der. Og så tar vi et kvarters pause til... hva blir det? 9.35 kan vi ta en pause.", "source": "lecture"}
{"lecture_id": "os2del6", "chunk_id": "os2del6_0000", "start": 0.0, "end": 75.9, "token_count": 217, "text": "Ja. Så det vi ønsker å oppnå som sluttresultat, altså helt til slutt i dag, så skal vi ha en krets som legger sammen to tolv. Generelt, det vi ønsker å oppnå, er binære funksjoner på denne måten her. At det kommer inn input ABC. Dette kan da f.eks. være tall. Og så kommer det ut funksjoner i andre enden. F av ABC og G av ABC. For eksempel denne funksjonen, være... Være en sum av... La oss si du har DEF også her. At ABC pluss DEF som to tall... At de til sammen gir det resultatet som kommer ut her. Eller at man har satt sammen not eron, not or and, sånn at man får... Og for å kunne lage alle typer CPU-operasjoner, trenger man å kunne lage alle mulige slags binære funksjoner.", "source": "lecture"}
{"lecture_id": "linux2del1", "chunk_id": "linux2del1_0000", "start": 0.0, "end": 79.64, "token_count": 295, "text": "Manualsider. Veldig ofte så trenger man å vite hvilke opsjoner man kan bruke på Linux-kommandoer. Og da kan det være greit å se på manualsidene. Eller eventuelt hvis man vil finne ut nøyaktig hvordan en kommando virker. Så i dette eksempelet skal vi se på manualsidene for date. Mann er da kommandoen som man bruker for å se på manualsider. Og så har jeg en kommando som heter date, som jeg ønsker å se. Det får man allsiden til. Da ser vi for opp en side med info. Og da kan man bla seg side for side nedover ved å taste mellomromstasten. Sånn som dette her. Så blar man seg nedover. Så kan man også gå oppover igjen med piltaster. Pil opp og pil ned kan man gå frem og tilbake. Ofte er det nyttig å kunne gå helt opp, og da taster man en G. Press H for hjelp eller Ku for kvitt. Kunne gå ut er viktig. Da taster man bare en Ku, så er man ute. Alternativt kan man taste H hvis man ønsker hjelp. Da får man listet opp alle disse shortcuttene som man kan bruke.", "source": "lecture"}
{"lecture_id": "linux2del1", "chunk_id": "linux2del1_0001", "start": 60.0, "end": 149.56, "token_count": 297, "text": "Press H for hjelp eller Ku for kvitt. Kunne gå ut er viktig. Da taster man bare en Ku, så er man ute. Alternativt kan man taste H hvis man ønsker hjelp. Da får man listet opp alle disse shortcuttene som man kan bruke. Det er ikke så veldig mange man trenger å bruke i praksis. Noe som kan være veldig nyttig, det er å søke. Så her ser vi. Man taster av en slash og skriver inn det man søker etter. Og så taster man N for hvert neste... for hvert neste sted dette står. I Date, f.eks., så kan vi søke etter ordet 'our' i Manal-siden. Da taster jeg inn en slash og 'our', og så taster jeg nå... N... Så kommer jeg til neste forekomst av over. N nedover, så. Det gikk kanskje litt fort. Jeg kan ta det en gang til. Mandate... For å søke så taster jeg nå en slash. Så kommer det opp en slash her nede. Så skriver jeg igjen det jeg søker på. 'Over' og'return'. Så kommer det første eksempelet på 'over' her oppe, og så taster jeg bare 'n' nedover.", "source": "lecture"}
{"lecture_id": "linux2del1", "chunk_id": "linux2del1_0002", "start": 130.72, "end": 162.0, "token_count": 115, "text": "Mandate... For å søke så taster jeg nå en slash. Så kommer det opp en slash her nede. Så skriver jeg igjen det jeg søker på. 'Over' og'return'. Så kommer det første eksempelet på 'over' her oppe, og så taster jeg bare 'n' nedover. Da kan jeg bla meg nedover og finne alle forekomster. Akkurat det er den mest nyttige saken man trenger for å se på manualet sitt.", "source": "lecture"}
{"lecture_id": "os13del17", "chunk_id": "os13del17_0000", "start": 0.0, "end": 87.7, "token_count": 294, "text": "Det er en figur fra Tallbaum, og det viser en oversettelse fra det virtuelle adresserommet til det fysiske adresserommet. Her er det veldig små størrelser. Vi har 32K fysisk minne. 64K virtuelt minne. På moderne maskiner har man opplevd mye større... Større både fysisk og virtuell minne, men prinsippene er akkurat det samme. Så her ser vi at... Hvor mange er det? Åtte av disse virtuelle sidene er mappet til fysisk minne. Det er akkurat de samme tabellene som vi hadde tidligere. Her nederst her er page nummer null. Vi ser at den ligger i fysisk frame nummer to. Så det går en pil herfra og så opp hit. Og da må man... Herfra inn til MMU-en, så må MMU-en lynraskt oversette den min-adressen til den riktige i den fysiske. Og det er det neste slide viser hvordan man gjør. Dette viser da på en måte den fysiske kablingen i MMU som gjør at et MMU-oppslag går på faktisk brøkdelen av en klokkesykkel.", "source": "lecture"}
{"lecture_id": "os13del17", "chunk_id": "os13del17_0001", "start": 64.5, "end": 161.3, "token_count": 279, "text": "den min-adressen til den riktige i den fysiske. Og det er det neste slide viser hvordan man gjør. Dette viser da på en måte den fysiske kablingen i MMU som gjør at et MMU-oppslag går på faktisk brøkdelen av en klokkesykkel. Fordi det er ikke en... Det regnes ikke ut ved hjelp av CPU-institusjoner. Det er direkte kabling. Og måten man får det til på, er at man har en innkommende adresse. Vi kan se konkret på dette eksempelet her. Har vi en innkommende adresse 8196... Vi har tolv bit her. Det betyr at vi har en... Hver side har to i tolvte adresser. Og to i tiende er 1024, så to i tolvte er 4096. Så disse tolvbitene her utgjør da 4096 adresser. Og det er liksom internt på siden hvilken adresse det er. Men så... I det virtuelle adresserommet har vi da i tillegg fire bit. Og de bitene sier hvilken side i det virtuelle adresserommet det er.", "source": "lecture"}
{"lecture_id": "os13del17", "chunk_id": "os13del17_0002", "start": 139.82, "end": 241.88, "token_count": 295, "text": "Så disse tolvbitene her utgjør da 4096 adresser. Og det er liksom internt på siden hvilken adresse det er. Men så... I det virtuelle adresserommet har vi da i tillegg fire bit. Og de bitene sier hvilken side i det virtuelle adresserommet det er. Og 0100, det er da dette... Det vil da være null, nei, enere. Og dette er toere. Så dette er tallet to. Så vi ser at den peker her. Det er det virtuelle side nummer to. Og det betyr at... Ja... Dette vil da bli to ganger 4096. Det er da 8192. Du kan se på de tallene. Jeg har skrevet det i detalj i forelesningsresultatene hvordan man oversetter det. Så prøv å gå gjennom det. Det er en typisk liten eksamensoppgave. Men dette er for at dere virkelig skal se mekanismen i hvordan dette oversettes. Så det som skjer, er at her har vi side to. Og de neste tolvbitene er bare hvor i adresserommet det er. Og her står det fire... I adresserommet. Adresse nummer fire.", "source": "lecture"}
{"lecture_id": "os13del17", "chunk_id": "os13del17_0003", "start": 215.14, "end": 307.1, "token_count": 283, "text": "i hvordan dette oversettes. Så det som skjer, er at her har vi side to. Og de neste tolvbitene er bare hvor i adresserommet det er. Og her står det fire... I adresserommet. Adresse nummer fire. Men så ser vi, da har vi det smarte, at her er MMU-tabellen. Og da er det bare 110... Den peker til... Nei, 2. Den peker til 110. Her står det 110. Så da tar man de bitene her som er i page nummer to. Så står det 110. Og det er da... Det er da tallet seks. Og så limer man da bare det tallet seks som sier hvilken frame det er. Så det sier fysisk frame nummer seks. Og det er akkurat det som vi så her nede. Her er vi page nummer to. Page nummer null, én, to. Page nummer to peker på fysisk adresse nummer seks. Og det gjøres ved at man limer den... Eller kabler, da. 110, sånn at den kommer først. Og så sendes da bare... Hele denne her sendes videre til databussen.", "source": "lecture"}
{"lecture_id": "os13del17", "chunk_id": "os13del17_0004", "start": 280.32, "end": 352.82, "token_count": 254, "text": "Så det sier fysisk frame nummer seks. Og det er akkurat det som vi så her nede. Her er vi page nummer to. Page nummer null, én, to. Page nummer to peker på fysisk adresse nummer seks. Og det gjøres ved at man limer den... Eller kabler, da. 110, sånn at den kommer først. Og så sendes da bare... Hele denne her sendes videre til databussen. Og det er på magisk vis... Det er da den riktige utgående fysiske adressen. Men vi har bare lint på et på en måte seks ganger 4096. Og det ble 24576. Og så kommer det firetall i tillegg. Firetallet er bare offset hvor i denne siden som den adressen vi skal ha tak i, ligger. Så dette viser hvordan man... Ved å bare kable dette helt riktig med bit for bit, så får man en hardware-bit, altså MMU, som gjør denne oversettelsen i løpet av brøkdelen av et skudd.", "source": "lecture"}
{"lecture_id": "os2del19", "chunk_id": "os2del19_0000", "start": 0.0, "end": 97.04, "token_count": 275, "text": "Her startet vi i dag tidlig. Dette var det vi ønsket. Håper dere nå ser hvordan man generelt går fram for å lage en sånn type krets som dette her, som aderer to firebits-tall. Hvis vi får tid, skal vi se litt etterpå på hvordan man... Man kan simulere dette her. Men dere vil nå kunne... Det er vel en oppgave denne uken også, hvor dere blir bedt om å lage en krets som legger sammen trebitstall. Firebitstall, så er det bare å legge til én bit til. Men det jeg håper dere ser, er hvordan man helt logisk kan... Man setter opp sannhetsstabeller hvor man koder inn den logikken som man ønsker skal skje, den operasjonen som skal skje med to binære tall. Og så skal man få ut det tredje. Og dette kan da utvides til alle mulige logiske operasjoner som man kan tenke seg en CPU trenger å gjøre. Og det er et ganske begrenset antall operasjoner av denne typen. Man må kunne trekke fra tall. Sammenligne tall, si om de er like eller ulike.", "source": "lecture"}
{"lecture_id": "os2del19", "chunk_id": "os2del19_0001", "start": 74.8, "end": 157.04, "token_count": 282, "text": "Og dette kan da utvides til alle mulige logiske operasjoner som man kan tenke seg en CPU trenger å gjøre. Og det er et ganske begrenset antall operasjoner av denne typen. Man må kunne trekke fra tall. Sammenligne tall, si om de er like eller ulike. Man må kanskje kunne gjøre skiftoperasjoner som tilsvarer å gange et tall med to. Man må kunne gjøre multiplikasjon, som er en god del mer kompleks. Men på samme måte kan du bruke multiplikasjonsalgoritmene og lage den kretsen du måtte ønske. Divisjon er kanskje enda mer komplisert, men når du har addisjon og subtraksjon, så kan du bygge de andre kretsene. Litt på samme måte. Man vet hvilken logikk man ønsker, og da kan man skrive ned en sanstabell, så kan man tegne en krets, og så får man akkurat den operasjonen man ønsker. Inni en notport så er det to transitorer. Så er det seks transistorer. Så da ser vi på hvordan en hel CPU er lagd", "source": "lecture"}
{"lecture_id": "os2del19", "chunk_id": "os2del19_0002", "start": 133.92, "end": 165.12, "token_count": 101, "text": "Man vet hvilken logikk man ønsker, og da kan man skrive ned en sanstabell, så kan man tegne en krets, og så får man akkurat den operasjonen man ønsker. Inni en notport så er det to transitorer. Så er det seks transistorer. Så da ser vi på hvordan en hel CPU er lagd bare av transistorer, som egentlig er bare små brytere som man setter sammen.", "source": "lecture"}
{"lecture_id": "linux7del15", "chunk_id": "linux7del15_0000", "start": 0.0, "end": 149.86, "token_count": 297, "text": "Der kommer det. Ser at jeg har en liste med tegnere. Så kan jeg ta RM på én av dem. ID-en der er faktisk det samme som host name. Alle har en del sånne rare navn, Fervent Galileo og Tender Williams osv. Percy Ellis. Man kan også bruke det navnet, som er enklere å huske. Men nå tar jeg bare sletter med ID-en. Hvis jeg lister på nytt nå, så forsvant en av vennene mine. Ja, vi kan prøve Loving Shep. Da forsvant den også. Hvis jeg tar bare dokker, container, LS, så får jeg bare de som kjører. Men det er ingen nå. Minus A gir alle. At vi hadde en brun... Jeg kan prøve volum sånn som det. Da ser vi... Slette alle Stop containers. Da sier jeg ja, og da... Der er alle borte. En gang iblant så kan det være greit å rydde opp. Der, ja. Jeg tror jeg skrev kommandoen feil. Skal prøve å finne ut hva jeg gjorde feil. Ja, jeg skrev... og da fikk jeg ikke opp noen ting. Det kan kanskje være instruktivt, for jeg fikk ikke noen god feil.", "source": "lecture"}
{"lecture_id": "linux7del15", "chunk_id": "linux7del15_0001", "start": 120.0, "end": 275.84, "token_count": 293, "text": "Der, ja. Jeg tror jeg skrev kommandoen feil. Skal prøve å finne ut hva jeg gjorde feil. Ja, jeg skrev... og da fikk jeg ikke opp noen ting. Det kan kanskje være instruktivt, for jeg fikk ikke noen god feil. Det ser bare helt dumt ut. Men det er viktig å ha syntaksen riktig. Docker image LS. Da ser jeg... Disse tar litt mer plass. Men... Så disse imagene kan det være lurt å rydde opp i. Men likevel, det tar ikke så voldsom plass. 64 MB er egentlig veldig lite. Hvis man har en ubuntu virtuell maskin, så tar det i hvert fall en white med disk-plus. Man kan også slette disse. Da forsvant den. Hvis jeg nå starter en ny i bunte... Vi kan prøve å starte 14.04, så er vi fortere der. Det jeg gjorde nå, var at jeg ikke ba om et skjell. Da får jeg ikke oppi noe skjell, sånn at jeg kan gjøre noe inni. Siden jeg ikke hadde lastet ned 1404 før, så blir den lastet opp. Men... jo, jeg fikk faktisk opp et skjell likevel.", "source": "lecture"}
{"lecture_id": "linux7del15", "chunk_id": "linux7del15_0002", "start": 240.0, "end": 329.98, "token_count": 178, "text": "Det jeg gjorde nå, var at jeg ikke ba om et skjell. Da får jeg ikke oppi noe skjell, sånn at jeg kan gjøre noe inni. Siden jeg ikke hadde lastet ned 1404 før, så blir den lastet opp. Men... jo, jeg fikk faktisk opp et skjell likevel. Da kan vi også se hosename. Det er den ID-en som vi får når vi lister opp. Så... Ja, det dere kan se nå, er at... Jeg har eksplisitt fått opp den 14.04. Hvis jeg nå går ut igjen og lister images, så ser vi at nå har jeg fått opp den litt mindre. Da ser vi igjen. Andre gang jeg kjører, så går det mye fortere.", "source": "lecture"}
{"lecture_id": "os1del5", "chunk_id": "os1del5_0000", "start": 0.0, "end": 85.98, "token_count": 297, "text": "Ja... Timeplaneksamen er det kanskje viktig å si noe om. I utgangspunktet så er det avsluttende tre timers eksamen i Inspera. Men så har det pga. eksamensavviklingen, at ikke den kan gjøres i lurveien, i hvert fall i utgangspunktet, så er det ikke helt bestemt ennå om... Det blir som i fjor, hvor det da ble bestått eller ikke bestått med tretimers Inspera-eksamen. Dette er som sagt ikke avgjort ennå, men det er noe som dere kan ha en innflytelse på. Så jeg tenker jeg etter hvert kan legge ut en poll, og så spørre dere litt om hva dere ønsker. For det er mange som syns det er kjedelig å ha en CV med bare bestått... Men samtidig så er det ikke... Så er det opplagte problemer med å gjennomføre eksamener når du har alle hjelpemidler og mulighet til å diskutere med andre, f.eks. Eller til og med få hjelp på eksamen. Det er noen problemstillinger rundt det, men der er det ikke... Som sagt, der er det ikke helt bestemt hva årets løsning blir.", "source": "lecture"}
{"lecture_id": "os1del5", "chunk_id": "os1del5_0001", "start": 66.06, "end": 118.68, "token_count": 187, "text": "å gjennomføre eksamener når du har alle hjelpemidler og mulighet til å diskutere med andre, f.eks. Eller til og med få hjelp på eksamen. Det er noen problemstillinger rundt det, men der er det ikke... Som sagt, der er det ikke helt bestemt hva årets løsning blir. En mengde løsningsforslag. Vår 2020 er den forrige fra i vår. Så det kan være ganske fornuftig å ta en titt på vår 20, høst 2019, og spesielt de siste eksamensoppgavene for å se hvordan de ser ut. Så da får man også et veldig godt inntrykk av hva det egentlig er vi ønsker at dere skal lære i dette kurset.", "source": "lecture"}
{"lecture_id": "linux4del4", "chunk_id": "linux4del4_0000", "start": 0.0, "end": 97.68, "token_count": 289, "text": "Man må være pinlig nøyaktig med å få riktig syntaks, ellers får man en feilmelding fra bæsjellet. Som et eksempel så kan vi definere en variabel v. V-en er nå lik varr, så innholdet av den skal da være varr. Så kan jeg kjøre en if-test og så se... if... Dollar ved er lik... var det sånn? Denne skulle da slå til, så jeg kan si ekko... ja. Og fin. Og det ser vi. Den slår til. Men hvis jeg skrur litt feil, hvis jeg f.eks. ikke har mellomrom der, så ser vi... Da skjønner ikke skjellet noen ting. Man får en syntaksfeil som er ganske kryptisk. Man får også en feil hvis man... Ikke har mellomrom der. Så man må ha mellomrom over alt hvor det skal være. Hvis du ikke har en mellomrom foran if der, så får du syntaksfeil. Så du må være veldig presis når man setter opp mellomrom. Og til og med rundt er lik kan det være. Viktig. Hvis jeg nå tester denne her, så får jeg ikke ja, som er riktig.", "source": "lecture"}
{"lecture_id": "linux4del4", "chunk_id": "linux4del4_0001", "start": 76.56, "end": 125.24, "token_count": 174, "text": "Hvis du ikke har en mellomrom foran if der, så får du syntaksfeil. Så du må være veldig presis når man setter opp mellomrom. Og til og med rundt er lik kan det være. Viktig. Hvis jeg nå tester denne her, så får jeg ikke ja, som er riktig. Men hvis jeg gjør sånn, så får jeg en syntaksfeil. Og hvis jeg gjør sånn, enda verre, da får jeg faktisk ja. For da er dette syntaktisk riktig. Men da er testmannen på hele den strengen. Og den returnerer tru. Så man må være pinlig nøyaktig med å... Og med syntaksen. Og ha mellomrom på riktig sted.", "source": "lecture"}
{"lecture_id": "linux5del11", "chunk_id": "linux5del11_0000", "start": 0.0, "end": 101.24, "token_count": 292, "text": "Vi skal nå se på ri i schellscript og i kommandolinjen. Og ri har en litt spesiell syntaks, for det er også definert i ettertid, så det har kommet som et tillegg til bæsj. Og konstruksjonen for å lage... La oss si jeg ønsker å lage et ri som heter noe med tall. Da er det en sånn konstruksjon. Hvis jeg skal bruke en sånn konstruksjon hele tiden, så kan jeg... Et lite knep er å bruke taste kontroll K. Da sletter jeg det fra linjen, og så kontroll Y når jeg skal bruke det. Så da kan jeg enkelt definere RI-elementer. La oss si første element... Tall av null. Det kan være null. Element én, det kan være én. Så kan jeg nå bruke kontroll Y. Så si to er lik to. Kontroll Y igjen. Tre er lik tre. Ikke tre, men T er i. Da har jeg definert et ray med fire elementer. Så kunne jeg jo tro at når jeg nå skal skrive ut et element... Det skulle få det til på denne måten, tall av 1, f.eks. Men det skriver bare ut tall av 1 - null.", "source": "lecture"}
{"lecture_id": "linux5del11", "chunk_id": "linux5del11_0001", "start": 69.86, "end": 178.96, "token_count": 291, "text": "Kontroll Y igjen. Tre er lik tre. Ikke tre, men T er i. Da har jeg definert et ray med fire elementer. Så kunne jeg jo tro at når jeg nå skal skrive ut et element... Det skulle få det til på denne måten, tall av 1, f.eks. Men det skriver bare ut tall av 1 - null. Ja, det skriver ut null av én, faktisk. På samme måte som tall av to skriver ut null av to. For å skrive ut det riktige elementet, så må man legge på krøllparenteser rundt. Derav det blir litt spesiell syntaks. Men da fungerer det som det skal. Nå kan vi skrive ut de forskjellige elementene. Bare man husker på den syntaksen, så fungerer det. Mens denne syntaksen... Den fungerer ikke i det hele tatt. Den bruker den nullen fra første elementet. Så f.eks. så ønsker man noen ganger å løpe gjennom alle elementene i et rai, eller alle indeksene. Og da er det noen konstruksjoner som er nyttig å kunne. En kan jeg ta kontroll K på den, og kontroll Y....", "source": "lecture"}
{"lecture_id": "linux5del11", "chunk_id": "linux5del11_0002", "start": 154.16, "end": 273.64, "token_count": 298, "text": "Den bruker den nullen fra første elementet. Så f.eks. så ønsker man noen ganger å løpe gjennom alle elementene i et rai, eller alle indeksene. Og da er det noen konstruksjoner som er nyttig å kunne. En kan jeg ta kontroll K på den, og kontroll Y.... For å få ut alle elementene må man legge inn en alfakrøll inne i re i stedet for elementnummeret. Da skrives ut verdien av alle elementene. Så kunne man også ønske seg å skrive ut indeksen. Igjen blir det litt kryptiske konstruksjoner. Men dette gir da alle indeksene av elementet. Og på den måten så kan man f.eks. løpe gjennom alle elementer i en forløkke. For i inn, og så... Så må vi ha en alfakrøll, og vi må ha et utropstegn først. Det får i inn, og så løpe gjennom alle indeksene. For hver indeks så kan du f.eks. skrive ut ekkoelement dollar i er... Og så... Og så element av dollar i. Da har jeg den riktige konstruksjonen. Krøllparenktes før og etter.", "source": "lecture"}
{"lecture_id": "linux5del11", "chunk_id": "linux5del11_0003", "start": 240.0, "end": 363.68, "token_count": 294, "text": "Det får i inn, og så løpe gjennom alle indeksene. For hver indeks så kan du f.eks. skrive ut ekkoelement dollar i er... Og så... Og så element av dollar i. Da har jeg den riktige konstruksjonen. Krøllparenktes før og etter. Tall av dollar i... og don. Og på den måten så ser vi hvordan vi kan løpe gjennom et helt r. Det finnes en annen måte å definere r-e på. Og det er å kan definere et helt r-e på en gang. På denne måten. La oss si... A, B, C, D, E, F. Sånn som det. Her har jeg nå... ... definert et r-ei. Eller definert de første elementene av r-eiet arr. Sånn. Så da kan jeg skrive et f.eks. element nummer 1. Men som oftest inni løkker så definerer man RI direkte. Så derfor er det vanligste måten å starte å definere et RI på, er bare å skrive inn elementer, sånn som dette her. Dette vil da være det vanligste utgangspunktet for å definere et RI. Det er bare det første ri-elementet.", "source": "lecture"}
{"lecture_id": "linux5del11", "chunk_id": "linux5del11_0004", "start": 330.0, "end": 404.64, "token_count": 189, "text": "Men som oftest inni løkker så definerer man RI direkte. Så derfor er det vanligste måten å starte å definere et RI på, er bare å skrive inn elementer, sånn som dette her. Dette vil da være det vanligste utgangspunktet for å definere et RI. Det er bare det første ri-elementet. Og jeg skriver det ut som ri-a0. Helt til slutt. Antall elementer i et ri har også en spesiell konstruksjon. Da må man ha med alfakrøll, og så må man ha en hashtag. Da får man ut antall elementer. Her var det bare ett element. I r var det fire. Og det samme var det i tall-raj, som jeg definerte. Så det gir antall elementer i raj.", "source": "lecture"}
{"lecture_id": "linux3del5", "chunk_id": "linux3del5_0000", "start": 0.0, "end": 100.0, "token_count": 296, "text": "Apostrofer blir mye brukt i Linux-skjell og i Linux-skript. Så vi skal nå se på apostrofer gjennom et eksempel. Så hvis jeg starter med å definere en lokal variabel... Så kan vi se på hva får man hvis jeg bruker enkle apostrofer? De som bare står retta opp. Og tar Ekko LSD-er på den måten... Så ser vi at da får jeg nøyaktig det som jeg skriver. Den type enkle apostrofer gir rett og slett bare den tekststrengen. Da er det ingen tolkning av dollar-dir som en variabel. Derimot, hvis jeg bruker doble apostrofer... Så ser vi at da tolkes innholdet i dollar-dir. Og vi får ut LS-mappe. Verdien av dir byttes ut med mappe, og så skrives det ut. Så er det en tredje type apostrofer. Det er den som står litt sånn tilbakelent. Hvis jeg nå prøver å gjøre akkurat den samme kommandoen med denne... Så vil vi se, da... Det som skjer da, er at da utføres denne kommandoen. Så når vi har små apostrofer som heller litt bakover,", "source": "lecture"}
{"lecture_id": "linux3del5", "chunk_id": "linux3del5_0001", "start": 74.22, "end": 170.12, "token_count": 287, "text": "Det er den som står litt sånn tilbakelent. Hvis jeg nå prøver å gjøre akkurat den samme kommandoen med denne... Så vil vi se, da... Det som skjer da, er at da utføres denne kommandoen. Så når vi har små apostrofer som heller litt bakover, så utføres kommandoen. Og da får vi til innholdet, for det er det samme vi får hvis vi utfører LS-mappe. Det kan være litt vanskelig å se forskjell på spesielt de to typer... Spesielt i script så kan det være veldig vanskelig. Vi skal se på en annen måte som vi kan bruke dette på. En sånn liten huskeregel kan være... Den apostrofen som heller bakover, den minner litt om en backslash. Det er det man bruker i Windows, og da vet man som regel ikke hva man får. Det ligner litt mer på en slash, som man bruker i Linux. I Linux bruker man slash den veien. Når man snakker om mapper og patermappe. I Windows bruker man backslash. Så i hvert fall... Denne apostrofen gir nøyaktig det du får ut.", "source": "lecture"}
{"lecture_id": "linux3del5", "chunk_id": "linux3del5_0002", "start": 146.52, "end": 251.5, "token_count": 291, "text": "Det ligner litt mer på en slash, som man bruker i Linux. I Linux bruker man slash den veien. Når man snakker om mapper og patermappe. I Windows bruker man backslash. Så i hvert fall... Denne apostrofen gir nøyaktig det du får ut. Mens denne apostrofen... Der utfører man kommandoen inni apostrofer. Fordi det kan være litt kryptisk å se dette her, og også av litt andre grunner, så fins det én måte som er litt bedre til å gjøre akkurat det samme. Så i stedet for... I stedet for å utføre en kommando sånn som dette her... Så kan man sette hele kommandoen inn i karanteser. Også med en dollar foran. Akkurat som det er en variabel. Og dette er en litt mer stødig syntaks. Det er litt lettere å se hva man gjør. Og så vil det i noen tilfeller også gi forskjell. Og da vil denne metoden virke. Jeg kan vise et eksempel på det. Et eksempel er hvis man gjør noe sånt som dette her... La oss si jeg ønsker å... Inni en variable line...", "source": "lecture"}
{"lecture_id": "linux3del5", "chunk_id": "linux3del5_0003", "start": 220.68, "end": 338.6, "token_count": 284, "text": "Og så vil det i noen tilfeller også gi forskjell. Og da vil denne metoden virke. Jeg kan vise et eksempel på det. Et eksempel er hvis man gjør noe sånt som dette her... La oss si jeg ønsker å... Inni en variable line... Så ønsker jeg å utføre en kommando. Og den kommandoen jeg ønsker å utføre, det er grep. Så ønsker jeg inni her å utføre who am I. Who am I gir meg brukernavnet. Her får jeg en feilmelding. Permission denied - det fungerer ikke som det skal. Anbefalte metoden for å legge inn variabler, nemlig en dollar foran og så parentes, og så med sluttparentes her borte. Så går det fint. Da utføres grep Haugerud-etter-passord, og så legges den verdien inn i variabelen. Så den fungerer. Men du vil ofte kunne se i skript at du ser denne konstruksjonen. Det er greit å vite hvordan man gjør det, men generelt vil jeg anbefale å bruke denne metoden når du da enten skal legge en kommando inn i en streng,", "source": "lecture"}
{"lecture_id": "linux3del5", "chunk_id": "linux3del5_0004", "start": 316.1, "end": 427.0, "token_count": 291, "text": "og så legges den verdien inn i variabelen. Så den fungerer. Men du vil ofte kunne se i skript at du ser denne konstruksjonen. Det er greit å vite hvordan man gjør det, men generelt vil jeg anbefale å bruke denne metoden når du da enten skal legge en kommando inn i en streng, eller som her legge verdien av en kommando inn i en variabel. Så vi kan se litt mer på det siste. F.eks. hvis du ønsker å legge verdien av P... Lag en sånn kommando, og så kan du skrive hvilken som helst kommando inni der. Og da vil mappe etterpå inneholde resultatet av p-dobbelen til deg. Et annet eksempel er sånn som... Ja, vi kan bruke denne. Sekseku, det er en kommando som lager en sekvens av tall. Så hvis en tar sek1-5, sånn som det... Og så skriver du ut verdien. Så ser vi at de har fått en sekvens av tall fra 1 til 5. Det er å bruke sånne krøllparenteser... Fra én til fire... Dette funker ikke helt.", "source": "lecture"}
{"lecture_id": "linux3del5", "chunk_id": "linux3del5_0005", "start": 394.32, "end": 484.4, "token_count": 224, "text": "Så hvis en tar sek1-5, sånn som det... Og så skriver du ut verdien. Så ser vi at de har fått en sekvens av tall fra 1 til 5. Det er å bruke sånne krøllparenteser... Fra én til fire... Dette funker ikke helt. Men hvis man legger på en ekko foran her, så får man satt den sekvensen. Begge disse her kan da brukes i forløkker. Man kan lage en forløkker for i... Finn... 1-4. Du... Skal vi se om den virker... Skriv ut valeri nå, og da ser vi at den funker fint. Så det er én måte å lage en forløker på. En annen måte å gjøre det samme på, er å bruke den sekk-kommandoen. Strekk én, ti, fire. Det... Da skjer det samme.", "source": "lecture"}
{"lecture_id": "linux8del12", "chunk_id": "linux8del12_0000", "start": 0.0, "end": 204.76, "token_count": 291, "text": "Den første problemstillingen... Eller det er vel egentlig bare én problemstilling som står igjen. Og det er å kunne få en fil lokalt til å vise innholdet i dokkecontaineren. Vi kan prøve å få det til... Skal vi se. Dette her... Ville jo starte en container på 8084. Så kan vi prøve å legge til et volum. Og da kan jeg prøve å... Skal vi se. Jeg kan prøve å legge til ruteområde her. Og så kan jeg kopiere... Veldig kort. Som inneholder... Hei. Og så kan jeg prøve å kjøre... Den kommandoen her. Men jeg kan ta og legge på et volum. Jeg tror det er sånn det skal kjøres. Jeg gjør et forsøk. Her var det en port som allerede var i bruk. Vi tar 85. Sånn. Straks ferdig. Så bare gjøre ett forsøk på dette her. Hva henter vi nå fra...?  Ja, det så ikke så godt ut. Vi fikk det nok ikke helt til, men det var fordi... ja. Det jeg prøvde å få til, var at denne mappen her...", "source": "lecture"}
{"lecture_id": "linux8del12", "chunk_id": "linux8del12_0001", "start": 154.74, "end": 244.76, "token_count": 198, "text": "Her var det en port som allerede var i bruk. Vi tar 85. Sånn. Straks ferdig. Så bare gjøre ett forsøk på dette her. Hva henter vi nå fra...?  Ja, det så ikke så godt ut. Vi fikk det nok ikke helt til, men det var fordi... ja. Det jeg prøvde å få til, var at denne mappen her... Men jeg kan... Vi har holdt på lenge nå, så jeg kan ta en liten pause. Så kan jeg komme tilbake om et kvarter, og så kan jeg pose her hvordan... Den riktige kommandoen for å få til dette på. Problemstillingen er å mappe en mappe eller en fil fra filteret. Sånn at når vi etterpå laster inn webfilen, så skal den gi den som ligger på åsen.", "source": "lecture"}
{"lecture_id": "os13del3", "chunk_id": "os13del3_0000", "start": 0.0, "end": 94.0, "token_count": 300, "text": "Tidligere så har vi sett på synkronisering. Vi har hele tiden... Det vil si, aller først så så vi på det å multitasking og parallellisere. Få ting til å gå fort i parallell. Og stort sett så går det veldig fint. Så bare å kjøre på i parallell, så sant det er mulig å parallellisere koden. Så kom jeg til noen tilfeller hvor man må serialisere koden. Hvor det er rett og slett ødeleggende at kode kjører i parallell. Og det er da typisk hvis man har en felles ressurs som to eller flere tråder jobber opp mot. Da kan de ødelegge for hverandre. Så et system må være tread safe. Det betyr at man ikke må ha tråder som ødelegger for hverandre. Og da må man serialisere og synkle. Og vi så foregang på forskjellige typer serialisering. Forskjellige metoder for å gjøre det. Bl.a. Mutex og semaforer, monitorer... Dette er teknologier og egentlig tilbud fra operativsystemet til programmereren for å hjelpe til å serialisere. I prinsippet så er det samme ting de oppnår.", "source": "lecture"}
{"lecture_id": "os13del3", "chunk_id": "os13del3_0001", "start": 60.0, "end": 162.28, "token_count": 286, "text": "Og vi så foregang på forskjellige typer serialisering. Forskjellige metoder for å gjøre det. Bl.a. Mutex og semaforer, monitorer... Dette er teknologier og egentlig tilbud fra operativsystemet til programmereren for å hjelpe til å serialisere. I prinsippet så er det samme ting de oppnår. Men f.eks. monitorer sånn som vi så på i Java, de er enklere å forholde seg til. Det var én enkel metode som man kunne legge rundt en hel blokk, som den synkroniserte metoden. Så den ville da synkronisere hele systemet på en veldig enkel måte. Å bruke mutexer direkte, og også semaforer, er litt mer komplisert. Så dette er på en måte forskjellige tilbud fra operativstemme til programmerere for å kunne serialisere. Men når man serialiserer på denne måten med mutexer, og tvinger prosesser til å vente på hverandre, så får man et problem med at deadlock kan skje. Og det er tre klare kriterier som må være tilfredsstilt for at deadlock skal oppstå.", "source": "lecture"}
{"lecture_id": "os13del3", "chunk_id": "os13del3_0002", "start": 130.64, "end": 231.8, "token_count": 286, "text": "for å kunne serialisere. Men når man serialiserer på denne måten med mutexer, og tvinger prosesser til å vente på hverandre, så får man et problem med at deadlock kan skje. Og det er tre klare kriterier som må være tilfredsstilt for at deadlock skal oppstå. Så hvis man klarer å unngå alle disse tre kriteriene, så kan man si at ok, da unngår jeg deadlock. Men samtidig så er dette gjerne noe man ønsker å få til i et program. Og da må man kode. Sånn at deadlock ikke oppstår. Men det første kriteriet er at man må ha en eller annen form for mutex. Altså man må ha ressurser som ikke kan deles. Hvis alle ressurser kan deles hele tiden, uten noe problem, så vil ikke deadlock oppstå. Så må man også ha et kriterium at en prosess kan beholde sin ressurs mens den venter på andre. Også at en prosess ikke kan tvinges til å gi opp sin ressurs. Hvis disse kriteriene er oppfylt, så kan deadlock oppstå. Og vi kan få deadlock ved sirkulær venting. Vi skal se hva det betyr.", "source": "lecture"}
{"lecture_id": "os13del3", "chunk_id": "os13del3_0003", "start": 206.08, "end": 319.24, "token_count": 299, "text": "mens den venter på andre. Også at en prosess ikke kan tvinges til å gi opp sin ressurs. Hvis disse kriteriene er oppfylt, så kan deadlock oppstå. Og vi kan få deadlock ved sirkulær venting. Vi skal se hva det betyr. Ja... Her er et enkelt eksempel på deadlock. Hvor... Generelt så kan man få deadlock hvis to eller flere prosesser venter på hverandre. Og i det eksempelet her så ser vi at vi kjører prosess A og prosess B. Og de gjør sånn de skal vente S1 for å vente på en ressurs, og signal S1 her nede for å avgi den ressursen. Hvis både Prosess A og Prosess B ønsker å få tak i ressurs S1 og S2... Og Prosess A sånn tilfeldigvis så gjør Prosess A først en wait på S1... Mens Prosess B gjør wait på S2. Og så, mens den venter på S1, så ønsker den også å vente på S2. Den vil også ha den ressursen. Og samtidig gjør... Og da vil vi få en låst situasjon. Da vil vi få en låst situasjon hvor prosess A venter på", "source": "lecture"}
{"lecture_id": "os13del3", "chunk_id": "os13del3_0004", "start": 285.0, "end": 378.2, "token_count": 296, "text": "Mens Prosess B gjør wait på S2. Og så, mens den venter på S1, så ønsker den også å vente på S2. Den vil også ha den ressursen. Og samtidig gjør... Og da vil vi få en låst situasjon. Da vil vi få en låst situasjon hvor prosess A venter på at prosess B skal release S2, for den har fått tak i SO. Den har nøkkelen her til SO. Og tilsvarende venter Prosess B på at Prosess A skal release essay. Kanskje de står her med en sånn... Med busy waiting. Står og spinner og venter og venter. Og dette kalte seg en deadlock. Den vil aldri løse seg opp. Eksempel én er jo kanskje enklere. Prosess 1 venter på P2. P2 venter på P3, og P3 venter på P1. De bare venter på hverandre. Det kan være en sånn semafor som dette her, men det kunne også være sånn som vi så på forrige gang, at prosess 2 skal være ferdig med noe i koden før prosess 3 går videre osv. Og dette er sånt som kan oppstå i den virkelige verden også.", "source": "lecture"}
{"lecture_id": "os13del3", "chunk_id": "os13del3_0005", "start": 360.0, "end": 435.6, "token_count": 300, "text": "Det kan være en sånn semafor som dette her, men det kunne også være sånn som vi så på forrige gang, at prosess 2 skal være ferdig med noe i koden før prosess 3 går videre osv. Og dette er sånt som kan oppstå i den virkelige verden også. Jeg husker veldig godt at jeg var ute og kjørte bil, og så kom jeg i et kryss hvor man har vikeplikt fra høyre. Og da hadde jeg tidligere snakket om dette på forelesning, at jo, hvis kommer det et kryss med fire biler som skal inn, og det var vanlig virkeplikt, så... Og da var det sånn at jeg ventet på den som sto ved siden av fra høyre. Den ventet på den som sto ved siden av fra høyre igjen, osv. Rundt hele krysset. Så alle sto og ventet på hverandre. Og jeg var den eneste, kanskje av bilistene, som jublet... Yes! Deadlock! De andre tenkte kanskje ikke så nøye over det, men akkurat denne situasjonen er det som skjer i programmer. Hvor de venter på hverandre, og så kan en deadlock-situasjon som det oppstå...", "source": "lecture"}
{"lecture_id": "os6del11", "chunk_id": "os6del11_0000", "start": 0.0, "end": 104.24, "token_count": 298, "text": "Ok. Det var en liten gjennomgang av Linux-historie. Nå skal vi gå inn på et helt nytt tema, nemlig multitasking. Aller først skal vi for tredje gang se på CPU-løkken. Det er dette vi må ha med videre. Og om og om igjen kjører instruksjoner. Det vi skal se litt nærmere på nå, er interrupt request. For en gang iblant så kan det komme et fysisk interrupt-orkest. F.eks. ved at jeg taster på tastaturet sånn. Maskinen må da reagere på den inntastingen veldig hurtig. Og det som da skjer, er at... Den avbrytes i sin evige løkke, og så håndterer den det signalet. Ofte brukes det pund noen mikrosekunder på å fullføre det den er i gang med. Og så hopper den til en interrupt rutine, som da sørger for at den piltasten som jeg trykket på, at den har en effekt. Den må avbrytes for å håndtere signalet. Da må man lagre adressen til neste institusjon, og så hoppe til en interrupt-rutine. Det blir litt som å gjøre et kall på en rutine,", "source": "lecture"}
{"lecture_id": "os6del11", "chunk_id": "os6del11_0001", "start": 80.2, "end": 190.2, "token_count": 298, "text": "at den piltasten som jeg trykket på, at den har en effekt. Den må avbrytes for å håndtere signalet. Da må man lagre adressen til neste institusjon, og så hoppe til en interrupt-rutine. Det blir litt som å gjøre et kall på en rutine, men her er det en fysisk interrupt som sendes inn, og så gjøres det kall på rutinen. Hvert interrupt eller IRQ har sin egen rutine som man da hopper til. Noe fra tastaturet, en annen hvis det kommer fra nettverket, en tredje hvis det kommer fra mikrofonen, osv. Vi skal se på multitasking. For å forstå multitasking er det viktig å vite hvordan minne eller ramm er koblet sammen med prosesser. Vi skal fokusere på ramm direkte, og da skal vi se mer på dette. Men det vi trenger å vite nå, er at det finnes flere deler i ramm som er tildelt en prosess. Dette som vi viser bildet her nå, det er én bit av ramm som er tilordnet én prosess. Operativsystemet er også en egen prosess. Den viktigste biten er kanskje koden eller teksten, som vi ser her nede.", "source": "lecture"}
{"lecture_id": "os6del11", "chunk_id": "os6del11_0002", "start": 156.68, "end": 253.36, "token_count": 280, "text": "Men det vi trenger å vite nå, er at det finnes flere deler i ramm som er tildelt en prosess. Dette som vi viser bildet her nå, det er én bit av ramm som er tilordnet én prosess. Operativsystemet er også en egen prosess. Den viktigste biten er kanskje koden eller teksten, som vi ser her nede. Unnskyld. Koden, det er da maskininstruksjonene som prosessen skal kjøre. Som ligger etter hverandre. Institusjon for institusjon. Det typiske som skjer når en prosess kjører, er at man starter på første institusjon til prosessen. Så er det gjerne en loop her, så den hopper opp og ned. Men så har vi sett at vi hele tiden har variabler i programmet, som brukes og skrives til ram. Og da i heapen, som går fra koden her og oppover, er det satt av masse plass til heapen, sånn at den kan utvide seg. For her kan man dynamisk legge inn nye variabler. De legges da på heapen. Stacken, det er et område hvor lokale variabler legges.", "source": "lecture"}
{"lecture_id": "os6del11", "chunk_id": "os6del11_0003", "start": 225.64, "end": 333.12, "token_count": 285, "text": "Og da i heapen, som går fra koden her og oppover, er det satt av masse plass til heapen, sånn at den kan utvide seg. For her kan man dynamisk legge inn nye variabler. De legges da på heapen. Stacken, det er et område hvor lokale variabler legges. F.eks. hvis du gjør et funksjonskall, så legger du på stacken returverdien fra det funksjonskallet, så man vet hvor man skal tilbake. Da er det enkelt å bare gå inn der. Så plukker du opp... I tillegg er det vanlig å ha en MM-mapp, som er en avbildning av filer og deviser inn i ramm. Men dette er igjen for at ting skal gå fortere. Så er det en kopi av noe av det som ligger på disk, sånn at man skal ha raskere aksess. Og Jeep, det er det vi snakker om. Her ligger alle variabler. Og her ligger instruksjonene. Tidligere så var det dette som var måten datamaskiner kjørte på. Man hadde bare... Man kjørte bare én oppgave av gangen.", "source": "lecture"}
{"lecture_id": "os6del11", "chunk_id": "os6del11_0004", "start": 300.0, "end": 415.16, "token_count": 294, "text": "Og Jeep, det er det vi snakker om. Her ligger alle variabler. Og her ligger instruksjonene. Tidligere så var det dette som var måten datamaskiner kjørte på. Man hadde bare... Man kjørte bare én oppgave av gangen. Så enten var det brukerprogram som kjørte, eller OS. Og da ser vi for... Selv om det var singeltasking, betyr det at det da er bare én prosess som kan kjøre av gangen. Det typiske som skjedde når man kjørte singeltasking OS, var at operativsystemet startet opp først. Og så hadde man da ett brukerprogram. Og når dette skulle kjøre, så satte OS i gang brukerprogrammet og kjøre. Og så hadde da Device-minne, Skjerm-minne osv. brukerdata eller Heap. Alle disse bitene hadde det. Men det var da bare én prosess som kunne kjøre av gangen. En sånn batch computing... Du hadde kanskje en rein operasjon som kunne ta en halvtime. Og da satte operativstemmet i gang denne operasjonen. Og så kjørte den til den var ferdig, og så kunne neste program starte.", "source": "lecture"}
{"lecture_id": "os6del11", "chunk_id": "os6del11_0005", "start": 397.88, "end": 507.96, "token_count": 295, "text": "En sånn batch computing... Du hadde kanskje en rein operasjon som kunne ta en halvtime. Og da satte operativstemmet i gang denne operasjonen. Og så kjørte den til den var ferdig, og så kunne neste program starte. Men alle moderne systemer har mulighet... Det er et system som kan få et antall programmer til å kjøre samtidig. Så her har vi et operativsystem som har to prosesser som kjører samtidig. Måten operativsystemet får til det på, det er at den deler opp tiden. Altså gir den litt tid til hver prosess, sånn at det ser ut som de kjører samtidig. Egentlig kjører de hand i gang, men for prosessene ser det ut som de kjører samtidig, og det er rett og slett multitasking. Men vi ser at hver prosess vil ha sitt eget område med heap og stack og program eller tekst eller kode, og også IO-områder. Altså for å snakke med disk, ta imot fra tastatur osv. Og multitasking, det er da det systemet som operativsystemet bruker for å kjøre prosesser samtidig. Hovedideen her er at CPU-tiden blir delt opp.", "source": "lecture"}
{"lecture_id": "os6del11", "chunk_id": "os6del11_0006", "start": 465.24, "end": 557.8, "token_count": 207, "text": "og program eller tekst eller kode, og også IO-områder. Altså for å snakke med disk, ta imot fra tastatur osv. Og multitasking, det er da det systemet som operativsystemet bruker for å kjøre prosesser samtidig. Hovedideen her er at CPU-tiden blir delt opp. Typisk størrelse på en liten bit av tiden man kan kjøre, er et hundredels sekund. Da har man en såkalt round robin-kø, og så har man en hardware-timer. Skal se på dette i detalj. Hvert hundredels sekund så sender et interrupt-signal til SIPPU. Så starter man opp den første... Den legges da i institusjonsregisteret. Og så lar OUS hver prosess etter tur brukes i PUN. Så CPU-en går da på rundgang mellom alle prosesser som ønsker å kjøpe.", "source": "lecture"}
{"lecture_id": "os9del10", "chunk_id": "os9del10_0000", "start": 0.0, "end": 102.04, "token_count": 293, "text": "Nå skal vi se litt på dette med å lage nye prosesser. Opplagt i alle OS må man ha en eller annen mekanisme for å lage prosesser. I Unix og nå i Linux så er det en litt spesiell måte å... Så er det en litt spesiell måte å starte opp prosesser på. Prosesser lages f.eks. ved systemoppstart. Da er det en første prosess innhent, den aller første prosessen, som starter opp. Man kan også lage prosesser... Hvis du har en kjørende prosess, så kan den utføre et systemcall, og så starte en ny prosess. Eller så kan du ha en bruker som ber om at en prosess startes, f.eks. hvis du er barsell. Og så vil du starte enda et vers. Skriver du vers, da initierer du at det starter opp en ny prosess. I Linux-verdenen, i Linux-kjernen, så er det alltid én prosess som lager en annen. Og dette skjer ved et såkalt folk-system-kall. Det som er spesielt med folk, er at det kloner seg selv. Når man gjør et forms system call, så får man en kloning av den eksisterende prosessen.", "source": "lecture"}
{"lecture_id": "os9del10", "chunk_id": "os9del10_0001", "start": 72.56, "end": 161.58, "token_count": 292, "text": "I Linux-verdenen, i Linux-kjernen, så er det alltid én prosess som lager en annen. Og dette skjer ved et såkalt folk-system-kall. Det som er spesielt med folk, er at det kloner seg selv. Når man gjør et forms system call, så får man en kloning av den eksisterende prosessen. Det høres litt rart ut, men det er ikke hver eneste at du får en kloning, og så setter du i gang og kjører et annet program i den kloningen. Dermed får du en helt ny prosess som kan være helt forskjellig fra foreldreprosessen. Det er alltid én prosess som starter en annen. Og den som starter, er naturlig nok foreldreprosessen. Og så får den et barn. En child-prosess. I prosessverdenen er det bare én forelder til hvert barn. Her ser vi et eksempel på det. Payday er prosess-id. Payday er parent-payday. Så har en parent med payday 17.12... Så gjør den en fock, så får man en child her nede. Med en ny payday. Typisk at det blir en høyere payday, for paydayene øker.", "source": "lecture"}
{"lecture_id": "os9del10", "chunk_id": "os9del10_0002", "start": 138.28, "end": 231.9, "token_count": 295, "text": "Her ser vi et eksempel på det. Payday er prosess-id. Payday er parent-payday. Så har en parent med payday 17.12... Så gjør den en fock, så får man en child her nede. Med en ny payday. Typisk at det blir en høyere payday, for paydayene øker. Også den vil ha en parent-payday på 1712. Så kan den her gi dem folk igjen og lage et barnebarn til den her oppe. Med payday 1734, og den har parent-ID 1730. Så får du den type hierarkier. Det fins eksempler på at man kan drepe en parentprosess med alle barn. Det hender også at det skjer noe galt der, og da kan man få såkalte zombieprosesser. Som er litt sånne halvdøde prosesser. De gjør ikke noe, men det er typisk hvis en parent har blitt drept uten at child har blitt drept. De kan være vanskelige å bli kvitt, men du kan se det i toppet noen ganger. Men stort sett så fungerer det ryddig, så det er bare med feil at det blir zombieprosesser. Linux Fork er et systemkall for å lage en shell-prosess.", "source": "lecture"}
{"lecture_id": "os9del10", "chunk_id": "os9del10_0003", "start": 206.44, "end": 311.34, "token_count": 298, "text": "uten at child har blitt drept. De kan være vanskelige å bli kvitt, men du kan se det i toppet noen ganger. Men stort sett så fungerer det ryddig, så det er bare med feil at det blir zombieprosesser. Linux Fork er et systemkall for å lage en shell-prosess. Som sagt så lager det en klone, en identisk prosess med kopi av alt. Data og så videre... Så her ser dere parent-dataene. Når man gir dem folk, så lages en kopi av alt dette her. Det høres jo veldig tungt ut, og det er... Det er ikke helt riktig, for... Det som egentlig skjer i Linux, det er at den clone... Den kopierer alt dette minnet. Det er mer en sånn copy on demand. Hvis en trenger noen av de dataene fra parent, så kopieres de over. Det er ikke sånn at en tar en absolutt kopi av alt. Det meste av strukturen kopieres. Men av effektivitetshensyn tar man ikke en fullstendig kopi i praksis. De delene av minnet som man trenger. Så kan man da starte opp en... Som vi skal se på etterpå, så kan det være en if-test.", "source": "lecture"}
{"lecture_id": "os9del10", "chunk_id": "os9del10_0004", "start": 290.1, "end": 315.98, "token_count": 90, "text": "Det meste av strukturen kopieres. Men av effektivitetshensyn tar man ikke en fullstendig kopi i praksis. De delene av minnet som man trenger. Så kan man da starte opp en... Som vi skal se på etterpå, så kan det være en if-test. If I'm a child, hvis jeg er barn, så start et a-program.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0000", "start": 0.0, "end": 113.08, "token_count": 287, "text": "Før pause så vi på et prioriteringseksempel med Java på Linux. Og så lovte jeg at jeg skulle prøve å kjøre på Windows. Og det er det jeg prøver å gjøre nå. Aller først var det et spørsmål om hvordan å kopiere filer fra... Fra Windows til Studie-SSO. Da fins et par måter å gjøre det på. Det beste som vi kommer tilbake til etter påske når vi skal se på Windows, er å installere Open SSO på Windows, for da kan man kopiere med SEP. Sånn som dette. Bare sp.prio.java. Eller tilsvarende over på Studiesocial. Og så skrive passord. Så kopierer man... Så blir filen kopiert over direkte. Det er mulig å sette opp passordnøkler også. Da kan man få enda mer direkte over. Et alternativ er å installere... VIN-SEP. Hvis man søker på VIN-SEP, så er det den første siten man kommer til. Så kan man installere derfra. Og det er... et guieprogram som ser ut noe sånt som dette her. Så man da kan... Hvor jeg da har logget meg inn på denne serveren.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0001", "start": 90.0, "end": 196.54, "token_count": 287, "text": "VIN-SEP. Hvis man søker på VIN-SEP, så er det den første siten man kommer til. Så kan man installere derfra. Og det er... et guieprogram som ser ut noe sånt som dette her. Så man da kan... Hvor jeg da har logget meg inn på denne serveren. Studio SSO i deres tilfelle. Og så kan man ta bare filer og kopiere. Frem og tilbake, sånn som dette er. Ved å peke og klikke. Men fra kommandolinja så kan man gjøre dem, som sagt, med SFP, hvis man installerer OpenSSO på Windows. Installere... Jeg tror man faktisk bare kan aktivere det, at det er en modul som kan aktiveres. Ok. Da skal vi se på Java-tråder på windows. Jeg har kopiert over den samme mappa. Det er prio.java. Så jeg kan kjøre den. Eneste forskjellen var at jeg... Ba den første tråden om å sove i 3000 millisekunder. Altså i tre sekunder. Men vi kan se av kjøringen hva slags prioriteter vi har. Tråd nummer to starter med prioritet 10, så den har høyest prioritet.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0002", "start": 165.96, "end": 257.16, "token_count": 283, "text": "Så jeg kan kjøre den. Eneste forskjellen var at jeg... Ba den første tråden om å sove i 3000 millisekunder. Altså i tre sekunder. Men vi kan se av kjøringen hva slags prioriteter vi har. Tråd nummer to starter med prioritet 10, så den har høyest prioritet. Etter tre sekunder starter tråd nummer én med prioritet 5. Windows tar virkelig hensyn til prioriteten. Den kjører bare tråd nummer to fordi den har høyest prioritet. Men så ser vi... Nå endrer vi prioritet for tråd nummer to. Og så endres den til fire. Og da er det tråd nummer én som har prioritet fem. Den kjører hele tiden. Så vi ser det er en enorm forskjell i prioriteter. Hvis en tråd har høyere prioritet enn en annen, så tar den omtrent alt som er av CPUT-tid. Så mens Linux default ikke bryr seg om Java-prioritet, så tar Windows ekstremt stor hensyn til det. Det er altså... Hvis man ser på prioritet i Windows,", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0003", "start": 227.24, "end": 320.32, "token_count": 274, "text": "Så vi ser det er en enorm forskjell i prioriteter. Hvis en tråd har høyere prioritet enn en annen, så tar den omtrent alt som er av CPUT-tid. Så mens Linux default ikke bryr seg om Java-prioritet, så tar Windows ekstremt stor hensyn til det. Det er altså... Hvis man ser på prioritet i Windows, så er den veldig sterk. Altså hvis man endrer prioritetsklasser, så får man en veldig stor effekt. Og det ser vi tydelig her. Hadde prioritet fire. Den var enerådende i praksis hele veien. Mens tråden som hadde prioritet nummer fem, den måtte i praksis vente til den andre var ferdig. Og så fullførte den sin jobb. Så vi kan konkludere at implementasjonen av prioritet på Java den er plattformavhengig. Men også, som sagt, så skredulerer operativstemme, altså både Windows og Linux, veldig bra med default prioritet. Sånn at dette her er ikke opplevd som noe veldig stort problem.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0004", "start": 294.68, "end": 425.34, "token_count": 289, "text": "den er plattformavhengig. Men også, som sagt, så skredulerer operativstemme, altså både Windows og Linux, veldig bra med default prioritet. Sånn at dette her er ikke opplevd som noe veldig stort problem. Man kan jo da også individuelt omprioritere med nice, f.eks. Eller på andre måter prioritere. Men stort sett så er operativsystemet... Moderne operativsystemer er så gode på å gi respons til de som trenger det interaktivt, og gi da en litt saktere respons til prosesser som bruker mye CPU. Og dette gjør da operativsystemene dynamisk på en så bra måte at det som regel ikke er noe stort behov for programmereren å gi Gi egne prioriteringer til prosesser. Ok, da skal vi gå videre med serialisering. Med mindre det er noen andre spørsmål? Skal vi se... Skal prøve å finne den sliden her. Der er vi. Ja, så... Problemstillingen er at... Hvis man jobber med fellesdata, så må man serialisere. Hvis ikke, så skal vi... Som vi skal se... Da kan man slåss om å bruke en felles variabel", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0005", "start": 402.56, "end": 504.2, "token_count": 292, "text": "Ja, så... Problemstillingen er at... Hvis man jobber med fellesdata, så må man serialisere. Hvis ikke, så skal vi... Som vi skal se... Da kan man slåss om å bruke en felles variabel og ødelegge hele datagrunnlaget. Resultatene kan bli helt feil. Et enkelt eksempel på dette er... Hvis vi tenker oss at vi har en webside som skriver ut billetter. En database som holder på antallet billetter. Så det ville jo kanskje gjøre dette enda mer komplisert, at du må koble deg opp mot databasen osv. Men da vil jeg alltid tenke på at vi må ha en trådsikker database. Det er da en database som er serialisert, hvor dette er tatt hensyn til. Men vi kan også tenke oss at vi bare har én webserver... Hvor det er to prosesser som står og kjører. Og begge må da ha tilgang til antall billetter. Ellers kan de ikke dele ut billetter i det hele tatt. Så i dette tilfellet tenker vi oss at vi har én variabel, ledige billetter, som sier hvor mange ledige billetter som finnes.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0006", "start": 488.72, "end": 576.82, "token_count": 295, "text": "Og begge må da ha tilgang til antall billetter. Ellers kan de ikke dele ut billetter i det hele tatt. Så i dette tilfellet tenker vi oss at vi har én variabel, ledige billetter, som sier hvor mange ledige billetter som finnes. Så kan vi tenke at koden for webserveren er noe sånt som dette her. Hvis ledige billetter er større enn null... Jo, da trekker vi fra lederbilletten med én, og så skriver vi ut en billett. Det ser jo enkelt og greit ut, men vi kan da få et mulig problem. Og det problemet er... Hva skjer hvis man er litt uheldig, og Prosess1 står og kjører og sjekker at det er lederbilletter? Men så vet vi at en sånn if-test utføres ikke i én instruksjon. Det er først en if. Først vil det være en compare av ledigbilletter med null, og se om den er større enn null. Og i dette tilfellet så vil dette slå til. Men før Prosess1 har rukket å minske ledigbilletter, Så skjer det en contact switch. Så hopper jeg over til prosess 2.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0007", "start": 556.2, "end": 649.36, "token_count": 295, "text": "og se om den er større enn null. Og i dette tilfellet så vil dette slå til. Men før Prosess1 har rukket å minske ledigbilletter, Så skjer det en contact switch. Så hopper jeg over til prosess 2. Og så utfører den den samme. Den sjekker at ledigbilletter er større enn null. Ja, ledigbilletter er større enn null. Og så trekker den fra. Og så skriver den ut en billett. Og så ser vi... Så gjør... Kommer vi etter den contact switchen, så kommer den tilbake. Ledigbillett til minus, minus. Den blir ned i minus én, og så skriver den ut. Enda en billett. Og det er klart det er to stykker som har fått billetter. Og her er det noe som går helt galt. Så på denne måten kan man ikke ha det. Så man må serialisere. Og man må sørge for at noe sånt som dette her ikke kan skje. Lett å forestille seg at dette kan skje, siden det er flere kodeoperasjoner involvert, at man først sjekker LED-billetter, og så trekke dem fram. Her er det en context match.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0008", "start": 616.14, "end": 709.76, "token_count": 283, "text": "Og man må sørge for at noe sånt som dette her ikke kan skje. Lett å forestille seg at dette kan skje, siden det er flere kodeoperasjoner involvert, at man først sjekker LED-billetter, og så trekke dem fram. Her er det en context match. Det tilfellet man også har, er at P1 og P2 kjører på hver sin CPU. Da vil det være enda mer problematisk, for da vil ikke de kunne... Sjekke seg imellom. Da vil de hente ned lederbilletter til sin CPU uten å sjekke om den andre da har gjort det. Så da er det enda vanskeligere å serialisere. Men vi skal også se at vi kan ha en race condition selv om det bare er én enkelt kodelinje.  Og en problemstilling for dette er at én linje høynivåkode... Selv om man bare ser koden, så ser man at dette er bare én linje. Så her kan det ikke skje noe galt med race condition. Men som vi har sett tidligere, så kan ofte én linje med høynivåkode oversettes til flere linjer med maskinkode.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0009", "start": 691.54, "end": 767.36, "token_count": 288, "text": "Og en problemstilling for dette er at én linje høynivåkode... Selv om man bare ser koden, så ser man at dette er bare én linje. Så her kan det ikke skje noe galt med race condition. Men som vi har sett tidligere, så kan ofte én linje med høynivåkode oversettes til flere linjer med maskinkode. Og i noen tilfeller så er det helt nødvendig, og det vil faktisk skje. Og en context switch kan oppstå når som helst mellom to maskininstitusjoner. For vi har sett mange ganger at operativsystemet aner ikke noe egentlig om hva de forskjellige... Om hva de forskjellige institusjonene betyr, og hva de gjør. Så operativsystemet bare sier ok, kjør. Institusjon, institusjon, institusjon. Sånn. Når som helst kan det komme en kontekstveksling. Og hvis prosessen opererer på to forskjellige CPU-er, har man operativstedet med enda mindre kontroll. Da skal vi se på et eksempel med to prosesser som oppdaterer én felles variabel.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0010", "start": 744.76, "end": 835.12, "token_count": 295, "text": "Når som helst kan det komme en kontekstveksling. Og hvis prosessen opererer på to forskjellige CPU-er, har man operativstedet med enda mindre kontroll. Da skal vi se på et eksempel med to prosesser som oppdaterer én felles variabel. Og da er det en saldo de oppdaterer. Og her ser vi koden for P1. Så gjør den et eller annet sted saldo alik saldo minus mill. Så den trekker fra en million kroner på saldo. Tilsvarende gjør P2. Gjør noen operasjoner, og så øker den saldo med én. Og da er det lett å tenke sånn at ja, dette her er bare én operasjon. Så om disse to kjører samtidig, så vil ikke det noe ha noe å si. For først trekker den fra 1 mill., og så ligger den til 1 mill. Man skulle tro at dette, spesielt hvis man kjører på samme CPU, burde gå fint. Men hva skjer egentlig hvis det på et uheldig sted kommer en Context Switch fra P1 til P2? Jo, da må vi tenke på maskinarkitektur. Og at det faktisk...", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0011", "start": 806.08, "end": 899.56, "token_count": 298, "text": "Man skulle tro at dette, spesielt hvis man kjører på samme CPU, burde gå fint. Men hva skjer egentlig hvis det på et uheldig sted kommer en Context Switch fra P1 til P2? Jo, da må vi tenke på maskinarkitektur. Og at det faktisk... ... prosesser gjør, er å utføre maskinkode. I dette tilfellet er det maskinkode for X86, altså rett på hardware. Men vi skal se senere at vi har det tilsvarende når vi kjører i Java. JVM utfører bite-kode. Så... Og da vil disse operasjonene, sånn som saldo..... Denne operasjonen kan ikke utføres av én enkelt maskininstitusjon. Det har vi sett tidligere. X86 tillater ikke to referanser til minnet samtidig. Så på en eller annen måte, uansett hvordan man kompilerer dette, eller om man skriver assembly-kode selv, så må man gjøre noe tilsvarende dette her. Man kunne gjort det kanskje et step videre, men noe tilsvarende som dette må skje. Og flytte saldo inn i et register. Og så har vi mill. Det ligger også ute i minnet.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0012", "start": 879.14, "end": 959.68, "token_count": 293, "text": "eller om man skriver assembly-kode selv, så må man gjøre noe tilsvarende dette her. Man kunne gjort det kanskje et step videre, men noe tilsvarende som dette må skje. Og flytte saldo inn i et register. Og så har vi mill. Det ligger også ute i minnet. Så vi flytter det inn i BX. Og så legger vi BX til AX. Da har vi lagt til saldo liks saldo pluss mill. Og så legger vi resultatet ut i saldo. Og så er det tilsvarende for subtraksjon. Og da får vi et problem. Da kan vi risikere at en million forsvinner. Og... da tenker vi oss at saldo er 5 først. Og så begynner vi med prosess 1, som trekker ifra. Den flytter saldo og mill inn i registrene sine. Og så skjer en context switch. Og da er det viktig å huske på at ved en context switch må alt lagres. Så alle registerverdier lagres da for den prosessen. Og så kommer prosess 2 inn. Det gjør det samme, men flytte saldo og mill inn i AXLX. Allerede her aner vi at her kan ting gå galt.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0013", "start": 939.2, "end": 1023.9, "token_count": 295, "text": "Og da er det viktig å huske på at ved en context switch må alt lagres. Så alle registerverdier lagres da for den prosessen. Og så kommer prosess 2 inn. Det gjør det samme, men flytte saldo og mill inn i AXLX. Allerede her aner vi at her kan ting gå galt. Denne P2 vil da ta og legge én mill til de fem eksisterende, sånn at den får AXLX. Så flytter den verdien ut, sånn at det blir seks millioner her ute. Så, før eller senere, skjer det en context switch tilbake til Prosess1. Prosess1sub Bx minus Ax. Men den bruker jo de gamle verdiene. Altså, den tar og trekker fra saldoen. Fem minus én, og da får den fire. Og så flytter den resultatet ut i saldo, og saldoen har blitt fire. Opplagt i dette tilfellet så burde jo saldoen ha blitt fem. Og én million er borte. Alltid kjedelig fra en saldo. Så konklusjonen her er at dette må opplagt serialiseres. Og det man må gjøre, er å serialisere aksess til felles data.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0014", "start": 996.76, "end": 1092.92, "token_count": 296, "text": "Og så flytter den resultatet ut i saldo, og saldoen har blitt fire. Opplagt i dette tilfellet så burde jo saldoen ha blitt fem. Og én million er borte. Alltid kjedelig fra en saldo. Så konklusjonen her er at dette må opplagt serialiseres. Og det man må gjøre, er å serialisere aksess til felles data. Å serialisere betyr at først gjør P1 seg ferdig med sine operasjoner med saldo, og så gjør P2 seg ferdig. Eller motsatt. Men de må ikke kunne gjøre det samtidig. Akkurat dette kalles et kritisk avsnitt. Når en prosess gjør en operasjon på en felles variabel, da er det et såkalt kritisk avsnitt. Og ideen med å serialisere er at kritisk avsnitt må fullføres i sin helhet før den andre prosessen slippes til. For å få til dette fins det en rekke forskjellige metoder. Men det skal vi se på neste gang, hva slags metoder man kan bruke for å fikse dette. Nå skal vi se på noen eksempler på hvordan dette ser ut i praksis", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0015", "start": 1059.68, "end": 1184.94, "token_count": 291, "text": "må fullføres i sin helhet før den andre prosessen slippes til. For å få til dette fins det en rekke forskjellige metoder. Men det skal vi se på neste gang, hva slags metoder man kan bruke for å fikse dette. Nå skal vi se på noen eksempler på hvordan dette ser ut i praksis med Java og med Petrads for tiden. Ja, da... Skal vi se. Da har vi... Et ja-program her som heter saldo. Og det skal vi studere nå. Det gjør litt av det samme som det saldoprogrammet. Vi så på jordet, men i vårt tilfelle så er det to saldotretts. Det er da to tråder, S1 og S2. Ja, saldo av 1000. Den bare sover 1000 millisekunder. Det spiller ingen rolle i dette tilfellet. Men det som er viktig, er at vi har en public static int-saldo. Det er en static in saldo, så det betyr at den er felles. Og så har vi to tråder som oppdaterer denne saldoen. Og det som vi ser, skjer, er hvis ID er lik 1, så økes saldoen med én maks antall ganger.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0016", "start": 1154.16, "end": 1260.36, "token_count": 299, "text": "Men det som er viktig, er at vi har en public static int-saldo. Det er en static in saldo, så det betyr at den er felles. Og så har vi to tråder som oppdaterer denne saldoen. Og det som vi ser, skjer, er hvis ID er lik 1, så økes saldoen med én maks antall ganger. Hvis ID er to, så minskes saldoen med én. Og da er det klart. Ja... Maks er et svært tall. Det er én million. Så det er klart, hvis du øker en saldo én million ganger med én, og så minsker den... Eller samtidig minsker den én million ganger med én, så burde det ende opp med null til slutt. Men... Da skal vi se hvordan det ser ut. Og vi kjører den. Den jobba. Ja. Da starter to tråder, begge med samme prioritet. Det spiller ikke så stor rolle. Men så ser vi et eller annet galt her... skjer. Den endelige, totale saldoen er 38 000. Og hvis vi prøver å kjøre på ny... Så ser vi at det ble 92 000. Og her... Det er 27 642.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0017", "start": 1234.76, "end": 1329.18, "token_count": 298, "text": "Det spiller ikke så stor rolle. Men så ser vi et eller annet galt her... skjer. Den endelige, totale saldoen er 38 000. Og hvis vi prøver å kjøre på ny... Så ser vi at det ble 92 000. Og her... Det er 27 642. Så vi ser at hver gang vi kjører, så får vi en helt annen verdi. Og her ble det minus 32 000. Og dette ser jo veldig merkelig ut. Men det er akkurat den effekten vi så i eksempelet. Med saldo og 1 mill. som blir borte. Det er ikke noen serialisering mellom trådene. Sånn at de vil hente inn den samme saldoverdien, og så vil de endre den. Og her ser vi at vi får en veldig stor effekt, fordi at... De vil gjøre mange operasjoner. Øke saldoen med 30 000, kanskje. Og så kommer den andre inn, og den har da allerede lest inn den samme verdien. Og så fortsetter de å jobbe med den. Så her blir... Forskjellene blir veldig store. Og det som kan være interessant da, er altså å se på...", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0018", "start": 1303.88, "end": 1412.16, "token_count": 295, "text": "De vil gjøre mange operasjoner. Øke saldoen med 30 000, kanskje. Og så kommer den andre inn, og den har da allerede lest inn den samme verdien. Og så fortsetter de å jobbe med den. Så her blir... Forskjellene blir veldig store. Og det som kan være interessant da, er altså å se på... Hvordan er det egentlig Javakoden som... Hvordan ser Javakoden som... Kjører dette her. Hvordan ser den ut? Og da er det en egen... Det er en egen applikasjon, JavaP, som kan vise Java Byte-kode. Men hvis vi tar på minus private, så får man se akkurat den koden som kjører saldotråden. Kjøre den kommandoen... Så det jeg gjorde, var Java Payments Private på saldotredd. Og det vi ser her, det er Java Byte-kode. Så jeg ser... Ja, det kan jo minne litt om Assembler-kode. Den eneste forskjellen er at Assembler-kode er for X86 fysiske maskiner. Javabyte-koden er for en Java-virtuell maskin. Og... da kan vi prøve oss å finne ut...", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0019", "start": 1387.56, "end": 1480.5, "token_count": 291, "text": "Så jeg ser... Ja, det kan jo minne litt om Assembler-kode. Den eneste forskjellen er at Assembler-kode er for X86 fysiske maskiner. Javabyte-koden er for en Java-virtuell maskin. Og... da kan vi prøve oss å finne ut... Jo, her er det en update-saldo. Det er den metoden som oppdaterer saldoen. Da kan vi se at det er to områder her. Her er det en e-ad, og her er det en e-sub. Og dette er de to områdene som saldoen blir oppdatert i. Og hvis vi konsentrerer oss om den delen som gjør... Dette er da tråd 1, som gjør saldo pluss, pluss. Og da skal jeg ikke gå så veldig inn på dette i detalj, men JVM er en såkalt stackmaskin. Det vil si at den legger variabler på stacken, og så opererer den på stacken. Det som faktisk foregår her, er... Her er det get static. Det betyr hent inn saldoen. Så hvis saldoen er 50, så legges tallet 50 på stacken. Og så icons 1. Den legger tallet 1 på stacken.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0020", "start": 1460.28, "end": 1542.66, "token_count": 282, "text": "Det som faktisk foregår her, er... Her er det get static. Det betyr hent inn saldoen. Så hvis saldoen er 50, så legges tallet 50 på stacken. Og så icons 1. Den legger tallet 1 på stacken. Og eAdd, den legger sammen de to tallene. Så da tar den 50 pluss 1 får 51. Puts Attic... og legger verdien ut. Og helt tilsvarende skjer med Sub her nede. Og da er det klart. Da ser vi med en gang at dette tar litt tid. Først så hentes verdien inn og legges på sacken. Og da... Dette implementeres jo da igjen av JVM, som så kjører maskinkode som gjør dette her. Så det som er tydelig, er at saldo blir... Og så legges det i registeret, som bare denne prosessen eier. Og den aner da ikke noe om hva som skjer her nede. Så når dette kjøres samtidig, så er det helt kaos. Saldo hentes inn, men det er ikke noe kontroll på hvor mange ganger det gjøres. Det er ingen kontroll på", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0021", "start": 1520.28, "end": 1598.64, "token_count": 300, "text": "Og så legges det i registeret, som bare denne prosessen eier. Og den aner da ikke noe om hva som skjer her nede. Så når dette kjøres samtidig, så er det helt kaos. Saldo hentes inn, men det er ikke noe kontroll på hvor mange ganger det gjøres. Det er ingen kontroll på at det ikke kan bli et avbrudd akkurat her. Og så overføres CPU-en til... Den andre tråden, og så trekker den fra. Og på en måte enda verre blir det når disse trådene opererer på hver sin CPU, for da jobber de helt uavhengig av hverandre. Og henter inn og ut saldo hele tiden. Uten å kontrollere hva den andre gjør i mellomtiden. Så det er helt klart at for at dette skal virke, så må man serialisere. Nøyaktig hvordan det gjøres, skal vi se på i... Vi ser på det neste gang, etter påske. Men det er en metode som heter'syncronized', som man kan bruke. Som da synkroniserer trådene i forhold til hverandre. Det som uansett er sikkert, er at hvis man ikke tar hensyn til dette her,", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0022", "start": 1580.28, "end": 1684.8, "token_count": 291, "text": "Vi ser på det neste gang, etter påske. Men det er en metode som heter'syncronized', som man kan bruke. Som da synkroniserer trådene i forhold til hverandre. Det som uansett er sikkert, er at hvis man ikke tar hensyn til dette her, hvis man ikke gjør programmene trådsikre, ikke tenker på race conditions, så kan ting som dette her oppstå. At man kjører samme programmet to ganger. Så er det helt vilkårlig hva man får ut som resultat. Ok. Da skal vi se på... Da skal vi se på et annet eksempel. Som på en måte er ligner, men denne gangen så er det... Så skal vi se på maskinkode. Og da skal vi se på faktisk... Helt enkeltinstitusjoner som likevel kan ha problemer med synkronisering. Så utgangspunktet her er... Dette programmet, tredd.c, det er da... Dette er da en implementasjon av p-tredds i c. Det er et bibliotek som gjør det mulig å kjøre tråder i et C-program. Vi skal ikke se så veldig mye på implementasjonen av det.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0023", "start": 1656.04, "end": 1742.52, "token_count": 300, "text": "Dette programmet, tredd.c, det er da... Dette er da en implementasjon av p-tredds i c. Det er et bibliotek som gjør det mulig å kjøre tråder i et C-program. Vi skal ikke se så veldig mye på implementasjonen av det. Det er ikke kjempeviktig, men det er litt sånn som Yawa. Her skaper vi en tråd - tråd 1 og tråd 2. Og de skapes, og så sendes det med en metode - ink. Det er den metoden her oppe. Den sendes med, så det som skjer, er at trådene kjører den metoden. Så ser vi at de har en join her nede. Det betyr at de venter på hverandre, sånn at begge er ferdige før main avslutter og skriver ut svaret. Og det metoden gjør, det ligner jo litt på saldo, men det er at den veldig mange ganger, skal vi se... 100 millioner ganger så kaller den på programmet, eller på metoden, én linje. Kalte én linje den metoden for å eksplisitt se at dette er én linje. Også for å kunne implementere den metoden direkte i Assembly.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0024", "start": 1719.4, "end": 1810.3, "token_count": 293, "text": "men det er at den veldig mange ganger, skal vi se... 100 millioner ganger så kaller den på programmet, eller på metoden, én linje. Kalte én linje den metoden for å eksplisitt se at dette er én linje. Også for å kunne implementere den metoden direkte i Assembly. Og da må vi se hva én linje gjør. Og den... Én dot c, den er ganske enkel. Den bare... Den tar en eksternint svar. Og så øker den den med 1. Enkelt og greit, sånn som saldo. Så her så ser vi... Denne variabelen her er deklarert globalt. Så når vi kompilerer den, når vi kompilerer dette programmet sammen med 1.c, så vil dette være en global variabel som da denne én-linje får tak i. Så... Alt i alt... Det som da bør skje, er at... Nå er det ikke en som trekker fra en som legger til, men begge disse her legger til. Sånn at vi har 100 mill. ganger så kaller vi svart pluss-pluss for den ene tråden og 100 mill. for den andre.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0025", "start": 1790.28, "end": 1903.68, "token_count": 298, "text": "Alt i alt... Det som da bør skje, er at... Nå er det ikke en som trekker fra en som legger til, men begge disse her legger til. Sånn at vi har 100 mill. ganger så kaller vi svart pluss-pluss for den ene tråden og 100 mill. for den andre. Så resultatet til slutt bør bli 200 millioner. Så da kan vi prøve å kopilere TredoC. Kommer noen oppgaver også om dette etter påske, så da kan det være greit å se på en typisk feil. Hvis du bare kompilerer sånn, så ser du at den... Den gir en feilmelding om P3d. Og det er fordi man må ha på en opsjon minus P3d. Den linker inn et bibliotek. Så må jeg skrive det riktig. Sånn. Da er jeg klar til å kjøre. Oi, se. Nå kjører Adatat. Så kjører den. Men vi ser... Akkurat som med Javatrådene, så blir svaret forskjellig fra gang til gang. Her får jeg noe sånt som 114 millioner. Det jeg burde fått, var 200 millioner. Så igjen ser vi... ", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0026", "start": 1872.6, "end": 2000.32, "token_count": 298, "text": "Så kjører den. Men vi ser... Akkurat som med Javatrådene, så blir svaret forskjellig fra gang til gang. Her får jeg noe sånt som 114 millioner. Det jeg burde fått, var 200 millioner. Så igjen ser vi...  Her er det et eller annet som går galt. Så da kan vi... Ja, vi... Det vi ikke vet her, er... Kan dette være fordi at den institusjonen, altså én linje... Det kunne jo være... At når den kompileres, at kompilatoren lager da flere linjer. Når den kompileres. Og for å sjekke ut det, for å være sikker på at den ikke gjør det, så kan vi da lage... I stedet for én linje, så kan vi lage en liten minimal... Assemblyfile. Et lite assemblyprogram som implementerer én linje. Og den implementerer vi veldig eksplisitt med én enkel instruksjon. Så dette er nå bare... Her er det liksom svart på hvitt at dette er bare én enkel assemblyinstruksjon. Og jeg skal ikke gå inn på det... RIP er et spesielt... Register som brukes til å overføre variabler.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0027", "start": 1978.12, "end": 2072.2, "token_count": 292, "text": "Så dette er nå bare... Her er det liksom svart på hvitt at dette er bare én enkel assemblyinstruksjon. Og jeg skal ikke gå inn på det... RIP er et spesielt... Register som brukes til å overføre variabler. Så det som skjer når jeg kjører denne her, er at den felles variabelen øker med igjen. Så den gjør i praksis akkurat det som 1.c gjør. Men 1.c ble komplert, så da var jeg ikke sikker på om dette faktisk ga én enkeltinstitusjon. Men dette her gir én enkeltinstitusjon. Så jeg kan da prøve... Og komplere på nytt, men i stedet for 1.c, så tar jeg med minimal. Sånn som det. Og så prøver jeg igjen. Og vi ser at... Jo, fortsatt så... Får jeg altså forskjellige svar. Og det... Det virker jo veldig rart. Her er det jo bare én institusjon. Så det kan ikke være noen context switch... Eller kan det være det? En context switch som gjør at den ene... Ja... At de får den samme effekten?", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0028", "start": 2046.32, "end": 2143.66, "token_count": 292, "text": "Får jeg altså forskjellige svar. Og det... Det virker jo veldig rart. Her er det jo bare én institusjon. Så det kan ikke være noen context switch... Eller kan det være det? En context switch som gjør at den ene... Ja... At de får den samme effekten? At man henter inn variabelen og så endrer på context switchen? Og så kommer context switchen, og så lagres den? Det virker rart, fordi at... Det virker rart fordi... Her er det bare én institusjon. Så vi har ikke noe sånn mellomlagring, sånn som vi hadde i Java. Og da er det jo én ting som er nærliggende å tenke deg. Hva om vi prøver med Task-sett her? Fordi at disse to programmene... skeduleres på hver sin CPU. Og da har vi plutselig ikke noe kontroll på det som skjer. Så et naturlig forsøk å gjøre her er å se - hva skjer... Hvis vi tvinger disse til å kjøre på samme CPU, får vi da den samme effekten? Nei, det får vi ikke. Da ser vi. Hvis jeg tvinger de...", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0029", "start": 2117.28, "end": 2222.16, "token_count": 284, "text": "Og da har vi plutselig ikke noe kontroll på det som skjer. Så et naturlig forsøk å gjøre her er å se - hva skjer... Hvis vi tvinger disse til å kjøre på samme CPU, får vi da den samme effekten? Nei, det får vi ikke. Da ser vi. Hvis jeg tvinger de... Til å kjøre på samme CPU. Så... Takket være at dette bare er én institusjon, så... Dette er bare én institusjon, så da kan vi ikke få noen kontekst-switch som hopper fra prosess A til prosess B. For du har ikke den mellomlagringen. Så her klarer operativs- og CPU-en og den ene... Men det er klart... Vanligvis kjører man ikke med Tacet. Så med en gang man kjører det i to CPU-er, så får man problemer. Ja... Spørsmålet er hvorfor det har noe å si at de kjører på hver sin CPU? Ja, det er fordi at... Vi har sett at det som egentlig skjer når man utfører en kodelinje, selv om det bare er svar pluss, pluss...", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0030", "start": 2180.96, "end": 2279.72, "token_count": 290, "text": "Så med en gang man kjører det i to CPU-er, så får man problemer. Ja... Spørsmålet er hvorfor det har noe å si at de kjører på hver sin CPU? Ja, det er fordi at... Vi har sett at det som egentlig skjer når man utfører en kodelinje, selv om det bare er svar pluss, pluss... Som i praksis så må den verdien, den må hentes fra RAM og inn i et register. Og selv om det gjøres som én operasjon, så har vi også sett at... Den er delt opp i mange sånne små mini-operasjoner, så ting skjer ikke sånn atomisk. Det skjer ikke som én operasjon hvor ingen andre ting utenom skjer. Og da må vi huske på at dette er to forskjellige CPU-er, så hver av de CPU-ene henter da inn denne variabelen. Den svarvariabelen ligger i ett spesielt sted. Begge er koblet inn med databussen, og begge henter ut den verdien når de skal gjøre svar pluss, pluss. Men da er det klart... Da vil det avhenge av hvem som blir først ferdig", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0031", "start": 2261.28, "end": 2358.88, "token_count": 285, "text": "Den svarvariabelen ligger i ett spesielt sted. Begge er koblet inn med databussen, og begge henter ut den verdien når de skal gjøre svar pluss, pluss. Men da er det klart... Da vil det avhenge av hvem som blir først ferdig med svaret før den sender, og før den henter ut neste, og trafikken på databussen. Og når man gjør dette 200 millioner ganger, så ser vi at hele tiden så... Kan det gå galt? Men det man kan gjøre... Jeg har en lock-minimål her. Og der har jeg fortsatt den ene institusjonen. Men så har jeg en institusjon som heter lock. Det er den første metoden vi skal se på som kan løse dette problemet. Den må jo da videreformidle til alle de andre CPU-ene at nå må ingen bruke databussen. Nå må vi låse av databussen. Neste institusjon, fra og med lokk, som jeg sender, som jeg gjør nå... Den låser databussen, så ingen andre kan... Etter at jeg har satt lokk, så kan ingen bruke databussen. Og dermed, hvis jeg nå kompilerer den...", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0032", "start": 2330.56, "end": 2446.84, "token_count": 300, "text": "at nå må ingen bruke databussen. Nå må vi låse av databussen. Neste institusjon, fra og med lokk, som jeg sender, som jeg gjør nå... Den låser databussen, så ingen andre kan... Etter at jeg har satt lokk, så kan ingen bruke databussen. Og dermed, hvis jeg nå kompilerer den... Og ikke bruker minimal, men lokk minimal i stedet... Så skal vi se at selv om jeg nå kjører adopt-out... Så ser vi at svaret blir riktig hver gang. Men så så vi, la kanskje merke til også, at dette tar lengre tid. Og det er ikke så rart, for nå må databussen låses ut hele tiden, sånn at de to trådene som kjører på hver sin CPU, de nå må koordineres. De opererer samtidig, men de må vente på hverandre. Det tar noe sånn som 4,3 sekunder hvis jeg... Hvis jeg kjører med den opprinnelig, minimal... Old timer, så tar det... Det går nesten fire ganger så fort. Og dette er noe som generelt gjelder for koordinering. Det vil opplagt ta lengre tid, for da må... Da låses bussen med jevn og mellomrom.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0033", "start": 2422.56, "end": 2532.04, "token_count": 298, "text": "Hvis jeg kjører med den opprinnelig, minimal... Old timer, så tar det... Det går nesten fire ganger så fort. Og dette er noe som generelt gjelder for koordinering. Det vil opplagt ta lengre tid, for da må... Da låses bussen med jevn og mellomrom. Og dermed så tar det rett og slett lengre tid. Men opplagt ikke minsten er at da unngår man race condition. Man får serialisert de to trådene, og resultatene blir riktige. Ja... Vi skal avslutte det, men det er ett spørsmål til. Hva er forskjellen på dette med plassering i RAM når man kjører to tråder på samme CPU og hver sin CPU? Ja, det er ikke noen direkte forskjell. Altså, én CPU er koblet med databussen til RAM. Men når disse to institusjonene kjører på samme CPU... Når man utfører svar pluss-pluss, eller når man utfører... ... man utfører denne institusjonen her, så... Hvis vi tenker oss at vi har to tråder, og den ene tråden utfører denne her, så vil hele den institusjonen fullføre.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0034", "start": 2503.68, "end": 2601.36, "token_count": 278, "text": "Når man utfører svar pluss-pluss, eller når man utfører... ... man utfører denne institusjonen her, så... Hvis vi tenker oss at vi har to tråder, og den ene tråden utfører denne her, så vil hele den institusjonen fullføre. Denne institusjonen henter ut fra ram variabelen svar... La oss si den er 50. Så øker den med 1 til 51 og legger ut svar igjen. Og dette foregår på én atomisk operasjon. Det er bare én operasjon i CPU-en. Og CPU-en ble aldri avbrutt midt inni den operasjonen. Da kan det skje en kontekst-switch, og da kan den andre tråden komme inn. Men på den måten ser vi at når de jobber på samme CPU, så vil først tråd 1 gjøre ferdig den. Og så kommer tråd 2 inn, og så vil den gjøre sin addisjon. Og da går det helt fint. Men når de er på to forskjellige CPU-er... Hver CPU henter da ut med denne institusjonen...", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0035", "start": 2575.8, "end": 2652.44, "token_count": 290, "text": "så vil først tråd 1 gjøre ferdig den. Og så kommer tråd 2 inn, og så vil den gjøre sin addisjon. Og da går det helt fint. Men når de er på to forskjellige CPU-er... Hver CPU henter da ut med denne institusjonen... Så sender den en beskjed ut på databussen - \".Hent inn variabelens svar.\" Og de er ikke koordinerte i det hele tatt. Så den trafikken går frem og tilbake totalt uten koordinasjon. Og da kan man risikere at Prosess1, som er på CPU1, kan hente svar i et tilfelle. Så kommer prosess 2, som er på CPU2. Den henter ut den samme, og de kan sende meldingen helt likt. Og da får begge svaret tilbake samtidig. Og begge vil da øke med én og sende svaret tilbake. Og da får vi akkurat det samme problemet tidligere. Hvis den opprinnelig var 50, så sender begge to tilbake svaret 51. Og 51 lagres to ganger. Men ett tall har da blitt borte.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0036", "start": 2634.68, "end": 2709.68, "token_count": 225, "text": "Og begge vil da øke med én og sende svaret tilbake. Og da får vi akkurat det samme problemet tidligere. Hvis den opprinnelig var 50, så sender begge to tilbake svaret 51. Og 51 lagres to ganger. Men ett tall har da blitt borte. Og dermed så ser vi at det totale antallet ofte blir mindre enn det det skal. Ok. Men da... Da stopper vi der. Og så... ... tar jeg iallfall en liten pause, og så åpner jeg... ... noen... hva heter det... break-out-rooms. Og så kan dere... Få hjelp der til oppgaver og andre ting. Husk også å gjøre MC2 og få hjelp til den hvis dere står fast. Da stopper jeg rekordingen der. Husk også å gjøre MC2 og få hjelp til den hvis dere står fast. Da stopper jeg rekordingen der.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0000", "start": 0.0, "end": 154.66, "token_count": 277, "text": "Hva er det som er så spesielt med denne filmen? Det er vanskelig å forstå hva som skjer i løpet av en uke. Ja. God morgen, alle sammen. Og i dag må jeg huske på å si at det er veldig hyggelig at det er så mange som står opp tidlig om morgenen for å gå på forelesning. Veldig bra. Så god morgen til alle sammen. Jeg er ikke sikker på om vi har med Ine i dag. Er du her i dag, Ine? Du er her, ja. Flott. Jeg hører deg også. Kjempebra. Da... Under hele forelesningen, så... Der er hun i chatten også. Hun er tilgjengelig for å svare på spørsmål. Avbryt når som helst og spør. I chatten kan dere spørre hele tiden. Også Ine hvis det er noe veldig viktig, så avbryter du meg. Eller uansett, hvis det er et godt spørsmål, så ta... Bare stopp meg og si... Hør her. Eller hvis jeg sier noe veldig galt. Det pleier ikke å skje.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0001", "start": 134.56, "end": 215.32, "token_count": 268, "text": "Også Ine hvis det er noe veldig viktig, så avbryter du meg. Eller uansett, hvis det er et godt spørsmål, så ta... Bare stopp meg og si... Hør her. Eller hvis jeg sier noe veldig galt. Det pleier ikke å skje. Kjempebra. Ja, også Ine, det er fint at dere minner meg på om å ta opp. Men nå startet jeg med å ta opp før jeg begynte her. For jeg tar ikke opp direkte i Zoom, sånn at dere ikke vil høre den stemmen som sier jeg tar opp. Men det blir tatt opp. Men nå blir det tatt opp sånn at... Hvis vi ikke ser bildene fra Zoom, f.eks., hvis dere dukker opp der. Så det blir tatt opp, og så legger jeg ut... Jeg tror jeg kanskje rekker å legge ut i pausen allerede fra første time. Og så deler jeg det som vanlig opp i biter, sånn at det er enklere å se på senere.  Men da skal vi først se på hva vi skal holde på med i dag.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0002", "start": 186.9, "end": 294.32, "token_count": 298, "text": "Så det blir tatt opp, og så legger jeg ut... Jeg tror jeg kanskje rekker å legge ut i pausen allerede fra første time. Og så deler jeg det som vanlig opp i biter, sånn at det er enklere å se på senere.  Men da skal vi først se på hva vi skal holde på med i dag. Og her er oversikten. Det kanskje viktigste denne uken er at det er frist for Obligin-levering på fredag. Og Obligin består i alle de deloppgavene som har vært Men da ikke fra uke 5. Altså ikke oppgavene denne uken. Det er vel til og med denne uken. Uke 4. Når du er ferdig med obliger denne uken, kan obligen leveres inn. Så alle oppgavene fra uke 4 skal leveres inn her. Det jeg håper dere gjør, er at dere jobber jevnt hver uke. Da vet dere hva som er obligatorisk, så gjør dere de oppgavene. Ja, altså Ine? Du hører meg? Ja, vi har snakket litt med... Litt om de som av forskjellige grunner er alene på en gruppe.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0003", "start": 264.36, "end": 358.74, "token_count": 294, "text": "Det jeg håper dere gjør, er at dere jobber jevnt hver uke. Da vet dere hva som er obligatorisk, så gjør dere de oppgavene. Ja, altså Ine? Du hører meg? Ja, vi har snakket litt med... Litt om de som av forskjellige grunner er alene på en gruppe. Spesielt nå er det ikke alltid så lett å få til samarbeid. Men uansett så tenker jeg det er fornuftig å så på en måte lempe litt på kravet til godkjent for de som er alene på en gruppe. Jeg tenker det er rimelig sånn at man... For det kan være litt ekstra utfordrende. Det er ganske mye oppgaver, men det aller viktigste å gjøre etter kurset er Det er å jobbe dere gjennom oppgavene. Jeg var jo alene selv da jeg leverte. Jeg husker jo det var ganske mye mer ekstra jobb. Ja, så vi tar det litt med i beregningen. Ja. Når vi vurderer godkjent, ikke godkjent. Ja, men det høres veldig rimelig ut. Så har jeg lagt ut digitale videoer om skjellscript.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0004", "start": 327.54, "end": 413.14, "token_count": 287, "text": "Jeg var jo alene selv da jeg leverte. Jeg husker jo det var ganske mye mer ekstra jobb. Ja, så vi tar det litt med i beregningen. Ja. Når vi vurderer godkjent, ikke godkjent. Ja, men det høres veldig rimelig ut. Så har jeg lagt ut digitale videoer om skjellscript. Jeg ligger litt etter der, så jeg har ikke fått ferdig de helt siste videoene. Jeg får det i løpet av dagen eller i morgendagen. Og så skal jeg også legge ut flere videoer om bæsj-scripting. Så det er liksom skjellscripting som er fokus nå. Og da blir det litt mer avanserte skjellscript. Og så fra neste uke... Prøver dere å få til det i løpet av uken, så skal jeg dele ut virtuelle maskiner til alle, sånn at alle får en virtuell maskin som dere kan logge inn på med en public ip-adresse hvor dere kan styre alt selv. Lage webservere osv. Egentlig er det ikke virtuelle maskiner. Vi kommer tilbake til det. Det er dokkerinstanser som ser ut som virtuelle maskiner.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0005", "start": 391.34, "end": 486.22, "token_count": 292, "text": "til alle, sånn at alle får en virtuell maskin som dere kan logge inn på med en public ip-adresse hvor dere kan styre alt selv. Lage webservere osv. Egentlig er det ikke virtuelle maskiner. Vi kommer tilbake til det. Det er dokkerinstanser som ser ut som virtuelle maskiner. Så skal vi bruke de fra neste uke, og så uken etter der igjen, så skal vi begynne å kjøre dokker-condeinere på disse VM-ene. Egentlig er det dokker i dokker, men det kommer vi tilbake til. I dag så er temaet C og maskinkode. Det er tema første time, og så skal vi se på pipelining og... Superskalære prosessorer i andre time. Og da skal vi gå hakket videre fra den skalære prosessoren som vi hadde i simuleringen. En skalær er altså en prosessor som gjør én ting av gangen. Så skal vi se på moderne CPU-er som faktisk selv innen den samme enkle CPU-en, Men det kommer vi til å stukke ut i andre time. Først kan vi fortsette å se på sammenhengen mellom høynivåkode og maskinkode.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0006", "start": 458.8, "end": 582.46, "token_count": 299, "text": "En skalær er altså en prosessor som gjør én ting av gangen. Så skal vi se på moderne CPU-er som faktisk selv innen den samme enkle CPU-en, Men det kommer vi til å stukke ut i andre time. Først kan vi fortsette å se på sammenhengen mellom høynivåkode og maskinkode. Og dette er det viktig å ha med seg senere i kurset, for da skal vi se hvordan operativsystemer styrer prosesser. Og i mange tilfeller så er det helt avgjørende hvordan hardwaren under virker. Hvor mange CPU-er man har, hyperthreading og til en viss grad også det med pipelining, er viktig for operativshemmede. Det vi først og fremst skal se på i dag, det er... maskinkode. Og det aller første jeg tenkte å se på, var optimalisering av maskinkode. Og da skal jeg gå til et eksempel på det. Skal vi se... Her har jeg laget en liten rutine. Som... Ja, det er ikke så viktig hva eksempelet er, men dette er da eksempel på kode som... Som går i en loop og som logisk bygger på hverandre. Så den...", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0007", "start": 543.82, "end": 645.66, "token_count": 288, "text": "Og da skal jeg gå til et eksempel på det. Skal vi se... Her har jeg laget en liten rutine. Som... Ja, det er ikke så viktig hva eksempelet er, men dette er da eksempel på kode som... Som går i en loop og som logisk bygger på hverandre. Så den... Den... Vi skal se senere. Denne koden kan ikke utføres i parallell. Men det viktigste nå er å se på hvordan utføres kode effektivt i en CPU. Det vi skal ha fokus på, er at vi har sett... I simuleringen forrige gang så vi at noen instruksjoner utføres bare på registrene. Og da står man inne i CPU-en, hvor man har registeret tilgjengelig. Og så tar man f.eks. R0 lik R0 pluss R1, som vi gjorde i simuleringen. Det er en operasjon som utføres kun på registeret. Men så så vi at vi også kan legge verdier ut i ramm. Det er det man typisk gjør når man har en variabel, sånn som den int a1 her. Når vi kjører et program som dette, så er det typiske som skjer da,", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0008", "start": 620.74, "end": 716.4, "token_count": 298, "text": "Det er en operasjon som utføres kun på registeret. Men så så vi at vi også kan legge verdier ut i ramm. Det er det man typisk gjør når man har en variabel, sånn som den int a1 her. Når vi kjører et program som dette, så er det typiske som skjer da, når vi skal lagre den variabelen, er at den lagres i ramm. En egenplass i ram. En integer er på 4 bite, så da settes det av 4 bite i ram til den integeren. Eller 4 bite er 32 bit, så det settes av i ram. En som vi så sist, ram deler seg inn i bites. Åtte bit av gangen, så det er den minste enheten i ram. Det tar mye lengre tid å lagre ting i ramm. Så ca. ti ganger så lang tid tar det å lagre et tall i ramm enn å lagre det i registeret. Så derfor lønner det seg stort sett å gjøre så mye som mulig med registeret, og så laste ut resultatene etterpå til ramm. Så det vi skal se på nå, er hvordan en kompilator lager maskinkode av denne koden her. Aller først kan vi se på", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0009", "start": 690.14, "end": 796.18, "token_count": 286, "text": "enn å lagre det i registeret. Så derfor lønner det seg stort sett å gjøre så mye som mulig med registeret, og så laste ut resultatene etterpå til ramm. Så det vi skal se på nå, er hvordan en kompilator lager maskinkode av denne koden her. Aller først kan vi se på hvordan denne koden kjøres. Så... Da har jeg en kode som heter maine sånn, som jeg skal kompilere og linke sammen med den fiberkoden. Her ser vi at vi definerer en ekstern int-fibo. Det er den assembly-metoden som jeg skal bruke. Eller nei, ikke assembly-metode. Dette er den C-metoden som jeg skal bruke. C-funksjonen som vi så på, nemlig fibo.c. Vi ser den må hete det samme. Og det som er litt forskjellig fra forrige gang, er at nå sender vi med... Vi kaller den Fibo med Last. Så ser vi i Main her, så setter jeg en Last Alec 10. Og så kjører jeg metoden Fibo på Last. Så Fibo er 10. Den skal gi Fibonacci-tall nummer 10 i rekken.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0010", "start": 770.74, "end": 887.94, "token_count": 289, "text": "Vi kaller den Fibo med Last. Så ser vi i Main her, så setter jeg en Last Alec 10. Og så kjører jeg metoden Fibo på Last. Så Fibo er 10. Den skal gi Fibonacci-tall nummer 10 i rekken. Så vi kan først se hvordan det ser ut i komposisjon. De kan jeg kompilere rett sammen på samme linje. Sånn. Da får jeg ett program adatat. En kjørbar fil. Og så ser vi... Her kommer resultatet 55 ut. Så den funker som den skal. Men det vi skal se på nå, er... Den maskinkoden ut som det kompileres til når man kompilerer den høynivåkoden Fibo. Og da kan vi som sist spørre... GCC, hvordan ser assembly-koden du lager, ut? Og det gjør man med minus S. Men når jeg kjører den, så... Er det stor S, kanskje? Ja. Man gjør det ikke med minst liten S, men med stor S. Med stor S ber jeg GCC om å lage asemblerkode. Og da ser vi, da har jeg fått en fil her som heter fibo.s. Det er den vi skal se på nå.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0011", "start": 860.74, "end": 969.34, "token_count": 287, "text": "Er det stor S, kanskje? Ja. Man gjør det ikke med minst liten S, men med stor S. Med stor S ber jeg GCC om å lage asemblerkode. Og da ser vi, da har jeg fått en fil her som heter fibo.s. Det er den vi skal se på nå. Det ser jo litt gresk ut, det som skjer her. Jeg skal ikke gå inn på dette i detalj, men vi ser... Den linja her oppe er viktig. Den definerer den rutinen Fibo. Men det eneste vi skal se på, som vi må få med oss her, det er at her brukes hele tiden... For det vi har sett tidligere, det er at... En sånn konstruksjon som dette er, det er en peker til en integr i ram. Det som er inne i parentesen, det er et register. Så adressen i ram ligger i dette registeret. Og minus 12, det er en sånn relativ adresse. Som sier at akkurat den integraen som vi skal hente ut, ligger minus 12 bite unna starten på det området. Så det eneste vi trenger å huske, er at dette er en variabel. Og dette er en variabel.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0012", "start": 946.26, "end": 1039.74, "token_count": 299, "text": "Og minus 12, det er en sånn relativ adresse. Som sier at akkurat den integraen som vi skal hente ut, ligger minus 12 bite unna starten på det området. Så det eneste vi trenger å huske, er at dette er en variabel. Og dette er en variabel. Så det vi kan konkludere med, er at alle de operasjonene som utføres her, sånn som den her, for eksempel... Den utføres på integer som ligger i ram. Så hvis jeg tar adel, denne her, den sier legg tallet 1 til denne variabelen som ligger i ram. Og denne variabelen her er typisk den tellevariabelen i løkken. For den ser vi øker med 1 hver gang i runden. Så det vi kan konkludere med her, er at... At når GCC lager kode her, så skriver den inn og ut av RAM hele tiden. Vi kan også lenge merke til at alle ad-operasjoner, så er det ett register og ett element fra RAM. Så den tar EAX og legger til den verdien som ligger der ute i RAM. Og i prinsippet så kunne man tenke seg at man... Hvis vi går ut til...", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0013", "start": 1017.54, "end": 1128.62, "token_count": 294, "text": "Vi kan også lenge merke til at alle ad-operasjoner, så er det ett register og ett element fra RAM. Så den tar EAX og legger til den verdien som ligger der ute i RAM. Og i prinsippet så kunne man tenke seg at man... Hvis vi går ut til... I prinsippet kunne det tenke seg at man utførte en operasjon som dette her direkte i RAM. Altså - man tok en referanse fra RAM og la den der. Spørsmål - hva betyr prosent-eax? Prosent-eax, det er et register. Det er et extended AX-register. Det er et 32-bits-register. Det vi brukte forrige gang, var 64-bits-registeret da vi skrev kode. Da heter de... Registrene starter opp på R. RAX, RBX osv. Når vi kompilerer her, så lager den 32-bitskode. Det kan man endre ved kompileringen. Og man kan forlange å få 64-bitskoden. Men det viktige er at %dax, det er et register. Kjempebra dere spør. Bare stopp og spør mer. Så... Det vi så nå, var at når vi kompilerer denne koden her, så...", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0014", "start": 1107.78, "end": 1198.38, "token_count": 294, "text": "Og man kan forlange å få 64-bitskoden. Men det viktige er at %dax, det er et register. Kjempebra dere spør. Bare stopp og spør mer. Så... Det vi så nå, var at når vi kompilerer denne koden her, så... Lage komplimenter om kode som går ut i minnet... Og lagrer hele ting i minnet. Og det er litt merkelig. Det jeg begynte å si, var at man kunne tenke seg at man gjorde en sånn operasjon med minnet også. At man tok det som ligger i A, legger til B... På en eller annen måte må det hentes inn i registrene før man legger sammen. Men det er det Hardware-en som gjør. Men i Exot 6 Hardware er det ikke definert operasjoner som bruker to minneadresser samtidig. Så i Exot 6 kan du f.eks. legge til et tall til en variabel direkte med en institusjon. Du kan ta et register og legge til i en variabel direkte i ramm. Men det er ikke lagde instruksjoner som gjør dette her. Det skal vi se på etterpå. Det vil bety at en sånn linje som dette her", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0015", "start": 1178.7, "end": 1269.98, "token_count": 296, "text": "til en variabel direkte med en institusjon. Du kan ta et register og legge til i en variabel direkte i ramm. Men det er ikke lagde instruksjoner som gjør dette her. Det skal vi se på etterpå. Det vil bety at en sånn linje som dette her kan aldri oversettes av én linje maskinkode. Ok. Men det er jo litt merkelig at GCC lager kode som ikke bruker registeret. For det er jo det mest effektive. Og da er det viktig å vite at GCC default, som det er raskest mulig å kompilere. Så hvis du har et stort program og driver og utvikler, så ønsker du at den skal kopiere så fort som mulig. Og det er det som er default i GCC. Men hvis du ønsker at GCC skal lage et mest mulig effektivt program, et som kjører fortest mulig, så må du si ifra om det, og da kan det ta lengre tid å kompilere, men da optimaliserer GCC for å kjøre fort. Da kan jeg prøve å gjøre det med... Hvis vi gjør det med main, så merker vi ikke så veldig forskjell, for det går ekstremt fort å gjøre dette her.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0016", "start": 1242.72, "end": 1346.74, "token_count": 290, "text": "så må du si ifra om det, og da kan det ta lengre tid å kompilere, men da optimaliserer GCC for å kjøre fort. Da kan jeg prøve å gjøre det med... Hvis vi gjør det med main, så merker vi ikke så veldig forskjell, for det går ekstremt fort å gjøre dette her. Det går kanskje enda fortere også akkurat de operasjonene inni CPU-en. Det går veldig fort, men hovedpoenget her er... Kan vi se på koden, hvordan den endrer seg? Hvordan GCC endrer på koden for å få den til å være raskere. Da kan vi gjøre det samme. Da kan vi be om... Stor minus S, da ber vi om GCC om å lage maskinkode. Eller da assemble kode, som ser ut... Som den maskinkoden den virkelig lager. Og så kan vi se på hvordan den ser ut nå. Og da ser vi at jo, her er det plutselig annerledes. Og det er ett sted så er det en referanse til Teram. Men stort sett så foregår alle operasjonene da inne i CPU-en med registeret. Det er det tallet som man sammenligner med.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0017", "start": 1314.18, "end": 1440.54, "token_count": 300, "text": "Og så kan vi se på hvordan den ser ut nå. Og da ser vi at jo, her er det plutselig annerledes. Og det er ett sted så er det en referanse til Teram. Men stort sett så foregår alle operasjonene da inne i CPU-en med registeret. Det er det tallet som man sammenligner med. Det er den som får løkka til å gå. Men hovedpoenget er at alt man... Alt som gjøres, det gjøres inni CPU uten at man refererer til ram. Så kan man heller ute i Main, så kan man lagre resultat i ram. Eller hvis resultatet bare skal skrives ut, så... Så trenger det ikke å lagres i ramme i det hele tatt. Det mest effektive er å kjøre det da inni CPUD. Men så er det begrenset lagreskapasitet i CPUD. Hvis du har et program som har en million... Et RA som har en million variabler, så kan du ikke ha alle de variablene i registeret. Da må tallene lastes i. Da skal vi se lite grann på dette, så skal vi gå tilbake og se på rutinen vi hadde. Vi har regnet ut en sum. Og den het noe sånt som... Skal vi se...", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0018", "start": 1390.7, "end": 1520.14, "token_count": 296, "text": "Et RA som har en million variabler, så kan du ikke ha alle de variablene i registeret. Da må tallene lastes i. Da skal vi se lite grann på dette, så skal vi gå tilbake og se på rutinen vi hadde. Vi har regnet ut en sum. Og den het noe sånt som... Skal vi se... Det var den funksjonen... Sumfunksjonen. Denne. Og... Det vi så på sist, var at vi ba GCC om å lage assemblykode for den. Hvordan den så ut. Vi kan repetere det. Jeg ba GCC om å lage assemblerkode. Og den skulle da bli sumfunksjon.des. Og den så ut som noe sånt som dette her. Så fant vi ut... Hvis jeg går inn og ser i detalj, så ligner den veldig på den. Maskinkoden vi hadde i simuleringen... Bortsett fra denne skriver nå ut til minnene. Vi ser det er hele tiden minnereferanser. Men i prinsippet så ligner koden veldig. Men det vi skulle se på nå, var hva skjer med denne funksjonen hvis jeg ber om å lage så effektiv kode som bare mulig. Jo, da kan vi prøve å se hva som skjer da.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0019", "start": 1502.46, "end": 1597.02, "token_count": 289, "text": "Men i prinsippet så ligner koden veldig. Men det vi skulle se på nå, var hva skjer med denne funksjonen hvis jeg ber om å lage så effektiv kode som bare mulig. Jo, da kan vi prøve å se hva som skjer da. Da får jeg en ny assembly-kode. Og denne er da lagd av GCC for å være mest mulig effektiv. Og da ser vi ganske overraskende at her var det ikke veldig mye kode. Noen som klarer å se hva denne koden her gjør? Den skal jo regne ut en hel sum. Det er veldig få instruksjoner her. Og det som da viser seg, er at kompilatoren er faktisk da så smart at den ser vel uansett hva som skjer med input og output eller i denne metoden her... Uansett når denne kjøres, så vil du regne ut en sum 1 pluss 2 pluss 3 som blir 6. Så den gjør vel da faktisk den optimale... Den regner ut hele løkka, og så kommer den fram til at svaret blir seks. Og så legges bare svaret seks ut i AX, og så returnerer det. Så det er morsomt nok.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0020", "start": 1569.84, "end": 1669.74, "token_count": 290, "text": "Uansett når denne kjøres, så vil du regne ut en sum 1 pluss 2 pluss 3 som blir 6. Så den gjør vel da faktisk den optimale... Den regner ut hele løkka, og så kommer den fram til at svaret blir seks. Og så legges bare svaret seks ut i AX, og så returnerer det. Så det er morsomt nok. Så er det den optimale... Den optimale versjonen av dette... Av denne løkka her. Det er jo bare å returnere. Det virker jo litt overraskende, men det er helt logisk. GCC går nå inn for å lage den hurtigst mulige versjonen av denne koden, og det er da faktisk bare å returnere tallet seks. Med en gang du får et input her, eller det kan skje andre ting, så er det klart, da kan man ikke optimalisere på den måten. Da ville vi sett at det fortsatt var en løkke, men at programmet da stort sett bare brukte registeret. Ok. Da skal vi... Hvis det ikke er noen spørsmål rundt optimalisering, så skal vi gå til en litt annen problemstilling, som er veldig viktig å ta med seg senere.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0021", "start": 1640.74, "end": 1752.42, "token_count": 298, "text": "Da ville vi sett at det fortsatt var en løkke, men at programmet da stort sett bare brukte registeret. Ok. Da skal vi... Hvis det ikke er noen spørsmål rundt optimalisering, så skal vi gå til en litt annen problemstilling, som er veldig viktig å ta med seg senere. Men vi skal se på det i detaljene. Her har jeg en kode som heter 1-linje. Og det er kode som viser 1 linje i... 1 linje i høynivåkode. Og det som er fokus her, det er at vi skal se at... Det ikke er en én-til-én-avhengighet fra høynivåkode til maskinkode. Så vi kan se på strukturen av dette programmet først, sånn at vi skjønner hvordan det virker. For det første så har vi da en ekstern metode som heter én-linje. Og dette er min, main, og den kaller da én-linje. Så skal vi fokusere på koden i énlinje og se hvordan den ser ut. Og én linje.c, den ser rett og slett sånn ut. Så her ser vi - det er et veldig enkelt svar", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0022", "start": 1725.02, "end": 1813.3, "token_count": 284, "text": "Og dette er min, main, og den kaller da én-linje. Så skal vi fokusere på koden i énlinje og se hvordan den ser ut. Og én linje.c, den ser rett og slett sånn ut. Så her ser vi - det er et veldig enkelt svar som regner ut meningen med livet. Som dere vet, er svar på det... meningen med livet er... Så denne regner ut dette svaret. Og det gjør vi ved å bare sette opp to variabler - svar og memoar. Det er altså en variabel i minnet, begge to. Og så gjør vi én institusjon her, som er svar er lik svar pluss memoar. Og det som er det viktigste med det vi gjør nå, er at... Én sånn linje i høynivåkode. Denne kan umulig gi en enkeltlinje i maskinkode. Det er ikke mulig fordi det ikke finnes instruksjoner som gjør en så kompleks operasjon i X86-instruksjonssettet. Alt dette må jo oversettes til X86-institusjoner som utføres.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0023", "start": 1793.98, "end": 1876.48, "token_count": 286, "text": "Denne kan umulig gi en enkeltlinje i maskinkode. Det er ikke mulig fordi det ikke finnes instruksjoner som gjør en så kompleks operasjon i X86-instruksjonssettet. Alt dette må jo oversettes til X86-institusjoner som utføres. Grunnen til at dette er viktig, er at når vi senere skal se på sånn som multitreading... Det å switche ut prosesser... Da skal vi ta en prosess, og så skal vi stoppe den midt i det programmet den gjør. Og så skal vi sette i gang andre prosesser på samme CPU. Da er det veldig viktig for operativsystemet å ha kontroll på hvilken prosess det er som gjør hva. Hvilken instruksjon det er. Og da er det som programmerer, og når vi ser på det selv, er det lett å tenke sånn at her har vi det programmet som prosessen kjører, og her utføres det én institusjon, og den er denne linjen. Men i virkeligheten så utfører prosessene ikke høynivåkode, men de utfører maskinkode. Så det vi skal se på nå,", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0024", "start": 1856.4, "end": 1963.82, "token_count": 298, "text": "er det lett å tenke sånn at her har vi det programmet som prosessen kjører, og her utføres det én institusjon, og den er denne linjen. Men i virkeligheten så utfører prosessene ikke høynivåkode, men de utfører maskinkode. Så det vi skal se på nå, er hvordan denne ene linjen med høynivåkode fører til flere linjer Med maskinkode. Og det vi må gjøre da, er... Vi må prøve oss igjen og kompilere den. Og så må vi se hvordan maskinkode GCC lager. Så... Det jeg skal prøve nå, er å be GCC lag maskinkode av... Denne C-koden. Og så kan jeg se på den. Ja... Igjen så ser vi at her brukes referanser til minne. Sånn som den første linjen her. Legg 32 i... på denne adressen. Og 32, det var den første. Memvar var den andre som var 10. Så legg ut den. Og så ser vi at denne verdien, altså det titallet, det legges i IX. Og så gjøres den ad long-verdien i IX, som da var 10. Det legges til 10.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0025", "start": 1946.1, "end": 2059.42, "token_count": 299, "text": "Så legg ut den. Og så ser vi at denne verdien, altså det titallet, det legges i IX. Og så gjøres den ad long-verdien i IX, som da var 10. Det legges til 10. Men verdien som lå i variabelen... Skal vi se... Hva var det jeg kalte den variabelen? Svar. Så opplegget er nå... Kompilatoren bestemmer seg for at denne adressen... Denne adressen, her skal variabelens svar ligge. Minus åtte bite fra toppen av området ram. Der skal variabelen svar ligge. Og memvar skal ligge fire bite fra toppen. Så de får nå hver sin plass i ram. Der legges tallet 10. Legges i eax med movel. Og så sier man adel... Altså legg til eax til variabelen svar. Her ser vi programmet flytter nå svar inn til eax. Og hvorfor gjør det det? Jo, det er fordi når du returnerer en metode, en fusjon, en c-fusjon, så forventes det av c at svaret, returverdien, ligger i eax. Og dermed oppfører en rutinen seg som den skal.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0026", "start": 2039.86, "end": 2125.78, "token_count": 296, "text": "Og hvorfor gjør det det? Jo, det er fordi når du returnerer en metode, en fusjon, en c-fusjon, så forventes det av c at svaret, returverdien, ligger i eax. Og dermed oppfører en rutinen seg som den skal. Her er den linjen som i høynivåkode var én linje. Den er da oversatt til tre linjer av kompulatoren. Man vet ikke hva kompulatoren gjør. Vanligvis vet man ikke det. Så man må alltid regne med at kompulatoren kan dele det opp i flere linjer. Og når vi senere skal drive med multitasking, så kan ikke operativsystemet vite Eller det vil si... Operativsømme vet når når det switcher fra en prosess til en annen. For nå kan vi tenke oss denne prosessen står og kjører, og så kommer det kanskje en annen prosess, som er en webserver, som skal gjøre noe helt annet. Men denne prosessen som står her og kjører, den må stoppes her og fryses. Og så må den etterpå gjøre neste operasjon. Det er avgjørende for om programmet virker som det skal.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0027", "start": 2107.3, "end": 2200.54, "token_count": 295, "text": "som skal gjøre noe helt annet. Men denne prosessen som står her og kjører, den må stoppes her og fryses. Og så må den etterpå gjøre neste operasjon. Det er avgjørende for om programmet virker som det skal. Vi skriver til og fra minne, og da kan det være andre programmer som bruker den samme variabelen med minne. Og da kan de bli sure, hvis ikke de gjør det i riktig rekkefølge. Dermed er det veldig viktig at én sånn institusjon kan føre til flere institusjoner i maskinkoden som virkelig kjøres. Og forholde seg til. Så generelt så kan man ikke vite hvordan det fungerer, men kan man på en måte tvinge Jesus og Hette til å bare lage én linje? Og i dette tilfellet så kan man ikke det heller. Man kan ikke det heller fordi... Som jeg har sagt tidligere, så er ikke det mulig å ha en sånn operasjon. Men vi kan se hva... Vi kan spørre GCC. Hvis du skal lage raskest mulig kode av denne funksjonen her, hvordan vil den se ut? Da ber vi om det, og så ser vi på den.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0028", "start": 2180.74, "end": 2288.1, "token_count": 290, "text": "Som jeg har sagt tidligere, så er ikke det mulig å ha en sånn operasjon. Men vi kan se hva... Vi kan spørre GCC. Hvis du skal lage raskest mulig kode av denne funksjonen her, hvordan vil den se ut? Da ber vi om det, og så ser vi på den. Ja... Da får vi det samme problemet igjen. Vi får på en måte ikke se den koden, fordi at her så ser vi... Hei, høre, gse-smarte-trekka. Den ser uansett hva vi måtte finne på her. Så får vi flytte opp. Så den gjør en liten scar der og legger den. Men... Men generelt så... Vil det være umulig å lage en kodelinje som adrerer sammen to tall i minnet på denne måten? Og det vi kan gjøre, vi kan prøve å lage en assembly-kode som gjør akkurat det. Og så se hvordan det fungerer. Skal vi se om jeg ikke har et eksempel på det... Assemblykode, som kanskje er den raskeste til å utføre akkurat dette her. Vi kan se på dette. Dette er kode som en assembly-programmerer skriver.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0029", "start": 2256.14, "end": 2365.58, "token_count": 291, "text": "Og så se hvordan det fungerer. Skal vi se om jeg ikke har et eksempel på det... Assemblykode, som kanskje er den raskeste til å utføre akkurat dette her. Vi kan se på dette. Dette er kode som en assembly-programmerer skriver. Man kan sette seg ned og skrive assembly-kode for X86. Så kan man inkludere den i C-koden og kjøre den. Assembleren som lager maskinkoden av denne her. Og maskinkode, stort sett så oversettes den linje for linje. Så når jeg skriver move memoer %rbx, så oversettes det av assembleren til maskinkode ved at move oversettes til det nummeret move har i instruksjonssettet osv. Så det er en én-til-én-oversettelse.  Det som er forskjellig fra forrige gang, som kommer i tillegg, det er her nede, så ser vi at vi har et datafelt. Og dette er måten man legger variabler i ram på. Så denne linjen her, den sier lag en variabelsvar, og legg i ram. Eller lagre 64 bit. Så denne vil lage 8 byte som inneholder denne variabelen.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0030", "start": 2337.76, "end": 2440.78, "token_count": 299, "text": "det er her nede, så ser vi at vi har et datafelt. Og dette er måten man legger variabler i ram på. Så denne linjen her, den sier lag en variabelsvar, og legg i ram. Eller lagre 64 bit. Så denne vil lage 8 byte som inneholder denne variabelen. Og den vil inneholde tallet 32. Og så kan vi se... Så det første jeg egentlig trenger, er å definere funksjonen én-linje. Så den global gjør at jeg kan bruke denne funksjonen fra main. Skal jeg gjøre det etterpå? Det er en standard start av funksjonen. Det jeg gjør først, er... Nå! Den dataen her nede betyr at jeg allerede har lagd tallet 32 i... Nei, her har jeg lagd tallet 10 i memoer. Så det første jeg gjør, er å flytte memoer til Erbex. Og så... Jeg legger til RBX til svar. Altså til svar som da ligger i ramm. Så denne ad-operasjonen her, den utføres på et register og et tall i ramm. Så det som utføres her nå, det er at jeg tar...", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0031", "start": 2409.84, "end": 2542.88, "token_count": 280, "text": "Så det første jeg gjør, er å flytte memoer til Erbex. Og så... Jeg legger til RBX til svar. Altså til svar som da ligger i ramm. Så denne ad-operasjonen her, den utføres på et register og et tall i ramm. Så det som utføres her nå, det er at jeg tar... I tallet 10 ligger det RBX, så jeg tar det og legger det til 32, og så får jeg svar. Hårek, det er et spørsmål om du kan gjenta hva denne koden betyr? Så den sier rett og slett'sett av 64 bit', eller 'atte bytes', til denne variabelen. Jeg tror hvis... Jeg husker ikke helt hvis man... Det er mulig det er.long, tror jeg det står, hvis du skal sette av 32 bit. Hvorfor er det et sånt tegn? Det er bare en kommentar. Ok. Men det vi skal se på nå, er... Først kan vi se på hvordan vi kan kjøre denne. Den kan jeg da kjøre ved å skjøtte den sammen med én linje main. Og enl.s, sånn.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0032", "start": 2508.64, "end": 2619.46, "token_count": 294, "text": "Hvorfor er det et sånt tegn? Det er bare en kommentar. Ok. Men det vi skal se på nå, er... Først kan vi se på hvordan vi kan kjøre denne. Den kan jeg da kjøre ved å skjøtte den sammen med én linje main. Og enl.s, sånn. Og så kjøre Adadats, og da ser vi at den funker som den skal. Så hvis jeg her nå starter med 22 i stedet, så skal vi sjekke at vi faktisk... Ja, så svarer den 32. Men... Det som er viktig her nå, er... Hva skjer hvis vi... Skal vi se... Jo... Her ser vi at man, som det står i kommentarene her... Man trenger to linjer i kode for å gjøre en høynivålinje, svar, leks, svar, pluss memoer. Men hva hadde vi trengt å gjøre dette her? Move memoer til RBX, og så add RBX? I stedet for å flytte Memvar til RBX først, så kunne vi bare addere Memvar til svar. For da ville det blitt én linje maskinkode som gjorde akkurat den jobben med å legge sammen de to.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0033", "start": 2592.34, "end": 2688.54, "token_count": 291, "text": "Move memoer til RBX, og så add RBX? I stedet for å flytte Memvar til RBX først, så kunne vi bare addere Memvar til svar. For da ville det blitt én linje maskinkode som gjorde akkurat den jobben med å legge sammen de to. Den linjen her, det er jo bare for å returnere. Så dette ville da gjøre den operasjonen i to. Nei, med én institusjon. Men da kan vi prøve oss og se hva som skjer hvis jeg... Ja, nå kan jeg jo... Jeg kan gjøre sånn. Og da ser vi... Og dette gjenspeiler da... Dette gjenspeiler da at X86-arkitekturen har ikke... Institusjon som kan legge sammen to referanser i minnet samtidig. Du kan ikke ta to variabler og legge sammen på den måten. Og det er rett og slett fordi at det kan ikke ha noe å gjøre. I prinsippet så kunne man ha lagd X86-arkitekturen sånn at det var mulig, men man har funnet det hensiktsmessig å ikke bruke den type operasjoner. Men det er det der viktig å vite.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0034", "start": 2668.94, "end": 2753.64, "token_count": 295, "text": "Og det er rett og slett fordi at det kan ikke ha noe å gjøre. I prinsippet så kunne man ha lagd X86-arkitekturen sånn at det var mulig, men man har funnet det hensiktsmessig å ikke bruke den type operasjoner. Men det er det der viktig å vite. Koder som dette her vil da nødvendigvis medføre at man må lage to uavhengige institusjoner i maskinkoden når den kjøres. Ok, men da ser jeg vi trenger en pause. Vi kan... Vi kan ta et kvarter pause, så starter vi en... Hva blir det? 9.33. Jeg har lyst til å si noe, bare, hvis det er greit. Vi har merket fra i fjor, så var det mange som ikke fikk med seg det at når vi retter oppliggene, så hvis det er spørsmål der vi tenker at vi kan forklare litt mer, eller altså vi gir det i kommentarer i den filen... Men det var da en del som fikk tilbake svar, og så hadde ikke de da fått med seg at det var sånne kommentarer til de ulike spørsmålene. At folk er klar over det.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0035", "start": 2734.42, "end": 2806.6, "token_count": 283, "text": "at vi kan forklare litt mer, eller altså vi gir det i kommentarer i den filen... Men det var da en del som fikk tilbake svar, og så hadde ikke de da fått med seg at det var sånne kommentarer til de ulike spørsmålene. At folk er klar over det. Du mener at de leser kommentarene og får med seg det? Ja, for vi har skrevet én kommentar som hovedkommentar-tilbakemelding på oppgaven. Men så hadde vi lagt inn enkeltkommentarer på de oppgavene det var aktuelt for. Der var det litt forklaringer eller tips til hva man kunne se på for å løse oppgavene. Og de er jo gjerne veldig nyttige å se på hvis vi tenker at noen ikke har forstått noe og prøver å forklare litt mer. Så det er veldig nyttig hvis folk kan se litt på de, så får de antakeligvis mye hjelp derfra. Ja, for det var mange i fjor som ikke fikk med seg at de hadde fått kommentarer. Ja. Men det er veldig bra du sa, for det er kjempeviktig.", "source": "lecture"}
{"lecture_id": "os5time1", "chunk_id": "os5time1_0036", "start": 2789.12, "end": 2904.58, "token_count": 292, "text": "Så det er veldig nyttig hvis folk kan se litt på de, så får de antakeligvis mye hjelp derfra. Ja, for det var mange i fjor som ikke fikk med seg at de hadde fått kommentarer. Ja. Men det er veldig bra du sa, for det er kjempeviktig. Man lærer aller meste av sine feil eller små mangler. Pass på å lese de kommentarene. At folk også får utbytte av at vi bruker den tiden. Ja, kjempebra. Og det er enda viktigere hvis en gruppe ikke får godkjent. Hvis de ikke har svart bra nok til å få godkjent. Så er det opplagt veldig viktig å se på kommentarene og rette opp av de feilene man har gjort. Det er greit å si ifra sånn at folk får det med seg. Nei. Kjempebra du sier det. Ja, da tar vi en noblere kvarter pause til femoral. Og så møtes vi igjen da til... Ja, først skal vi se på en If-test, og så skal vi gå videre med pipelining og superskalare seppuer. Hva er det som er så spesielt med denne filmen?", "source": "lecture"}
{"lecture_id": "linux3del9", "chunk_id": "linux3del9_0000", "start": 0.0, "end": 67.3, "token_count": 213, "text": "Vi så tidligere på hvordan vi kan pipe feilmeldinger videre, med en litt sånn komplisert konstruksjon. Men jeg skal vise en litt enklere måte å gjøre det på her. La oss si hvis vi skriver ECHO high, så skriver jeg med ville feil ECHO feil. Og da kommer det en feilmelding. Tre linjer med feilmeldinger. La oss si jeg ønsket å … Og så lete etter noe i den feilmeldingen, f.eks. at jeg ønsker å finne Found. Men da ser vi at dette virker ikke. For det som sendes i den pipen, det er standard out. Standard er sendes rett til terminal. Men da går det an å legge på en Å bak der, og så kan man da få ut... Da sendes også standard R til pipen, og så sendes det videre til grep, og så kan man greppe.", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0000", "start": 0.0, "end": 104.78, "token_count": 294, "text": "Tråder er en måte å findele prosesseringen av en prosess på. Tidligere har vi sett på prosesser som bare har én tråd. Alle prosesser har en tråd, og tråden er på en måte den veien gjennom et program, eller den veien som følges når man utfører et program. Jeg har en litt senere sløyd her som viser disse trådene. Det er sånn man tenker seg en tråd. At det er veien som man snor seg gjennom når man kjører kode. Her er det en sånn tradisjonell... Da... Når vi er oppe i data her, så kanskje vi har en kommando som lagrer noe til data. Og så gjør den noen instruksjoner. Og så hopper den frem og tilbake. Den følger en tråd gjennom kode og data. Men for en prosess vil dette bare være én tråd som følges. Hele tiden vet man nøyaktig. Hvilken institusjon prosessen utfører. Det er denne rekken av institusjoner som vi kaller en tråd. Så kommer den nye når vi snakker om begrepet tråder.", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0001", "start": 75.04, "end": 169.88, "token_count": 278, "text": "Og så hopper den frem og tilbake. Den følger en tråd gjennom kode og data. Men for en prosess vil dette bare være én tråd som følges. Hele tiden vet man nøyaktig. Hvilken institusjon prosessen utfører. Det er denne rekken av institusjoner som vi kaller en tråd. Så kommer den nye når vi snakker om begrepet tråder. Det er at man innenfor den samme prosessen har flere tråder. Man utfører den samme koden i parallell. Samtidig så kjøres denne koden her. Men den har også noen data som er spesielle for hver tråd. PCB, f.eks. Det er registerverdier for trådene. De er forskjellige. Så man har da... Når man har flere tråder inni en prosess, så har man flere utførelser av det samme programmet. Lage en analogi om. Det var denne analogien som inspirerte meg til å lage vafler og forelese samtidig. Og det er et bilde av bateråret som tar utgangspunkt i", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0002", "start": 133.12, "end": 238.1, "token_count": 299, "text": "Så man har da... Når man har flere tråder inni en prosess, så har man flere utførelser av det samme programmet. Lage en analogi om. Det var denne analogien som inspirerte meg til å lage vafler og forelese samtidig. Og det er et bilde av bateråret som tar utgangspunkt i at vi har en prosess som er at en kokk lager én porsjon middag i et kjøkken. Det er litt som selve kokken. Hjernen min - hvis jeg er kokken. Og så har man masse ressurser, som et kjøkken med kniver og fjøl og matvarer. Og eksplisitt oppskriften. Som er den oppskriften på den porsjonen med middag som kokken skal lage. Serien av hendelser som skjer når kokken lager en porsjon. Da jeg lagde vafler, var det å følge oppskriften punkt for punkt. Tråden går den veien jeg fulgte oppskriften. Den tråden kan hoppe rundt. I tilfelle skulle jeg sjekke om noe er nok pisket. Da er det avhengig av andre forhold hvor den tråden hopper.", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0003", "start": 215.2, "end": 310.88, "token_count": 295, "text": "Da jeg lagde vafler, var det å følge oppskriften punkt for punkt. Tråden går den veien jeg fulgte oppskriften. Den tråden kan hoppe rundt. I tilfelle skulle jeg sjekke om noe er nok pisket. Da er det avhengig av andre forhold hvor den tråden hopper. Tråden kan endre seg. Når den porsjonen med mat er ferdig, da er den prosessen avsluttet. Men man kan gjøre dette på forskjellige måter. Spesielt hvis man ønsker å lage vafler eller... Lage en rett fortere. Jeg skulle laget to retter. Enten kan man ha to uavhengige prosesser... Det er sånn vi har sett på prosesser helt til nå, uten tråder. Da har vi to uavhengige prosesser som jobber hver for seg. Det tilsvarer i kokkeanalogien at vi har to kjøkken. Men så har vi fortsatt bare én CPU. Så vi gjør en multitasking Den lager én porsjon i hvert kjøkken. Så har du en oppskrift i hvert kjøkken, og så følges den oppskriften.", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0004", "start": 285.82, "end": 369.94, "token_count": 292, "text": "Det tilsvarer i kokkeanalogien at vi har to kjøkken. Men så har vi fortsatt bare én CPU. Så vi gjør en multitasking Den lager én porsjon i hvert kjøkken. Så har du en oppskrift i hvert kjøkken, og så følges den oppskriften. Det er sånn som vi har gjort med multitasking. Da har vi kanskje gitt 100 sekunder til sepunien i én prosess, og så 100 sekunder til sepunien i en annen prosess. Da kan de to rettene vi har laget, være den samme. De gjør jo samme jobben, men Superhunden løper mellom kjøkkenet og lager mat. Så kommer den nye måten å gjøre dette på, og det er med treds. Da tenker vi... Ok, det koster litt mye å ha to hele kjøkken og så skal denne kokken løpe fram og tilbake. For det er så veldig mye som er likt, f.eks. Med sånn regnejobb... Den samme koden som utføres. Hvorfor kan den ikke da... Hvorfor kan den ikke reise? Den har to-tre år.", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0005", "start": 352.38, "end": 424.92, "token_count": 284, "text": "og så skal denne kokken løpe fram og tilbake. For det er så veldig mye som er likt, f.eks. Med sånn regnejobb... Den samme koden som utføres. Hvorfor kan den ikke da... Hvorfor kan den ikke reise? Den har to-tre år. Og da forenkles dette med at vi har bare ett kjøkken, og så bytter kokken på å jobbe med de to porsjonene. Og da kan den kokken f.eks. lage to porsjoner fra samme oppskrift. Så i mitt tilfelle med vafler, så finner jeg da at den samme vaffeloppskriften... Men så kunne jeg kanskje hatt to forskjellige boller. Og så kunne jeg hente egg fra det samme... Fra det samme eggbrettet. Og melk som melkemann kommer med. Det kunne jeg bruke på begge porsjonene. Men så kunne jeg da... Ha en del ting som har felles. F.eks. oppskriften vil være akkurat den samme. Enn om jeg måtte gå ut av kjøkkenet, inn på et annet kjøkken,", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0006", "start": 404.08, "end": 497.66, "token_count": 294, "text": "Det kunne jeg bruke på begge porsjonene. Men så kunne jeg da... Ha en del ting som har felles. F.eks. oppskriften vil være akkurat den samme. Enn om jeg måtte gå ut av kjøkkenet, inn på et annet kjøkken, og så fortsette med en vaffeloppskrift på det kjøkkenet. Så det er det som er prinsippet. En prosess er ganske tung å særte opp. Den har en masse ressurser, så med tråder så utnytter man de ressursene bedre. Jobber i et kjøkken av gangen. Da kan det være samme kokken som løper fram og tilbake. Men vi har også sett på SMP at vi kan ha én kokk i hvert kjøkken. Ellers kan kokken hoppe fram og tilbake og multitaske. Men SMP, det er ikke tråder. Da har man i utgangspunktet to forskjellige prosesser. Og så er det bare én CPU som jobber med hver sin prosess. Da er det fortsatt én tråd i hver prosess. Men med tråder så kan man da ha flere kokker inne i hvert kjøkken.", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0007", "start": 469.96, "end": 550.14, "token_count": 296, "text": "Men SMP, det er ikke tråder. Da har man i utgangspunktet to forskjellige prosesser. Og så er det bare én CPU som jobber med hver sin prosess. Da er det fortsatt én tråd i hver prosess. Men med tråder så kan man da ha flere kokker inne i hvert kjøkken. Og tilsvarende - man kan ha flere tråder i hver prosess. Og da kan man ha... Da kan man ha flere CPU-er som jobber innenfor den samme prosessen. Vi kjører den samme koden. For eksempel kan en gjøre regneoppgaver i parallell. Vi hadde et eksempel med at vi skulle regne ut summen fra 1000 til 2000. I dette tilfellet kunne du ha en tråd som regnet ut summen fra 1000 til 1000, og så kunne du ha en annen tråd som regnet ut summen fra 1000 til 2000. Gjorde dette i parallell. Og når det skeduleres en sånn prosess, så skreduleres det som to uavhengige enheter. Da kunne faktisk den ene tråden kjøre på en SPU, og den andre på en A.", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0008", "start": 529.92, "end": 610.74, "token_count": 287, "text": "og så kunne du ha en annen tråd som regnet ut summen fra 1000 til 2000. Gjorde dette i parallell. Og når det skeduleres en sånn prosess, så skreduleres det som to uavhengige enheter. Da kunne faktisk den ene tråden kjøre på en SPU, og den andre på en A. Og faktisk i parallell kjøre helt samtidig. Ja, så... Det var en intro om tråder. Det finnes noen forskjellige definisjoner av tråder. Den som jeg har brukt her... Sammenhengen, rekken av helser, institusjoner som utføres når et program kjøres. Og den neste er tråden som følges når programmet utføres. Når det hopper fra institusjon til institusjon. Det er det vi har prøvd å lage et bilde av hele veien. Lettvektsprosess er også brukt om tråder. Men det er kanskje litt mer uprosist fordi... fordi en tråd ikke inneholder alle de begrepene som en prosess har. Så man kan ha flere tråder innenfor samme prosess.", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0009", "start": 588.76, "end": 675.56, "token_count": 294, "text": "Lettvektsprosess er også brukt om tråder. Men det er kanskje litt mer uprosist fordi... fordi en tråd ikke inneholder alle de begrepene som en prosess har. Så man kan ha flere tråder innenfor samme prosess. Noe som er veldig viktig, er at det er programmereren som vet hva som skrives i programmet, og ikke operativsystemet. Det så vi på tidligere, at hvis vi hadde en adoptatkopiert versjon som summerer fra 1 til 2000, så er det umulig for operativsystemet å vite at... Oi, her kan jeg gjøre så smart. Jeg kan la én CPU legge seg sammen fra 1000 til 1000, og så kan jeg la en annen CPU legge seg sammen fra 1000 til 2000. Det er det umulig for operativsystemet å forstå. For operativsystemet ser bare enkeltinstitusjonene i programmet. Så det er helt opp til programmereren og... Gjøre den type vurderinger og tenke at dette kan parallelliseres. Ok, her går jeg inn med to tråder. Sånn som JA-tråder og Petreds trådbiblioteket...", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0010", "start": 656.88, "end": 754.18, "token_count": 296, "text": "Så det er helt opp til programmereren og... Gjøre den type vurderinger og tenke at dette kan parallelliseres. Ok, her går jeg inn med to tråder. Sånn som JA-tråder og Petreds trådbiblioteket... Det legger til rette for at programmereren kan styre hele prosessen, sånn at flere uavhengige tråder jobber samtidig med oppgavene som skal gjøres. Fordele arbeidsoppgaver mellom troene. Men så overlater programmereren til operativsystemet å skredulere troene. Standard er at troene skreduleres uavhengig av hverandre. Det skal vi se på litt i praksis etter hvert. Dette er det første bildet vi begynte med, med en singeltreddert prosess. Én tråd følges, og hvis vi bare har én CPU her, så vil den CPU-en følge denne tråden. Med multitreddingsprosess så ser vi at vi har tre samtidige tråder. Og da kan det være sånn at hvis man har et system med tre CPU-er eller flere, så vil typisk at et system med screedileyer dette her, Og kan jobbe reelt samtidig.", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0011", "start": 724.38, "end": 809.98, "token_count": 288, "text": "så vil den CPU-en følge denne tråden. Med multitreddingsprosess så ser vi at vi har tre samtidige tråder. Og da kan det være sånn at hvis man har et system med tre CPU-er eller flere, så vil typisk at et system med screedileyer dette her, Og kan jobbe reelt samtidig. Men hvis denne prosessen kjører på én enkel SPU... Hvis vi kjører task-sett og tvinger den til å være på samme SPU... Så vil operativstønaden skruddelegge disse trådene helt uavhengig. Men da ville man multitaske mellom trådene. Så dette ble helt tilsvarende som om man multitasker med flere prosesser. Men i tilfelle med tråder så sparer man en del ressurser. Man har felles data, felles kode, og så går det raskere å switche mellom tråder enn mellom prosesser. Her er en oppsummering av fordelene med Tourettes. For det første, som vi har nevnt mange ganger, så er det ressursdeling. Man trenger ikke å duplisere koden mellom hver prosess.", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0012", "start": 785.44, "end": 883.34, "token_count": 285, "text": "mellom tråder enn mellom prosesser. Her er en oppsummering av fordelene med Tourettes. For det første, som vi har nevnt mange ganger, så er det ressursdeling. Man trenger ikke å duplisere koden mellom hver prosess. Hvis jeg kjører 100 regnejobber og starter med.1, så vil det være 100 kopier av denne koden og av dataene. Men i tråder så... Hvis man har flere tråder innenfor samme prosess, så kan man kjøre på samme kode og lagre i de samme dataene. Respons er en viktig fordel. F.eks. hvis du har et program som står og regner og kverner på et eller annet, og så skal gi tilbakemelding, så... Så vil det være veldig kjedelig hvis du da må vente på at utregningen skal bli ferdig, før programmet gir respons. Og hvis man da har én tråd som regner... Den kunne til og med nices. Og så kunne jeg ha en annen tråd som svarer på henvendelser. Og da får du veldig god respons for den applikasjonen.", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0013", "start": 857.22, "end": 937.32, "token_count": 286, "text": "før programmet gir respons. Og hvis man da har én tråd som regner... Den kunne til og med nices. Og så kunne jeg ha en annen tråd som svarer på henvendelser. Og da får du veldig god respons for den applikasjonen. Effektivitet - jeg nevnte så vidt at det går mye raskere å switche mellom to tråder enn å switche mellom to prosesser. Altså en hel context-switch kan ta fem ganger så lang tid som å switche mellom tråder. Så tar det lengre tid å starte prosesser også. Rett og slett fordi det er tyngre. Det er mer ressurser og mer som skal settes opp. Multiprosessor og -nett, det er opplagt at du hver tråd kan tilhøres en egen CPU. Så hvis du har en cellebrød med 48 CPU, så kan du da jobbe 48 ganger raskt hvis prosessen din er mulig å parademisere. Det er ikke så lett å sette opp mellom prosesser, det går an, men det kan være ganske tungvint. Altså felles deler av ramm,", "source": "lecture"}
{"lecture_id": "os10del8", "chunk_id": "os10del8_0014", "start": 914.68, "end": 943.6, "token_count": 108, "text": "Så hvis du har en cellebrød med 48 CPU, så kan du da jobbe 48 ganger raskt hvis prosessen din er mulig å parademisere. Det er ikke så lett å sette opp mellom prosesser, det går an, men det kan være ganske tungvint. Altså felles deler av ramm, som to forskjellige prosesser snakker til. Men etter et år så er det trivielt å sette opp.", "source": "lecture"}
{"lecture_id": "os2del18", "chunk_id": "os2del18_0000", "start": 0.0, "end": 85.4, "token_count": 300, "text": "Eller til en liten boks, en liten komponent, som kalles en full adder. En full adder gjør nøyaktig den operasjonen vi så på, ved å legge sammen de sifferne her, sette mente, og så får den ut ett siffer som summen, og én carry. Eller en mente som da går videre til neste operasjon. Og det som er flott nå, Når du har fått laget en liten boks som gjør dette her, så kan man sette sammen flere sånne bokser for å utføre regneoperasjoner. Da setter man sammen to sånne fulladere. Og da ser vi... Den første fulladeren her... Her kommer x0 inn og y0 inn. Og i det første leddet så er det jo alt drenomentet. Så den er null. Og så vet vi... Vi har konstruert denne boksen sånn at her kommer riktig S0 ut, og så kommer riktig C ut her nede, som er mente som skal sendes videre til neste operasjon. Så da utfører vi den operasjonen her med X0 pluss Y0 lik S0 og mente. Så sender vi mente videre til neste boks, og så utføres X1 pluss Y1 pluss mente", "source": "lecture"}
{"lecture_id": "os2del18", "chunk_id": "os2del18_0001", "start": 68.72, "end": 156.62, "token_count": 299, "text": "som er mente som skal sendes videre til neste operasjon. Så da utfører vi den operasjonen her med X0 pluss Y0 lik S0 og mente. Så sender vi mente videre til neste boks, og så utføres X1 pluss Y1 pluss mente blir S1. Det ble første summen. Og så den carrien går. Dermed har vi på magisk vis lagd en liten boks som kan legge sammen tobitstall. Det er kanskje ikke noe å rope hurra over, men vi kan jo se at dette kan vi ta videre. Vi kan... Hvis vi ønsker å legge sammen trebitstall, så bare legger vi på en fullader til. Det tredje bittet i begge de tallene, de skal da inn i denne boksen. Og så ser vi at vi får en operasjon hvor vi utfører den algoritmen som vi lærte på skolen da vi skulle legge sammen tall. Den utføres nå ved hjelp av bitt inne i CPU-en. Tallene strømmer bortover her, og til slutt så kommer svaret ut. Så det denne kretsen her gjør, er å legge sammen disse to tallene. Det kan være f.eks. 101 pluss 001. To binære tall.", "source": "lecture"}
{"lecture_id": "os2del18", "chunk_id": "os2del18_0002", "start": 135.3, "end": 209.0, "token_count": 226, "text": "Den utføres nå ved hjelp av bitt inne i CPU-en. Tallene strømmer bortover her, og til slutt så kommer svaret ut. Så det denne kretsen her gjør, er å legge sammen disse to tallene. Det kan være f.eks. 101 pluss 001. To binære tall. Og så får vi et starry til den andre. Så på denne måten så kan man da lage enhver logisk ønsket operasjon, kan man konstruere på denne måten. Man setter opp sanestabellen. Skriver ned det logiske bolske uttrykket og forenkler. Og så lager man kretsen. Og i SPU vil man hele tiden lage denne typen av små operasjoner, og så setter man de sammen til større operasjoner. Sånn som dette her, som kan da... Med 64 sånne fulleidere så kan man legge sammen 64-bitstall.", "source": "lecture"}
{"lecture_id": "linux1del5", "chunk_id": "linux1del5_0000", "start": 0.0, "end": 109.24, "token_count": 279, "text": "Filer er et sentralt Linux-begrep. Alt i Linux er filer, og alle data som strømmes mellom kommandoer, de kan også legges inn i filer. Så det er veldig viktig i Linux å ha oversikt over Linux-filsystemet. Og her ser vi et bilde av et Linux-filsystem. Øverst har vi det som kalles ROT-katalogen, og alle mapper, eller directories, de ligger da under denne ROT-katalogen. Og her ser vi en del sånne typiske mapper, som bind var user, bind, her ligger det kjørbare programmer, var ligger blant analog-filer... USR, det er sånn... En del lokale filer og man pages og... Jussebind ligger nok de aller fleste bindene her. Temperaturfiler, boot, og så er det Sandra Home for hjemmekataloger, hjemmemapper. Det som vi skal se på noen år fremover, er spesielt filene med passive shadow. Så de ligger her. Så f.eks. hvis vi går ned i filteret til dobbelte, dobbelte, dobbelte her, så kan man referere til denne mappen her som slash...", "source": "lecture"}
{"lecture_id": "linux1del5", "chunk_id": "linux1del5_0001", "start": 90.0, "end": 177.54, "token_count": 290, "text": "Det som vi skal se på noen år fremover, er spesielt filene med passive shadow. Så de ligger her. Så f.eks. hvis vi går ned i filteret til dobbelte, dobbelte, dobbelte her, så kan man referere til denne mappen her som slash... Og da er det den rotekatalogen. Slash home, slash per - den rurkeren. Og så ned slash vever. V, v, v... Så dette er da et typisk Linux-filter. Og det vi skal se på nå i starten, er hvordan manøvrerer man seg rundt i et slikt filter? Og her ser vi meg en liste over noen av de viktigste kommandoene man bruker for å manøvrere seg rundt i filteret. Så det vi skal... Gjøre videre er å bruke de kommandene. Det er også oppgaver som går på det. Så alle de beste måtene å lære seg etterpå, er egentlig bare å prøve og feile. Og om og om igjen å bli vant til å orientere seg i linjeskriteret og bevege seg ut. Pade over til det. Det er en kommando så enkel som Print working directory.", "source": "lecture"}
{"lecture_id": "linux1del5", "chunk_id": "linux1del5_0002", "start": 153.78, "end": 256.14, "token_count": 287, "text": "Det er også oppgaver som går på det. Så alle de beste måtene å lære seg etterpå, er egentlig bare å prøve og feile. Og om og om igjen å bli vant til å orientere seg i linjeskriteret og bevege seg ut. Pade over til det. Det er en kommando så enkel som Print working directory. Men her ser vi at vi ikke har noen slash først. Og det betyr at da beveger jeg meg i forhold til der jeg står. Så hvis det ikke er noen mappe som heter Home i den mappen jeg står i, så vil jeg ikke komme dit. Så alltid når man går inn der selv, så er man i en eller annen mappe. Det vanlige når du logger inn, er at du kommer til din hjemmemappe, som typisk er -home og så et brukernavn. Men det kan være annerledes. På Studies ESO så er det litt annerledes. Så vil du se hva hjemmemappen din heter. Så kan man alltid bruke Absolute Path når man flytter seg. Så jeg kan alltid skrives cd.slash.etc. Da vil jeg alltid komme dit, uansett hvor jeg står.", "source": "lecture"}
{"lecture_id": "linux1del5", "chunk_id": "linux1del5_0003", "start": 235.66, "end": 306.98, "token_count": 274, "text": "Men det kan være annerledes. På Studies ESO så er det litt annerledes. Så vil du se hva hjemmemappen din heter. Så kan man alltid bruke Absolute Path når man flytter seg. Så jeg kan alltid skrives cd.slash.etc. Da vil jeg alltid komme dit, uansett hvor jeg står. Hvis jeg ikke har en slash foran, da beveger jeg meg relativt til der jeg står. Så et annet eksempel er cd.prikk-prikk. Det betyr flytt en katalog opp. En katalog opp nærmere roten av fyllesystemet. Så kan man sette sammen det... Da flytter man seg - to kataloger opp. Så bare skriv.cd, så kommer du faktisk bare hjem til hjemmekatalogen. LS viser filer i den mappen du ligger i. LSMSL legger på ekstra info om disse filene. Så generelt har man en masse små Linux-kommandoer sånn som dette her. Så kan man legge på opsjoner. som... Som gjør at kommandoen virker på andre måter enn default uten opsjoner.", "source": "lecture"}
{"lecture_id": "os9del5", "chunk_id": "os9del5_0000", "start": 0.0, "end": 89.76, "token_count": 298, "text": "Nice er som ordet sier, å være snill med andre. Det er betydningen av ordet. Og det er akkurat det vi skal se på nå. Vi skal se hvordan vi kan endre på prioritering selv på egne prosesser. Hvis vi ikke bruker nice, ikke gjør dette eksplisitt, så er det jo operativsystemet som dynamisk endrer på prioritering. Det gir dem forskjellig prioritet i forhold til hvor mye CPU de bruker. Interaktive prosesser som ikke bruker CPU, de får høy prioritet. Mens det motsatte med rene jobber. Men nei, så er det en kommando som eksplisitt nedprioriterer seg selv. Så en Linux-prosess kan nedprioritere seg selv. Høyere nice-verdi gir mindre saputi. Men egentlig er det logisk, for hvis du har en høy nice-verdi, den går opp til 19, som er maks, så er du ekstremt snill mot andre. Da er du veldig beskjeden, som lua i hånda, bare tar saputiks når ingen andre vil ha det. Default nice-verdi er null. Da ligger du på midten. Og du kan også ha negative nice-verdier. Og hvis du er negativ nice, da er du bad.", "source": "lecture"}
{"lecture_id": "os9del5", "chunk_id": "os9del5_0001", "start": 72.4, "end": 178.9, "token_count": 295, "text": "Da er du veldig beskjeden, som lua i hånda, bare tar saputiks når ingen andre vil ha det. Default nice-verdi er null. Da ligger du på midten. Og du kan også ha negative nice-verdier. Og hvis du er negativ nice, da er du bad. De prosessene er slemme og tar ekstra resept ut hit fra de andre. Og det er da typisk noen sånne RUT-prosesser som har negativ nice-verdi. Og det kommer noen oppgaver om dette også. Og litt av clouen da er at for å sette negative nice-verdier, så må du... Men vanlige brukere kan sette vanlige Nice-verdier. Så... Ja, vi kan starte også se litt på det. Ja, da kan vi jo egentlig starte med regn, og så kan jeg sette... Oi. Nå skal vi gå på Nice, og da må jeg ha med dere. Skal vi se... Der var vi. Ja, vi skal nå se på Nice og hvordan vi kan bruke Nice til å endre på prioriteten. Og nå la jeg på et par nuller, sånn at den regnejobben står og kjører lenge. Sånn at jeg kan med Nice endre på Nice-verdien.", "source": "lecture"}
{"lecture_id": "os9del5", "chunk_id": "os9del5_0002", "start": 150.0, "end": 280.4, "token_count": 296, "text": "Der var vi. Ja, vi skal nå se på Nice og hvordan vi kan bruke Nice til å endre på prioriteten. Og nå la jeg på et par nuller, sånn at den regnejobben står og kjører lenge. Sånn at jeg kan med Nice endre på Nice-verdien. Så jeg kan ta... Først kan vi vise hvordan det brukes. Vi kan f.eks. starte nice minus en ni og så regn. Den starter da en regnejobb med nice-verdi ni. Og det kan vi se her når vi kjører topp. Her står det ni. Det er da nice-verdi 9. Men det som da er litt rart, er... Oi. Nå ser jeg at jeg står litt i veien her. Sånn. Det som er litt rart, er at her oppe så ser vi... Denne jobben bruker jo 100 % CPU. Selv om den er nice. Det var litt rart... La oss si jeg prøver å sette i gang en til... Så ser vi at... Jo, den er veldig nice, men... Den bruker fortsatt så å si 100 % separatitt. Så skal vi se hvordan man kan også renise. Jeg kan renise og så si pluss 19 på den paydayen der.", "source": "lecture"}
{"lecture_id": "os9del5", "chunk_id": "os9del5_0003", "start": 243.26, "end": 366.68, "token_count": 300, "text": "La oss si jeg prøver å sette i gang en til... Så ser vi at... Jo, den er veldig nice, men... Den bruker fortsatt så å si 100 % separatitt. Så skal vi se hvordan man kan også renise. Jeg kan renise og så si pluss 19 på den paydayen der. Den som hadde 9. Og da setter vi old priority 9, new priority 19. Skal vi se... Vi kan sjekke om den er absolutt. Der er det minus 3. Nei, jeg får ikke lov til å sette det minus 3. Da får jeg permission to night. So that's a minus... Det betyr bare sett til... Nei... Pluss skal du så. Jeg får ikke lov til å være negativ. Sett pluss 18. Det betyr... Sett verdien til pluss 18. Men hvorfor fikk jeg...? Ikke lov å renice den... Gjør jo sånn, ja. Der fikk jeg prioritert 19 på den prosessen. Men likevel... Fortsatt er problemet her... Det høres ikke ut som noe av det jeg har sagt, er riktig. De er jo ikke nice. De tar alle sefurene. Ja, det var et godt spørsmål... Det skulle være mulig å gjøre det lavere.", "source": "lecture"}
{"lecture_id": "os9del5", "chunk_id": "os9del5_0004", "start": 338.88, "end": 438.98, "token_count": 274, "text": "Men likevel... Fortsatt er problemet her... Det høres ikke ut som noe av det jeg har sagt, er riktig. De er jo ikke nice. De tar alle sefurene. Ja, det var et godt spørsmål... Det skulle være mulig å gjøre det lavere. Kanskje ikke. Det må jeg undersøke. Men det kan jeg ta pausen å gjøre. Og så kan dere også da... I pausen kan dere tenke på... Hva er det som gjør at nice ikke ser ut til å ha noen effekt der? Hvorfor fortsetter de å kjøre i 100 % disse jobbene selv om de har en høy nice-verdi? Jeg ser for øvrig et par RUT-prosesser som har minus 20. Det vil si den høyeste prioriteten du kan gitt i noen prosess med nice minus 20. Men de jobber ikke så mye. En gang de ønskes i PUS, så får de det. Og så blir det prioritert fremfor alle andre. Men tenk litt på i pausen... Hva kan dette skilles? Og i tillegg så kan vi se på om det går an å rinheise nedover.", "source": "lecture"}
{"lecture_id": "os4del19", "chunk_id": "os4del19_0000", "start": 0.0, "end": 89.8, "token_count": 293, "text": "Hvordan vet man at man ikke overskriver registeren eller RAM hvis de f.eks. brukes av en annen prosess? Og det er et veldig godt spørsmål. Og det kommer vi tilbake til etter hvert. Men der er det helt klare kjøreregler. Hvis vi husker tilbake da vi snakket med Prosesser om at Prosesser er et liv som... en veldig viktig oppgave for operativstemme er å sørge for at de ikke ødelegger for hverandre. Når det gjelder ramm, gjøres det ved at til hver prosess eller hvert program tildeles det en gitt bit av ramm. Og de bitene er da sikret, sånn at det er umulig for den prosessen å skrive til andre deler. av ram enn det operativsystemet har bestemt. Så da får man en feil hvis man prøver å skrive til en adresse. Ofte i C-programmet så får man sånn core dumped. Det er typisk hvis man prøver å skrive til et sted i ram hvor man ikke har lov til, så krasjer programmet. Så det er én ting. En annen ting er med registrene, og da er det sånn at...", "source": "lecture"}
{"lecture_id": "os4del19", "chunk_id": "os4del19_0001", "start": 70.02, "end": 151.0, "token_count": 290, "text": "Ofte i C-programmet så får man sånn core dumped. Det er typisk hvis man prøver å skrive til et sted i ram hvor man ikke har lov til, så krasjer programmet. Så det er én ting. En annen ting er med registrene, og da er det sånn at... Registrene brukes av ett program av gangen. Som vi skal se på senere... Når et operativsystem kjører flere programmer, så bytter de på. Hvis dette programmet står og kjører, sånn som nå... Så innimellom her at denne summen ble regnet ut. Så kunne det være et annet program som kjørte en kort stund. Det typiske de gjør, er at de får ca. et hundredels sekund. Og når de er ferdige med det hundredels sekundet, så lagrer operativstemmet alle registerverdiene. Alle verdiene som er i registeret. Og alt som er i RAM, er allerede lagret. Men de verdiene som er i registrene, lagres av operativstemmet i RAM. Og når prosessen etterpå skal inn og kjøre videre, så laster man tilbake de registerverdiene. Kardinene.", "source": "lecture"}
{"lecture_id": "os13del4", "chunk_id": "os13del4_0000", "start": 0.0, "end": 99.8, "token_count": 288, "text": "Dining philosophers problem, det er et veldig kjent problem hvor deadlock da kan oppstå. Og dette er kjent fordi at det blir ofte brukt som et eksempelproblem. Så man trenger da... Eller man bruker semaforer og mutex. Og så skal man programmere disse filosofene til å siste å spise spagetti og tenke. Men så må man gjøre det på en sånn måte at man unngår deadlock. Så problemet, hvis dere kan se her, så er det... Den tegningen skal forestille et bord med fem porsjoner med spagetti. Og så ligger det mellom hver tallerken en gaffel. Og da tenker vi også at det er fem filosofer som sitter rundt her og skal spise. Og dette må da programmeres som filosofprosesser. Og de oppfører seg sånn at noen ganger så sitter de og tenker uten gafler. Men så er det noen ressurser de deler på, og det er gaflene. Hvis det sitter en over seg her... Så har han to gafler som han kan ta. Og systemet er sånn at for å spise så må man ha to gafler.", "source": "lecture"}
{"lecture_id": "os13del4", "chunk_id": "os13del4_0001", "start": 72.64, "end": 162.24, "token_count": 299, "text": "Og de oppfører seg sånn at noen ganger så sitter de og tenker uten gafler. Men så er det noen ressurser de deler på, og det er gaflene. Hvis det sitter en over seg her... Så har han to gafler som han kan ta. Og systemet er sånn at for å spise så må man ha to gafler. Og da er det typisk sånn... Jo, det er programmet, dette her, så de må da ta opp gafler én av gangen. Og da må de med mutixer og så videre sjekke at gaflene er ledige. Så må de plukke opp først en gaffel, og så en til. Og så, når de kommer i gang, så kan de starte med å spise. Og da må disse programmere sånn at det er random tidsbruk. Altså de kan sitte og tenke en stund, og så bestemmer de seg. ... Nå skal jeg begynne å spise. Og så begynner de å spise. Problemstillingen er da å programmere dette sånn at alle sitter og spiser. Og så... må de da... Jo, programmet må være sånn at de når som helst kan ta en gaffel", "source": "lecture"}
{"lecture_id": "os13del4", "chunk_id": "os13del4_0002", "start": 131.0, "end": 209.96, "token_count": 300, "text": "Altså de kan sitte og tenke en stund, og så bestemmer de seg. ... Nå skal jeg begynne å spise. Og så begynner de å spise. Problemstillingen er da å programmere dette sånn at alle sitter og spiser. Og så... må de da... Jo, programmet må være sånn at de når som helst kan ta en gaffel og komme i gang med å spise, og så må dette flyte. Og dette må gjelde i alle situasjoner. Og da kan det være sånn at dette fungerer veldig fint lenge, og så plutselig kommer du til deadlock. Og et eksempel på deadlock da, det vil typisk være at... Jo, tenk om... Hvis vi tenker oss disse fem trådene... Kjøre på én CPU... Så vil du gjøre én ting av gangen. I og for seg kan det akkurat det samme skje hvis vi kjører på fem forskjellige CPU-er. Men i hvert fall hvis man tenker seg at alle samtidig kommer til det steget at de har tatt én gaffel opp. Og så sitter de og holder på den ressursen. Og så gjør alle de andre det samme. For da...", "source": "lecture"}
{"lecture_id": "os13del4", "chunk_id": "os13del4_0003", "start": 189.1, "end": 262.92, "token_count": 289, "text": "I og for seg kan det akkurat det samme skje hvis vi kjører på fem forskjellige CPU-er. Men i hvert fall hvis man tenker seg at alle samtidig kommer til det steget at de har tatt én gaffel opp. Og så sitter de og holder på den ressursen. Og så gjør alle de andre det samme. For da... Alle tar opp høyre gaffel, og så venter de på at venstre gaffel skal bli ledig. Men hvis man ikke programmerer med høyde for deadlock på den måten, så vil det kunne skje at alle bare da sitter og venter med en gaffel i høyre hånd, og venter på at den venstre skal bli ledig. Og det skjer aldri. Og da har man en deadlock. Og det viser seg at det er ikke så enkelt å få til å programmere dette her. Ja, det er kommentarer med selvkjørende biler. Ja, og da vil du virkelig få en deadlock. Når selvkjørende biler blir så avanserte at de kjører ut i trafikken, så er absolutt det noe man må ta hensyn til og få til en deadlock-løsning.", "source": "lecture"}
{"lecture_id": "os13del4", "chunk_id": "os13del4_0004", "start": 240.0, "end": 329.96, "token_count": 297, "text": "Ja, det er kommentarer med selvkjørende biler. Ja, og da vil du virkelig få en deadlock. Når selvkjørende biler blir så avanserte at de kjører ut i trafikken, så er absolutt det noe man må ta hensyn til og få til en deadlock-løsning. Og ja, en mulig løsning kan kanskje være at man... Ja, nei, det er ikke noe... Hvis du tenker på det med selvkjørende biler... Det er et godt eksempel. Det er ikke så enkelt å finne ut hvem som skal kjøre... Det må kanskje være noe sånn at en starter å begynne å kjøre, og så detektere, men da vil den andre si at... ja. Rangere med prioritet. Jo, det kunne være en mulighet. Alle biler har en prioritet. Så må de snakke sammen. Men det var et veldig godt eksempel på en virkelig deadlock som kan oppstå, og som rent praktisk må kunne løses. Ja. Men kunstig intelligens... Jo, det blir jo en kunstig intelligens, men det er ikke så lett å lære det heller. Kunstig intelligens lærer ofte av tidligere data.", "source": "lecture"}
{"lecture_id": "os13del4", "chunk_id": "os13del4_0005", "start": 300.0, "end": 405.78, "token_count": 294, "text": "Men det var et veldig godt eksempel på en virkelig deadlock som kan oppstå, og som rent praktisk må kunne løses. Ja. Men kunstig intelligens... Jo, det blir jo en kunstig intelligens, men det er ikke så lett å lære det heller. Kunstig intelligens lærer ofte av tidligere data. Men det er klart. Dette er virkelig... Det er jo kunstig nøkkelgjens. Men... Hovedpoenget her er at dette er noe som oppstår med en gang man deler på ressurser og prøver å synkronisere seg imellom. Og det er ikke så lett å unngå deadlock, men det er usedvanlig viktig å... Det kommer mange gode forslag her. Trafikklys, jo, det er jo en... Man trenger jo ikke engang å være synlig i trafikklys, men at man har... Man legger inn det i alle kryss. Man kan jo på en måte lage software-trafikklys som alle indirekte vet om. OK. Men... Ja, så... Så dette er deadlock-problemstillingen. Mulige løsninger for deadlock. Den første og viktigste løsningen er å prøve å forhindre det.", "source": "lecture"}
{"lecture_id": "os13del4", "chunk_id": "os13del4_0006", "start": 371.84, "end": 469.44, "token_count": 289, "text": "men at man har... Man legger inn det i alle kryss. Man kan jo på en måte lage software-trafikklys som alle indirekte vet om. OK. Men... Ja, så... Så dette er deadlock-problemstillingen. Mulige løsninger for deadlock. Den første og viktigste løsningen er å prøve å forhindre det. F.eks. internt i operativsystemkjernen så er det utrolig viktig at deadlock forhindres, sånn at prosesser ikke står og venter på hverandre. Skrive kode som gjør da at det aldri oppstår deadlock. Og det kan være litt vanskelig å programmere, fordi du ofte må teste det ut. Men da kan det være sånn at deadlock oppstår bare i ekstremt sjeldne tilfeller. Og så oppdager man ikke før det skjer i kjørende kode. For vanlige brukerprosesser så er det vanskelig for operativsystemet. Å garantere at det ikke skjer en deadlock. Altså, la oss si at operativsystemet tilbyr sematforer sånn som dette med mate og signal, men hvis to programmer bruker det på denne måten her, så skjer det en deadlock.", "source": "lecture"}
{"lecture_id": "os13del4", "chunk_id": "os13del4_0007", "start": 442.28, "end": 513.98, "token_count": 250, "text": "For vanlige brukerprosesser så er det vanskelig for operativsystemet. Å garantere at det ikke skjer en deadlock. Altså, la oss si at operativsystemet tilbyr sematforer sånn som dette med mate og signal, men hvis to programmer bruker det på denne måten her, så skjer det en deadlock. Og det er... Da er det vanskelig for operativsystemet å gjøre noe med det. Så metode to er altså å løse opp en deadlock, men det er generelt vanskelig. For ofte så holder en prosess på en ressurs av en grunn. Det er ikke bare tilfeldig at den har tatt den gaffelen. Den skal ha den. Så det er generelt vanskelig å løse opp deadlocker etter at det har skjedd. Så en vanlig måte å håndtere deadlock-problemer på er å stikke hodet i sanden, som strutser gjør. Og det er ofte sånn operativsystemet gjør. Så ignorerer operativstemme det problemet.", "source": "lecture"}
{"lecture_id": "linux4del5", "chunk_id": "linux4del5_0000", "start": 0.0, "end": 103.06, "token_count": 287, "text": "Vi skal nå se på diverse andre filtester og teste ut hvordan de virker. Så da starter jeg en tom mappe. Og så lager jeg en fil. Og så lager jeg en mappe. Så kan jeg også lage en link, f.eks. en link til passordfilen. Hvis jeg lister den nå, så ser vi at alle de finnes. Og da kan vi starte med den testen vi så på... If minus fphi... Ikke dollar, men bare fil.txt. Det er navnet på den fyren. Så kan vi, hvis den finnes, hvis dette blir true, så kan vi skrive ut... Kanskje bare true og fi... sånn. Og da ser vi at vi fikk ut en tru. Hvis vi kjører den kommandoen, så får vi ut tru. Så kan vi gjøre det tilsvarende med mappe. Men det har vi også sett tidligere. Hvis vi tester på en mappe sånn, så får vi også ut tru. Men siste testen er minus L for link. Hvis jeg tester det på mappe, så får jeg ingenting. Hvis jeg tester det på den linken, så ser vi. Jo, da får vi tru. Dette er da en link.", "source": "lecture"}
{"lecture_id": "linux4del5", "chunk_id": "linux4del5_0001", "start": 77.18, "end": 185.64, "token_count": 289, "text": "Hvis vi tester på en mappe sånn, så får vi også ut tru. Men siste testen er minus L for link. Hvis jeg tester det på mappe, så får jeg ingenting. Hvis jeg tester det på den linken, så ser vi. Jo, da får vi tru. Dette er da en link. Så har vi også noen andre tester, f.eks. hvordan å teste om en fil er skrivbar. Så kan vi se på denne filen her. Er den skrivbar? Ja, den er skrivbar, så det skulle gå an å få det til. Og det tester man med minus W. Da får jeg tro, for jeg kan skrive til. Hvis jeg nå endrer den til... La oss si 4.00. Det vil nå gi at film bare kan leses. Så ser vi da hvorfor jeg ikke tror lenger. Og tilsvarende hvis jeg setter den, la oss si, til... 3.00. Hva vil det si? Jo, det er bare å skrive og kjøre rett etter. Hvis jeg nå tester på å skrive her, så får jeg ikke tro. Men selvsagt så er den fortsatt en fil. Og nå kan jeg også teste på kjørbar. Og den er da også kjørbar.", "source": "lecture"}
{"lecture_id": "linux4del5", "chunk_id": "linux4del5_0002", "start": 153.96, "end": 268.5, "token_count": 290, "text": "Og tilsvarende hvis jeg setter den, la oss si, til... 3.00. Hva vil det si? Jo, det er bare å skrive og kjøre rett etter. Hvis jeg nå tester på å skrive her, så får jeg ikke tro. Men selvsagt så er den fortsatt en fil. Og nå kan jeg også teste på kjørbar. Og den er da også kjørbar. Så på den måten kan man teste masse egenskaper for filer. Det fins en del andre filtester også, men det er det de oftest trenger. Av andre tester så kan det være nyttig å sammenligne strenger. Sammenligne to strenger på denne måten... La oss si if A er lik A. Det ser vi her, tror jeg. Mens A er derimot ikke lik B. Da får vi ingenting. Så kan vi... Men utropstegn gir ikke. Så vi kan også teste sånn. A er ikke lik B. Igjen så ser vi at vi må være forsiktige med syntaks. Hvis vi har utropstegner for langt fra... Eller om vi har et mellomrom imellom, så fungerer det ikke. Ja... Så kan man også sammenligne tall. Man kan f.eks. si...", "source": "lecture"}
{"lecture_id": "linux4del5", "chunk_id": "linux4del5_0003", "start": 240.0, "end": 341.96, "token_count": 282, "text": "Igjen så ser vi at vi må være forsiktige med syntaks. Hvis vi har utropstegner for langt fra... Eller om vi har et mellomrom imellom, så fungerer det ikke. Ja... Så kan man også sammenligne tall. Man kan f.eks. si... To er lik... To. Den slår til. Ja, det ville også fungert med streng sammenheng. Men det som ikke ville ha fungert, er mindre enn. Så dette er en test på om to er mindre enn to. Og den har da ikke tro. Men hvis vi tester om to er mindre enn fire, så får vi tro. Hvis det motsatte er greitere enn, Den er false. Men hvis vi gjør det tallet større, så får vi tro. Så det er en måte å sammenligne tall på. Vi skal se senere at... Det å jobbe med tall og nummerikk er... litt tungvint. Så en annen måte å få en mer moderne syntakse på, det er å bruke to parenteser på denne måten her. Da kan man teste på denne måten, som er mer naturlig. Med større enn og mindre enn. Denne vil da ikke slå til.", "source": "lecture"}
{"lecture_id": "linux4del5", "chunk_id": "linux4del5_0004", "start": 311.36, "end": 402.64, "token_count": 292, "text": "Det å jobbe med tall og nummerikk er... litt tungvint. Så en annen måte å få en mer moderne syntakse på, det er å bruke to parenteser på denne måten her. Da kan man teste på denne måten, som er mer naturlig. Med større enn og mindre enn. Denne vil da ikke slå til. Da funker det ikke å sette lik. Dette er mer sånn Java CS-intaks. Da må man ha to like stein hvis du skal teste om de er like. Og hvis jeg setter 7 lik 7, så får jeg tro. Så på den måten så kan man... Når man tester tall... Generelt når vi bruker tall og aritmetikk, så er syntaksen enklere å ligne på javo-syntaks hvis man setter to parenteser rundt. Dette er typisk sånn som er lagt til skjellet i ettertid at det ble laget. Da bruker man den dobbel-parentes-syntaksen for å kunne legge til noe nytt. I tillegg så har vi logiske operatorer. Hvis vi da går tilbake til denne typen, så kan vi f.eks. si if 7 er greater enn 4. Da er det true.", "source": "lecture"}
{"lecture_id": "linux4del5", "chunk_id": "linux4del5_0005", "start": 379.28, "end": 442.98, "token_count": 175, "text": "Da bruker man den dobbel-parentes-syntaksen for å kunne legge til noe nytt. I tillegg så har vi logiske operatorer. Hvis vi da går tilbake til denne typen, så kan vi f.eks. si if 7 er greater enn 4. Da er det true. Men så kan vi legge til noe mer. Minus a er da en add. Vi kan f.eks. legge til strengen true. Da skal det fortsatt være riktig. Men hvis vi har en tom streng med ant, så ser vi... Da får vi false fordi den tomme strengen... ... jeg ikke tror. Or... Det er minus O, den gir or. Så denne vil da likevel slå til fordi syv er større enn fire.", "source": "lecture"}
{"lecture_id": "os4del10", "chunk_id": "os4del10_0000", "start": 0.0, "end": 100.0, "token_count": 257, "text": "Hvorfor ligger ikke RAM inni CPU? Nei, hvorfor ligger ikke RAM inni CPU? Skulle ikke det ligget utenfor? Og da med en referanse til... ... til det vi har sett på tidligere. Dette bildet. Jo, og her ser vi... Simulere en... En komplett CPU. Og det er helt riktig som det er påpekt, at... Ja, jeg tar opptak. Men jeg tar opptak... Veldig fint du spør. Jeg tar opptak i OBS-studio, sånn at opptaket pågår i bakgrunnen. Og spørsmålet er hvorfor ligger RAM inni CPU? Burde ikke den ligge utenfor? Jo, og det er helt riktig. Så det er på en måte... Jeg tror jeg må rette opp figurtittelen her til å si en komplett CPU tilkoblet RAM. For RAM, den ligger egentlig utenfor CPU. Sånn at de åtte... I dette tilfellet så utgjør de databussen mellom RAM og CPU. Så det burde vært påpekt her.", "source": "lecture"}
{"lecture_id": "os14del9", "chunk_id": "os14del9_0000", "start": 0.0, "end": 143.2, "token_count": 293, "text": "For eksempel sa jeg i forrige time ofte mange ganger 8K. Sånn som det der. Og strengt tatt definisjonen på K, altså i si-enheter... Som definerer kilo og alt mulig sånt... Kilo og gram og så videre... Så er egentlig K lik 1000, sånn som det er. M er da ti i sjette, G er en milliard, eller ti i niende. Så er det naturlig å snakke om det i PowerA2. Og det vi ofte gjør da, er at vi sier K er lik... Er lik 2 oppe til 10. Så to i tiende bite. Men det er jo lik 1024. Og pga. den lille forskjellen der, så er det noen som har prøvd å innføre, det har ikke vært helt å lykkes, men at ki er lik to i tiende. Da vil du se at det står kib for kilobite. Og kib er da... Eksakt lik 1024 bite. Så der kan det være en sånn liten forskjell. Men når jeg snakker om 8K, så når det gjelder RAM, så betyr det 1024...", "source": "lecture"}
{"lecture_id": "os14del9", "chunk_id": "os14del9_0001", "start": 107.0, "end": 215.6, "token_count": 249, "text": "Da vil du se at det står kib for kilobite. Og kib er da... Eksakt lik 1024 bite. Så der kan det være en sånn liten forskjell. Men når jeg snakker om 8K, så når det gjelder RAM, så betyr det 1024... Så tenker jeg på 1024 når jeg sier K. Strengt tatt burde jeg sagt key. Og tilsvarende så har du da MIB, som da er lik 1024 ganger 1024 bites. Eller ikke to i tiende, men to i tyvende. Men det 32 er tilnærmet lik 109. Men... Eller en milliardbite. Eller det vi kaller for en gigabyte. Men når det begynner å komme... Her så har den faktoren 1024 litt å si. Så da kan det begynne å bli litt forskjeller, spesielt når det kommer opp i terabyte. Men vi kan se på det senere. Men uansett så er akkurat det viktig å ha med seg.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0000", "start": 0.0, "end": 116.4, "token_count": 300, "text": "Ja... Da er vi i gang igjen. Før vi fortsetter med C-programmering, så skal jeg svare på noen veldig gode spørsmål som kom i pausen. Og så kan jeg også si at med OBS Studio så kan... Man slipper å... Som i Zoom, så må den... Så tar det en halvtime å få lagd den. Så her nå har jeg allerede... Lagt ut en... Nei, ikke slides. Skal vi se... I dagens forelesning... Her. Å starte recording. Og da ser vi at det funker faktisk. Og dette fører til at... Recordingen. Jeg skal ikke ta en dobbel... Så hvis det er noe du lurer på fra første time, så kan du gå tilbake og sjekke og eventuelt stille spørsmål. Men det var noen spørsmål fra pausen. Og det første var hvorfor ligger ikke RAM inne i CPU? Nei, hvorfor ligger RAM inne i CPU? Skulle ikke det ligget utenfor? Og da med en referanse til... ... til det vi har sett på tidligere. Dette bildet. Jo, og her ser vi... Simuler en... Tittelen her er en komplett CPU. Og det er helt riktig som det er påpekt.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0001", "start": 90.0, "end": 196.28, "token_count": 299, "text": "Skulle ikke det ligget utenfor? Og da med en referanse til... ... til det vi har sett på tidligere. Dette bildet. Jo, og her ser vi... Simuler en... Tittelen her er en komplett CPU. Og det er helt riktig som det er påpekt. At... Ja, jeg tar opptak. Men jeg tar opptak... Veldig fint du spør. Jeg tar opptak i OBS-studio, sånn at opptaket pågår i bakgrunnen. Her står det at dette er en komplett SUPU. Og spørsmålet er hvorfor ligger RAM inni SUPU? Burde ikke den ligge utenfor? Jo, og det er helt riktig, så det er på en måte... Jeg tror jeg må rette opp figurtittelen her til å si en komplett CPU tilkoblet ram. For ram, den ligger egentlig utenfor CPU. Sånn at de åtte linjene her, i dette tilfellet, så utgjør de databussen mellom ram og CPU. Så det burde vært påpekt her. Det var også spørsmål om hva som er forskjellen på address out og data out i Datapath. Og det er også et godt og viktig spørsmål.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0002", "start": 175.58, "end": 262.44, "token_count": 288, "text": "så utgjør de databussen mellom ram og CPU. Så det burde vært påpekt her. Det var også spørsmål om hva som er forskjellen på address out og data out i Datapath. Og det er også et godt og viktig spørsmål. Jo, adresse ut, den sender da de fire byttene til hvilken adresse i ramm vi skal skrive til. Mens dataene, de sender her... Data out... Her sendes data... Så i det første tilfellet, når vi skulle lagre R3, som inneholdt 6, inn i ramm, så ble tallet 6 kablet rett inn her, til data out. Mens adressen... Da brukte vi R1, som var adresse nummer 1. Da ble de fire bitene koblet inn til adresse out. Og så ble det utført en tabelle. Skriving av resultatet. Så det er forskjellen på de to der. Men akkurat som på alle institusjoner må man da trykke på de riktige knappene her for å få til nettopp det. De riktige knappene i datapoden. Et siste spørsmål var om branch-kontroll i boksen på bildet.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0003", "start": 246.12, "end": 329.6, "token_count": 279, "text": "Men akkurat som på alle institusjoner må man da trykke på de riktige knappene her for å få til nettopp det. De riktige knappene i datapoden. Et siste spørsmål var om branch-kontroll i boksen på bildet. Altså den her tilsvarer kontrollenheten i CPU. Og det er også et godt spørsmål. Og svaret er ja, men i tillegg så... Så tilhører også instruksjonsdekoderen og program counter og alt det som ligger rundt datapath. Det tilhører også kontrollenheten i CPU. Og det spørsmålet tenker jeg er referert til... Bildet av en von Neumann-arkitektur. Nemlig... Her ser vi at vi har en kontrollenhet og en alu og registeret. Dette er et litt unøyaktig bilde. Det er vel kanskje det som er tilfellet. Men kontrollenhet her, det symboliserer bransjekontroll og instruksjonsdekoder og alt det som ligger rundt. Som gjør at en instruksjon som kommer inn her, sørger for...", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0004", "start": 307.72, "end": 395.8, "token_count": 295, "text": "Dette er et litt unøyaktig bilde. Det er vel kanskje det som er tilfellet. Men kontrollenhet her, det symboliserer bransjekontroll og instruksjonsdekoder og alt det som ligger rundt. Som gjør at en instruksjon som kommer inn her, sørger for... Kontrollenheten sørger da for at alle de rette knappene trykkes på i aluen og i registrene, sånn at riktig tall her aderes til et annet tall og lagres her nede, f.eks. Så alu og registers i denne figuren, det er det som vi vanligvis kaller datapath. Og for vår tegning så er det veldig detaljert nøyaktig hva datapath er. Still gjerne enda flere spørsmål underveis. Det er veldig nyttig at dere stiller spørsmål. Hvis du har et eller annet du lurer på, så er det sikkert mange andre som lurer på akkurat samme. Så ikke vær redd for å stille spørsmål. Og så har jeg helt glemt å si at det er veldig hyggelig å se dere, alle sammen. Står opp så tidlig for å være med på dette her.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0005", "start": 373.72, "end": 475.44, "token_count": 282, "text": "så er det sikkert mange andre som lurer på akkurat samme. Så ikke vær redd for å stille spørsmål. Og så har jeg helt glemt å si at det er veldig hyggelig å se dere, alle sammen. Står opp så tidlig for å være med på dette her. Ok. Da skal vi gå videre med C-programmering. Og se på... Ja, og se på hvordan denne maskinkoden som vi så i simuleringen... Hvordan den faktisk er mer eller mindre akkurat den samme når vi kompilerer høynivåspråk ned til maskinkode. For heldigvis så slipper programmerere å skrive maskinkode. Det ville vært ekstremt tungvint hvis man skulle begynne å putte inn nuller og enere helt direkte, på samme måten som vi skriver den inn i ramme i simuleringen. Og du vil da skrive maskinkoden direkte inn. På de aller første datamaskinene så gjorde man det. Da... På de aller første datamaskinene så var det nettopp det man gjorde. Man skrev inn enere og nuller direkte inn i maskinen.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0006", "start": 450.0, "end": 537.12, "token_count": 285, "text": "Og du vil da skrive maskinkoden direkte inn. På de aller første datamaskinene så gjorde man det. Da... På de aller første datamaskinene så var det nettopp det man gjorde. Man skrev inn enere og nuller direkte inn i maskinen. Hadde gjerne hullkort som man da skrev enere og nuller på. Med hull på kortet. Det var nuller og enere. Og så ble det lagret inn i maskinen som et program. Og da var det maskinkode. Til å begynne med hadde man ikke kopilator. Men så fant man ut at... Dette ble ofte veldig feil. Fordi med de gamle maskinene så puttet man inn en bunke med hullkort med maskinkode. Så fikk man resultatet. Oi, her hadde man gjort én bit feil, så alt måtte gjøres på nytt. Og denne operasjonen med å skrive maskinkode gir opplagt ekstremt mange feil. Så for å ordne på det så fant man opp høynivåspråk og kompulator. Og det som er ganske fantastisk, er at en kompulator kan oversette", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0007", "start": 517.18, "end": 616.7, "token_count": 292, "text": "Og denne operasjonen med å skrive maskinkode gir opplagt ekstremt mange feil. Så for å ordne på det så fant man opp høynivåspråk og kompulator. Og det som er ganske fantastisk, er at en kompulator kan oversette til maskinkode absolutt alle mulige former for høynivåkode. Så lenge syntaksen er riktig. Det er noen restriksjoner, syntaksen var riktig, men hvis du da skriver inn for-løkker og if-tester og wiløkker osv., så vil kompilatoren lage maskinkode som gjør nøyaktig det du ber om. Ja, det er en kommentar om at man klarte å lande på månen med hullkort og maskinkode, og det er riktig. Ikke helt riktig. Da man landet på månen i 69, så hadde man kompilatorer. Men hullkort var det mange som brukte fortsatt. Ok. Så... Det vi skal se på nå, er hvordan... Det er hvordan... Hva skjer når... Vi prøver å komplere en sånn løkke... Den løkken vi hadde med et C-program, som regner ut en sum.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0008", "start": 577.28, "end": 699.92, "token_count": 300, "text": "Men hullkort var det mange som brukte fortsatt. Ok. Så... Det vi skal se på nå, er hvordan... Det er hvordan... Hva skjer når... Vi prøver å komplere en sånn løkke... Den løkken vi hadde med et C-program, som regner ut en sum. Så skal jeg først finne frem de riktige programmene som gjør det. Så skal vi prøve å se litt på hva innholdet egentlig er i denne... ... eller... Hello... Og da er det et... Det fins mange programmer som kan dumpe sånn Bite-kode. Eller ikke Bite-kode, men binær kode. For dette er en binær fil. Så X63 dumper ut innholdet av den binære filen. Og da ser vi kommer det en masse tegn. Vi kan pipe den til More, sånn at vi ser hva den inneholder. Og da ser vi... Ja, dette er da... Dette er da Heks. Så ser vi det står 7F. Og det betyr at... Det første er det vanlige tallet 7, men hva er F? Jo, F er... Dette er heks, så det går opp til 16. Altså 10 er A... 11 er B, 12 C, 13 D, 14 E...", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0009", "start": 677.12, "end": 772.24, "token_count": 298, "text": "Dette er da Heks. Så ser vi det står 7F. Og det betyr at... Det første er det vanlige tallet 7, men hva er F? Jo, F er... Dette er heks, så det går opp til 16. Altså 10 er A... 11 er B, 12 C, 13 D, 14 E... Altså F er 15. Så F betyr da... F betyr da fire enere. Så... Så dette... Dette er da to bite. Så dette er... På en måte en... Det er en kortform av binært. Hvis du skrev det med nuller og ender, så ville det bli mye lengre. Så heks er en vanlig måte å skrive ut binær kode. Men elf er hva slags type binær kode dette er. Men vi kan se... Her nede så ser vi... Her kommer det... Oi... Hvis jeg tar... Sorry, en gang til. Her nede så kan man se at det står... Og det er en av de situasjonene hvor vi ser at i denne maskinkoden så snakker man med operativsystemet. Det er ikke bare institusjoner som adder og mover osv. Det er også kode her som snakker med operativsystemet,", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0010", "start": 745.92, "end": 848.68, "token_count": 296, "text": "Her nede så kan man se at det står... Og det er en av de situasjonene hvor vi ser at i denne maskinkoden så snakker man med operativsystemet. Det er ikke bare institusjoner som adder og mover osv. Det er også kode her som snakker med operativsystemet, for man må be operativsystemet om å skrive ut resultatet. Og dette kommer vi masse tilbake til, hvordan operativsystemet... Og programmer snakker sammen. Så ser vi også at det er LIBC... Det er et bibliotek som da linkes inn. Dette er typisk biblioteker som brukes for å kunne skrive ut Printf. Men det vi skal prøve å fokusere på, er den koden som utfører algoritmen. Altså den forløkken som vi har sett på mange ganger. Hvordan utføres egentlig den? Men jeg ser det er masse koder der, og så rett og slett kommer det en goddel som bare er tomt. OK. Så... Det vi skal se på da aller først, det er et seerprogram som summerer. Så her har jeg et seerprogram. Som egentlig gjør akkurat det samme som vi kjørte i simuleringen vår.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0011", "start": 813.66, "end": 919.68, "token_count": 299, "text": "og så rett og slett kommer det en goddel som bare er tomt. OK. Så... Det vi skal se på da aller først, det er et seerprogram som summerer. Så her har jeg et seerprogram. Som egentlig gjør akkurat det samme som vi kjørte i simuleringen vår. Nemlig den S-løkken som går tre ganger. Eller faktisk... Hvor mange ganger går denne her? Den går faktisk... Den starter på i lik null. Så den går en ekstra gang hvor... Den legger ikke til noe. Så det hadde vel egentlig vært riktigere å starte på 1 her. Hadde ikke det? Ja, for dette blir en gang som slår rundt i luften. Så hvis jeg starter på 1, så gjør den det samme som vår simulering. Altså den starter med I like 1, og S er initiert til 0.  Og så økes den første runde, så blir den én... Så legges i lik to, så legges to til, så blir det tre... Så går i opp i lik tre, og så legges den til. Så får vi resultatet seks, og så returneres det resultatet seks. Vi skal nå se hvordan dette utføres når vi kompilerer", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0012", "start": 896.8, "end": 986.56, "token_count": 290, "text": " Og så økes den første runde, så blir den én... Så legges i lik to, så legges to til, så blir det tre... Så går i opp i lik tre, og så legges den til. Så får vi resultatet seks, og så returneres det resultatet seks. Vi skal nå se hvordan dette utføres når vi kompilerer og kjører dette programmet. Hvordan blir egentlig maskinkoden? Det er viktig å vite at når man definerer en variabel, S lik 0, her, så tilordnes det en adresse i ram til denne variabelen. Og en integer, den er på 4 bite, eller 32 bits. Og det igjen er bare en konvensjon. Altså i C så skal integer være 4 bite. Den samme metallet her, I, den er også 4 bite. Men så har man andre variabler. F.eks. kan man lage en long-long int, som er 64 bit. Da brukes 64 bit, eller 8 bites, i ramm. Så når det lages plass til denne variabelen her i ramm, så settes det av 4 bites som ligger rett etter hverandre. Når man da skal aksessere den variabelen,", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0013", "start": 961.6, "end": 1057.9, "token_count": 291, "text": "Men så har man andre variabler. F.eks. kan man lage en long-long int, som er 64 bit. Da brukes 64 bit, eller 8 bites, i ramm. Så når det lages plass til denne variabelen her i ramm, så settes det av 4 bites som ligger rett etter hverandre. Når man da skal aksessere den variabelen, Så sender man ut på bussen en adresse. Adresse 100.045 millioner. Der ligger vår variabel. Og så er det fire bite etter hverandre som ligger der. Så dette ble akkurat som vi gjorde i simulering. Ok. Jeg kunne ha skrevet dette, all koden, inne i Maine. Men... Og definere eller deklarere funksjoner på denne måten. Så nå har jeg gjort det for å kunne skille ut dette fra main, sånn at vi etterpå kan se på hva som skjer med akkurat denne koden. Hvordan ser den ut i maskinkode? Men før vi kommer så langt, så kan jeg vise hvordan vi kompilerer og kjører dette programmet. Kalle det sum. Ja, det er spørsmål om hvorfor det står int-main og ikke void-main.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0014", "start": 1035.76, "end": 1136.4, "token_count": 287, "text": "Hvordan ser den ut i maskinkode? Men før vi kommer så langt, så kan jeg vise hvordan vi kompilerer og kjører dette programmet. Kalle det sum. Ja, det er spørsmål om hvorfor det står int-main og ikke void-main. Det er et litt for vanskelig spørsmål. Det fungerer hvis du skriver void-main også, så vidt jeg husker. Men jeg tror det er en konvensjon fordi den returnerer et... Main returnerer et tall. Altså den returnerer en integer. Men, ja... Men det... Jo, det er mulig den returnerer det til operativstemme som en sånn feilkode etter at det har kjørt. At main da returnerer en integer-feilkode. Jeg tror det er det det kommer av. OK. Mens jeg kopierer programmet og kjører det, så ser vi at vi får sum like 6. Og siden vi var inne på det, skjer det noe annerledes hvis vi... Hvis vi starter med ILI-knull? Nei, det bør være det samme. Det er bare egentlig en overflødig linje, så vi kan like gjerne starte på én. Eller... Det er enda bedre.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0015", "start": 1106.6, "end": 1222.52, "token_count": 296, "text": "Og siden vi var inne på det, skjer det noe annerledes hvis vi... Hvis vi starter med ILI-knull? Nei, det bør være det samme. Det er bare egentlig en overflødig linje, så vi kan like gjerne starte på én. Eller... Det er enda bedre. Men foreløpig så kan jeg på en måte ikke... Jeg kan ikke kompilere denne biten alene, for alt henger sammen. Men det som går an å gjøre, er å dele opp C-programmet, sånn at vi har én bit som... Som utfører summen, og en annen bit som er mail. Da skal vi se hvis jeg finner den funksjonen. Jeg tror det er en som heter Sumfunksjon. Sånn, ja. Sumfunksjon, den inneholder da bare denne funksjonen. Og det går da an å kompilere det for seg. Og så kan man i tillegg ha... En main som kaller denne funksjonen. Så her har vi en extern int-sum i den sum main. Og den kaller da sum. Er katten sum to m-er, for ikke å blande? Sum kaller funksjon sum, og så skriver den ut hva den gjør.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0016", "start": 1196.6, "end": 1286.76, "token_count": 272, "text": "En main som kaller denne funksjonen. Så her har vi en extern int-sum i den sum main. Og den kaller da sum. Er katten sum to m-er, for ikke å blande? Sum kaller funksjon sum, og så skriver den ut hva den gjør. Og dette er mulig å gjøre i IC. Og her har jeg gjort det eksplisitt, fordi vi da etterpå skal kunne gå inn og se på maskinkode for denne summen. Hvis vi ser på den samlede maskinkoden for hele sum, så er det mye mer oversiktlig, for da inkluderer det main og all kommunikasjon med operativsystemet osv. Men da kan vi se hvordan vi kan kompliere dette. Og én måte å kompilere det på er å kompilere alt sammen. Sum main og sum funksjon. Og så kalle det gjensum. Og på samme måte så får vi da et program som vi kan kjøre. Men det som er fint for oss nå, som generelt er fint,  Man kan f.eks. ha samme main, og så gjør man bare endringer her i sum.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0017", "start": 1263.96, "end": 1359.72, "token_count": 291, "text": "Og så kalle det gjensum. Og på samme måte så får vi da et program som vi kan kjøre. Men det som er fint for oss nå, som generelt er fint,  Man kan f.eks. ha samme main, og så gjør man bare endringer her i sum. Da kunne det vært fint å kunne komplere de uavhengige av hverandre. Og så skjøte de sammen etterpå. Og det er mulig. Jeg kan først komplere main. Men da må jeg legge på en... Hvis jeg legger på en opsjon minus c, så betyr det bare kompiler. Og ikke... Ikke load systembiblioteker og alt annet som trengs for å få en ferdig kjørbar kode. Bare kompler akkurat den koden inni her. Og så kan jeg kanskje kalle den for... La oss si... Main er vel et naturlig navn på den. Jeg kaller den Main. Det jeg fikk nå, var et... Eksekver hver kode som heter main, som inneholder bare den biten. Og så kan jeg gjøre det samme med... Med den symfunksjonen her borte. Den ønsker jeg å kompilere i en annen bit.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0018", "start": 1337.72, "end": 1440.32, "token_count": 286, "text": "Det jeg fikk nå, var et... Eksekver hver kode som heter main, som inneholder bare den biten. Og så kan jeg gjøre det samme med... Med den symfunksjonen her borte. Den ønsker jeg å kompilere i en annen bit. Og så kan jeg kalle den for eksempel funk. Sånn. Og da gir dette maskinkode som inneholder bare koden for funksjonen funk. Så for å lage en eksekverbar kode der, totalt sett, så må jeg legge sammen... Den operasjonen jeg gjør nå, er å linke programmet. Og da oppfører Jesus seg som en linker. Jeg linker nå main og funk sammen. Og så får jeg ut en kjørbar fil som heter SUP. Så kjører jeg den, og så ser vi at det fungerer. Så i praksis er det samme operasjonen jeg gjorde her oppe, da jeg kompilerte hele programmet og kjørte det. Men jeg delte dem opp nå i to biter. Hvis vi ser på sum, det eksekverbare programmet, så ser vi det er 8672 bytes. Det er mye større enn summen av disse to.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0019", "start": 1420.92, "end": 1535.76, "token_count": 298, "text": "da jeg kompilerte hele programmet og kjørte det. Men jeg delte dem opp nå i to biter. Hvis vi ser på sum, det eksekverbare programmet, så ser vi det er 8672 bytes. Det er mye større enn summen av disse to. Det er fordi det da er linket til en biblioteker inn i den ferdige, eksekverbare koden. Og så er den da klar til å kjøre. OK... Men vi har da gått... Denne lange veien for å... For å kunne se på hva som egentlig er innholdet i... I sumfunksjon. Så skal vi kanskje hoppe litt i... I fremstillingen her. Og så kan vi prøve å be kompilatoren om å lage... Assembler-kode. Og måten man gjør det på, er at man... I stedet for... sånn som her... at jeg bruker minus C. Minus C sier 'lag maskinkode' av denne funksjonen. I stedet så kan jeg be GCC-kompilatoren om å lage assembler-kode. Så når jeg legger på den opsjonen minus S, Den ser vi at den er ganske liten. Vi kan se på den her... Hvordan... hvordan ser den ut?", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0020", "start": 1504.92, "end": 1614.14, "token_count": 287, "text": "Minus C sier 'lag maskinkode' av denne funksjonen. I stedet så kan jeg be GCC-kompilatoren om å lage assembler-kode. Så når jeg legger på den opsjonen minus S, Den ser vi at den er ganske liten. Vi kan se på den her... Hvordan... hvordan ser den ut? Jo, den er ikke større enn dette her. Og her ser vi... Her begynner det å ligne på noe vi har sett tidligere. Og dette her er såkalt assembly-kode. Og denne koden kan man skrive for hånd selv. Så tidligere i de tidligste datamaskinene var det veldig vanlig å skrive i assembly. I dag også så skriver man assembly i noen få tilfeller hvor man... Ønsker å få ting til å gå veldig fort for å optimalisere. Men det har blitt mindre og mindre vanlig å skrive assembly. Kanskje litt vanligere for ARM, for der er det veldig viktig at ting er effektive, mobile deviser. Men... Men det å skrive assembly, det er på en måte å gjøre jobben til kompilatoren. For det vi ser her, det er nå, da...", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0021", "start": 1591.28, "end": 1677.72, "token_count": 289, "text": "Kanskje litt vanligere for ARM, for der er det veldig viktig at ting er effektive, mobile deviser. Men... Men det å skrive assembly, det er på en måte å gjøre jobben til kompilatoren. For det vi ser her, det er nå, da... Assembly-versjonen av den maskinkoden som GCC vil lage hvis jeg legger på minus C i stedet for minus S. Det jeg ba GCC om nå, var... Vis meg assembly-versjonen av den maskinkoden du vil lage. Og da ser vi at fra høynivåspråket så er det kompulatoren som da bestemmer nøyaktig hvordan denne loopen skal være. Og vi ser her for eksempel så har vi en jump less equal. Det er hopp hvis... Hvis de to tallene, altså tallet 3 og dette her, som er en referanse til ram... Hvis... Jeg tror det er sånn at hvis denne er mindre enn 3, så skal du hoppe. Og det er typisk... Det er da metoden som kompulatoren har valgt. for å få til å lage en løkke. Da skal vi hoppe til L3, og det er opp her igjen.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0022", "start": 1656.0, "end": 1752.48, "token_count": 295, "text": "som er en referanse til ram... Hvis... Jeg tror det er sånn at hvis denne er mindre enn 3, så skal du hoppe. Og det er typisk... Det er da metoden som kompulatoren har valgt. for å få til å lage en løkke. Da skal vi hoppe til L3, og det er opp her igjen. Og den utfører da akkurat den helt tilsvarende kode som vi lagde. Da skal vi se litt mer på den koden, men før vi gjør det, så kan det være greit å kjenne litt mer til X86 Assembly. De forskjellige tingene her... Hva de gjør. Så det vi skal se på nå, er hvordan man skriver assemblerkode direkte. Men det som kan være greit å ta med videre, er denne konstitusjonen her. Den ser litt rar ut. Og... dette er et register. Så denne konstitusjonen er... Det er en referanse til ram, og det er en referanse til den adressen i ram som ligger da inn i dette registeret RBP. Så akkurat som i simuleringen, hvis inni RBP ligger tallet 2, så er dette en referanse til byte nummer 2 i ramma.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0023", "start": 1733.3, "end": 1818.78, "token_count": 293, "text": "og det er en referanse til den adressen i ram som ligger da inn i dette registeret RBP. Så akkurat som i simuleringen, hvis inni RBP ligger tallet 2, så er dette en referanse til byte nummer 2 i ramma. Men så er det litt sånn minus 4 her etter, og det er... Det betyr at... Det er egentlig ikke byte nummer 2, Så det blir da... Ja, la oss si RBP var åtte, da. Så blir denne adressen egentlig til bite nummer fire. For det er åtte minus fire. Du trekker fra fire bite. Eller du trekker fra adressen med fire bite. Og dette kan være... Jeg ser ganske gresk ut til å begynne med. Men vi skal bruke litt tid på å se på assembly for å forstå hva som foregår. Det er også veldig nyttig senere, i andre sammenhenger, å kunne forstå hva assembly-koden er. Og så er dette på en måte linken fra transistorene og opp til høynivåkode. Så litt må vi forstå av registeret og hvordan de brukes. Når jeg snakker om registeret, og da ser vi at e-a-x er et register.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0024", "start": 1796.4, "end": 1900.84, "token_count": 293, "text": "å kunne forstå hva assembly-koden er. Og så er dette på en måte linken fra transistorene og opp til høynivåkode. Så litt må vi forstå av registeret og hvordan de brukes. Når jeg snakker om registeret, og da ser vi at e-a-x er et register. ... så er det fire viktige registre. AX, BX, X og DX. Og E betyr at det er et 32-bitsregister. Og Move L betyr at vi skal flytte en long. Og en long det er da 32-bit. Så Movel, Adel og disse her opererer på 32-bit. Så jeg skal skrive litt assemblykode. Da skal vi bruke i stedet RAX. Og det er en utvidet versjon. Det er 64-bits-registeret. Men vi kan gå tilbake, og så kan vi se litt på... Vi kan se litt på det som står i notatene... Om Assembly. Det står ikke så veldig mye. Jeg har lagt inn et... Et par referanser... Det er et compaigner fra Erik Hjelmås som ligger i Canvas. Det inneholder litt om assembly. Så er det masse referanser på nettet også, sånn som denne her.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0025", "start": 1872.84, "end": 1963.2, "token_count": 286, "text": "Om Assembly. Det står ikke så veldig mye. Jeg har lagt inn et... Et par referanser... Det er et compaigner fra Erik Hjelmås som ligger i Canvas. Det inneholder litt om assembly. Så er det masse referanser på nettet også, sånn som denne her. Så vi skal ikke gå veldig dypt i assembly-programmering. Vi skal bare forstå og ta med oss noen enkle sammenhenger. Men det som er viktig å vite, er at nøyaktig som i den simulerte maskinen, så fins det assembly-institusjoner. Og det er ikke noe annet enn at i X86, når det finnes en institusjon Move, så har den bare et nummer i rekken. Det er en rekke institusjoner. Kanskje Move er institusjon nummer 24. Og når den skal utføres av en X86-maskin... Så står tallet 24 der, og da er det kodet akkurat som i vår simulering. Tallet 24 betyr - legg sammen. Og så er det da en syntaks for alle instruksjoner, sånn som for move. Så angir man... Man starter med en assemblerinje med move,", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0026", "start": 1935.92, "end": 2029.76, "token_count": 295, "text": "Og når den skal utføres av en X86-maskin... Så står tallet 24 der, og da er det kodet akkurat som i vår simulering. Tallet 24 betyr - legg sammen. Og så er det da en syntaks for alle instruksjoner, sånn som for move. Så angir man... Man starter med en assemblerinje med move, og så angir man source og destination. Så move SDD... Her skriver move ax til bx, så betyr det rett og slett... Ta det som ligger i register ax, og legg i bx. Og så er assembly lagd av en masse sånne institusjoner som tilsvarer alle maskininstitusjoner. Så når maskinen er lagd, så definerer den alle institusjoner. Og f.eks. add sd... Det betyr da... Hvis jeg nå adds AxBx, så vil det bety legge sammen det som ligger i Bx med Ax, og lagre det i designation, nemlig Bx. Og tilsvarende for andre institusjoner. Det vi trenger for å gjøre akkurat den samme løkken som vi hadde i simuleringen, er disse institusjonene. Så trenger vi også å compare.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0027", "start": 2007.2, "end": 2127.6, "token_count": 288, "text": "legge sammen det som ligger i Bx med Ax, og lagre det i designation, nemlig Bx. Og tilsvarende for andre institusjoner. Det vi trenger for å gjøre akkurat den samme løkken som vi hadde i simuleringen, er disse institusjonene. Så trenger vi også å compare. Som er akkurat den samme som vi hadde i simuleringen. Sammenlign verdien av de to registrene. Og så etterpå så har vi en jump not equal. Den finnes også i Exo-86. Og da... Jump not equal, den hopper da til den riktige linjen i programmet. Og da, når vi har med det, så vet vi omtrent... For å skrive en sånn summeringsfunksjon. Så da kan vi prøve å gå inn og se på hvordan... hvordan det ser ut. Så skal vi se. Da har jeg... noen sånne funksjoner her. Og... Denne, ja. Dette er da et assembly-program som vi har skrevet. Det er egentlig bare å sette seg ned med en taxi door og skrive assembly-kode. Så det jeg prøver å etterligne, eller det er egentlig ikke den...", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0028", "start": 2076.56, "end": 2204.72, "token_count": 293, "text": "Så skal vi se. Da har jeg... noen sånne funksjoner her. Og... Denne, ja. Dette er da et assembly-program som vi har skrevet. Det er egentlig bare å sette seg ned med en taxi door og skrive assembly-kode. Så det jeg prøver å etterligne, eller det er egentlig ikke den... Det er den funk... sum... funksjonen. Denne. Det jeg gjør nå, er at jeg prøver å skrive et assembly-program som kan erstatte denne funksjonen her. Og så skal vi også se at den kan erstatte den funksjonen. Og den erstatter da direkte denne funksjonen. Kanskje vi kan gjøre det først, så kan vi se veldig kjapt her. Hvis dere ser godt etter, så er dette program som ligner helt på programmet fra simuleringen. Den eneste forskjellen er at her hadde vi... Maks i løkka kalte vi vel kanskje den for R0. Men det er fire registre, akkurat som vi i simuleringen brukte R0, R1, R2, R3 og R4. Så denne skal gjøre den løkka, og så skal den sende resultatet tilbake til main.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0029", "start": 2180.04, "end": 2269.64, "token_count": 300, "text": "Maks i løkka kalte vi vel kanskje den for R0. Men det er fire registre, akkurat som vi i simuleringen brukte R0, R1, R2, R3 og R4. Så denne skal gjøre den løkka, og så skal den sende resultatet tilbake til main. Så det... Vi kan se på hvordan det fungerer i praksis. Så det jeg skal gjøre nå, er den.summain.c. I stedet for å kompilere den sammen med dette C-programmet, så vil jeg nå kompilere den sammen med as.s. Og det kan jeg gjøre på samme måte. Jeg kan si at jeg vil ha med summain, og så vil jeg ha med as.s. Sende ut en eksekverbar kode, som er sum. Hvis jeg gjør det, og så kjører den, så ser vi... Ja. Vi får tallet seks. Men man er på en måte ikke helt overbevist om at det er faktisk denne koden her som kjører. Og da kan vi jo teste det veldig raskt ved å si... Det tallet der er jo en maks som man skal gå til i løkka, som man sammenligner med. Skal se litt nøyere på koden etterpå.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0030", "start": 2256.64, "end": 2340.66, "token_count": 295, "text": "at det er faktisk denne koden her som kjører. Og da kan vi jo teste det veldig raskt ved å si... Det tallet der er jo en maks som man skal gå til i løkka, som man sammenligner med. Skal se litt nøyere på koden etterpå. Men jeg kan i hvert fall save den der, og så prøve å kompilere på nytt, og så kjøre det. Og da ser vi... Jo, det ser ut til å virke, dette her. Det er den assembly-koden som nå utfører denne løkken her. Og da har jeg hele clouet at jeg som programmerer kan nå velge å si at nei, jeg stoler ikke på GSWC. GCC lager ikke bra nok kode. Jeg vil skrive denne koden i stedet. Og så skriver jeg denne koden, som jeg håper er mer effektiv enn koden som GCC lager. Men fra vårt ståsted så er det viktigste å se hvordan henger dette her sammen? Altså hvordan går man fra høynivåkode, som her, til maskinkode? Er det da kompilatoren som gjør den jobben? Den kompilerer da symfunksjon.c og lager eksekverbar kode.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0031", "start": 2320.8, "end": 2427.04, "token_count": 294, "text": "hvordan henger dette her sammen? Altså hvordan går man fra høynivåkode, som her, til maskinkode? Er det da kompilatoren som gjør den jobben? Den kompilerer da symfunksjon.c og lager eksekverbar kode. Men i stedet nå så kan vi... Vi kan gjøre sånn også. Kompilere as.s. Og så lage eksekverbar kode som jeg kan kalle as. SumMain, var det katten. Og så kan jeg kalle den Main. Og så kan jeg lime sammen de to bitene AS og Main og lagre det som en kjørbar filsum. Og så kan jeg kjøre det igjen. Nå er dette på en måte to uavhengige biter, så jeg kan gå inn her og endre tilbake. Endre den til tre igjen, sånn at summen skal bli ti. Da trenger jeg ikke kompilere sum main på nytt, men jeg må kompilere... Assemblykoden. Den må jeg kompilere på nytt, og så må jeg linke den sammen med main til en ny eksekuerbar kode, og så må jeg kjøre den. Så jeg kunne gjort dette én operasjon, men dette var bare for å illustrere", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0032", "start": 2400.76, "end": 2493.32, "token_count": 287, "text": "Da trenger jeg ikke kompilere sum main på nytt, men jeg må kompilere... Assemblykoden. Den må jeg kompilere på nytt, og så må jeg linke den sammen med main til en ny eksekuerbar kode, og så må jeg kjøre den. Så jeg kunne gjort dette én operasjon, men dette var bare for å illustrere at nå er det denne koden jeg kompilerer, og bare denne. Og det er uavhengig av meg. Og det gjorde jeg ved denne operasjonen. Da kan vi til slutt se litt på hvordan denne koden virker. Hva er det som egentlig skjer her? I koden her så er det bare litt info. Jeg har oppsummert noen av de størrelsene som man bruker i Assembly. B står for bite, 8-bit. W er Word, 16-bit. L er long, 32-bit eller har 4-bite. Og Q er code, 64-bit eller 8-bite. Så har man da tilsvarende registre som er av forskjellig størrelse. Så har man tradisjonelt AX, BX, CX og DX. Og så har man en slags... Åtte-bit-registeret, AH og AL.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0033", "start": 2469.12, "end": 2551.86, "token_count": 283, "text": "Og Q er code, 64-bit eller 8-bite. Så har man da tilsvarende registre som er av forskjellig størrelse. Så har man tradisjonelt AX, BX, CX og DX. Og så har man en slags... Åtte-bit-registeret, AH og AL. Og da omtaler man egentlig første og andre, altså high og low av de 16-bitene i AX. Så har vi Extended AX, som er 32-bit. De første CPU-ene var på 4... Etter hvert var det vanlig med 16-bits CPU-er. Men så kom 32-bits, og da måtte man utvide registrene. Så kom, sånn rundt 2000, 64-bits CPU-er. Og da måtte man utvide til 64-bit. Det som jeg bruker her, er som vi ser, RCX. Det er da et 64-bits-register. Så det er litt overkill når vi bare snakker om så små tall. Men jeg gjør akkurat det samme som i simuleringen. Jeg legger først tallet 3 i R6. Med move-kommandoer så legger jeg tallet 1 i AddX.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0034", "start": 2528.72, "end": 2611.7, "token_count": 290, "text": "Det som jeg bruker her, er som vi ser, RCX. Det er da et 64-bits-register. Så det er litt overkill når vi bare snakker om så små tall. Men jeg gjør akkurat det samme som i simuleringen. Jeg legger først tallet 3 i R6. Med move-kommandoer så legger jeg tallet 1 i AddX. Og vi ser det som er litt... Dette er syntaksen i Assembly. Den er sånn at tallet 3... Dette er bare en konstant. Hvis det står en dollar, så kommer det en konstant etterpå. Så dette er tallet 3. I tillegg må man ha en prosent foran registeret når man antaller et register. Så jeg legger nå 3 i icx, 1 i dx, 0 i bxax... Og så begynner jeg å kjøre en løkke. Og da... Det første jeg gjør her, er add dx til bx. Og det betyr da egentlig... Ta verdien i RBX og så legg til RDX. Og det er da en I pluss pluss. Jeg kunne gjort dette her med bare en Operasjon INK. Da ville det hatt den samme effekten.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0035", "start": 2591.52, "end": 2676.92, "token_count": 288, "text": "Og det betyr da egentlig... Ta verdien i RBX og så legg til RDX. Og det er da en I pluss pluss. Jeg kunne gjort dette her med bare en Operasjon INK. Da ville det hatt den samme effekten. Men jeg gjør det akkurat som i simuleringen, og så legger til tallet 1. Og så fortsetter jeg add RBX i RAX. Det betyr da ta RAX lik RAX pluss RBX. Og det er den summen. Og så kommer sammenligningen. Jeg sammenligner nå R6 og RBX. Og R6... Det ser vi i det tallet i den løkka jeg hadde. Så den avgjør hvor langt løkka går. Så når jeg endret den til fire, så gikk den én runde til. Det kommer først som compare, er i lik tre. Og så jump, not equal. Hvis de ikke er like. Så hopp opp til start. Og her står det 'Label start'. Det er da... I virkeligheten så vil dette programmet ligge i ramm når det er kompilert, og da er dette en adresse som den hopper opp til. Akkurat som i simulering.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0036", "start": 2649.72, "end": 2741.36, "token_count": 291, "text": "Det kommer først som compare, er i lik tre. Og så jump, not equal. Hvis de ikke er like. Så hopp opp til start. Og her står det 'Label start'. Det er da... I virkeligheten så vil dette programmet ligge i ramm når det er kompilert, og da er dette en adresse som den hopper opp til. Akkurat som i simulering. Så når alt er ferdig, så returnerer man. Og da kan man endre på koden her. For eksempel så sa jeg... RBX er lik RBX pluss RDX... Det kunne man jo f.eks. i stedet. Så kunne jeg bare si ink rbx her. Det betyr øk rbx med én. Så kan jeg da teste. Det er veldig lett å skrive feil i assembly-programmer. Men jeg kan teste nå om dette gikk bra. Kopierer først assembly-koden. Så linker jeg med meg. Og så kjører jeg. Ja, det gikk faktisk bra. Jeg oppnådde det samme med en annen institusjon, nemlig INK, som er Increment. Den bare øker RBX med én. Ja, da ser vi at vi har brukt opp tiden.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0037", "start": 2712.04, "end": 2812.18, "token_count": 293, "text": "Kopierer først assembly-koden. Så linker jeg med meg. Og så kjører jeg. Ja, det gikk faktisk bra. Jeg oppnådde det samme med en annen institusjon, nemlig INK, som er Increment. Den bare øker RBX med én. Ja, da ser vi at vi har brukt opp tiden. Men det er noen spørsmål i chatten. Hvordan vet man at man ikke overskriver registeren eller RAM hvis de f.eks. brukes av en annen prosess? Og det er et veldig godt spørsmål. Og det kommer vi tilbake til etter hvert. Men der er det helt klare kjøreregler. Hvis vi husker tilbake da vi snakket med Prosesser om at Prosesser er et liv En veldig viktig oppgave for operativstemme er å sørge for at de ikke ødelegger for hverandre. Når det gjelder ramm, gjøres det ved at til hver prosess eller hvert program tildeles det en gitt bit av ramm. De bitene er sikret, sånn at det er umulig for den prosessen å skrive til andre deler. av ram enn det operativsystemet har bestemt.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0038", "start": 2787.18, "end": 2872.32, "token_count": 291, "text": "Når det gjelder ramm, gjøres det ved at til hver prosess eller hvert program tildeles det en gitt bit av ramm. De bitene er sikret, sånn at det er umulig for den prosessen å skrive til andre deler. av ram enn det operativsystemet har bestemt. Så da får man en feil hvis man prøver å skrive til en adresse. Ofte i C-programmet så får man sånn core damped. Det er typisk da hvis man prøver å skrive til et sted i ram hvor man ikke har lov til, så krasjer programmet. Så det er én ting. En annen ting er med registrene. Og da er det faktisk sånn at... Registrene brukes av ett program av gangen. Vi skal se på senere... Når et operativsystem kjører flere programmer, så bytter de på. Hvis dette programmet kjører, sånn som nå... Så innimellom her at denne summen ble regnet ut. Så kunne det være et annet program som kjørte en kort stund. Det typiske de gjør, er at de får ca. et hundredels sekund Og når de er ferdige med det hundredels sekundet,", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0039", "start": 2855.14, "end": 2957.32, "token_count": 293, "text": "Så innimellom her at denne summen ble regnet ut. Så kunne det være et annet program som kjørte en kort stund. Det typiske de gjør, er at de får ca. et hundredels sekund Og når de er ferdige med det hundredels sekundet, så lagrer operativsystemet alle registerverdiene. Alle verdiene som er i registeret. Og alt som er i RAM, er allerede lagret. Men de verdiene som er i registrene, lagres av operativsystemet i RAM. Og når prosessen etterpå skal inn og kjøre videre, så laster man tilbake de registerverdiene. Ja... Det er et spørsmål om hvordan vet du hva som returnerer? Bare å skrive rett. Og det er et godt spørsmål. Det er... Men det er bare en konvensjon. Og konvensjonen er at verdien i r-a-x, det er den som returneres. Så hvis... Hvis jeg her, for eksempel, bare skriver inn ... move 42... 43... 42 til... Da må jeg komme til... Hvor var det jeg skulle? RAX. Sånn. Så kan vi se at etter programmet er ferdig,", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0040", "start": 2914.52, "end": 3027.6, "token_count": 292, "text": "Og konvensjonen er at verdien i r-a-x, det er den som returneres. Så hvis... Hvis jeg her, for eksempel, bare skriver inn ... move 42... 43... 42 til... Da må jeg komme til... Hvor var det jeg skulle? RAX. Sånn. Så kan vi se at etter programmet er ferdig, så er det en konvensjon som bare returnerer det som er i RAX. Så da må vi kompilere på nytt. Og kjøre. Så ser vi... Da kommer sum 42. Nå har jeg jo ødelagt hele programmet. Men det er det jo da veldig fort å gjøre. Så hvis jeg f.eks. skriver en syntaksfeil sånn som dette her... Nei, det var ikke til den... Det er komplisert. Så ser vi... Her får jeg en beskjed fra assembleren. Her har du gjort noe feil. Og det er rett og slett en syntaksfeil. Vi kan si til slutt at dette her med å assemble kode sånn som dette er, For en assembler, som man ofte kaller det programmet som lager maskinkode fra assembly, en assembler stort sett så er det bare direkte oversettelse", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0041", "start": 2996.44, "end": 3101.2, "token_count": 294, "text": "Her har du gjort noe feil. Og det er rett og slett en syntaksfeil. Vi kan si til slutt at dette her med å assemble kode sånn som dette er, For en assembler, som man ofte kaller det programmet som lager maskinkode fra assembly, en assembler stort sett så er det bare direkte oversettelse av institusjon for institusjon til maskinkode. Og det er bare snakk om bokholderi. Altså ad er institusjon nummer fire. Compare er nummer 32. Så lager man 0001 osv. Og tilsvarende med... Hvilket register det er. Så det er en veldig enkel prosess. Derimot - det å kompilere høynivåkode, det er en veldig kompleks prosess. Og det er veldig vanskelig å skrive en kompulator. Det er et veldig avansert program som må kunne oversette enhver høynivåkode til maskinkode. Og det er komplisert. Men en assembler kunne man relativt enkelt skrive. Ok. Men da stopper vi der. Og så tar vi en liten pause. Jeg tror ikke det er så mange i dag. Det blir kanskje bare jeg og Rune som er her.", "source": "lecture"}
{"lecture_id": "os4time2", "chunk_id": "os4time2_0042", "start": 3066.08, "end": 3154.68, "token_count": 244, "text": "enhver høynivåkode til maskinkode. Og det er komplisert. Men en assembler kunne man relativt enkelt skrive. Ok. Men da stopper vi der. Og så tar vi en liten pause. Jeg tror ikke det er så mange i dag. Det blir kanskje bare jeg og Rune som er her. Så har jeg også en tosk igjen, men har ikke fått kontrakt ennå. Men han kommer etter hvert. Men uansett så skal jeg lage i hvert fall to breakout-rooms. Så kan dere komme dit etter pausen. Og så stille spørsmål. Jobb med oppgavene. Det er en del oppgaver til slutt denne uken som går på akkurat dette her. Her ser du forelesningstotatene til hvor langt det kom. Så hvis det kommer noen oppgaver som er litt for tidlig ute, så kan du prøve på det også. Men vi kommer til å snakke mer om dette i neste uke. Da stopper vi der.", "source": "lecture"}
{"lecture_id": "linux11del11", "chunk_id": "linux11del11_0000", "start": 0.0, "end": 111.02, "token_count": 291, "text": "Apostrofer! Apostrofer virker så å si som i Linus. Hvis jeg da lager... Ja, la oss si jeg kan lage en mappe her. Og så kan jeg kopiere fil stjerne til mappe. Elles mappe. Så vi ser igjen... Dette fungerer sånn som på limits. Men så kan jeg lage en mariabel som jeg kaller for mappe, på den måten. Og så vil vi da se på samme måte igjen som... I et Linux-skjell - jeg gjentar det til det kjedsommelige - så vil apostrofer virke på samme måte. Hvis jeg skriver 'ekko dollar dir' med enkeltapostrofer, sånn her, så får jeg nøyaktig det som står. Men hvis jeg bruker doble apostrofer, så ser vi... Da får jeg... Da substitueres den variabelen, og jeg får ut... På samme måte så kan jeg da også... Jeg kan kjøre filer, kjøre kommandoer inni strenger. F.eks. så kan jeg lage en streng som ser sånn ut. Filer. Og så kan jeg bruke den samme denne konstruksjonen til å kjøre en kommando.", "source": "lecture"}
{"lecture_id": "linux11del11", "chunk_id": "linux11del11_0001", "start": 82.92, "end": 194.84, "token_count": 298, "text": "På samme måte så kan jeg da også... Jeg kan kjøre filer, kjøre kommandoer inni strenger. F.eks. så kan jeg lage en streng som ser sånn ut. Filer. Og så kan jeg bruke den samme denne konstruksjonen til å kjøre en kommando. Kjøre LS-dollar-dealer. Da vil LS-dollar-dealer kjøres som en kommando her. Og jeg vil få ut dette innholdet. Og da ser vi... Da får jeg ut fil.tx og file.tx. Og da ligner det faktisk i enda større grad på Linus. Jeg får ikke ut hele den utskriften her, men jeg får ut akkurat de filene der. På samme måte kan jeg lage en variabel ut fra dette her. Jeg kan si $var er lik den kommandoen. Og da får jeg ut all teksten. Det oppfører seg litt annerledes i første tilfelle her. Så nå har jeg skrevet den her. Så fikk jeg i dette tilfellet fil.taxi.file.taxi. Mens i det andre tilfellet så fikk jeg hele det. Så litt annerledes ser det ut. Og noe av grunnen til det er at i PowerShell så er all output", "source": "lecture"}
{"lecture_id": "linux11del11", "chunk_id": "linux11del11_0002", "start": 167.06, "end": 200.96, "token_count": 93, "text": "Så nå har jeg skrevet den her. Så fikk jeg i dette tilfellet fil.taxi.file.taxi. Mens i det andre tilfellet så fikk jeg hele det. Så litt annerledes ser det ut. Og noe av grunnen til det er at i PowerShell så er all output fra kommandoer og commandlets egentlig objekter. Og det skal vi se på nå.", "source": "lecture"}
{"lecture_id": "os7del9", "chunk_id": "os7del9_0000", "start": 0.0, "end": 107.42, "token_count": 299, "text": "Aller først så var det et godt spørsmål i pausen om Output from time. Om, så vidt jeg forstod spørsmålet, så var det hvorfor det er en liten forskjell på totaltiden her og user og system, hvis du legger sammen. Men her ser du 4 pluss 12. Det blir ikke 5.18. Og her er det også enda litt mer forskjell. Og svaret på det er at ja, egentlig så skal ikke de nødvendigvis bli de samme. Og det kan vi også se av den prosenten. Hvis den er 100 %, så skal de to være det samme. For det betyr at da har CPU-en vært 100 % i bruk. Og da vil du kunne se at de er like. Men i utgangspunktet så er denne kolonnen hvor mye CPU-tid som er brukt i såkalt user mode. Og det er... User mode er en modus av CPU-en hvor... Brukerprogrammet selv styrer alt og kjører Sippoon. Og det brukes stort sett hele tiden når man f.eks. regner, for da må brukerprosessen få tilgang til Sippoon og står og regner om og om igjen inne i aluen.", "source": "lecture"}
{"lecture_id": "os7del9", "chunk_id": "os7del9_0001", "start": 90.0, "end": 183.98, "token_count": 288, "text": "Brukerprogrammet selv styrer alt og kjører Sippoon. Og det brukes stort sett hele tiden når man f.eks. regner, for da må brukerprosessen få tilgang til Sippoon og står og regner om og om igjen inne i aluen. System er hvor mye tid som brukes i cornal mode, og det er hvor mye tid operativsystemkjernen bruker på denne prosessen. Og hvis det er mye kall til disk og andre... andre områder, eller mange kall til prosedyrer i operativstemmekjernen, så vil du se at... Skal vi se senere? Da kan man bruke mye tid her. Og sammenlagt så er dette hvor mye tid som brukes av CPU-en på denne prosessen. Men realtime, det er faktisk realtime. Det er hvor lang tid det tar. Så real time kan være dobbelt så lenge hvis det er to prosesser som... Hvis det er to prosesser som kjører, for eksempel... Ja, dette blir kanskje et dårlig eksempel. Hvis jeg kjører de to samtidig, så... De vil kjøre på samme CPU... Nei, de vil kjøre på hver sin.", "source": "lecture"}
{"lecture_id": "os7del9", "chunk_id": "os7del9_0002", "start": 156.02, "end": 199.9, "token_count": 124, "text": "Hvis det er to prosesser som kjører, for eksempel... Ja, dette blir kanskje et dårlig eksempel. Hvis jeg kjører de to samtidig, så... De vil kjøre på samme CPU... Nei, de vil kjøre på hver sin. Sånn at de vil vel få en... Ja, de vil få en tilsvarende... Vi kan se på et annet eksempel, men da passer det bra å ta en poll for akkurat det eksempelet vi skal se på.", "source": "lecture"}
{"lecture_id": "os7del1", "chunk_id": "os7del1_0000", "start": 0.02, "end": 89.6, "token_count": 284, "text": "Ja. God morgen, alle sammen. Som alltid er det veldig hyggelig å se at så mange av dere har kommet dere opp og er klar for Operativstem-forelesning. Det er kjempebra. Jeg vet jo ikke hvordan det går fremover. Vi kan jo håpe det blir fysiske forelesninger snart. Men som dere vet, så er det fortsatt uklart. Men vi håper at vi etter hvert skal komme i gang. Men som dere ser på timeplanen her, så er det... Ja, så har vi kommet ganske langt. Vi er nå i uke syv, så i neste uke er det konteuke. Så da er det ingen vanlige forelesninger. Og det er heller ikke ny. Nye oppgaver. Som det står her, er det ikke oppgaver pga. Conte-eksamene. Så... Så da er det ikke nye oppgaver. Men jeg tenker... Det er heller ikke lagt ut noe om container og dokker, som er neste tema. Men jeg tenkte å gjøre det i løpet av uka, iallfall, sånn at de som er veldig langt fremme, kan komme i gang med oppgaver fra uke ni.", "source": "lecture"}
{"lecture_id": "os7del1", "chunk_id": "os7del1_0001", "start": 73.44, "end": 155.92, "token_count": 292, "text": "Men jeg tenker... Det er heller ikke lagt ut noe om container og dokker, som er neste tema. Men jeg tenkte å gjøre det i løpet av uka, iallfall, sånn at de som er veldig langt fremme, kan komme i gang med oppgaver fra uke ni. Og for de som er veldig hyppe på å komme i gang med det, så skal vi se veldig kort på hvordan vi kan starte dokkekonteinere i Linux-VM-ene, sånn at dere kan komme i gang med å eksperimentere. Det var litt uklart med Ine og Rune i dag, men jeg tror etter hvert kanskje begge kommer. Så uansett, still spørsmål i chatten, og i hvert fall si ifra hvis noe er galt. Ja, så må jeg si at dette opptaket blir tatt opp. Selv om dere ikke hører den This meeting is recorded-stemmen, så tar jeg det opp i bakgrunnen. Som vanlig så legger jeg det ut etter hvert. Jeg lurer på om jeg kanskje ikke har husket å redigere fra forrige gang. Altså... Nei. Der ser jeg vi bare har uredigerte opptak.", "source": "lecture"}
{"lecture_id": "os7del1", "chunk_id": "os7del1_0002", "start": 132.72, "end": 246.78, "token_count": 297, "text": "så tar jeg det opp i bakgrunnen. Som vanlig så legger jeg det ut etter hvert. Jeg lurer på om jeg kanskje ikke har husket å redigere fra forrige gang. Altså... Nei. Der ser jeg vi bare har uredigerte opptak. Men det kommer vi også til å gjøre i løpet av uka. Redigere disse og legge det ut under enkelttemaer. Så det er litt lettere å bli her hvis man står fast med problemer i oppgaver, f.eks. Så... Temaet i dag er multitasking fortsatt. Vi så forrige gang på multitasking litt sånn i... Skal vi se... Hadde jeg en sist... Nei, det hadde jeg ikke. Vi kan gå tilbake til forrige gang. Ja, vi avsluttet dette med Branch Prediction. Så så vi litt på operativsystemhistorie. Og så så vi på... Og for å repetere det veldig fort, så er hovedideen at prosesser bytter på. Man kan bruke... Oi... Kan du dele skjermen? Betyr det at dere ikke ser skjermen min? Jeg ser, ja. Jeg ser skjermen... Ja, fint. For det jeg gjør, er å...", "source": "lecture"}
{"lecture_id": "os7del1", "chunk_id": "os7del1_0003", "start": 210.0, "end": 304.4, "token_count": 287, "text": "Og for å repetere det veldig fort, så er hovedideen at prosesser bytter på. Man kan bruke... Oi... Kan du dele skjermen? Betyr det at dere ikke ser skjermen min? Jeg ser, ja. Jeg ser skjermen... Ja, fint. For det jeg gjør, er å... Jo, jeg deler det vinduet som jeg ser, sånn at da må du... Ja, hvis dere ikke ser vinduet, så kanskje prøve å logge på igjen på Zoom. Jeg kjemper for at dere svarer kjapt. De fleste ser her i hvert fall. OK... Ja, da ser dere her. Dette er liksom grunnideen i multitasking. Vi har tre prosesser P1, P2 og P3. Og så bytter man hele tiden på hvilken av de prosessene som kjører. Og hele tiden, det er veldig ofte. Her ser du så millisekunders. Omtrent hvert hundredels sekund så kommer det da en ny prosess inn. Og tar over CPU-en og kjører. Først kjører P1. Men i løpet av et mikrosekund, kanskje enda mindre,", "source": "lecture"}
{"lecture_id": "os7del1", "chunk_id": "os7del1_0004", "start": 288.76, "end": 357.88, "token_count": 298, "text": "Og hele tiden, det er veldig ofte. Her ser du så millisekunders. Omtrent hvert hundredels sekund så kommer det da en ny prosess inn. Og tar over CPU-en og kjører. Først kjører P1. Men i løpet av et mikrosekund, kanskje enda mindre, så skjer det en kontekst-witch. P1 hives ut, P2 kommer inn. Og sånn fortsetter en evig løkke. Og det er ikke alltid at det er noen som ønsker å bruke CPU-en. Selv om du bare har én CPU, så vil de fleste prosesser bare stå og vente, kanskje på input og gjøre noe en gang iblant. Men hvis man har regnejobber som skal regne ut... Eller jeg skal rendre en video, altså gjøre masse operasjoner for å få ut de riktige pikslene. En skal vri bildet 50 grader, og så må man regne ut hvilke piksler som kommer ut. Da står CPU-en og jobber hele tiden. Og da vil det foregå sånn som dette her. Eller en kompilator, f.eks., som lager maskinkode. Den bruker også CPU hele tiden.", "source": "lecture"}
{"lecture_id": "os7del1", "chunk_id": "os7del1_0005", "start": 339.98, "end": 422.78, "token_count": 255, "text": "En skal vri bildet 50 grader, og så må man regne ut hvilke piksler som kommer ut. Da står CPU-en og jobber hele tiden. Og da vil det foregå sånn som dette her. Eller en kompilator, f.eks., som lager maskinkode. Den bruker også CPU hele tiden. Og så begynte vi forrige gang så vidt å se på multitasking i en server som har én CPU. Og da så vi at den serveren, den gjorde akkurat dette her. Hvis det kom to regnejobber som sto og regnet, så fikk de 50 % CPU-tid hver. Det vi skal fortsette med i dag, er å se på multitasking med... Altså multicore multitasking, at du har mange CPU-er som kjører i parallell. Og da skal vi se på hvordan jobbene da blir fordelt mellom CPU-ene. Og det... Vi så vel så vidt på det forrige gang også, men vi fortsetter omtrent... Da er vi slappe, i hvert fall.", "source": "lecture"}
{"lecture_id": "linux3del8", "chunk_id": "linux3del8_0000", "start": 0.0, "end": 89.96, "token_count": 285, "text": "Omdirigering til og fra kommandoer med pipes... Det har vi allerede gjort mange ganger. F.eks. så har vi gjort kommandoer som dette her. PCAUX gir ofte mye outfit, så da kan vi pipe det til kommandoen'more'. Da får vi outfit side for side. Det går også an å... Før man piper til'more', så kan man pipe det til... Plukke ut alle linjer med Haugerud, og så pipe det videre til Moore. På den måten så får man et rørsystem som man sender kommandoer mellom. Eller output fra én kommando går som input til neste. Og da kan man sette sammen kommandoer slik man vil, sånn at man får utført nøyaktig det man ønsker. Et annet eksempel... La oss si man tar Cat på passordfila. Da sendes den til terminal. Men i dette tilfellet så kanskje vi ønsker å sortere linjene her. Da kan vi pupe ut et sort. Sort sorterer da alfabetisk på første bokstav av linjen. Og så kan vi, istedenfor å sende videre til en kommando, så kan vi sende til en fil.", "source": "lecture"}
{"lecture_id": "linux3del8", "chunk_id": "linux3del8_0001", "start": 69.02, "end": 165.8, "token_count": 287, "text": "Men i dette tilfellet så kanskje vi ønsker å sortere linjene her. Da kan vi pupe ut et sort. Sort sorterer da alfabetisk på første bokstav av linjen. Og så kan vi, istedenfor å sende videre til en kommando, så kan vi sende til en fil. Og da ligger den sortert utgave av passordfila inne i fil.tkst. Anis kommer først her. A, C og så videre. Alfabetisk. Det som skjer da, er... Egentlig, når vi lager disse kommandoene, så tar vi da det første eksempelet. Så sendes Standard out fra PCA-WX. Alle de linjene. De sendes inn i Standard in tomorrow. Og så kan man ta Standard out videre og sende til grep, f.eks. Så på den måten så får man et rødskyss hjem. Det andre eksempelet vi hadde, Cat eats the password. Da ser vi... Eats the password sendes inn til Standard in for Cat. Og Standard out for Cat sendes videre til... Så tar vi den kanalen og sender inn i Filot-tekster. Og det kan faktisk eksplisitt skrives på denne måten.", "source": "lecture"}
{"lecture_id": "linux3del8", "chunk_id": "linux3del8_0002", "start": 137.76, "end": 228.94, "token_count": 285, "text": "Det andre eksempelet vi hadde, Cat eats the password. Da ser vi... Eats the password sendes inn til Standard in for Cat. Og Standard out for Cat sendes videre til... Så tar vi den kanalen og sender inn i Filot-tekster. Og det kan faktisk eksplisitt skrives på denne måten. Så kan man eksplisitt skrive at jeg ønsker... 8C-passord skal inn i CAT. Default funker sånn som det her. Man kan også med den mindre enn tegne, så ser vi veldig tydelig at etce passord sendes inn til Cat, og det som går ut fra Cat, sendes inn i Sort. Så på den måten har man et veldig kraftig system for å sette sammen kommandoer. At man kan sette sammen kommandoer av mange små kommandoer, eller at man kan effektivt løse mange oppgaver fra kommandoene. Nå skal jeg vise et eksempel på det. Hvor vi tar PSA og AX... Og det jeg ønsker nå, er å plukke ut første del av PSA og AX. Hvor det står brukernavn... Hvis du ser i første kolonne her, så står det brukernavn.", "source": "lecture"}
{"lecture_id": "linux3del8", "chunk_id": "linux3del8_0003", "start": 207.42, "end": 298.92, "token_count": 297, "text": "Nå skal jeg vise et eksempel på det. Hvor vi tar PSA og AX... Og det jeg ønsker nå, er å plukke ut første del av PSA og AX. Hvor det står brukernavn... Hvis du ser i første kolonne her, så står det brukernavn. Det fins flere måter man kan gjøre det på, men kanskje den enkleste... Den som går mest frem, er å bruke et hjelpeprogram. Og det har en litt spesiell syntaks, men i hvert fall på denne måten. Print-dollar-1, så vil Åk... Det som er inni her, det er en kommando, dette er bare syntaksen til programmet Åk. Så vi piper nå alle dataene til Åk, og så på denne måten her, så kan vi få Åk til å printe ut det første ordet, den første kolonnen. Hvis vi gjør det, så kommer det da en masse brukernavn, men det er bare den kolonnen som vi får ut. La oss si vi ønsker å telle antall brukernavn. Så kunne vi jo pipe dette til wc minus l. Men da teller vi igjen bare antall linjer. Men for å få ut antall brukernavn, så kan vi gjøre et lite triks.", "source": "lecture"}
{"lecture_id": "linux3del8", "chunk_id": "linux3del8_0004", "start": 275.08, "end": 361.84, "token_count": 281, "text": "men det er bare den kolonnen som vi får ut. La oss si vi ønsker å telle antall brukernavn. Så kunne vi jo pipe dette til wc minus l. Men da teller vi igjen bare antall linjer. Men for å få ut antall brukernavn, så kan vi gjøre et lite triks. Først pipe dette til sort, for da sorterer vi sånn at... Vi kan se hvordan det ser ut. Sånn at alle bruker noen kommer etter hverandre. Alle med Ruth kommer etter hverandre. Og så kan vi sende det videre til en kommando som heter Unique. Den gjør sånn at hvis det kommer mange like ord etter hverandre, så plukker den bare ut ett. Og da får vi straks en niste. Med alle brukere som har en kjørende prosess. Og så kan vi til slutt pipe den videre til wc-minusert, som teller antallet. Og dermed får vi ut at 13 brukere har kjørende prosesser. Det er egentlig ikke helt nøyaktig, men det er en oppgave som spør om akkurat det. Hvorfor det er en feil på én i det tallet. Det overlater vi til oppgaven.", "source": "lecture"}
{"lecture_id": "os6del8", "chunk_id": "os6del8_0000", "start": 0.0, "end": 70.68, "token_count": 293, "text": "Følgene er veldig viktige å huske fra datamaskinarkitektur. Alt CPU-ene gjør, er å bare slavisk utføre maskininstitusjoner. Én for én i en evigvarende røkke. Det er opplagt at CPU-en har ikke noe annet som hva maskininstitusjonene gjør, hva slags logikk det er inni der. Den bare følger blindt institusjonene én for én. Vi vet heller ikke operativsystemet om den indre logikken i maskininstitusjonene. Men det viktige er at NCPU utfører bare én og én institusjon. Og så er det ingen én-til-én-forbindelse mellom institusjoner i høynivåkode og maskinkode. Vi har sett at en kompulator kan lage forskjellige typer maskinkode, så det er ingen garanti for hvordan maskinkoden ser ut. Og i enkelte tilfeller er det umulig. Å lage én linje maskinkode som gjør hele høynivåkoden. Én linje kode i høynivåspråk fører ofte til mange maskininstitusjoner", "source": "lecture"}
{"lecture_id": "os6del8", "chunk_id": "os6del8_0001", "start": 53.48, "end": 135.48, "token_count": 299, "text": "så det er ingen garanti for hvordan maskinkoden ser ut. Og i enkelte tilfeller er det umulig. Å lage én linje maskinkode som gjør hele høynivåkoden. Én linje kode i høynivåspråk fører ofte til mange maskininstitusjoner i det ferdigkompliserte programmet. Så har vi også denne CPU-løkken. Den viser bare at CPU-en er en evig løkke. While not halved, altså så lenge maskinen står på. Hvis den ikke har noen institusjoner å gjøre, så gjør den den såkalte NOP. No operations. Altså at den bare står og slår i lufta og venter. Etter hvert som det har kommet servere med veldig mange SUPU-er, så ville det tatt mye energi at alle står sånn og spinner og bruker energi på det. Da er det kommet nye features hvor du kan legge SUPU-er. Men i utgangspunktet har du i hvert fall én som står og kontrollerer og slår i lufta helt til det noe skjer, at det enten er kode som skal kjøres, eller at det kommer et interrupt.", "source": "lecture"}
{"lecture_id": "os6del8", "chunk_id": "os6del8_0002", "start": 114.42, "end": 185.92, "token_count": 234, "text": "Da er det kommet nye features hvor du kan legge SUPU-er. Men i utgangspunktet har du i hvert fall én som står og kontrollerer og slår i lufta helt til det noe skjer, at det enten er kode som skal kjøres, eller at det kommer et interrupt. Det er viktig å ha med seg videre at når som helst så kan det komme et interrupt. F.eks. hvis man taster bokstaven A, så vil det da sendes en interrupt til CPU-en, Her har det kommet input fra en bruker. Eller kanskje det har kommet en pakke fra nettverket. Eller annen input fra Harberg. Så når som helst så kan det da skje et såkalt interrupt. Og da må CPUN stoppe med å gjøre disse institusjonene. Så må den ta seg av interruptet. Men dette styres da i samarbeid med... Operativsystemet må ha et opplegg for å kunne behandle interpeter.", "source": "lecture"}
{"lecture_id": "os3bdel10", "chunk_id": "os3bdel10_0000", "start": 0.0, "end": 81.24, "token_count": 298, "text": "Ja, helt til slutt, den viktigste biten i Landis & Pooh-en, det er bransjekontroll. Hvis man ikke hadde bransjekontroll, om man hadde et program på ti linjer, så ville man bare kunne kjøre de ti linjene, og så var man ferdig. Bransjekontroll gjør at man kan hoppe i koden, og det var det vi så vi gjorde hver gang vi kom til en test. Så hoppet vi som et resultat. Det er resultatet av den testen. Hvis den var likt, så hoppet vi ikke. Hvis den var jump not equal, hvis det ikke var likt, så hoppet man. Dermed kan man konstruere for- og wirelucker og if-tester og alle mulige slags konstruksjoner kan da konstrueres på den måten. Det helt avgjørende da er at man har en branch-kontroll her. Avhengig av resultatet, ved en sammenligning, så settes Z og C0 her nede. Så sendes det til branch-kontrollen. Og da ser vi at branch-kontrollen sender et signal opp til counteren. Program-counter teller seg nedover hvilke institusjoner man gjør.", "source": "lecture"}
{"lecture_id": "os3bdel10", "chunk_id": "os3bdel10_0001", "start": 60.0, "end": 106.74, "token_count": 148, "text": "Avhengig av resultatet, ved en sammenligning, så settes Z og C0 her nede. Så sendes det til branch-kontrollen. Og da ser vi at branch-kontrollen sender et signal opp til counteren. Program-counter teller seg nedover hvilke institusjoner man gjør. Og da endres den program-conteren, sånn at man hopper i koden. Og det er hele clouet for... Og det er hele clouet for hvordan en CPU kan programmeres til if-tester, få løkker og wild løkker. Og egentlig alt man trenger i en CPU.", "source": "lecture"}
{"lecture_id": "os3del9", "chunk_id": "os3del9_0000", "start": 0.0, "end": 81.0, "token_count": 260, "text": "Ja, det er også et spørsmål om problemene i de to første kretsene. Vi har et par oppgaver som vi skal se på, men jeg kan si det kjapt. Her er problemet... Det er at man ikke kan endre på verdien. Hvis man først har en ener inn her, så er det umulig å endre på den eneren. Så dermed legger vi på dette systemet for å kunne endre verdien. Og nå har vi et system som kan endre verdi. Nå er det null her. Da lagres den nullen. Hvis jeg endrer den til én, så kommer den ned under her. Men problemet her nå er at med en gang jeg gjør en endring her, så endres verdien seg. Men jeg ønsker å ha en lagerenhet som man på en måte kan skru av. Den lagrede enheten bare forblir her, uten å endres. Og for å få til det, så trenger man en litt mer kompleks struktur. Nemlig en bryter, en kontroller, C, som skrur av og på det at man kan lagre data.", "source": "lecture"}
{"lecture_id": "os13del14", "chunk_id": "os13del14_0000", "start": 0.0, "end": 94.96, "token_count": 288, "text": "Som vi har argumentert for tidligere, så må alle de virtuelle adressene kunne knyttes til fysiske adresser. Som jeg nevnte, så kunne det skjedd ved Loading. Men det er både tidkrevende og tungvint og lite dynamisk. Så i alle moderne OS gjøres dette dynamisk mens programmet kjører. Og det gjør at man kan flytte inn og ut programmer og biblioteker... som operativstemme ønsker, når det vil for å kunne kjøre alle programmer mest mulig effektivt. Vi kunne hatt sånn at operativstemme oversatte mellom fysiske adresser og de logiske eller virtuelle. Men det ville gått altfor sakte. Man kan ikke ha kode som gjør det. Fordi disse operasjonene foregår hele tiden. Så dette må skje i brøkdelen av et sekund. Vi trenger hjelp fra hardware. Vi trenger en egen enhet, MMU, Memory Management Unit. Og dette er skissert et bilde av MMU-en. Vi så på den simulerte CPU-en at vi har en databuss, og det er da linjer med bits som går fra CPU-en og ut i ram. Den adressebiten, den oversettes av MMU.", "source": "lecture"}
{"lecture_id": "os13del14", "chunk_id": "os13del14_0001", "start": 60.0, "end": 155.0, "token_count": 299, "text": "Vi trenger hjelp fra hardware. Vi trenger en egen enhet, MMU, Memory Management Unit. Og dette er skissert et bilde av MMU-en. Vi så på den simulerte CPU-en at vi har en databuss, og det er da linjer med bits som går fra CPU-en og ut i ram. Den adressebiten, den oversettes av MMU. CPU-en sender ut en logisk adresse, så oversetter MMU-en til fysisk adresse. Så kobles den på databussen. Det er da linjer som går herfra og inn hit. Så trykker de linjene på... La oss si jeg har sendt meg adresse... MMU oversetter... La oss si logisk adresse 8 til fysisk adresse 1008. Så går 1008 ut hit. Så kobler man på RAM 1008 med bits... bang, bang, bang... inn her. Og dermed leses det som ligger i byte nummer 1008, og så sendes det tilbake til Zepperun. Og det skjer hver eneste gang man henter noe i RAM. Ja... Vi skal se på et lite eksempel, litt sånn fiktivt eksempel med program 1 og program 2. Som skal kjøres, for å se hvordan det kan se ut i praksis.", "source": "lecture"}
{"lecture_id": "os13del14", "chunk_id": "os13del14_0002", "start": 133.4, "end": 219.98, "token_count": 292, "text": "Og det skjer hver eneste gang man henter noe i RAM. Ja... Vi skal se på et lite eksempel, litt sånn fiktivt eksempel med program 1 og program 2. Som skal kjøres, for å se hvordan det kan se ut i praksis. Og etter at man har kompilert programmene, så er adressene logiske. Og da må man ha en MMU, eller en eller annen slags MMU-tabell, som oversetter de logiske, eller virtuelle, adressene til det fysiske. Da kan det f.eks. se sånn ut. Program 1, vi har kompilert det. Da står det i program 1, f.eks. på linje 24, så står det \"-low 32\". Det betyr å laste inn i CPU-en det som ligger på linje 32 i ram. Som i dette tilfellet er tallet 671. Så har vi noe tilsvarende i program 2. På linje 28 i program 2 så står det kanskje \"-low 36\". Det betyr å laste inn denne 712, som ligger på linje 36 i ram. Når disse skal kjøres, så legges program 1 og program 2.", "source": "lecture"}
{"lecture_id": "os13del14", "chunk_id": "os13del14_0003", "start": 195.88, "end": 280.16, "token_count": 280, "text": "Så har vi noe tilsvarende i program 2. På linje 28 i program 2 så står det kanskje \"-low 36\". Det betyr å laste inn denne 712, som ligger på linje 36 i ram. Når disse skal kjøres, så legges program 1 og program 2. De loads inn i ramm. Og her har de fått en plassering. Men da ser vi at ingen av disse virtuelle adressene vil være de riktig fysiske. F.eks. program 1 har tilfeldigvis havnet der på 100. Program 2 har havnet på 150. Når Program 1 sier \".load 32\", så mener det egentlig load 132. Og det er da 132 må sendes ut på minibussen, sånn at programmet får denne verdien. Men husk at load 32, når den skal kjøres, først må det lasses inn i CPU-en. Så utføres load 32. Og da vil CPU-en, ved hjelp av MMM-en, oversette 32 til... Og så sendes det tilbake hit. Så da kunne man jo tenke seg at man hadde en tabell som ordner dette her.", "source": "lecture"}
{"lecture_id": "os13del14", "chunk_id": "os13del14_0004", "start": 256.0, "end": 339.08, "token_count": 296, "text": "Men husk at load 32, når den skal kjøres, først må det lasses inn i CPU-en. Så utføres load 32. Og da vil CPU-en, ved hjelp av MMM-en, oversette 32 til... Og så sendes det tilbake hit. Så da kunne man jo tenke seg at man hadde en tabell som ordner dette her. Jeg ser spørsmål i chatten. Logiske adresser og er de samme som virtuelle? Ja, jeg bruker det litt om hverandre. Logiske eller virtuelle adresser. Hovedpoenget er at de må oversettes til fysiske adresser. Sånn så tabellen ut som dette her. For program 1 så kunne vi si OK, adresse 24, den mappes over til 124. For program 2, adresse 28, mappes over til 178. Men det er klart, da hadde vi jo plutselig en tabell som var like stor som hele ramm. Så dette er helt umulig. Og altfor minnekrevende. Men vi kunne i stedet dele opp det logiske minnet i pages. Så kunne vi ha en side med 50 adresser. Og så kan vi si program 1 starter på adresse 100, og program 2 starter på adresse 150.", "source": "lecture"}
{"lecture_id": "os13del14", "chunk_id": "os13del14_0005", "start": 321.6, "end": 356.4, "token_count": 132, "text": "Og altfor minnekrevende. Men vi kunne i stedet dele opp det logiske minnet i pages. Så kunne vi ha en side med 50 adresser. Og så kan vi si program 1 starter på adresse 100, og program 2 starter på adresse 150. Og dermed har vi bare én faktor som må legges til. For da sier vi at program 1 ligger på denne siden, og alle adresser må da bare... Man må legge på 100. Og det er i praksis sånn... Omtrent sånn MMU virker.", "source": "lecture"}
{"lecture_id": "os5del8", "chunk_id": "os5del8_0000", "start": 0.0, "end": 123.8, "token_count": 297, "text": "Jeg har lyst til å si noe, hvis det er greit? Ja, supert. Kom igjen. Jeg har merket fra i fjor, så var det mange som ikke fikk med seg det at når vi retter oppliggene, så hvis det er spørsmål der vi tenker at vi kan forklare litt mer, eller altså vi gir det i kommentarer i den filen, men det var da en del som fikk tilbake svar, og så hadde ikke de da fått med seg at det var sånne kommentarer til det, At folk er klar over det. Du mener at de leser kommentarene og får med seg det? Ja, for vi har skrevet én kommentar som hovedkommentar-tilbakemelding på oppgaven. Men så hadde vi lagt inn enkeltkommentarer på de oppgavene det var aktuelt for. Der var det litt forklaringer eller hint eller tips til hva man kunne se. Ja. Vi var veldig flinke til å gi forklaringer der vi så at hvis det var noen som ikke forsto noe, så var vi veldig detaljerte og ga veldig mye gode tilbakemeldinger for å hjelpe folk. At folk også får utbytte av at vi bruker den tiden.", "source": "lecture"}
{"lecture_id": "os5del8", "chunk_id": "os5del8_0001", "start": 60.02, "end": 152.68, "token_count": 189, "text": "Ja. Vi var veldig flinke til å gi forklaringer der vi så at hvis det var noen som ikke forsto noe, så var vi veldig detaljerte og ga veldig mye gode tilbakemeldinger for å hjelpe folk. At folk også får utbytte av at vi bruker den tiden. Ja, kjempebra. Og det er enda viktigere hvis en gruppe ikke får godkjent. Altså hvis de ikke har svart bra nok til å få godkjent. Så er det opplagt veldig viktig å se på kommentarene og rette opp av de feilene man har gjort. Det er greit å si ifra sånn at folk får det med seg. Det kom kanskje ikke så godt frem i fjor. Nei. Kjempebra du sier det.", "source": "lecture"}
{"lecture_id": "os3bdel8", "chunk_id": "os3bdel8_0000", "start": 0.0, "end": 83.36, "token_count": 293, "text": "Ja, da skal vi til slutt se på høynivåkode. For det til syvende og sist, når du skriver et program, så skriver du ikke maskinkode, men du skriver høynivåkode. Så det vi skal se litt på nå, er hvordan høynivåkode sånn som dette er... En liten forløkke som summerer. Den starter på I liker 1, så den går til... Når vi har en sånn høynivåkode, det vi ønsker at CPU-en skal utføre, det er de følgende tre operasjonene. Først starter vi med i lik 1. Summen er 0 pluss 1 er lik 1 osv. Så øker verdien i til 2. Så legger vi til den summen 3. Så til slutt får vi et tall av 6, som blir summen. I oppgavene senere i dag så skal du prøve å overbevise deg om at denne simuleringsmaskinen utfører nøyaktig dette. Så skal du etter hvert endre den lite grann, sånn at den løkka går til tre. Og da må du faktisk skrive maskinkode. Eller du må endre på maskinkoden", "source": "lecture"}
{"lecture_id": "os3bdel8", "chunk_id": "os3bdel8_0001", "start": 60.0, "end": 161.08, "token_count": 295, "text": "I oppgavene senere i dag så skal du prøve å overbevise deg om at denne simuleringsmaskinen utfører nøyaktig dette. Så skal du etter hvert endre den lite grann, sånn at den løkka går til tre. Og da må du faktisk skrive maskinkode. Eller du må endre på maskinkoden for å få den til å gjøre nøyaktig dette her. Men for å virkelig se hva som skjer, så skal vi utføre dette selv. For å få til det, så trenger man å kjenne til instruksjonene for denne maskinen. Instruksjonssettet til maskinen, det utgjør arkitekturen, f.eks. X86-arkitekturen. Den har et gitt sett med instruksjoner. Det er fastlåst, for det er definert av arkitekturen. Og det brennes fast i kretskortene som utgjør Alu og CPU og alle delene. Da har man bare bestemt, sånn som jeg bestemte for denne maskinen her... F.eks. addisjon. Den skal ha binært nummer 0100. Det er altså da fire. Institusjon nummer fire.", "source": "lecture"}
{"lecture_id": "os3bdel8", "chunk_id": "os3bdel8_0002", "start": 132.0, "end": 208.86, "token_count": 218, "text": "Og det brennes fast i kretskortene som utgjør Alu og CPU og alle delene. Da har man bare bestemt, sånn som jeg bestemte for denne maskinen her... F.eks. addisjon. Den skal ha binært nummer 0100. Det er altså da fire. Institusjon nummer fire. Det skal være en add-institusjon. Og den skal addere operand 1. Og den skal legge til operand 2.  Og det betyr at man da utfører DR erlik DR pluss SR. Og vi ser de fire første bitene der. Det er da de fire første bitene i institusjonen. Det definerer hvilken institusjon vi skal gjøre. De neste fire bitene definerer operand 1 og operand 2. Og det kan variere ut fra hvilken institusjon det er, nøyaktig hva disse... Disse operandene gjør.", "source": "lecture"}
{"lecture_id": "linux12del6", "chunk_id": "linux12del6_0000", "start": 0.0, "end": 120.54, "token_count": 284, "text": "I dette skriptet så tenkte jeg å prøve å drepe prosesser med et visst navn. La oss si jeg starter opp en notepad... Som står og kjører. Og så vil jeg nå ønske å lage et skript som dreper prosesser med navnet notepad. Da kan jeg gjøre det så jeg kan starte på samme måte. Kan lage en forage. Tanken er nå å gå gjennom alle prosesser. Forage p inn... Da må jeg liste alle prosesser. Og det gjør jeg med ps. Forage p inn ps.  Så hva ønsker jeg å gjøre nå? Jo, jeg ønsker å... Drepe prosessen hvis den heter nopad. Så da starter jeg med if... prosessen sitt navn. Hvis det er lik... Så må jeg bruke anførselstegn. Not-Pat. Hvis navnet er Not-Pat, da skal jeg drepe prosessoren. Så får jeg en ny løkke... Nei, så... Ny blokk. Og så skriver jeg her... Og det jeg skal drepe, er da... Ja, da kan man... Hvordan er IDNA egentlig? Vi kan da prøve å se...", "source": "lecture"}
{"lecture_id": "linux12del6", "chunk_id": "linux12del6_0001", "start": 83.76, "end": 190.56, "token_count": 284, "text": "Not-Pat. Hvis navnet er Not-Pat, da skal jeg drepe prosessoren. Så får jeg en ny løkke... Nei, så... Ny blokk. Og så skriver jeg her... Og det jeg skal drepe, er da... Ja, da kan man... Hvordan er IDNA egentlig? Vi kan da prøve å se... Og prøve å tabbe, men det fungerer ikke her. Her i skriptet så vet du ikke editoren at dollar er en PS. Så det man ofte gjør da, er å gå ut i skjellet og utføre PS. Og da kan du få en idé her, og så se... Jo, herregud... Det er nok ID som er den riktige måten å få tak i ID-en på. Mer generelt så kan man sende over din APS til getmember eller GM. Og så får man opp en liste over alle properties og metoder. Hvis man blar gjennom den lange listen her, så vil du se at her står det ID. Så da bruker jeg.id. Kill prosessen sin id. Så er det en fin opsjon på kill som er what if. Da kan man teste ut før man kjører skriptet,", "source": "lecture"}
{"lecture_id": "linux12del6", "chunk_id": "linux12del6_0002", "start": 160.36, "end": 267.02, "token_count": 285, "text": "Og så får man opp en liste over alle properties og metoder. Hvis man blar gjennom den lange listen her, så vil du se at her står det ID. Så da bruker jeg.id. Kill prosessen sin id. Så er det en fin opsjon på kill som er what if. Da kan man teste ut før man kjører skriptet, i tilfelle det er noen sensitive prosesser som man ønsker å ikke drepe noen andre, kanskje. Så kan man teste ut skriptet med what if. Sånn. Da skal jeg skrive skriftlig, i hvert fall prøve å drepe Noped. Da taster jeg FM. Da ser vi her nede. What if performing the operation stop process on target Noped? 29.60. Da ser vi... Jo, det ser ut til å fungere bra. Nå har vi... Der har vi en oppad-oppekjører. Hvis jeg nå tar bort Notif, så burde den dreves. Så tar jeg fem, og da ser vi... Da forsvant... Kunne skimte at den forsvant bak hjørnet der. Men i hvert fall... Dette er da et skript som... dreper prosesser med et gitnad.", "source": "lecture"}
{"lecture_id": "linux12del6", "chunk_id": "linux12del6_0003", "start": 239.72, "end": 353.18, "token_count": 283, "text": "Hvis jeg nå tar bort Notif, så burde den dreves. Så tar jeg fem, og da ser vi... Da forsvant... Kunne skimte at den forsvant bak hjørnet der. Men i hvert fall... Dette er da et skript som... dreper prosesser med et gitnad. Så kan man utvikle det til å plukke opp andre egenskaper. En ting vi kunne prøve å få til, var å lage et skript som tar imot et argument.  Og generelt så... så tas argumenter ut i et r-ei som heter arcs. Så jeg kunne prøve å skrive bak her istedenfor notads, så kunne jeg skrive arcs av null. Arcs av null er det første argumentet som de sender med kommando. Da kan jeg ikke bare skrive... Da kan jeg ikke bare skrive F5, for da sender jeg ikke med en argument. Jeg kan prøve. Men da skjer det ikke så veldig mye. Men hvis jeg starter på ny Nalpad... Og så prøver... Kanskje bedre å bruke Votif her, siden jeg tester ut. Sånn. Så kan jeg prøve å kjøre KIL2.", "source": "lecture"}
{"lecture_id": "linux12del6", "chunk_id": "linux12del6_0004", "start": 321.94, "end": 450.3, "token_count": 280, "text": "Jeg kan prøve. Men da skjer det ikke så veldig mye. Men hvis jeg starter på ny Nalpad... Og så prøver... Kanskje bedre å bruke Votif her, siden jeg tester ut. Sånn. Så kan jeg prøve å kjøre KIL2. KIL2.0, tenker jeg. Jeg ser det skjer ingenting. Men det er også fordi jeg ikke sender noe argument. Så hvis jeg prøver å skrive noe oppå den her, så skjer det heller ingenting. Jo, jeg tror jeg vet hva det kommer av. Vi kan teste litt. Jeg tror det skyldes at vi først her må ta en... Legge det argumentet i et ra. Nei, i en arabel. Sånn. Og så kan jeg teste ut... Om navnet er lik det argumentet. Der gjør vi et nytt forsøk. Ja. Da sa vi at vi fikk det til å virke. Det er noe sånt generelt, et problem med r-race i PowerShell. Hvis man skal skrive ut verdien av r-race f.eks., så fungerer det ikke å skrive det ut i en streng sånn som dette her.", "source": "lecture"}
{"lecture_id": "linux12del6", "chunk_id": "linux12del6_0005", "start": 421.88, "end": 571.94, "token_count": 292, "text": "Ja. Da sa vi at vi fikk det til å virke. Det er noe sånt generelt, et problem med r-race i PowerShell. Hvis man skal skrive ut verdien av r-race f.eks., så fungerer det ikke å skrive det ut i en streng sånn som dette her. Da må man først tilordne det til en vanlig variabel, og så skrive det ut. Fikk du den nisten under? Fikk svaret. Ja. OK. Fint. Ja... Vi må altså tilordne argumentet til en vanlig variabel. Og det er ikke noe spesielt med argumenter, men det gjelder generelt. Så kan det hjelpe å sette det lik... Tilordne verdien til en enkel variable. Da fungerer det sånn som det må gjøre. Man kunne også tenke seg at man vil løpe gjennom en rekke argumenter. Da prøver jeg å løpe gjennom hvert navn i rekken av argumenter. Fungerer uten å legge på ekstra parenteser. Altså om det fungerer med sjansene her. Hvis de sier vi rakker å kjøre. Nei, det fungerer ikke. Så man må ha på de parentesene.", "source": "lecture"}
{"lecture_id": "linux12del6", "chunk_id": "linux12del6_0006", "start": 523.18, "end": 665.36, "token_count": 290, "text": "Da prøver jeg å løpe gjennom hvert navn i rekken av argumenter. Fungerer uten å legge på ekstra parenteser. Altså om det fungerer med sjansene her. Hvis de sier vi rakker å kjøre. Nei, det fungerer ikke. Så man må ha på de parentesene. Så da gjør vi det. Én startparentes her. Og én sluttparentes her. Hvis jeg prøver og kjører det nå, så ser vi at det fungerer. Da kunne vi også ha med f.eks. Idol. Ja... Det er ikke så rart, for her inne så står det jo 'Dollar S'. Så... da løper den over... det første elementet to ganger. Så hva må jeg endre på da? Jo, her inne så skal det jo stå navn.  Vi har nå en indre løkke, og vi løper gjennom... Navnet er kanskje dårlig... For A, kan vi si. For h-a. Hvert argument i arks. Hvis navnet er lik A, så dreper man. Så da prøver jeg å kjøre igjen. Og da ser vi at løkken gjør som vi ønsker.", "source": "lecture"}
{"lecture_id": "linux12del6", "chunk_id": "linux12del6_0007", "start": 644.24, "end": 728.84, "token_count": 289, "text": "Vi har nå en indre løkke, og vi løper gjennom... Navnet er kanskje dårlig... For A, kan vi si. For h-a. Hvert argument i arks. Hvis navnet er lik A, så dreper man. Så da prøver jeg å kjøre igjen. Og da ser vi at løkken gjør som vi ønsker. Den går da systematisk gjennom argumentene sine. Og prøver å drepe Idol og prøver å drepe Nopap. Hvis man virkelig prøver å drepe Idol, så vil du ikke få lov til det. For det er liksom den grunnleggende funksjonen. Vi kan se hva som skjer da. Ja, da får man en melding om access denied. Men i utgangspunktet så ser man... Vi kan ta imot argumenter, og vi kan løpe gjennom argumenter i en løkke, og vi kan løpe gjennom prosesser i en løkke. Og igjen, det fine med PowerShell er at output fra command-let, sånn som PS, det er prosesser. Nei, det er objekter. Så det er ikke bare teksten sånn som det er i Lille X, men det er objekter.", "source": "lecture"}
{"lecture_id": "linux12del6", "chunk_id": "linux12del6_0008", "start": 705.32, "end": 739.02, "token_count": 105, "text": "og vi kan løpe gjennom prosesser i en løkke. Og igjen, det fine med PowerShell er at output fra command-let, sånn som PS, det er prosesser. Nei, det er objekter. Så det er ikke bare teksten sånn som det er i Lille X, men det er objekter. Plukke ut egenskaper ved å bekte. Og det er veldig mye mer rett frem enn på linens.", "source": "lecture"}
{"lecture_id": "os1del4", "chunk_id": "os1del4_0000", "start": 0.0, "end": 47.88, "token_count": 159, "text": "Øvingstimer... Jo, det er det viktig å ta med. Dette er da Ine som dere har hilst på. Og så er det Rune Bakken som kommer på lab etter forelesning i dag. Og de kan dere også nå på e-pos her. Så hvis det er noen spørsmål spesielt relatert til øvingsoppgavene, så kan dere gå inn og spørre dem direkte også. Foreløpig blir det også øvinger på Zoom. Etter hvert håper vi å komme inn i pH451 på den datalaben. Men ja, det ser jo ikke sånn veldig bra ut foreløpig. Så vi får se hvordan...", "source": "lecture"}
{"lecture_id": "linux10del5", "chunk_id": "linux10del5_0000", "start": 0.0, "end": 105.78, "token_count": 285, "text": "Ja, som dere ser... Så er det mange som har svart mange ting her. Skytjenesterefleksibilitet er det få som har svart, for det er ganske... Oi, du ser ikke svarene! Det var rart. Oi, nei. Det var ikke så rart. Sånn. Nå ser du svarene, ikke sant? Der, ja. OK, da starter vi på nytt. Jo, som dere ser, svarene er ganske mye fordelt utover. Men fleksibilitet og skytjenester er kanskje de to mest sentrale tingene som er en fordel ved virtualisering. Det er det ikke så mange av dere som har svart. Vi kan si med en gang at det som de fleste... Nettopp det kan være et problem med virtualisering. Det er lett å tenke seg, for man skal jo emulere en virtuell maskin. Man har et element av emulering, så det må foregå noe ekstra arbeid for at man skal kunne kjøre et program. Etter mange år med virtualisering så har det vist seg at man har klart å gjøre det ganske effektivt, men generelt vil du alltid ha litt reduksjon på effektiviteten.", "source": "lecture"}
{"lecture_id": "linux10del5", "chunk_id": "linux10del5_0001", "start": 76.72, "end": 158.56, "token_count": 296, "text": "Man har et element av emulering, så det må foregå noe ekstra arbeid for at man skal kunne kjøre et program. Etter mange år med virtualisering så har det vist seg at man har klart å gjøre det ganske effektivt, men generelt vil du alltid ha litt reduksjon på effektiviteten. Derimot er det mange som sier ressurssparing, og det kan jo være naturlig å tenke det. Altså at du bruker mer ressurser, men ressurssparing kan du få til ved at... Når du kjører virtuelle maskiner, så kan du fordele mange virtuelle maskiner på én VM. Nei... Du kan fordele mange virtuelle maskiner på én fysisk maskin, og dermed spare ressurser ved at du utnytter ressursene til den ene fysiske maskinen. I stedet for å ha kanskje ti fysiske maskiner som straks er veldig mye mer ressurskrevende, så kjører man ti VM-er inne på den samme fysiske maskinen, og deler bedre på ressursene. Isolasjon... På en måte er det naturlig å tenke, så er ikke det så godt svar", "source": "lecture"}
{"lecture_id": "linux10del5", "chunk_id": "linux10del5_0002", "start": 139.28, "end": 175.92, "token_count": 162, "text": "I stedet for å ha kanskje ti fysiske maskiner som straks er veldig mye mer ressurskrevende, så kjører man ti VM-er inne på den samme fysiske maskinen, og deler bedre på ressursene. Isolasjon... På en måte er det naturlig å tenke, så er ikke det så godt svar hvis man tenker sånn at hvis du fysisk har en maskin, så isolerer du den fullstendig fra de andre. Men isolasjon i forbindelse med virtualisering, så tenker man at da er det veldig lett å isolere én enkelt tjeneste på en virtuell maskin.", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0000", "start": 0.0, "end": 111.16, "token_count": 299, "text": "Maskinkode. Så... Og det aller første jeg tenkte å se på, var optimalisering av maskinkode. Og da skal jeg gå til et eksempel på det. Skal vi se... Her har jeg laget en liten... Her har jeg laget en liten rutine. Denne som... Ja, det er ikke så viktig hva eksempelet er, men dette er da eksempel på kode som... Som går i en loop, og som logisk bygger på hverandre. Så den... Vi skal se senere. Denne koden kan ikke utføres i parallell. Men det viktigste nå er å se på hvordan kode utføres effektivt i en CPU. Det vi skal ha fokus på, er at vi har sett... I simuleringen forrige gang så vi at noen instruksjoner utføres bare på registrene. Og da står man inne i CPU-en, hvor man har registeret tilgjengelig. R0 ellik R0 pluss R1, som vi gjorde i simuleringen. Det er en operasjon som utføres kun på registeret. Men så så vi at vi også kan legge verdier ut i ramm. Og det er det man typisk gjør når man har en variabel, sånn som int A lik 1.", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0001", "start": 86.36, "end": 182.96, "token_count": 286, "text": "R0 ellik R0 pluss R1, som vi gjorde i simuleringen. Det er en operasjon som utføres kun på registeret. Men så så vi at vi også kan legge verdier ut i ramm. Og det er det man typisk gjør når man har en variabel, sånn som int A lik 1. Når vi kjører programmer som dette, så er det typiske som skjer da... En variabel har en egenplass i ram. En integer er på fire bite, så da settes det av fire bite i ram til integeren. Eller, fire bite er 32 bit, så det settes av i ram. Ram deler seg inn i bites, åtte bit av gangen, så det er den minste enheten i ram. Men da tar det mye lengre tid å lagre ting i ram. Så ca. ti ganger så lang tid tar det å lagre et tall i ram enn å lagre det i registeret. Så derfor lønner det seg stort sett å gjøre så mye som mulig med registeret, og så laste ut resultatene etterpå til ram. Så det vi skal se på nå, er hvordan... En kompilator lager maskinkode av denne koden her.", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0002", "start": 159.28, "end": 260.1, "token_count": 284, "text": "enn å lagre det i registeret. Så derfor lønner det seg stort sett å gjøre så mye som mulig med registeret, og så laste ut resultatene etterpå til ram. Så det vi skal se på nå, er hvordan... En kompilator lager maskinkode av denne koden her. Og da kan vi aller først så kan vi se på hvordan... Hvordan denne koden kjøres. Så... Da har jeg en... En kode som heter main sånn, som jeg skal kompilere. Og linke sammen med den fibokoden. Så her ser vi at vi definerer en ekstern int-fibo. Det er den assembly-metoden som... som jeg skal bruke. Eller nei - ikke assembly-metode. Dette er den C-metoden som jeg skal bruke. C-funksjonen som vi så på. Nemlig fibo.c. Vi ser den må hete det samme. Det som er litt forskjellig fra forrige gang, er at nå sender vi med en parameter til Fibo. Så vi kaller den Fibo med Last. Så ser vi i Main her, så setter jeg inn Last Alec 10. Og så kjører jeg metoden Fibo på Last.", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0003", "start": 232.0, "end": 334.64, "token_count": 282, "text": "Vi ser den må hete det samme. Det som er litt forskjellig fra forrige gang, er at nå sender vi med en parameter til Fibo. Så vi kaller den Fibo med Last. Så ser vi i Main her, så setter jeg inn Last Alec 10. Og så kjører jeg metoden Fibo på Last. Så Fibo er 10. Den skal gi da Fibonacci-tall nummer 10 i rekken. Vi kan først se hvordan det ser ut når jeg kompilerer de to og kjører. De kan jeg kompilere rett sammen på samme linje. Sånn. Da får jeg ett program adatat. En kjørbar fil. Og så ser vi... Her kommer resultatet 55 ut. Så den funker som den skal. Men det vi skal se på nå, er... Hvordan ser egentlig den maskinkoden ut som det kompileres til, når man kompilerer den høynivåkoden Fibo? Og da kan vi som sist spørre... ... GCC, hvordan ser assembly-koden du lager, ut? Og det gjør man med minus S. Når jeg kjører den, så... Skal vi se... Er det stor S, kanskje?", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0004", "start": 308.32, "end": 416.32, "token_count": 293, "text": "når man kompilerer den høynivåkoden Fibo? Og da kan vi som sist spørre... ... GCC, hvordan ser assembly-koden du lager, ut? Og det gjør man med minus S. Når jeg kjører den, så... Skal vi se... Er det stor S, kanskje? Ja. Man gjør det ikke med minst liten S, men med stor S. Med stor S så ber jeg GCC om å lage assemblerkode. Og da ser vi. Da har jeg fått en fil her som heter fibo.s. Det er den vi skal se på nå. Oi. Og den ser vi, den er ganske stor. Det ser jo litt gresk ut, det som skjer her. Jeg skal ikke gå inn på dette i detalj, men vi ser... Den linjen her oppe er viktig. Den definerer da den rutinen Fibo. Men det eneste vi skal se på... som vi må få med oss... Det er at her brukes hele tiden ram. For det vi har sett tidligere, det er at... En sånn konstruksjon som dette her, det er en peker til en integri-ram. Det som er inne i parentesen, det er et register. Så adressen i ram ligger i dette registeret.", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0005", "start": 391.72, "end": 487.54, "token_count": 287, "text": "For det vi har sett tidligere, det er at... En sånn konstruksjon som dette her, det er en peker til en integri-ram. Det som er inne i parentesen, det er et register. Så adressen i ram ligger i dette registeret. Og minus 12 er en sånn relativ adresse som sier at... Akkurat den integeren som vi skal hente ut, ligger minus 12 bite unna starten på det området. Så det eneste vi trenger å huske, er at dette er en variabel. Og dette er en variabel. Så det vi kan konkludere med, er at alle de operasjonene som utføres her... Sånn som den her, for eksempel. Den utføres på integer, som ligger i ram. Så hvis jeg tar adel, denne her... Den sier legg tallet én til denne variabelen som ligger i ram. Og denne variabelen her er typisk den tellevariabelen i løkken. For den ser vi øker med én hver gang i runden. Så det vi kan konkludere med her, er at når GCC lager kode her, så skriver den inn og ut av Ram hele tiden.", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0006", "start": 460.8, "end": 564.52, "token_count": 288, "text": "Den sier legg tallet én til denne variabelen som ligger i ram. Og denne variabelen her er typisk den tellevariabelen i løkken. For den ser vi øker med én hver gang i runden. Så det vi kan konkludere med her, er at når GCC lager kode her, så skriver den inn og ut av Ram hele tiden. Vi kan også legge merke til at i alle ad-operasjoner så er det ett register og ett element fra Ram. Så når jeg tar eax og legger til den verdien som ligger der ute i Ram... I prinsippet kunne man tenke seg at man... Hvis jeg går ut til koden igjen... I prinsippet kunne man tenke seg at man utførte en operasjon som dette her direkte i RAM. Altså man tok en referanse fra RAM og la den til. Spørsmå. Hva betyr prosent-eax? AIX er et register. Alle sånne referanser er til registeret. AIX er et Extended AX-register. Dette er et 32-bitsregister. Det vi brukte forrige gang, var 64-bitsregisteret da vi skrev kode. Da heter de... Registrene starter opp på R.", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0007", "start": 536.36, "end": 631.92, "token_count": 289, "text": "AIX er et register. Alle sånne referanser er til registeret. AIX er et Extended AX-register. Dette er et 32-bitsregister. Det vi brukte forrige gang, var 64-bitsregisteret da vi skrev kode. Da heter de... Registrene starter opp på R. Mens GCC kompilerer her, så lager den 32-bitskode. Det kan man endre ved kompileringen, og man kan forlange å få 64-bitskode. Men det viktige er at %dax, det er et register. Kjempebra dere spør. Bare stopp og spør mer. Så... Det vi så nå, var at... Når vi kompilerer denne koden her, så lager kompilatoren kode som går ut i minnet, og lagrer hele ting i minnet. Og det er litt merkelig. Og det jeg begynte å si, var at A lik A pluss B... Man kunne tenke seg at man gjorde en sånn operasjon med minnet også. At man tok det som ligger i A, legger til B... På en eller annen måte så må det jo hentes inn i registrene før man legger sammen, men det er det hardwaren som gjør.", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0008", "start": 609.16, "end": 691.14, "token_count": 296, "text": "Og det er litt merkelig. Og det jeg begynte å si, var at A lik A pluss B... Man kunne tenke seg at man gjorde en sånn operasjon med minnet også. At man tok det som ligger i A, legger til B... På en eller annen måte så må det jo hentes inn i registrene før man legger sammen, men det er det hardwaren som gjør. Men så er det sånn at i Exo86 Hardware så er det ikke lov eller deilig. Det er ikke definert operasjoner som bruker to minneadresser samtidig. Så i Exo86 så kan du f.eks. legge til et tall til en variabel direkte med en instruksjon. Du kan... Ta et register og legge til i en variabel. Direkte ram. Det er det lagd instruksjoner for, men det er ikke lagd instruksjoner som gjør dette. Det skal vi se på etterpå. Det vil bety at en sånn linse som dette her kan aldri oversettes av én linje maskinkode. Ok. Men det er jo litt merkelig at GCC lager kode som ikke bruker register. Det er jo det mest effektive. Da er det viktig å vite at GCC default lager den maskinkoden", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0009", "start": 663.36, "end": 741.82, "token_count": 281, "text": "Det skal vi se på etterpå. Det vil bety at en sånn linse som dette her kan aldri oversettes av én linje maskinkode. Ok. Men det er jo litt merkelig at GCC lager kode som ikke bruker register. Det er jo det mest effektive. Da er det viktig å vite at GCC default lager den maskinkoden som det er raskest mulig å kompilere. Så hvis du har et stort program og driver og utvikler, så ønsker du at den skal kompileres så fort som mulig. Og det er det som er default i GCC. Men hvis du ønsker at GCC skal lage et mest mulig effektivt program, et som kjører fortest mulig, så må du si ifra om det. Da kan det ta lengre tid å kompilere, men da optimaliserer GCC for å kjøre fort. Den opsjonen man bruker for å få til det, det er minus O. Så da kan jeg prøve å gjøre det med... Hvis vi gjør det med maine, altså sånn gjør vi det, så merker vi ikke så veldig forskjell, for det går ekstremt fort å gjøre dette her.", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0010", "start": 720.4, "end": 816.88, "token_count": 296, "text": "Den opsjonen man bruker for å få til det, det er minus O. Så da kan jeg prøve å gjøre det med... Hvis vi gjør det med maine, altså sånn gjør vi det, så merker vi ikke så veldig forskjell, for det går ekstremt fort å gjøre dette her. Det går kanskje enda fortere også akkurat de operasjonene inne i CPU-en. Det går veldig fort, men hovedpoenget her er... Kan vi se på koden, hvordan den endrer seg? Hvordan GCC endrer på koden for å få den til å gå raskere? Da kan vi gjøre det samme. Da kan vi be om stor minus S. Da ber vi om GCC. om å lage maskinkode, eller assemble kode, som ser ut som den maskinkoden den virkelig lager. Og så kan vi se på hvordan den ser ut nå. Og da ser vi at... Jo, her er det plutselig annerledes. Ett sted er det en referanse til TeRam, men stort sett foregår alle operasjonene da. Inne i CPU-en med registeret. Her f.eks. legges tallet tre i et register. Og det er det tallet som man sammenligner med.", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0011", "start": 788.52, "end": 883.86, "token_count": 293, "text": "Og da ser vi at... Jo, her er det plutselig annerledes. Ett sted er det en referanse til TeRam, men stort sett foregår alle operasjonene da. Inne i CPU-en med registeret. Her f.eks. legges tallet tre i et register. Og det er det tallet som man sammenligner med. Så det er den som får løkka til å gå. Men hovedpoenget her er at alt man... Alt som gjøres, det gjøres inni CPU uten at man refererer til ram. Eller ute i Maine, så kan man lagre resultateram. Eller hvis resultatet bare skal skrives ut, så trenger det ikke å lagres i ramme i det hele tatt. Det mest effektive er å kjøre det da inni CPUN. Men så er det begrenset lagreskapasitet i CPUN. Hvis du har et program som har en million... Et RA som har en million... Da kan du ikke ha alle variablene i registeret. Da må tallene lastes inn og ut av rammen hele tiden. Derfor vil litt større programmer alltid laste inn og ut av rammen. Men utgangspunktet er det raskeste å kjøre programmer inne i CPU-en.", "source": "lecture"}
{"lecture_id": "os5del3", "chunk_id": "os5del3_0012", "start": 863.98, "end": 885.7, "token_count": 75, "text": "Da kan du ikke ha alle variablene i registeret. Da må tallene lastes inn og ut av rammen hele tiden. Derfor vil litt større programmer alltid laste inn og ut av rammen. Men utgangspunktet er det raskeste å kjøre programmer inne i CPU-en. Bare bruke pokalregister.", "source": "lecture"}
{"lecture_id": "linux8del11", "chunk_id": "linux8del11_0000", "start": 0.0, "end": 112.44, "token_count": 298, "text": "Ja, der er oppfølgingsspørsmålene fra som jeg ikke så. Hvis man har flere image i en container, så bruker man bare én dokkefil. Ja, det er riktig at man har flere image i en container, men en container bygges opp av flere image, som på en måte er lagdelt. Men hvis man tenker på det grunnleggende imaget, Man har bare ett image. Det er da i dokkefilen. Øverst i dokkefilen står det 'from Ubuntu'. Det betyr hent et Ubuntu-image. Men så... Ja. Og det du henter da, er egentlig alt som skal til for å gjøre det underliggende Linux-operativsystemet til en Ubuntu 1804. Her så er det jo ikke... Vi kan se... VM-en her... Det er jo en... Det er jo Debbian. Debbian versjon 10.3. Så når jeg kjører From Ubuntu... Det imaget inneholder alt som skal til for at dette Debian-operativstemmet ser nøyaktig ut som Ubuntu 1804. Når jeg installerer Apache 2, kommer det et nytt lag på det imaget. Og det laget inneholder installasjonen av Apache 2. Alt som gjør det ubundne imaget forskjellig fra det.", "source": "lecture"}
{"lecture_id": "linux8del11", "chunk_id": "linux8del11_0001", "start": 97.5, "end": 123.98, "token_count": 97, "text": "ser nøyaktig ut som Ubuntu 1804. Når jeg installerer Apache 2, kommer det et nytt lag på det imaget. Og det laget inneholder installasjonen av Apache 2. Alt som gjør det ubundne imaget forskjellig fra det. På den måten er det en lagdeling som gjør at man til slutt får et image som inneholder alt. Det er det man trenger.", "source": "lecture"}
{"lecture_id": "os11del5", "chunk_id": "os11del5_0000", "start": 0.0, "end": 94.4, "token_count": 293, "text": "Blokkerende systemcall. Dette er opprinnelig den viktigste grunnen til at vi har tråder i det hele tatt. Blokkerende systemcall er systemcall som da blokkerer prosessen fordi den venter på en input-output-forespørsel. Det kan f.eks. være at man ønsker å lese noe fra en disk. Da er det jo naturlig at programmet ikke går videre før den har lest det som den har på disken. Og i alle denne type systemkall hvor man må vente på resultatet før programmet kan gå videre, det er da representert ved et blokkerende systemkall. For da gjør man et systemkall, og så blokkerer det prosessen, sånn at den ikke får kjøre videre. Det kan være veldig uheldig. For du ønsker gjerne at en applikasjon skal være responsiv, selv om den leser noe fra disk eller gjør noe annet som krever IO. Og derfor så... Det var på en måte en av hovedideene for å få inn tråder. Nemlig at programmereren ved hjelp av tråder kan styre de forskjellige arbeidsoppgavene. Det henger da ikke i å vente på blokkerende systemcall.", "source": "lecture"}
{"lecture_id": "os11del5", "chunk_id": "os11del5_0001", "start": 67.92, "end": 161.68, "token_count": 293, "text": "selv om den leser noe fra disk eller gjør noe annet som krever IO. Og derfor så... Det var på en måte en av hovedideene for å få inn tråder. Nemlig at programmereren ved hjelp av tråder kan styre de forskjellige arbeidsoppgavene. Det henger da ikke i å vente på blokkerende systemcall. Noen eksempler på den type systemcall er sånn som read and write, await, opplagt hvor du venter på andre toaletter, og sleep, altså opplagt blokkerende, for der venter du eksplisitt. Det mest typiske er sånn som read, hvor du leser noe fra disk, og da må du vente på å få resultatet. Så fins en del ikke-blokkerende systemkall også, eller veldig mange, sånn som GetPayDay og GetTimeOfDay f.eks. De eksekverer ferdig veldig raskt, og de blokkerer da ikke prosessen. Trådmodeller. Det finnes mange implementasjoner av tråder, og dette er det. De er de tre vanligste og mest brukte trådmodellene. Den som er aller vanligst med en gang, det er 1-1.", "source": "lecture"}
{"lecture_id": "os11del5", "chunk_id": "os11del5_0002", "start": 130.64, "end": 229.08, "token_count": 286, "text": "De eksekverer ferdig veldig raskt, og de blokkerer da ikke prosessen. Trådmodeller. Det finnes mange implementasjoner av tråder, og dette er det. De er de tre vanligste og mest brukte trådmodellene. Den som er aller vanligst med en gang, det er 1-1. Det er denne modellen her hvor for hver tråd brukeren starter... F.eks. vi starter et Java-program. JVM starter 20 tråder. Da vil det tilsvarende være 20 kjernetråder. Det betyr i praksis at du... Du har 20 tråder som skreduleres som 20 uavhengige regneoperasjoner. I tillegg har vi én til mange. Vi kan se litt på neste slide hvor disse blir beskrevet. Én til mange, det betyr at alle trådene skreduleres som én prosess. Tidligere fantes en del sånne implementasjoner. Det kalles ofte green threats. Den aller første implementasjonen på Linux av JVM var av green threats. Men det er jo litt upraktisk, for det som skjer da, er at programmeren selv må skedulere.", "source": "lecture"}
{"lecture_id": "os11del5", "chunk_id": "os11del5_0003", "start": 210.0, "end": 291.58, "token_count": 286, "text": "Tidligere fantes en del sånne implementasjoner. Det kalles ofte green threats. Den aller første implementasjonen på Linux av JVM var av green threats. Men det er jo litt upraktisk, for det som skjer da, er at programmeren selv må skedulere. Vi har f.eks. en metode som kalles Yield, som sier... Ok, nå vil jeg gi fra meg CPU-en. Og Yield er en sånn... Når man overlater til operativsystemet å skredulere. Men dette er da den trådmodellen. Så har vi 1-1, som er det mest vanlige, hvor alle tråder skreduleres uavhengig av hverandre av operativsystemet. Det er det som vi har i Java, og etter pausen skal vi se på Post-Ex-Treats eller P-Treats. De skreduleres også på den måten. En tredje måte er mange-til-mange. Og da skal du lese som én-til-én hvis det ikke er altfor mange tråder. Men så har det vært en del operativsystemer som har implementert mange-til-mange for tilfeller hvor det er ekstremt mange tråder.", "source": "lecture"}
{"lecture_id": "os11del5", "chunk_id": "os11del5_0004", "start": 270.0, "end": 327.88, "token_count": 167, "text": "En tredje måte er mange-til-mange. Og da skal du lese som én-til-én hvis det ikke er altfor mange tråder. Men så har det vært en del operativsystemer som har implementert mange-til-mange for tilfeller hvor det er ekstremt mange tråder. Altså mange hundre eller mange tusen tråder. Skreduleres hver for seg. Så lager man grupper, sånn at én kjernetråd tar hånd om et sett av tråder. Så kan det være 50 tråder som skreduleres av denne, og 50 av denne tråden. Da får de en intern skredulering seg imellom.", "source": "lecture"}
{"lecture_id": "linux3del6", "chunk_id": "linux3del6_0000", "start": 0.0, "end": 102.72, "token_count": 296, "text": "Omdirigering er et viktig tema. Det står til og med i notatene at dette er viktig. Så dette er det veldig nyttig å få med seg. Veldig mye av det som man jobber med i Linux, er å dirigere datastrømmer til og fra filer og også til og fra kommandoer. Og akkurat dette gjør at man kan sette sammen mange små kommandoer. Løse oppgaver effektivt og ikke minst fleksibelt. Masse kombinasjonsmuligheter. Det som er utgangspunktet, er at alle Linux-programmer og kommandoer har tre åpne kanaler. Null, én og to. Den første er StandardInn. SDDin. Det er på en måte en input-kanal. Default som kommer fra tastaturet. Så kommer det inn til en Linux-kommando. Jeg illustrerte dette som en kanal som kommer inn i kommandoen. F.eks. hvis vi tar Econotext, altså piper til Cat, så kommer den teksten inn til Linux-kommandoen Cat. Så har man to ut-kanaler. Den ene er standard out, den vanlige output-en. Den går vanligvis til skjermen hvis man ikke omdirigerer den.", "source": "lecture"}
{"lecture_id": "linux3del6", "chunk_id": "linux3del6_0001", "start": 77.92, "end": 186.08, "token_count": 289, "text": "F.eks. hvis vi tar Econotext, altså piper til Cat, så kommer den teksten inn til Linux-kommandoen Cat. Så har man to ut-kanaler. Den ene er standard out, den vanlige output-en. Den går vanligvis til skjermen hvis man ikke omdirigerer den. Så har du kanal to. Den er litt spesiell. Det standard er er standard error. Det er en egen feilmeldingskanal. Vi skal nå se på hvordan vi kan omdirigere på disse her. Man tar standard-ot fra én kommando og sender til standard inn i en annen kommando eller til en fil. Det gjør man da ved en pipe eller med andre... Det er andre tegn som omdirigerer til andre steder. F.eks. en større enn pil som omdirigerer til en fil. Da skal vi se hvordan det ser ut i praksis. Vi har allerede gjort dette en del... For eksempel... En type ting man gjør, er å... Hvis jeg tar 'eats a password', så kommer det masse tekst ut. Så det jeg kan gjøre, er å pipe det til en annen kommando, nemlig'more'. Det var fordi jeg typet den til målet.", "source": "lecture"}
{"lecture_id": "linux3del6", "chunk_id": "linux3del6_0002", "start": 155.56, "end": 261.92, "token_count": 279, "text": "For eksempel... En type ting man gjør, er å... Hvis jeg tar 'eats a password', så kommer det masse tekst ut. Så det jeg kan gjøre, er å pipe det til en annen kommando, nemlig'more'. Det var fordi jeg typet den til målet. Hvis vi da går tilbake på sliden og ser, så vil vi se her at... Det som egentlig skjer da, er at jeg omdirigerer. Vi ser her nede et annet eksempel. PSAUX blir omdirigert standardat fra PCAUX ved hjelp av en sånn pipe, så sendes den til More. Tilsvarende kan man sende et passord til CAT, som så kan sendes til SVART. Det er på denne måten man lager store konstruksjoner av kommandor, som gjør at akkurat et... Så tok jeg første etiske passord, men kan også psox. Outputen sendes nå til standard. Og så sender jeg det til More i stedet for å sende det til Default, som er rett ut på skjermen. Hvis jeg sender det rett ut på skjermen, så går alt rett ut.", "source": "lecture"}
{"lecture_id": "os9del13", "chunk_id": "os9del13_0000", "start": 0.0, "end": 113.08, "token_count": 282, "text": "Skal vi se litt på... Linux-arkitektur... Ja... Hovedprinsippet bak denne tegningen er at dette som er inni boksen her, det er Linux-kjernen. Og så ser vi alle applikasjoner og verktøy. De er i use space. Linux-kjernen er delt opp i fem moduler. Som sagt er det ikke objektorientert, men det er modulært. Så det er veldig systematisk satt opp. Men i prinsippet så kan skeduleren der borte endre på ting i... Hvis man skrev kode som var skikkelig hårete, så ville det bli ekstremt komplekst og aldri funke. Det er et enormt svært program. Konklusjonen på oppgaven denne uken er noe sånt som at hvis man... ... i bøker og stabler dem oppå hverandre, og så får man en stabel som er 25 meter høy. Så det er enormt mye kode. Så dette må være veldig modulært og bygd systematisk opp. Det er fem viktige hovedmoduler. Det første vi har sett på veldig mye nå, er alt som har med prosessmanagement,", "source": "lecture"}
{"lecture_id": "os9del13", "chunk_id": "os9del13_0001", "start": 93.88, "end": 193.02, "token_count": 291, "text": "og så får man en stabel som er 25 meter høy. Så det er enormt mye kode. Så dette må være veldig modulært og bygd systematisk opp. Det er fem viktige hovedmoduler. Det første vi har sett på veldig mye nå, er alt som har med prosessmanagement, scheduler, multitasking osv., og det er relatert til det vi har her nede, nemlig SEPUT. Det neste punktet vi skal se på, er ram og cash. Cash styres ikke av operativsystemet direkte. Det er hardware-styrt, men alt som har med ram å gjøre, styres av operativsystemet, og det skal vi se på i detalj senere. Vi kommer også til å se på filsystemet og filer av directories, mapper, Alt dette er lagret på harddisk. Det er de tre viktige komponentene. I tillegg har vi alle mulige devices. Sånn som tastatur og terminaler og... Nettverkskort kommer inn i nettverk. Men alle mulige andre devices i USB, f.eks. Det er i prinsippet ganske enkle ting, men det som gjør det vanskelig, er at det er hardware. Så det er veldig mye jobb å skrive drivere", "source": "lecture"}
{"lecture_id": "os9del13", "chunk_id": "os9del13_0002", "start": 169.66, "end": 226.0, "token_count": 166, "text": "Nettverkskort kommer inn i nettverk. Men alle mulige andre devices i USB, f.eks. Det er i prinsippet ganske enkle ting, men det som gjør det vanskelig, er at det er hardware. Så det er veldig mye jobb å skrive drivere til alle mulige typer hardware. Det kom vi ikke så veldig mye inn på. Vi kommer heller ikke inn på nettverk. Så... Mange av dere har nettverk med app. I det kurset, hvor dataingeniører har gitt det, er det det kurset hvor vi ser på nettverk. Tidligere var nettverk en del av OS-kurset, men nå er det et eget kurs.", "source": "lecture"}
{"lecture_id": "linux11del8", "chunk_id": "linux11del8_0000", "start": 0.0, "end": 99.06, "token_count": 288, "text": "Vi så før pausen at for å kunne... For å kunne kjøre påskjellscript, så måtte man sette execution policy til remote side. Og det måtte man gjøre som administrator. Når man først har gjort det, så kan man lage egen script og kjøre alt man ønsker å kjøre. Først skal vi se på et par command lets som er veldig nyttige. Vi ser... man kan bruke tabbe på samme måte som i et linjeskjelv. Hvis jeg skriver get co, f.eks., og så tabbe, så ser vi at den fullutfører med get-kommand. Så kan jeg fortsette å tabbe, og da vil jeg tabbe meg med... Gjennom alle mulige... command-lets som begynner på get-dash-c. Så get-kommand gir en oversikt over alle kommandoer. Og det vil da være fryktelig mange, men vi kan som et Linux-styrk pipe det til mål. Da ser vi at vi får en lang liste over ikke bare command-lets, men også alle som er definert. Og alle funksjoner. Og det er en rekke funksjoner, og så er det en mengde command-lets.", "source": "lecture"}
{"lecture_id": "linux11del8", "chunk_id": "linux11del8_0001", "start": 74.38, "end": 178.68, "token_count": 294, "text": "Og det vil da være fryktelig mange, men vi kan som et Linux-styrk pipe det til mål. Da ser vi at vi får en lang liste over ikke bare command-lets, men også alle som er definert. Og alle funksjoner. Og det er en rekke funksjoner, og så er det en mengde command-lets. Stop computer stop-prosess, for eksempel, tilsvarer kill. Og en rekke andre. Så kan man... Jeg bruker get-kommand til å finne ut hva som skjer hvis jeg kjører LS. Da vil jeg se at LS egentlig er et alias. Det er sånn man har lagd alle Linux-kommandoene, sånn at man kan bruke LSIMV osv. Da har man lagd et alias som er til get-shild-iter. Så kan man ønske å vite hva er get. Der kom jeg innom Shighlight Am. Litt for rask. Get command, get shighlight am. Da får jeg vite hva er egentlig get shighlight am. Da får jeg ikke så veldig mye informasjon. Det jeg får vite da, er at dette er en command-let. Typen står her, command-let. Og så får jeg versjonen og hvor den kommer fra.", "source": "lecture"}
{"lecture_id": "linux11del8", "chunk_id": "linux11del8_0002", "start": 157.12, "end": 229.2, "token_count": 191, "text": "Get command, get shighlight am. Da får jeg vite hva er egentlig get shighlight am. Da får jeg ikke så veldig mye informasjon. Det jeg får vite da, er at dette er en command-let. Typen står her, command-let. Og så får jeg versjonen og hvor den kommer fra. Hvis jeg skal vite mer om en kommando, så kan jeg bruke get help. Da kan jeg ta get help, og da får jeg en manualside som ligner på Linux-mann. Det går også an å bare... Istedenfor get help, så kan jeg bare bruke help. Men den gir da automatisk en war også, så den hjelper kanskje enda bedre å bruke. De to kommandoene er nyttige, for de kan da gi deg informasjon... De kan gi deg informasjon om kommander.", "source": "lecture"}
{"lecture_id": "os12del15", "chunk_id": "os12del15_0000", "start": 0.0, "end": 95.74, "token_count": 283, "text": "Semaforer er et begrep som er mye brukt når det gjelder synkronisering. Og semaforer, de... Det er en slags teller. Så en binær semafor, altså en semafor som bare har 0 eller 1, det er akkurat som en myteks. Men generelt så kan en semafor ha flere verdier. Du kan f.eks. Starter med S like T. Og da... Da har man ti ressurser som man kan på en måte bruke opp før man må vente og synkronisere med andre. Og på en semafor så har man to metoder som man bruker. Signal-S og wait-S. Og signal-S, det signaliserer nå... Nå er alt klart. Semaforer er jo et gammelt begrep som handler om flagg. At man bruker sånne tegn for flagg for å sende signaler over lange avstander. Så dette er semaforer som da brukes til å sende tegn prosesser imellom. Og Deikstra, som er en nederlandsk professor som på 60-, 70-tallet... Han la grunnlag for mye av dette med synkronisering", "source": "lecture"}
{"lecture_id": "os12del15", "chunk_id": "os12del15_0001", "start": 65.7, "end": 155.3, "token_count": 288, "text": "At man bruker sånne tegn for flagg for å sende signaler over lange avstander. Så dette er semaforer som da brukes til å sende tegn prosesser imellom. Og Deikstra, som er en nederlandsk professor som på 60-, 70-tallet... Han la grunnlag for mye av dette med synkronisering og den Dijkstra-algoritmen som vi skal se på i oppgavene. Og han fant på dette begrepet - semaforer. Hvis det skal implementeres riktig, så må de være uninterruptable. Altså, de må være atomiske, sånn at de ikke kan... Sånn at det ikke kan komme en contex-switch midt inni her. Og det gjør man da ofte med hardware-støtte. Og de operasjonene man gjør... Her så ser vi så lenge S er mindre enn lik null, så venter man, og så minsker man. Det betyr... La oss si S i utgangspunktet er 5, da. Så vil alle som går inn i veit, de vil senke den nedover. Når den når 0, da vil den ikke gå lenger ned. Da er det et signal til andre.", "source": "lecture"}
{"lecture_id": "os12del15", "chunk_id": "os12del15_0002", "start": 132.56, "end": 221.24, "token_count": 282, "text": "så lenge S er mindre enn lik null, så venter man, og så minsker man. Det betyr... La oss si S i utgangspunktet er 5, da. Så vil alle som går inn i veit, de vil senke den nedover. Når den når 0, da vil den ikke gå lenger ned. Da er det et signal til andre. Men hvis vi starter med S1, så vil en semafor se ut som en mytex. Så en binærsemafor som enten er 0 eller 1, den er akkurat som en lokk eller som en mytex. Og da kan man bruke semaforer akkurat som man har gjort tidligere. Tidligere så sa vi get Mutex og release Mutex. Men her ville vi nå ta Wait-S og Signal-S. Men de har da den tilsvarende egenskapen. Da kan man kjøre et kritisk avsnitt inni. Og da, når man gjør Wait-S, så setter man S lik 0. Og det er da et signal til alle andre at de må stå og vente. Uansett... Generelt med mutexer... Og hvis man gjør det med software, lager den type mutexer,", "source": "lecture"}
{"lecture_id": "os12del15", "chunk_id": "os12del15_0003", "start": 192.28, "end": 292.84, "token_count": 292, "text": "Da kan man kjøre et kritisk avsnitt inni. Og da, når man gjør Wait-S, så setter man S lik 0. Og det er da et signal til alle andre at de må stå og vente. Uansett... Generelt med mutexer... Og hvis man gjør det med software, lager den type mutexer, så bruker man busy waiting. Og det er opplagt en ulempe. Operativsystemet har den store fordelen at det kan styre prosesser og sette de inn og ut av køer. Så dette er en implementasjon av semafore reoperativsystemet. Og da kan... Hvis vi starter med wait, så kan en... Hvis en ressurs er opptatt, og man må vente, så kan operativstudenten blokkere den prosessen og legge det i en venteliste. Det fine med det, er at da tas bare prosessen ut av reddelist. Og den vil ikke måtte stå og vente med en busy waiting. Den vil da bare legges på vent. Og så, når andre prosesser er ferdig, og gjør en signal, så kan Operativ CMC, OK, S økes med igjen. Ja, da kan vi vekke opp neste prosess fra ventelisten.", "source": "lecture"}
{"lecture_id": "os12del15", "chunk_id": "os12del15_0004", "start": 270.0, "end": 339.6, "token_count": 217, "text": "Den vil da bare legges på vent. Og så, når andre prosesser er ferdig, og gjør en signal, så kan Operativ CMC, OK, S økes med igjen. Ja, da kan vi vekke opp neste prosess fra ventelisten. Så da vekkes den prosessen opp som har ligget og ventet. Og på den måten så får man en veldig ryddig og effektiv på å synkronisere prosesser. Og det er et viktig poeng at operativsystemer legger til rette for at programmerere kan synkronisere med sånn som signal-o-wait. Mens det er programmereren som må skrive koden som gjør det. Så operativsystemer synkroniserer ikke for programmererne. Det er programmererne som må gjøre dette, men Operativ Svømme legger til rette ved f.eks. å kunne tilby semaforer.", "source": "lecture"}
{"lecture_id": "os2del11", "chunk_id": "os2del11_0000", "start": 0.0, "end": 89.88, "token_count": 299, "text": "Jo, det var et spørsmål i pausen om denne kretsen her. Og spesielt hvordan... Hvis det kommer en positiv spenning inn her ved x, altså x², hvorfor det da går... Hvorfor det da kommer null ut? Fordi... Ja-spørsmålet var vel... Hvis det kommer en ener inn her, så skrus jo denne bryteren på. Og da går det strøm herfra og opp hit. Og hvis det går strøm, er ikke da den også en ener? Men dette gjelder spenninger, så det er på en måte... Problemstillinga er hvis du måler spenningen som er her på Y i forhold til null. Hva får du da? Og da vil det være sånn at når en ener kommer inn, altså når det er positiv spenning her ved X, så er det riktig, da skrus den bryteren på. Og da tilsvarer det at det går en ledning herfra, altså fra null volts, så går det en ledning og opp til y. Og da vel, siden dette er en ledning, en kobberledning som leder veldig godt, så vil det på y, så vil det da være null spenning når du setter på.", "source": "lecture"}
{"lecture_id": "os2del11", "chunk_id": "os2del11_0001", "start": 70.42, "end": 155.7, "token_count": 291, "text": "Og da tilsvarer det at det går en ledning herfra, altså fra null volts, så går det en ledning og opp til y. Og da vel, siden dette er en ledning, en kobberledning som leder veldig godt, så vil det på y, så vil det da være null spenning når du setter på. Spenning her. Så åpnes porten. Denne blir strømførende, og det blir en ledning som går da direkte fra jord, fra null volt og opp til y. Så hvis du da måler spenningen her på y, så vil du få null. Så... Skrur du på den bryteren her, så betyr det at det er en ledning mellom y og null. Hvis det kommer en ener inn, så kommer det null ut. Vi skal ikke bruke veldig mye tid på dette, men hovedtanken er at da kan dere se at dette... Sånn funker det, og sånn er det mulig å få til alle de andre bitene også. Det er mer sånn at hvis det skjedde en tredje verdenskrig og alt gikk tapt, Så skulle dere ved hjelp av de ideene her, så skulle dere kunne tenke dere frem til", "source": "lecture"}
{"lecture_id": "os2del11", "chunk_id": "os2del11_0002", "start": 125.26, "end": 175.92, "token_count": 173, "text": "Vi skal ikke bruke veldig mye tid på dette, men hovedtanken er at da kan dere se at dette... Sånn funker det, og sånn er det mulig å få til alle de andre bitene også. Det er mer sånn at hvis det skjedde en tredje verdenskrig og alt gikk tapt, Så skulle dere ved hjelp av de ideene her, så skulle dere kunne tenke dere frem til hvordan kan man lage neste generasjon datamaskiner ved hjelp av dette her. For det er ganske enkel logikk med denne type brytere, som lager all logikk i en datamaskin. Og verre er det ikke, men samtidig blir det komplisert når man setter det sammen.", "source": "lecture"}
{"lecture_id": "os6del3", "chunk_id": "os6del3_0000", "start": 0.02, "end": 102.96, "token_count": 296, "text": "Så jeg kan se på hvordan det ser ut i praksis. Hvis jeg nå går til riktig vindu i... Skal vi se. Jeg tror jeg har et studiesesongvindu her. Litt mange vinduer her. Her har jeg et vindu i studiesesong. Så kan vi tenke oss at det enten er i SUSH, eller at dere logger direkte inn med putty. Begge deler går. Det skal gå an å logge seg inn hjemmefra også. Denne her er ikke innenfor... Dere må ikke bruke... Hva heter det... VPN. Dere må ikke bruke Oslomett VPN for å komme inn til disse. Jeg har tatt en gruppe som er nummer 100, så jeg må da logge meg på som group 100. Dere må gjerne prøve dette her nå. Passordet dere skal ha for group 100, eller group 13, det ligger i en announcement i Kanas på OS-gruppen. Så hvis dere er OS 100, hvis dere var OS 100, så vil dere da gå inn i den gruppen og se på announcement som ligger der. Da kan dere plukke ut passordet. Dette er felles for alle som er på gruppen. Og så er urlnvlab.cs.hioa.no...", "source": "lecture"}
{"lecture_id": "os6del3", "chunk_id": "os6del3_0001", "start": 80.4, "end": 193.06, "token_count": 300, "text": "Så hvis dere er OS 100, hvis dere var OS 100, så vil dere da gå inn i den gruppen og se på announcement som ligger der. Da kan dere plukke ut passordet. Dette er felles for alle som er på gruppen. Og så er urlnvlab.cs.hioa.no... Tror ikke OsloMet funker, men Hioa skal funke. Så må dere skrive passordet som dere har fått. Se om jeg husker passordet jeg har fått. Ja. Og da er det plutselig et Linux-skjell på samme måte som... Ja, ligner veldig på Studies SO. Det kjører Ubuntu 2004. Så det er en helt ny versjon av Ubuntu. Det er mulig den er nyere enn den den er på Studies SO. Hittil på StudieSV, men dere kan da gjøre enda mer. Og det er det viktig å være klar over. Her er dere RUT. Dere har RUT-aksess. Så dere kan gjøre sudo-SU og så skrive passordet på nytt. Da ser du - vips - så er det RUT på systemet. Og da kan dere gjøre alt dere måtte ønske. For eksempel å installere. Kjøre Apt-get-update før dere installerer.", "source": "lecture"}
{"lecture_id": "os6del3", "chunk_id": "os6del3_0002", "start": 155.12, "end": 260.28, "token_count": 284, "text": "Og det er det viktig å være klar over. Her er dere RUT. Dere har RUT-aksess. Så dere kan gjøre sudo-SU og så skrive passordet på nytt. Da ser du - vips - så er det RUT på systemet. Og da kan dere gjøre alt dere måtte ønske. For eksempel å installere. Kjøre Apt-get-update før dere installerer. Så kan dere installere hva som helst som dere måtte ønske. Eller som dere trenger i oppgavene. Tvert i oppgaven kommer det noen instruksjoner om å installere screen og kron og en del forskjellig annet. Er det denne uken eller kanskje neste uke hvor dere blir bedt om å installere en webserver? Og det... Skal vi se... Jeg tror jeg har gjort det allerede her. Så vi kan kikke på det. Hvis jeg... Skal vi se... Hvis jeg skriver inn nå OS100 her... Sånn, ja. Så ser vi det kommer opp en aposje, to ubundte default-patch. Så det er nå webserveren til OS100. Som dere kan endre på og styre som dere vil.", "source": "lecture"}
{"lecture_id": "os6del3", "chunk_id": "os6del3_0003", "start": 230.56, "end": 350.14, "token_count": 290, "text": "Hvis jeg skriver inn nå OS100 her... Sånn, ja. Så ser vi det kommer opp en aposje, to ubundte default-patch. Så det er nå webserveren til OS100. Som dere kan endre på og styre som dere vil. Legg merke til at dette her er jo en... Dette er nå en public IP. Så ifconfig... Oi, nå må jeg tilbake. Nå er jeg inne på OS101. ifconfig viser info om nettet. Og her ser vi at dette er public IP. Hvis du er OS1, så har du public IP 13 i 120, 101 og 102 for OS2 osv. Det er veldig viktig å være klar over. Denne eap-en her nås av... av alle. Sånn at her er det helt inn folk som prøver å... Prøver å logge seg på. Vi kan se om... Nei, det ser ikke ut som... Den kjører auto-at-the-log. Ja, det kan vi se på senere. Alle har tilgang herfra, og det vil foregå en del... Eller SSH-skanning foregår det hele tiden. Dvs. at man prøver å logge seg på og gjette passordet til din maskin.", "source": "lecture"}
{"lecture_id": "os6del3", "chunk_id": "os6del3_0004", "start": 322.04, "end": 430.0, "token_count": 278, "text": "Den kjører auto-at-the-log. Ja, det kan vi se på senere. Alle har tilgang herfra, og det vil foregå en del... Eller SSH-skanning foregår det hele tiden. Dvs. at man prøver å logge seg på og gjette passordet til din maskin. Så det betyr at hvis du lager en konto med brukerland-test og passord-test... Ikke gjør det, for da vil vel... Vær veldig forsiktig med brukernavn og passord. Neste uke skal dere lage et brukernavn. Og tilsvarende brukernavn som dere har på StudieSSH, og sett det passord. Når dere gjør det, så hjelper det veldig å ha sånne sære brukernavn som s123456, men sett også et godt passord. Og for all del, ikke bruk brukernavn som Linux eller Ubuntu eller Test eller noe sånt med dårlig passord. Da er det straks noen... i hvert fall i løpet av timer, noen som kommer inn og tar over IP-en. Så vær generelt obs for den. Men den vemen er der ute i den store verden og har veldig lite beskyttelse.", "source": "lecture"}
{"lecture_id": "linux4del7", "chunk_id": "linux4del7_0000", "start": 0.0, "end": 83.8, "token_count": 292, "text": "Så har jeg sett at når vi kjører en forløkke, så splittes elementene i forløkken opp på mellomrom. Det er default. Og da er det greit å sette opp en forløkke, men ganske ofte så har man f.eks. en variabel eller... Eller noe annet man ønsker å løpe gjennom som ser ut sånn som dette her. Fil 1, fil 2... Og som er atskilt med kolon. Path er et eksempel på dette. Så ønsker jeg å lage en forløkke som jeg løper gjennom fil 1, fil 2, fil 3. Og da kan jeg si noe sånt nå for i-in... Kanskje gjøre det eksplosivt for fil-in-dollar-hver. Da ønsker jeg å løpe gjennom, og så ønsker jeg å skrive ut. Eller noe annet med hver enkelt fil. Så gjør jeg det på den måten. Men da ser vi. Da oppfattet Shellet dette at den dollar var, det er bare én variabel med dette innholdet. Og dermed så går løkka bare én gang. Det kan vi fikse på med en variabel som heter ifs,", "source": "lecture"}
{"lecture_id": "linux4del7", "chunk_id": "linux4del7_0001", "start": 60.0, "end": 149.04, "token_count": 294, "text": "Eller noe annet med hver enkelt fil. Så gjør jeg det på den måten. Men da ser vi. Da oppfattet Shellet dette at den dollar var, det er bare én variabel med dette innholdet. Og dermed så går løkka bare én gang. Det kan vi fikse på med en variabel som heter ifs, eller internal field separator. Og den er det. ... eller faktisk space og tab og ny linje... Så hvis vi setter IFS lik kolon på den måten, så vil vi se... Hvis vi da løper gjennom den samme løkka, så splitter den opp på kolon, og så får vi for hver fil... Så kan vi gjøre det vi måtte ønske. Som sagt så kan dette være veldig nyttig for å løpe gjennom path. For da kan vi prøve å gjøre akkurat samme med variabelen path. Og da skriver vi da i stedet ut hvert element path. Og på den måten så kan man løpe gjennom path og behandle elementene der. Det samme gjelder med en linje i passordfilen. De er også utslitt med konon. Så det er ganske vanlig. Men IFS kan da sette...", "source": "lecture"}
{"lecture_id": "linux4del7", "chunk_id": "linux4del7_0002", "start": 128.88, "end": 152.32, "token_count": 92, "text": "Og da skriver vi da i stedet ut hvert element path. Og på den måten så kan man løpe gjennom path og behandle elementene der. Det samme gjelder med en linje i passordfilen. De er også utslitt med konon. Så det er ganske vanlig. Men IFS kan da sette... Det kan knyttes til hva som helst.", "source": "lecture"}
{"lecture_id": "linux4del6", "chunk_id": "linux4del6_0000", "start": 0.0, "end": 99.24, "token_count": 296, "text": "Fåløkker er det veldig viktig å kunne i shadeskripting, for det bruker vi hele tiden. Så syntaksen for en fåløkke er rett og slett 'får' og så en variabel. Det er et variabelnavn man finner på selv. Kaller den Vari, f.eks. Inn, og så kommer det bare en liste med et eller annet. F.eks. la oss si jeg bare skriver en liste på to og tre... Og så er syntaksen do. Altså inni den løkka, så skal vi gjøre følgende. Og så kommer det linjer som vi skal skrive ut. Og da kan vi jo f.eks. i dette tilfellet skrive ut dollarvari. Så kan vi gjøre noe med litt mer. Variabel er her... Vari. Sånn. Og eventuelt... flere linjer med det vi skal gjøre. Pause. Bare å skru ut noe, og så Don. Og da ser vi at vi går gjennom løkken, og så først får variabelen H1. Så skriver vi ut akkurat dette her, og H1 endrer seg nedover. Den generelle syntaksen for løkker. Hvis man skal ha noe hjelp for sånt som dette,", "source": "lecture"}
{"lecture_id": "linux4del6", "chunk_id": "linux4del6_0001", "start": 70.34, "end": 175.24, "token_count": 288, "text": "Bare å skru ut noe, og så Don. Og da ser vi at vi går gjennom løkken, og så først får variabelen H1. Så skriver vi ut akkurat dette her, og H1 endrer seg nedover. Den generelle syntaksen for løkker. Hvis man skal ha noe hjelp for sånt som dette, så kunne man jo prøve Man4, men det er ikke noe manual entry for 4. Og det er fordi 4 er skjell-keyword, så det er bygd inn i skjellet. Så hvis man har et skjell-keyword, så må man i stedet skrive help. Og da er dette den generelle syntaksen. De listene i Ford, det kan være veldig mye. F.eks. kunne vi tenke oss å løpe gjennom LS. Output fra LS. Og da kan jeg legge det inn i denne... Jeg får løkken. Var den litt lang, så jeg kan f.eks. ta... La oss si... At jeg i stedet bare skriver ut... \"... ekkodollarvari\". Sånn. Sånn det er. Og så kan jeg nå i stedet si... OK, her ønsker jeg en liste med LS.", "source": "lecture"}
{"lecture_id": "linux4del6", "chunk_id": "linux4del6_0002", "start": 150.0, "end": 238.68, "token_count": 295, "text": "Jeg får løkken. Var den litt lang, så jeg kan f.eks. ta... La oss si... At jeg i stedet bare skriver ut... \"... ekkodollarvari\". Sånn. Sånn det er. Og så kan jeg nå i stedet si... OK, her ønsker jeg en liste med LS. Da kan jeg ikke bare skrive eller sånn. Det... Da får jeg bare... I stedet si... OK, her ønsker jeg en liste med LS. Da kan jeg ikke bare skrive eller sånn. Det... Da får jeg bare... Så jeg må utføre den kommandoen. Men da har vi sett tidligere at da har vi en egen konstruksjon med parenteser. Sånn utfører vi en kommando. Så da vil LS utføres, og så returnere de verdiene her oppe. Så får vi én linje for hver verdi som LS utfører. Eller som LS finner. En vilkårlig kommando her inne. Et annet eksempel er at man kan se på innholdet i en fil. Her er innholdet i den filen 123. Da kan jeg skifte ut den kommandoen, og så kan jeg si... Ops... Tok en... Ja, tar den på nytt.", "source": "lecture"}
{"lecture_id": "linux4del6", "chunk_id": "linux4del6_0003", "start": 210.0, "end": 319.56, "token_count": 280, "text": "En vilkårlig kommando her inne. Et annet eksempel er at man kan se på innholdet i en fil. Her er innholdet i den filen 123. Da kan jeg skifte ut den kommandoen, og så kan jeg si... Ops... Tok en... Ja, tar den på nytt. Så kan jeg i den kommandoen som skal inngå i listen, skrive ut fil. Da vil jeg skrive ut filen her, og så vil den på hver linje i filen gå inn og utføre kommando. Så på denne måten kan man løpe gjennom det meste i et skjell. En litt annen måte å gjøre det på er å skrive... Stjerne. Stjerne generelt, det gir... alt som er i mappen. Så kunne jeg f.eks. la oss si at jeg skulle løpe gjennom alle filer som ender på tekst t. Da kan jeg gjøre det på den måten. Så kunne jeg også legge inn en variabel. La oss si... Var... La oss si jeg setter den til LS, sånn at var nå inneholder LS. Da kunne jeg også løpe gjennom alle elementene i den variabelen på denne måten.", "source": "lecture"}
{"lecture_id": "linux4del6", "chunk_id": "linux4del6_0004", "start": 290.66, "end": 387.96, "token_count": 280, "text": "Da kan jeg gjøre det på den måten. Så kunne jeg også legge inn en variabel. La oss si... Var... La oss si jeg setter den til LS, sånn at var nå inneholder LS. Da kunne jeg også løpe gjennom alle elementene i den variabelen på denne måten. Så da innholdet var de fire strengene her, så løper forlokken igjennom. Denne måten å bruke folk på, Det bruker man hele tiden. Så det går også an å skrive en mer tradisjonell forløkke. Igjen så er det da den syntaksen vi bruker i nummerikk og i matte, nemlig med doble parenteser. Og her, så kan du, hvis du foretrekker det, så kan du skrive mer vanlig java-syntaks i lik null i mindre enn fem. I pluss-pluss, sånn som det. Og så kan man sette du og Don. Ekko... La oss si vi bare skriver ut tallet. Og Don på den måten. Så det er en... En enklere måte å skrive forløpet på hvis du liker Javar-lignende syntaks.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0000", "start": 0.0, "end": 99.7, "token_count": 287, "text": "Der ser det ut som recordingen starter hos meg, i hvert fall. Ja, da skal vi starte med... Jeg tenkte vi kunne bare starte med å si litt om opplegget, så nå deler jeg kurstiden med dere. Sånn. Og da ser vi... Vi er nå i uke to, tirsdag 12. Og det vi skal snakke om i dag, er transistorer, porter og en krets om aldere tall. Så når du ser her hvor det står F, så er det forelesninger, sånn som nå, live. Mens for det andre temaet denne uken... Hver uke er det første temaet generelt om operativstemmer. Og det andre... Som er mer hands on, praktisk. Mye i starten er Linux og Linux-kommandoer. Her står den D for digital. Så her er det du kan kalle det digitale forelesninger som er spilt inn på forhånd. Da er tanken sånn at den digitale forelesningen fra forrige uke, som jeg la ut stort sett på onsdag, onsdag ettermiddag kanskje... Derfra er det oppgaver om denne uken. Jeg har også lagt ut oppgaver til uke tre.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0001", "start": 73.26, "end": 174.08, "token_count": 285, "text": "som er spilt inn på forhånd. Da er tanken sånn at den digitale forelesningen fra forrige uke, som jeg la ut stort sett på onsdag, onsdag ettermiddag kanskje... Derfra er det oppgaver om denne uken. Jeg har også lagt ut oppgaver til uke tre. De som ligger litt foran, kan se på det nye temaet fra onsdag 13.11, med Linux filsystemer osv., og gjøre oppgaver fra uke tre. Da kommer jeg til å legge ut noen tilsvarende opptak hvor jeg diskuterer slider og stoff. Ja, i løpet av denne halvdagen. Du kan bare se kjapt hvordan det ser ut. Hvis man går inn på de de-forelesningene, så er det notater der. Litt mer utfyllende enn slides. Og så har jeg da lagd noen små demoer f.eks. av hvordan man flytter seg. Da ble det to stykker av meg på en gang. Men sånn er tanken at dere skal kunne gå inn og se på det dere ønsker. Det som er fint med at dere har alt direkte, alt, er jo det kan bli mye frihetsgrader.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0002", "start": 141.16, "end": 232.96, "token_count": 287, "text": "Og så har jeg da lagd noen små demoer f.eks. av hvordan man flytter seg. Da ble det to stykker av meg på en gang. Men sånn er tanken at dere skal kunne gå inn og se på det dere ønsker. Det som er fint med at dere har alt direkte, alt, er jo det kan bli mye frihetsgrader. Men da har dere iallfall mulighet til å jobbe litt sånn som dere selv syns er best. Eller så kan dere begynne å jobbe med oppgavene. Og hvis alt går greit, så går det greit. Spesielt i den praktiske delen er det snakk om å få det inn i fingrene og øve på det og få det til. Det er ikke sånn at du må se alle videoene for å få det til. Men en måte å jobbe på kan være å prøve å jobbe med oppgavene. Hvis dere står fast, så kan dere gå inn og se en video eller lese en slide og lese dere opp på akkurat det. Så vil dere også se... jo, på denne, nei, litt frem og tilbake her... På den digitale forlesningen så ser vi også at jeg har den siste demoen her,", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0003", "start": 198.4, "end": 297.96, "token_count": 298, "text": "Men en måte å jobbe på kan være å prøve å jobbe med oppgavene. Hvis dere står fast, så kan dere gå inn og se en video eller lese en slide og lese dere opp på akkurat det. Så vil dere også se... jo, på denne, nei, litt frem og tilbake her... På den digitale forlesningen så ser vi også at jeg har den siste demoen her, er litt om oppgavene til denne uken, altså i uke to. Da kan det være lurt å prøve på oppgaven først, hvis dere står fast og ikke skjønner helt hva jeg mener. Så kan dere prøve å gå inn der og se på en mer detaljert forklaring. Ja, det er én kommentar om at det er gode videoer, og det er kjempebra. Takk for den tilbakemeldingen. Og kom gjerne med andre tilbakemeldinger også. Eller noe dere ikke forstår eller... Et eller annet med videoene som ikke er bra, lyd, bilde, hva som helst. Så gi tilbakemelding. Ja. Hvis det ikke er noen spørsmål da, så tenkte jeg å gå i gang med det som er temaet for i dag.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0004", "start": 270.0, "end": 388.66, "token_count": 286, "text": "Eller noe dere ikke forstår eller... Et eller annet med videoene som ikke er bra, lyd, bilde, hva som helst. Så gi tilbakemelding. Ja. Hvis det ikke er noen spørsmål da, så tenkte jeg å gå i gang med det som er temaet for i dag. Nei, ingen flere spørsmål. Da skal jeg dele noen slider med dere. Og så skal vi først og fremst se på hva som er dagens tema. Eller hva som er essensen i dagens tema. Sånn. Nå deler jeg en slide om transistorer. Så si ifra hvis dere ikke ser dem. Et lite spørsmål i chatten. Kunne vi bare bruke Putty istedenfor en Linux-terminal? Ja, absolutt. Det kan dere gjøre. Hva slags verktøy, om dere bruker Putty eller Linux-terminal fra Mac eller fra... Det spiller ingen rolle, det er bare en litt sånn teknisk greie. Så bruk det som fungerer for dere. OK. Før jeg begynner på selve slidene, så tenkte jeg å prøve å hoppe til slutten for å se på hva jeg egentlig ønsker å fortelle dere i dag.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0005", "start": 360.02, "end": 458.02, "token_count": 291, "text": "Det spiller ingen rolle, det er bare en litt sånn teknisk greie. Så bruk det som fungerer for dere. OK. Før jeg begynner på selve slidene, så tenkte jeg å prøve å hoppe til slutten for å se på hva jeg egentlig ønsker å fortelle dere i dag. Og slutten er dette her, som vi skal komme fram til i løpet av dagen. Som vi skal bruke en del tid på. For dette gir på en måte essensen i hva en datamaskin er, og hvordan den er bygd opp fra helt enkle, logiske enheter. Og det vi skal komme frem til i dag, som vi skal jobbe videre med fra neste gang for å lage en hel CPU, det er å få til å få til... Hvordan en krets kan lage, kan gjøre en vilkårlig logisk operasjon. Og den spesielle logiske operasjonen vi ser på her, er hvordan kan en CPU legge sammen to tall. For det er på en måte lett å tenke seg at hvis en CPU kan legge sammen to tall, så kan du få til alle andre mulige ting. Å legge sammen tall er en kompleks logisk operasjon som man ikke uten videre gjør.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0006", "start": 432.5, "end": 520.8, "token_count": 286, "text": "Og den spesielle logiske operasjonen vi ser på her, er hvordan kan en CPU legge sammen to tall. For det er på en måte lett å tenke seg at hvis en CPU kan legge sammen to tall, så kan du få til alle andre mulige ting. Å legge sammen tall er en kompleks logisk operasjon som man ikke uten videre gjør. Spesielt ikke i store tall, så er ikke det så enkelt. Men hvis vi får til dette, kan vi bygge videre. Da kan vi lage gange og subtraksjon og sammenligning og alt mulig annet. På tilsvarende måte. Det vi skal se på i dag, er å... Logisk, men også praktisk. Vise hvordan man kan lage innmaten i denne boksen her. Som er en slags trolldomsboks, som er sånn at hvis man putter inn binære tall på toppen, A og B, så kommer svaret ut som A pluss B. Og da må man starte med... Som du ser her, så starter man med nuller og enere. Det er temaet for neste gang. Da skal vi se på registeret, hvordan man lager bits inne i ICPU-en, sånn at man kan si", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0007", "start": 492.58, "end": 584.8, "token_count": 297, "text": "binære tall på toppen, A og B, så kommer svaret ut som A pluss B. Og da må man starte med... Som du ser her, så starter man med nuller og enere. Det er temaet for neste gang. Da skal vi se på registeret, hvordan man lager bits inne i ICPU-en, sånn at man kan si OK, jeg vil legge sammen A pluss B, hva blir det? Men det vi ser på nå, er hvordan kan man da kable dette sammen på en sånn måte at uansett hva du putter inn for AB, så kommer summen C ut i den andre enden. Det er ikke noen enkel oppgave. Hvis du fikk den oppgaven og aldri hadde hørt om transistorer og and or not, så ville det vært en relativt vanskelig oppgave. Men det går an å helt logisk bare sette opp dette her, og systematisk lage denne innhatten her med and or not-porter. Og når man har gjort det, så kan man i dag sende inn det til en... Produsent av halvlederblikker. Og så kan man få brent dette inn i hardware. Og man kan sette opp denne logikken med Andorra not porter, og så kan man brenne det i hardware.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0008", "start": 565.28, "end": 659.98, "token_count": 299, "text": "så kan man i dag sende inn det til en... Produsent av halvlederblikker. Og så kan man få brent dette inn i hardware. Og man kan sette opp denne logikken med Andorra not porter, og så kan man brenne det i hardware. Og så får man ut i andre enden en dataship som gjør akkurat det man ønsker. Og det er i bunn og grunn det en CPU er. Så det vi skal se på i detalj i dag, er hvordan kan man logisk sett, eller i praksis... Få til dette og lage en vilkårlig krets som gjør en operasjon. Transistoren. Transistoren er grunnlaget for dette her. Altså for det å kunne i det hele tatt lage en datamaskin. De aller første datamaskinene, Det var en transistorrør som lagde disse logiske portene. Og de fungerte, men problemet med det var at de transistorrørene var store. Så datamaskinene ble helt ekstremt store. Så det som la grunnlaget for CPU-en, var halvledertransistoren. Og det var det Shockley Bardin og Bratt Hane som fikk nobelprisen i fysikk for dette.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0009", "start": 635.56, "end": 730.0, "token_count": 295, "text": "Og de fungerte, men problemet med det var at de transistorrørene var store. Så datamaskinene ble helt ekstremt store. Så det som la grunnlaget for CPU-en, var halvledertransistoren. Og det var det Shockley Bardin og Bratt Hane som fikk nobelprisen i fysikk for dette. Mange argumenterer for at det er den viktigste oppdagelsen i forrige århundre. Det sier ikke lite, fordi den var grunnlaget for alt som har med datamaskiner å gjøre. Det som er så spesielt med halvleddetransistoren, er at den er ekstremt liten. Det er mulig å konstruere den ekstremt liten, helt nede i nanometer. Bitte små halvlederbitene, så kan man lage logiske and or or not porter. Og ikke bare logiske, men faktisk fysiske porter som utfører logikken. Man har teknologi helt nede i fem nanometer. Og da er det som komponenter av størrelsen fem nanometer, og det er ekstremt lite. Denne teknologien gjør at det er mulig å pakke sammen ekstremt mange små transistorer", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0010", "start": 699.28, "end": 820.04, "token_count": 288, "text": "Og ikke bare logiske, men faktisk fysiske porter som utfører logikken. Man har teknologi helt nede i fem nanometer. Og da er det som komponenter av størrelsen fem nanometer, og det er ekstremt lite. Denne teknologien gjør at det er mulig å pakke sammen ekstremt mange små transistorer på et lite område. Der har det vært en fantastisk utvikling fra 70-tallet, hvor de første kommersielle CPU-ene kom. Den hadde noen tusen transistorer. Så har vi økt til i dag hvor det er 20 milliarder transistorer på de største CPU-ene. Det er et ekstremt antall. Så er det noe som heter Mores lov. Det er ikke en lov, men en empirisk lov. Man har vist at sånn ca. annethvert år, så dobler antall transistorer seg i CPU-er. Det har funka ganske bra fra 70-tallet og så helt opp til i dag. Det er logarismisk skala her. Hvis den oppførselen er sånn at den går som to i x-halvet... Hvor ekstra tid den er. Så vil det være en ganske rett strek", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0011", "start": 791.64, "end": 887.3, "token_count": 286, "text": "Det har funka ganske bra fra 70-tallet og så helt opp til i dag. Det er logarismisk skala her. Hvis den oppførselen er sånn at den går som to i x-halvet... Hvor ekstra tid den er. Så vil det være en ganske rett strek når du bruker loggplott. Så dette er faktisk en dobling. Da kan man spørre seg hvordan i all verden... For det første er det en teknologisk bragd å få til. Om man har begynt å nærme seg slutten for hva som er mulig. Men for det andre... Dette gjør ikke bare at CPU-ene går raskere og kan utføre mer arbeid. En stor del av de ekstra transistorene de siste årene har kommet pga. cash. Men det som har vært viktig for utviklingen, er at jo mindre transistorer du har, jo hurtigere kan operasjonene kjøres. Så du får... Du kan kjøre Klokkefrekvensen har også økt hele veien. Her er noen tall på det. Den Intel 404 som lå helt til venstre i hjørnet på den forrige graffen, den hadde 2300 transistorer.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0012", "start": 863.02, "end": 953.46, "token_count": 276, "text": "jo hurtigere kan operasjonene kjøres. Så du får... Du kan kjøre Klokkefrekvensen har også økt hele veien. Her er noen tall på det. Den Intel 404 som lå helt til venstre i hjørnet på den forrige graffen, den hadde 2300 transistorer. Også Intel CEON, som ligger ganske høyt oppe til høyre, den har 7,2 milliarder transistorer. Så det er faktisk en økning på en faktor, en million. Basert tilsvarende på klokkefrekvenser, så har ikke de økt like mye. Men de har økt fra... Den Intel her hadde 500 kHz, eller en halv megahertz. I dag er det typisk fire gigahertz klokkefrekvens. Så det betyr en økning på 8000 omtrent. Da betyr det at siden 1970 så går ting minst åtte gigahertz. Det er gjort en masse andre forberedelser også. Men den største faktoren er at klokkefrekvensen har økt. Den teknologien man har nå, er ganske imponerende.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0013", "start": 914.9, "end": 1019.98, "token_count": 294, "text": "I dag er det typisk fire gigahertz klokkefrekvens. Så det betyr en økning på 8000 omtrent. Da betyr det at siden 1970 så går ting minst åtte gigahertz. Det er gjort en masse andre forberedelser også. Men den største faktoren er at klokkefrekvensen har økt. Den teknologien man har nå, er ganske imponerende. Man kan få 100 millioner transistorer inn på en kvadratmillimeter. Det er helt vanvittige tall. Og man fortsetter nedover. TSMC, som er en halvlederprodusent på Taiwan, som f.eks. IMD nå har outsourcet sin produksjon til. Intel har også noe der. Men Intel produserer det meste selv av CPU-er og silisiumbrikker. Vi jobber også med to og tre nanometer. Men man begynner å nærme seg slutten. Etter hvert er det ikke mulig å gå lenger ned. Fordi radius til et silisiumatom er på 0,1 nanometer. Så det vil ha en diameter på 0,2. Så hvis du får fem silisiumatomer ved siden av hverandre, så vil det ta kanskje...", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0014", "start": 1000.58, "end": 1079.96, "token_count": 294, "text": "Etter hvert er det ikke mulig å gå lenger ned. Fordi radius til et silisiumatom er på 0,1 nanometer. Så det vil ha en diameter på 0,2. Så hvis du får fem silisiumatomer ved siden av hverandre, så vil det ta kanskje... Stort lenger ned enn det kan man ikke gå, man kan ikke bygge fysiske komponenter. For da må man begynne med kvantemekanikk. Effekter som kvantemekanisk tunnelering har faktisk noe å si. Og det skaper problemer for disse silikonprodusentene, halvledderprodusentene. Så de fysiske grensene nærmer seg, så man kan ikke nå lage... Enda mindre og enda raskere CPU-er. Og som jeg nevnte, CPU-frekvensen har ikke økt særlig mye de siste 15 årene. Den var oppe i 3 GHz i 2005 omtrent, og der har det stått stabilt. Det man i stedet har gjort, er å putte på mer cash, som vi skal snakke mye om senere. Putte på mer cash og lage flere CPU-er inn på samme.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0015", "start": 1056.44, "end": 1146.36, "token_count": 287, "text": "Og som jeg nevnte, CPU-frekvensen har ikke økt særlig mye de siste 15 årene. Den var oppe i 3 GHz i 2005 omtrent, og der har det stått stabilt. Det man i stedet har gjort, er å putte på mer cash, som vi skal snakke mye om senere. Putte på mer cash og lage flere CPU-er inn på samme. Altså multicore computing. Vi har noen servere som har kanskje 64 CPU-er. Tidligere hadde alle én. Så var det vanlig med to, og så hadde alle fire. Så økningen, eller måten man får servere til å bli mer effektive på nå, er først og fremst å ha flere CPU-er. Vi skal se litt om teknologien. Vi skal ikke gå så nøye inn på det, vi skal se mer på logikken. Men CMOS er en halvlederteknologi. Og er den som er brukt i så å si alt som er av halvledere. Og den består av to typer transitorer. NMOS og PMOS. Forskjellen på de er at den ene har hull, og den andre har...", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0016", "start": 1114.78, "end": 1214.6, "token_count": 283, "text": "Men CMOS er en halvlederteknologi. Og er den som er brukt i så å si alt som er av halvledere. Og den består av to typer transitorer. NMOS og PMOS. Forskjellen på de er at den ene har hull, og den andre har... Altså, det har positive hull, og den andre har elektroner. Men som sagt, vi skal ikke gå inn i tekniske detaljer her. Vi skal se mer på logikken. Og logikken er ganske enkel. Dette er en NMOS-transistor. Og den har en sannhetstabell. Som er ganske enkel. Den er sånn at... her står det X. Og så ser vi her streker her. Dette er ledninger. Hvis vi ser 10 nanometer-teknologi, så er ledningene av den størrelsesorden. Så det er bare noen atomer... Noen silisium... Eller i dette tilfellet er det kobberledninger. Så det er bare noen kobberatomer. Og så er det inni her som halvlederen ligger, her er silisium, som er lagd på en sånn måte at hvis det er en spenning...", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0017", "start": 1188.36, "end": 1268.02, "token_count": 292, "text": "Så det er bare noen atomer... Noen silisium... Eller i dette tilfellet er det kobberledninger. Så det er bare noen kobberatomer. Og så er det inni her som halvlederen ligger, her er silisium, som er lagd på en sånn måte at hvis det er en spenning... Vi kan starte med den første. Hvis det er null her, det betyr at det er null spenning. Null volt inn her. Og da opererer dette som en bryter. Hvis vi kan tenke oss at det kommer strøm inn på toppen, og strøm ut i bunnen her. Så hvis du har spenning 0 inn, så er den bryteren av. Da er det ingen kobling mellom toppen og bunnen. Men hvis du setter på en spenning, f.eks. 5 volt inn her, over den transistoren, så skrur man på denne bryteren. En transistor er egentlig bare en bryter. Man skrur på bryteren, og da går det strøm igjennom. Og det er egentlig hele greia. Med den type brytere så kan man... Men hvordan, det skal vi se på i detalj.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0018", "start": 1245.58, "end": 1346.0, "token_count": 292, "text": "så skrur man på denne bryteren. En transistor er egentlig bare en bryter. Man skrur på bryteren, og da går det strøm igjennom. Og det er egentlig hele greia. Med den type brytere så kan man... Men hvordan, det skal vi se på i detalj. Pemos er broren til NMOS. Bortsett fra at den virker helt motsatt. Han kunne tenkt seg at man... Logisk sett hadde man ikke trengt å ha denne. Man får mye mindre effekttap med denne måten å gjøre det på, å bygge logiske porter av PMOS og NMOS. En PMOS-transistor virker på motsatt måte. Hvis det kommer null inn her, null spenning, så er bryteren på. Da går det strøm igjennom. Hvis det kommer en ener inn, så er den av. Så kommer hele poenget. Hvordan kan man bygge logiske porter ved hjelp av transistor? Som vi så på tidligere, så kan alle logiske operasjoner, de kan utføres hvis man har and-or-or-not-porter. Så hvis vi kan bygge dem med de transistorene, så kan vi.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0019", "start": 1324.48, "end": 1417.8, "token_count": 296, "text": "Hvordan kan man bygge logiske porter ved hjelp av transistor? Som vi så på tidligere, så kan alle logiske operasjoner, de kan utføres hvis man har and-or-or-not-porter. Så hvis vi kan bygge dem med de transistorene, så kan vi. Her ser vi et eksempel på hvordan man kan bygge en notport av to NMOS og PMOS-transistorer. Det sitter en PMOS her. PMOS var den med en liten runding på. Og så sitter det en NMOS her nede. Her ser vi hele koblingsskjemaet. En notport, det vet vi har en sannhetstabell som dette her. Hvis det kommer en spenning 0 inn, hvis det er 0 her, så skal det komme spenning 1 ut. Det kan vi se at vi får til med disse transistorene. For hvis det kommer 0 her, hva skjer da? Jo, da settes det på null spenning opp her til denne P-mossen her oppe. Og da vil den virke. Den vil skru på bryteren. Så da vil det være en lening fra 5 volt og ned til Y. Og dermed så kommer det en positiv spenning ut her.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0020", "start": 1398.64, "end": 1469.92, "token_count": 286, "text": "Jo, da settes det på null spenning opp her til denne P-mossen her oppe. Og da vil den virke. Den vil skru på bryteren. Så da vil det være en lening fra 5 volt og ned til Y. Og dermed så kommer det en positiv spenning ut her. Samtidig når det kommer en null inn her i NMOS-transistoren her nede, så vil den stenge. Altså den stenger av denne her. Så hvis den ikke stengte av den, så ville det bli en spenningsforskjell, og det ville gå strøm gjennom. Og det er akkurat de spenningsforskjellene som man unngår. Ved å bruke to transistorer så gjør man at det momentant skifter. Hvis man bytter om fra 0 til 1 her, så skifter det momentant om fra 1 til 0. Og det går veldig lite strøm i kretsen. Og så tilsvarende. Hvis vi nå switcher, og så setter på en spenning her. Så ser vi, da vil det gå en ener ned hit. Denne vil åpnes. Skru på den bryteren.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0021", "start": 1453.2, "end": 1538.88, "token_count": 287, "text": "Og det går veldig lite strøm i kretsen. Og så tilsvarende. Hvis vi nå switcher, og så setter på en spenning her. Så ser vi, da vil det gå en ener ned hit. Denne vil åpnes. Skru på den bryteren. Dermed går det strøm gjennom her, og du får en positiv spenning ut her. Og tilsvarende en ener inn her vil lukke denne transistoren, sånn at du ikke går strøm ut hit. Uansett så har vi nå laget en port som er sånn at kommer det null spenning inn, så går det én positiv spenning ut. Kommer det positiv spenning inn, så kommer det null spenning ut. Og dette er den aller minste byggescenen i en datamaskin. Ved hjelp av sånne brytere så kan man da bygge hva som helst. Det vil si, man kan ikke bygge hva som helst med en nattport. Man trenger også or og and. Og or og and er litt mer kompliserte. Begge to. Da trenger man seks transistorer for å lage den riktige logikken.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0022", "start": 1507.16, "end": 1603.44, "token_count": 295, "text": "Ved hjelp av sånne brytere så kan man da bygge hva som helst. Det vil si, man kan ikke bygge hva som helst med en nattport. Man trenger også or og and. Og or og and er litt mer kompliserte. Begge to. Da trenger man seks transistorer for å lage den riktige logikken. Her blir det litt mer innfløkt. Men hvis man setter seg ned og ser på dette, så er det ganske enkelt å overbevise om alle mulighetene. A og B skal da være 0, 0, 1, 1, 0 og 1, 1. Så kan man se på hver av de. B er 0, da stenges denne bryteren. Hvis A er 1, så åpnes denne, osv. Så kan man finne ut at den virker akkurat som den skal. Hvis det kommer 0-0 inn her, så kommer det 0 ut der. Hvis det kommer 0-1, så vil det alltid komme 1 ut her som resultatet. Og så ser vi da, med seks transistorer, så kan vi da bygge en sånn or-port fysisk. Og den blir da brent inn...", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0023", "start": 1576.64, "end": 1669.44, "token_count": 283, "text": "Hvis det kommer 0-0 inn her, så kommer det 0 ut der. Hvis det kommer 0-1, så vil det alltid komme 1 ut her som resultatet. Og så ser vi da, med seks transistorer, så kan vi da bygge en sånn or-port fysisk. Og den blir da brent inn... Man lager transistorene, og så brenner man dette inn i små kretskort. Og så får man ut akkurat det man ønsker. Tilsvarende har man for ranporten. At man får dens virkemåte. Ved å sette sammen seks transitorer på en litt annen måte, som da gir en annen port. Ja. Så det vi ønsker å oppnå som sluttresultat... Altså helt til slutt i dag så skal vi ha en krets som legger sammen to tall. Generelt, det vi ønsker å oppnå, er binære funksjoner, At det kommer inn input abc. Dette kan da f.eks. være tall. Og så kommer det ut funksjoner i andre enden, f av abc og g av abc. Og da kunne f.eks. denne funksjonen være...", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0024", "start": 1646.04, "end": 1743.96, "token_count": 293, "text": "Generelt, det vi ønsker å oppnå, er binære funksjoner, At det kommer inn input abc. Dette kan da f.eks. være tall. Og så kommer det ut funksjoner i andre enden, f av abc og g av abc. Og da kunne f.eks. denne funksjonen være... Være en sum av... La oss si du har def også her. Abc pluss def som to tall. De til sammen gir det resultatet som kommer ut her. Eller at man har satt sammen not eron, not all and, sånn at man får ut akkurat den funksjonen man ønsker. Og for å kunne lage alle typer CPU-operasjoner, så trenger man generelt å kunne lage alle mulige slags binære funksjoner. En liten repetisjon av and or not fra forrige gang, var for å se hvordan... For de skal vi da bruke hele tiden når vi bygger de logiske funksjonene. Her ser vi and-tabellen. Og i digital teknikk er det vanlig å bruke et gangetegn, a ganger b. For dere som har hatt diskré matematikk, har dere typisk brukt dette tegnet av and. Det er samme operasjon.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0025", "start": 1724.72, "end": 1810.2, "token_count": 292, "text": "Her ser vi and-tabellen. Og i digital teknikk er det vanlig å bruke et gangetegn, a ganger b. For dere som har hatt diskré matematikk, har dere typisk brukt dette tegnet av and. Det er samme operasjon. I bolsk algebra vil du ha uttrykk som dette. Null ganger null er null. Vi ser at alle disse uttrykkene stemmer med vanlig algebra. Dette er et symbol for en annen port. Det kommer A og B inn fra venstre, og ut på høyresiden får man A ganger B. Tilsvarende for År. I digital teknikk skriver man det vanlig som A pluss B. Dere er kanskje vant til... Noen av dere er vant til A eller B på denne måten? Og igjen så er dette bolsk algebra. Null pluss null er null. Her ser vi at det er én forskjell. Dette ligner jo på vanlig algebra. Helt fram til hit. Én pluss én er én. Og der vil de fleste susse, som er vant til... Men én pluss én er én. Det betyr at hvis det kommer to enere inn i en orf-port, så skal det gå en ener ut også.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0026", "start": 1793.08, "end": 1882.3, "token_count": 290, "text": "Helt fram til hit. Én pluss én er én. Og der vil de fleste susse, som er vant til... Men én pluss én er én. Det betyr at hvis det kommer to enere inn i en orf-port, så skal det gå en ener ut også. Not, som vi så veldig nær på hvordan man bygger fysisk. Den er veldig enkel. Kommer det null inn, så kommer det en ener ut. I digital teknikk så vil en strek over... I diskré matematikk brukte dere dette tegnet, og det som er mer vanlig i logikk sånn generelt. Så er dette tegnet for not. Det betyr det samme. Sannhetstabell er viktig for det vi skal jobbe med. En sannhetstabell er en tabell som sier nøyaktig hvordan en logisk funksjon er. Og denne skal vi da bruke når vi f.eks. skal legge sammen tall. Så har vi noen ideer om hvordan skal disse a-ene og b-ene kobles sammen. Hva skal vi ha ut? Og denne fa-b-en her er bare et eksempel på en sannhetstabell. Det er et eksempel på en logisk funksjon.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0027", "start": 1860.0, "end": 1956.38, "token_count": 279, "text": "Og denne skal vi da bruke når vi f.eks. skal legge sammen tall. Så har vi noen ideer om hvordan skal disse a-ene og b-ene kobles sammen. Hva skal vi ha ut? Og denne fa-b-en her er bare et eksempel på en sannhetstabell. Det er et eksempel på en logisk funksjon. Og da er det rett og slett spesifisert på den måten at man setter av... Alle mulige verdier for A og B. Og så må man spesifisere i hvert tilfelle hva den logiske funksjonen skal bli. F.eks. hvis A lik 0 og B lik 0, altså ikke kommer spenning inn på noen av portene, da skal det være en positiv spenning ut. Og tilsvarende for de andre linjene. Logisk uttrykk. Det vi som regel gjør, er at vi vet sannhetsstabellen. Vi vet hva vi ønsker å få til, hva vi ønsker å skape med den logiske kretsen vår. Men så trenger vi å kunne tegne det med ære. Det er her de logiske uttrykkene kommer inn.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0028", "start": 1920.0, "end": 2023.82, "token_count": 298, "text": "Logisk uttrykk. Det vi som regel gjør, er at vi vet sannhetsstabellen. Vi vet hva vi ønsker å få til, hva vi ønsker å skape med den logiske kretsen vår. Men så trenger vi å kunne tegne det med ære. Det er her de logiske uttrykkene kommer inn. Gitt en sandhetsstabell, vi ser nå på to variabler, men vi kan også ha mange variabler. Fire variabler f.eks. Da kan man helt tilsvarende sette opp sandhetsstabeller. Med fire variabler blir det 16 forskjellige linjer i sandhetsstabellen. Men uansett så kan man på samme måte ut ifra Sandnes-stabellen, så kan man skrive ned et logisk uttrykk. Det er en systematisk måte å gjøre det på. Og det man gjør, den teknikken man bruker for å få til det, det er at man ser på at et sånt som er et produkt A ganger B, det vil kun være lik én hvis både A og B er like. I alle andre tilfeller så vil det produktet være lik null. Så hvis man da tar en... Så plukker man ut alle linjene i sannhetstabellen som skal være én.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0029", "start": 2000.02, "end": 2086.08, "token_count": 298, "text": "det er at man ser på at et sånt som er et produkt A ganger B, det vil kun være lik én hvis både A og B er like. I alle andre tilfeller så vil det produktet være lik null. Så hvis man da tar en... Så plukker man ut alle linjene i sannhetstabellen som skal være én. Og så lager man det... Og så lager man det produktet, det logiske produktet, som er sånn at det blir lik én i dette tilfellet. Det blir litt teoretisk, men vi kan se på for eksempel den... Skal vi se hvilket eksempel bruker jeg her... Jo, den første. I dette tilfellet så er det to ledd i sannhetstabellen som er igjen. Og da tar vi det... Hvis A og B skal bli lik 1, altså hvis A ganger B skal bli lik 1, så må jo... Da må vi gange sammen ikke A, gange ikke B. Altså hvis vi setter en not på a og en not på b, da får vi 1, og da får vi ut produktet 1. Så det vi da må gjøre, er å ha med dette leddet. Det er det første leddet man må ha med i den summen", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0030", "start": 2065.16, "end": 2145.1, "token_count": 288, "text": "så må jo... Da må vi gange sammen ikke A, gange ikke B. Altså hvis vi setter en not på a og en not på b, da får vi 1, og da får vi ut produktet 1. Så det vi da må gjøre, er å ha med dette leddet. Det er det første leddet man må ha med i den summen som skal utgjøre hele det logiske uttrykket. Hvis du har med dette leddet her, så er du sikker på at det leddet... Hvis a er 0 og b er 0, så blir dette leddet 1. Det smarte da er at da kan man starte med dette leddet, og så kan man legge til eller ta med en pluss, eller en logisk eller. Man tar med pluss og legger til alle de andre leddene i Sandnes-stabellen som skal bli én. I vårt tilfelle er det bare ett annet ledd som skal bli én. Det er dette leddet her. Og for å få med et produkt som alltid gir 1, så må dette bare være A ganger B. A ganger B er alltid 1 hvis A og B er 1. I alle andre tilfeller blir det 0.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0031", "start": 2123.72, "end": 2210.8, "token_count": 290, "text": "I vårt tilfelle er det bare ett annet ledd som skal bli én. Det er dette leddet her. Og for å få med et produkt som alltid gir 1, så må dette bare være A ganger B. A ganger B er alltid 1 hvis A og B er 1. I alle andre tilfeller blir det 0. Så hvis vi legger til A ganger B til dette leddet her, så vil vi få, som vi ser her nede, så får vi dette uttrykket som da er hele det logiske uttrykket for... Hele denne sannhetsstabellen. Dette oppsummerer hva vi gjør. Vi skriver ned tilsvarende uttrykk for alle linjer som gir 1 i sannhetsstabellen. I vårt tilfelle så var det to sånne linjer som ga 1. Og så til slutt så legger vi sammen alle disse med or. Og da blir det riktig for at... Ikke sant, sånn som a ganger b? At denne gir en logisk ener. I alle andre tilfeller så gir dette null. Men det å legge til null, det endrer ikke uttrykket. Hvis du har en variabel a pluss null, det gir a.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0032", "start": 2182.42, "end": 2267.92, "token_count": 288, "text": "Og da blir det riktig for at... Ikke sant, sånn som a ganger b? At denne gir en logisk ener. I alle andre tilfeller så gir dette null. Men det å legge til null, det endrer ikke uttrykket. Hvis du har en variabel a pluss null, det gir a. Så det endrer ikke noe på uttrykket. Og dermed vil vi oppnå at denne logiske funksjonen her alltid er riktig. Så... De detaljene her er ikke så ekstremt viktige. Men det som er veldig viktig, det er, hvis vi går tilbake til sandelstabellen, at gitt en sandelstabell, så kan vi bare skrive ned med de enkle reglene vi ser, et logisk uttrykk. Og det er det logiske uttrykket som vi trenger. For nå skal vi ta det logiske uttrykket, og så skal vi tegne en kredits. Og da er vi på en måte i mål. Ja. Da har vi startet med en sannhetstabell, og så har vi skrevet ned et logisk uttrykk for den sannhetstabellen. Og da kan vi begynne å tegne krets.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0033", "start": 2250.0, "end": 2328.16, "token_count": 296, "text": "Og da er vi på en måte i mål. Ja. Da har vi startet med en sannhetstabell, og så har vi skrevet ned et logisk uttrykk for den sannhetstabellen. Og da kan vi begynne å tegne krets. Og når vi har tegnet en krets, så kan vi bare sende inn til Intel og be dem om å brenne denne kretsen, og så får vi hardware som er akkurat som Men først må vi tegne kretsen. Det er ganske enkelt, for da har vi ledninger A og B som kommer inn her. Så må man sette spenning over. Og så, når man har et uttrykk som det her, A ganger B pluss A ganger B, så tenker vi oss først at først må jeg ha A ganger B. Og A ganger B, da trenger jeg en and-port. Og den har jeg her. Så da kommer A ganger B ut her på høyre side. Så trenger jeg å legge til, eller... legge til med en år, som jeg skal se... Jeg trenger å legge til dette uttrykket. Not A ganger Not B. Og da kan jeg bare sette på to not-porter her oppe av.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0034", "start": 2307.96, "end": 2388.28, "token_count": 282, "text": "Så da kommer A ganger B ut her på høyre side. Så trenger jeg å legge til, eller... legge til med en år, som jeg skal se... Jeg trenger å legge til dette uttrykket. Not A ganger Not B. Og da kan jeg bare sette på to not-porter her oppe av. For da kommer det en kabel her med A. Så går den inn i not-port. Da kommer ikke-A ut på andre siden. Og så kommer ikke-B her. Og de sendes inn and-port. Her står det en pluss, det er en år. Så da er det bare å ta de to, a ganger b og ikke a ganger b, og legge inn i årporten. Og vips, så har vi kretsen vi ønsker. Hvis vi har flere ledd her, så er det bare å legge dem inn i samme årport. Eller man kan også ha flere årporter. Hvis man har a ganger b ganger c, så kan man også legge det inn. Og på den måten så kan man skrive ned hardware for enhver logisk krets. Og så... Før man da... Før man da sender inn til brenning av kretser,", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0035", "start": 2362.52, "end": 2467.94, "token_count": 298, "text": "Eller man kan også ha flere årporter. Hvis man har a ganger b ganger c, så kan man også legge det inn. Og på den måten så kan man skrive ned hardware for enhver logisk krets. Og så... Før man da... Før man da sender inn til brenning av kretser, så ønsker man gjerne å forenkle. Så... Det man... Ja. Bare for å vise litt forenkling, så kan vi se på en krets. For det første... Hva blir den bolske funksjonen for denne her? Jo, her ser vi at vi har to enere. Så den bolske funksjonen for dette her må bli ikke A ganger B pluss A ganger B. Ja, vi kan jo ta det her. Ikke A ganger B, det er det første uttrykket her, pluss A ganger B, siden dette også skal gi en ener. Dette logiske uttrykket vil alltid oppfylle sannhetstabellen, fordi det gir ener i de to tilfellene og null i de to andre. Men så kan man jo da tegne opp dette som en krets. Her har jeg tegnet opp denne kretsen. Men det vi skal se på nå, er hvordan kan man forenkle denne kretsen.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0036", "start": 2440.02, "end": 2548.34, "token_count": 300, "text": "Dette logiske uttrykket vil alltid oppfylle sannhetstabellen, fordi det gir ener i de to tilfellene og null i de to andre. Men så kan man jo da tegne opp dette som en krets. Her har jeg tegnet opp denne kretsen. Men det vi skal se på nå, er hvordan kan man forenkle denne kretsen. Igjen så blir dette mer sånn ingeniørmessig. Kretsen virker som den skal. Men man kan spare enormt med porter hvis man forenkler kretser. Og det kan også gjøres på en sympatisk... Ikke sympatisk, men systematisk. Og det er at man først forenkler, og så brenner man kretsen. Ser det kommer en spoiler-alert her i chatten. Det er faktisk helt riktig, og det ser jo litt utrolig ut. Men vi skal se på etter pausen, hvordan man kan generelt forenkle det. Den er en liten spoiler av løk. Prøv å se på dette i pausen. Hvorfor er egentlig... Hvorfor er dette riktig? At f er lik b? OK. Men da tar vi en liten, eller et kvarters pause der. Vi tar pause til 9.30, så starter vi igjen da.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0037", "start": 2524.98, "end": 2669.98, "token_count": 300, "text": "Prøv å se på dette i pausen. Hvorfor er egentlig... Hvorfor er dette riktig? At f er lik b? OK. Men da tar vi en liten, eller et kvarters pause der. Vi tar pause til 9.30, så starter vi igjen da. ... og det er veldig vanskelig å forstå hva som skjer. Sånn. Der er også opptak i gang. Før vi fortsetter, så var det noen spørsmål i pausen, så jeg skal gå gjennom det. Og så tenkte jeg også å kjøre en liten quiz, eller en liten poll, på noen av disse kretsene. Bare så dere kan prøve dere litt. Og vise hva dere har fått med dere. Men aller først, det var et spørsmål... Nei, ikke kaot, bare en zoompoll. Kanskje det kommer noe kaot etter hvert. Skal vi se. Jeg skal dele slidene først. Men om denne kretsen her, og spesielt hvordan... Hvis det kommer en positiv spenning inn her ved X, altså XL1... Hvorfor det da går... Hvorfor det da kommer null ut? Fordi... Ja-spørsmålet var vel... Hvis det kommer en ener inn her, så...", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0038", "start": 2640.02, "end": 2729.96, "token_count": 298, "text": "Men om denne kretsen her, og spesielt hvordan... Hvis det kommer en positiv spenning inn her ved X, altså XL1... Hvorfor det da går... Hvorfor det da kommer null ut? Fordi... Ja-spørsmålet var vel... Hvis det kommer en ener inn her, så... Skrus jo denne bryteren på, og da går det strøm herfra og opp hit. Og hvis det går strøm, er ikke da den også en ener? Men dette gjelder spenninger, så det er på en måte... Problemstillinga er hvis du måler spenningen som er her på Y i forhold til null. Hva får du da? Og da vil det være sånn at når... Når en ener kommer inn, altså når det er positiv spenning hos X, så er det riktig. Da skrus den bryteren på, og da tilsvarer det at det går en ledning herfra. Altså fra null volt så går det en ledning og opp til y. Og da vel, siden dette er en ledning, en kobberledning som leder veldig godt, så vil det på y, så vil det da være null spenning. Når du setter på spenning her, så åpnes porten.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0039", "start": 2711.24, "end": 2796.3, "token_count": 292, "text": "Altså fra null volt så går det en ledning og opp til y. Og da vel, siden dette er en ledning, en kobberledning som leder veldig godt, så vil det på y, så vil det da være null spenning. Når du setter på spenning her, så åpnes porten. Denne blir strømførende, og det blir en ledning som går da direkte fra jord, fra 0 volt og opp til y. Så hvis du da måler spenningen her på y, så vil du få null. Så... Skrur du på den bryteren her, så betyr det at da er det en ledning mellom y og null, og da vil den være null. Vi skal ikke bruke veldig mye tid på dette og se på det i detalj, men ideen, eller hovedtanken, er at da kan dere se at dette... Sånn funker det. Og sånn er det mulig å få til alle de andre bitene også. Det er mer sånn at hvis det skjedde en tredje verdenskrig og alt gikk tapt, så skulle dere ved hjelp av de ideene her, Så skulle dere kunne tenke dere frem til hvordan kan man lage neste generasjon datamaskiner", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0040", "start": 2773.26, "end": 2871.46, "token_count": 292, "text": "Og sånn er det mulig å få til alle de andre bitene også. Det er mer sånn at hvis det skjedde en tredje verdenskrig og alt gikk tapt, så skulle dere ved hjelp av de ideene her, Så skulle dere kunne tenke dere frem til hvordan kan man lage neste generasjon datamaskiner ved hjelp av dette her. For det er ganske enkel logikk med denne type brytere som lager all logikk i en datamaskin. Og verre er det ikke, men samtidig blir det komplisert når man setter det sammen. OK. Som sagt, før vi går videre, så tenkte jeg... Og prøve å kjøre en liten tål. Men da skal jeg bare dele en krets først. Skal vi se... Nå ser dere forhåpentligvis en liten krets. Og spørsmålet e, hva blir det logiske uttrykket FAB for denne kretsen? Hvor første spørsmål er...? Den vises hos meg i hvert fall. Nå er det noen som svarer også, så da funker det. Det er to spørsmål. Det første, hva blir det logiske uttrykket for kretsen på bildet?", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0041", "start": 2836.54, "end": 2951.24, "token_count": 300, "text": "Og spørsmålet e, hva blir det logiske uttrykket FAB for denne kretsen? Hvor første spørsmål er...? Den vises hos meg i hvert fall. Nå er det noen som svarer også, så da funker det. Det er to spørsmål. Det første, hva blir det logiske uttrykket for kretsen på bildet? Og det neste er, hva kan kretsen forenkles til? Det går an å gjøre en forenkling på den kretsen. Bruk gjerne et... ja, folk er i gang med svaret. Bruk gjerne litt tid på å se på det. Ine? Ja. Nå er Ine her, så når som helst i forelesningen så send spørsmål i chatten. Enten til alle eller til Ine direkte, så kan hun svare. Altså Ine, man ser ikke hva de andre svarer, ikke sant, på den pollen? Jeg tror ikke det, jeg kan teste å bare svare noe tilfeldig. Jeg bare ser hva som skjer, hvordan du ser ut. Nei, da forsvinner den hos meg etterpå. Jeg får bare opp den, og så får jeg spørsmålene, og når jeg da har svart, så forsvinner den.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0042", "start": 2929.96, "end": 3094.8, "token_count": 300, "text": "Jeg tror ikke det, jeg kan teste å bare svare noe tilfeldig. Jeg bare ser hva som skjer, hvordan du ser ut. Nei, da forsvinner den hos meg etterpå. Jeg får bare opp den, og så får jeg spørsmålene, og når jeg da har svart, så forsvinner den. Ja, den er grei. Da... Tenk litt mer... Jeg ser halvparten av dere har svart. Bruk gjerne litt mer tid og prøv å tenke til svar. Dette er anonymt i tillegg, så ingenting vil... Det vil bli lagret, så ikke vær redd for å slenge av gårde et svar. Så skal vi se litt på svarene etterpå og prøve å forklare hvilke svar som er riktige. Jeg kan jo prøve det mens dere svarer. Det jeg tenkte å gjøre, var å tegne på et ark. Nå skal jeg se om jeg klarer å vise det til dere. Ja... Nå ser jeg 74 % av svart. Vi kan ta et minutt til, vi. Så stopper jeg pollen om 50 sekunder, og så ser vi på svarene. Ine er klar. Hvor lang tid har du å se hva jeg tegner, da?", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0043", "start": 3017.56, "end": 3175.9, "token_count": 293, "text": "Ja... Nå ser jeg 74 % av svart. Vi kan ta et minutt til, vi. Så stopper jeg pollen om 50 sekunder, og så ser vi på svarene. Ine er klar. Hvor lang tid har du å se hva jeg tegner, da? Den... siden når du har delt skjermen, så blir bildepokalen litt lite. Jeg ser det sånn lite grann, og så er den opp ned. Opp ned, ja. Eller for meg, da. Å ja. Er den riktig vei nå? Nei, det var ikke opp ned i stad. Jeg tror kanskje bilde av fryste eller noe sånt, for jeg har ikke sett at det endrer seg. Ja, akkurat. Men jeg kan prøve å stoppe å dele, så kan vi se om det ser bedre ut da. Ja, for den var litt liten mens den skjermdelingen var på. Ja, et øyeblikk. Sånn. Hvordan ser det ut nå, kan du se tegningen? Ja, jeg ser den. Ja, flott. Så det jeg tegner opp nå, er bare den tegningen som vi hadde i oppgaven? Så kommer F ut der. Da kan vi stoppe. Da ser jeg 80-80.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0044", "start": 3150.0, "end": 3278.88, "token_count": 293, "text": "Sånn. Hvordan ser det ut nå, kan du se tegningen? Ja, jeg ser den. Ja, flott. Så det jeg tegner opp nå, er bare den tegningen som vi hadde i oppgaven? Så kommer F ut der. Da kan vi stoppe. Da ser jeg 80-80. Det er kjempebra. Da stopper jeg og så deler jeg resultatene. Ine, kan du se resultatene fra pollen nå? Ja, jeg får opp sånn prosentvis på svarene, og så markert med farge. Ja, da kan vi se på det første svaret. Og her ser vi at tre fjerdedeler av dere har svart A ganger B pluss B. Og det er kjempebra, for det er helt riktig. For det som skjer her, er at dette er en anport. Og da er det A og B kommer inn i anporten. I tillegg tar man en kabel fra B her og inn i denne årporten. Dette er en and, og dette er en år. Da kommer det inn i årporten, og da vil det som kommer ut da, være a ganger b pluss er år, pluss den b-en som kommer derfra. Veldig bra. En stor del av dere hadde fått med seg dette.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0045", "start": 3248.06, "end": 3345.12, "token_count": 285, "text": "Dette er en and, og dette er en år. Da kommer det inn i årporten, og da vil det som kommer ut da, være a ganger b pluss er år, pluss den b-en som kommer derfra. Veldig bra. En stor del av dere hadde fått med seg dette. Neste spørsmål er litt vanskeligere. Hva kan kretsen forenkles til? Og det er jo ikke så opplagt. Jeg kan se på et par måter å forenkle på. En måte er å ta utgangspunkt i det uttrykket. A ganger B pluss B. Ikke at vi skal drive veldig mye med bolsk algebra, men det er fint å være klar over muligheten. I bolsk algebra så kan man faktisk bruke en del av de metodene som man bruker i vanlig algebra. F.eks. kan jeg sette B utenfor parentes, akkurat som om det skulle vært vanlig algebra, og så skrive A pluss 1. Og A pluss 1. Det er altså A år 1. Og man vet om en årport hvis man får inn en ener på en... Hvis én av inputene er én, så er årporten alltid én.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0046", "start": 3323.46, "end": 3412.54, "token_count": 293, "text": "akkurat som om det skulle vært vanlig algebra, og så skrive A pluss 1. Og A pluss 1. Det er altså A år 1. Og man vet om en årport hvis man får inn en ener på en... Hvis én av inputene er én, så er årporten alltid én. Så det betyr det er en identitet i bord skalgebra at A pluss én, det er rett og slett én. Så dette her vil da være lik én ganger B. Og én and B... Det er også en identitet. Den vil alltid være lik B. Så riktig svar på den... Det har også flertallet fått til. Veldig bra. 43 % har svart at man kan forenkle den til en B. Det går også an å se dette her ved å prøve og feile. Så man kan f.eks. si sånn OK... Hvis det kommer en ener inn i B-en, så går den borti overporten. Og hvis det kommer en ener inn i overport, så kommer det alltid en ener ut. Så i det tilfellet at B ligger 1, da er det B. Hvis B er 0, så kommer det en 0 inn i overporten.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0047", "start": 3390.02, "end": 3478.8, "token_count": 294, "text": "Hvis det kommer en ener inn i B-en, så går den borti overporten. Og hvis det kommer en ener inn i overport, så kommer det alltid en ener ut. Så i det tilfellet at B ligger 1, da er det B. Hvis B er 0, så kommer det en 0 inn i overporten. Så det som kommer ut til slutt, er det som kommer inn her. Men hvis B er 0, så vil det da komme 0 inn i overporten. Så vil det gå en null inn der. Og da får man null ut. Dermed kan man også på den måten se at OK, dette er... Uttrykket er lik B. En siste måte å se dette på, det er å rett og slett skrive opp sannhetsstabellen. Det kan man alltid gjøre. Jeg skriver opp standardstabellen og sier at hvis jeg sjekker punkt for punkt... Hvis 0-0 kommer inn, så finner jeg ut at da kommer 0 ut. Hvis 0-1 kommer inn, så ser jeg hva alt blir. Da kommer en ener ut. Hvis 1-0 kommer inn, hva blir det da? Jo, da kommer det en null ut. Sjekker alle portene osv.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0048", "start": 3455.56, "end": 3575.46, "token_count": 292, "text": "Hvis 0-0 kommer inn, så finner jeg ut at da kommer 0 ut. Hvis 0-1 kommer inn, så ser jeg hva alt blir. Da kommer en ener ut. Hvis 1-0 kommer inn, hva blir det da? Jo, da kommer det en null ut. Sjekker alle portene osv. Og så kan jeg rett og slett fra sandenstabellen se at... OK, men her ser vi at F er lik B, faktisk. I alle tilfeller så er F lik B. Så da kan vi bare lese ut fra sandenstabellen og se at en F er lik B. Sånn kan man forklare svaret på de to Poll-resultatene. Ok. Fint. Da skal vi gå videre. Og som jeg har sagt noen ganger, det er ikke så ekstremt viktig å kunne alle detaljene om obolske algebra osv. Men det er viktig å få med seg... Prinsippet er at hvis vi kjenner sannhetstabellen, så kan vi skrive ned en logisk krets. Og så kan vi faktisk da fysisk brenne og lage denne kretsen. Så tilbake til slidene. Da kan jeg kanskje bare endre... Bilde her også.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0049", "start": 3540.0, "end": 3678.2, "token_count": 294, "text": "Prinsippet er at hvis vi kjenner sannhetstabellen, så kan vi skrive ned en logisk krets. Og så kan vi faktisk da fysisk brenne og lage denne kretsen. Så tilbake til slidene. Da kan jeg kanskje bare endre... Bilde her også. Oi, det er... så jeg litt mer ut som... Et lite øyeblikk her. Oi. Ine, hører du meg? Ja. Du ser veldig morsom ut. Der. Det er tydeligvis et eller annet galt med screen her nå. Jeg blir rosa og grønn innimellom, så det hender den tuller litt. Det ble litt surrende, bittert kamera her. Men... Jeg fikk en beskjed om at den stoppet, men du kan høre meg fortsatt? Ja, hører deg og... jeg ser deg. Du er en litt mørk stripe i ansiktet, men ellers så syns det greit. Det har skjedd noen ganger at jeg har blitt rosa, og så har den stabilisert seg litt etter hvert, så vet ikke om... Kanskje det skjer. Jeg kan bare prøve å skifte... Nei, det hjelper ikke.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0050", "start": 3655.28, "end": 3778.66, "token_count": 283, "text": "men ellers så syns det greit. Det har skjedd noen ganger at jeg har blitt rosa, og så har den stabilisert seg litt etter hvert, så vet ikke om... Kanskje det skjer. Jeg kan bare prøve å skifte... Nei, det hjelper ikke. Ja, det er ikke så viktig. Jeg kan egentlig... Ja, da tar jeg bare vanlig green screen, så... OK. Det var noen spørsmål i chatten her som vi kan ta først. Er det slik at den siste kretsen er en forenkling av den foregående, siden begge kunne forenkles til FRLigB? I forhold til den vi antar spørsmålet er, Denne kretsen. Og den forenkler seg også til B. Men det er egentlig mer tilfeldig. Det er en forskjellig krets, men den... tilfeldigvis forenkles den til B. Ine, bare ett spørsmål. Ser du sliden her nå OK? Ja, nå ser du også helt normal ut. Så alt er bra. Ikke helt normal, kanskje, men sånn du pleier. Ikke som en superhelt i hvert fall.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0051", "start": 3740.62, "end": 3851.98, "token_count": 294, "text": "Det er en forskjellig krets, men den... tilfeldigvis forenkles den til B. Ine, bare ett spørsmål. Ser du sliden her nå OK? Ja, nå ser du også helt normal ut. Så alt er bra. Ikke helt normal, kanskje, men sånn du pleier. Ikke som en superhelt i hvert fall. Det vi så på var hvordan kan denne kretsen forenkles, og da kom en spoiler-alert. Denne kretsen er bare lik B. I første omgang kan vi se dette sånn som jeg gjorde fra Sandnes-stabellen. En annen måte å se på det på er å bruke Bolsk-algebraa og forenkle. Da er det noen identiteter i Bolsk-algebraa som er enkle å skrive ned. I Bolsk-algebraa er det bare to muligheter. Enten A er 0 eller 1, så vil alltid dette være 1. Hvis X er 0, så er 1 og 0 er 0. Hvis X er 1, så er 1 og 1 1. Så kan man forenkle sånn som dette her, som jeg gjorde, man kan sette B utenfor i en parentes, og ikke A pluss A, det er én.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0052", "start": 3828.04, "end": 3906.84, "token_count": 284, "text": "Enten A er 0 eller 1, så vil alltid dette være 1. Hvis X er 0, så er 1 og 0 er 0. Hvis X er 1, så er 1 og 1 1. Så kan man forenkle sånn som dette her, som jeg gjorde, man kan sette B utenfor i en parentes, og ikke A pluss A, det er én. Dermed får man én og B. Én og B er alltid B, så dette er B. Og dermed så kan denne kompliserte kretsen forenkles til bare en direkte kobling mellom B og F. Det er klart. Det er klart at dette er... det er veldig viktig å gjøre den type forenklinger for at kretsene ikke skal bli så kompliserte. Men i prinsippet kunne man bare levert inn de tegningene på den opprinnelige stabellen. Men da ville man ikke kunne ha like høy klokke, folkens, på CPU-en man lager. Så dette er mer en sånn ingeniørmessig ting, at man forenkler før. Før man tegner og brenner kretsen, for at den skal bli mer effektiv.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0053", "start": 3881.28, "end": 3970.8, "token_count": 293, "text": "Men i prinsippet kunne man bare levert inn de tegningene på den opprinnelige stabellen. Men da ville man ikke kunne ha like høy klokke, folkens, på CPU-en man lager. Så dette er mer en sånn ingeniørmessig ting, at man forenkler før. Før man tegner og brenner kretsen, for at den skal bli mer effektiv. OK. Vi startet ut med at vi ønsket å lage en krets som utfører binær addisjon mellom to binære tall. Det vi må gjøre da, er at vi må implementere... Algoritmen for å legge sammen binært må vi implementere med logiske funksjoner. Etter vi har gjort det, kan vi tegne en krets som utfører det vi ønsker. Da må vi først se på hvordan virker binær adhesjon. Den virker nøyaktig som, om dere ikke har gjort dette før, så er metoden nøyaktig sånn som når man legger sammen desimaltall. Med mente osv. Vi kan se på hvordan vi legger sammen to tall her. Dette er 01 pluss 11. 01 er jo tallet 1. Det er en 0 toere og en ener.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0054", "start": 3947.12, "end": 4016.4, "token_count": 279, "text": "Den virker nøyaktig som, om dere ikke har gjort dette før, så er metoden nøyaktig sånn som når man legger sammen desimaltall. Med mente osv. Vi kan se på hvordan vi legger sammen to tall her. Dette er 01 pluss 11. 01 er jo tallet 1. Det er en 0 toere og en ener. Og så legger man til en toer og en ener, som er tallet 3. Man starter her med 1 pluss 1. 1 pluss 1 er jo 2, men binært så er 1 pluss 1 10. Så vi får da 10, og 0 er det siste sifferet, så det skrives ned her. Og så gjør man akkurat samme operasjonen på neste to siffer, da, i det binære tallet. Da er det en ener der, en null der og en ener der. Så det blir igjen én pluss én er to. Og to er én null. Så da kommer en mente opp hit, og så kommer denne eneren ned hit. Og så får man svaret én null null. Og én null null det er da fire.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0055", "start": 3990.0, "end": 4068.4, "token_count": 295, "text": "Og så gjør man akkurat samme operasjonen på neste to siffer, da, i det binære tallet. Da er det en ener der, en null der og en ener der. Så det blir igjen én pluss én er to. Og to er én null. Så da kommer en mente opp hit, og så kommer denne eneren ned hit. Og så får man svaret én null null. Og én null null det er da fire. Så det vi har gjort nå, er å regne ut én pluss tre er lik fire. Tilsvarende algoritme kan man bruke på absolutt alle binære addisjoner. Om du har 64-bit, så kjører du denne algoritmen 64 ganger. Så får du ut svaret. Det vi skal se på nå, er da... Ja, men hva om vi kan lage en krets som gjør akkurat denne operasjonen her. Ta mente og de to sifferne, og så får du ut et svar og et mente. Og det er akkurat det man gjør. Man lager 64 sånne kretser. Og så setter man sammen de 64 kretsene, og vips, så har du en aderi som kan legge sammen 64-bitstall.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0056", "start": 4050.0, "end": 4133.96, "token_count": 300, "text": "Ta mente og de to sifferne, og så får du ut et svar og et mente. Og det er akkurat det man gjør. Man lager 64 sånne kretser. Og så setter man sammen de 64 kretsene, og vips, så har du en aderi som kan legge sammen 64-bitstall. For å få til den fysiske boksen, den lille logiske kretsen, som gjør den ene operasjonen, Så kan man skrive ned sannhetsstabellen for en sånn addisjonskrets. En full adder, kalles det. En sånn boks. Og det er da ganske rett frem å skrive ned sannhetsstabellen. Det er denne operasjonen vi skal gjøre om og om igjen. Vi skal legge sammen X og Y. Og så har vi en mente fra før, Z. Så disse tre byttene er da input X, Y og Z. Og så får vi et svar S her. Da er det ganske enkelt for hver av tilfellene å se hva s og z er. Det første tilfellet vi hadde var at z var 1 og y var 1, og x var 0. Det er det leddet her. Z av 1, i av 1 og x er 0.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0057", "start": 4103.2, "end": 4187.46, "token_count": 281, "text": "Så disse tre byttene er da input X, Y og Z. Og så får vi et svar S her. Da er det ganske enkelt for hver av tilfellene å se hva s og z er. Det første tilfellet vi hadde var at z var 1 og y var 1, og x var 0. Det er det leddet her. Z av 1, i av 1 og x er 0. Hva skal vi få ut da? Jo, da får vi to, så det blir 1-0. S skal være 0 og C være 1. Så får vi en 0 her og en 1 der. Det var den operasjonen vi hadde tidligere. Og tilsvarende kan vi lett sette opp alle de andre. F.eks. hvis alle er 0, da blir det både 0 her og 0 der. Det er den første linja. Og så kan man gå videre sånn. Sånn. Så den generelle metoden... Når man skal lage en bolsk funksjon og putte det inn i en CPU som man kan gjøre en operator. Den anvender vi her i dette tilfellet. Vi skriver ned det bolske uttrykket for de to funksjonene.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0058", "start": 4166.4, "end": 4245.98, "token_count": 286, "text": "Sånn. Så den generelle metoden... Når man skal lage en bolsk funksjon og putte det inn i en CPU som man kan gjøre en operator. Den anvender vi her i dette tilfellet. Vi skriver ned det bolske uttrykket for de to funksjonene. For disse to funksjonene her. Da bruker vi igjen samme metoden. For S så må vi ha med et ledd for hver gang den er én. Så f.eks. det første leddet her. Ikke X, ikke Y, ganger... Altså ikke X, ganger, ikke Y, ganger Z. Og så, etter man har gjort det, så forenkler man med Bolskalgebra. Eller noe som heter Carnot-diagram, som er en mer avansert måte, så man kan utføre ganske kompliserte forenklinger med diagrammer. Vi hadde tidligere et kurs som het datamaskinarkitektur. Da brukte vi Carnot-diagrammer og lagde sånne kretser. Nå ser vi mer på prinsippene, men etter at vi har forenklet, så kan vi da tegne en krets med det bortskrivne uttrykket.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0059", "start": 4225.92, "end": 4306.0, "token_count": 295, "text": "Vi hadde tidligere et kurs som het datamaskinarkitektur. Da brukte vi Carnot-diagrammer og lagde sånne kretser. Nå ser vi mer på prinsippene, men etter at vi har forenklet, så kan vi da tegne en krets med det bortskrivne uttrykket. Som utfører nøyaktig den operasjonen vi ønsker. Så... Først forenkler vi. Så dette er skrevet rett ned fra sandstabellen. Og det er det som dere må sitte igjen med. Har du... Så kan du bare skrive ned kretsen og tegne den og produsere den. Sandhetsstabellen får du fra den logikken du ønsker. Vi ønsket å kunne legge sammen tall. Da skrev vi ned en sandhetsstabell med det innholdet. Og så så vi at det som da skal komme ut av S og C, s er de to funksjonene. Og så kan man med Bols galgebra eller på andre måter vise at f.eks. den funksjonen her, den kan forenkles til dette uttrykket. Og så, når man har gjort forenklinger på begge, så kan man begynne å tegne.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0060", "start": 4278.8, "end": 4364.64, "token_count": 284, "text": "Og så så vi at det som da skal komme ut av S og C, s er de to funksjonene. Og så kan man med Bols galgebra eller på andre måter vise at f.eks. den funksjonen her, den kan forenkles til dette uttrykket. Og så, når man har gjort forenklinger på begge, så kan man begynne å tegne. Nå tegner jeg bare opp C-en. C-en vil la oss se sånn ut. Du får X, Y, Z inn fra venstre, og så får du C-en ut til høyre. Så kan man gjøre det tilsvarende med... Når man har fått til det, kan man sette det sammen til en krets. Eller til en liten boks, en liten komponent, som kalles en full adder. En full adder gjør nøyaktig den operasjonen vi så på. Ved å legge sammen de sifrene her, sett deg mente, og så får den ut ett siffer. Summen og én carry, eller en mente, som da går videre til neste operasjon. Og det som er flott nå, når du har fått laget en liten boks som gjør dette her,", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0061", "start": 4338.6, "end": 4420.56, "token_count": 274, "text": "En full adder gjør nøyaktig den operasjonen vi så på. Ved å legge sammen de sifrene her, sett deg mente, og så får den ut ett siffer. Summen og én carry, eller en mente, som da går videre til neste operasjon. Og det som er flott nå, når du har fått laget en liten boks som gjør dette her, så kan man da sette sammen flere sånne bokser for å utføre regneoperasjoner. Da setter man sammen to sånne fulleidere. Og da ser vi. Den første fulleideren her. I det første leddet er det aldri noe mente. Så den er null. Vi har konstruert denne boksen sånn at her kommer riktig S0 ut, og så kommer riktig C ut her nede, som er mente, som skal sendes videre til neste operasjon. Så da utfører vi den operasjonen med X0 pluss Y0 lik S0 og mente. Og så utføres X1 pluss Y1 pluss mente, blir S1. Det ble første summen. Og så den carrien går opp, og så kommer den ut her.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0062", "start": 4397.74, "end": 4479.14, "token_count": 279, "text": "som skal sendes videre til neste operasjon. Så da utfører vi den operasjonen med X0 pluss Y0 lik S0 og mente. Og så utføres X1 pluss Y1 pluss mente, blir S1. Det ble første summen. Og så den carrien går opp, og så kommer den ut her. Og dermed så har vi på magisk vis lagd en liten boks som kan legge sammen tobitstall. Det er kanskje ikke noe å rope hurra over, men vi kan jo se da at dette kan vi ta videre. Vi kan... Hvis vi ønsker å legge sammen tre-bits tall, så bare legger vi på en fullader til. Og da kommer det tredje bittet i begge de tallene. De skal da inn i denne boksen. Og så ser vi at vi får en operasjon hvor vi utfører den algoritmen som vi lærte på skolen når vi skulle legge sammen tall. Den utføres nå ved hjelp av bit inne i CPU-en. Tallene strømmer bortover her. Og til slutt så kommer svaret ut. Det denne kretsen her gjør, er å legge sammen disse to tallene.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0063", "start": 4459.84, "end": 4555.22, "token_count": 298, "text": "som vi lærte på skolen når vi skulle legge sammen tall. Den utføres nå ved hjelp av bit inne i CPU-en. Tallene strømmer bortover her. Og til slutt så kommer svaret ut. Det denne kretsen her gjør, er å legge sammen disse to tallene. X2, X1, X0. Det kan være f.eks. 101 pluss 001. To binære tall. Og så får vi et svar ut i den andre delen. Så på denne måten så kan man da lage enhver... Hvilken logisk ønsket operasjon kan man konstruere på denne måten? Man setter opp sandelstabellen, skriver ned det logiske bolske uttrykket og forenkler. Og så lager man kretsen. I SPU vil man hele tiden lage denne typen av små operasjoner,  Så setter man de sammen til større operasjoner. Sånn som dette her, som kan da, med 64 sånne fulleidere, så kan man legge sammen 64-bits-tall. Her startet vi i dag tidlig. Dette var det vi ønsket. Og jeg håper dere nå ser hvordan man generelt går fram for å lage en sånn type krets som dette her.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0064", "start": 4531.64, "end": 4635.96, "token_count": 297, "text": "Så setter man de sammen til større operasjoner. Sånn som dette her, som kan da, med 64 sånne fulleidere, så kan man legge sammen 64-bits-tall. Her startet vi i dag tidlig. Dette var det vi ønsket. Og jeg håper dere nå ser hvordan man generelt går fram for å lage en sånn type krets som dette her. Som adderer to firebits-tall. Hvis vi får tid skal vi se litt etterpå på hvordan man kan simulere dette. Men dere vil nå kunne... Det er vel en oppgave denne uken også. Hvor dere blir bedt om å lage en krets som legger sammen... Men det jeg håper dere ser, er hvordan man helt logisk kan sette opp sannhetsstabeller hvor man koder inn den logikken som man ønsker skal skje. Den operasjonen som skal skje med to binære tall. Og så skal man få ut det tredje. Alle mulige logiske operasjoner som man kan tenke seg en CPU trenger å gjøre. Og det er et ganske begrenset antall operasjoner av denne typen. Vi kan tenke oss at du må kunne trekke fra tall. Sammenligne tall, si om de er like eller ulike.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0065", "start": 4604.96, "end": 4688.2, "token_count": 289, "text": "Den operasjonen som skal skje med to binære tall. Og så skal man få ut det tredje. Alle mulige logiske operasjoner som man kan tenke seg en CPU trenger å gjøre. Og det er et ganske begrenset antall operasjoner av denne typen. Vi kan tenke oss at du må kunne trekke fra tall. Sammenligne tall, si om de er like eller ulike. Man må kanskje kunne gjøre skiftoperasjoner som tilsvarer å gange et tall med to. Multiplikasjon, som er en god del mer kompleks, men på samme måte så kan du bruke multiplikasjonsalgoritmene og lage den kretsen du måtte ønske. Divisjon er kanskje enda mer komplisert, men når du har addisjon og subtraksjon, så kan du bygge de andre kretsene. Litt på samme måte. Man vet hvilken logikk man ønsker. Og da kan man skrive ned en sanstabell, så kan man tegne en krets, og så får man akkurat den operasjonen man ønsker. Og så vet vi nå... Inni en notport så er det to transistorer.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0066", "start": 4666.02, "end": 4780.32, "token_count": 296, "text": "så kan du bygge de andre kretsene. Litt på samme måte. Man vet hvilken logikk man ønsker. Og da kan man skrive ned en sanstabell, så kan man tegne en krets, og så får man akkurat den operasjonen man ønsker. Og så vet vi nå... Inni en notport så er det to transistorer. Inni ore og and så er det seks transistorer. Så da ser vi på... Ser vi hvordan en hel CPU er lagd bare av transistorer, som egentlig er bare små brytere som man setter sammen. OK. Ja. Ina, har det vært noen spørsmål som vi burde ta opp? Det har vært noen spørsmål i forhold til den forenklingen og sånt nå. Med funksjonen av portene. Men nå har de gått litt mer gjennom det. Ja, OK. Jeg kan kikke litt på hva dere har spurt om i chatten, så kan jeg eventuelt legge til noe i notatene. Men skal vi se... Det jeg tenkte å prøve å få til nå, var å se lite grann på... Det simuleringsverktøyet som dere skal bruke i oppgavene. Da kan dere laste det ned til egen...", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0067", "start": 4742.9, "end": 4864.8, "token_count": 287, "text": "så kan jeg eventuelt legge til noe i notatene. Men skal vi se... Det jeg tenkte å prøve å få til nå, var å se lite grann på... Det simuleringsverktøyet som dere skal bruke i oppgavene. Da kan dere laste det ned til egen... Hvis dere kjører Windows, så kan dere laste det ned til egen Windows-maskin. Alternativt så kan dere starte den virtuelle maskinen, som virtuelle Windows-VM-en, Så da skal jeg dele... dele det vinduet med dere, så vi kan se på det sammen. Sånn. Her er den virtuelle Windows-maskinen. Og så har jeg lastet ned det verktøyet som... Det sto vel en link i forrige ukes oppgaver. Så kan jeg kjøre det. Men sånn ser dette verktøyet ut. Så når jeg ser av designet, er det heller ikke veldig nytt. Men det funker som det skal. Så dere får noen oppgaver denne uken, eller det er noen oppgaver hvor dere skal laste ned noen komponenter og sette dem sammen. Men helt til slutt i dag, så kan jeg vise noen enkle ting, hvordan man bruker det.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0068", "start": 4836.6, "end": 4920.44, "token_count": 289, "text": "Men det funker som det skal. Så dere får noen oppgaver denne uken, eller det er noen oppgaver hvor dere skal laste ned noen komponenter og sette dem sammen. Men helt til slutt i dag, så kan jeg vise noen enkle ting, hvordan man bruker det. Her oppe så ser dere at vi har forskjellige gates, eller porter som det heter på norsk. Dette her f.eks. er en and-gate. Hvis man klikker på den, og så klikker uti kanna sånn her, så ser du at du får opp en port.  Og så blir dere bedt om å gjøre noen oppgaver hvor dere skal sette sammen sånne porter. For i dette verktøyet kan man logisk sette sammen porter, sånn at de virker sånn som de ville virke hvis man brenner dette og lager det med halvledere. Så da er det noen sånne input man trenger. F.eks. her oppe står det en interaktiv input. Så hvis jeg klikker på den, og så plasserer den ut her. Dette er en bryter som kan skrus på som null og én. Og så ønsker jeg deg å putte den inn i en AND-port.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0069", "start": 4899.54, "end": 4982.56, "token_count": 293, "text": "og lager det med halvledere. Så da er det noen sånne input man trenger. F.eks. her oppe står det en interaktiv input. Så hvis jeg klikker på den, og så plasserer den ut her. Dette er en bryter som kan skrus på som null og én. Og så ønsker jeg deg å putte den inn i en AND-port. Og da er det en liten blyant oppå hjørnet her, Viring Tool. Den vil jeg nå bruke for å koble sammen inputen der til AND-porten. Og da... Venstre-klikker jeg sånn, så har jeg koblet de to sammen. Så kan jeg gjøre det tilsvarende... Jeg ønsker å ha en input til. Da gjør jeg tilsvarende. Hvis man er litt forsiktig, så får man rette og fine linjer. Nå ble den kanskje litt skjev. Sånn. Da har jeg to input, og så ønsker jeg å se hva som blir output her. Her oppe har jeg en ledd. Et lite leddlys. Rødt kan vi tenke oss at det betyr én, mens hvitt eller ingenting, det er null. Og nå har jeg lagd en liten krets.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0070", "start": 4958.94, "end": 5042.42, "token_count": 289, "text": "Sånn. Da har jeg to input, og så ønsker jeg å se hva som blir output her. Her oppe har jeg en ledd. Et lite leddlys. Rødt kan vi tenke oss at det betyr én, mens hvitt eller ingenting, det er null. Og nå har jeg lagd en liten krets. Og så, i utgangspunktet, så... Skal vi se... Så kan vi prøve å kjøre den kretsen. For å kjøre kretsen, så trenger jeg å bruke den hånden der, altså peke. Da kan jeg skru på en ener. Da kommer det en ener inn i anden. Og nå setter jeg på en ener til. Så kommer det to enere. Da burde det jo komme en null ut, men da må vi først kjøre kretsen. Her oppe står det rønn. Så hvis du trykker på rønn nå, så begynner kretsen å kjøre. Da virker kretsen. Og da ser vi... Av én og én, det gir en ener ut. Hvis jeg sender en null inn i en annen port, så får jeg null ut. Sender jeg to nuller, så får jeg også en null.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0071", "start": 5020.98, "end": 5109.72, "token_count": 281, "text": "så begynner kretsen å kjøre. Da virker kretsen. Og da ser vi... Av én og én, det gir en ener ut. Hvis jeg sender en null inn i en annen port, så får jeg null ut. Sender jeg to nuller, så får jeg også en null. Uansett, hvis jeg har en null inn i en annen port, så kommer det null ut. Det er kun hvis det er to enere at jeg får ut en ener. Så på denne måten så... Så kan man da bygge kretser, og så kan man teste det. Jo, des... Det som dere skal gjøre i oppgavene, det er vel å legge inn... Skal vi se om jeg får til det. Legge inn makroer. Skal vi se. Sånn, ja. Da trykker jeg på en bed makro her oppe. Det betyr legge inn en liten boks. I oppgaveteksten står det at dere skal legge inn en fulladder, f.eks. Det var den som vi bygde. Da har jeg lastet ned den til desktopen her, sånn at den har fulladder her. Og så legger jeg inn der. Og da ser vi...", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0072", "start": 5089.96, "end": 5168.24, "token_count": 286, "text": "Det betyr legge inn en liten boks. I oppgaveteksten står det at dere skal legge inn en fulladder, f.eks. Det var den som vi bygde. Da har jeg lastet ned den til desktopen her, sånn at den har fulladder her. Og så legger jeg inn der. Og da ser vi... Da får vi en liten boks som er kodet inn med akkurat den logikken som vi så på. Med de metodene her, altså hvis dere ønsker å ha input til sett, så kan dere legge på en liten boks her, en null sånn, og så lage en wire herfra dit. Og så fortsette sånn. Da kan dere lage kretser. F.eks. skal dere sette sammen to sånne, for å kunne legge sammen to tall. Dette er da teknikken man bruker for å gjøre det. Da kan man også se... Hvis jeg peker på den og høyre klikker, så kan jeg se inne i boksen og se hva det er som foregår her. Og da ser vi. Dette er hele logikken i boksen. XYZ. Dette ser jo enklere ut enn det vi kom fram til,", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0073", "start": 5149.96, "end": 5239.88, "token_count": 294, "text": "Hvis jeg peker på den og høyre klikker, så kan jeg se inne i boksen og se hva det er som foregår her. Og da ser vi. Dette er hele logikken i boksen. XYZ. Dette ser jo enklere ut enn det vi kom fram til, men her er det gjort noen enda mer smarte forenklinger. Og så bruker de noen også noen... Dette er vel en X-over-port. Vi bruker noen andre porter. Du kan uttrykke dette and or not. Det er en enda mer effektiv måte å gjøre det på. Dette er den mest effektive måten å kode en fullader på, med and-or og not-porter. Dvs. dette er en x-or, som igjen er and-og-or-porter. Dermed kan man lage dette med xi og z inn, og riktig c og s ut. Hovedpoenget er da... Da kan man ta... Legge inn flere sånne. Sånne makroer som dette her. Legge inn to og tre boksere av den typen. Og så sette det sammen og få en krets som da legger sammen tall med både to og tre siffer. Sånn, ja. Man må klikke på kanvasen for å få ut det.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0074", "start": 5209.96, "end": 5306.72, "token_count": 292, "text": "Legge inn flere sånne. Sånne makroer som dette her. Legge inn to og tre boksere av den typen. Og så sette det sammen og få en krets som da legger sammen tall med både to og tre siffer. Sånn, ja. Man må klikke på kanvasen for å få ut det. Så kan jeg så... Det man da må gjøre etter hvert, er liksom ta wire... Mente derfra. Det skal jo opp i Z. Så kan man kable det på den måten der. Sette sammen boksene, og vips, så har man... En operasjon... En liten bit av en CPU, som er den biten som legger sammen tall. En hel datamaskin som er bygd på denne måten. Det var en oppgave vi hadde tidligere i Datamaskinarkitektur. Da bygde alle stuntene en hel datamaskin som opererer akkurat som en vanlig CPU, men som er simulert med hand-off-rapporter på denne måten. Oi, men nå ser vi at vi har gått langt over tiden, så jeg trenger i hvert fall dere. En pause? Ikke en pause, men... Jo, en pause, for vi skal ha lab etterpå.", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0075", "start": 5288.06, "end": 5394.96, "token_count": 289, "text": "men som er simulert med hand-off-rapporter på denne måten. Oi, men nå ser vi at vi har gått langt over tiden, så jeg trenger i hvert fall dere. En pause? Ikke en pause, men... Jo, en pause, for vi skal ha lab etterpå. Så som vanlig så lager vi noen sånne... Hva het... Hva kaltes de rommene, Ine? Hjelp meg. Breakout rooms. Yes. Vi lager noen breakout rooms. Og så kan dere gå inn der og stille spørsmål. Sånn én til én. Dere kan også stille spørsmål i chatten, for jeg holder dette rommet oppe ut dagen. Eller iallfall til klokka to. Så ikke nøl med å spørre om hjelp hvis dere står fast. Men da tar i hvert fall jeg en liten pause der. Nei, ok. Men jeg kan opprette det. Ja, det er litt... Kanskje det er noen andre innstillinger enn fra i fjor. Ja, jeg kan se på det senere. Men jeg opprettet det. Yes. Da slutter vi der. Still spørsmål i chatten og vær aktiv i BreakOutRules. Å...", "source": "lecture"}
{"lecture_id": "os2", "chunk_id": "os2_0076", "start": 5359.98, "end": 5636.3, "token_count": 176, "text": "Nei, ok. Men jeg kan opprette det. Ja, det er litt... Kanskje det er noen andre innstillinger enn fra i fjor. Ja, jeg kan se på det senere. Men jeg opprettet det. Yes. Da slutter vi der. Still spørsmål i chatten og vær aktiv i BreakOutRules. Å... Hei! Jeg heter Ash. Jeg er 40 år og jeg er 40 år gammel. Takk! Det er vanskelig å forstå hvordan det er å være døv på skolen. Hvordan var det å få til det? Hvordan var det å få til det? Hvordan var det å få til det? Hvordan var det å få til det? Det er vanskelig å forstå hvordan det er å være gravid.", "source": "lecture"}
{"lecture_id": "linux1del4", "chunk_id": "linux1del4_0000", "start": 0.0, "end": 105.88, "token_count": 295, "text": "Ja, nå er jeg logget inn på min egen Linux-desktop. Og det jeg tenkte å vise nå, er hvordan man logger seg inn på Studio SSÅ fra Linux. Eller fra det som gjelder for mange flere, fra Mac. Hvis man har en Mac, så er det mulig å oppdatere en terminal. Programmet Terminal, og da får du opp et terminalvindu som ser ut litt som dette her. Skjellkommandoer, sånn som pwd, som viser hvor du er. Eller housename, som gir deg navnet på maskinen. Men det vi skal se på nå, er hvordan logge seg inn på StudieSSH fra en Mac-terminal. Og da bruker man programmet SSH. Og så må du skrive brukernavnet. Så har jeg en testbruker. S318329. Og så må jeg bruke att. Studsso.cs.joa.no. Og så return. Da blir man bedt om passord. Og da må du bruke ditt studentnummer og ditt eget passord. Det som du bruker på CANDAS. Skal vi se... Hvis jeg klarer å skrive det passordet riktig, så må jeg komme igjen. Jeg har opplevd tidligere når jeg har logget inn det samme med bruker,", "source": "lecture"}
{"lecture_id": "linux1del4", "chunk_id": "linux1del4_0001", "start": 79.96, "end": 129.0, "token_count": 164, "text": "Og da må du bruke ditt studentnummer og ditt eget passord. Det som du bruker på CANDAS. Skal vi se... Hvis jeg klarer å skrive det passordet riktig, så må jeg komme igjen. Jeg har opplevd tidligere når jeg har logget inn det samme med bruker, at det tar noen ganger veldig lang tid. Hvis det bare står sånn og henger, så kan det skyldes det. Så ha litt tålmodighet. Men når det første da har kommet inn, så kan du skrive Linux-kommandoer, LS, LS-minus L, og generelt utføre de første ukeoppgavene i uke to.", "source": "lecture"}
{"lecture_id": "linux7del16", "chunk_id": "linux7del16_0000", "start": 0.0, "end": 115.54, "token_count": 291, "text": "Vi skal se på et poeng som er viktig i forhold til å sette opp webservere. Det vi skal prøve nå, er å få til en maskin som kjører en liten webserver, som da kan kjøre oss fra hvor som helst. I utgangspunktet så har vi ikke noe nettverk, eller vi er inne på et privat nettverk. Her ser vi et eksempel med Nginx, som er en dockerinstans som kjører en webserver. Etterpå skal vi prøve å bare kjøre Ubuntu og installere Apache 2, som tidligere. Men i første gang kan vi starte med Nginx. Da ser vi. Gjør akkurat som tidligere. Det som vi har med her, er minus P 80-80 kolon 80. Det betyr at hvis man sender en innkommende forespørsel på port 80-80 til hosten, hosten er i vårt tilfelle Linux VM, så vil man ved hjelp av såkalt port forwarding... Man oversetter pakker som kommer inn med PSB-heder. Det blir oversatt til 80 og så sendt videre til konteineren. På den måten kan man da sette opp en webserver her på konteineren", "source": "lecture"}
{"lecture_id": "linux7del16", "chunk_id": "linux7del16_0001", "start": 80.74, "end": 157.0, "token_count": 206, "text": "hosten er i vårt tilfelle Linux VM, så vil man ved hjelp av såkalt port forwarding... Man oversetter pakker som kommer inn med PSB-heder. Det blir oversatt til 80 og så sendt videre til konteineren. På den måten kan man da sette opp en webserver her på konteineren som svarer på innkomne forespørsler. Da vil det ha gått rett inn til konteineren. Men på denne måten kan man ha én webserver som kjører på port 80 på Hovsten, og så kan man ha en annen som kjører på port 80 på konteineren. Men så kan man velge hvilken av de to man... Oppgaven denne uken er at man skal sette opp et par sånne konteinere. Som en webserver i Linux-VM, som kan nås utenfra.", "source": "lecture"}
{"lecture_id": "linux2del8", "chunk_id": "linux2del8_0000", "start": 0.0, "end": 104.36, "token_count": 293, "text": "Vi skal nå se på symbolske linker, eller lenke kan man også kalle det. Det er da lenker som peker fra et sted i filsystemet til et annet. Vi kan først se på hvordan man kan lage en symbolsk lenke til en mappe. Linker... Eller snarveier kan man også kalle det. La oss si jeg ønsker å lage en lenk til... Man skriver alltid til der man ønsker å... Eller til den mappen som finnes. Det som finnes fra før, er det første argumentet, og så... Den du ønsker å lage, er det andre argumentet. Nå lager jeg en lenke. Hvis jeg lister med minus L, så vil det si at her så har jeg en link... Og den starter med L, i motsetning til mapper som starter med D og filer som starter med en strek. Så... Da ser vi at dette er en link som peker på Jusubin. Så hvis jeg nå flytter meg til Mbin... Og gjør LS... Så ser vi... Jeg har hatt igjen masse filer, for det er alle de som ligger i user-bind. Men hvis jeg utfører PWD, så ser vi at det ser ut som jeg er i under min i M-bind.", "source": "lecture"}
{"lecture_id": "linux2del8", "chunk_id": "linux2del8_0001", "start": 75.92, "end": 178.96, "token_count": 294, "text": "Da ser vi at dette er en link som peker på Jusubin. Så hvis jeg nå flytter meg til Mbin... Og gjør LS... Så ser vi... Jeg har hatt igjen masse filer, for det er alle de som ligger i user-bind. Men hvis jeg utfører PWD, så ser vi at det ser ut som jeg er i under min i M-bind. Hvis jeg går opp igjen også, så er jeg tilbake her hjemme. Men hvis jeg går ned, så kunne det vært nyttig å vite hvor jeg egentlig er i filsystemet. Det er en shell-bilt-in, så den flytter med i filsystemet. Men det finnes også en bind-P32D. Og hvis jeg bruker den, så får jeg se da hvor jeg er absolutt i filsystemet. Så kan jeg gå opp igjen. Man kan også lage pekere etter filer. La oss si... Da ser vi at den peker til bind PWD, det programmet der. Og så skal jeg bare kalle den for P. Da ser vi at jeg har en filpeker her nå, som P peker til bind PWD. Og da kan jeg utføre den kommandoen ved å taste P. Og da ser vi... Da utfører den...", "source": "lecture"}
{"lecture_id": "linux2del8", "chunk_id": "linux2del8_0002", "start": 150.0, "end": 214.28, "token_count": 199, "text": "Da ser vi at den peker til bind PWD, det programmet der. Og så skal jeg bare kalle den for P. Da ser vi at jeg har en filpeker her nå, som P peker til bind PWD. Og da kan jeg utføre den kommandoen ved å taste P. Og da ser vi... Da utfører den... Dette er da en fil som peker til en annen fil. Dette er en moppe som peker til en annen moppe, så dette blir en slags snarvei. Mens dette her blir en slags alias for det programmet. Og det kan være nyttig hvis du ønsker at en versjon av et eller annet program skal peke til én bestemt versjon. F.eks. at Emax skal peke til emax21.34. Lag en link i systemet som gjør dette.", "source": "lecture"}
{"lecture_id": "os9del15", "chunk_id": "os9del15_0000", "start": 0.0, "end": 115.7, "token_count": 281, "text": "Da skal vi se på en folk-demo. Folk er litt merkelige. Det er ikke så lett med en gang å skjønne hvordan det fungerer. Men det som skjer når jeg gjør et folk-call... Dette er et se-program, og jeg trenger disse bibliotekene for å kunne bruke folk. Den første skriver ut folk-demo. En linje. Og så gjør man et system kalt folk, så skriver man ut en linje til. Og det som skjer da, når du gjør folk, er at fra og med neste linje så fortsetter jo dette programmet... Altså Parents, de fortsetter å kjøre, og skriver ut den linja. Siden Child er en kopi av Parent, vil den fortsette der Parent slapp. Så vil den også skrive ut folk-demoer. Så vi kan prøve å kjøre den og se hva som skjer. Men da får vi ut tre folk-demoer. Jeg skriver bare to ganger. Den første folk-demoen her... For å gjøre det helt klart... Folk-demo... Vi kan kalle den én. Og så kan vi skrive folk-demo to. Det er den første, og så kommer det to som er folk-demo to.", "source": "lecture"}
{"lecture_id": "os9del15", "chunk_id": "os9del15_0001", "start": 90.0, "end": 201.3, "token_count": 299, "text": "Jeg skriver bare to ganger. Den første folk-demoen her... For å gjøre det helt klart... Folk-demo... Vi kan kalle den én. Og så kan vi skrive folk-demo to. Det er den første, og så kommer det to som er folk-demo to. Så vi kan gjøre det eksplosivt. Komplimenter å kjøre i. Folkdemo én skrives ut av den første, og så folkdemo to av den andre. Og sånn kan man jo fortsette. Hvis vi gjør det sånn... Hvor mange folkdemo skrives ut av? Sånn totalt antall linjer... Hva tror dere? Det er et forslag om sju stykker. Ja, det høres fornuftig ut, fordi... Man kunne kanskje tenke at det bare ble fem, men her har jeg jo en fork, og da er det allerede... Den vil også childgjøre, så den vil lage et barnebarn. Her nede vil jeg doble igjen. Så jeg får liksom... Først er det én prosess, så er jeg to, og så er jeg fire. Så da burde det bli syv stykker. Yes. Dere er altfor gode. Dere svarer riktig med en gang.", "source": "lecture"}
{"lecture_id": "os9del15", "chunk_id": "os9del15_0002", "start": 180.0, "end": 297.96, "token_count": 280, "text": "Her nede vil jeg doble igjen. Så jeg får liksom... Først er det én prosess, så er jeg to, og så er jeg fire. Så da burde det bli syv stykker. Yes. Dere er altfor gode. Dere svarer riktig med en gang. Mye bedre om noen av dere feiler først, men veldig bra. Hvordan kan man egentlig bruke dette her? Det ville jo ikke vært så veldig hensiktsmessig hvis... Hvis man bare kjørte videre akkurat det samme programmet. Men da får jeg prøve å se på litt hva... Hva er det denne folk... Returnerer. Int. pay.ve. Så kan jeg ta... Skal vi se... Kan jeg ta en printf? Ja... Det er et spørsmål om hvorfor det skrives nr. 3 ut fire ganger. Ja, da må jeg se litt nærmere på det. Jo... Det er fordi... Her startes en shile. Og dermed er det to programmer som skriver ut Folkdemo 2. Og da vil det første... Parent som skrev ut Folkdemo 2 her... Det vil gjøre folk. Og da vil du få...", "source": "lecture"}
{"lecture_id": "os9del15", "chunk_id": "os9del15_0003", "start": 260.94, "end": 379.02, "token_count": 293, "text": "Ja, da må jeg se litt nærmere på det. Jo... Det er fordi... Her startes en shile. Og dermed er det to programmer som skriver ut Folkdemo 2. Og da vil det første... Parent som skrev ut Folkdemo 2 her... Det vil gjøre folk. Og da vil du få... Skru ut demo 3, og den charden som den lagde, skru ut demo 3. Det samme skjer da med den demo 2 her, som ble startet. Den skrur ut demo 2, og så lager den chard. Så selv skrur den ut demo 3, og så er det charden dens igjen som skriver ut enda en demo 3. Så dermed blir det fire ganger utskrift med demo 3. Men det er ganske forvirrende når man driver og setter det opp. Det er ikke så opplagt at det blir syv, men... Det er noen oppgaver denne uken som går på dette, så prøv å feile litt med folk. Men hovedpoenget var at man kan... Hvis jeg husker riktig syntaks, så kan man skrive ut... Er lik... skal vi se... 14 % d. Kan prøve noe sånt. Og da ser vi...", "source": "lecture"}
{"lecture_id": "os9del15", "chunk_id": "os9del15_0004", "start": 340.46, "end": 441.72, "token_count": 279, "text": "så prøv å feile litt med folk. Men hovedpoenget var at man kan... Hvis jeg husker riktig syntaks, så kan man skrive ut... Er lik... skal vi se... 14 % d. Kan prøve noe sånt. Og da ser vi... Payday er 2726, skrives ut. Og så er det payday lik null. Og akkurat dette her kan vi bruke til noe. Det er en kommentar at dette er nesten som rekvisjon. Ja, det er rekvisjon, men ikke helt sånn når en metode kaller seg selv. Når en metode kaller seg selv, så starter den alltid fra starten. Men her er det en slags rekvisjon hvor du... Eller, det er kun herfra som man starter. Man kunne tenke seg at når du gjør en folk at du starter programmet på ny... Men da må man huske på at dette er en kopi av det programmet som kjører. Så det er en kopi som fortsetter å kjøre derfra parent-prosessen er. Det er akkurat det samme programmet, og dermed vil den ikke... Shield vil ikke sette i gang og kjøre den første printen.", "source": "lecture"}
{"lecture_id": "os9del15", "chunk_id": "os9del15_0005", "start": 420.0, "end": 550.74, "token_count": 292, "text": "Men da må man huske på at dette er en kopi av det programmet som kjører. Så det er en kopi som fortsetter å kjøre derfra parent-prosessen er. Det er akkurat det samme programmet, og dermed vil den ikke... Shield vil ikke sette i gang og kjøre den første printen. Den vil bare fortsette derfra. Det er derfor jeg aldri får noen første print fra Shield. Et slags rekkerskiftkall, men det rekkerskiftkallet starter fra nøyaktig der parent er, og fortsetter derfra. Det er rett og slett en kopi. Man kopierer alt ved prosessen og legger den i minnet, og så kjører den videre derfra den forrige slapp. Og det er nemlig den paydayen. For da er det sånn at i Child så returnerer forkallet null. Så dermed så kan man teste om man er i Child eller ikke. Mens i Parent så returneres paydayen til Child. Man kan utnytte dette, og så kan man si... Hva skjer da? Jo, da kan man si... Da kan jeg si at... Ok. Jeg er shiled. Og da bør det bli... Sånn. Og så kan vi si Els.", "source": "lecture"}
{"lecture_id": "os9del15", "chunk_id": "os9del15_0006", "start": 502.46, "end": 647.14, "token_count": 299, "text": "Mens i Parent så returneres paydayen til Child. Man kan utnytte dette, og så kan man si... Hva skjer da? Jo, da kan man si... Da kan jeg si at... Ok. Jeg er shiled. Og da bør det bli... Sånn. Og så kan vi si Els. Og så må vi da si at... Jeg er ferdig. Sånn... Kan vi glemme de siste der? Vi kunne forresten ha med... For det kan være litt interessant... Folkdemo-avsluttet. Hvor mange ganger skrives denne siste linjen ut her? Jo, det som forhåpentligvis skjer nå, er at for 'Child' så kjører jeg denne. Og for 'Parent' så kjører jeg bare den der, så vi skal få to forskjellige utskrifter. Men hvor mange ganger kjører den folk de har måttet avslutte på? Eller hvor mange ganger kjører den? Jo... To ganger, ja. Flere som sier to. Helt riktig. Dette er bare en if-test, så hvis den er skjelt, så kjører du den der. Men etter den if-testen så vil den ikke gå inn her, men den vil faktisk fortsatt kjøre den der.", "source": "lecture"}
{"lecture_id": "os9del15", "chunk_id": "os9del15_0007", "start": 622.4, "end": 719.86, "token_count": 295, "text": "Jo... To ganger, ja. Flere som sier to. Helt riktig. Dette er bare en if-test, så hvis den er skjelt, så kjører du den der. Men etter den if-testen så vil den ikke gå inn her, men den vil faktisk fortsatt kjøre den der. Vi ser der FolkDemo1. Jeg er parent. Folk ga PID 26923. Og så rekker den akkurat å skrive ut FolkDemo avsluttet, før den... Shield er nå light og skriver ut:\"Jeg er Shield. Folk har payday-liknull.\" Og folk de må ha sluttet. Det vanlige er at du har en sånn test, og så kjører du ikke noe mer felles kode. Du kjører bare den koden inni her og den koden inni her. Men man kan også kjøre felles kode sånn som det. Avanserte måter å bruke folk på, sånn som dette her... Hvor man har parent og shield. Vi skal ikke se på det i detalj, men bare for å gi et inntrykk. Så kan det se sånn ut. Man kan styre 'jeg er parenten' med Prosess Payday 2697. Og så sier man 'jeg er shield'. I dette tilfellet så venter...", "source": "lecture"}
{"lecture_id": "os9del15", "chunk_id": "os9del15_0008", "start": 696.04, "end": 803.58, "token_count": 297, "text": "Hvor man har parent og shield. Vi skal ikke se på det i detalj, men bare for å gi et inntrykk. Så kan det se sånn ut. Man kan styre 'jeg er parenten' med Prosess Payday 2697. Og så sier man 'jeg er shield'. I dette tilfellet så venter... Ikke på at shide har avsluttet. Da ser vi den bare fortsetter. Siden det er en kloning, så har den samme terminal output også. Så den skriver default TDA output. Ja, alle shide-prosesser har null i... Nei, en shide-prosess har ikke null i payday, men forkallet returnerer null. Så payday-en til shide-prosessen... Som parent får. Så dette vil da være paydayen til child-prosessen. Men... Nei, dette er paydayen til parentativet. Child får en payday, men variabelen payday er lik null inni child. Dette er kommunikasjon mellom de to prosessene. Vi kan gjøre en wait-payday. Her er jeg nå i Parents, og den sier ok... 'Jeg skal vente på...' Så... venter ikke. Det var bare det jeg skrev. Hvis jeg skal gjøre det riktig, så burde det stått sånn.", "source": "lecture"}
{"lecture_id": "os9del15", "chunk_id": "os9del15_0009", "start": 776.96, "end": 838.94, "token_count": 195, "text": "Vi kan gjøre en wait-payday. Her er jeg nå i Parents, og den sier ok... 'Jeg skal vente på...' Så... venter ikke. Det var bare det jeg skrev. Hvis jeg skal gjøre det riktig, så burde det stått sånn. Så her ser vi Parents står og venter. Scheinprosess avslutter. Og så avslutter parent også. På den måten kan man starte nye prosesser, og så kan de kommunisere med hverandre. Og siden man har en sånn if-test, så kan den nye shell-prosessen gjøre hva som helst. F.eks. så kan man lage en shell-prosess, og så kan man be den om å kjøre Firefox. Og dermed har man en helt ny, uavhengig prosess som kjører dette amperet.", "source": "lecture"}
{"lecture_id": "os9del8", "chunk_id": "os9del8_0000", "start": 0.02, "end": 89.92, "token_count": 283, "text": "Skal vi se lite grann på prosessforløpet... Vi har jo vært mye inne på dette tilsvarende som i den vaffelsimuleringen. Men det er kanskje et par ting... noen begreper som vi kan ta med. Et prosessforløp starter som en ny prosess. Det er sånn alle prosesser starter. Og så legges det i ready-list. I vaffelsimuleringen var forelesning og vaffelprosessen... De lå helt inne i ready-list og ønsket å kjøre. Og så det typiske interruptet som kom da, var... Når det er ready-list, så er det en dispatcher. Det er den delen av scheduleren som velger hvilken prosess som skal kjøre. Dispatcheren setter i gang og kjører prosessen. Når den er i rønningtilstand, så kan den få et interrupt. Det typiske interruptet er timer interrupt. Hvert hundredels sekund vil man kunne bli avbrutt. Men så kan scooteren også velge å... Hvis det ikke er noen andre interrupt, så kan man velge å gi flere tics til samme prosess, sånn at den kjører litt lenger enn minste tidsevne.", "source": "lecture"}
{"lecture_id": "os9del8", "chunk_id": "os9del8_0001", "start": 68.86, "end": 158.88, "token_count": 293, "text": "Hvert hundredels sekund vil man kunne bli avbrutt. Men så kan scooteren også velge å... Hvis det ikke er noen andre interrupt, så kan man velge å gi flere tics til samme prosess, sånn at den kjører litt lenger enn minste tidsevne. Så kan man også få IO. Det er sånn man venter på melkemannen, eller noe fra disk, eller noe som tar lang tid. Så blir den tatt ut fra Rønning og satt i en ventingkø. Da er den heller ikke i ready-list, for shelleren leter hele tiden etter de prosessene som er klare til å kjøre. Det er de som får tid. Det var også derfor de to jobbene som var nicet, fikk stå i Rønning. Fordi det ikke var noen andre i Ready-list på den CPU-en. Så det er klart, dette er én CPU. Dette er én enkel CPU, så vi har... Hvis du har flere CPU-er, så vil du ha én kø for hver CPU. Vi kan se... Jeg har en liten demo av dette her også, som ligger på... Som ligger på kurssiden. Det er en liten demo som viser hele det forløpet...", "source": "lecture"}
{"lecture_id": "os9del8", "chunk_id": "os9del8_0002", "start": 131.34, "end": 241.98, "token_count": 298, "text": "Dette er én enkel CPU, så vi har... Hvis du har flere CPU-er, så vil du ha én kø for hver CPU. Vi kan se... Jeg har en liten demo av dette her også, som ligger på... Som ligger på kurssiden. Det er en liten demo som viser hele det forløpet... Med at du har prosesser som står i ReadyList... Og så har du Dispatcher, eller Shedular Dispatcher... Som tar jobber fra ReadyList og ut til Running. Igjen så har denne simuleringen her... Eller denne illustrasjonen... Men med en gang du har flere CPU-er, kan kjernetråder også kjøres på mange CPU-er samtidig. Så dermed kan du få en enda mer effektiv utnyttelse av de CPU-ene du har. Og brukerprogrammet vil da kunne kjøre helt i den. Den kan kjøre på en annen CPU og så skritulere dette. Men dette bildet er, har jeg tenkt, én CPU som står og kjører. Her var det en som måtte vente. Og da kommer den tilbake i Redelist når den er ferdig med å vente. Det er herfra at skredderne har ledd dispatcheren fra Redelist hele tiden. Plukkegrabber.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0000", "start": 0.0, "end": 98.84, "token_count": 299, "text": "Sånn. Fra nå blir foreløpningen tatt opp. Vi ser vi har kommet til uke 17. Det vil si, vi har vel hatt i hvert fall to uker... en studieuke og en påskeuke. Men det har vært 15 uker med nytt stoff. Litt mindre de siste ukene. Er disker og filsystemer et ganske morsomt tema? Og noe som er relativt forskjellig fra det vi har holdt på med tidligere. Så nå er vi over på den aller tregeste, seineste delen av operativsystemet. Her kan det gå inntil en million ganger saktere. Her er vi faktisk avhengig av plater som snurrer rundt. Ting tar tid. Men like fullt så er disker og filtsystemer en viktig del av operativsystemet. Kanskje ikke like viktig som for 10 og 20 og 30 år siden. Fordi vi i moderne systemer så har ramm blitt såpass billig, og man har såpass store mengder ramm at man ofte kan unngå de problemene Man får det med 3G-disker ved disk-cashing. Altså at man rett og slett bare laster inn svære filer på mange gigabyte", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0001", "start": 77.36, "end": 171.28, "token_count": 299, "text": "Fordi vi i moderne systemer så har ramm blitt såpass billig, og man har såpass store mengder ramm at man ofte kan unngå de problemene Man får det med 3G-disker ved disk-cashing. Altså at man rett og slett bare laster inn svære filer på mange gigabyte inn i ramm. Og det løser en del problemer. Selv store databasesystemer kan ha store deler av databasen i ramm, og da går ting veldig mye raskere enn om man alltid må ut på disk og hente det. Men uansett trenger man disker. Når man skrur av datamaskinen, forsvinner alt som er i ramm. Så det holder ikke helt. Så det er dette som er temaet denne uken. Ikke minst så er det noen morsomme oppgaver... Som er... Ja, som går ganske... De er ganske praktisk anlagt. De går ut på å se på filsystemer. Og for å kunne gjøre det, så trenger vi noen ekstra verktøy. Og vi skal bruke et verktøy som heter autopsy. Det er en sånn open source forensics browser. Forensics, det er sånn... På norsk heter det kanskje rettsmedisin.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0002", "start": 143.36, "end": 227.68, "token_count": 285, "text": "De er ganske praktisk anlagt. De går ut på å se på filsystemer. Og for å kunne gjøre det, så trenger vi noen ekstra verktøy. Og vi skal bruke et verktøy som heter autopsy. Det er en sånn open source forensics browser. Forensics, det er sånn... På norsk heter det kanskje rettsmedisin. Otopsy er jo sånn hvor man ser på døde personer og finner ut hva som har skjedd. Det er verktøy. Det blir brukt ofte hvis man... Hvis noen ganger politiet kommer og henter datamaskiner, da tar de det første de gjør, og tar en kopi av harddisken. Og så går det løs på den og prøver å finne ut hva som har vært på disken. Det er ofte sånn også at man kanskje ser på mobiltelefoner, eventuelt minnepinner. Og så er det da ting som... Som har blitt slettet på disse minnepinnene. Men så leser man ofte at 'det går an å finne igjen'. Det er ikke helt borte. Og det stemmer faktisk. Hvis man sletter en fil fra en disk,", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0003", "start": 204.6, "end": 288.02, "token_count": 280, "text": "eventuelt minnepinner. Og så er det da ting som... Som har blitt slettet på disse minnepinnene. Men så leser man ofte at 'det går an å finne igjen'. Det er ikke helt borte. Og det stemmer faktisk. Hvis man sletter en fil fra en disk, så blir bare linken til der hvor stoffet har ligget, slettet. Så selve dataene ligger der helt til de tilfeldigvis skrives. Med mindre man eksplisitt skriver over seg. Så på en Wallaby Service du sletter en film, så sier vi at den er borte for godt. Men i virkeligheten så ligger den fortsatt på disken. Og det gjelder også SSD-disker, og det gjelder også minnepinner. Så mot slutten av oppgaven denne uken, så er det en oppgave som... Den går ut på at man... At det er en kar som kommer til Norge, og så har han med seg litt diverse utstyr, men blir stoppet av politiet på grensen, på Gardermoen. Men da har han akkurat klart å slette et bilde som han har på harddisken.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0004", "start": 273.26, "end": 357.08, "token_count": 300, "text": "At det er en kar som kommer til Norge, og så har han med seg litt diverse utstyr, men blir stoppet av politiet på grensen, på Gardermoen. Men da har han akkurat klart å slette et bilde som han har på harddisken. Og i tillegg så har han slettet innholdet på en minnepinne. Men som eksperter så skal dere gå inn med autopsy. Og så skal dere se på de diskene. Jeg har fått tak i en kopi av et image av hver av diskene. Og så skal dere da lete bl.a. etter et bilde og diverse tekst og noen nøkler for å finne ut hvordan man kan løse mysteriet. Og det dere vil se etter hvert, er at her er det faktisk et bilde som dere kan få tak i, som har vært slettet fra en disk. Dere får trylle det frem igjen med autopsy. Det er ikke så veldig rett frem, men det er en del jobb. Men det er morsomt når man først får det til. Og litt av poenget her er at da skal dere samtidig lære hvordan et filsystem er bygd opp, for da må dere gå inn under de vanlige filene og se på sammenhengene hvordan filer egentlig er lagret.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0005", "start": 339.08, "end": 446.32, "token_count": 297, "text": "Men det er morsomt når man først får det til. Og litt av poenget her er at da skal dere samtidig lære hvordan et filsystem er bygd opp, for da må dere gå inn under de vanlige filene og se på sammenhengene hvordan filer egentlig er lagret. Så her er det på mange nivåer. Så er det data som er skjult, som dere kan få fram med relativt enkle midler. Vi skal se etterpå hvordan vi bruker autopsy for å se på noen filer. Jeg tenkte å prøve å gjøre det, bygge et image fra scratch. Lage en fil på det imaget og slette det, og så se om vi klarer å finne det igjen. Ok. Det var mye om dagens oppgaver. Ja, vi kan se. Her nede er en oppgave tre det jeg snakket om. Hvor dere skal drive med computer forensics, som det heter, og se på disker og finne ut hva som har skjedd. OK. Da skal vi se på hva vi skal holde på med i dag. Vi kan kanskje aller først raskt se på hva vi holdt på med sist. Forrige gang så var det RAM, internminnet, som vi så på.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0006", "start": 413.0, "end": 520.0, "token_count": 291, "text": "og se på disker og finne ut hva som har skjedd. OK. Da skal vi se på hva vi skal holde på med i dag. Vi kan kanskje aller først raskt se på hva vi holdt på med sist. Forrige gang så var det RAM, internminnet, som vi så på. Og vi så først og fremst på i praksis hvordan... Hva som skjer ved bruk av internmine, og hva som er viktig. Det som er det viktige, er å få plass til alt i RAM. Hvis man må begynne å bruke disk for å programme programmer, så tar ting veldig lang tid. RAM, derimot, er veldig hurtig. Og enda hurtigere er det ved hjelp av cash. Så vi så på noen... Noen rammetester, sånn som her. Og en rammetest som er sånn som denne... Den skriver da små blokker om og om igjen. Og da, i praksis, så vil ikke dette skrives helt ut til disk fortløpende. For hastigheten ut til disk er ikke så rask. Altså cash nærmest CPU-en. Så hvis man skriver to ganger raskt etter hverandre til samme område,", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0007", "start": 492.0, "end": 580.44, "token_count": 293, "text": "Den skriver da små blokker om og om igjen. Og da, i praksis, så vil ikke dette skrives helt ut til disk fortløpende. For hastigheten ut til disk er ikke så rask. Altså cash nærmest CPU-en. Så hvis man skriver to ganger raskt etter hverandre til samme område, så blir det ofte bare lagret til cash. Og så etter hvert når ting ror seg, så blir det skrevet helt ut til disken. Og vi kunne da se at her er det en forskjell på en faktor åtte i forhold til når man skriver større mengder, som da skrives helt ut til disk. Så dette viser hvor viktig Cash er for å få ting hurtig ut på disken. Og vi så også på noen eksempler på hvordan man... Hvis man må hoppe i ramm... Vi så f.eks. på en matrise. Så hvis man bruker feil indeks i en matrise, så hopper man store biter av gårde i ramm når man lagrer. Det tar da straks veldig mye mer tid. Det kan fort bli en faktor på 510. Fordi man da må tilbake til hastigheten av vanlig RAM,", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0008", "start": 559.84, "end": 646.32, "token_count": 285, "text": "Så hvis man bruker feil indeks i en matrise, så hopper man store biter av gårde i ramm når man lagrer. Det tar da straks veldig mye mer tid. Det kan fort bli en faktor på 510. Fordi man da må tilbake til hastigheten av vanlig RAM, som ikke er hurtig nok for CPU-en. Og det er hele hovedpoenget. Hadde RAM vært like hurtig som CPU, så hadde vi ikke trengt å ha hele cash-opplegget i det hele tatt. Og et annet poeng med cash er at det styres ikke av operativstemme. Det er det samme med MMU. Ok, da kan vi gå til dagens tema. Først skal vi se litt på det som kan kalles gammeldagse disker, selv om det er mye bruk i vanlige PC-er og laptop-er også. Så vi skal se på oppbygning av disker. Og så skal vi se på partisjoner og litt på SSD. Solid State Drive, som er da en raskere utgave av en raskere disk, som bruker en helt annen teknologi, som bruker den samme teknologien som i minnepinner.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0009", "start": 624.2, "end": 718.68, "token_count": 280, "text": "Så vi skal se på oppbygning av disker. Og så skal vi se på partisjoner og litt på SSD. Solid State Drive, som er da en raskere utgave av en raskere disk, som bruker en helt annen teknologi, som bruker den samme teknologien som i minnepinner. Og som ligner mer på det som ligner egentlig mer på ram og registre, faktisk. Men forskjellen er at SSD, den beholder informasjonen Skal vi se på filsystemer, hvordan et filsystem er bygd opp, og det er egentlig bare en oversikt over hva som er lagret på en disk. Kortversjonen er at man har såkalte sektorer, som er minste enhet på 512 bite. Og filsystemet er bare en litt komplisert oversikt over hvor alle disse sektorene, De minste byggescenene, hvor de ligger på disken. Ja. Så skal vi se litt konkret på... på disker og DMA, hvordan operativsystemet avlastes og lagrer... Hvordan ting lagres direkte mellom ramme og disk uten at OUS trenger å jobbe for mye.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0010", "start": 690.0, "end": 793.82, "token_count": 291, "text": "De minste byggescenene, hvor de ligger på disken. Ja. Så skal vi se litt konkret på... på disker og DMA, hvordan operativsystemet avlastes og lagrer... Hvordan ting lagres direkte mellom ramme og disk uten at OUS trenger å jobbe for mye. Vi skal ta opp igjen det med Kib, mib og gib, som jeg nevnte sist. Og så skal vi helt til slutt se på rate, som er en måte å parallellisere disker. Man setter mange disker ved siden av hverandre, og så leser man og skriver i parallell for å få ting til å gå fortere. Ok. Da skal vi starte med magnetiske disker. Magnetiske disker, de ser ut som små CD-plater, og de snurrer veldig fort rundt. 1000 ganger i sekundet, eller der noe omkring. Og så har de... Som man ser her, så er det lesehoder som ligger veldig tett inntil diskene. Så prinsippet er bygd på magnetisering. Så man har magnetisert områder på disken. Og da kan det være sånn at et bitte lite område som er magnetisert,", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0011", "start": 767.4, "end": 854.56, "token_count": 299, "text": "Og så har de... Som man ser her, så er det lesehoder som ligger veldig tett inntil diskene. Så prinsippet er bygd på magnetisering. Så man har magnetisert områder på disken. Og da kan det være sånn at et bitte lite område som er magnetisert, det er en ener. Og hvis det ikke er magnetisert, så er det null. Og dette er en varig lagring, sånn at hvis man skrur av strømmen, så ligger jo det der fortsatt. Men for å lese av den magnetiseringen så trenger du lesehoder Veldig tett inntil diskene. Og de ligger både over og under. Og siden jeg har dem, så har du mange lag med disker. Det kan se ut noe sånt ut. Sånn størrelsesorden 100 ganger i sekundet roterer disse diskene rundt. Og så har man lesehoder over og under. Sånn at man lagrer på begge siden av alle diskene. En ting som er viktig med disker, er at sektor er den minste grunnhenheten for en disk. Det er den minste biten. Hvis jeg har en sektor her ute, den er på 512 bite.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0012", "start": 831.76, "end": 909.42, "token_count": 285, "text": "Sånn at man lagrer på begge siden av alle diskene. En ting som er viktig med disker, er at sektor er den minste grunnhenheten for en disk. Det er den minste biten. Hvis jeg har en sektor her ute, den er på 512 bite. Og når man leser fra en disk, så leser man ikke én og én bite, men man leser 512 av gangen. Det er den minste enheten. Skal ikke se så veldig mye på oppbyggingen av disker, for nå blir det mer eller mindre. Men noen ganger vil man se at man møter begrepet track. Og det er akkurat som en løpebane. En track er hele den banen rundt her. Og så har du én sektor per track, og så har du mange tracker innover. Så i tillegg må du si hvilken skive du er på, og om du er over eller under. Så på den måten kan du spesifisere nøyaktig hvor en sektor er. På SSD-disker som vi kommer til, så er dette helt... De er bygd opp helt annerledes. De snurrer ikke rundt. De er faste.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0013", "start": 886.34, "end": 966.2, "token_count": 291, "text": "Så i tillegg må du si hvilken skive du er på, og om du er over eller under. Så på den måten kan du spesifisere nøyaktig hvor en sektor er. På SSD-disker som vi kommer til, så er dette helt... De er bygd opp helt annerledes. De snurrer ikke rundt. De er faste. Mer som ramm. Men likevel bruker man det sektorbegrepet for å kunne bruke de samme filsystemene som på klassiske disker. Sylinder er et begrep som fortsatt brukes, og som dukker opp i mange sammenhenger. Og egentlig er en sylinder samlingen av alle plater... De ligger i samme avstand fra sentrum. Altså samme trekk. Så trekk opp og nede på alle sylinderne... Nei, trekk opp og nede på alle skivene. Det utgjør én sylinder. Og generelt, når man da skal be om én sektor, be om én sånn liten sektor her, så kan man gjøre det ved å si hvilket lesehode det er. Hvilket nummer, hvilken track og hvilken sektor rommet på denne tracken.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0014", "start": 945.88, "end": 1039.1, "token_count": 292, "text": "Og generelt, når man da skal be om én sektor, be om én sånn liten sektor her, så kan man gjøre det ved å si hvilket lesehode det er. Hvilket nummer, hvilken track og hvilken sektor rommet på denne tracken. Og da får du akkurat den sektoren du trenger. Og tradisjonelt så er det operativsystemet som har styrt dette her. Helt ned til detaljnivå. Og for å lese en fil så organiserte da operativsystemet sånn at den sendte ut meldinger, lesehode, track-sektor-nummer ut i disken, og så kom det tilbake. En egen diskontroller som gjør alle disse operasjonene, sånn at operativstemmet kan jobbe på et høyere nivå og så bare be om alle sektorene som en fil utgjør. Og så ordner diskontrolleren det praktiske med hvor det ligger. Hvis man har isolert et operativsystem på en datamaskin, så bruker man begrepet partisjoner. Da må man først partisjonere disken. F.eks. så kan man ha filer som man endrer på.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0015", "start": 1010.84, "end": 1104.46, "token_count": 285, "text": "Og så ordner diskontrolleren det praktiske med hvor det ligger. Hvis man har isolert et operativsystem på en datamaskin, så bruker man begrepet partisjoner. Da må man først partisjonere disken. F.eks. så kan man ha filer som man endrer på. Det kan være med på én partisjon, og så kan man ha operativsystemet på en annen partisjon. Så kan man beholde hovmpartisjonen, alle filene man har som bruker. Og så bare bytter man om. Da kan man formatere den partisjonen som OS ligger på, og legge OS på nytt. Men egentlig er partisjon en samling av sylindere. På dette bildet ser vi de fire innerste sylinderne. De utgjør til sammen en partisjon. Og grunnen til at man deler det inn på denne måten her, er at én sånn sylinder ligger i samme avstand. Så hvis lesehodene ligger fast, så snurrer disken. Og da vil man naturlig lese en hel sylinder. For lesehodene går ut og inn.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0016", "start": 1080.0, "end": 1177.48, "token_count": 296, "text": "Og grunnen til at man deler det inn på denne måten her, er at én sånn sylinder ligger i samme avstand. Så hvis lesehodene ligger fast, så snurrer disken. Og da vil man naturlig lese en hel sylinder. For lesehodene går ut og inn. Det er derfor man i utgangspunktet har en sylinder. Og det samme gjelder partisjoner. Det ligger fysisk inntil hverandre, så da kan man... Hvis man fortløpende skal lese en stor fil som ligger på samme partisjon, så går man utover i... eller innover i sylinderne og leser det samme. Så dette er årsaken til noen av de begrepene som man har i harddisker. Det er en helt annen type teknologi enn disker som snurrer med magnetisk lagring. Det er basert på flashminner. Akkurat samme minne som i minnepinner. Det har ingen bevegelige deler, og det er faktisk en liten... Den ligner egentlig mest på en liten lagringsenhet for ram. Hvis vi husker RAM, så hadde vi én liten transistor. Men den måtte...", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0017", "start": 1151.74, "end": 1237.4, "token_count": 295, "text": "Det er basert på flashminner. Akkurat samme minne som i minnepinner. Det har ingen bevegelige deler, og det er faktisk en liten... Den ligner egentlig mest på en liten lagringsenhet for ram. Hvis vi husker RAM, så hadde vi én liten transistor. Men den måtte... Den lille transistoren holder en ladning. Med ladning er det én, og uten er det null. Men i RAM må den refreshes. Altså den må fylles opp på nytt. Hvert ti ganger i sekundet fordi ladning siver ut. Men i mine pinner... Et par ekstra lag rundt den transistoren som gjør at man kan lagre varig en bitte liten ladning. Den vil gå ut etter hvert, men den kan lagres i lang tid, sånn at man ikke trenger strøm for å ta vare på den. Men den er ikke like rask som den. Det er kanskje en fakta på 1000? Kanskje noe mer også. Så det er mye tregere. Men... I forhold til disker som roterer, så har den mange opplagte fordeler, blant annet at den ikke har noen bevegelige deler.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0018", "start": 1218.48, "end": 1294.88, "token_count": 300, "text": "Men den er ikke like rask som den. Det er kanskje en fakta på 1000? Kanskje noe mer også. Så det er mye tregere. Men... I forhold til disker som roterer, så har den mange opplagte fordeler, blant annet at den ikke har noen bevegelige deler. Med en laptop med en HDD, en harddisk, så må du spinne harddisken, så må man ofte være litt forsiktig med å vri fort på den, for da kan du til og med høre at det sier... Og så kan disken gå i stykker. Så den tåler da å vrisses og flyttes på. På en helt annen måte enn en vanlig harddisk. Og så er det mye raskere. Spesielt med random aksesttid. Ned mot 0,1 millisekunder, og kanskje enda mindre også, litt avhengig av hvordan man kobler til. Mens for roterende risker så er det oppe i 5-10 millisekunder. Og det er fordi at da du skal hente én gitt sektor, så er det virkelig ikke ram. For da må du jo flytte på lesehodet, og så må disken snurre,", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0019", "start": 1272.76, "end": 1360.0, "token_count": 292, "text": "og kanskje enda mindre også, litt avhengig av hvordan man kobler til. Mens for roterende risker så er det oppe i 5-10 millisekunder. Og det er fordi at da du skal hente én gitt sektor, så er det virkelig ikke ram. For da må du jo flytte på lesehodet, og så må disken snurre, og så kan man lese en sektor. Så det er veldig forskjellig. Men SSE er dyrere. Nå har prisene begynt å... Etter hvert som man produserer mer, så går prisene nedover. Men de er fortsatt en god del dyrere enn HDD, eller Hard Disk Drive, som er roterende disker. Hvordan man kobler til, har mye å si. NVME... Det er såkalt Non-Volatile Memory Express. Det er en spesiell teknologi hvor du kobler rett på PCI-en i en datamaskin. PCI er et sånt generelt tilkoblingspunkt for alle devices som disker av nettargskort og lydkort. Tross alt så har man andre tilkoblinger. Men med SSD, så for å oppnå høy hastighet som man i utgangspunktet har,", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0020", "start": 1328.92, "end": 1447.48, "token_count": 282, "text": "Det er en spesiell teknologi hvor du kobler rett på PCI-en i en datamaskin. PCI er et sånt generelt tilkoblingspunkt for alle devices som disker av nettargskort og lydkort. Tross alt så har man andre tilkoblinger. Men med SSD, så for å oppnå høy hastighet som man i utgangspunktet har, høyere hastighet enn andre disker, så har man klart å koble det i da... Eller fått lag teknologi som kobler det rett på PCI-en, sånn at det kan gå mye raskere. Og mens en vanlig disk kjører sånn typisk 100 MB per sekund... Så kan du få SSD-er opp i 2500. Vi kunne ta en kikk på det. Skal vi se om vi får til å teste noen disker. Skal vi se... Vi kan starte med... her. Ja... Jeg kan starte og kjøre en kommando som heter HD-parm. Før jeg gjør det, så kan vi først starte med å prøve å se på disken. Nå er jeg på en Linus-desktopp som... Og den har en standard harddisk. Så hvis jeg tasser DF...", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0021", "start": 1410.0, "end": 1508.32, "token_count": 285, "text": "Ja... Jeg kan starte og kjøre en kommando som heter HD-parm. Før jeg gjør det, så kan vi først starte med å prøve å se på disken. Nå er jeg på en Linus-desktopp som... Og den har en standard harddisk. Så hvis jeg tasser DF... DF-mins òg, den gir en oversikt over disken og diskbruk. Så ser vi det er en del dev loop her, og det er... Det er typisk... lagret i ramm. Så du kan komme tilbake og se på dev loop senere. Men... Disse her, Rønn og så videre, de er også... Og Dev og Rønn, de er avbildet ramm for at ting skal gå fortere. Men det som er selve disken her, harddisken, det er denne linjen. DWSDA1. Her har jeg bare én partisjon. Jeg kunne hatt flere partisjoner. Da ville jeg hatt typisk DWSDA1, DWSDA2 osv. Men her har jeg bare alt under disken på ett sted. En sånn disk er montert et eller annet sted i filsystemet. Her ser vi hvis den er montert på...", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0022", "start": 1485.72, "end": 1594.86, "token_count": 297, "text": "Her har jeg bare én partisjon. Jeg kunne hatt flere partisjoner. Da ville jeg hatt typisk DWSDA1, DWSDA2 osv. Men her har jeg bare alt under disken på ett sted. En sånn disk er montert et eller annet sted i filsystemet. Her ser vi hvis den er montert på... Denne disken er montert på slash, altså øverst på roten. Så det betyr at når jeg skrur av datamaskinen, så ligger alt på denne devicen. Alt dette ligger på en disk og er evig lagret. Iallfall lagret uten strøm. Og 278 G. Vi ser for øvrig ikke alt av den disken. Fordi noe av det ligger på... Eller dette er en... Jeg har dual boot, så jeg har også en Windows-disk. Men man kan se resten med F-disk. Og typisk når jeg skal se på en disk, så... Så må jeg ha Ruths rettigheter. For generelt sett en vanlig bruker adgang til devices som disk. Så nå starter jeg F-disk på denne disken, og så kan jeg taste P. Da printer man ut en oversikt over disken. Jeg har flere partisjoner der.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0023", "start": 1560.0, "end": 1668.8, "token_count": 295, "text": "Så må jeg ha Ruths rettigheter. For generelt sett en vanlig bruker adgang til devices som disk. Så nå starter jeg F-disk på denne disken, og så kan jeg taste P. Da printer man ut en oversikt over disken. Jeg har flere partisjoner der. SDA2 er en extended. Så ser jeg også at jeg har SWAP. SOP snakket vi om forrige gang. Det er da det området på disken som brukes til virtuelt minne. Så her har jeg satt opp SWAP på 16G. Det er like stort som internminne. Sånn at man hele tiden har en kopi av alt som er internminne, Inn og ut på disken, eller si man får ha 16G ekstra. Og ha på en måte en slags backup-ram i disken. Såping går sakte. Så på mange moderne systemer så har du så mye ram at du egentlig aldri bruker såpp. Men hovedpenget er at man har... Her har jeg Linux. Men SWOP er da en egen partisjon. Så SDA5 er en egen, uavhengig bit av disken. Og dette med partisjoner, det må man definere fra scratch", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0024", "start": 1633.84, "end": 1727.76, "token_count": 279, "text": "Så på mange moderne systemer så har du så mye ram at du egentlig aldri bruker såpp. Men hovedpenget er at man har... Her har jeg Linux. Men SWOP er da en egen partisjon. Så SDA5 er en egen, uavhengig bit av disken. Og dette med partisjoner, det må man definere fra scratch når man installerer operativsystemet. Det finnes forskjellige verktøy som kan endre på partisjoner. Endre partisjonene. Kanskje det er sånn at 280 gigabyte brukes av Windows. Og så kan man plukke ut 100 gigabyte av den og si at OK, nå vil jeg ha Linux på denne. Og det har jeg ikke på denne desktopen, men på laptopen din har jeg en sånn delt minne. Det kan vi se på etterpå. Så det jeg egentlig skulle se, var hastigheten. Så bruker jeg en kommando som heter HDParm, med HD-parm på dev.sda, for å teste hvor lang tid det tar å lese disken. Og da ser vi... Her står det først 'Timing. Cash the Reads'.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0025", "start": 1701.8, "end": 1804.92, "token_count": 296, "text": "Så det jeg egentlig skulle se, var hastigheten. Så bruker jeg en kommando som heter HDParm, med HD-parm på dev.sda, for å teste hvor lang tid det tar å lese disken. Og da ser vi... Her står det først 'Timing. Cash the Reads'. Og det går veldig fort, for i praksis er det å lese fra DiskCash. Så her ser vi... Her er det 13 000 MB. Altså... 13 gigabyte per sekund. Så det går ekstremt fort, og det ligner mer på rammehastighet. Men vi ser på disk-kassetten, med buffer disk-grids... Den leser da direkte fra disk. Og der er vi nedi mer som er antydet 100 megabyte per sekund. Ganske fort det også, men ikke i nærheten av ramme. Så kan vi se på det tilsvarende på min laptop, som er her. Igjen kan vi starte med DF. Her ser vi også, det er masse fra Snap, som er en sånn installeringsapp. Men øverst her, så kan vi se... Igjen er det en del devices som ligger i Ram, som UDV og TempFS. Men her er selve disken på denne laptopen.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0026", "start": 1781.88, "end": 1880.6, "token_count": 287, "text": "Igjen kan vi starte med DF. Her ser vi også, det er masse fra Snap, som er en sånn installeringsapp. Men øverst her, så kan vi se... Igjen er det en del devices som ligger i Ram, som UDV og TempFS. Men her er selve disken på denne laptopen. Her ser vi også at det står eksplisitt NVME. Og denne er da raskere enn NVME011. Den er da raskere enn en standard harddisk. Så vi kan prøve oss og se... Vi kan ta hastigheten først. På denne disken. Igjen så må jeg være ruth. Nå er jeg altså på en annen maskin. Nå er jeg på en laptop som har en SSD-disk. Og vi ser... Den har litt høyere ramme også. Den... Nei, kanskje ikke. Det var det... Må sammenligne her oppe. Sorry. Jo, 13... Det gikk faktisk ikke raskt litt senere, men det er mulig... Denne maskinen her sliter tungt nå ved å kjøre både OBS og Zoom samtidig, så det kan skyldes litt det. Men vi ser at lesningen fra disk går mye raskere.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0027", "start": 1850.32, "end": 1961.76, "token_count": 283, "text": "Må sammenligne her oppe. Sorry. Jo, 13... Det gikk faktisk ikke raskt litt senere, men det er mulig... Denne maskinen her sliter tungt nå ved å kjøre både OBS og Zoom samtidig, så det kan skyldes litt det. Men vi ser at lesningen fra disk går mye raskere. 1800 megabyte per sekund, mens her oppe så var det 80. Vi ser der at det var en fakto på 20 ganger raskere med SSD-disken. Vi ser det er en vesentlig forskjell, og det merker man også på når man brukte, f.eks. Det går mye raskere å bute med en SSD-disk. HDD-disken som jeg hadde, gikk på ca. 80, mens SSD-disken gikk på 2000. Skal vi se... Oi, hvor var jeg? Her var det, ja. Hoppe tilbake en gang til. For vi glemte å se på én ting. Vi skulle se på... Vi skulle bruke eftisk... Og se på denne disken. Hvordan den ligger ut her. P-printer. Og her ser vi et annet eksempel på partisjoner.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0028", "start": 1935.28, "end": 2021.36, "token_count": 287, "text": "Her var det, ja. Hoppe tilbake en gang til. For vi glemte å se på én ting. Vi skulle se på... Vi skulle bruke eftisk... Og se på denne disken. Hvordan den ligger ut her. P-printer. Og her ser vi et annet eksempel på partisjoner. Alle disse her er da partisjoner som er antalt som deviser her. P1, P2, P3 osv. Og her ser vi... Her er Linux-fillsystemet, som da bruker 200 GW. Men så ser vi her... Her har vi et Microsoft Basic. Så her har jeg en helt annen partisjon. Og den, så vidt jeg husker, så bruker den NTFS. Så dette er en Windows-installasjon på den samme laptopen. Men som vi så da vi startet liningsmaskinen, så så vi ikke engang... Med eftisk så så vi ikke... Nei, ikke med eftisk, men... Vi ser liste filer. I Linux så ser jeg ikke engang disse partisjonene. Men det går an å montere det. Man kan gå inn på det, men de ligger der. Men det er da en fullstendig Windows 10-installasjon.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0029", "start": 2001.84, "end": 2087.6, "token_count": 295, "text": "Nei, ikke med eftisk, men... Vi ser liste filer. I Linux så ser jeg ikke engang disse partisjonene. Men det går an å montere det. Man kan gå inn på det, men de ligger der. Men det er da en fullstendig Windows 10-installasjon. Så når jeg booter, så kan jeg da velge å starte Windows 10. Eller jeg kan starte Linux. Og da bruker jeg helt forskjellige uavhengige partisjoner. Jo, denne laptopen kom med Windows. Og da var alt på hele disken. Og det jeg gjorde da, var å repartsjonere med et repartsjoneringsverktøy. Så endret jeg partsjonene. Jeg tror faktisk det kan gjøre med å kjøre en vanlig Linux-installasjon fra en minnepinne. Så kommer det eksisterende Windows-systemet opp, og så kan man velge å repartsjonere. Og da valgte jeg at nå skulle halvparten være til Linux. Og etter det så kan jeg da bute Linux eller Windows, avhengig av hva jeg ønsker å starte. De kan opplagt da ikke kjøre samtidig, men man kan aksessere Windows-filene likevel,", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0030", "start": 2066.48, "end": 2164.66, "token_count": 295, "text": "Og da valgte jeg at nå skulle halvparten være til Linux. Og etter det så kan jeg da bute Linux eller Windows, avhengig av hva jeg ønsker å starte. De kan opplagt da ikke kjøre samtidig, men man kan aksessere Windows-filene likevel, for de ligger i samme fyllesystemet, men det ligger i forskjellige pallisjoner. Kan vi gå tilbake til sleidene? Ja. Jeg nevnte innledningsvis at man har en diskontroller som styrer en harddisk. Hvis vi tenker oss herr CPU-en med operativsystemet som kjører og gjør instruksjoner, så... Var det tidligere sånn at helt fra CPU-en, fra operativstemme, så kom det beskjeder... Hent sektornummer, så trekk det, og plate nummer fire. Men den detaljstyringen, den er nå på moderne harddisker, så er det over... Så styres det av en diskontroller, som er en helt egen liten datamaskin, som styrer harddisken, og får beskjeder fra... Operativstemme om sektorer som skal hentes. Men så styrer den harddisken lokalt.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0031", "start": 2140.96, "end": 2235.72, "token_count": 296, "text": "Men den detaljstyringen, den er nå på moderne harddisker, så er det over... Så styres det av en diskontroller, som er en helt egen liten datamaskin, som styrer harddisken, og får beskjeder fra... Operativstemme om sektorer som skal hentes. Men så styrer den harddisken lokalt. I tillegg så har man DMA, Direct Memory Access, og det gjør at operativstemme kan overlate en del av oppgavene med å styre diskontrolleren til DMA. Så i praksis så vil hvis operativstemme ønsker at en fil skal leses... Da gir operativsystemet beskjed til DMA om hvilken fil man ønsker. Så snakker DMA med diskontrolleren, harddisken henter filen, og DMA legger den filen rett i ramm. Her har vi disk-cash, som vi så på sist. Den disk-cashen inneholder da én eller flere filer fra harddisken. Og det Linux-systemet gjør det hele tiden. Det bruker alle de gigabyteene man har, til å kontinuerlig cashe filer. Men med en gang du kjører et program som trenger masse ram, så vil bare den cashen slettes.", "source": "lecture"}
{"lecture_id": "os15time1", "chunk_id": "os15time1_0032", "start": 2210.1, "end": 2283.88, "token_count": 196, "text": "Den disk-cashen inneholder da én eller flere filer fra harddisken. Og det Linux-systemet gjør det hele tiden. Det bruker alle de gigabyteene man har, til å kontinuerlig cashe filer. Men med en gang du kjører et program som trenger masse ram, så vil bare den cashen slettes. Og da må man helt ut på disk for å... Helt ut på disken for å hente fil. Neste tema er filsystemer. Men da sier jeg det passer godt å ta en pause. Så... da tar vi en pause der. Kom gjerne med spørsmål i pausen. Og havbryt veldig gjerne underveis også i neste time. Men hvis det er ting dere har... Så spør i pausen. Så tar jeg 15 minutter til 9.30.", "source": "lecture"}
{"lecture_id": "os8del5", "chunk_id": "os8del5_0000", "start": 0.0, "end": 102.76, "token_count": 295, "text": "Det er et godt spørsmål i chatten, som... Som ofte dukker opp, og som er et veldig viktig poeng. Spørsmålet er... Hvis du gjør dette, sudo PC-user, altså hvis du kjører et skript... Som-route med sudo, kjører du da skript i privilegert modus? Nei, det er det viktig at man ikke gjør. Det er en veldig stor forskjell på det å være Rut på en maskin, Rut eller administrator, og det å være operativkjerne. For Rut har adgang til alle, man kan si, alle devicer. Det vil si da alle filer, alle nettverkspakker som kommer inn. Og... Så alt dette har Ruth tilgang til. Den kan stoppe prosesser, og den kan gjøre alt mulig. Men den kjører ikke av deg i den grunn i privilegert modus. Kernel-mode, det er en modus som operativsystemet kjernen kjører i. Og hvis du er Ruth, og du starter opp en regnejobb, så kjører du ikke, da. Du kjører i user mode. Så det er en veldig distinkt forskjell på operativsystemkjernen og det å være rout eller administrator.", "source": "lecture"}
{"lecture_id": "os8del5", "chunk_id": "os8del5_0001", "start": 77.36, "end": 121.2, "token_count": 129, "text": "Kernel-mode, det er en modus som operativsystemet kjernen kjører i. Og hvis du er Ruth, og du starter opp en regnejobb, så kjører du ikke, da. Du kjører i user mode. Så det er en veldig distinkt forskjell på operativsystemkjernen og det å være rout eller administrator. Hvis du er administrator, så har du full kontroll på alle deviser, men ikke på selve institusjonene inni kjernen. Det er det bare operativsystemkjernen som har. Øh...", "source": "lecture"}
{"lecture_id": "linux1del6", "chunk_id": "linux1del6_0000", "start": 0.0, "end": 93.28, "token_count": 297, "text": "Jeg er nå logget inn i et terminalvindu, et såkalt Linux-skjell. Vi skal nå se litt på hvordan man beveger seg rundt i filsystemet ved hjelp av kommandoer. En første kommando er Pwd, Print Working Directory, som viser meg hvor jeg står i filsystemet. Og her er logget inn som en student, en testbruker på SSÅ. Og da ser vi at i dette tilfellet så er ikke home... ... slash home slash brukernavn, men vi ser vi har en annen path foran her. Og dette er fordi disse filene ligger ikke på denne serveren, men de ligger på en annen server. Hvis man beveger seg rundt i filsystemet, så kan det være greit å kunne liste hvilke filer man har. Og da er det en kommando som heter LS, som lister filer og mapper. Her ser vi at det som kommer ut i blått, er mopper, og det andre er filer. Hvis man lister med LS minus L, legger til opsjon L, så får man en lang listing. Vi skal senere se i detalj på hva alt dette her betyr. Men her kan man se at der det står en D først, er det for directory.", "source": "lecture"}
{"lecture_id": "linux1del6", "chunk_id": "linux1del6_0001", "start": 69.02, "end": 149.88, "token_count": 289, "text": "Her ser vi at det som kommer ut i blått, er mopper, og det andre er filer. Hvis man lister med LS minus L, legger til opsjon L, så får man en lang listing. Vi skal senere se i detalj på hva alt dette her betyr. Men her kan man se at der det står en D først, er det for directory. Da er det en mappe. Og mappe kan man bevege seg ned i. Og hvis jeg f.eks. ønsker å gå til mappen undervisning, så bruker jeg CD, Change Directory, og så skriver jeg undervisning. Hvis det er litt lange ord, så er det et fint tips. Da fylles resten ut hvis det er entydig. En kjapp måte å gå ned til undervisning på, det er bare å skrive CDU, og så TAB, og så utføre-kommandoen ved å trykke Return. Så kommer jeg ned i undervisning. Når vi ser i det prompet her, så vises det hele tiden hvor jeg er. Så når man kommer et nytt sted, så er det ofte lurt å finne ut hva jeg er. Hva er det som finnes her? Jo, her ser vi...", "source": "lecture"}
{"lecture_id": "linux1del6", "chunk_id": "linux1del6_0002", "start": 131.56, "end": 219.2, "token_count": 292, "text": "Så kommer jeg ned i undervisning. Når vi ser i det prompet her, så vises det hele tiden hvor jeg er. Så når man kommer et nytt sted, så er det ofte lurt å finne ut hva jeg er. Hva er det som finnes her? Jo, her ser vi... Her er det en mappe under her igjen. Så da kan jeg gå ned i den mappen med CD-mappe. Jeg kan skrive det helt ut sånn, CD-mappe. Og så har jeg kommet hit. Hvis mappen er tom, så... Så viser jeg sånn at den er tom. Da kommer det bare 12.0. LS viser ingenting. Jeg må også kunne gå oppover igjen i filsystemet. Så da kan jeg ta cd. Den går ett hakk opp. Så nå er jeg kommet opp til undervisning. Hvis jeg nå går ned igjen, så kan jeg gå to steg opp på denne måten. Prikk, prikk, slash, prikk, prikk. Da kommer jeg helt øverst igjen. Så da kan jeg gå ned til undervisning. Så kommer jeg til hjemmemappen. Hvis man ønsker å få en blank skjerm, så kan man taste Kontroll-L.", "source": "lecture"}
{"lecture_id": "linux1del6", "chunk_id": "linux1del6_0003", "start": 188.68, "end": 296.56, "token_count": 290, "text": "Hvis jeg nå går ned igjen, så kan jeg gå to steg opp på denne måten. Prikk, prikk, slash, prikk, prikk. Da kommer jeg helt øverst igjen. Så da kan jeg gå ned til undervisning. Så kommer jeg til hjemmemappen. Hvis man ønsker å få en blank skjerm, så kan man taste Kontroll-L. Blanke skjerm. Det kan også være praktisk. En del sånne tips som dette her står under Linux-hjelp på kurssiden. Vi kommer også til å gå gjennom litt mer detalj. Sånne små triks som gjør det raskere å bruke kommandolinjen. Nå er jeg et stykke ned i filteret, men det kan gå sakte bakover, sånn som dette her. Og så gå helt opp i toppen av filteret. Og da ser vi her... Nå er jeg på roten av filsystemet. Og så kan jeg gå tilbake igjen. Ned til U0, og ned til min bruker. S31830. Jeg kunne gjort alt dette her også ved å bare gå direkte opp til roten. Da er jeg helt øverst i filteret. Og så kan jeg gå hjem igjen ved bare CD.", "source": "lecture"}
{"lecture_id": "linux1del6", "chunk_id": "linux1del6_0004", "start": 260.36, "end": 303.1, "token_count": 93, "text": "Og så kan jeg gå tilbake igjen. Ned til U0, og ned til min bruker. S31830. Jeg kunne gjort alt dette her også ved å bare gå direkte opp til roten. Da er jeg helt øverst i filteret. Og så kan jeg gå hjem igjen ved bare CD. Kledd over til det. Så vil jeg nå se at nå er jeg hjemme.", "source": "lecture"}
{"lecture_id": "linux9del1", "chunk_id": "linux9del1_0000", "start": 0.0, "end": 112.78, "token_count": 298, "text": "Da skal vi begynne å jobbe med oppgave tolv. Og den går ut på å sammenligne hastigheten til programmeringsspråk. I den oppgaven så skal vi sette opp en dockercontainer som installerer alle programmeringsmiljøene som er nødvendig for å kjøre alle disse programmene. Kompilere og kjøre det. Det man først og fremst trenger, er disse verktøyene. Så kan man etterpå gå inn og kompilere og kjøre. I første omgang skal vi bare bygge en container som installerer alt som er nødvendig. Så skal vi gå inn interaktivt og kjøre koden. Det som er tanken, og som dere kan gjøre, inkludert i neste oppgave, det er å prøve å automatisere dette i enda større grad. Sånn at til slutt, i ukens største utfordring, så blir dere bedt om å gjøre alt dette her og automatisere det, sånn at til slutt alt går automatisk. Og man setter opp en webserver som legger ut resultatene av kjøringene. Da vil det være lett å gjenta det samme for andre versjoner. F.eks. se hvordan forskjellen blir med Ubuntu 1604.", "source": "lecture"}
{"lecture_id": "linux9del1", "chunk_id": "linux9del1_0001", "start": 87.08, "end": 214.52, "token_count": 288, "text": "sånn at til slutt alt går automatisk. Og man setter opp en webserver som legger ut resultatene av kjøringene. Da vil det være lett å gjenta det samme for andre versjoner. F.eks. se hvordan forskjellen blir med Ubuntu 1604. Men vi tar ett steg av gangen. I første omgang skal vi lage en docker container. Dette er for å komplisere C-kode. JDK er for Java. Og i tillegg installerer vi Python. Programmene som skal brukes, ligger på Github. Jeg har et reportasje der som heter Zoom.git. I første omgang kan man laste ned det med Gith-clow. Veldig enkelt å bruke fra kommandolinjen. Det er veldig nyttig å kunne bruke det fra kommandolinjen, for da kan man automatisere alt som har med å pushe og pulle kode osv. I første omgang så vil jeg da gå til en OS-gruppe på... Går til OS70. Så da skal jeg dele et annet vindu med dere. Sånn. Og da er vi i deres land. Som dere ser her, så har jeg nettopp kjørt et script stop and remove som sletter... Alt som er av dokker.", "source": "lecture"}
{"lecture_id": "linux9del1", "chunk_id": "linux9del1_0002", "start": 169.16, "end": 293.64, "token_count": 298, "text": "I første omgang så vil jeg da gå til en OS-gruppe på... Går til OS70. Så da skal jeg dele et annet vindu med dere. Sånn. Og da er vi i deres land. Som dere ser her, så har jeg nettopp kjørt et script stop and remove som sletter... Alt som er av dokker. Imager, konteinere osv. Stopper alt og sletter alt. Det kan være lurt å gjøre en gang iblant, når dere tester ut dette på Linings VM. For det er relativt lite plass. Som dere ser, så har jeg 1,5 gigabyte nå. Så... Så nå som jeg har slettet alt, må jeg også bygge alt fra scratch. Jeg tenkte jeg kunne ta... Ja, vi kunne kanskje først... Aller først så kunne jeg vise hvordan... Skal vi se om jeg har en mappe som heter Sum. Nei. Så skal jeg vise hvordan... Oi. Da må jeg ha den kopien som jeg hadde. Det jeg skal gjøre nå, er at jeg skal klone fra Gits. Og da lages det en mappesum. Hvis jeg går inn den mappen og ser, så ligger det en rekke... en rekke skript- og programmeringsprodukter her.", "source": "lecture"}
{"lecture_id": "linux9del1", "chunk_id": "linux9del1_0003", "start": 257.7, "end": 371.66, "token_count": 297, "text": "Oi. Da må jeg ha den kopien som jeg hadde. Det jeg skal gjøre nå, er at jeg skal klone fra Gits. Og da lages det en mappesum. Hvis jeg går inn den mappen og ser, så ligger det en rekke... en rekke skript- og programmeringsprodukter her. Og utgangspunktet er da bæsj-skriptet. Som vi ser. Som regner ut en løkke 50 000 ganger. Og de andre programmene regner da ut disse... Dette programmet, eller denne arbeidsoppgaven, X ganger. Så det vi skal finne ut, er hvem klarer flest sånne oppgaver på like lang tid.  Dette må vi da få til å gjøre inni dokkercontaineren. Det jeg tenkte å gjøre da, er å ta utgangspunkt i det vi gjorde forrige gang. Skal vi se om jeg har... Da hadde jeg en mappe som het Webserver. Så det jeg tenkte, var rett og slett bare å kopiere Webserver. Til en mappe som heter Sum. Så går jeg inn i summappa, og så starter jeg... Oi. Nei, det ble feil. Da hadde jeg lagd en mappesum allerede.", "source": "lecture"}
{"lecture_id": "linux9del1", "chunk_id": "linux9del1_0004", "start": 339.0, "end": 436.62, "token_count": 300, "text": "Det jeg tenkte å gjøre da, er å ta utgangspunkt i det vi gjorde forrige gang. Skal vi se om jeg har... Da hadde jeg en mappe som het Webserver. Så det jeg tenkte, var rett og slett bare å kopiere Webserver. Til en mappe som heter Sum. Så går jeg inn i summappa, og så starter jeg... Oi. Nei, det ble feil. Da hadde jeg lagd en mappesum allerede. Så hvor endte den opp, da? Jo, da ble den vel kopiert inn der. For å rydde opp litt. Så tar jeg bort sum. Og så kopiere. Sånn. Nå har jeg en mappesum. Og så vil jeg i den mappa lage en dockyfile som gjør akkurat det jeg ønsker. Vi kan starte på samme måte som tidligere. I forrige uke. Vi kan laste inn fra Ubuntu. Så kan vi kjøre Apt-get-after. Det er viktig å ha med minus Y, for dette må skje automatisk. Men da skal vi ikke installere Apasje denne gangen. Og vi trenger heller ikke dette her. Men det vi trenger å installere, det er det som ble oppgitt på oppgaveteksten.", "source": "lecture"}
{"lecture_id": "linux9del1", "chunk_id": "linux9del1_0005", "start": 406.66, "end": 519.28, "token_count": 286, "text": "I forrige uke. Vi kan laste inn fra Ubuntu. Så kan vi kjøre Apt-get-after. Det er viktig å ha med minus Y, for dette må skje automatisk. Men da skal vi ikke installere Apasje denne gangen. Og vi trenger heller ikke dette her. Men det vi trenger å installere, det er det som ble oppgitt på oppgaveteksten. Så da kopierer jeg litt derfra. De linjene under står det i oppgaveteksten at vi trenger. Da kan jeg tilpasse de til dokkefilen. Ved å passe på å legge til en Y på de linjene, så skulle det bli det samme. Men vi hopper over Apasje. Sånn. Og til slutt så installerer vi python. Som vi husker fra forrige gang, så vil dette gjøres linje for linje. Så... Hvis jeg først har fått den første delen til å virke, og lagt inn de, så vil det gå raskt å legge på neste. Ingenting er gitt. Ingenting ligger i konteineren i utgangspunktet. Den er så tom som bare mulig. Så vi må installere gits.", "source": "lecture"}
{"lecture_id": "linux9del1", "chunk_id": "linux9del1_0006", "start": 488.82, "end": 608.24, "token_count": 297, "text": "Så... Hvis jeg først har fått den første delen til å virke, og lagt inn de, så vil det gå raskt å legge på neste. Ingenting er gitt. Ingenting ligger i konteineren i utgangspunktet. Den er så tom som bare mulig. Så vi må installere gits. Og så etterpå... Nei, jo, så må vi også... Etter at vi har installert gits, så må vi gjøre en git clone. Da må jeg gå ut i oppgaveteksten igjen og finne repositoriet. Det ligger da på GitHub. Og det er linjen til repositoriet. Så dette ser da ut som en OK dokkefeil. Så går jeg ned i vinduet under, hvor jeg fortsatt er på samme sted. Det vil si, jeg må gå inn i sum. Og så må jeg da bygge Dockify. Hvis man ikke husker helt hvordan syntaksen var på Bilt, så kan det være, hvis du har bygget før, så kan det være greit å bla. Da bruker jeg kontroll R, og da ser vi dokkebilde. Her har jeg satt på en time også. Det er fordi at det tar ganske lang tid å bygge dette her.", "source": "lecture"}
{"lecture_id": "linux9del1", "chunk_id": "linux9del1_0007", "start": 584.48, "end": 670.96, "token_count": 294, "text": "Hvis man ikke husker helt hvordan syntaksen var på Bilt, så kan det være, hvis du har bygget før, så kan det være greit å bla. Da bruker jeg kontroll R, og da ser vi dokkebilde. Her har jeg satt på en time også. Det er fordi at det tar ganske lang tid å bygge dette her. Med dokkebilde minus til sum, det gir jeg da et navn til imaget. Prikk betyr at jeg bygger den dokkefilen som jeg ser over, som er i samme mappe. Da begynner dere å jobbe og henter første image. Det er syv stepp her. Det tilsvarer de syv steppene her oppe. Hvert av disse steppene vil legge på et nytt lag. Hvis noe går galt underveis, så kan man gå tilbake og gjøre det på nytt. Da slipper man å gjøre steppet på nytt. Eller hvis det er noe feil med git clone. Og alt det andre er riktig, så kan man bare rette opp Git Klovn. Og så få det til å kjøre. Men som sagt, dette tar ganske lang tid. For det er mye kode å hente. Det tar omtrent åtte minutter.", "source": "lecture"}
{"lecture_id": "linux7del1", "chunk_id": "linux7del1_0000", "start": 0.0, "end": 113.08, "token_count": 234, "text": "Ok. Ja, som sagt. Mike Long, han jobber i et firma som heter Pragma. Og de jobber mye med devops og continuous delivery. Og den teknologien som går ut på at man hele tiden tester de applikasjonene man lager. Ha en stor release... Ops. Sorry. I stedet for å ha en stor release en gang i året, så har man da... Så legger man ut ny kode fortløpende. For å få til det, så er noe sånt som dokker og containere helt nødvendig. Så det er litt av bakgrunnen hans. Det er litt reklame også. Eller reklame... De har en gang i året holdt en gratis åpen introduksjon til continuous delivery. Forhåpentligvis er vi ferdig med Vi skal arrangere et sånt seminar. Det går over fire dager. Det er generelt veldig nyttig for dere. Jeg anbefaler absolutt å melde dere på når dere får beskjed om det senere.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0000", "start": 0.0, "end": 110.04, "token_count": 288, "text": "Som dere ser, så er temaet for i dag konteinere og dokker. For et par år siden hadde vi en gjesteforeleser, Mike Long, som foreleste om dokker. Og han har et veldig bra opplegg. Så det jeg hadde tenkt å gjøre i dag, er å stort sett følge hans opplegg. I tillegg så er... så vil dere se på ukens oppgaver. At det er ikke så veldig mange oppgaver denne uken. Det er først noen fra OS-pensumet som gjelder hypertrening og tråder. Og så er det opplegg... obligatorisk fem. Fire og fem som er de obligatoriske. Oppgave fire går ut på å gå gjennom og teste ut mye av det vi gjør nå. Så er det en litt større oppgave nummer fem, som går ut på at man skal bruke dette til å sette opp en Docker Apache webserver. I tillegg skal man lage en kopi av den. Når man bruker containere, er det lett Målet med i dag er å få til dette her, å komme såpass langt. Å se hvor lett det er å sette opp en webserver med containere, og ikke minst hvor fort det går.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0001", "start": 77.26, "end": 202.92, "token_count": 292, "text": "dette til å sette opp en Docker Apache webserver. I tillegg skal man lage en kopi av den. Når man bruker containere, er det lett Målet med i dag er å få til dette her, å komme såpass langt. Å se hvor lett det er å sette opp en webserver med containere, og ikke minst hvor fort det går. Hvis vi kommer litt lenger, så er ukens utfordring å lage et selskap Det er en litt avansert utgave, men det viser hvor fort og langt man kan komme med å... OK. Så da tenkte jeg å starte først med å fortelle litt om dokker sånn helt generelt. Dere kan laste dere ned direkte fra presentasjonen. Det skal gå an. I tillegg ligger de under filer i kanvas, så dere kan se på de der. Og så er det veldig fint hvis dere stopper og spør. Eller ikke stopper, men dere kan skrive spørsmål i chatten, så skal jeg... Kan jeg svare på spørsmål i pausen også? Ok. Ja, som sagt... Mike Long, han... Han jobber i et firma som heter Pragma, og de jobber mye med devops og continuous delivery.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0002", "start": 171.72, "end": 307.76, "token_count": 290, "text": "Eller ikke stopper, men dere kan skrive spørsmål i chatten, så skal jeg... Kan jeg svare på spørsmål i pausen også? Ok. Ja, som sagt... Mike Long, han... Han jobber i et firma som heter Pragma, og de jobber mye med devops og continuous delivery. I stedet for å ha én stor release én gang i året, så legger man ut ny kode fortløpende. For å få til det, er noe sånt som dokker og containere helt nødvendig. Så det er litt av bakgrunnen hans. Ja, her ser vi en slide om Continuous Delivery. Og det er egentlig litt sånn reklame også. Eller reklame... En gang i året de siste årene så har de holdt en gratis åpen introduksjon til Continuous Delivery. Ja, forhåpentligvis er... Er vi ferdig med koronaviruset i august, så er planen om at de skal arrangere et sånt seminar. Det går over fire dager. Det er generelt veldig nyttig for dere. Så jeg anbefaler absolutt å melde dere på når dere får beskjed om det senere. Men vi skal se på hva er... Hva er dere?", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0003", "start": 270.0, "end": 388.92, "token_count": 287, "text": "Er vi ferdig med koronaviruset i august, så er planen om at de skal arrangere et sånt seminar. Det går over fire dager. Det er generelt veldig nyttig for dere. Så jeg anbefaler absolutt å melde dere på når dere får beskjed om det senere. Men vi skal se på hva er... Hva er dere? Ja. Igjen tar vi utgangspunkt i... Dette er Pragmas utgangspunkt, med at man har en developer som sitter her oppe øverst i diagrammet og skal skrive kode, som så skal bygges og kjøres. I motsetning til å ha store releaser, som er hvert halvår eller hver måned, releases fortløpende kode fra developeren. Og kjører gjennom hele kjeden, inkludert automatiske tester. Da gjør det å bruke containere... Det er bra. Det gjør dette mye enklere, eller det er det som kanskje muliggjør dette i det hele tatt. Derfor er det en sentral del i Continuous Delivery. Ideen med containere i det hele tatt er den samme som på containerskip. At man skal lage en enhet, en liten server som passer.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0004", "start": 352.76, "end": 460.16, "token_count": 296, "text": "Da gjør det å bruke containere... Det er bra. Det gjør dette mye enklere, eller det er det som kanskje muliggjør dette i det hele tatt. Derfor er det en sentral del i Continuous Delivery. Ideen med containere i det hele tatt er den samme som på containerskip. At man skal lage en enhet, en liten server som passer. Her oppe er det dokker. Konteinerne er bygd sånn at de lett kan stables oppå hverandre. Det er også ideen med dokker i dataverden. Man kan få en liten enhet og sette den til å kjøre hvor som helst. I motsetning til i tidligere tider, hvor man hadde store servere, som... Kjørte i maskinrom. De var veldig vanskelige å endre på. Og ikke minst var det vanskelig for utviklere å utvikle kode som fungerte, på mange forskjellige typer servere. Og alt det forenklet enormt ved hjelp av DotGit. Vi kommer nok litt mer til å se på bakgrunnen for dere litt mer teoretisk etter hvert. Målet er å se på teknologien og se hvordan den kan brukes. Det er en del begreper her.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0005", "start": 434.64, "end": 532.34, "token_count": 290, "text": "Og alt det forenklet enormt ved hjelp av DotGit. Vi kommer nok litt mer til å se på bakgrunnen for dere litt mer teoretisk etter hvert. Målet er å se på teknologien og se hvordan den kan brukes. Det er en del begreper her. Det vi skal konsentrere oss om, er Docker Engine. Som på en måte er den installasjonen vi har gjort på Linux-VM-ene. Vi har allerede installert dokker, så for dere skal det bare være å logge inn på Linux-VM. Som Roots, det er det enkleste. Så kan dere da bare kjøre docker. Det skal vi se på i første praktiske del. I tillegg så har man DockerHub. Det er etter hvert veldig viktig. Det skal vi se mer på i neste uke. Det er litt sånn som Gitube, hvor man kan laste ned kode til prosjekter. Så kan man på DockerHub laste ned hele servere og hele systemer som... Dokker images, og så kan man kjøre det. Det er det som skjer når du kjører dokker Hello World, som er det første vi skal gjøre. Da lastes det ned et lite image. Og så kjøres det på lokalmaskinen.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0006", "start": 502.68, "end": 636.04, "token_count": 291, "text": "Så kan man på DockerHub laste ned hele servere og hele systemer som... Dokker images, og så kan man kjøre det. Det er det som skjer når du kjører dokker Hello World, som er det første vi skal gjøre. Da lastes det ned et lite image. Og så kjøres det på lokalmaskinen. Så er det dokkemaskin og dokker composed. Det er begreper som vi ikke... Det er mer for å styre litt større systemer. Ok... ja. Her ser vi et bilde av noe som ser ut som ekte containere. Og en del av... eller kanskje den viktigste ideen er avhengighet. For eksempel så vil det generelt være vanskelig å ta et programsystem og kjøre på en annen servertype. Opplagt hvis du går fra Linux-servere til Window-servere, så er det umulig. Men det er også vanskelig å gå fra Red Hat til... Men det fine med dere er at hele den biten kan enkelt testes ut ved å kjøre containere. Da kan man starte opp en Ubuntu-container og en Reddat-container, og så kan man teste ut og kjøre koden. Det skal vi se på etter hvert. Som vi nok kommer tilbake til.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0007", "start": 592.4, "end": 709.3, "token_count": 285, "text": "Men det er også vanskelig å gå fra Red Hat til... Men det fine med dere er at hele den biten kan enkelt testes ut ved å kjøre containere. Da kan man starte opp en Ubuntu-container og en Reddat-container, og så kan man teste ut og kjøre koden. Det skal vi se på etter hvert. Som vi nok kommer tilbake til. Senere i kurset skal vi snakke mye om virtuelle maskiner. Dere kjører jo allerede på en virtuell maskin nå med de Linux-VM-ene som vi har gitt dere. Hovedpoenget med virtuelle maskiner er å forenkle det å... Å installere, drifte og kjøre servere. Tidligere, sånn ca. 20 år siden, så kjørte alle servere, webservere og databaser og alt, på fysiske servere. Som var bokser eller gjerne rack-servere som sto i store rack, som de fortsatt gjør. Her nede på det grå området her. Infrastruktur. Da var det et host operating system, så kjørte applikasjonene rett på den hosten. Så ser vi til venstre i figuren her. Her står det hypervisor.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0008", "start": 675.98, "end": 769.86, "token_count": 286, "text": "Som var bokser eller gjerne rack-servere som sto i store rack, som de fortsatt gjør. Her nede på det grå området her. Infrastruktur. Da var det et host operating system, så kjørte applikasjonene rett på den hosten. Så ser vi til venstre i figuren her. Her står det hypervisor. Det er dette som er infrastrukturen som gjør at man kan kjøre virtuelle maskiner. Oppå hypervisoren så kjører det tre forskjellige virtuelle maskiner. Helt øverst kjører applikasjonen. Da kan dette være Gest OS. Kan da være forskjellige versjoner av OS. Den røde kan være Ubuntu. Den oransje kan være Red Hat. Og den grønne kan være Fedora f.eks. Eller det kan være det samme. Du kan ha tre sykler av det samme. Men det som hypervisoren gjør, er at den får hver av disse... Den gir det samme API-et som fysisk hardware gir. For en Ubuntu VM som kjører der, ser det ut som den kjører direkte på fysisk hardware. Men i virkeligheten har den et virtuelt API her nede.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0009", "start": 743.36, "end": 848.08, "token_count": 298, "text": "Men det som hypervisoren gjør, er at den får hver av disse... Den gir det samme API-et som fysisk hardware gir. For en Ubuntu VM som kjører der, ser det ut som den kjører direkte på fysisk hardware. Men i virkeligheten har den et virtuelt API her nede. Men alt den gjør, går egentlig gjennom hypervisoren. Dette forenkler veldig. Det med å sette opp, starte og stoppe servere. Men en ulempe, og kanskje den største ulempen med virtuelle maskiner, er at som dere ser her i dette eksempelet, så kreves det tre hele OS. Og de OS-ene er store. Vi snakker om OS som bruker... Mange gigabyte med ram. Hvis du kjører 100 sånne, så tar det opplagt enormt med ressurser. Det er der dokker kommer inn. Og konteinere. For konteinerne som er på høyre side av bildet her, har mye av de samme egenskapene. At man kjører applikasjoner og man kan ha forskjellige operativsystemer. Det kan være igjen Ubuntu, Red Hat og Fedora f.eks. Tre helt forskjellige.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0010", "start": 820.58, "end": 909.94, "token_count": 291, "text": "Det er der dokker kommer inn. Og konteinere. For konteinerne som er på høyre side av bildet her, har mye av de samme egenskapene. At man kjører applikasjoner og man kan ha forskjellige operativsystemer. Det kan være igjen Ubuntu, Red Hat og Fedora f.eks. Tre helt forskjellige. Som applikasjonene kjører på. Men her er det en veldig forenkling, for her er det bare ett underliggende operativsystem. Da er det en docker engine som ligger mellom operativsystemet og dockercontainerne. Som på en måte fyller inn all den forskjellen det gjør. Med virtuelle maskiner bruker man masse ressurser for å få til den fortsettelsen. Derfor er dokker mye enklere på den måten at de bruker mindre ressurser. Og de er lynraske å starte opp. Skal se etterpå at det går veldig fort å starte en Apache-webserver som kjører på dokker. For operativsystemet er allerede i gang. Hvis man starter en stor KVM-VM, så kan det fort ta et halvt minutt å starte. Mens det bare tar sekunder med dokker.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0011", "start": 887.86, "end": 978.32, "token_count": 284, "text": "Og de er lynraske å starte opp. Skal se etterpå at det går veldig fort å starte en Apache-webserver som kjører på dokker. For operativsystemet er allerede i gang. Hvis man starter en stor KVM-VM, så kan det fort ta et halvt minutt å starte. Mens det bare tar sekunder med dokker. Ok. Som sagt, skriv gjerne spørsmål i chatten hvis det er noe dere lurer på. Ja. Dette var litt av det jeg begynte å snakke om. Tilbake på 2000-tallet... Man hadde svære servere. Og så fikk man en periode hvor man begynte å virtualisere. At da i stedet for å ha store fysiske servere som sto og kjørte i årevis, så var det en katastrofe om de gikk ned. Så begynte man å få virtuelle maskiner som var mye mer fleksible. Det er kommet enda lenger i dag med dokker. Det typiske med dokker er at du har én instans, én dokkercontainer, som kjører én tjeneste. Det er det den gjør. Ikke noe annet.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0012", "start": 949.9, "end": 1042.66, "token_count": 299, "text": "Så begynte man å få virtuelle maskiner som var mye mer fleksible. Det er kommet enda lenger i dag med dokker. Det typiske med dokker er at du har én instans, én dokkercontainer, som kjører én tjeneste. Det er det den gjør. Ikke noe annet. Tidligere var det store servere som gjerne kjørte flere tjenester samtidig. Og de sto og gikk i årevis. Og de måtte da vel... Og det var veldig tungt å oppgradere, f.eks. å få inn nye biblioteker osv. Ofte så unngikk man det, så det tok veldig lang tid å oppgradere. Med Dokker så kom man bare i en fei. Plasserte et nytt oppdragsinstitutt med nye biblioteker. Og så er man klar til å kjøre videre med den nye versjonen. Én ting må nevnes når det gjelder Dokker. Det er sikkerhet. Og da, kan man si, generelt er virtuelle maskiner sikrere. Fordi det eneste de gir til VM-ene, er et API. Og det er veldig vanskelig å gjennom det API-et å kunne gå fra én VM til en annen.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0013", "start": 1009.28, "end": 1113.06, "token_count": 286, "text": "Og så er man klar til å kjøre videre med den nye versjonen. Én ting må nevnes når det gjelder Dokker. Det er sikkerhet. Og da, kan man si, generelt er virtuelle maskiner sikrere. Fordi det eneste de gir til VM-ene, er et API. Og det er veldig vanskelig å gjennom det API-et å kunne gå fra én VM til en annen. Det er praksis umulig. I hvert fall. Veldig vanskelig å komme opp her. Skillet er ikke så sterkt mellom to dokkecontainere. Du kan se på det som prosesser som kjører på samme maskin. Hvis du får hacket en av dem, så er det større muligheter til å komme inn på systemet og hacke den andre. Det er det største problemet i forhold til verktøy eller maskin. Nå skal vi straks begynne å kjøre noen containere. Da skal vi se at det er en liten applikasjon. Det er som sagt i praksis en prosess som er veldig avlukket. Ingen andre prosesser i det hele tatt... Nesten i det hele tatt kan se hva som skjer innenfor.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0014", "start": 1089.86, "end": 1190.38, "token_count": 282, "text": "Nå skal vi straks begynne å kjøre noen containere. Da skal vi se at det er en liten applikasjon. Det er som sagt i praksis en prosess som er veldig avlukket. Ingen andre prosesser i det hele tatt... Nesten i det hele tatt kan se hva som skjer innenfor. Vi kan kjøre starte og stoppe og flytte og delete. Og laste ned nye fra Dockerup. Og vi kan også lage egne. Ja. Litt mer om VM-er i forhold til containere. Vi ser på... På høyre side ser vi en VM. Dette er VM-en, som kjører på et gjeste-OS. Så har vi Linux-kjernen her. Så ser vi at en container, det er på en måte midt imellom en vanlig prosess og en VM. Med virtuell maskin kjører prosessen her oppe på gjeste-OS. Mens her, konteineren, vi ser at det er en vanlig prosess, men den er isolert fra alle andre prosesser på en mye bedre måte enn standard. Her på venstre side ser vi det en nevnte, at her kjører de en Ubuntu-konteiner", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0015", "start": 1165.64, "end": 1277.44, "token_count": 287, "text": "Med virtuell maskin kjører prosessen her oppe på gjeste-OS. Mens her, konteineren, vi ser at det er en vanlig prosess, men den er isolert fra alle andre prosesser på en mye bedre måte enn standard. Her på venstre side ser vi det en nevnte, at her kjører de en Ubuntu-konteiner og så kjører de en SentOS-konteiner, men begge to kjører på den samme Linux-jern. Men de trenger en vinduskjerne under. Muligens får vi tid til å se på det også. Litt terminologi... Vi har konteinere. Vi har konteinere av imager. Images er hele... den blokken av konteinere. Hvis man har virtuell maskin, så er et image absolutt hele apparativsystemet og alt som kjører. Mens for konteinere så er et image ikke så stort som hele OS. Det er alt det du trenger for å få en generell Linux-hjerne til å se ut som en ubudt kjører. Man starter images, og en instans som kjører et image, det kalles en container. Neste uke skal vi se litt på volumer, men det vil være lagringsplass for containerne.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0016", "start": 1240.3, "end": 1390.08, "token_count": 294, "text": "og alt som kjører. Mens for konteinere så er et image ikke så stort som hele OS. Det er alt det du trenger for å få en generell Linux-hjerne til å se ut som en ubudt kjører. Man starter images, og en instans som kjører et image, det kalles en container. Neste uke skal vi se litt på volumer, men det vil være lagringsplass for containerne. Opplagt så har de nettverk. Det er egentlig stort sett det vi ser på i dag. Vi tar imager og kjører det. Ja, da skal vi ta oss og kjøre en Hello World. Ja, jeg kan jo ta oss og... Med disse slidene så kan jeg ta og... I stedet for slidene... Det kan sikkert være fint for dere å ha slidene oppe. Men jeg kan da dele... Et dokkervindu med dere i stedet. Sånn. Jeg kan kanskje vise hvordan det er tenkt at dere skal gjøre det. Her er jeg inne på desktopen min, som står nede på bordet mitt. Og så går jeg inn som jeg bruker OS70. Dere bare logger inn på den som vanlig. Ja, generelt så må man bruke sudo for å kjøre dokker.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0017", "start": 1341.16, "end": 1490.04, "token_count": 292, "text": "Sånn. Jeg kan kanskje vise hvordan det er tenkt at dere skal gjøre det. Her er jeg inne på desktopen min, som står nede på bordet mitt. Og så går jeg inn som jeg bruker OS70. Dere bare logger inn på den som vanlig. Ja, generelt så må man bruke sudo for å kjøre dokker. Som jeg snakket om tidligere, dette er VM-er, så man trenger ikke være like bekymret for å kjøre ting som Ruud. Hvis noe galt skjer, går det an å bygge For de som er interessert, kan du se at her ligger en dokker.so. Jeg installerte dokker på VM-en, så var det eneste jeg gjorde, var å kjøre det scriptet der. Det installerer sertifikat og noe greier. Så henter det ned dokker fra dokker.com. Så er det som er installert, dokker. Når man har gjort det, så kan man begynne å kjøre konteinere. Så vi kan starte med dokkesteiner grønn. Også Hello World. Det er en bitte liten dokker hello world. Da ser vi den starter oss oppover. Men da har den kjørt en liten container.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0018", "start": 1452.14, "end": 1600.02, "token_count": 299, "text": "Når man har gjort det, så kan man begynne å kjøre konteinere. Så vi kan starte med dokkesteiner grønn. Også Hello World. Det er en bitte liten dokker hello world. Da ser vi den starter oss oppover. Men da har den kjørt en liten container. Vi kan kanskje gå tilbake til slidene og se på hva som egentlig skjer her. Etter hvert skal vi kjøre litt mer avanserte ting. Istedenfor Hello World kan man kjøre Ubuntu. Da starter opp tilsvarende en hel Ubuntu-server. Dokker-info og dokker-version gir litt informasjon om installasjonen. Så ser vi... Den kommandoen der var det jeg kjørte. Men hva var det som egentlig hendte, da? Når jeg kjører dokker-rund, så er det egentlig flere kommandoer som skjer. Men det er bare dokker-bild, dokker-pull og dokker-rund. Så man kjører egentlig de tre kommandoene der. Og pull, dvs. at den går ut i dokkerhøv, som er et repositorium. Altså et lager av forskjellige dokker-images. Som vi ser her, kan vi hente EngineX eller hele Ubuntu.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0019", "start": 1564.9, "end": 1733.08, "token_count": 286, "text": "Så man kjører egentlig de tre kommandoene der. Og pull, dvs. at den går ut i dokkerhøv, som er et repositorium. Altså et lager av forskjellige dokker-images. Som vi ser her, kan vi hente EngineX eller hele Ubuntu. Så lastes det imaget ned fra Dockerup hit. Det var pull og så rund. Da kjøres det imaget som en container. Disse slidene er bygd opp sånn at her står det... Your turn, hello world. Men da fant jeg ut i går at det er litt problem hvis man trykker på de, så... Jo, så kommer man ikke... Her er en feil med... Den går til exercise. Da får du en feilmelding om at du ikke finner siden. Man trenger ikke gå gjennom det på den måten. Man kan også gå... Vi har en link i oppgavesettet. Prøv å gå dit den måten her. Jeg deler et annet vindu, sånn at vi... Sånn, ja. Hvis jeg trykker her, så ser du det kommer opp en... 04. Hvis jeg da tasser inn null foran eneren her... Tydeligvis er ikke dette oppdatert.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0020", "start": 1680.0, "end": 1864.7, "token_count": 290, "text": "Prøv å gå dit den måten her. Jeg deler et annet vindu, sånn at vi... Sånn, ja. Hvis jeg trykker her, så ser du det kommer opp en... 04. Hvis jeg da tasser inn null foran eneren her... Tydeligvis er ikke dette oppdatert. Da kommer jeg til den riktige. Ellers kan dere følge linken som står i oppgaven. Disse oppgavene er egentlig sånn selv... help contain, som man kan kalle det. Dere kan gå gjennom og så gjøre bit for bit. Men det jeg tenkte, var at vi kan gjøre det sammen. Prøv å gjøre det samtidig som jeg gjør det. Eller alternativt, hvis dere foretrekker, så kan dere slappe av og se på når jeg gjør det første gang. Og så kan dere stille og rolig på egen hånd teste det ut selv senere. Første oppgave har vi allerede gjort. Kjør Love World. Det vi kan prøve å gjøre, er å gjøre en litt mer avansert oppgave. Nemlig å... Start opp en container. Ja, jeg ser at noen har problemer med å se noe her.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0021", "start": 1780.74, "end": 1960.0, "token_count": 283, "text": "Og så kan dere stille og rolig på egen hånd teste det ut selv senere. Første oppgave har vi allerede gjort. Kjør Love World. Det vi kan prøve å gjøre, er å gjøre en litt mer avansert oppgave. Nemlig å... Start opp en container. Ja, jeg ser at noen har problemer med å se noe her. Men at det virker å refreshe sidene. Nå har jeg problemer med å selge et vindu. Sånn. Jeg startet med å kjøre Docker container rundt Hello world. Men da kan jeg prøve å kjøre et helt OS. Hvis jeg skriver minus IT, gir jeg for interaktivt. T er for at en skal sette opp en T10. Så kan jeg f.eks. bare si Ubuntu, for å få opp en Ubuntu-VM. I noen av oppgavene senere kjører de Alpine, som er en sånn mini... Liten Linux-installasjon. Jeg kan starte Ubuntu her, så vi er litt mer vant til det. Så må jeg starte et bæsjvindu også, for å... Nå står den og sier... og da er den ute på og henter ned et image.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0022", "start": 1929.36, "end": 2049.0, "token_count": 286, "text": "I noen av oppgavene senere kjører de Alpine, som er en sånn mini... Liten Linux-installasjon. Jeg kan starte Ubuntu her, så vi er litt mer vant til det. Så må jeg starte et bæsjvindu også, for å... Nå står den og sier... og da er den ute på og henter ned et image. Uansett hva slags Linux jeg har, eller hvilken distribusjon jeg har lokalt her, så vil det imaget sørge for at dette ser helt ut som... Vi har fått opp et promp som Ruth. Jeg er Ruth. Det pleier man å være i de imagene. Vi har et fullt filssystem her. Dette ser ut som en... Eller, det er en praksis. Jeg får opp Ubuntu 1804. Jeg prøver en liste prosesser, så ser vi at det er veldig lite prosesser som kjører. Det er en av de tingene som er gjort med tegnere, at man skiller det helt fra resten av apparativsystemet. Selv om jeg vet at under her er det et fullt OL som kjører. Den store forskjellen nå, hvis jeg kjører exit her, så er hele den containeren", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0023", "start": 2019.94, "end": 2149.36, "token_count": 300, "text": "Jeg prøver en liste prosesser, så ser vi at det er veldig lite prosesser som kjører. Det er en av de tingene som er gjort med tegnere, at man skiller det helt fra resten av apparativsystemet. Selv om jeg vet at under her er det et fullt OL som kjører. Den store forskjellen nå, hvis jeg kjører exit her, så er hele den containeren som jeg startet opp og kjørte, den store forskjellen nå... Den er stoppet fullstendig. Kjører ingenting av det som jeg hadde tillit til. Sånn generelt så kan jeg kjøre dokkecontainer-PS. Da viser jeg alle containere som kjører. Da er det ingen containere som kjører, men hvis jeg legger på AS... Jeg har et stort vindu for å få med alt, så da er det kanskje vanskelig for dere... ... vanskelig for dere å se. Klarer du å se dette? Det er helt på grensen om det går. Poenget er at... Bare si hva det er. Dette er en listing av alle de tre konteinerne som... Ingen av de kjører. Status er 'exited' for alle sammen. Hovedpoenget er når du starter og kjører en konteiner...", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0024", "start": 2114.78, "end": 2218.68, "token_count": 282, "text": "Klarer du å se dette? Det er helt på grensen om det går. Poenget er at... Bare si hva det er. Dette er en listing av alle de tre konteinerne som... Ingen av de kjører. Status er 'exited' for alle sammen. Hovedpoenget er når du starter og kjører en konteiner... Da stopper den igjen etterpå, så fjerner du hele konteineren. Jeg kan prøve å bare starte på nytt. Nå så vi... Nå gikk det mye fortere. Det går egentlig ekstremt kjapt å starte og stoppe en container. Så nei, den kommandoen her startet og stoppet... En hel server, kan du si. Med fysisk server tar det mange minutter. Med en VM tar det fort i hvert fall et halvt minutt. Men med... Ja, jeg ser... Det er ikke timer. Tenkte å prøve å ta tiden på denne. Med dere så går det veldig fort. Der ser du start og stopp på under fem sekunder. OK. Vi skal se mer i detalj på hvordan man stopper og starter. Men jeg tenkte vi kunne gå litt tilbake til høydene.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0025", "start": 2183.92, "end": 2328.84, "token_count": 287, "text": "Ja, jeg ser... Det er ikke timer. Tenkte å prøve å ta tiden på denne. Med dere så går det veldig fort. Der ser du start og stopp på under fem sekunder. OK. Vi skal se mer i detalj på hvordan man stopper og starter. Men jeg tenkte vi kunne gå litt tilbake til høydene. De følgende slidene handler generelt om å kjøre imager, som vi gjorde. Det er mulig å laste ned imager. Hvis jeg kjører docker container-en, så både lastes ned og startes imager. Docker pull og alpine. Et spørsmål her... Er skrivebordsprogrammet f.eks. dokkere? Nei, altså et standard skrivebordsprogram er ikke en dokkerinistans. Et standard skrivebordsprogram er mer sånn klassisk at det er... Det som er spesielt med Docker, er at det typisk bare kjører én eneste tjeneste. F.eks. en regneoppgave eller en webserver eller en database. Men det eneste Docker-instansen gjør, er å kjøre den tjenesten. Da kan man... Det betyr at man da laster ned et image. Som man så kan kjøre.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0026", "start": 2280.02, "end": 2412.42, "token_count": 298, "text": "Det som er spesielt med Docker, er at det typisk bare kjører én eneste tjeneste. F.eks. en regneoppgave eller en webserver eller en database. Men det eneste Docker-instansen gjør, er å kjøre den tjenesten. Da kan man... Det betyr at man da laster ned et image. Som man så kan kjøre. Ja... I neste runde skal vi teste ut noen av disse her. Vi kan bare se kort på hva man kan gjøre. Den kommandoen her... Den starter opp Alpine. Alpine er en liten... Alpine er en liten Linux-versjon som er veldig lett. Ubuntu er stor, mange gigabyte. Alpine er veldig liten og lett. Men det som skjer, er at man starter opp Alpine, gjør LS-L, og så stopper hele containerne. Tilsvarende her så starter man Alpa1 og bare skriver ut. Et skrivebordsprogram har flere dokker som kjører? Nei, det er på en måte helt forskjellige greier. Det spørs hva du mener med et skrivebordsprogram. Men... Generelt så kan du kjøre mange dokkere, mange dokkerinstanser samtidig. En av oppgavene denne uken går på å sette opp ni webservere", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0027", "start": 2385.0, "end": 2510.1, "token_count": 297, "text": "Nei, det er på en måte helt forskjellige greier. Det spørs hva du mener med et skrivebordsprogram. Men... Generelt så kan du kjøre mange dokkere, mange dokkerinstanser samtidig. En av oppgavene denne uken går på å sette opp ni webservere som er helt uavhengige av hverandre, og som kjører dokker. Men det viktige med det oppsettet er at i praksis så bruker alle de ni underliggende kreativsystemet som er det samme. I tidligere tider, når man da brukte VM-er, det gjør man fortsatt, så når man starter ti VM-er, så starter man hele OS for hver av de VM-ene. Det tar mye tid og det tar mye ressurser. Så det er den største forskjellen. Jeg kunne kanskje bare gå inn og se kjapt på hvordan... ser det ut? Ja, nå har jeg gått inn på Dokkerhaug, og her liker det da imager som... Som kan lastes ned. Det vi lastet ned var Ubuntu. Hvis jeg går på Explore her, så vil man se at det er et uttall. Her er det 21 av 3 mill. forskjellige imager.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0028", "start": 2473.58, "end": 2634.02, "token_count": 284, "text": "Ja, nå har jeg gått inn på Dokkerhaug, og her liker det da imager som... Som kan lastes ned. Det vi lastet ned var Ubuntu. Hvis jeg går på Explore her, så vil man se at det er et uttall. Her er det 21 av 3 mill. forskjellige imager. Det er imager som... Av forskjellige typer, som er lastet opp. Her har vi buntet som vi nettopp losset ned. En rekke imager. Da kan man bare lock and run Debian, så får man en Debian-versjon som man... Så kan man også selv laste opp imager til. Det er et stort men, og det er sånn sikkerhetsmessig, altså sånn som Ubuntu følger opp sine egne imager, men det er et generelt problem med sikkerhet. Og man vet hva egentlig et image inneholder. Litt sikkerhetsmessig er det litt mer Mer tvilsomt enn om man installerer systemer og applikasjoner selv. Imagetags kan man også se på i neste... ... gjør det selv. Imagetags er generelt sånn at man kan velge hvilken nasjon Ja, vi tar en pause.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0029", "start": 2566.04, "end": 2769.92, "token_count": 285, "text": "Og man vet hva egentlig et image inneholder. Litt sikkerhetsmessig er det litt mer Mer tvilsomt enn om man installerer systemer og applikasjoner selv. Imagetags kan man også se på i neste... ... gjør det selv. Imagetags er generelt sånn at man kan velge hvilken nasjon Ja, vi tar en pause. For dere som har lyst til å jobbe litt i pausen, så kan dere gå videre og teste ut... Neste slide. Noen slider til. Your turn, running images. Det kan dere gå i gang med. Da tar vi... Da tar vi... ... gutten min. Så kan vi ta dem opp når... Pausen er over. Ja, da starter vi igjen. Det kom et veldig godt spørsmål i chatten i pausen om hvordan dere er nyttige og hvordan. Man bruker det i praksis. Og det er selvsagt ikke absolutt alle som bruker dokker i sine løsninger eller containere, men vi har hatt en enorm vekst i bruken. Spesielt i litt mer moderne områder. F.eks. som finn.no. Da var han overrasket over at de i veldig stor grad brukte dokker.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0030", "start": 2730.0, "end": 2842.94, "token_count": 294, "text": "Man bruker det i praksis. Og det er selvsagt ikke absolutt alle som bruker dokker i sine løsninger eller containere, men vi har hatt en enorm vekst i bruken. Spesielt i litt mer moderne områder. F.eks. som finn.no. Da var han overrasket over at de i veldig stor grad brukte dokker. Det mange bruker er kybernetes, som er et system for å orkestrere dokkerbruk. Altså sette opp store systemer med databaser, webservere som regnesatistikk osv. Sette opp det sammen sånn at det kjører og fungerer. Det er kubernettis. Men hver av de elementene vil bestå av konteinere som gjør sine oppgaver. Sånn konkret for en programmerer så er det man typisk gjør, er å skrive kode og så teste den ut i en dockercontainer. Conteineren vil være akkurat den samme som du kjører i produksjon. Det er nettopp det med å teste kode som man lager, helt og nøyaktig i samme miljø, det å forenkle og sette opp det miljøet, at det kan kopieres og så kjøres i produksjon,", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0031", "start": 2820.02, "end": 2924.68, "token_count": 288, "text": "Conteineren vil være akkurat den samme som du kjører i produksjon. Det er nettopp det med å teste kode som man lager, helt og nøyaktig i samme miljø, det å forenkle og sette opp det miljøet, at det kan kopieres og så kjøres i produksjon, det er det som er kanskje det aller viktigste med dokker og containere. Vi kommer ikke så langt inn på det i denne uke, men jeg tenkte neste uke, så... så kommer vi mer inn på det. Se hvordan vi kan bruke Dockerfiles og definere hvilke biblioteker og hva... Alt som man trenger for å kjøre en viss applikasjon. Det er helt riktig. Den har samme funksjon som Jodhlem, som er Java virtuell maskin. Jodhlem gjør det samme som virtuelle maskiner, som også dere gjør. Den abstraherer bort det underliggende hardwaren. En classfil kan kjøres på forskjellige JVM-er. Du kan ha en JVM på Windows og du kan ha en JVM på Linux. Begge kan kjøre den samme classfilen. På samme måte gjelder det med docker-images.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0032", "start": 2903.56, "end": 3010.02, "token_count": 300, "text": "Den abstraherer bort det underliggende hardwaren. En classfil kan kjøres på forskjellige JVM-er. Du kan ha en JVM på Windows og du kan ha en JVM på Linux. Begge kan kjøre den samme classfilen. På samme måte gjelder det med docker-images. Altså at de kan... ta seg av alle avhengigheter. Sånn at de kan kjøre på forskjellig hardware og også på forskjellige operativstemmer. Likevel får du akkurat det samme miljøet for din applikasjon som du har utviklet. Det er det som er viktig. Hvis man skal utvikle en applikasjon og teste den for ekstremt mange forskjellige miljøer, så blir det veldig vanskelig. Det forenkler lokker for det første med at du kan utvikle i forskjellige containere. Dette er den containeren vi bruker. Alle utviklere og i all drift og all testing brukes nøyaktig dette miljøet. Det miljøet er veldig lett å spre til alle som er innholdet. OK. Your turner and images, ja. Jeg tror egentlig vi har sett på det meste av kjøring. Vi kan kjøre litt flere eksempler.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0033", "start": 2970.02, "end": 3143.16, "token_count": 277, "text": "Dette er den containeren vi bruker. Alle utviklere og i all drift og all testing brukes nøyaktig dette miljøet. Det miljøet er veldig lett å spre til alle som er innholdet. OK. Your turner and images, ja. Jeg tror egentlig vi har sett på det meste av kjøring. Vi kan kjøre litt flere eksempler. Da kan jeg... Linux-VM-vinduet igjen. Vi kan også kjøre det... f.eks. lukket container... Så kan vi beskrive en melding. Hvis vi kjører den, så ser vi. Den finner ikke alpaen lokalt, altså imaget. Dermed så henter den det fra dokker opp og laster ned. Hvis jeg gjør det en gang til, så går det mye fortere. Da kommer det fra alpaen med en gang. Så kan jeg ta igjen og liste... Ja, det var litt rart. Det hadde jeg forventet å... ... det ligge noen... Da ser vi... jeg kan prøve å holde det i den formen så dere ser. Det første som står, er ID-en. Det er også navnet til konteineren.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0034", "start": 3074.0, "end": 3229.12, "token_count": 293, "text": "Så kan jeg ta igjen og liste... Ja, det var litt rart. Det hadde jeg forventet å... ... det ligge noen... Da ser vi... jeg kan prøve å holde det i den formen så dere ser. Det første som står, er ID-en. Det er også navnet til konteineren. Så ser vi image. Her har vi Alpine, Ubuntu og Low World. Det er de tre imagene vi har lastet ned. Status på alle sammen er exit, altså at vi har kjørt dem ferdig. Ja, det er vel stort sett det vi trenger for å kjøre konteinere. Etter hvert skal vi se litt hvordan man... Hvordan man kobler seg til konteinere som kjører. Det vi har gjort nå hele tiden, er at vi har startet konteinere, og så har vi stoppet igjen. Og da ligger imaget der fortsatt, men konteineren selv er stoppet. Og det er akkurat som om man starter en prosess og kjører en prosess. Og stopper en prosess. Det er ikke verre. Deleting skal ikke brukes av veldig mye tid på det. Men konteinere er en veldig kast å bruke. Det gjelder også virtuelle maskiner.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0035", "start": 3202.86, "end": 3307.32, "token_count": 291, "text": "Og det er akkurat som om man starter en prosess og kjører en prosess. Og stopper en prosess. Det er ikke verre. Deleting skal ikke brukes av veldig mye tid på det. Men konteinere er en veldig kast å bruke. Det gjelder også virtuelle maskiner. For dere som kjører skytjenester, er dere vant til at dere bare kan starte på en ny VM. Hvis et eller annet galt skjer, så kan man... Ta et nytt image og start en ny VM. Det samme gjelder konteinere, men i enda høyere grad. Det er kast og bruk. Ja, her er det litt om... vekt for å se på... Jeg tror vi hopper over det. Dere kan jo se på det på egen hånd. Vi kan ta litt på hvordan man sletter konteinere. Generelt, hvis du ikke sletter konteinerne, så ligger alle der når du lister Docker Container LS. Det er ikke noe stort problem, for det tar ikke veldig mye plass. Det er imagene som tar plass. Men det kan bli rotete, så det kan være greit å rydde opp på det. Det sletter da tegnerne. Men Docker Image RM sletter image.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0036", "start": 3286.56, "end": 3404.04, "token_count": 295, "text": "når du lister Docker Container LS. Det er ikke noe stort problem, for det tar ikke veldig mye plass. Det er imagene som tar plass. Men det kan bli rotete, så det kan være greit å rydde opp på det. Det sletter da tegnerne. Men Docker Image RM sletter image. Og image kan ta litt plass. Dere har ikke så voldsomt mye plass på VM-ene. Men dere har noen gigabyte. Men hvis dere kjører veldig mange forskjellige docker-imager, og spesielt store, så kan det ta mye plass. Og da kan det være lurt å slette... Du kan ta dokker image proon. Det vil da fjerne alle. I hvert fall de som ikke er aktivt. Vi kan teste litt fjerning. Skal vi se om... Der kommer det. Så ser vi at jeg har en liste med tegnere. Så kan jeg... ta RM på en av de. Den ID-en der, det er faktisk det samme som host name. Men det har også... Vi ser alle har en del sånne rare navn. Man kan også bruke det navnet, som er enklere å huske. Men nå tar jeg bare sletter med ID-en. Hvis jeg lister på nytt nå,", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0037", "start": 3379.82, "end": 3509.02, "token_count": 290, "text": "Den ID-en der, det er faktisk det samme som host name. Men det har også... Vi ser alle har en del sånne rare navn. Man kan også bruke det navnet, som er enklere å huske. Men nå tar jeg bare sletter med ID-en. Hvis jeg lister på nytt nå, så forsvant en av vennene mine. Container, da. Kan jeg ta den Tender Williams, f.eks.? Vi kan prøve Loving Shed. Da forsvant den også. Hvis jeg tar bare dokker, container, LS, så får jeg bare de som kjører. Men det er ingen nå. Minus A gir alle. Så så vi at vi hadde en prun. Jeg kan prøve sånn som det. Da ser vi... Slette alle Stop containers. Da sier jeg ja, og da sier jeg... alle. Så der er alle borte. En gang iblant så kan det være greit å rydde opp. Jeg skrev kommandoen feil. Skal prøve å få øye på hva jeg gjorde feil. Ja, jeg skrev docker images ls, og da fikk jeg ikke opp noen ting. Det kan kanskje være instruktivt, for jeg fikk ikke noen god feilmelding heller.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0038", "start": 3480.02, "end": 3629.96, "token_count": 295, "text": "Jeg skrev kommandoen feil. Skal prøve å få øye på hva jeg gjorde feil. Ja, jeg skrev docker images ls, og da fikk jeg ikke opp noen ting. Det kan kanskje være instruktivt, for jeg fikk ikke noen god feilmelding heller. Men det er viktig å ha syntaksen riktig. Docker image LS. Da ser jeg... Disse tar litt mer plass. Men... Så disse imagene kan det være lurt å rydde opp i. Men likevel tar det ikke så voldsomt plass. 64 MB er veldig lite for en ubuntu. Så tar det i hvert fall en white med disk-plass. Så man kan også slette disse... Da forsvant den. Og da betyr det ganske enkelt... Hvis jeg nå starter en ny Ubuntu... Vi kan prøve å starte 14.04, så får vi til det. Det jeg gjorde nå, var at jeg ikke ba om et skjell. Da skal vi si at da får jeg ikke opp noe skjell som jeg kan gjøre noe inni. Jeg ser nå, siden jeg ikke hadde lastet ned 1404 før, så blir den lastet opp. En... Jo, jeg fikk faktisk opp et skjell likevel.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0039", "start": 3600.0, "end": 3738.68, "token_count": 283, "text": "Det jeg gjorde nå, var at jeg ikke ba om et skjell. Da skal vi si at da får jeg ikke opp noe skjell som jeg kan gjøre noe inni. Jeg ser nå, siden jeg ikke hadde lastet ned 1404 før, så blir den lastet opp. En... Jo, jeg fikk faktisk opp et skjell likevel. Housename er den ID-en som vi får når vi lister opp. Det dere kan se nå, er at... Hvis jeg nå går ut igjen og lister images, så ser vi at nå har jeg fått opp den. Den er litt mindre. Da ser vi igjen. Andre gang jeg kjører, så går det mye fortere. Da skal vi se på ett poeng som er viktig i forhold til å sette opp webservere. Det vi skal prøve nå, er å få til en maskin som gjør en liten webserver, som da kan ta oss fra hvor som helst. I utgangspunktet så har vi ikke noe nettverk Vi er inne på et privat nettverk, så vi har nett, kan kjøre AppGet, AppDate osv. Her ser vi et eksempel med NGNX, som er dockerinstans som kjører en webserver.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0040", "start": 3709.76, "end": 3822.96, "token_count": 299, "text": "som da kan ta oss fra hvor som helst. I utgangspunktet så har vi ikke noe nettverk Vi er inne på et privat nettverk, så vi har nett, kan kjøre AppGet, AppDate osv. Her ser vi et eksempel med NGNX, som er dockerinstans som kjører en webserver. Etterpå skal vi prøve oss å bare kjøre Ubuntu og installere Apache2, som tidligere. Vi gjør som tidligere, dere container run. Men det vi har med her, er minus P 80-80 kolon 80. Det betyr at hvis man sender en innkommende forespørsel på port 8080 til hosten, hosten er i vårt tilfelle Linux VM, så... Ved hjelp av såkalt port forwarding, som man sender videre pakkene til port 80 på konteineren. Så man oversetter pakker som kommer inn med PSB-hedder. Det blir oversatt til 80 og så sendt videre til konteineren. På den måten kan man da sette opp en webserver her på konteineren. Som svarer på innkomne forespørsler. Man kunne også hatt port 80 til 80. Da ville du gått rett inn til konteineren.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0041", "start": 3793.16, "end": 3936.42, "token_count": 296, "text": "med PSB-hedder. Det blir oversatt til 80 og så sendt videre til konteineren. På den måten kan man da sette opp en webserver her på konteineren. Som svarer på innkomne forespørsler. Man kunne også hatt port 80 til 80. Da ville du gått rett inn til konteineren. Men på denne måten kan man da ha én webserver som kjører på port 80 på hosten, og så kan man ha en annen som kjører på port 80 på konteineren. Men så kan man da velge hvilken av de to man... Og få dem til å kjøre som en webserver i Linux-VM, som kan nås utenfra. Ja, der var det your turn allerede. Da kan vi hoppe rett til overwarding. Da skal vi dele... da skal vi få opp... Ja... I oppgaven i dag så står det, i eksempelet på slidene til Mike, eller til opplegget til Rahma, så står det port 8080. Og det er et problem. Hvis man kjører port 8080, så får man ikke kontakt med serveren. Nei, vi tar en annen port med en gang, sånn at det virker.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0042", "start": 3900.0, "end": 4030.0, "token_count": 280, "text": "Ja... I oppgaven i dag så står det, i eksempelet på slidene til Mike, eller til opplegget til Rahma, så står det port 8080. Og det er et problem. Hvis man kjører port 8080, så får man ikke kontakt med serveren. Nei, vi tar en annen port med en gang, sånn at det virker. Problemet med port 8080 er at den ble stoppet i brannmuren inn til OsloMet. Så hvis man da kommer utenfra og prøver å koble seg til, så funker det ikke. Så hvis vi tar port 7979, sender vi den videre til port 80, og så kjører vi EngineX. Da laster jeg opp... EngineX. Den starter å kjøre. Nå står den her og kjører. Det vi må teste ut da, er hvordan kan vi... Da... trenger jeg et bråsevindu. Sånn. Og nå er jeg... Jeg var jo på OS70. Det går til OS70 v-lab der. Så i dag får jeg den... Den kan ikke nås. Jeg har ikke noen webserver som kjører, men hvis jeg da tar 79, så kommer jeg", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0043", "start": 3990.0, "end": 4177.2, "token_count": 298, "text": "Da... trenger jeg et bråsevindu. Sånn. Og nå er jeg... Jeg var jo på OS70. Det går til OS70 v-lab der. Så i dag får jeg den... Den kan ikke nås. Jeg har ikke noen webserver som kjører, men hvis jeg da tar 79, så kommer jeg \". Velkommen til EngineX.\" Da er det den webserveren som står der og kjører. Hva er neste stepp her? Neste steg er da attaching og executing, altså hvordan man setter opp en konteiner som står og kjører i bakgrunnen. Og hvordan man kan gå inn på den og endre den. Så det vi kan... Det vi kan prøve å få til, er å gjøre det tilsvarende med en utgift. Da er det et par måter å koble seg til konteineren som står og kjører på. En er attach og en annen er execute. Da er vi egentlig rett over på neste. Del fem er vel den vi hadde tenkt å... Det er det vi hadde tenkt å få til i dag. Ja, vi kan også prøve å installere Ubuntet, som vi er litt mer kjent med. Og teste hvordan vi kan starte opp Ubuntu og koble oss inn og ut.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0044", "start": 4129.32, "end": 4296.84, "token_count": 299, "text": "Da er vi egentlig rett over på neste. Del fem er vel den vi hadde tenkt å... Det er det vi hadde tenkt å få til i dag. Ja, vi kan også prøve å installere Ubuntet, som vi er litt mer kjent med. Og teste hvordan vi kan starte opp Ubuntu og koble oss inn og ut. Da skal jeg først... stoppe EngineX. Jeg bare tok kontroll C, så stoppet den. Hvis jeg nå prøver å laste websiden, så vil den være borte. For vi kan... Neste konteinere... LS-minus-A. Da ser vi... Jeg har flere konteinere, men alle tre er exitet. Så kan jeg prøve å starte en... Prøve å starte en ubundet konteiner. Dere konteinere. Men så kan jeg ta minus D. Den betyr... Legg den i bakgrunnen. Så kan jeg ta minus IT også. Som et skjell. Så vil jeg la den laste ned. Vi begynte på nytt og starter den opp. Nå hadde jeg opsjonen minus D, så nå er jeg fortsatt i Linux-VM. Da må jeg prøve å liste konteinere. Da ser vi Docky container PS. Jo, her har jeg en container som står og kjører.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0045", "start": 4260.0, "end": 4407.82, "token_count": 292, "text": "Vi begynte på nytt og starter den opp. Nå hadde jeg opsjonen minus D, så nå er jeg fortsatt i Linux-VM. Da må jeg prøve å liste konteinere. Da ser vi Docky container PS. Jo, her har jeg en container som står og kjører. Men så må vi da prøve å klare å koble oss til den containeren. Hvis jeg tar PS minus A, så ser vi at da får jeg opp alle. Den eneste som har status up, det er den siste. Én måte å koble seg opp til en konteiner på, det er å bruke Execute. Lage en kobling, og så skal vi se. Den konteineren vi kjører, den har den i den der. Bruker den konteineren i den. Så kjører jeg selv litt bæsj. Da ser vi. Nå er jeg inne i Ubuntu-konteineren. Her kan jeg gjøre hva jeg vil. Og hvis jeg nå ønsker å... Lage en webserver av denne konteineren, så kan jeg... Det fungerer. For å installere Apache 2 nå, så er jeg akkurat sånn som man kan gjøre i Linux-VM. Installerer AppGetInstallApache2. Eller som jeg gjorde det nå.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0046", "start": 4361.28, "end": 4512.24, "token_count": 288, "text": "Her kan jeg gjøre hva jeg vil. Og hvis jeg nå ønsker å... Lage en webserver av denne konteineren, så kan jeg... Det fungerer. For å installere Apache 2 nå, så er jeg akkurat sånn som man kan gjøre i Linux-VM. Installerer AppGetInstallApache2. Eller som jeg gjorde det nå. Det som skjer nå, er at dette gjøres lokalt i imaget. Imaget vil nå endre seg. Hvis du lister størrelsen på imaget, vil du se at dette er litt større enn det originale buntimaget som vi la inn. Det er ikke så rart, for alt jeg gjør nå, vil gjøre at dette imaget, De blir forskjellige fra andre imager. Fra det originale imaget. Da trenger det litt mer plass på å... Det trenger litt mer plass for å lagre all den informasjonen. Men man kan ta Apache... Nei. Apache 2, og så start. Gjør jeg det, så vil jeg nå starte en Apache webserie-brett. Og da... Jeg ser at i den dokkerinstansen her nå, så kjører jeg Apache. Hvis jeg tar exit nå, så vil... Så vil hele containeren stoppe.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0047", "start": 4470.02, "end": 4604.88, "token_count": 291, "text": "Men man kan ta Apache... Nei. Apache 2, og så start. Gjør jeg det, så vil jeg nå starte en Apache webserie-brett. Og da... Jeg ser at i den dokkerinstansen her nå, så kjører jeg Apache. Hvis jeg tar exit nå, så vil... Så vil hele containeren stoppe. Men det man kan gjøre, er å ta kommandosekvensen kontroll P, kontroll Q. Jeg gjør nå kontroll P, kontroll Q mens jeg holder kontroll inne. Da ser vi... Jeg går ut og... ut av containeren igjen. Mens konteineren med ubunter på, den står fortsatt og kjører. Men... Så nå kjører det en konteiner... Nei, nå kjører det en BEPS-server på port 80 inni denne konteineren. Det jeg ikke gjorde når jeg skulle starte denne, var å lage en port-forwarding. Sånn som jeg gjorde på den andre containeren. Da er det mulig jeg må starte opp den på nytt for å få til port-forwarding. Det er å se litt på en av oppgavene denne uken, som går ut på å lage en... Lage en kopi av en eksisterende konteiner.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0048", "start": 4570.68, "end": 4697.9, "token_count": 292, "text": "Sånn som jeg gjorde på den andre containeren. Da er det mulig jeg må starte opp den på nytt for å få til port-forwarding. Det er å se litt på en av oppgavene denne uken, som går ut på å lage en... Lage en kopi av en eksisterende konteiner. Hvis jeg nå bare stopper denne konteineren, så... Så kan jeg ikke starte den opp igjen med det samme innholdet. Så... Nå har jeg lagd... jeg lister image der nå... Container image LS. Image. Docker image LS. Så ser vi at jeg har en Ubuntu. Men den Ubuntu-en der, det er en plain Ubuntu uten webserver. Jeg har gjort endringer, så jeg vil lage en kopi av den tegneren. Det jeg kan gjøre da, er å... Bruke kommandoen docken contain commit. Commit er sånn generelt det man gjør når man skal commite kode. Hvis man har lagd ferdig kode, så vil man sende til Github eller andre steder. Men i dette tilfellet vil jeg nå committe å lage en kopi av min eksisterende Ubuntu. Da tegner de ID-en til Ubuntu. Det er den her. Der du ser den står og kjører.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0049", "start": 4668.02, "end": 4769.0, "token_count": 290, "text": "Commit er sånn generelt det man gjør når man skal commite kode. Hvis man har lagd ferdig kode, så vil man sende til Github eller andre steder. Men i dette tilfellet vil jeg nå committe å lage en kopi av min eksisterende Ubuntu. Da tegner de ID-en til Ubuntu. Det er den her. Der du ser den står og kjører. Så commit, nå vil jeg lage en kopi av den her. Så vil jeg kalle den f.eks. Apache Ubuntu. Det er da en Ubuntu med en Apache-server. Vi ser dette tar litt tid, for den må da kopiere hele imaget. Der var den ferdig, så når jeg lister imaget nå, gjør jeg at jeg har fått et nytt image som heter Apache Ubuntu. Og som er en god del større enn det standard-Ubuntu-imaget. Nå har det fått inn en hel webserver her oppe. Så kan jeg prøve å starte det imaget, og så kan jeg prøve å fortere forwarde det til det imaget. Da kan jeg gjøre omtrent det samme som jeg gjorde her med Ginex. Bare for å se at det er noe annet, så kan jeg ta et annet portnummer her.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0050", "start": 4744.88, "end": 4923.66, "token_count": 292, "text": "Så kan jeg prøve å starte det imaget, og så kan jeg prøve å fortere forwarde det til det imaget. Da kan jeg gjøre omtrent det samme som jeg gjorde her med Ginex. Bare for å se at det er noe annet, så kan jeg ta et annet portnummer her. Innkommende request til port 7878 på Linux-VM-en min nå, det vil jeg sende til port 80. Så vil jeg kjøre det på... ... bakgrunn. Jeg vil sende det nå til Apartsjubuntu. Nå prøver jeg å starte en ny konteiner som inneholder den serveren jeg satte opp. Da kan jeg prøve å koble meg til den med Execute. Da går jeg igjen på den. Kobler meg til den nye kopien, en Apache-bunte. Hvis jeg hadde vanlig Ubuntu-image, så ville jo ikke det gått. Her ser vi. Her fungerer det. Har nå en Apache-server... Hvis jeg nå gjentar kontroll-p, kontroll-q, og har lister, så ser vi... Her står den og kjører. Så skulle jeg nå kunne gå inn i et webvindu og prøve å koble meg til. Jeg skal åpne vinduet for dere.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0051", "start": 4868.84, "end": 5050.0, "token_count": 300, "text": "Her ser vi. Her fungerer det. Har nå en Apache-server... Hvis jeg nå gjentar kontroll-p, kontroll-q, og har lister, så ser vi... Her står den og kjører. Så skulle jeg nå kunne gå inn i et webvindu og prøve å koble meg til. Jeg skal åpne vinduet for dere. Her ser vi den gamle siden med 7979. Hvis jeg nå beholder den, så er det naturlig nok ikke noe der, for der kjører ikke den NGINX-containeren lenger. Jeg prøver 7878. Da ser vi... Jo, her kommer Apache-serveren ut. Den ser ut som en default Apache-server, så det er ikke så lett å se forskjellen på det. Men vi kan prøve å gå inn på... Og bare endre litt på teksten på avanseserveren. Det er også en del av oppgaven denne uken å gjøre akkurat det. Så kan jeg ta app install her på Vemund. For det har jeg tydeligvis ikke gjort før. Nå jobber jeg på to nivåer. Det jeg prøver først her, er å installere Apache-VM på Linux. Da går jeg inn på porten på LinuxV og skal få opp Apache-serveren som kjører her.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0052", "start": 4989.8, "end": 5132.86, "token_count": 299, "text": "Så kan jeg ta app install her på Vemund. For det har jeg tydeligvis ikke gjort før. Nå jobber jeg på to nivåer. Det jeg prøver først her, er å installere Apache-VM på Linux. Da går jeg inn på porten på LinuxV og skal få opp Apache-serveren som kjører her. Men først skal jeg prøve å koble meg opp til konteineren som kjører Apache.  Den konteineren står nå på og kjører Apache til port 80. Men alt som sendes til 7878, vil sendes videre til den konteineren. Men det er ikke særlig nyttig å kjøre webserver hvis du ikke kan endre på innholdet. Det vi gjør i dag, er at vi går direkte inn på konteineren og endrer på innholdet der. Det som er mer vanlig, og som vi skal gjøre neste uke, det er å gå... Ha et volum som er... Som ligger utenfor containeren. Sånn at containeren bare kjører webserveren og leser filer fra det volumet. Men det ser vi på i neste uke. Nå skal vi ta nok Container PS. Da ser vi den konteineren som står og kjører. Det er da den der.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0053", "start": 5107.98, "end": 5279.92, "token_count": 294, "text": "Som ligger utenfor containeren. Sånn at containeren bare kjører webserveren og leser filer fra det volumet. Men det ser vi på i neste uke. Nå skal vi ta nok Container PS. Da ser vi den konteineren som står og kjører. Det er da den der. Så kobler jeg meg inn til den konteineren. Og så går jeg til der hvor webserveren ligger. Så kan jeg skrive f.eks.... Image fra OS70. Sånn. Så kan jeg legge det inn i indeks 1212 der i stedet. Jeg kan altså sjekke det lokalt ved å... be om å bruke køl. Og så be om en side. Nei. Har ikke køl her. Har jeg vegget, da? En applaus fordel med både konteinere og VM-er, er at du kan installere hva du vil. Og styre akkurat som du selv vil. Vi ser også at konteinere er veldig minimalistiske. De skal være så små som bare mulig for å bruke minst mulig ressurser. Og så kan man tilpasse det med hvor flott det er man med. Nå kan jeg gå ut og sjekke webserveren, om den virker.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0054", "start": 5236.54, "end": 5359.72, "token_count": 297, "text": "Og styre akkurat som du selv vil. Vi ser også at konteinere er veldig minimalistiske. De skal være så små som bare mulig for å bruke minst mulig ressurser. Og så kan man tilpasse det med hvor flott det er man med. Nå kan jeg gå ut og sjekke webserveren, om den virker. Nå har vi satt på 7878, så skal det fortsatt stå en webserver og kjøre. Nå skal den være endret til det vi... Nei... Skal vi se når den dukker opp hos seere. Da ser vi docker-image fra OS70. Det er den endringen som jeg gikk inn på docker-containeren og endret. Da ser vi med det samme, hvis jeg nå bare går inn på OS70, da får vi den default-pagen. Dette er nå en tjeneste fra webserveren på LinuxV. Med en gang jeg skriver 7878 her nå... Så default for en webserver er å koble seg til på port 80. Så hvis jeg eksplisitt skriver port 80 her, så kommer jeg til den samme siden. Men jeg kan generelt be om hvilken som helst port. Så hvis jeg nå... Det jeg gjør nå, egentlig, det er å be broseren", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0055", "start": 5338.04, "end": 5442.92, "token_count": 287, "text": "Så default for en webserver er å koble seg til på port 80. Så hvis jeg eksplisitt skriver port 80 her, så kommer jeg til den samme siden. Men jeg kan generelt be om hvilken som helst port. Så hvis jeg nå... Det jeg gjør nå, egentlig, det er å be broseren om å koble seg til webserveren på OS70 på port 7878. Når jeg gjør det, så er docky satt opp sånn at alt som sendes inn til port 78-78, det videresender til docky-imaget til docky-containeren som står og kjører. Og port 80. Og da ser vi. Dermed så får jeg opp den. Dermed så får jeg opp babysurmeren som vi har laget på Docky-inside. Det er bare helt til slutt å se om... Ja, der var Kurl ferdig. Sånn. På den måten så kan man teste... ... teste at webserveren funker. Kurl 127.001, det er... Da får man kontakt med local host. Man kunne vel også gjort noe sånt. Det fungerer også. Så på den måten kan du enkelt teste om WebStore-en funker.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0056", "start": 5408.1, "end": 5537.48, "token_count": 284, "text": "Sånn. På den måten så kan man teste... ... teste at webserveren funker. Kurl 127.001, det er... Da får man kontakt med local host. Man kunne vel også gjort noe sånt. Det fungerer også. Så på den måten kan du enkelt teste om WebStore-en funker. Nå er jeg inne i containeren. Dere kan se at på host name er du enda sikrere. Det kan da sjekke om webserveren virker. Hvis den virker, men du ikke kommer inn utenfra, da er det noe med hvordan du har startet... Hvordan du har startet... Skal jeg se... Jeg hadde vel... Nei, det var jo ikke her jeg gjorde det. Da er det kontroll P og Q, og så går jeg ut. Den kommandoen skulle jeg ha frem. Med den kommandoen så startet jeg da Apache Buntu-imaget sånn at det blir portforwarding mellom 78 og 78. Ok. Da har vi tre minutter over den tilmålte tiden. Så da...... skal vi slutte her. Men vi har lab etterpå. Så vi tar en pause. Så kommer vi tilbake... Jeg kommer også tilbake etter pausen.", "source": "lecture"}
{"lecture_id": "linux7", "chunk_id": "linux7_0057", "start": 5508.28, "end": 5557.56, "token_count": 122, "text": "det blir portforwarding mellom 78 og 78. Ok. Da har vi tre minutter over den tilmålte tiden. Så da...... skal vi slutte her. Men vi har lab etterpå. Så vi tar en pause. Så kommer vi tilbake... Jeg kommer også tilbake etter pausen. Det jeg hadde tenkt å prøve å få til, som jeg ikke har prøvd før heller, er at jeg åpner Såkalte... hva heter det... Breakout rooms. Lager tre breakout rooms.", "source": "lecture"}
{"lecture_id": "os9del4", "chunk_id": "os9del4_0000", "start": 0.0, "end": 95.9, "token_count": 294, "text": "Prioritet er viktig å ha mellom prosesser. Dvs. det er viktig å kunne skille prosesser på prioritet. Og vi så i forrige uke at Linux opererer med noe sånn som 140 prioritetsklasser. Fra lav prioritet opp til høy. Og det Linux-scheduleren gjør, er å gi... Mange tics, eller en lang time-slice, til prosesser med høy prioritet. Og så velger man alltid den med høyest prioritet når man skal kjøre. Dvs. når scheduler kommer inn og skal gjøre en vurdering av hvilken prosess som skal settes i gang. Men sånn grovt sett så er det rollen robin. Man bare bytter på de... De som kjører. For i praksis vil det da bli en Ron Robin. Selv en prosess som har høy prioritet og kommer først inn, når den er ferdig med sine tics i epoken, så vil den hoppe til neste. Og det er det som er Ron Robin. Dynamisk så vil den Linux-skadeleren gjøre det sånn at interaktive brukerprosesser får høyere prioritet. Sånn at med en gang de skal gjøre noe, så går de foran i køen.", "source": "lecture"}
{"lecture_id": "os9del4", "chunk_id": "os9del4_0001", "start": 76.96, "end": 147.88, "token_count": 282, "text": "Og det er det som er Ron Robin. Dynamisk så vil den Linux-skadeleren gjøre det sånn at interaktive brukerprosesser får høyere prioritet. Sånn at med en gang de skal gjøre noe, så går de foran i køen. Men de bruker gjerne ikke mye SUPU, så med en gang de er ferdige, så hopper de ut igjen. Mens batchjobber som står og bruker SUPU hele tiden, de har da lav prioritet. Men de jobber da hele tiden når ingen andre vil jobbe. Og det skal vi se på etterpå med Nice. Og det kan vi gjøre enda mer ekstremt. Vi kan velge å være Nice og være enda mer vertsjobb. Spesielt så er det en del kjerneprosesser som jobber etter first come, first served. Og de kommer deg rett inn i køen, og de kan ikke kjøre Ron Robin, for de må da fullføre før noen andre kan kjøres. Og det er typisk å ha veldig korte prosesser som blir raskt ferdig, men de kommer inn, og så utfører de alt de skal, og så avslutter de.", "source": "lecture"}
{"lecture_id": "os9del4", "chunk_id": "os9del4_0002", "start": 127.76, "end": 215.0, "token_count": 296, "text": "Og de kommer deg rett inn i køen, og de kan ikke kjøre Ron Robin, for de må da fullføre før noen andre kan kjøres. Og det er typisk å ha veldig korte prosesser som blir raskt ferdig, men de kommer inn, og så utfører de alt de skal, og så avslutter de. For andre operativstemmer. Alle har en typeprioritering sånn som dette her. Generelt så finnes det mange scheduling- eller scheduleringsalgoritmer. Og den vi har sett på med Linux, er One Robin. Da bytter prosesser på å kjøre. Det tar litt tid hver runde. Og det finnes jo mange andre tilfeller hvor man bruker schedulering.  Alle disse metodene her brukes også i andre sammenhenger. Det er alle sammenhenger hvor man har ressurser man skal dele på. Som regel er det tidsressurser, men det kan også være andre ressurser. First come, first served. Det som navnet sier, så er den første prosessen som kommer inn, den blir først prosessert. Det er den som setter i gang uansett. Fifo er first in, first off. Førsten som kommer inn, er den første som blir ferdig, og første som sendes ut.", "source": "lecture"}
{"lecture_id": "os9del4", "chunk_id": "os9del4_0003", "start": 192.14, "end": 256.32, "token_count": 246, "text": "First come, first served. Det som navnet sier, så er den første prosessen som kommer inn, den blir først prosessert. Det er den som setter i gang uansett. Fifo er first in, first off. Førsten som kommer inn, er den første som blir ferdig, og første som sendes ut. SJDF, eller 'Shortest Job First', er en litt annen måte å gjøre det på. Da er det den prosessen som tar kortest tid, som er den neste som kjøres. F.eks. hvis man skal printe ut ting, så kan det være en smart måte. Sånn at det er fem sikkerhetsnummer som skrur ut én side, så gjør man det først, og så kommer den som skal ha 150 sider. Den kommer til slutt. Det er ikke alltid så lett å få til det, for da må man vite lengden på prosesseringen. Og det vet man generelt ikke når det gjelder prosesser. Så for prosesser så er det ikke så vanlig å ha den type skrift.", "source": "lecture"}
{"lecture_id": "linux7del4", "chunk_id": "linux7del4_0000", "start": 0.0, "end": 102.14, "token_count": 281, "text": "Dette er et viktig diagram som vi nok kommer tilbake til. Senere i kurset skal vi snakke mye om virtuelle maskiner. Dere kjører allerede på en virtuell maskin nå, med de Linux-vevene vi har gitt dere. Er å forenkle det å... installere, drifte og kjøre servere. Tidligere, sånn ca. 20 år siden, så kjørte alle servere, webservere, databaser og alt, på fysiske servere. Som var bokser eller gjerne rackservere som sto i store rack, som de fortsatt gjør. Men da... Applikasjonene kjørte direkte på hardware. Altså her nede på det grå området. Da var det et host operating system, og så kjørte applikasjonene rett på den hosten. Til venstre i figuren her, så ser vi her står det hypervisor. Det er dette som er infrastrukturen som gjør at man kan kjøre virtuelle maskiner. Oppå hypervisoren kjører det tre forskjellige virtuelle maskiner. Helt øverst kjører applikasjonen. Da kan dette være Gest OS.", "source": "lecture"}
{"lecture_id": "linux7del4", "chunk_id": "linux7del4_0001", "start": 78.36, "end": 170.12, "token_count": 297, "text": "Til venstre i figuren her, så ser vi her står det hypervisor. Det er dette som er infrastrukturen som gjør at man kan kjøre virtuelle maskiner. Oppå hypervisoren kjører det tre forskjellige virtuelle maskiner. Helt øverst kjører applikasjonen. Da kan dette være Gest OS. Det kan være forskjellige versjoner av OS. Den røde kan være Ubuntu. Den oransje kan være Red Hat, og den grønne kan være Fedora f.eks. Eller det kan være det samme. Du kan ha tre sykler av det samme. Det som hypervisoren gjør, er at den for hver av disse virtuelle maskinene, så gir den det samme API-et som fysisk hardware gir. Og for en Ubunte VM som kjører her, så ser det akkurat ut som den kjører direkte på fysisk hardware. Men i virkeligheten så har den et virtuelt API her nede. Men alt den gjør... Det går gjennom hypervisoren. Dette forenkler veldig det med å sette opp, starte og stoppe servere. Men en ulempe, og kanskje den største ulempen med virtuelle maskiner, er at", "source": "lecture"}
{"lecture_id": "linux7del4", "chunk_id": "linux7del4_0002", "start": 145.98, "end": 248.82, "token_count": 300, "text": "Men alt den gjør... Det går gjennom hypervisoren. Dette forenkler veldig det med å sette opp, starte og stoppe servere. Men en ulempe, og kanskje den største ulempen med virtuelle maskiner, er at som dere ser her på dette eksempelet, så kreves det tre hele OS. De OS-ene er store. Vi snakker om OS som bruker mange gigabyte med ram. Hvis du kjører 100 sånne, så tar det opplagt enormt med ressurser. Og det er der docker kommer inn. Og konteinere. For konteinerne som er på høyre side av bildet her, har mye av de samme egenskapene. Man kjører applikasjoner og man kan ha forskjellige operativsystemer. Det kan være igjen Ubuntu, Red Hat og Fedora f.eks. Tre helt forskjellige. Som applikasjonene kjører på. Men her ser vi... Her er det en veldig forenkling, for her er det bare ett underliggende operativsystem. Da er det en docker engine som ligger mellom operativsystemet og dockercontainerne. Som på en måte fyller inn all den forskjellen det gjør å være Ubuntu, Fedora eller Red Hat.", "source": "lecture"}
{"lecture_id": "linux7del4", "chunk_id": "linux7del4_0003", "start": 225.64, "end": 283.6, "token_count": 212, "text": "Men her ser vi... Her er det en veldig forenkling, for her er det bare ett underliggende operativsystem. Da er det en docker engine som ligger mellom operativsystemet og dockercontainerne. Som på en måte fyller inn all den forskjellen det gjør å være Ubuntu, Fedora eller Red Hat. Her med virtuelle maskiner, så bruker man en masse ressurser for å få til den fortsettelsen. Så derfor er Docker mye enklere på den måten at de bruker mindre ressurser, og de er lynraske å starte opp. Skal se etterpå at det går veldig fort å starte en Apache. ... webserver som kjører på dokker. For operativsystemet er allerede i gang. Hvis man starter en stor KVM-VM, så kan det fort ta et halvt minutt å starte. Mens det bare tar sekunder med dokker.", "source": "lecture"}
{"lecture_id": "os4del13", "chunk_id": "os4del13_0000", "start": 0.0, "end": 107.66, "token_count": 297, "text": "Ok, da skal vi gå videre med C-programmering og se på... Ja, og se på hvordan denne maskinkoden som vi så i simuleringen, hvordan den faktisk er mer eller mindre akkurat den samme når vi... Kompilerer høynivåspråk ned til maskinkode. For heldigvis så slipper programmerere å skrive maskinkode. Det ville vært ekstremt tungvint hvis man skulle begynne å putte inn nuller og enere helt direkte, på samme måten som vi skriver inn i rom i simuleringen. Hvor du da skriver maskinkoden direkte inn. På de aller første datamaskinene så... Så gjorde man det. Da... På de aller første datamaskinene så var det nettopp det man gjorde. Man skrev inn enere og nuller direkte inn i maskinen. Hadde gjerne hullkort som man da skrev enere og nuller på med hull på kortet. Det var nuller og ener. Og så ble det lagret inn i maskinen som et program. Og da var det maskinkode. Til å begynne med hadde man ikke kopulator. Men så fant man ut at... Dette ble ofte veldig feil. Fordi med de gamle maskinene", "source": "lecture"}
{"lecture_id": "os4del13", "chunk_id": "os4del13_0001", "start": 88.16, "end": 163.2, "token_count": 284, "text": "Det var nuller og ener. Og så ble det lagret inn i maskinen som et program. Og da var det maskinkode. Til å begynne med hadde man ikke kopulator. Men så fant man ut at... Dette ble ofte veldig feil. Fordi med de gamle maskinene så puttet man inn en bunke med hullkort med maskinkode. Og så gikk det en time, så fikk man resultatet, og så så man... Oi, her hadde man gjort én bit feil. Og denne operasjonen med å skrive maskinkode gir opplagt ekstremt mange feil. Så for å ordne på det så fant man opp høynivåspråk og kompulator. Og det som er ganske fantastisk, er at en kompulator kan oversette til maskinkode absolutt alle mulige former for høynivåkode. Så lenge syntaksen er riktig. Det er noen restriksjoner. Syntaksen var riktig. Men hvis du da skriver inn for-løkker og if-tester og wil-løkker osv., så vil kompilatoren lage maskinkode som gjør nøyaktig det du ber om.", "source": "lecture"}
{"lecture_id": "os4del13", "chunk_id": "os4del13_0002", "start": 140.08, "end": 250.68, "token_count": 292, "text": "til maskinkode absolutt alle mulige former for høynivåkode. Så lenge syntaksen er riktig. Det er noen restriksjoner. Syntaksen var riktig. Men hvis du da skriver inn for-løkker og if-tester og wil-løkker osv., så vil kompilatoren lage maskinkode som gjør nøyaktig det du ber om. Ja, det er en kommentar om at man klarte å lande på månen med hullkort og maskinkode, og det er riktig. Eller ikke helt riktig. Når man landet på månen i 69, så hadde man Men hullkort var det mange som brukte fortsatt. Ok. Så... Det vi skal se på nå, er hvordan... Det er hvordan... Hva skjer når vi prøver å kompilere en sånn løkke? Den løkken vi hadde med et C-program, som regner ut en sum. Så skal jeg først finne frem de riktige programmene som gjør det. Ja, eller kanskje før vi går videre, så skal vi prøve å se litt på Denne Adotops eller Helloed. Hello... Og da er det et... Det fins mange programmer som kan dumpe sånn bitekode.", "source": "lecture"}
{"lecture_id": "os4del13", "chunk_id": "os4del13_0003", "start": 221.44, "end": 326.4, "token_count": 296, "text": "Så skal jeg først finne frem de riktige programmene som gjør det. Ja, eller kanskje før vi går videre, så skal vi prøve å se litt på Denne Adotops eller Helloed. Hello... Og da er det et... Det fins mange programmer som kan dumpe sånn bitekode. Eller ikke bitekode, men binær kode. For dette er en binær... Dette er nå en binær fil. Så XX3, den dumper ut innholdet av den binære filen. Og da ser vi... Kommer det en masse tegn. Vi kan pipe den til More, sånn at vi ser hva den inneholder. Og da ser vi... Ja, dette er da... Dette er da Heks. Så ser vi det står 7F. Og det betyr at... Det første er vanlige tallet, 7, men hva er F? Jo, F er... Dette er Heks, og det går opp til 16. Altså 10 er A. B, B, 12 C, 13 D, 14 E... Altså F er 15. Så F betyr da... F betyr da fire enere. Så... Så dette er da to bite. Så dette er på en måte en kortform og binært.", "source": "lecture"}
{"lecture_id": "os4del13", "chunk_id": "os4del13_0004", "start": 294.28, "end": 393.96, "token_count": 298, "text": "Jo, F er... Dette er Heks, og det går opp til 16. Altså 10 er A. B, B, 12 C, 13 D, 14 E... Altså F er 15. Så F betyr da... F betyr da fire enere. Så... Så dette er da to bite. Så dette er på en måte en kortform og binært. Hvis vi skrev med nuller og enere, vil det bli mye lengre. Er en vanlig måte å skrive ut binær kode. Men ELF er hva slags type binær kode dette er. Men vi kan se... Her nede så ser vi... Her kommer det... Hvis jeg tar... Sorry, en gang til... Her nede så kan man se at det står LIB64 Linux X86. Og det er en av de situasjonene hvor... Vi ser at i denne maskinkoden så snakker man med operativsystemet. Det er ikke bare institusjoner som adder og mover osv. Det er også kode her som snakker med operativsystemet, for man må be operativsystemet om å skrive ut resultatet. Og dette kommer vi masse tilbake til, hvordan operativsystemet og programmer snakker sammen. Og så ser vi også at det er LIBC...", "source": "lecture"}
{"lecture_id": "os4del13", "chunk_id": "os4del13_0005", "start": 365.98, "end": 423.24, "token_count": 198, "text": "Det er ikke bare institusjoner som adder og mover osv. Det er også kode her som snakker med operativsystemet, for man må be operativsystemet om å skrive ut resultatet. Og dette kommer vi masse tilbake til, hvordan operativsystemet og programmer snakker sammen. Og så ser vi også at det er LIBC... Det er et bibliotek som da linkes inn. Og dette er typisk biblioteker som brukes for å kunne skrive ut Printf. Men det vi skal prøve å fokusere på, er den koden som utfører algoritmen. Altså den forløkken som vi har sett på mange ganger. Hvordan utføres egentlig den? Men jeg ser det er masse koder der, og så rett og slett kommer det... En god del som bare er tomt.", "source": "lecture"}
{"lecture_id": "linux10del3", "chunk_id": "linux10del3_0000", "start": 0.0, "end": 104.66, "token_count": 292, "text": "OK. Da skal vi se litt mer på virtualisering og prinsippene for virtualisering. Og aller først litt historie. Virtualisering regnes jo som et moderne begrep ofte. Men faktisk så drev IBM med virtualisering på sine stormaskiner allerede på 60-tallet. Så var det stort sett fysiske maskiner det gikk i, både i desktopper og ikke minst servere. Den første vitaliseringsløsningen for X86 Intella AMD, det var BMW-er i 1999. Så det er ca. 20 år siden. Det var den spede begynnelsen. Og deretter fulgte Send, som... Det er et virtualiseringssystem som dere kjører på deres Linux-VM-er. Virtual Box har dere kanskje vært borti, og KVM som vi skal se på senere i dag. Og mange andre. Microsoft har jo virtualisering, og også... Ja, VM-er er kanskje en av de aller største. Så var det et viktig punkt, og det var i 2005 som kom... Før det så var det... i praksis så var det ikke mulig å lage virkelig virtualisering. Hvor operativsystemet er helt uendret.", "source": "lecture"}
{"lecture_id": "linux10del3", "chunk_id": "linux10del3_0001", "start": 81.44, "end": 195.88, "token_count": 289, "text": "Ja, VM-er er kanskje en av de aller største. Så var det et viktig punkt, og det var i 2005 som kom... Før det så var det... i praksis så var det ikke mulig å lage virkelig virtualisering. Hvor operativsystemet er helt uendret. Før det så måtte man bruke en del adhoc-metoder. For å komme rundt det at X86-hardware ikke støttet virtualisering. Vi skal se på nøyaktig hvordan virtualisering ble støttet for X86 i 2005. Det var et tidlig arbeid av påpeker Goldberg fra 1974, som så litt mer sånn i store trekk på hva som skal til for å kunne virtualisere en maskin. Man skal kunne kjøre et operativsystem på en virtuell maskin. Det de sa da, var at en maskin kan bare virtualiseres hvis alle sensitive institusjoner også er privilegerte institusjoner. Vi skal nå se litt på hva det egentlig betyr.  En sensitiv institusjon er en institusjon som bare kan utføres i cornal mode. Og da tenker vi typisk på sånne... Institusjoners rom som Holt, f.eks.", "source": "lecture"}
{"lecture_id": "linux10del3", "chunk_id": "linux10del3_0002", "start": 164.9, "end": 270.16, "token_count": 289, "text": "hvis alle sensitive institusjoner også er privilegerte institusjoner. Vi skal nå se litt på hva det egentlig betyr.  En sensitiv institusjon er en institusjon som bare kan utføres i cornal mode. Og da tenker vi typisk på sånne... Institusjoners rom som Holt, f.eks. I use mode så kan det ikke være sånn at en hvilken som helst prosess kan skru av maskinen. Det er da en sensitiv institusjon. En privilegert institusjon er en institusjon som forårsaker en trapp til cornal mode, hvis den gjøres i use mode. Det betyr at hvis du i use mode utfører en privilegert institusjon, så vil da systemet trappe til kjernen. Da vil kjernen få et varsel. Så kommer kjernen inn. Så behandler den kallet etter det. Sånn som f.eks. skjer i et systemkall. En institusjon som er et eksempel på dette er POPF, som skrur av og på intervjus. Det er en sensitiv institusjon. Den kan bare utføres i Kölnmoll. Utføres den i husimot, så skjer det ingenting.", "source": "lecture"}
{"lecture_id": "linux10del3", "chunk_id": "linux10del3_0003", "start": 235.68, "end": 334.96, "token_count": 290, "text": "Så behandler den kallet etter det. Sånn som f.eks. skjer i et systemkall. En institusjon som er et eksempel på dette er POPF, som skrur av og på intervjus. Det er en sensitiv institusjon. Den kan bare utføres i Kölnmoll. Utføres den i husimot, så skjer det ingenting. Så da bare ignorerer maskinen det som skjer. Akkurat som med for eksempel NOP. NOP betyr no operation. Ingenting skjer hvis den institusjonen utføres. Og det skal vi se, det er et problem for virtualisering. Og det er det som ikke må skje. Påpeker Goldberg sier her at alle sensitive institusjoner De må også være privilegerte. Mens dette er da en sensitiv institusjon. Når den utføres, så skjer det ingenting. Det Goldberg påpeker, er at en sånn institusjon, når den utføres, den må trappe. Den må være privilegert. Den må trappes sånn at operativsystemet vet hva som Et eksempel på en annen sensitiv instruksjon er CLI, clear interrupt flag. Men den er også privilegert.", "source": "lecture"}
{"lecture_id": "linux10del3", "chunk_id": "linux10del3_0004", "start": 309.34, "end": 415.36, "token_count": 290, "text": "Det Goldberg påpeker, er at en sånn institusjon, når den utføres, den må trappe. Den må være privilegert. Den må trappes sånn at operativsystemet vet hva som Et eksempel på en annen sensitiv instruksjon er CLI, clear interrupt flag. Men den er også privilegert. Hvis den utføres i user mode, så gjøres en trapp til corner mode. Og dette går fint med virtualisering. Vanlige institusjoner som vi stort sett har sett på, som ADAL, CMP og Move osv., De kan kjøres i user mode uten problemer, og man kan få utført akkurat det man vil. Men det som er problemet, er at et virtuelt operativsystem kjører i user mode. Det er et spørsmål om hva X86 er. Ja, det er på en måte Assembly, men... Når jeg sier X86, så snakker jeg da om hele det institusjonssettet. X86 er det institusjonssettet som defineres av AMD og Intel. Så alle de prosessorene som de lager, som er da... De prosessorene som brukes av så å si alle servere og desktopper i verden.", "source": "lecture"}
{"lecture_id": "linux10del3", "chunk_id": "linux10del3_0005", "start": 385.68, "end": 460.66, "token_count": 210, "text": "Når jeg sier X86, så snakker jeg da om hele det institusjonssettet. X86 er det institusjonssettet som defineres av AMD og Intel. Så alle de prosessorene som de lager, som er da... De prosessorene som brukes av så å si alle servere og desktopper i verden. De bruker X86-institusjoner. Popf er en X86-institusjon. Det betyr at det er en institusjon som finnes i alle Intel- og IMDi-CPU-er. Det samme gjør Chalmé, eller Ad, Comp og Move osv. I Assembly bruker vi disse X86-institusjonene helt direkte. Men det fins også Assembly for andre institusjonssett. Arm, som er arkitekturen til mobiler, de bruker Arm Assembly. Der kan man skrive Arm Assembly. De bruker Arm Institution.", "source": "lecture"}
{"lecture_id": "linux3del3", "chunk_id": "linux3del3_0000", "start": 0.0, "end": 89.0, "token_count": 295, "text": "Vi skal nå se på environment-variabelen PATH. Vi så på den tidligere. Den inneholder da alle mappene som det letes i når man utfører en kommando. Generelt så kan man finne alle globale variabler med NV. Og da, hvis man prøver å finne PATH, så kunne man jo tenke seg at man kunne gjøre noe sånt som dette her. Men da ser vi... Da finner man bare noen variabler hvor det står.path her. Og det er fordi grep generelt leter etter nøyaktig det du skriver, altså bare etter små bokstaver. Hvis man ønsker begge, så kan man legge på en opsjon minus i. Da får du både små og store bokstaver. Og da vil du se at du finner en variabel path. En sletter-path. Da starter jeg nytt skjell når jeg tester ut dette her, sånn at jeg slipper å ødelegge det skjellet jeg har. Og så kan jeg sette path til ingenting. Noe sånt. Og hvis jeg nå gjør en kommando som mv, så sier den ... no search file and or directory. Og det er fordi jeg har fjernet path, og da finner den plutselig ikke de...", "source": "lecture"}
{"lecture_id": "linux3del3", "chunk_id": "linux3del3_0001", "start": 65.36, "end": 130.02, "token_count": 220, "text": "sånn at jeg slipper å ødelegge det skjellet jeg har. Og så kan jeg sette path til ingenting. Noe sånt. Og hvis jeg nå gjør en kommando som mv, så sier den ... no search file and or directory. Og det er fordi jeg har fjernet path, og da finner den plutselig ikke de... Kommandoene som MV ligger i bind MV, og da finner den ikke det pga. at Path ikke er definert. Pwd, det finner man fordi Pwd er en skjell-built-in. Siden jeg nå går ut av det skjellet igjen, så kommer jeg tilbake til mitt tidligere skjell, hvor Path er definert. Og da ser vi at MV er bind MV. Så det som skjedde da Path ikke var definert, Skjell hadde ikke noe å lete i, så da kunne han ikke gå inn i slashbind og finne MV.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0000", "start": 0.0, "end": 107.48, "token_count": 278, "text": "Så fra nå blir forlesningen tatt opp. Vi snakket om ram og registre for å lagre adresser før pause. Og det var et godt spørsmål om å presisere disse registrene. Og da tenker jeg vi kan gå tilbake til det bildet... Det er viktig å huske på det bildet vi har av en CPU. Og det bildet her viser her nede hvordan RAM er koblet til CPU-en. Så her er det data out, adresse out. Så dette utgjør totalt sett adressebussen. I vår veldig enkle CPU så hadde vi... Men dette er det samme om du har... La oss si 64-bit. Da vil det være 64-bits-registre med 64 sånne koblinger mellom CPU-en. Datapath er en del av CPU-en, mens RAM er det vi snakker om nå - internmine. Og da ser vi uansett hvordan vi... Når vi skal snakke med RAM, Så må vi spesifisere adressen. Her er det fire bits som spesifiserer adressen. Det typiske man gjør da, er at man kobler et register inn i bussen på adresselinjene.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0001", "start": 83.52, "end": 185.82, "token_count": 296, "text": "Og da ser vi uansett hvordan vi... Når vi skal snakke med RAM, Så må vi spesifisere adressen. Her er det fire bits som spesifiserer adressen. Det typiske man gjør da, er at man kobler et register inn i bussen på adresselinjene. Og hvis man da kobler rn, hvor det står tallet 1, inn i Address Out, så betyr det skriv til byte nummer 1 i ram. Står det 80rn, så skriver man til. Så på den måten så trenger man både et register som kobles til adressen, og et som kobles til dataene. Og de trenger ikke nødvendigvis være like store. 64 bit kan være litt overkill på rammeadresse, fordi ramme ikke er så stort. Så da kan man f.eks. velge å bruke... Et 48-bits-register til akkurat disse adressene. Og så kan man sende 64-bits med data. Altså man kan sende det registeret. Ja, altså... Så hvis man skal... Hvis man f.eks. skal sende tallet 8 til adresse 4... Så på denne CPU-en her så må du da ha ett register med tallet 8.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0002", "start": 162.56, "end": 263.08, "token_count": 274, "text": "Altså man kan sende det registeret. Ja, altså... Så hvis man skal... Hvis man f.eks. skal sende tallet 8 til adresse 4... Så på denne CPU-en her så må du da ha ett register med tallet 8. Og så må det kobles til data out. Og så må du ha et annet register med tallet 4. Og så kobles det til adresse out. Og så trykker du på skriveknappen, og så skrives det til ramm. Så alle tall som kommer fra CPU-en på en eller annen måte, det må lagres i registeret. Og når vi skulle programmere dette her, så måtte vi f.eks. da ta Skrive kode som inneholdt tallet 3, og så la vi det et register. Og så pekte det på en adresse. Sånn fungerte det hele veien. Ok. Vi så til sist før pausen at vi trengte MMU. Vi trengte en veldig hurtig hardware-bit som oversetter virtuelle adresser. Alle programmer bruker virtuelle adresser. De oversettes da til fysiske adresser. Så hvis vi skulle lagd det i...", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0003", "start": 216.16, "end": 321.48, "token_count": 296, "text": "Og så pekte det på en adresse. Sånn fungerte det hele veien. Ok. Vi så til sist før pausen at vi trengte MMU. Vi trengte en veldig hurtig hardware-bit som oversetter virtuelle adresser. Alle programmer bruker virtuelle adresser. De oversettes da til fysiske adresser. Så hvis vi skulle lagd det i... Det kunne vært nyttig å se til også. Hvis vi skulle lagd det her, så betyr det at da... Hvis vi skulle brukt et virtuelt adresserom, så betyr det at de adressene som vi sender ut her på AddressOut, de er da virtuelle. Så da kunne det være sånn at når vi sender ut adresse nr. 8, så har vi et system som sier at OK, egentlig så... Det er det virtuelle adresserommet. Egentlig skal den peke til adresse nummer 108 fysisk ramme. Og her, imellom address out og ram, så måtte man ha en egen enhet. Og det er det som er MMU-en, en egen enhet som da lynraskt oversetter... Akkurat som resten av CPU-en, med tilsvarende logikk, oversetter denne adressen fra 8 til 108.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0004", "start": 300.0, "end": 393.2, "token_count": 288, "text": "Og her, imellom address out og ram, så måtte man ha en egen enhet. Og det er det som er MMU-en, en egen enhet som da lynraskt oversetter... Akkurat som resten av CPU-en, med tilsvarende logikk, oversetter denne adressen fra 8 til 108. Så det vil måtte være en boks inni her. Denne CPU-en har fysisk adressering, så her kan du ikke bruke virtuelt. Men alle moderne CPU-er bruker et virtuelt adresserom. Så da har man en MMU i denne biten av databussen. Så det er det vi kommer til nå. Men først skal vi se på noen andre... Ja, se litt på mer praktisk bruk. Vi skal se på hvordan vi kan kompilere hva som skjer, når vi kompilerer programmer, og lowder dem. For det er jo det som i prinsippet skjer hele tiden. Man har kode som kompileres, og så får vi kjørbar kode. Og så må det legges inn i en termine og kjøres. Og det er det vi ser på denne sliden her. Så vi starter her oppe med... Kildekode. Og så kompilerer vi.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0005", "start": 368.16, "end": 447.16, "token_count": 291, "text": "For det er jo det som i prinsippet skjer hele tiden. Man har kode som kompileres, og så får vi kjørbar kode. Og så må det legges inn i en termine og kjøres. Og det er det vi ser på denne sliden her. Så vi starter her oppe med... Kildekode. Og så kompilerer vi. Og det er da typisk, når vi har gjort det med C-programmet, så har vi skrevet GCC minus C, og så kode.c. Og da har vi ofte lagt på en minus O, og så kalt det noe. Rønn, for eksempel. Og den... Den rønn vil da være maskinkode. Og da har vi... Kompilatoren har oversatt kildekoden til maskinkode. Og her er det da maskinkode med null og enere. Vi har sett at vi kan se på den maskinkoden ved å be om å få assembly-kode. Men det er da en én-til-én mellom assembly-koden og maskinkoden. Dette er maskinkode som sier nøyaktig hvilke instruksjoner som skal utføres. Men det vi ikke har sett på tidligere, er at inni her så er det relative adresse.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0006", "start": 430.12, "end": 508.68, "token_count": 282, "text": "Vi har sett at vi kan se på den maskinkoden ved å be om å få assembly-kode. Men det er da en én-til-én mellom assembly-koden og maskinkoden. Dette er maskinkode som sier nøyaktig hvilke instruksjoner som skal utføres. Men det vi ikke har sett på tidligere, er at inni her så er det relative adresse. Ethvert program som dette her starter med et minnerom fra null til 4G. Fra null til maks. Og de adressene vil da være relative. For de vil ikke være de fysiske adressene som ligger her ute i rom. Men så før vi får ferdig maskinkoden som kan kjøres... Så har vi sett tidligere at vi har lagt til én linje. Med linking. Vi kan gjøre hele dette i en operasjon, men det vi typisk tatt har gjort, er at vi f.eks. har kompilert to biter. Vi har kompilert én main og én... Vi hadde en sånn sum-funksjon. Den kompilerte vi i to forskjellige programmer. Og da er det i linkingen så limes de to programmene til ett virkende system.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0007", "start": 484.68, "end": 565.8, "token_count": 293, "text": "men det vi typisk tatt har gjort, er at vi f.eks. har kompilert to biter. Vi har kompilert én main og én... Vi hadde en sånn sum-funksjon. Den kompilerte vi i to forskjellige programmer. Og da er det i linkingen så limes de to programmene til ett virkende system. Var at her i kildekoden så hadde vi f.eks. sånn Include STDIO... Altså for å kunne skrive print. Og det var da et systembibliotek som da linkes inn... Da er det kode her fra systembiblioteket for å printe ut. Det linkes sammen med maskinkoden som er lagd av kildekoden av programmet. Så alt dette limes sammen til én stor maskinkode. Og så, når programmet... Skal kjøres, så må det lastes inn i ram. Og det ser vi. Her er denne koden tatt og lastet inn i ram. Og det er maskinkode som da kan kjøres. CPU-en setter i gang hjørnes her på adresse 0, og så kjører den nedover. Så ser vi at vi har en sinus og x her. Og det er typisk et sånt systembibliotek.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0008", "start": 549.04, "end": 629.98, "token_count": 298, "text": "Og det er maskinkode som da kan kjøres. CPU-en setter i gang hjørnes her på adresse 0, og så kjører den nedover. Så ser vi at vi har en sinus og x her. Og det er typisk et sånt systembibliotek. Man ønsker i kildekoden å regne ut sinus og x. I stedet for å skrive kode som regner ut det fra scratch, så bruker man et eller annet mattebibliotek som man linker inn herfra. Så kan man kjøre SiensaX. Og det kan man statisk linke inn. Man kan ta den SiensaX-koden og hive rett inn i maskinkoden. Men så kan man også ha såkalt dynamisk bibliotek. Og da vil man ha kode som ikke engang er utgangspunktet. Hvis man begynner å kjøre denne maskinkoden, så kan det være at man akkurat i dette tilfellet ikke regner ut SinusAX. Hvis det viser seg når du kjører dette programmet, så ønsker man å regne ut SinusAX. Da har man en dynamisk link. Og da laster operativsystemet inn dette biblioteket her med maskinkode som regner ut SinusAX og andre funksjoner.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0009", "start": 609.48, "end": 694.26, "token_count": 284, "text": "Hvis det viser seg når du kjører dette programmet, så ønsker man å regne ut SinusAX. Da har man en dynamisk link. Og da laster operativsystemet inn dette biblioteket her med maskinkode som regner ut SinusAX og andre funksjoner. Laster inn den, og så hopper koden til riktig sted her. Regner ut SinusX og returnerer. Og fordelen med dette med å ha et sånt dynamisk bibliotek, er at da kan jo flere programmer bruke den samme dynamiske koden. Dette er der shared memory. Vi ser her program 2. Det ønsker også å regne ut SinusX. Og da i stedet for at Koden er kopiert, Både i maskinkoden her oppe og i program 2 så peker begge til denne delen, til dette dynamiske biblioteket. Og på den måten så kan det da regne ut sinus 6. Men vi ser med en gang... Vi begynner å se på dette her. Jo, vi skal løfte inn maskinkode inn i ramm. Så begynner vi å tenke sånn... Hvordan disse adressene her... De begynner på null.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0010", "start": 671.12, "end": 752.28, "token_count": 286, "text": "Og på den måten så kan det da regne ut sinus 6. Men vi ser med en gang... Vi begynner å se på dette her. Jo, vi skal løfte inn maskinkode inn i ramm. Så begynner vi å tenke sånn... Hvordan disse adressene her... De begynner på null. Jo, vi kunne hatt sånn at... La oss si at dette er adresse 1000. Så kunne vi hatt sånn at da legger vi til 1000 på alle disse her. Da må alle adressene som er her inne, oversettes. Da må man legge til 1000, og så limer de fast her. Men problemet med det er at da må denne maskinkoden her forever ligge akkurat der. Og den dynamiske her må forever ligge akkurat der. Men hva om vi ønsker å legge inn nye programmer? Jo, da må de legges ut i resten av ramm. Men til slutt går ramm full, og man har ikke plass til flere. Og da må man begynne å ta programmer ut. Og da ville det vært veldig tungvint hvis alle programmer til enhver tid skulle vite hvor de lå, og alle måtte vite de... De fysiske adressene.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0011", "start": 731.48, "end": 830.4, "token_count": 299, "text": "Men til slutt går ramm full, og man har ikke plass til flere. Og da må man begynne å ta programmer ut. Og da ville det vært veldig tungvint hvis alle programmer til enhver tid skulle vite hvor de lå, og alle måtte vite de... De fysiske adressene. Og denne oversettelsen her er veldig tungvint og veldig lite dynamisk. Så det man har kommet opp med da, er en metode med virtuelt minne. Hvor alle adressene her, null til maks, de... Etter at det er lagt inn, så har man en tabell som viser hvor alle de forskjellige programmene. Sånn at når det er kode her som spør om rammeadresse 48, så vet det systemet, MMM-en, hvor rammeadresse 48 for akkurat denne kodebiten her ligger. Hvilken fysisk adresse det er. På denne måten så er det veldig enkelt å flytte programmer inn og ut. MMU, pagetabellene, de blir oppdatert når man flytter programmer inn og ut, og det muliggjør å ha en veldig dynamisk organisering av prosessene som ligger i rammen. Men før vi ser på det MMU i detalj, så skal vi se på", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0012", "start": 804.3, "end": 906.4, "token_count": 285, "text": "På denne måten så er det veldig enkelt å flytte programmer inn og ut. MMU, pagetabellene, de blir oppdatert når man flytter programmer inn og ut, og det muliggjør å ha en veldig dynamisk organisering av prosessene som ligger i rammen. Men før vi ser på det MMU i detalj, så skal vi se på et eksempel på hvordan man kan gjøre dette her i praksis. Jeg skal ikke vise det i praksis, men bare først skissere... Hva som skjer her. Dette er en simulering jeg lagde en gang. Så det er et C++-prosjekt. Og da lagde jeg et bibliotek som gjorde noen beregninger. Og regnet ut standard og vik osv. Det jeg gjorde da, var at jeg lagde et C++-library. Altså mitt eget bibliotek. Og det G++ er en C++-kompilator. Så det jeg gjorde da først, var å kompilere kildekoden til biblioteket. Og da lages det kalktools.o og roundtools.o. Og så er ar en kommando for å lage et bibliotek.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0013", "start": 881.5, "end": 980.16, "token_count": 292, "text": "Og det G++ er en C++-kompilator. Så det jeg gjorde da først, var å kompilere kildekoden til biblioteket. Og da lages det kalktools.o og roundtools.o. Og så er ar en kommando for å lage et bibliotek. Og det biblioteket jeg lagde, er livtools.a. Og så hadde jeg en simulering som jeg kompilerte. Akkurat tilsvarende som vi gjorde tidligere. Lage maskinkode. Og så til slutt... Så denne operasjonen her nede... Den lager en eksekverbar fil-sim ved å lime sammen alle programmene. Og her er det også noen kommandoer som gjør at man limer inn det biblioteket her oppe. Så i praksis det jeg gjorde, var at jeg laget mitt eget lille bibliotek her. Og så, den siste operasjonen, linket det sammen. Og all koden var det her inne. Og så kan den lastes inn og kjøres. Så vi kan... Vi kan se på hvordan det ser ut i praksis. Så her under 'Tools' så har jeg da de verktøyene. For eksempel 'Calc Tools'.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0014", "start": 946.72, "end": 1082.0, "token_count": 283, "text": "Og så, den siste operasjonen, linket det sammen. Og all koden var det her inne. Og så kan den lastes inn og kjøres. Så vi kan... Vi kan se på hvordan det ser ut i praksis. Så her under 'Tools' så har jeg da de verktøyene. For eksempel 'Calc Tools'. Det er da en metode som regner ut varianse. Og så har jeg en... Bare et lite program som... Skal vi se... Sånn, kanskje. Dette er et lite skript som kompilerer. Så først kompileres de to programmene, og så lager jeg et bibliotek. Ved å eksplisitt kjøre det. Sånn. Nå har jeg lagd en bibliotekfil. Og den... Ta den her. Libtools.a. Det er selve bibliotekfilen som jeg nå skal bruke når jeg skal kjøre. Så... da kan jeg gå til selve simuleringen. Her har jeg også et lite program som kompilerer. Den komplerer selve simuleringen og noen andre hjelpeprogram. Og så her linkes det sammen til en simulering. Så jeg skal gjøre det her.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0015", "start": 1047.0, "end": 1194.86, "token_count": 298, "text": "Så... da kan jeg gå til selve simuleringen. Her har jeg også et lite program som kompilerer. Den komplerer selve simuleringen og noen andre hjelpeprogram. Og så her linkes det sammen til en simulering. Så jeg skal gjøre det her. Jeg skriver bæsj minus x, for da får jeg se eksplisitt hva som skjer. Nå er jeg lagd av en simulering. 27 000 bites. Og så kan den simuleringen kjøre. Så det som skjer når jeg kjører, Lastes den inn i minnet, inkludert biblioteksfilene? Så skal jeg prøve å gjøre det samme på en litt annen måte. Det jeg skal gjøre da, er... Nå har jeg en S-Tools. Men her skal jeg vise hvordan man lager et dynamisk bibliotek. Det er veldig mye av det samme. Det ligner veldig. Men du ser dynamiske bibliotek. Under Linux heter de.so. I Windows heter det DLL. Dynamical Linkable... DLL... Dynamical Linked Library heter det. Så hvis jeg kjører dette, så lager jeg da et dynamisk bibliotek. libstools.so. Så... da kan jeg... gå hit, hvor jeg bruker det dynamiske.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0016", "start": 1153.76, "end": 1270.88, "token_count": 293, "text": "I Windows heter det DLL. Dynamical Linkable... DLL... Dynamical Linked Library heter det. Så hvis jeg kjører dette, så lager jeg da et dynamisk bibliotek. libstools.so. Så... da kan jeg... gå hit, hvor jeg bruker det dynamiske. Så kan jeg compilere med det dynamiske biblioteket. Og da ser det veldig likt ut. Jeg legger på en minus-L-tools der. Og så er det nå klart til at jeg kan kjøre den simuleringen i stedet. Det er akkurat den som går litt fortere. Det er ikke noen forskjell i koden egentlig. Det er bare en løkke som er mindre her. Så... Det ser jo veldig likt ut når jeg kjører, men det som er en viktig forskjell her, er at når... I det andre tilfellet her, når jeg starter denne her, som bruker et dynamisk bibliotek, så lastes det biblioteket inn når jeg kjører det. Og da kunne jeg også lage andre programmer som bruker det samme biblioteket. Vi kan se at det er en liten forskjell. Hvis jeg nå tar LS minus L på SIM, så ser vi at den er på 26,68.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0017", "start": 1242.8, "end": 1344.96, "token_count": 296, "text": "så lastes det biblioteket inn når jeg kjører det. Og da kunne jeg også lage andre programmer som bruker det samme biblioteket. Vi kan se at det er en liten forskjell. Hvis jeg nå tar LS minus L på SIM, så ser vi at den er på 26,68. Mens den første simuleringen, den er på 27,880. Så du ser her, det er en forskjell på én kilobite. Og den kilobiten er rett og slett at i dette tilfellet, Så da er all koden fra biblioteket ligger fysisk inne i den kjørbare filen. Mens her så lastes den kjørbare... Det dynamiske biblioteket lastes dynamisk, og dermed ser vi at koden er litt mindre. Så hvis vi går tilbake til slidene, så... I det andre tilfellet så hadde jeg da et dynamisk bibliotek, Som ble lastet inn når jeg kjørte koden. I det første tilfellet så lå alt inni her. Og dermed så var den 1K større enn den koden jeg brukte. Ja. Da skal vi se veldig kort på Linux prosess segmentation. Dette er da... Dette er da slik Linux...", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0018", "start": 1317.0, "end": 1430.94, "token_count": 289, "text": "Som ble lastet inn når jeg kjørte koden. I det første tilfellet så lå alt inni her. Og dermed så var den 1K større enn den koden jeg brukte. Ja. Da skal vi se veldig kort på Linux prosess segmentation. Dette er da... Dette er da slik Linux... Det er bare noen begreper her som er nyttige å ha med seg. Vi ser... Stack har vi sett på tidligere. Det brukes til lokale variabler. Og så har vi her nede tekst, eller koden. Og det er da typen... Den maskinkoden som programmet bruker når det kjører. Og så har vi også noe som kalles HEAP. Og her lagres det globale variabler og data som... Som genereres dynamisk mens programmet kjører. Det ligger på heapen. Vi ser at den kan vokse oppover, sånn at vi kan... Og legge til dynamisk mer og mer variabler, f.eks., eller RA, som vi skal se på senere. Også MMApp. Det er en sånn minneavbilding av filer rett inn på ram, igjen sånn at ting skal gå raskere. Men nå skal vi se på minneadressering og MMU.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0019", "start": 1412.62, "end": 1496.0, "token_count": 288, "text": "som vi skal se på senere. Også MMApp. Det er en sånn minneavbilding av filer rett inn på ram, igjen sånn at ting skal gå raskere. Men nå skal vi se på minneadressering og MMU. Ja, som jeg har argumentert for tidligere, så må alle de... Virtuelle adressene må kunne knyttes til fysiske adresser. Som jeg nevnte, så kunne det skjedd ved loading, men det er både tidkrevende og tungvint, og lite dynamisk. Så i alle moderne OS så gjøres dette dynamisk mens programmet kjører. Og det gjør at man kan flytte inn og ut programmer og biblioteker og alt som operativstemme ønsker, når det vil. For å kunne kjøre alle programmer mest. Vi kunne hatt sånn at operativsystemet oversatte mellom fysiske adresser og de logiske eller virtuelle. Men det ville gått altfor sakte. Man kan ikke ha kode som gjør det. Fordi disse operasjonene foregår hele tiden. Så dette må skje i brøkdelen av et sekund. Og da trenger vi hjelp fra hardware. Vi trenger en egen enhet, MMU.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0020", "start": 1479.04, "end": 1572.2, "token_count": 298, "text": "Men det ville gått altfor sakte. Man kan ikke ha kode som gjør det. Fordi disse operasjonene foregår hele tiden. Så dette må skje i brøkdelen av et sekund. Og da trenger vi hjelp fra hardware. Vi trenger en egen enhet, MMU. Og dette er skissert et bilde av MMU-en. Vi så på den simulerte CPU-en at vi har en databuss. Og det er da linjer med bits som går fra CPU-en og ut i RAM. Og den adressebiten, den oversettes av MMU. CPU-en sender ut en logisk adresse. Så oversettes MMU-en til fysisk adresse. Så kobles den på databussen. Det er da linjer som går herfra og inn hit. Så trykker de linjene på... La oss si jeg har sendt med adresse... MMU har oversett... La oss si logisk adresse 8 til fysisk adresse 1008. Så går 1008 ut hit. Så kobler man på RAM. 1008 med bits. Bang, bang, bang inn her. Så leses det som ligger i Byte nr. 1008, og så sendes det tilbake til CPUN. Og det skjer hver eneste gang man henter noe i RAN.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0021", "start": 1544.8, "end": 1626.42, "token_count": 288, "text": "La oss si logisk adresse 8 til fysisk adresse 1008. Så går 1008 ut hit. Så kobler man på RAM. 1008 med bits. Bang, bang, bang inn her. Så leses det som ligger i Byte nr. 1008, og så sendes det tilbake til CPUN. Og det skjer hver eneste gang man henter noe i RAN. Ja... Vi skal se på et lite eksempel, litt sånn fiktivt eksempel, med program 1 og program 2 som skal kjøres. Bare for å se hvordan det kan se ut i praksis. Etter at man har kompilert programmene, så er adressene logiske. Og da må man ha en MMU, eller en eller annen slags MMU-tabell, som oversetter de logiske eller virtuelle adressene til det fysiske. Da kan det f.eks. se sånn ut. Program 1, vi har kompilert det, og da står det i program 1... F.eks. på linje 24 står det LOW32. Det betyr da... Last inn i CPU-en det som ligger på linje 32 i ram. Som i dette tilfellet er tallet 671.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0022", "start": 1602.56, "end": 1686.0, "token_count": 286, "text": "Da kan det f.eks. se sånn ut. Program 1, vi har kompilert det, og da står det i program 1... F.eks. på linje 24 står det LOW32. Det betyr da... Last inn i CPU-en det som ligger på linje 32 i ram. Som i dette tilfellet er tallet 671. Så har vi noe tilsvarende i program 2. På linje 28 i program 2 så står det kanskje LOW 36. Og det betyr last inn denne 712, som ligger på linje 36 i ram. Når disse skal kjøres, så... Legges program 1 og program 2, de loads inn i ramm. Her har de fått en plassering. Men da ser vi at ingen av disse virtuelle adressene vil være de riktig fysiske. F.eks. program 1 har tilfeldigvis havnet der på 100. Program 2 har havnet på 150. Og da er det klart... Når program 1 sier \".load 32\", så mener det egentlig load 132. Og der da 132 må sendes ut på minnebussen... Sånn at programmet får denne verdien.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0023", "start": 1665.92, "end": 1746.4, "token_count": 288, "text": "Program 2 har havnet på 150. Og da er det klart... Når program 1 sier \".load 32\", så mener det egentlig load 132. Og der da 132 må sendes ut på minnebussen... Sånn at programmet får denne verdien. Men husk at load 32, når den skal kjøres... Først må det lasses inn i CPU-en. Så utføres load 32. Og da vil CPU-en ved hjelp av MMU-en oversette 32 til 132, og så sendes tilbake hit. Så da kunne man jo tenke seg at man hadde en tabell... Som ordner dette her. Spørsmål i chatten... Logiske adresser, og er de samme som virtuelle? Ja, jeg bruker det litt om hverandre. Logiske eller virtuelle adresser. Hovedpoenget er at de må oversettes til fysiske adresser. Vi kunne hatt den tabellen som så ut som på dette. For program 1 så kunne vi si... OK, adresse 24, den mappes over til 100. Program 2, adresse 28, mappes av til 178. Men da hadde vi plutselig en tabell som var like stor som hele Ram.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0024", "start": 1728.2, "end": 1815.4, "token_count": 281, "text": "Vi kunne hatt den tabellen som så ut som på dette. For program 1 så kunne vi si... OK, adresse 24, den mappes over til 100. Program 2, adresse 28, mappes av til 178. Men da hadde vi plutselig en tabell som var like stor som hele Ram. Så dette er helt umulig og altfor minnekrevende. Men vi kunne i stedet dele opp det logiske minnet i pages. Sånn som dette eksempelet her, så kunne vi ha en side med 50 adresser. Og dermed har vi bare én faktor som må legges til. For da sier vi at program 1 ligger på denne siden, og alle adresser må da bare legge på 100. Og det er i praksis omtrent sånn MMU virker. Og dette med å bruke et virtuelt minnerom, det kalles generelt paging. Det er fordi man deler inn hver sin prosess, sitt virtuelle minnerom, i et antall sider. Så la oss si den forrige prosessen, da. De hadde 50 bite per side. Så hvis den besto av 500 bites, så ville de fått ti sider.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0025", "start": 1790.28, "end": 1880.92, "token_count": 279, "text": "Og dette med å bruke et virtuelt minnerom, det kalles generelt paging. Det er fordi man deler inn hver sin prosess, sitt virtuelle minnerom, i et antall sider. Så la oss si den forrige prosessen, da. De hadde 50 bite per side. Så hvis den besto av 500 bites, så ville de fått ti sider. Og så ville... I MMU så ville det bare stå hvor disse ti sidene ligger.  Og da... Når vi organiserer Ramm, det virtuelle Ramm, i sider, eller pages på denne måten, så kan operativsystemet da dynamisk laste inn og ut disse sidene fra Ramm. Og det kan da types å være sånne enheter på 4K, f.eks. En vanlig sidestørrelse er 4K, og da deles alle programmer inn. Og så laster operativstemme inn og ut disse bitene. På den måten har jeg operativstemme full kontroll over minibruken og kan dynamisk endre tildelingen av ramm til alle prosesser. Ja... Her er det et lite fiktivt eksempel på hvordan dette kan se ut.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0026", "start": 1852.06, "end": 1940.64, "token_count": 293, "text": "En vanlig sidestørrelse er 4K, og da deles alle programmer inn. Og så laster operativstemme inn og ut disse bitene. På den måten har jeg operativstemme full kontroll over minibruken og kan dynamisk endre tildelingen av ramm til alle prosesser. Ja... Her er det et lite fiktivt eksempel på hvordan dette kan se ut. Har størrelse 2 jentebites. Skal se senere hvorfor det må være akkurat 2 i jente. Typiske verdier er 1 lik 12 eller 13, sånn at du får en sidestørrelse på 4 eller 8 kBite. 4 kBite er vanlig for X86-prosessorer. Det er ganske standard. Så dette gjelder per prosess. Så vi har da en tabell... Hver prosess har en egen tabell. Hvis du har én CPU, så er det bare én prosess som kjører av gangen. Så i MMU trenger vi bare å ha den ene tabellen for prosessen som kjøres. Når en prosess switches ut, så lagres da MMU-tabellen i PCB. Men vi kan tenke oss... Her har vi en prosess med logisk minne.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0027", "start": 1915.94, "end": 2008.48, "token_count": 296, "text": "Hvis du har én CPU, så er det bare én prosess som kjører av gangen. Så i MMU trenger vi bare å ha den ene tabellen for prosessen som kjøres. Når en prosess switches ut, så lagres da MMU-tabellen i PCB. Men vi kan tenke oss... Her har vi en prosess med logisk minne. Og MMU vil da være en tabell som sier hvor i det fysiske minnet disse sidene ligger. Så f.eks. her står det frame nummer... Eller virtuell side nummer 0 ligger i page nummer 1. Eller ligger i frame nummer 1. Det logiske minnet kaller pages. Og så er dette i fysisk minne, det er frames. Og i MMU så står det her... Page nr. 0 ligger i frame 1. Og page nr. 1 ligger i frame 4 osv. Enkelt og greit. Bare en tabell som viser denne oversettelsen. Men det er veldig viktig at denne oversettelsen må være veldig hurtig. Så vi skal se litt i detalj på etter hvert hvordan oversettelsen foregår. I en sånn pagetabell så har vi da en pagetable-entry", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0028", "start": 1981.76, "end": 2086.1, "token_count": 298, "text": "Bare en tabell som viser denne oversettelsen. Men det er veldig viktig at denne oversettelsen må være veldig hurtig. Så vi skal se litt i detalj på etter hvert hvordan oversettelsen foregår. I en sånn pagetabell så har vi da en pagetable-entry for hver eneste side. Og det viktigste da er sidenummeret. Det er altså... Det er det nummeret her. Hvilken frame er det som denne siden... Denne virtuelle siden, i hvilken fysisk frame ligger den? Noen andre bits. F.eks. sånn at man kan sette skrive- og leserettigheter på minnet også, per prosess og per page. Og så har man present-absent-bit. Det sier om... Det sier om denne siden faktisk ligger i det fysiske minnet. Hvis du ser null her, så betyr det at den ligger bare på disken. Og da... Hvis programmet ønsker å hente noe fra denne siden, så må den ut på disken og hente den. Og det er en såkalt page fault. Siden mangler, og må ut på disken og hente. Og det tar veldig lang tid. Endret bytte, det er også null eller én.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0029", "start": 2066.36, "end": 2162.88, "token_count": 298, "text": "Og da... Hvis programmet ønsker å hente noe fra denne siden, så må den ut på disken og hente den. Og det er en såkalt page fault. Siden mangler, og må ut på disken og hente. Og det tar veldig lang tid. Endret bytte, det er også null eller én. Hvis den er én, så betyr det at siden er dirty, eller har blitt endret. At hvis... Hvis den siden skal ut av ramm, så må verdien skrives til disk. Hvis den ikke har blitt endret og den skal ut av ramm, så kan du bare droppe den. Men hvis endret-bittet er én, så er siden dirty, og den må skrives til disk før den kan fjernes fra ramm. Så er det reference. Det brukes av... Pagingaloritmer som velger hvilke sider som til enhver tid skal ha plass i rammen. TelB, Translation Look-Aside Buffer, det er en viktig bit. Og det vi har sett på i CPU-en, så har vi L1 og L2 Cash for ramm. Men da snakker vi hele tiden om... Om kode og variabler. Men vi har det samme for MMU, fordi MMU må gå så raskt.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0030", "start": 2134.48, "end": 2224.28, "token_count": 291, "text": "TelB, Translation Look-Aside Buffer, det er en viktig bit. Og det vi har sett på i CPU-en, så har vi L1 og L2 Cash for ramm. Men da snakker vi hele tiden om... Om kode og variabler. Men vi har det samme for MMU, fordi MMU må gå så raskt. Så har man TLB, som er en cashbit spesielt for MMU-adressene. Og som et eksempel, da... Hvis man har en prosess som bruker 100 MB, så vil de gi 4 KB... Med sider... Nei, så vil det med 4 kB sider... Altså med 1 lik 12, så har vi 4 kB størrelse på sidene... Så vil det bety omtrent 25 000 sider. Så vi ser det blir fort veldig mange. En sånn topp-L blir fort veldig stor. En 4 GB prosess har 1 million sider i MMW. Og da får man ikke plass til å lagre dette inne i CPU-en. Der er det bare et begrenset antall registre. Så dermed så vil MMU være med også da... Den vil i utgangspunktet ligge i ramm, men så vil du ha noe i cash.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0031", "start": 2202.98, "end": 2291.64, "token_count": 293, "text": "En 4 GB prosess har 1 million sider i MMW. Og da får man ikke plass til å lagre dette inne i CPU-en. Der er det bare et begrenset antall registre. Så dermed så vil MMU være med også da... Den vil i utgangspunktet ligge i ramm, men så vil du ha noe i cash. Og TLB-en er da den innerste delen av cashen som de... som er raskest å treffe. Så TLB er... er da hurtigcash for... Og den vil da bare inneholde en bitte liten del av pagetabellen, men heldigvis er det ofte den som treffes på. Akkurat som med annen type cash, så bruker man ofte de samme sidene om og om igjen, sånn at da treffer man ofte på den oversettelsen. Hvis man ber om en adresse som ikke ligger i TLB, så får man en såkalt TLB-miss, eller en soft-miss. Og det tar vesentlig lengre tid enn om den ligger i TLB, for da må man lenger ut i cash, eventuelt helt ut i ram for å hente denne siden. Dette er bare noen eksempler på sånn typisk TLB-ytelse.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0032", "start": 2267.76, "end": 2349.3, "token_count": 298, "text": "så får man en såkalt TLB-miss, eller en soft-miss. Og det tar vesentlig lengre tid enn om den ligger i TLB, for da må man lenger ut i cash, eventuelt helt ut i ram for å hente denne siden. Dette er bare noen eksempler på sånn typisk TLB-ytelse. Størrelse... En cash-linje, det er da en bit av cash... Altså den minste biten av cash er typisk på 64 bytes. Og til B-er kan være sånn mellom 16 000 og 4000 linjer. Eller mellom 1 og 256 kB. Så det er relativt... Det er en relativt liten tabell. Men det som er viktig, oppslagstiden er ekstremt hurtig. Dere kan gå i underkant av en klokkesykkel og slå opp. Det er hardware-kablet. Så man gjør ikke noen instruksjoner og regner noe. Adressene direkte. Hvis det er en TLB miss, så kan det forgå mange klokkesykler for å hente den, avhengig av om den er i cash eller i ram. Men det som er veldig fint med dette, er at TLB miss-frekvensen", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0033", "start": 2332.16, "end": 2404.56, "token_count": 298, "text": "Adressene direkte. Hvis det er en TLB miss, så kan det forgå mange klokkesykler for å hente den, avhengig av om den er i cash eller i ram. Men det som er veldig fint med dette, er at TLB miss-frekvensen sånn statistisk så er den veldig liten. Stort sett så bruker man de samme adressene om og om igjen, og de ligger da i TLB. Så noe sånt som dette her kan det se ut. Tidligere at vi har level 2-cash, også level 3-cash, inne på prosessoren. Og så har vi RAM her ute. Så tidligere har vi sett at vi har LN-cash for data og for instruksjoner. Sånn at når... Ofte så henter man de samme instruksjonene, de samme dataene, om og om igjen. Og det ligger veldig nære CPU-en. Og dermed går det ti ganger så raskt som om man skulle hente det ut til RAM. Det samme er det for MMU, og da har vi en TLB-L1-cash her inne. Og dette er TLB-en som vi snakker om. Her ligger hurtigoppslagene for minneadressering.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0034", "start": 2388.12, "end": 2482.08, "token_count": 294, "text": "Og dermed går det ti ganger så raskt som om man skulle hente det ut til RAM. Det samme er det for MMU, og da har vi en TLB-L1-cash her inne. Og dette er TLB-en som vi snakker om. Her ligger hurtigoppslagene for minneadressering. Så 99 % av tilfellene så treffer man på et LB, og da går oversettelsen fra virtuelt minne til fysisk minne veldig raskt. Vi kan... Ja... Vi kommer ikke så veldig lenger i dag, men vi skal i hvert fall ta med akkurat denne oversettelsen her. Det er en figur fra Tallbaum, og det viser en oversettelse fra det virtuelle adresserommet til det fysiske adresserommet. Her er det veldig små størrelser. 64K fysisk minne. 64K virtuelt minne. På moderne maskiner så har man opplevd mye større både fysisk og virtuelt minne, men prinsippene er akkurat det samme. Så her ser vi at... Hvor mange er det? Åtte av disse virtuelle sidene er mappet til fysisk minne. Det er akkurat det samme.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0035", "start": 2456.4, "end": 2552.8, "token_count": 300, "text": "På moderne maskiner så har man opplevd mye større både fysisk og virtuelt minne, men prinsippene er akkurat det samme. Så her ser vi at... Hvor mange er det? Åtte av disse virtuelle sidene er mappet til fysisk minne. Det er akkurat det samme. Her nederst her er page nummer null. Vi ser at den ligger i physical frame nummer to. Så det går en pil herfra og så opp hit. Og da må man, når det kommer en mineadresse herfra, inn til MMU-en, så må MMU-en lynraskt oversette den mineadressen til den riktige i den fysiske. Og det er det neste slide viser hvordan man gjør. Det er på en måte den fysiske kablingen i MMU som gjør at et MMU-oppslag går på faktisk brøkdelen av en klokkesykkel. Fordi det er ikke en... Det regnes ikke ut ved hjelp av CPU-instruksjoner. Det er direkte kabling. Og måten man får det til på, er at man har en innkommende adresse. Vi kan se konkret på dette eksempelet her. Har vi en innkommende adresse 8196...", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0036", "start": 2524.76, "end": 2627.52, "token_count": 295, "text": "Fordi det er ikke en... Det regnes ikke ut ved hjelp av CPU-instruksjoner. Det er direkte kabling. Og måten man får det til på, er at man har en innkommende adresse. Vi kan se konkret på dette eksempelet her. Har vi en innkommende adresse 8196... Og vi ser vi har... Vi har tolv bytt her. Det betyr at vi har en... Hver side har to i tolvte adresser. Og to i tolvte er... To i tiende er 1024, så to i tolvte er 4096. Så disse tolvbitene utgjør 4096 adresser. Og det er liksom... Det er internt på siden hvilken adresse det er. Men så... I det virtuelle adresserommet har vi da i tillegg fire bit. Og de bitene sier hvilken side i det virtuelle adresserommet det er. Og 0100, det er da dette... Det vil da være null, nei, enere. Og dette er Tore, så dette er tallet to. Så vi ser at den peker her. Er det virtuelle side nummer to. Og det betyr at... Ja, dette vil da bli to ganger 4000...", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0037", "start": 2598.4, "end": 2706.2, "token_count": 298, "text": "Og 0100, det er da dette... Det vil da være null, nei, enere. Og dette er Tore, så dette er tallet to. Så vi ser at den peker her. Er det virtuelle side nummer to. Og det betyr at... Ja, dette vil da bli to ganger 4000... Det er da 8192. Dere kan se på de tallene. Jeg har skrevet det i detalj i forelesningsresultatene, hvordan man oversetter det. Så prøv å gå gjennom det. Og forstå nøyaktig hvordan vi kommer fra 8196 til 24580 her oppe. Det er en sånn typisk liten eksamensoppgave. Men dette er for at dere virkelig skal se mekanismen i hvordan dette oversettes. Her har vi side to. De neste tolvbitene er bare hvor i adresserommet det er. Her står det fire. Så dette er internt i adresserommet. Adresse nummer fire. Men så ser vi at her er MMU-tabellen. Den peker til... Nei, 2. Den peker til 110. Her står det 110. Så da tar man de bitene her som er... I page nummer to så står det 110, og det er da...", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0038", "start": 2679.0, "end": 2782.34, "token_count": 287, "text": "Men så ser vi at her er MMU-tabellen. Den peker til... Nei, 2. Den peker til 110. Her står det 110. Så da tar man de bitene her som er... I page nummer to så står det 110, og det er da... Det er da tallet seks. Og så ser vi om man limer da bare det tallet seks som sier hvilken frame det er. Det er akkurat det som vi så her nede. Her er page nummer to. Page nummer 012... Page nummer to peker på fysisk adresse nummer seks. Det gjøres ved at man limer den... Kabler, da. 110. Sånn at den kommer først, og så sendes da bare hele denne her... Sendes videre til databussen. Og det er på magisk vis... Men vi har bare lint på et på en måte seks ganger 4096... Og det ble 24 576. Og så kommer det firetallet i tillegg. Firetallet er bare offset hvor i denne siden som denne adressen vi skal ha tak i, ligger. Så dette viser hvordan man... Ved å bare kable dette helt riktig med... Så får man en hardware-bit, altså MMU,", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0039", "start": 2756.16, "end": 2868.24, "token_count": 292, "text": "Og det ble 24 576. Og så kommer det firetallet i tillegg. Firetallet er bare offset hvor i denne siden som denne adressen vi skal ha tak i, ligger. Så dette viser hvordan man... Ved å bare kable dette helt riktig med... Så får man en hardware-bit, altså MMU, som gjør denne oversettelsen i løpet av brøkdelen av et skudd. Ok... Ja. Så dette er bare å oppsummere hvordan dette her virker. Paging gjør da at man deler inn programmer, prog1 og prog2, i sider på denne måten her. Og så har man... Og så har man fysisk ram som ligger imellom her. Og da kan det være at ikke alle sidene i disse to programmene ligger i ram. Det kan kanskje bare være page 3 fra program 1. Og page 0 fra program 1 og page 4 fra program 2. De andre vil da ligge på disken. Disse sidene ligger da på swap-området på disken. Det er typisk noe tilfelle hvor man får problemer hvor det ikke er plass til alle programmene i RAM samtidig. Da sliter man, hvor da begynner... Da kaller man det...", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0040", "start": 2844.28, "end": 2934.32, "token_count": 294, "text": "De andre vil da ligge på disken. Disse sidene ligger da på swap-området på disken. Det er typisk noe tilfelle hvor man får problemer hvor det ikke er plass til alle programmene i RAM samtidig. Da sliter man, hvor da begynner... Da kaller man det... Swapping... Hvis du har en fysisk disk, vil du kunne høre at den disken driver og kjører og kjører, for hele tiden flyttes ting inn og ut av minnet fra disken. Og det går ekstremt tregt. Og det er da ting virkelig går sakte på en maskin. Ja... Oi, jeg ser mye tid for å avslutte det der. Bare veldig kjapt - persingalrytmer. Det er da algoritmer som bestemmer hvilke sider som skal ligge i ramm, og det er da en del av operativsystemet som gjør paging. Det tippet som skjer at du får en pagefault, det er da man adresserer noe... En adresse som ikke ligger i ramm, men som ligger ute på disk. Og det tar veldig lang tid, for da må man fysisk ut. Hente det inn i RAM, og så varsle alt.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0041", "start": 2910.24, "end": 3022.64, "token_count": 294, "text": "Det tippet som skjer at du får en pagefault, det er da man adresserer noe... En adresse som ikke ligger i ramm, men som ligger ute på disk. Og det tar veldig lang tid, for da må man fysisk ut. Hente det inn i RAM, og så varsle alt. Så typisk vil en prosess scheduleres ut mens man venter på denne siden. Men de algoritmene som bestemmer hvilke sider skal ligge inne, og hvilke skal ligge på disk, det er pitching allerede. Så fortsetter vi der med dynamisk allokering neste gang. Ja... Vi skal se. Det var noen gode spørsmål her i chatten. Først er det spørsmål om R32 fra starten av den designerte startadressen. Ja... Jeg antar du spørsmålet gjelder denne her. Lov 32, det vil være når... Helt konkret når man kompilerer, så vil kompilatoren lage minneadresser. Og den bruker det logiske adresserommet, og det logiske adresserommet starter på null. Altså Love 32, det er en logisk eller virtuell adresse innen det adresserommet som program 1 tror han er ene hersker over.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0042", "start": 3005.24, "end": 3116.62, "token_count": 283, "text": "så vil kompilatoren lage minneadresser. Og den bruker det logiske adresserommet, og det logiske adresserommet starter på null. Altså Love 32, det er en logisk eller virtuell adresse innen det adresserommet som program 1 tror han er ene hersker over. Og programmet vet ikke da om når det blir loved ut, om dette blir da fysiske adresser eller ikke. Men det betyr ikke noe at programmet gjør det, for det er dette sørger MMU for at 32 alltid blir oversatt til i dette tilfellet. Ja... Men hva om prosessen bruker mer enn Pagent sin adresse? Det hender man får segmentation fault, og det er typisk hvis et program her inne snakker om en adresse som ikke er sin. Så hvis den er utenfor sine sider, så vil du typisk få en page fault. Så en av de delene som operativsystemet må gjøre, er å sørge for at ingen programmer kan skrive over i andres minner. Men med paging så kan operativsystemet styre dette totalt, sånn at det sikrer at ingen overskriver for hverandre. Til slutt er det spørsmål om...", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0043", "start": 3090.78, "end": 3184.18, "token_count": 297, "text": "Så en av de delene som operativsystemet må gjøre, er å sørge for at ingen programmer kan skrive over i andres minner. Men med paging så kan operativsystemet styre dette totalt, sånn at det sikrer at ingen overskriver for hverandre. Til slutt er det spørsmål om... Hvorfor legger man ikke mer lagringsplass i LNC1GB? Og det er et godt spørsmål, men... Kunne du ikke bare hatt enormt mye lagringsplass her? Og dette er da et fysisk spørsmål... Man lager dette så effektivt som mulig, men hvis du har én GB her inne, så... Eller la oss si du hadde én GB her og ikke hadde noe L1, så... Da ville du straks hatt det problemet at det tok lengre tid, fordi det er så mange. 1 GB er enormt... Mange transistorer. Og det er jo fysiske systemer, dette her. Det er derfor vi har L1-cash, L2-cash, L3-cash osv. Man skulle jo ønske at så mye som mulig var nær CPU-en, men der er det fysiske begrensninger, så alt kan ikke være nær CPU-en.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0044", "start": 3163.3, "end": 3246.5, "token_count": 297, "text": "Mange transistorer. Og det er jo fysiske systemer, dette her. Det er derfor vi har L1-cash, L2-cash, L3-cash osv. Man skulle jo ønske at så mye som mulig var nær CPU-en, men der er det fysiske begrensninger, så alt kan ikke være nær CPU-en. Og de størrelsene man har på L1, L2 og L3-cash, de har liksom blitt tilpasset og lagd sånn ut fra hardt... Hvordan kan man få det mest mulig effektivt? En grunn til at man da ikke lager LN-cash på én gigabyte, er at... ... er at det... Stort sett så er det ikke én gigabyte med data som brukes hele tiden om og om igjen. Ut fra statistikk av hvordan programmet kjører, har man funnet ut at... Sånn som med TLB, at det er 1 %... 99 % av tilfellene så treffer man med den TLB-en som ligger her, med kanskje bare 500K med data. Helt tett opp. Og da er det bedre å ha disse 500K med data veldig tett i CPU-en, sånn at det går lynraskt når de skal inn til registrene.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0045", "start": 3226.74, "end": 3306.38, "token_count": 293, "text": "99 % av tilfellene så treffer man med den TLB-en som ligger her, med kanskje bare 500K med data. Helt tett opp. Og da er det bedre å ha disse 500K med data veldig tett i CPU-en, sånn at det går lynraskt når de skal inn til registrene. Og så heller å ha én GB her ute med neste ledd. Men kanskje ikke så mye som 1 GB... Men appetitt-megabyte, i hvert fall. Og igjen så er det en sånn avveining. Hvis du skulle hatt 1 GB her, så måtte det være plass til alle, og da ville det tatt lengre tid å få et vilkårlig bite herfra inn til CPU. Så dette med størrelsen på L1, L2, L3 Cash, de er nøye avveiet for å få det til å gå... Man kunne kjøre alt i cash. Ja, man prøver å lage cash større og større, men det er mye dyrere og krever mer strøm. Så det er begrensninger på det òg. Men utviklingen av CPU-er har hele tiden vært sånn at man legger inn mer og mer cash.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0046", "start": 3283.3, "end": 3345.78, "token_count": 171, "text": "Man kunne kjøre alt i cash. Ja, man prøver å lage cash større og større, men det er mye dyrere og krever mer strøm. Så det er begrensninger på det òg. Men utviklingen av CPU-er har hele tiden vært sånn at man legger inn mer og mer cash. Det er sånn Wars Law har funket de siste årene. Enda raskere. OK. Da tenker jeg at dere sikkert også trenger en pause. Det kan jeg holde på i noen timer til. Men vi stopper der. Og så tar vi heller og jobber med oppgaver. Det er oppgaver som går på akkurat dette her i denne uken. I neste uke.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0000", "start": 0.0, "end": 113.08, "token_count": 289, "text": "Og der starter jeg opptak av forelesningen. Det var... Det kom ett godt spørsmål i pausen, så vi kan starte med det. Skal vi se hvis jeg klarer å finne frem her. Sånn. Jo... Det var et spørsmål om forskjellene fra tidligere og til i dag om... Hvordan operativsystemet styrer harddisken. Og det jeg prøvde å poengtere, var at tidligere så detaljstyrte operativsystemet harddisken. På den måten at den ba eksplisitt om leseholde track sektornummer. Over hvor alle sektorene lå. Så operativsystemet styrte da de algoritmene som leser fra disken. Og det fins faktisk mange forskjellige typer algoritmer. En som er heisalgoritmen, og... Og heisalgoritmen, den fungerer sånn at... Typisk så trenger operatørstemaet en liste med sektorer. Som vi skal se, en fil... Selv om man har en hel fil, så kan den ligge i sektorer rundt omkring på disken. Og da vil man trenge en algoritme", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0001", "start": 79.96, "end": 165.08, "token_count": 294, "text": "Og heisalgoritmen, den fungerer sånn at... Typisk så trenger operatørstemaet en liste med sektorer. Som vi skal se, en fil... Selv om man har en hel fil, så kan den ligge i sektorer rundt omkring på disken. Og da vil man trenge en algoritme som på smartest mulig måte henter ut dem. Én teknikk kan da være at man ettersom lesehode... Og det flytter seg innover og utover, så plukker den med seg de sektorene. Og da ikke nødvendigvis i den rekkefølge som operativsystemet sier 'Jeg ønsker sektor 71524'. Da kan det være at den plukkes opp i en annen rekkefølge. Og dermed viser jeg masse sånne algoritmer som må kjøres. Tidligere kjørte operativsystemet og styrte disse algoritmene. Men i dag styres det av... Diskontrolleren her nede. Det er den som styrer algoritmene for å lese av den harddisken. Så det er én forskjell. I tillegg så kommer DMA som en avlastning.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0002", "start": 146.62, "end": 248.6, "token_count": 294, "text": "Men i dag styres det av... Diskontrolleren her nede. Det er den som styrer algoritmene for å lese av den harddisken. Så det er én forskjell. I tillegg så kommer DMA som en avlastning. Slik at CPU-en, eller da operativsystemet gjennom kommando fra CPU-en, den ber om f.eks. at man skal lese fil.taxd. Og i stedet for å be om Sektor for sektor direkte harddisken, så overlater han denne jobben til DMA. Sånn at CPU-en egentlig bare trenger å si til DMA at jeg trenger fil.txd. Så vil DMA på egenhånd snakke med harddisken og sørge for at sektor for sektor så blir fil... som operativstømmen ønsker, lagt inn i RAM. Og når det er ferdig i RAM, så sendes det et interrupt til CPU-en som sier at den IO-jobben, i dette tilfellet disklesing, er fullført. Og så kan da operativstømmen komme inn og fortsette med det den skal etter at den har fått film. Moderne operativsystemer med DMA og diskontroller i forhold til tidligere.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0003", "start": 214.06, "end": 318.04, "token_count": 288, "text": "Og når det er ferdig i RAM, så sendes det et interrupt til CPU-en som sier at den IO-jobben, i dette tilfellet disklesing, er fullført. Og så kan da operativstømmen komme inn og fortsette med det den skal etter at den har fått film. Moderne operativsystemer med DMA og diskontroller i forhold til tidligere. Filsystemer. I utgangspunktet så er... Når en disk kommer fra fabrikken, så er den såkalt lavnivåformatert. Det betyr at da er disken delt inn i 512 bytes. Det kalles en sektor, og det er den minste leseskriveenheten. Så man skal skrive én bite i en disk, som man jo kan. Lage en fil med én bokstav. Så settes det av minst 512 bite til denne filen. Og så skrives det. Ja, så når man har formatert disken fra scratch, så da... Da er diskkontrolleren klar til å kunne lese og skrive sektorer. Man snakker ofte om å formatere disker. Og det er ikke sånn fabrikkformatering med 512 beiter osv.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0004", "start": 293.96, "end": 386.8, "token_count": 298, "text": "Ja, så når man har formatert disken fra scratch, så da... Da er diskkontrolleren klar til å kunne lese og skrive sektorer. Man snakker ofte om å formatere disker. Og det er ikke sånn fabrikkformatering med 512 beiter osv. Den ligger fast. Men når man formaterer en disk, så følger man den tilbake til der hvor den var da den kom fra fabrikken. Ingen av sektorene er da i bruk. Et filsystem er rett og slett et system som holder orden på hvor alle de sektorene ligger på disken. Man kunne lage veldig enkle filsystemer, men det viser seg at det er ganske mange ting man må tenke på. Ikke minst at det kan skje fysiske problemer med disken. Det er magnetisering, så deler av dataene på disken kan bli borte. Så en viktig oppgave for filsystemer er å ha en måte å reagere på feil. Fysiske feil på disken. Det kan også skje på SSD-disker. Men først og fremst ved HDD-disker som snurrer rundt. Så det er lett å tenke seg at hvis man vipper på laptoper,", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0005", "start": 368.72, "end": 460.0, "token_count": 280, "text": "Så en viktig oppgave for filsystemer er å ha en måte å reagere på feil. Fysiske feil på disken. Det kan også skje på SSD-disker. Men først og fremst ved HDD-disker som snurrer rundt. Så det er lett å tenke seg at hvis man vipper på laptoper, så kan det bli diskproblemer. Det finnes en rekke filsystemer. De tre første her er for Windows. FAT er det gamle filsystemet som fortsatt brukes f.eks. på minnepinner. Som dere kan se i oppgaven i dag. NTFS har lenge vært standard på Windows. Men nå er Resilient FS, REFS, den siste versjonen av filsystemer. På Linux bruker man som regel XT. XT3 og... XT4 er da den siste av XT-variantene. Men det finnes også andre filsystemer. Som BTRF. BTRFS... ISO 9660. Det er typisk sånt filsystem som man bruker på CD- og DVD-disker. Så bruker man filsystemer. Og som jeg nevnte, da er det et typisk fett som brukes.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0006", "start": 432.16, "end": 535.64, "token_count": 294, "text": "Men det finnes også andre filsystemer. Som BTRF. BTRFS... ISO 9660. Det er typisk sånt filsystem som man bruker på CD- og DVD-disker. Så bruker man filsystemer. Og som jeg nevnte, da er det et typisk fett som brukes. Så filsystemet, det fordeler da mapper og filer på diskens sektorer. Og holder da orden på hvor alle disse sektorene er. Sånn at man kan si catfill og takestay. Og så kommer, selv om dette er en kjempefill på mange gigabytes, så kommer den pent ut i riktig rekkefølge. Vi skal se at fyllesystemer deles inn i... ... i større blokker enn sektorer. På Linux kalles blocks eller fragments, som brukes i otopser, som vi skal se. På Windows snakka man om clustre. Og da en blokk eller en cluster kan da være et antall sektorer. Unnskyld? Det er et spørsmål i chatten. Ja. Disko1 og... Ja, skal vi se... Det er spørsmål om mintisering... Ja, han leser av alle punktene på sektoren på en gang.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0007", "start": 504.68, "end": 618.68, "token_count": 300, "text": "Og da en blokk eller en cluster kan da være et antall sektorer. Unnskyld? Det er et spørsmål i chatten. Ja. Disko1 og... Ja, skal vi se... Det er spørsmål om mintisering... Ja, han leser av alle punktene på sektoren på en gang. Ja, det er akkurat sånn som på... sånn som med cash. Den tar en stor blokk av gangen. Så den vil lese alle 512 bitene og så sende dem. Det er også litt sånn som med cash at veldig ofte så... Om man ikke trenger de dataene som ligger der, den i noen tilfeller... Så trenger man data som ligger innen den samme sektoren. Så det er på en måte en sånn... På samme måte som man ikke leser én av én bit fra RAM... Man leser alltid minst én bite. Altså minst åtte bit av gangen. Så gjelder det samme på fyllesystemer. Så størrelsen på blokker varierer, og det bestemmes når filsystemet lages. Så da kan man si at man vil ha blokkstørrelse på 4K, f.eks. Åtte sektorer.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0008", "start": 594.68, "end": 686.76, "token_count": 287, "text": "Så gjelder det samme på fyllesystemer. Så størrelsen på blokker varierer, og det bestemmes når filsystemet lages. Så da kan man si at man vil ha blokkstørrelse på 4K, f.eks. Åtte sektorer. Ja, da er det jo noen ulemper og fordeler med blokkstørrelse. Jeg skal ikke si så veldig mye om det. Hovedtanken er da hvis man har store blokker, så da vil jo dataene ligge rett etter hverandre på en harddisk, på en HDD, en skivedisk, mens på SSD-disker så spiller jo ikke det så stor rolle. En ulempe med stor blokkestørrelse, og da en fordel med små, er at små blokker bruker mindre disk. Hvis du har svære blokker, 64K f.eks., og du lagrer bare bokstaven A, så må du sette av 64K på disken til hver eneste fil. Og det er opplagt en ulempe. Men gjerne så finner man en sånn mellomstørrelse, som 4K f.eks., som fungerer OK til det meste.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0009", "start": 660.0, "end": 744.04, "token_count": 291, "text": "Hvis du har svære blokker, 64K f.eks., og du lagrer bare bokstaven A, så må du sette av 64K på disken til hver eneste fil. Og det er opplagt en ulempe. Men gjerne så finner man en sånn mellomstørrelse, som 4K f.eks., som fungerer OK til det meste. Og i tillegg... Når man da bruker RammCash og mellomlagrer i Ramm, så spiller det ikke så veldig stor rolle hvordan det er organisert på filsystemet. Og jeg prøvde å illustrere et filsystem, bare for å vise at det er en tabell over hvor filene ligger på disken. Nå har jeg tegnet opp dette som sektorer. Dette er sektor 1, 2, 3, 4, 5 og 6. På en disk vil det ligge og snurre rundt, mens på en SSD-disk så... Så vil dette bildet være mer naturlig. Men hovedpoenget er at la oss si vi har en fil på 6K her, og så har vi en blokkstørrelse på 2 kB, altså på fire sektorer.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0010", "start": 723.16, "end": 803.96, "token_count": 283, "text": "På en disk vil det ligge og snurre rundt, mens på en SSD-disk så... Så vil dette bildet være mer naturlig. Men hovedpoenget er at la oss si vi har en fil på 6K her, og så har vi en blokkstørrelse på 2 kB, altså på fire sektorer. Da vil man fylle opp de 6 kB her med fil 1. Så ser vi jeg tegnet et litt annet mønster på fil 2. Der er det 4 kB, men likevel så trenger man to helleblokker. For man får ikke plass til... Ja, den fylles jo nesten opp. Men hvis denne var på litt over 2 kB, så ville man likevel trenge to. På den måten fordeler man sånn som fil 4 kommer her. Men så er litt av poenget at hvis man begynner å skrive én fil, så vet man ikke helt hvor den havner. Den legges ut etter et system, men det som kan skje, er at andre filer skrives innimellom. Og så trenger man to nye blokker. Man øker størrelsen på fil 1. Da kan de plutselig ende opp her.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0011", "start": 784.72, "end": 863.72, "token_count": 292, "text": "så vet man ikke helt hvor den havner. Den legges ut etter et system, men det som kan skje, er at andre filer skrives innimellom. Og så trenger man to nye blokker. Man øker størrelsen på fil 1. Da kan de plutselig ende opp her. Lenger ned kommer det enda mer til fil 1, og den havner på 19 og 20. Så dermed vil sektorer som dette... De vil spres utover disken. Så de ligger ikke nødvendigvis rett etter hverandre. Og dermed kan det, spesielt etter lang tid, når man sletter filer og går mye fram og tilbake... Så kan det oppstå hull og fragmentering, sånn som på denne disken. Her har jeg nå slettet fil 1. Og da ser vi at det er tomme områder her som ikke er i bruk. Det vil si, som vi skal se... Ofte så ligger faktisk dataene fortsatt. Men filsystemet har slettet sine pekere til disse dataene. Så det er vanskelig å finne fram. Filsystemet vet ikke hvor de ligger. Og disse blir markert som ledige, sånn at hvis det kommer en ny fil,", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0012", "start": 842.92, "end": 945.12, "token_count": 285, "text": "Det vil si, som vi skal se... Ofte så ligger faktisk dataene fortsatt. Men filsystemet har slettet sine pekere til disse dataene. Så det er vanskelig å finne fram. Filsystemet vet ikke hvor de ligger. Og disse blir markert som ledige, sånn at hvis det kommer en ny fil, Hvis man har mange sånne hull, så kalles det fragmentering. Men Linux og XD bryr seg stort sett ikke om fragmentering. Det fungerer greit hvis man passer på å spre dataene rundt omkring. På Windows har man såkalt defragmentering, som kan hjelpe på diskhastigheten. Man kjører da defragmentering. At systemet vil legge filer etter hverandre på disken. For SSD-disk gir det ikke mening med defragmentering. Men for harddisker som roterer, så kan det være en viktig faktor for hvor rask disken jobber. Ja... Når en fil slettes, så slettes ikke alle dataene, men linkene, eller pekerne i filsystemet, som sier hvilke blokker som ligger hvor. Det er typisk en tabell. FAT, som står for File Allocation Table,", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0013", "start": 911.9, "end": 1007.02, "token_count": 286, "text": "så kan det være en viktig faktor for hvor rask disken jobber. Ja... Når en fil slettes, så slettes ikke alle dataene, men linkene, eller pekerne i filsystemet, som sier hvilke blokker som ligger hvor. Det er typisk en tabell. FAT, som står for File Allocation Table, og det er da bare en tabell over hvilke sektorer som utgjør en fil. Og det er denne, i forhold til... Da slettes all informasjon om hvor de forskjellige blokkene ligger. Da kan det være veldig komplisert å sette sammen en fil igjen hvis man ikke vet hvor innholdet ligger. Ofte så ligger det da etter hverandre, sånn som i denne oppgaven med et bilde som dere skal se på denne uken, så... Hele bildet ligger etter hverandre i sektorer. Det er vanlig hvis du skriver et bilde til en disk, så blir det lagt etter hverandre. Det er ganske vanlig at det ligger sånn, og da kan det være mulig å få ut hele bildet helt. Men hvis det er fragmentert og ligger rundt omkring på mange steder på disken,", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0014", "start": 989.5, "end": 1070.54, "token_count": 285, "text": "Det er vanlig hvis du skriver et bilde til en disk, så blir det lagt etter hverandre. Det er ganske vanlig at det ligger sånn, og da kan det være mulig å få ut hele bildet helt. Men hvis det er fragmentert og ligger rundt omkring på mange steder på disken, så kan det være veldig vanskelig å få ut hele bildet.  Der kan man plukke ut tekstbiter. Da vil det ligge biter av tekst rundt omkring. Men selv om man da eksplisitt sletter filene... Og det man kan gjøre for å slette en fil, er f.eks. å skrive nuller. Eller skrive et gitt tegn over hele filen. Og da vil du jo slette innholdet også. Her ser vi et lite 3D-bilde av magnetisering. Og her kan vi se hvordan lesehodet kan oppfatte nuller og enere ved om det er magnetisert eller ikke. Men hvis man da har verktøy som er enda bedre enn lesehodene, altså det har høyere oppløsning, kan lese av magnetisering... Som i dette tilfellet, så vil man kunne da se...", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0015", "start": 1052.3, "end": 1121.18, "token_count": 300, "text": "ved om det er magnetisert eller ikke. Men hvis man da har verktøy som er enda bedre enn lesehodene, altså det har høyere oppløsning, kan lese av magnetisering... Som i dette tilfellet, så vil man kunne da se... Så kan man se noe av det underliggende, altså hva som faktisk lå bak etter at det har blitt skrevet over av nuller og enere på den måten. Så kan man se antydning til... Oi, her var det kanskje en ener. Her er det en ener, og så nuller. Det er et sånt til pjusk. Avanserte verktøy som politiet og etterretningstjenesten bruker for å kunne lese ut innhold som er slettet på disker. Så ofte sier man at for å slette ordentlig en disk, så må du kanskje... Skrive over med randomt tall seks eller syv ganger for å unngå sånne effekter som dette. Og da begynner det å bli vanskelig. Men for å være helt sikker, så bør man helst løse opp disken i saltsyre så den er skikkelig borte. Første, da kan du si... Da er det helt borte.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0016", "start": 1100.98, "end": 1199.7, "token_count": 295, "text": "Skrive over med randomt tall seks eller syv ganger for å unngå sånne effekter som dette. Og da begynner det å bli vanskelig. Men for å være helt sikker, så bør man helst løse opp disken i saltsyre så den er skikkelig borte. Første, da kan du si... Da er det helt borte. Da tenkte jeg å skulle se på fyllesystemet. Men før vi gjør det, så skal jeg prøve å... Vise hvordan man kan lage et filsystem på en fil, og hvordan man kan slette filer på denne og montere og så videre. Og kanskje skal vi prøve oss å få til å se om jeg kan finne igjen en tekst som er slettet. Så da hopper jeg inn her. Skal vi se... Jo, det jeg vil gjøre først da, er å lage en... Jeg prøver bare å lage en tom fil som inneholder data. Og én måte å gjøre det på er å bruke en kommando som heter DD.  Og det jeg skal prøve å gjøre, er også å ta IF-opsjonen til DV. Den sier hvilke data skal jeg bruke. Og da vil jeg bruke DevZero.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0017", "start": 1171.84, "end": 1276.02, "token_count": 278, "text": "Jeg prøver bare å lage en tom fil som inneholder data. Og én måte å gjøre det på er å bruke en kommando som heter DD.  Og det jeg skal prøve å gjøre, er også å ta IF-opsjonen til DV. Den sier hvilke data skal jeg bruke. Og da vil jeg bruke DevZero. Det er på en måte en device som bare inneholder nuller, altså ASKI-tegn 0. Så den skal da fylle den filen jeg lager, med tegn. Så jeg kaller den bare én. Så må jeg her spesifisere hvor stor fil jeg vil lage. Dette er da opsjoner til DD. Jeg kan si at jeg vil ha 8 mega. Og så blokker vi 11. Biter på 8 mega, og så count 1. Da vil jeg bare ha én sånn bit. Hvis jeg hadde sagt 10 her, så hadde jeg fått 80 mega. Så får jeg da laget en fil som er på 8,0 mega. Så dette er da 8 mega. Hvis vi regner ut eksplisitt, så er mega 1024 ganger 1024.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0018", "start": 1242.82, "end": 1348.22, "token_count": 296, "text": "Hvis jeg hadde sagt 10 her, så hadde jeg fått 80 mega. Så får jeg da laget en fil som er på 8,0 mega. Så dette er da 8 mega. Hvis vi regner ut eksplisitt, så er mega 1024 ganger 1024. Hvis jeg ganger det med 8, så ser jeg at jeg får akkurat det tallet der. Så det er da en fil på 8 MW. OK. Men i utgangspunktet så er dette bare en tom fil med tegn som vi ikke ser engang. Hvis jeg tar HED på én fil, så vil vi se... Ja, jeg ser den er helt tom. Men det er bare fordi den har ASKI-tegn 0. Så den synes ikke. Men jeg kan da gjøre den til et image. Og det kan jeg gjøre med en kommando som heter mkfs. Den kan da lage et filsystem på denne tomme filen. Vanligvis bruker man mkfs direkte på harddisker og lager da filsystemet på en disk som er fysisk montert, f.eks. en minnepinne. Harddisk som er montert på maskinen. Så må man si hva slags filsystem man ønsker. Jeg ønsker da ekstra tre.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0019", "start": 1324.68, "end": 1407.18, "token_count": 277, "text": "Vanligvis bruker man mkfs direkte på harddisker og lager da filsystemet på en disk som er fysisk montert, f.eks. en minnepinne. Harddisk som er montert på maskinen. Så må man si hva slags filsystem man ønsker. Jeg ønsker da ekstra tre. Og så vil jeg lage det filsystemet på én fil. Og da ser vi... Her lager den filsystemet, og den bruker de fått 1K blokker. Og da er det da 8192 blokker. Og det er da... Åtte ganger 1024. Så hvis vi får 8000 sånne blokker med størrelse 1K... Det skal vi se etterpå. Når vi studerer filsystemet, skal vi se at det er 8000 sånne blokker. Og når man da lager en fil på et sånt system, så legges det inne i en blokk. Så kan jeg prøve å montere denne disken, eller dette imaget. Og da må jeg ha sudorettigheter for å få til det. Og måten jeg kan montere det på, er med kommando mount.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0020", "start": 1388.82, "end": 1477.82, "token_count": 287, "text": "så legges det inne i en blokk. Så kan jeg prøve å montere denne disken, eller dette imaget. Og da må jeg ha sudorettigheter for å få til det. Og måten jeg kan montere det på, er med kommando mount. Så mount, jeg kan si... Jeg ønsker å montere én fil, altså imaget, på filsystemet under slash mnt. Men det kan være en hvilken som helst mappe i filsystemet. Men det finnes en standardlappe som heter slash mnt, som det er vanlig å montere. Filer og disker på. Så dette kunne vært noe... F.eks. en minnepinne som er plugget inn i laptopen. DF viser hva som er montert. Og ja... Dette er Snap som monterer en masse. Det er et sånt installasjonsprogram. Men kjelt nederst her så ser vi at den... Nå har jeg fått montert min fil. Og loop det brukes for å montere image. Tidligere i dag så vi på selve disken. Den er montert her på dev.loop. Så dette er en fysisk SSD-disk som er montert.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0021", "start": 1450.36, "end": 1543.62, "token_count": 292, "text": "Men kjelt nederst her så ser vi at den... Nå har jeg fått montert min fil. Og loop det brukes for å montere image. Tidligere i dag så vi på selve disken. Den er montert her på dev.loop. Så dette er en fysisk SSD-disk som er montert. Men man monterer den på helt samme måte med image. Og dermed så kan man... For eksempel så går det an å ta en... Og så kan man ta en kopi av hele dette disk-imaget. Og da får man noe som ligner på den filen jeg har. Men så er da poenget... Når jeg har den montert, så kan jeg gå inn på disken. Sånn. Så nå er jeg inne på disken. Det er en sånn mappe som heter Lost and Found, som er en sånn standardmappe som lages i EXA. Så kan jeg nå begynne å lage filer på denne disken. Det vil si, den rettighetene er... Jeg trenger fortsatt ruterettigheter. Akkurat som med vanlig filsystem, så kunne jeg endre rettighetene til Hauger og så videre, og så kunne jeg skrive der.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0022", "start": 1517.02, "end": 1626.8, "token_count": 284, "text": "Så kan jeg nå begynne å lage filer på denne disken. Det vil si, den rettighetene er... Jeg trenger fortsatt ruterettigheter. Akkurat som med vanlig filsystem, så kunne jeg endre rettighetene til Hauger og så videre, og så kunne jeg skrive der. Men jeg kan heller ta og blir ut. Nå har jeg fått laget én fil. Og så kan jeg lage kanskje en fil til. Sånn. Så nå har jeg to filer som ligger på disken. Og da vet jeg at selv om dette bare er filer på seks bites, så bruker hver av de en hel blokk. Hvis jeg nå øker størrelsen på pilen, så vil jeg fortsette å skrive utover i blokka. Men jeg kan prøve å gå ut herfra. Gå vekk fra disken. Og så kan jeg avmontere disken. Og nå er den borte. Hvis jeg nå prøver å gå inn... Så ligger det ingenting der. Da er det bare en tom mappe. Så hender det man må synke for at det skal skrives til disk, det som ligger der.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0023", "start": 1592.12, "end": 1694.94, "token_count": 298, "text": "Gå vekk fra disken. Og så kan jeg avmontere disken. Og nå er den borte. Hvis jeg nå prøver å gå inn... Så ligger det ingenting der. Da er det bare en tom mappe. Så hender det man må synke for at det skal skrives til disk, det som ligger der. Den synkoperasjonen vil sørge for at det skrives til disk, sånn at det ikke bare blir liggende i ram med ramcash eller lignende. Det jeg tenkte å prøve nå, var å prøve å montere den igjen. Og så gå inn og slette... Nei, hva er det jeg skal? Jeg skal montere... Nå må jeg finne ut hvor jeg var. Jeg var på disk. Her har vi en fil. Så det jeg skal prøve å gjøre, er å montere igjen én fil på... Mount... Og så skal jeg gå inn på Mount. Og så ser vi... Jeg kan gjøre det eksplisitt. Jeg har to filer her. Én fil og to fil. Så kan jeg nå ta opp RM2fil.tkst. Ok, nå sletter jeg den filen. Og da er... Hvis vi snakker om Linux-filsystemer og så videre,", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0024", "start": 1673.14, "end": 1785.02, "token_count": 297, "text": "Og så ser vi... Jeg kan gjøre det eksplisitt. Jeg har to filer her. Én fil og to fil. Så kan jeg nå ta opp RM2fil.tkst. Ok, nå sletter jeg den filen. Og da er... Hvis vi snakker om Linux-filsystemer og så videre, Det fins ikke noe ønderlig. Så hvis man har slettet en fil, så er den borte. Punktum. Så da kan du glemme å finne den. Men det som vi skal se på nå, er at man sletter faktisk ikke selve filen. Man sletter bare linkene til filen. Så det skal være mulig å finne igjen innholdet av denne filen, selv om den ikke synes nå på fyllesystemet. Og du kan ikke med... Vanlig standard Linux-operativsystem, så kan du ikke finne igjen det innholdet i Tofil. Men vi kan prøve likevel. Vi kan først og så avmontere Umount MNT. Og da ser vi... Her så har vi nå fortsatt den enfield-disken. Og legger også merke til at størrelsen er fortsatt den samme. Vi hadde vel... Oi... Langt der oppe... Når vi lagde den.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0025", "start": 1743.96, "end": 1861.94, "token_count": 289, "text": "Vi kan først og så avmontere Umount MNT. Og da ser vi... Her så har vi nå fortsatt den enfield-disken. Og legger også merke til at størrelsen er fortsatt den samme. Vi hadde vel... Oi... Langt der oppe... Når vi lagde den. Skal vi se om vi finner størrelsen her, da... Her. 8388608. Den størrelsen er fortsatt den samme. Så imaget er på en måte... Hele disken har en gitt størrelse. Den er delt nå inn i 8000 blokker, så det endrer seg ikke. Når man skriver inn på den disken, så endrer du de. Men en disk har en gitt størrelse, og det vil også gjelde for et image som dette. Men det vi skal prøve nå, er å bruke otopsiverktøyet til å gå inn og se på den disken. Da må jeg prøve å hoppe dit. Sånn. Det står instruksjoner om hvordan man skal installere... Og bruke dette verktøyet på... Tanken er at man da bruker det på Linux-VM. Men så kan man... Når man skal installere på Linux-VM,", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0026", "start": 1835.28, "end": 1935.78, "token_count": 290, "text": "Da må jeg prøve å hoppe dit. Sånn. Det står instruksjoner om hvordan man skal installere... Og bruke dette verktøyet på... Tanken er at man da bruker det på Linux-VM. Men så kan man... Når man skal installere på Linux-VM, men man skal bruke det, så kan du bruke det fra egen laptop. For den kjører da over web. Så hvis dere følger instruksjonene, så kan dere se senere hvordan man setter opp. Og det er ganske rett frem. Men nå vil jeg lage en ny case for å se på et image. Man trenger et casename. Jeg bare kaller det det samme som filen. Så tror jeg man trenger en investigator. Det er da HH. Og så new case. Og da ser vi... Directory created. Og så må jeg bare si Adhost... Ja... Jeg kan kalle det en HH-lapp. Det er da liksom maskinen som denne disken har ligget på. Og så er det en del forskjellige ting som man kunne bruke i en mer seriøs case, men jeg velger bare Adhost. Og så må jeg legge til det imaget jeg har. Det jeg ønsker å se på.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0027", "start": 1918.26, "end": 2023.26, "token_count": 283, "text": "Det er da liksom maskinen som denne disken har ligget på. Og så er det en del forskjellige ting som man kunne bruke i en mer seriøs case, men jeg velger bare Adhost. Og så må jeg legge til det imaget jeg har. Det jeg ønsker å se på. Og da må jeg ha full path til det imaget som... ... som jeg skal bruke. Ja, men så har jeg glemt en ting, og det kan fortere gjøres når jeg skal bruke dette her. Det imaget jeg har lagd og bruker, det er jo én fil, og det ligger på laptopen min. Otopsy kjører på min Linux-VM. Så aller først må jeg kopiere det dit. Så da hopper jeg hit og så kopierer jeg nå hele disken. Og dette kunne være en kopi av en fysisk harddisk eller minnepinne som jeg nå kopierer rundt omkring. Så jeg skal ha den til group 100 at os 100. Kolon... ja. Så nå kopierer jeg den inn på... Inn på Linux-laptopen, og der, inne på... Inne som Group 100, der har jeg startet Otopsy.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0028", "start": 1987.46, "end": 2092.18, "token_count": 289, "text": "som jeg nå kopierer rundt omkring. Så jeg skal ha den til group 100 at os 100. Kolon... ja. Så nå kopierer jeg den inn på... Inn på Linux-laptopen, og der, inne på... Inne som Group 100, der har jeg startet Otopsy. Frenzy Broser. Det er det programmet som kjører på web. Her ser vi jeg bruker 8166. Det er da IP-en som jeg har lokalt her på min laptop. Så sånn virker systemet. Så nå kan jeg komme tilbake her. Og så kan jeg skrive inn at den ligger... Filen ligger på Group 100. Og så la jeg den på én fil. Og så må man velge partition. Det står også i oppgaven denne uken. Partition, og så Next. Så skal man egentlig bare ignore hash value. Det er litt sånn for hvis man skal forsikre seg om at det er riktig fil, osv. Så kan man lage sånn MD5-hash, sånn at senere når du skal bevise dette i retten, så kan du dobbeltkontrollere at det er riktig hash. Men den motepoint der kan man bare beholde.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0029", "start": 2071.78, "end": 2167.94, "token_count": 292, "text": "Det er litt sånn for hvis man skal forsikre seg om at det er riktig fil, osv. Så kan man lage sånn MD5-hash, sånn at senere når du skal bevise dette i retten, så kan du dobbeltkontrollere at det er riktig hash. Men den motepoint der kan man bare beholde. Otopsi ser at det er en XD, så dette ser OK ut. Så nå kan jeg da trykke på OK, for nå har jeg lagt til dette imaget. Og da har jeg fått opp en case med et image som jeg kan analysere. Og da er det egentlig bare å trykke på Analyze. Og så kan jeg begynne å se på fillesystemet. Så nå har jeg på en måte lagd en liten disk, og så har jeg fått den inn i systemet. Jeg kan se på image details her oppe. Og da ser vi litt sånn at det er en X3. Og så her kommer det litt mer metainformasjon. Det er de pekerne som peker til hvor sektorene eller fragmentene ligger. Og her ser vi Blokkrange. 0 til 8191. Det betyr at det er 8192 blokker med størrelse 1024.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0030", "start": 2139.68, "end": 2260.1, "token_count": 296, "text": "Og så her kommer det litt mer metainformasjon. Det er de pekerne som peker til hvor sektorene eller fragmentene ligger. Og her ser vi Blokkrange. 0 til 8191. Det betyr at det er 8192 blokker med størrelse 1024. Så når vi skal snakke om de blokkene, så må vi si at denne filen ligger i blokk nummer 6856. Da kan man gå inn på File Analysis. Det er kanskje det beste stedet å starte. Oi... Nå ser jeg faktisk at jeg har kommet inn på feil fil. Eller er det riktig? Jeg testet ut dette i går. Skal vi se... Nei, det ser riktig ut. 09.59.27. Ja. Nei, dette er riktig. Jeg kalte det 1fil.tkc og 2fil.tkc. Og 2fil.tkc... Den ser vi er slettet. Men vi kan se på den filen der. Den kan vi jo se på, for den ligger på disken. Den er det ikke noe problem på. Så jeg klikker på den, og så kan jeg displaye den som... Som Aski. Skal vi se. Men hvorfor kommer ikke den opp? Et øyeblikk.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0031", "start": 2219.62, "end": 2362.94, "token_count": 293, "text": "Og 2fil.tkc... Den ser vi er slettet. Men vi kan se på den filen der. Den kan vi jo se på, for den ligger på disken. Den er det ikke noe problem på. Så jeg klikker på den, og så kan jeg displaye den som... Som Aski. Skal vi se. Men hvorfor kommer ikke den opp? Et øyeblikk. Ja, jeg ser det fungerer litt dårlig med zoom her. Skal vi se... Det problemet nå er å få vist vinduet. Jeg tror jeg må ta den litt mindre sånn. Men det står her nede... Den layteksten der er én fil. Men vi må ha litt større. Sånn. Så problemstillingen er nå... 1fil.tk, den ligger her. Og hvis vi husker tilbake... Så sto det en tekst inni den enfil.tk. Og det var den teksten Enfil der. Så det er på en måte filen. Og hvis jeg nå klikker på den filen... her... Så kan vi se. Her er ID-none nummer tolv. Og her er da data om denne filen. Enfil.tk. Og denne er ikke slettet. At den ligger i blokk nummer 1537.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0032", "start": 2337.7, "end": 2431.22, "token_count": 279, "text": "Og hvis jeg nå klikker på den filen... her... Så kan vi se. Her er ID-none nummer tolv. Og her er da data om denne filen. Enfil.tk. Og denne er ikke slettet. At den ligger i blokk nummer 1537. Så filsystemet gjør da inode 12, peker på blokk 1537, og der ligger da teksten til enfill.tk. Hvis dette var en fil som krevde flere blokker, altså en som var større enn en K, så ville den allokere mange blokker. Så en tusen blokker som kunne ha en en megabyte for fil. Men vi går nå inn på den ene blokken. Trykket jeg på det fragmentet, eller som det også kalles, eller blokk 1537. Og her ser vi... Her står den teksten. Og her ser vi da 1K med data. Hvis man trykker på Heks display, så kan man se tydeligere hvilket data det er. Vi starter på null, og helt i starten på denne blokka så ser vi at det står én fil. Og det er da aski-tegnen for én fil.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0033", "start": 2406.12, "end": 2501.44, "token_count": 295, "text": "Og her ser vi da 1K med data. Hvis man trykker på Heks display, så kan man se tydeligere hvilket data det er. Vi starter på null, og helt i starten på denne blokka så ser vi at det står én fil. Og det er da aski-tegnen for én fil. Men vi ser også at den bruker én K, eller en hel blokk, 1024 bite for å lagre denne bitte lille filen. Men så er spørsmålet hvor... Hvor er den andre filen? Og det... Problemet er da at filstemma har nå slettet linkene. Så selv om vi går på File Analysis her, så er det ikke noe... Den der er på en måte bare... Den sier... Ja, den hadde INOD13, men den er ikke allokert mer. Innholdet av INOD13 er slettet. Og dermed er filen borte. Men den ligger et eller annet sted, så hvis man leter godt, så kan man finne 2Fill.txe. I utgangspunktet så kan den ligge hvor som helst på disken blant de 8000 blokkene som man har på denne disken. Og da kan man begynne å lete.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0034", "start": 2477.02, "end": 2566.82, "token_count": 283, "text": "Men den ligger et eller annet sted, så hvis man leter godt, så kan man finne 2Fill.txe. I utgangspunktet så kan den ligge hvor som helst på disken blant de 8000 blokkene som man har på denne disken. Og da kan man begynne å lete. Ja, vi kunne jo... Én ting som funker noen ganger, er å starte ut fra den én fil... Gå til Inode 12 og se hvor den peker. 1537... Og så kan man prøve å se i nærheten der. Hvis jeg skriver inn 1530 og ber om ti blokker, så får jeg alle blokkene som er i nærheten. Der ser vi... Her er én fil, men ikke noe mer. Men da har jeg... Med en rekke blokker etter hverandre. Og inne i de blokkene... Så der starter en blokk, og der ligger én fil. Så kan man lete gjennom og prøve å finne to fil. Når det er tekst, så går det an å søke. Så jeg kan f.eks. søke på strengen fil. Da søker jeg på en måte gjennom all teksten.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0035", "start": 2542.1, "end": 2632.58, "token_count": 298, "text": "Så der starter en blokk, og der ligger én fil. Så kan man lete gjennom og prøve å finne to fil. Når det er tekst, så går det an å søke. Så jeg kan f.eks. søke på strengen fil. Da søker jeg på en måte gjennom all teksten. Og her ser vi jeg får noen treff på 1-fil og 2-fil. Og spesielt her nede så får jeg en treff på 2-fil... På 7169. Så da kan jeg hoppe dit. Og vips, der ser vi. Der fant jeg 2-fil. Og den lå da i blokk 7169. Og som vi ser, selv om jeg... Slettet filen med RM og greier... Så ligger fortsatt den teksten der. Problemet er at vi ikke har filsysteminformasjonen som sier nøyaktig hvor den ligger. Hvis dette har vært en stor fil som var fragmentert rundt omkring, ville det vært en kjempejobb å finne den, for du har ikke informasjon om hvor bitene ligger. Men likevel så kunne man da finne ut deler. Og skjøte dem sammen osv. Så hovedpoenget er at...", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0036", "start": 2610.64, "end": 2690.98, "token_count": 273, "text": "Hvis dette har vært en stor fil som var fragmentert rundt omkring, ville det vært en kjempejobb å finne den, for du har ikke informasjon om hvor bitene ligger. Men likevel så kunne man da finne ut deler. Og skjøte dem sammen osv. Så hovedpoenget er at... 7169, da kan man gått... Når man finner ut hvor... En fil ligger... Hvis man vet fragmentnummeret... Kjenner til den blokken, så kan man bare gå dit og peke på View. Og så ser vi... Her ligger to filer. Det er den blokken.  Men problemet er da at når du gjør RM på en fil, så sletter du det tallet der rett og slett fra filsystemet, så man ikke vet lenger hvor den ligger. Men det kan være mulig sånn som dette her å likevel finne fram fil. Og i oppgaven denne uken så går det ut på at man skal... Jo, om man skulle gjøre noe lignende, men med et bilde, Siden bildene ligger pent etter hverandre, er det mulig å gjenskape bildet", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0037", "start": 2666.26, "end": 2759.36, "token_count": 293, "text": "Men det kan være mulig sånn som dette her å likevel finne fram fil. Og i oppgaven denne uken så går det ut på at man skal... Jo, om man skulle gjøre noe lignende, men med et bilde, Siden bildene ligger pent etter hverandre, er det mulig å gjenskape bildet ved å plukke ut alle blokkene som utgjør bildet, og så hente det ut fra otopsi. Så får man ut et helt bilde selv om det er slettet fra en disk. Ja. Det er også en oppgave som går på NTFS, og da vil dere se at NTFS-filsystemet... Det ligner på den måten at det har mye av de samme egenskapene. Det er egentlig en liste over clustere, men det er bare organisert på en litt annen måte. Så... Jeg har noen slider her med NTFS, men jeg tenker... Ja, nå ser jeg klokka er veldig mye, så jeg overlater de siste slidene til et lite selvstudium. Prøv å se på disse samtidig som dere gjør oppgaven om NTFS, som er denne uken, hvor du da bruker otopsi og leter rundt på et NTFS-system,", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0038", "start": 2731.26, "end": 2832.9, "token_count": 298, "text": "Så... Jeg har noen slider her med NTFS, men jeg tenker... Ja, nå ser jeg klokka er veldig mye, så jeg overlater de siste slidene til et lite selvstudium. Prøv å se på disse samtidig som dere gjør oppgaven om NTFS, som er denne uken, hvor du da bruker otopsi og leter rundt på et NTFS-system, og da vil du se at det er organisert på denne måten som er beskrevet her. Men hovedpoenget er at det bare er en liste over hvor klusterne ligger. På samme måte Linux filsystem først og fremst en liste over hvor blokkene eller fragmentene ligger. Men det er én liten ting som... Hvis dere holder ut fem ekstra minutter, så skal jeg si litt om raid helt til slutt. For der er det en ganske morsom sak med raid og paritet. Så... Aller først, hva er raid? RAID står for Redundant Area Independent Disks. Og redundant betyr overflødig eller i overflod. Generelt betyr redundant disk at man lagrer ting mer ett sted. Og det er da typisk for å lagre det i parallell, sånn at man kan lese det hurtigere.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0039", "start": 2804.74, "end": 2905.24, "token_count": 296, "text": "RAID står for Redundant Area Independent Disks. Og redundant betyr overflødig eller i overflod. Generelt betyr redundant disk at man lagrer ting mer ett sted. Og det er da typisk for å lagre det i parallell, sånn at man kan lese det hurtigere. Det fins mange raid-nivåer. Raid, som veldig mye annet innen operativsystemet, er et system for å øke hastigheten. Disker er trege, så de hjelper veldig mye med raid for å gjøre ting i parallell. Så akkurat som CPU-er, at man bruker flere CPU-er og gjør ting i parallell, Og Raid 0. Det er egentlig ikke Raid, for det er ikke redundant, men man striper da diskene. Det å stripe disker er at man da tar en fil, og så skriver man den over to disker. Så hvis jeg skulle lagre den setningen her, minst to disker i stripediskene, så ville kanskje minst to disker ligge på den første disken... Og det er jo ikke redundans, men dette vil da være hurtigere å lese, for da kan jeg lese fra to disker samtidig og nesten doble hastigheten.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0040", "start": 2885.14, "end": 2963.98, "token_count": 291, "text": "Så hvis jeg skulle lagre den setningen her, minst to disker i stripediskene, så ville kanskje minst to disker ligge på den første disken... Og det er jo ikke redundans, men dette vil da være hurtigere å lese, for da kan jeg lese fra to disker samtidig og nesten doble hastigheten. Jeg leser minst to disker fra den ene og stripediskene på den andre. Raid 1, det er ekte raid. Da har man to disker, og så dupliserer man dataene. Så det skrives på begge diskene. Det vil ta like lang tid å skrive. Men det går hurtigere å lese, for da kan du lese én setning fra hver. Og så går det dobbelt så fort å lese. Så er det RAID 3 og 4. Der bruker man i tillegg paritet. RAID 3 og 4 er ikke så mye brukt, så vi hopper til RAID 5. Da har man minst tre disker, og pariteten lages fordelt på diskene. Det er om man har et odd- eller likeantall enere. Altså hvis man er tre enere, så har man paritet 1.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0041", "start": 2940.1, "end": 3027.46, "token_count": 298, "text": "RAID 3 og 4 er ikke så mye brukt, så vi hopper til RAID 5. Da har man minst tre disker, og pariteten lages fordelt på diskene. Det er om man har et odd- eller likeantall enere. Altså hvis man er tre enere, så har man paritet 1. Hvis man er fire enere, så har man paritet 0. La oss si du ser på én bite. Og det brukes i mange andre sammenhenger til å feilsjekke, for å sjekke om bitt har endret seg underveis. Med RAID5 bruker man minst tre disker. Og så fordeler man dataene på disse diskene, sånn at det kan både skrives og leses parallelt. Og pariteten lagres også fordelt på diskene. Og det betyr at uansett hvilken... Hvis du har én disk som nå ryker, så vil man kunne gjenopprette alt som var på diskene. På alle diskene ut fra de to eller flere gjenværende diskene som ikke har røket. Og det høres jo veldig rart ut, men det funker. Selv om du har ti disker, uansett hvilken av de som ryker,", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0042", "start": 3008.6, "end": 3090.38, "token_count": 294, "text": "så vil man kunne gjenopprette alt som var på diskene. På alle diskene ut fra de to eller flere gjenværende diskene som ikke har røket. Og det høres jo veldig rart ut, men det funker. Selv om du har ti disker, uansett hvilken av de som ryker, så kan man rette opp innholdet fra paritetsdisken. Og samtidig så har man den samme fordelen som med RAID-0, at man leser i... Sånn at det går mye raskere. Dette er litt komplisert, men vi skal se på et konkret eksempel. Så da vil jeg se at det faktisk ikke er så komplisert. Så dette er det siste eksempelet vi skal gå gjennom. Nå bruker jeg raid 3 fordi at... For det første så lagrer det alt pariteten på én disk. Raid 5, som er vanligere, den fordeler denne pariteten. Og det fungerer like bra, men det er litt enklere prinsipp å se på... Pariteten på den måten ved at man har den på én disk. Vi ønsker å lage alle disse fire kolonnene med data.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0043", "start": 3067.66, "end": 3151.3, "token_count": 290, "text": "Raid 5, som er vanligere, den fordeler denne pariteten. Og det fungerer like bra, men det er litt enklere prinsipp å se på... Pariteten på den måten ved at man har den på én disk. Vi ønsker å lage alle disse fire kolonnene med data. Dette er dataene våre. Og så sprer vi det utover på disker. Når vi skal lese det inn, går det fire ganger så fort som om alt lå på disken. I tillegg har vi denne mystiske paritetsdisken. Den er veldig enkel. Hvis det er et like antall enere... Altså hvis det er to... Nei... Jo, hvis det er et like antall enere... Hvis det er to... Her er det også to. Eller fire enere. Så er pariteten null. Det samme ville det vært... Da ville pariteten vært null. Men hvis det er et odd-antall... Sånn som her er det tre enere. Da er pariteten én. Her er det én ener. Da er pariteten én. Hvis du først har satt opp denne disken, så er det veldig kjapt å lese ut pariteten.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0044", "start": 3131.46, "end": 3212.42, "token_count": 276, "text": "Da ville pariteten vært null. Men hvis det er et odd-antall... Sånn som her er det tre enere. Da er pariteten én. Her er det én ener. Da er pariteten én. Hvis du først har satt opp denne disken, så er det veldig kjapt å lese ut pariteten. Det kan man gjøre med en exor, og det er ofte hardware som gjør dette. Men så kommer det geniale. Nå hevder jeg at uansett... Hvis hvilken av disse diskene som måtte ryke, sånn at du mister absolutt all informasjon, så kan man bygge opp disken igjen fra paritetsdisken. Det er klart at hvis paritetsdisken ryker, så gjør det ikke noe. For da kan man bare regne ut pariteten på nytt. Så her kommer årets siste slide - paritet og trolldom. Hvordan kan man nå trylle frem dataene? Disk 2 her ryker. Tenk bitte lite grann på det. Kanskje... Kanskje noen som har noen ideer om det, så kan dere foreslå i chatten.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0045", "start": 3182.46, "end": 3305.66, "token_count": 297, "text": "Så her kommer årets siste slide - paritet og trolldom. Hvordan kan man nå trylle frem dataene? Disk 2 her ryker. Tenk bitte lite grann på det. Kanskje... Kanskje noen som har noen ideer om det, så kan dere foreslå i chatten. Disk 2 er nå slettet totalt. Hvordan kan jeg få tilbake bittene som var der? Ja, da skal jeg prøve å... Mens dere tenker, så skal jeg prøve å sette på... Dokumentkamera. Der. Og så skal jeg begynne å trylle. Så kan jeg prøve å bare... Uten å si noe, så kan jeg... Det ville vært lett for meg å jukse, men jeg lover - jeg jukser ikke. Jeg ser bare på den disken her. Det pleier å være et glansnummer når jeg har tavle, og det er opplagt at jeg ikke jukser. Men jeg kan nå, ut fra paritetsdisken og de andre diskene, skrive ned verdien på disk 2. Og da ser jeg at her må det være. Her må det være 1. Her må det være 0. Her må det være 0. Her må det være 1. Her må det være 0.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0046", "start": 3269.52, "end": 3381.12, "token_count": 293, "text": "Men jeg kan nå, ut fra paritetsdisken og de andre diskene, skrive ned verdien på disk 2. Og da ser jeg at her må det være. Her må det være 1. Her må det være 0. Her må det være 0. Her må det være 1. Her må det være 0. Og her må det være 1. Jeg skal hoppe tilbake, og så må jeg se... Stemmer det i forhold til de opprinnelige slidene? Ja. Hvis vi hopper fram og tilbake... 1.00, 1.01, 1.00, 1.01. Så... Og dere har sikkert sett... Pariteten sier jo om det er et odde eller like antall nuller. Nei... Et odde antall enere. Så i det første tilfellet her, siden det var en ener og paritetsvis en visu null, så måtte det bli en ener for å gi den samme pariteten. Så på den måten kan man da bare regne ut. Her var det tre enere. OK, da er pariteten 1, så da må det være 0. Og her var det to enere. Pariteten er 0, så da må det være 0.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0047", "start": 3364.14, "end": 3436.18, "token_count": 298, "text": "så måtte det bli en ener for å gi den samme pariteten. Så på den måten kan man da bare regne ut. Her var det tre enere. OK, da er pariteten 1, så da må det være 0. Og her var det to enere. Pariteten er 0, så da må det være 0. I denne kolonnen så måtte det komme en ener, for pariteten var 0. Og da måtte jo det ha vært en ener. To enere i paritet 0. Her var pariteten 1, så da må det være 0. Og igjen her er det tre enere. Paritet 0, det stemmer ikke, så den må ha vært en ener. Og på den måten så kan man da... Vi kan lett tenke oss at selv om disk 4, disk 3 eller disk 1 røyk, så ville du kunne trylle frem disken igjen ved hjelp av paritetsberegningen. Her kan du ha ti disker i parallell, og bare ved å legge til én ekstra disk, så får du rendudans ved at om én disk ødelegges, så kan du bygge opp neste. Første spørsmål i chatten, hva om to disker ryker?", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0048", "start": 3409.7, "end": 3491.38, "token_count": 292, "text": "så ville du kunne trylle frem disken igjen ved hjelp av paritetsberegningen. Her kan du ha ti disker i parallell, og bare ved å legge til én ekstra disk, så får du rendudans ved at om én disk ødelegges, så kan du bygge opp neste. Første spørsmål i chatten, hva om to disker ryker? Vel, da er du ferdig. Hvis to disker ryker, så er det krok mot døra. Da har du mistet alle dataene. Men heldigvis så er det sånn at det er sjelden at... Altså, disker ryker etter en stund, men det er heldigvis sjelden at de ryker helt samtidig. Og med harddisk... Nei, med... Raid... Med spesiell hardware for raid så kan den faktisk regne ut dette veldig raskt on the fly. Sånn at om en disk er ødelagt en stund, så kan dissystemet fortsatt stå og virke lenge. Ok, beklager. Da har jeg gått kjempemasse over tiden. Men nå får dere til gjengjeld en kjempelang pause helt fram til eksamen, eller iallfall til...", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0049", "start": 3472.9, "end": 3565.54, "token_count": 291, "text": "Sånn at om en disk er ødelagt en stund, så kan dissystemet fortsatt stå og virke lenge. Ok, beklager. Da har jeg gått kjempemasse over tiden. Men nå får dere til gjengjeld en kjempelang pause helt fram til eksamen, eller iallfall til... Prøveeksamen. Kom gjerne med forslag til når dere ønsker prøveeksamen. Vi må koordinere litt i forhold til... Ja, det er mange som har skytetjeneste, f.eks. Så vi må koordinere litt i forhold til det. Men først og fremst, prøv på ukens oppgaver. De er morsomme. Spesielt den med spionoppgaven. Få ut bildet, men gjør et forsøk. Så kommer det et fyldig løsningsforslag etter hvert, hvis dere så først. Ok. Da er det spørsmål her... Når skal dere publisere fasit til obligen? Ja, godt spørsmål. Jeg har... Jeg har publisert noe. Skal vi se... Jeg tror jeg har publisert til og med Oblique 2 i hvert fall. Hvis vi går inn...", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0050", "start": 3538.68, "end": 3652.06, "token_count": 299, "text": "Ok. Da er det spørsmål her... Når skal dere publisere fasit til obligen? Ja, godt spørsmål. Jeg har... Jeg har publisert noe. Skal vi se... Jeg tror jeg har publisert til og med Oblique 2 i hvert fall. Hvis vi går inn... Jo, det er en Oblig. Vi ser ikke absolutt alt jeg har... Men så... Til og med Obligue 2 er publisert. Å publisere før alle har fått svar på objekt-treet og eventuelt sjansen til å prøve på nytt. Men det som det kan anbefales sånn generelt for å jobbe med kurset fremover, er å begynne å se på gamle eksamensoppgaver. Først og fremst... Jeg har vært litt av og på dette kurset. I 2012 var det Erik Hjelmås som hadde kurset, med litt annet pensum. Men fra våren 2017 og til 2020 til nå, så har jeg hatt kurset... Oi, du ser kanskje ikke slutten her. Her. Til og med 2020. Så den beste treningen er kanskje å jobbe med disse eksamsoppgavene fra 2017 og fram til 2020.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0051", "start": 3623.22, "end": 3705.24, "token_count": 283, "text": "med litt annet pensum. Men fra våren 2017 og til 2020 til nå, så har jeg hatt kurset... Oi, du ser kanskje ikke slutten her. Her. Til og med 2020. Så den beste treningen er kanskje å jobbe med disse eksamsoppgavene fra 2017 og fram til 2020. Og det er veldig viktig når dere jobber med eksamsoppgaver, at dere ikke bare går rett på løsningsforslaget, men at dere gjør et seriøst forsøk på eksamsoppgavene og så ser på løsningsforslaget etterpå. Det å jobbe videre med tidligere oppgaver er kanskje den beste måten Det er kanskje den beste måten å lære dette på, å jobbe aktivt med oppgaver. Det er først da man får en dypere forståelse for dette stoffet. For det er mye stoff, og det er en del litt kompliserte sammenhenger. Så jobb aktivt med stoffet når dere jobber videre med det. Det er mitt hovedbudskap. Da vil jeg takke for følget så langt,", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0052", "start": 3679.54, "end": 3771.62, "token_count": 287, "text": "Det er først da man får en dypere forståelse for dette stoffet. For det er mye stoff, og det er en del litt kompliserte sammenhenger. Så jobb aktivt med stoffet når dere jobber videre med det. Det er mitt hovedbudskap. Da vil jeg takke for følget så langt, spesielt til dere som trofast har stått opp hver tirsdag morgen. Veldig bra jobba. Håper virkelig dere får igjen for det på eksamen, at dere gjør en bra eksamen. Ja, det var... Det kan jeg ta opp her. Det var egentlig et godt spørsmål om begrunnelse for å gjøre... For å ha karakter på eksamen. For det var en som uttrykte at det var litt urettferdig om... Om noen får hjelp på eksamen av familie eller venner osv. Som hjelper til på eksamen. Det er jo opplagt juks, så jeg håper og jeg tror også at det er veldig få som gjør det. Så tror jeg dette faget er såpass vanskelig at det er ikke så mange som har familiemedlemmer eller venner som kan hjelpe til med en sånn eksamen.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0053", "start": 3752.04, "end": 3840.92, "token_count": 293, "text": "Det er jo opplagt juks, så jeg håper og jeg tror også at det er veldig få som gjør det. Så tror jeg dette faget er såpass vanskelig at det er ikke så mange som har familiemedlemmer eller venner som kan hjelpe til med en sånn eksamen. For du må jobbe veldig målbevisst, konkret frem med dette stoffet for å kunne det såpass godt at du på tre timer kan komme opp med svar på en ganske omfattende eksamensoppgave. Som gjør at det vil skje i veldig liten grad. I tillegg er det en begrunnelse at det er veldig kjedelig for mange av dere som får veldig mange pass-fail-karakterer. Spesielt når du skal gå videre på studier og søke om master- og ph.d. etter hvert. Så er det litt kjedelig å jobbe veldig hardt med kurs. Og så bare - bare få en godkjent når du ellers kanskje ville fått en A eller en B. På eksamen skal jeg også prøve å differensiere litt, sånn at man ikke får samme oppgaver. Så det er vanskelig å samarbeide om oppgaven også.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0054", "start": 3821.46, "end": 3904.22, "token_count": 289, "text": "Og så bare - bare få en godkjent når du ellers kanskje ville fått en A eller en B. På eksamen skal jeg også prøve å differensiere litt, sånn at man ikke får samme oppgaver. Så det er vanskelig å samarbeide om oppgaven også. Så jeg håper i hvert fall at det skal gi rettferdige karakterer for alle. At dette har vært en tung tid. At det er vanskeligere forhold å studere under. Og ja, det vil i hvert fall jeg prøve å ta hensyn til. Jeg tar ofte hensyn til sånne aspekter ved at... Hvis det viser seg at en eksamensoppgave har vært veldig vanskelig... Det er ikke alltid så lett å se for meg - oi, dette var vanskelig. Hvis det er en veldig vanskelig oppgave, så viser det seg at 1 av 100 har klart å svare på det... Så skjønner jeg da i ettertid at dette var kanskje mye vanskeligere enn de studentene som hadde eksamen i fjor. Og da kan man i ettertid, sammen med sensor, gjøre en vurdering om", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0055", "start": 3884.74, "end": 3965.8, "token_count": 282, "text": "så viser det seg at 1 av 100 har klart å svare på det... Så skjønner jeg da i ettertid at dette var kanskje mye vanskeligere enn de studentene som hadde eksamen i fjor. Og da kan man i ettertid, sammen med sensor, gjøre en vurdering om at man gir en litt snillere... Man setter rett og slett litt snillere grenser Så den type vurderinger gjøres hele tiden, og det vil jeg også gjøre i år. Men ikke ta det som en såpepute. Jobb seriøst fram til eksamen. Og prøv å gjøre det så bra som bare mulig. Og så får dere forhåpentligvis, med god jobbing, så får dere en god karakter også. Ok. Da vil jeg takke for følget så langt, og så... Da ses vi forhåpentligvis på prøveeksamen. Kanskje vi til og med kan ha en fysisk gjennomgang. Vi får se. Blir det en prøveeksamen som øving til? Ja, det blir det. Det gjenstår å se når. Jeg må snakke med Inspera-admin også.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0056", "start": 3941.46, "end": 4024.92, "token_count": 291, "text": "Da ses vi forhåpentligvis på prøveeksamen. Kanskje vi til og med kan ha en fysisk gjennomgang. Vi får se. Blir det en prøveeksamen som øving til? Ja, det blir det. Det gjenstår å se når. Jeg må snakke med Inspera-admin også. I fjor fikk vi til i hvert fall én prøveeksamen som var i Inspera. Helt samme setting som dere får til eksamen. At dere sitter hjemme og gjør en tretimerseksamen. Så jeg håper dere får til i hvert fall ett tilfelle. Kanskje to også. Kanskje jeg kan gjenta prøveeksamen fra i fjor. For der har jeg allerede en gjennomgang på videoer. Ja... Derfor kommer det flere spørsmål her. Det er bra. I den grad det blir teorispørsmål, hvordan gjør du med kilder hvis det blir aktuelt? Det er et godt spørsmål. Det kommer nok ikke til å bli så veldig mye teori av den typen som er veldig lett å google. Hva er en CPU, eller... Men i den grad det blir det, så gjelder det samme kilde...", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0057", "start": 4001.48, "end": 4096.74, "token_count": 297, "text": "I den grad det blir teorispørsmål, hvordan gjør du med kilder hvis det blir aktuelt? Det er et godt spørsmål. Det kommer nok ikke til å bli så veldig mye teori av den typen som er veldig lett å google. Hva er en CPU, eller... Men i den grad det blir det, så gjelder det samme kilde... Alltid. Hvis man bruker kilder, så må man referere til det. Og det vil ikke godtas som et godt svar på en eksamensoppgave hvis man bare tar en kopi av noe som ligger et sted, selv om man da skriver en referanse. Hvis man opplagt plagerer, bare kopierer noe fra et eller annet sted... Av hverandre. Så er det et plagiat når man da... Hvis man ikke oppgir referanse. Så... Man må være ganske forsiktig... Hvis du er veldig inspirert av innholdet på et eller annet sted på nettet, så er det veldig viktig å ha med en referanse, sånn at ikke man kommer etterpå og blir stoppet av Urkuns plagiatkontroll. Da får man 100 % likt, og så så man der. For det kan være ganske alvorlig.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0058", "start": 4075.9, "end": 4150.14, "token_count": 289, "text": "Hvis du er veldig inspirert av innholdet på et eller annet sted på nettet, så er det veldig viktig å ha med en referanse, sånn at ikke man kommer etterpå og blir stoppet av Urkuns plagiatkontroll. Da får man 100 % likt, og så så man der. For det kan være ganske alvorlig. Men når det er sagt sånn som eksamen i fjor... Den er nok ganske bygd opp på den måten at vi ser på konkrete problemstillinger. Jeg viser f.eks. et program som kjører, og så skjer sånn og sånn. Og så er spørsmålet hvorfor bruke så mye ramm i dette tilfellet? Hvorfor tar dette dobbelt så lang tid som... Den type spørsmål som man måtte tenke og bruke det man har lært, i større grad enn direkte teorispørsmål. Så det vil nok være litt forskjellig fra... Hvis man ser på tidligere eksamensoppgaver, så er det en del direkte teorispørsmål fordi da var det eksamen uten hjelpemidler. Så det er først og fremst de oppgavene.", "source": "lecture"}
{"lecture_id": "os15time2", "chunk_id": "os15time2_0059", "start": 4133.44, "end": 4189.68, "token_count": 179, "text": "Så det vil nok være litt forskjellig fra... Hvis man ser på tidligere eksamensoppgaver, så er det en del direkte teorispørsmål fordi da var det eksamen uten hjelpemidler. Så det er først og fremst de oppgavene. De oppgavene som er mer konkrete, som er de mest mestrelevante. Ok. Da håper jeg dere ikke er helt utslitt. Men ta gjerne en pause og kom tilbake på laben. Så skal jeg nå lage break-out-rooms til alle studentassistentene. Så kan dere få hjelp. Jeg tar et kvarters pause. Så takk for i dag og takk for følget dette som hestere. Stå på videre.", "source": "lecture"}
{"lecture_id": "os4del8", "chunk_id": "os4del8_0000", "start": 0.02, "end": 100.72, "token_count": 295, "text": "Ok, det var bransjekontroll. Da skal vi se på... Da skal vi se på ram. Det vi skal prøve å gjøre nå, er altså å endre... Eller legge til en institusjon, sånn at maskinen skriver til Ramm. Da kan jeg legge programmet her, og så kan vi gå inn og... Og så se på... Skal vi prøve... Vi kan lukke den av. Jeg må ha riktig peker, så skal vi prøve å komme inn i ramme der. Her er altså ramme. Dette er en ekstremt liten ramme. 16 ganger 4. Vanligvis er ramme på milliarder av bytes. Gigabyte med ram. Her har vi en bitte liten ram. Det er bare plass til 16 bites, og det er ikke bites engang. Det er 4 bites. Så dette er på en måte halve bites. Hvis vi åpner den, så ser vi at dette her er bare 4 bits som er lagret for hver linje. Og det er totalt 16 linjer. Vi legger merke til at her ligger det nå... Hva ligger her? 2, 4, 8. Så det vi skal prøve å gjøre nå,", "source": "lecture"}
{"lecture_id": "os4del8", "chunk_id": "os4del8_0001", "start": 76.88, "end": 172.04, "token_count": 297, "text": "Hvis vi åpner den, så ser vi at dette her er bare 4 bits som er lagret for hver linje. Og det er totalt 16 linjer. Vi legger merke til at her ligger det nå... Hva ligger her? 2, 4, 8. Så det vi skal prøve å gjøre nå, er å legge resultatet fra beregningen inn i ramm. For det er det som vanligvis skjer i en beregning. Til å begynne med skjer alle beregningene inni registrene lokalt i maskinen. Så skriver man resultatet ut i ram. For å gjøre det, så trenger man da en instruksjon som gjør akkurat det. Da må vi gå tilbake hit, og så må vi se at... Jo, her er det to instruksjoner som vi ikke har brukt - load og store. Og store, den gjør akkurat det. Den lagrer resultater i ram. Denne institusjonen er sånn at førsteopprang er Destination Register, og andre er Source Register. Så det betyr at vi må angi til slutt hvilket... Eller det tallet i et register, eller et av registrene, så må vi ha adressen til dit vi skal legge det.", "source": "lecture"}
{"lecture_id": "os4del8", "chunk_id": "os4del8_0002", "start": 150.0, "end": 239.98, "token_count": 290, "text": "Denne institusjonen er sånn at førsteopprang er Destination Register, og andre er Source Register. Så det betyr at vi må angi til slutt hvilket... Eller det tallet i et register, eller et av registrene, så må vi ha adressen til dit vi skal legge det. Da kan jeg f.eks. si at i R0, når beregningen er ferdig, der ligger tallet 3. Så da kan jeg... Legge inn R av 3 ut i ram. Og så la oss si... I R1 så ligger vel tallet 1. Så jeg kan velge Destination Register. Det er som 1. Ja, nå sa jeg feil. R av denne, det er jo det som legges ut. Og den skal jo være R3. Som... som resultatet vårt ligger i. Så jeg må ta R3 og legge ut i en gitt adresse. Og det viktigste er Store. Det er 1010. Vi bruker litt tid på dette, for dette er hvordan man programmerer en maskin direkte i maskinkode. Heldigvis så slipper vi å gjøre det med Exo86. Da har vi compulator som fikser den jobben, men nå skal vi prøve å gjøre det.", "source": "lecture"}
{"lecture_id": "os4del8", "chunk_id": "os4del8_0003", "start": 223.9, "end": 329.72, "token_count": 286, "text": "Vi bruker litt tid på dette, for dette er hvordan man programmerer en maskin direkte i maskinkode. Heldigvis så slipper vi å gjøre det med Exo86. Da har vi compulator som fikser den jobben, men nå skal vi prøve å gjøre det. 1.0, 1.0. Det er da altså Store. Og da må jeg gå inn i rommet her oppe. Nå er jeg over i rom, så nå er det Instrukt maskininstruksjonene. Så tenker jeg nå at nå kan jeg legge til en maskininstruktor. Oi... Vi ser ikke. Supert. Bra du sier ifra. Ja, da går jeg litt tilbake. Det jeg skal prøve å gjøre nå, er å legge til en institusjon som lagrer sluttresultatet som ligger i hjertet. Og da går jeg nå ned til institusjon nummer åtte. Altså etter den siste jumpen, for i dag fortsetter programmet bare nedover. Og så må jeg her skrive inn riktig institusjon. Og det var vel... Institusjonen var 1010 for Store. Skal jeg passe på å gå tilbake... Sånn.", "source": "lecture"}
{"lecture_id": "os4del8", "chunk_id": "os4del8_0004", "start": 300.0, "end": 404.36, "token_count": 297, "text": "Og da går jeg nå ned til institusjon nummer åtte. Altså etter den siste jumpen, for i dag fortsetter programmet bare nedover. Og så må jeg her skrive inn riktig institusjon. Og det var vel... Institusjonen var 1010 for Store. Skal jeg passe på å gå tilbake... Sånn. Så må jeg gå inn her og skrive 1.0, 1.0. Og så ønsker jeg å lagre det som ligger i R3. Og det var... Da skulle jeg skrive 3 der, for det betyr legg verdien av register 3 i denne adressen. Adressen er nå 0,0, men la oss si jeg bruker R1. Altså det tar... Tallet som det ligger i, er 1. Da bruker jeg 01. Sånn. Har jeg programmert en linje, så må jeg i denne editoren gå ett hakk ned, og så er det lagret. Ok. Da kan jeg prøve å kjøre, og så prøver jeg å se i Ramm etterpå om dette fungerer som det skal. Så da fortsetter jeg å kjøre programmet. Hva betyr R1 her? R1 er da... Det er da adressen i ram.", "source": "lecture"}
{"lecture_id": "os4del8", "chunk_id": "os4del8_0005", "start": 370.12, "end": 485.84, "token_count": 292, "text": "gå ett hakk ned, og så er det lagret. Ok. Da kan jeg prøve å kjøre, og så prøver jeg å se i Ramm etterpå om dette fungerer som det skal. Så da fortsetter jeg å kjøre programmet. Hva betyr R1 her? R1 er da... Det er da adressen i ram. Det er den linjen i ram som resultatet skal lagres i. Så etter kjøringen så er vel R1 lik 1, og da skal resultatet lagres i ram. Linje nummer én. Nå kjører vi sakte gjennom. Nå har vi fått ut tallet seks i R3. Og så ser vi... Nå hopper vi ikke. Nå lyste det ikke her. Så vi hopper ikke. Og nå utføres da ram-operasjonen. Og det den skal gjøre... Nå er den ferdig. Det er... Den skulle legge resultatet, det som ligger der. Det skal legges i RAM på adresse 1, siden det er R1. Da må vi bare gå inn og sjekke i RAM. Har dette skjedd? Hvis vi er heldige, så har vi fått til det. Skal vi se... Nytt forsøk. Der.", "source": "lecture"}
{"lecture_id": "os4del8", "chunk_id": "os4del8_0006", "start": 447.76, "end": 562.24, "token_count": 293, "text": "Den skulle legge resultatet, det som ligger der. Det skal legges i RAM på adresse 1, siden det er R1. Da må vi bare gå inn og sjekke i RAM. Har dette skjedd? Hvis vi er heldige, så har vi fått til det. Skal vi se... Nytt forsøk. Der. Ja, faktisk så har vi fått dette til å virke. Fordi at vi ser... Dette er adresse 0. Men dette er adresse 1. Og her har vi lagret tallet 6, som var sluttresultatet. Og det er nøyaktig slik det virker. Hvis vi f.eks. lager en integersum... Som resultatet 6 skal legges i, eller integer S, som vi vel brukte... Så er det en kobling sånn at S ligger på en spesiell adresse. På en eller annen adresse i RAM. Her ser vi at S ligger i adresse 1. Så det vi gjorde akkurat nå, var å programmere maskin... Som lagret sluttresultatet i RAM på adresse 1. Og det gjøres hele tiden i vanlig kode. Kan man lagre ting på adresse 0 også? Ja. Hvis jeg ønsket å lagre noe i adresse 0,", "source": "lecture"}
{"lecture_id": "os4del8", "chunk_id": "os4del8_0007", "start": 535.92, "end": 645.28, "token_count": 294, "text": "Så det vi gjorde akkurat nå, var å programmere maskin... Som lagret sluttresultatet i RAM på adresse 1. Og det gjøres hele tiden i vanlig kode. Kan man lagre ting på adresse 0 også? Ja. Hvis jeg ønsket å lagre noe i adresse 0, så måtte jeg bare endret på den maskinkoden her nede på kode 8. Og da hadde det ikke vært så lett egentlig å... Da kunne jeg ikke bare brukt én institusjon, for det jeg måtte gjøre først, var å ta en move i-institusjon, legge tallet 0 i R1. Før denne institusjonen. Eller så kunne jeg beholdt institusjonen, for da ville jeg... Hvis jeg før dette la inn tallet 0 i R1 med move in... Og så, etterpå, utførte denne institusjonen. Så ville jeg oppnå akkurat det og lagre resultatet på adresse 0. Ja... Så... Så det betyr at på denne måten så kan man programmere... Programmere CPU-en. Og dette skjer da om og om igjen inni programmer. Og det vi skal se på sånn konkret nå, er hvordan vi...", "source": "lecture"}
{"lecture_id": "os4del8", "chunk_id": "os4del8_0008", "start": 616.5, "end": 721.7, "token_count": 288, "text": "Ja... Så... Så det betyr at på denne måten så kan man programmere... Programmere CPU-en. Og dette skjer da om og om igjen inni programmer. Og det vi skal se på sånn konkret nå, er hvordan vi... Hvordan dette helt tilsvarende skjer når vi kompilerer C-programmer og får ut maskinkode. Vi tar oss tid til et par spørsmål til. Det var en oppsummering her, så vi brukte bare verdien til R1, som altså var 1, som referanse til en adresse vi skulle lagre. Helt riktig. F.eks. om R1 hadde vært lik 2, så hadde vi lagret adresse 2 i RAM. Det er helt riktig, og dette er veldig viktig, så det må vi ha med videre. For hele tiden refererer vi til RAM. Så vi kan bare vise et eksempel. F.eks. hvis jeg kan sette R3 på begge. Da betyr det legg... Svaret som ligger i R3, i adressen som har samme nummer som R3. Så det vil da være... Hvis jeg lagrer den... Nå bør tallet 6 da lagres på adressenummer 6.", "source": "lecture"}
{"lecture_id": "os4del8", "chunk_id": "os4del8_0009", "start": 695.56, "end": 788.72, "token_count": 253, "text": "Da betyr det legg... Svaret som ligger i R3, i adressen som har samme nummer som R3. Så det vil da være... Hvis jeg lagrer den... Nå bør tallet 6 da lagres på adressenummer 6. Så hvis jeg kjører gjennom fra starten av nå... Altså klikker raskt igjennom. Det kan jeg følge med her. Så ser vi, der kommer... Det er først tre, så blir svaret seks. Og der. Nå skal vi da legge... Det den skal gjøre... Det første er å legge svaret 6 inn i adresse nummer 6. Og da kan vi gå inn i RAM, og så kan vi se. Har det det som har skjedd? Ja, da ser vi her nede. På adresse 6 så ligger nå resultatet som også er tallet 6. På den måten er det maskinkode. Aksepterer ram. Og ram er bare en kjempelang remse med adresser, som er adresser til én og én byte.", "source": "lecture"}
{"lecture_id": "os6del5", "chunk_id": "os6del5_0000", "start": 0.0, "end": 99.12, "token_count": 289, "text": "Aller først, branch prediction. Branch prediction er en slags konsekvens av det vi så på forrige gang. At vi bruker, for det første, pipelining. Pipelining er at man deler én institusjon. Da tenker vi på en sånn institusjon. Som ADD AX til svar... Altså legge til verdien i registeret AX til svar i RAM. Denne operasjonen... I maskinkode så er det én maskininstitusjon. Men denne deles opp i mange mikroinstitusjoner. Først hentes den din, så dekodes den... Så deles den opp i små deler og utføres, for det er flere ting som skulle gjøres. Man må hente inn verdien fra RAM inn i et temporært register. Så må man legge til. Og så må det resultatet legges ut igjen, akkurat som vi gjorde i simulerings-CPU-en. Vi må på et eller annet tidspunkt ta verdien i et register og legge ut i RAM når man gjør en sånn operasjon. Alt dette brytes da ned i... Mange små mikrooperasjoner. Som typisk for Intel kan det være 14 sånne operasjoner.", "source": "lecture"}
{"lecture_id": "os6del5", "chunk_id": "os6del5_0001", "start": 73.2, "end": 158.72, "token_count": 291, "text": "Og så må det resultatet legges ut igjen, akkurat som vi gjorde i simulerings-CPU-en. Vi må på et eller annet tidspunkt ta verdien i et register og legge ut i RAM når man gjør en sånn operasjon. Alt dette brytes da ned i... Mange små mikrooperasjoner. Som typisk for Intel kan det være 14 sånne operasjoner. Pipelining, da... Når vi starter på en institusjon som har 14 deler, så venter vi ikke med å få gjort alle de 14 delene ferdig. Vi begynner på neste del. Neste institusjon... Med en gang den første institusjonen er gjort, så begynner vi på... Den første instruksjonen for den instruksjonen som kommer etter i pipeline. Sånn at i praksis så kjøres ting delvis parallelt. Og i tillegg så har man superskalaarkitektur. Hvor det faktisk virkelig går parallelt. Og da kan det være flere samtidige institusjoner som går inn... Som kommer i en pipeline delt opp i 14 biter. Men så vil da hver av de små bitene... De kan kjøres helt samtidig.", "source": "lecture"}
{"lecture_id": "os6del5", "chunk_id": "os6del5_0002", "start": 139.2, "end": 228.36, "token_count": 299, "text": "Hvor det faktisk virkelig går parallelt. Og da kan det være flere samtidige institusjoner som går inn... Som kommer i en pipeline delt opp i 14 biter. Men så vil da hver av de små bitene... De kan kjøres helt samtidig. Altså institusjonen som er fem institusjoner etter den første, den kan kjøres samtidig. Og dette går veldig fint hvis institusjonene er uavhengige av hverandre. Altså hvis det ikke er noen direkte sammenheng. Men i noen tilfeller så er det en sammenheng, og det viktigste til... ... som du da har i Fawlucker og Violen... Hele tiden så har man branching. Typiskvis hvis du har en if-test, så er det en branch. Hvis svaret er true, så går det den ene veien. Hvis det er folk, så går det den andre veien. Og det vet man ikke før man kommer dit. Det blir da plutselig et problem med en sånn branching når systemet allerede er i gang med å... Utføre neste institusjon... Det største problemet er at man kunne løst det ved å... Hvis man kom til en bransje, så bare stoppet man helt. Pipelining og superskalære...", "source": "lecture"}
{"lecture_id": "os6del5", "chunk_id": "os6del5_0003", "start": 198.8, "end": 288.16, "token_count": 300, "text": "Og det vet man ikke før man kommer dit. Det blir da plutselig et problem med en sånn branching når systemet allerede er i gang med å... Utføre neste institusjon... Det største problemet er at man kunne løst det ved å... Hvis man kom til en bransje, så bare stoppet man helt. Pipelining og superskalære... Altså å kjøre mikroinstitusjoner i reell parallellitet, med parallellitet. Altså kjøre de helt samtidig. Man kunne skru det helt av. Men da ville ting gå... Mye saktere. Så det man prøver på da, er å gjette. Man gjetter hvilken bransje som skal kjøres, og så bare sier man sånn... Ja, tidligere så har det ofte... Har disse testene blitt true når programmet ble kjørt. Så vi gjetter at det blir true igjen. Og så hiver man alle institusjonene i den bransjen som om den testen... Hvis da testen ikke slår til, og man har gjettet feil, hva skjer da? Jo, det er ikke katastrofe, for da må man rett og slett bare glemme hva som skjedde, og hoppe tilbake.", "source": "lecture"}
{"lecture_id": "os6del5", "chunk_id": "os6del5_0004", "start": 263.0, "end": 372.44, "token_count": 290, "text": "Og så hiver man alle institusjonene i den bransjen som om den testen... Hvis da testen ikke slår til, og man har gjettet feil, hva skjer da? Jo, det er ikke katastrofe, for da må man rett og slett bare glemme hva som skjedde, og hoppe tilbake. Og så må man kjøre om igjen den andre bransjen. Det er klart, dette gir en masse ekstra logikk og overhead å få til dette her. Men igjen - alt er gjort for at ting skal gå raskere. Vi skal se på det i praksis, men vi kan ta med ett eksempel som gjorde at dette med pipelining og ikke minst parallellitet i mikroinstruksjoner, altså superskalaarkitektur... og moderne CPU-er etter 2000 har, det var Meltdown og Specter, som var to sikkerhetshull som ble funnet i 2018. Det var noe så spesielt som et hardware-sikkerhetshull. Og det rammet Intel og Arm og IBM-prosessorer av alt som var av prosessorer, ble rammet. At kode blir utført i parallell. Men det var virkelig et hack.", "source": "lecture"}
{"lecture_id": "os6del5", "chunk_id": "os6del5_0005", "start": 340.12, "end": 435.78, "token_count": 282, "text": "som var to sikkerhetshull som ble funnet i 2018. Det var noe så spesielt som et hardware-sikkerhetshull. Og det rammet Intel og Arm og IBM-prosessorer av alt som var av prosessorer, ble rammet. At kode blir utført i parallell. Men det var virkelig et hack. Men det utnyttet det at når man kommer til en bransje, så går man inn og kjører parallelt. Og man kan også gjøre tester. F.eks. er det hele tiden sånne tester. Har denne prosessen lov å lese data fra den andre prosessen? Dette systemet fungerer helt fint hvis systemet er sikker på at CPU utfører én og én institusjon. Men med parallellitet, med pipelining, og med at institusjoner faktisk utføres i parallell, så begynner man noen ganger å... Utføre en instruksjon som å sjekke om man har lov til å lese RAM, samtidig som en annen prosess legger noen av sine data i ram. Det dette sikkerhetsrullet utnyttet, var at man i en prosess da kunne, ved en feil,", "source": "lecture"}
{"lecture_id": "os6del5", "chunk_id": "os6del5_0006", "start": 414.6, "end": 487.98, "token_count": 257, "text": "faktisk utføres i parallell, så begynner man noen ganger å... Utføre en instruksjon som å sjekke om man har lov til å lese RAM, samtidig som en annen prosess legger noen av sine data i ram. Det dette sikkerhetsrullet utnyttet, var at man i en prosess da kunne, ved en feil, lese RAM for en annen prosess. Og det er virkelig en sikkerhetskatastrofe. F.eks. så kunne det brukes til at en prosess kunne lese passord som en annen prosess. Dette brukte de hardware-effektene sånn at for å rette opp i denne feilen, så måtte både CPU-ene endres for å sikre seg mot denne feilen, og operativsystemet. Dette er ett eksempel på hvor det er nyttig å vite litt om hva som foregår enda lenger ned. Så skjer det på operativsystemnivå, altså med kode. Men i dette tilfellet så skjedde det da altså med halvvei.", "source": "lecture"}
{"lecture_id": "linux7del19", "chunk_id": "linux7del19_0000", "start": 0.0, "end": 123.78, "token_count": 293, "text": "Men det vi kan gjøre først, er å se litt på en av oppgavene denne uken. Som går ut på å lage en kopi av en eksisterende konteiner. Hvis jeg nå bare stopper den konteineren, så... Så kan jeg ikke starte den opp igjen med det samme innholdet. Nå har jeg lagd... Jeg lister image her nå. Container image LS. Da ser vi at jeg har en Ubuntu. Men den Ubuntu der, det er en plain Ubuntu uten webserver. Så det jeg skal prøve nå, er å lage en kopi. Nå har jeg gjort endringer, så jeg vil lage en kopi av den tegneren. Det jeg kan gjøre da, er å... Komit er sånn generelt det man gjør når man skal commit-kode. Hvis man har lagd ferdig kode, så vil man sende til Egypt-hub eller andre steder. Men i dette tilfellet vil jeg nå commit-e og lage en kopi av min eksisterende ubuntu. Da tegner jeg id-en til ubuntu. Det er den her. Der den står og kjører. Kom hit. Nå vil jeg lage en kopi av den her. Så vil jeg kalle den f.eks. en Apache-Ubuntu.", "source": "lecture"}
{"lecture_id": "linux7del19", "chunk_id": "linux7del19_0001", "start": 94.28, "end": 197.32, "token_count": 285, "text": "Men i dette tilfellet vil jeg nå commit-e og lage en kopi av min eksisterende ubuntu. Da tegner jeg id-en til ubuntu. Det er den her. Der den står og kjører. Kom hit. Nå vil jeg lage en kopi av den her. Så vil jeg kalle den f.eks. en Apache-Ubuntu. Det er da en Ubuntu med en Apache-server. Dette tar litt tid, for den må da kopiere hele imaget. Der var den ferdig. Så når jeg lister imaget nå, gjør det at jeg har fått et nytt image, som heter Apache Ubunte. Og som er en god del større enn det standard-Ubunte-imaget. Fordi nå har det fått inn en hel webserver her oppe. Så kan jeg prøve å starte det imaget, og så kan jeg prøve å forte det. Da kan jeg gjøre omtrent det samme som jeg gjorde her med EngineX. For å se at det er noe annet, kan jeg ta et annet portnummer her. 7878. Innkommende rekvest til port 7878 på Linux-VM-en min nå. Det vil jeg sende til port 80, og så vil jeg kjøre det på...", "source": "lecture"}
{"lecture_id": "linux7del19", "chunk_id": "linux7del19_0002", "start": 168.9, "end": 306.98, "token_count": 285, "text": "Da kan jeg gjøre omtrent det samme som jeg gjorde her med EngineX. For å se at det er noe annet, kan jeg ta et annet portnummer her. 7878. Innkommende rekvest til port 7878 på Linux-VM-en min nå. Det vil jeg sende til port 80, og så vil jeg kjøre det på... Bakgrunn. Jeg vil sende det nå til Apartsjubentu. Sånn. Nå prøver jeg å starte en ny konteiner som inneholder den serveren jeg satte opp. Nå lister jeg kjørende kommandtegnere, så ser vi at jeg har... Men det er bare den der som jeg har forbeholdt 78-78. Da kan jeg prøve å koble meg til den med Execute. Da går jeg inn på den. Så kobler jeg meg til den nye kopien, den av Apache-Ubuntu. Det som er interessant der nå... Er det nå mulig å starte Apache-webserveren? Hvis jeg hadde vanlig Ubuntu-image, så ville jo ikke det gått. Her ser vi. Her fungerer det. Jeg har nå en Apache-server... Jeg har nå en Apache-server som står og kjører på fort 80.", "source": "lecture"}
{"lecture_id": "linux7del19", "chunk_id": "linux7del19_0003", "start": 272.28, "end": 403.8, "token_count": 295, "text": "Er det nå mulig å starte Apache-webserveren? Hvis jeg hadde vanlig Ubuntu-image, så ville jo ikke det gått. Her ser vi. Her fungerer det. Jeg har nå en Apache-server... Jeg har nå en Apache-server som står og kjører på fort 80. Hvis jeg nå gjentar kontroll P, kontroll Q og har lister, så ser vi... Her står den og kjører. Så skulle jeg nå kunne... Gå inn i et webvindu og prøve å koble meg til. Så kan jeg åpne vinduet for dere. Her ser vi den gamle siden med 7979. Hvis jeg nå tilholder den, så er det naturlig nok ikke noe der, for der kjører ikke den. Jeg prøver 7878. Da ser vi... Jo, her kommer Aparce-serveren ut. Det er da den serveren som kjører på konteineren som vi startet opp. Det ser ut som en default Aparce-server, så det er ikke så lett å se... Vi kan prøve å gå inn på... Vi kan gå inn, så kan vi prøve å bare endre litt på teksten på avanseserveren. Det er også en del av oppgaven denne uken å gjøre akkurat det.", "source": "lecture"}
{"lecture_id": "linux7del19", "chunk_id": "linux7del19_0004", "start": 368.22, "end": 507.6, "token_count": 295, "text": "Det ser ut som en default Aparce-server, så det er ikke så lett å se... Vi kan prøve å gå inn på... Vi kan gå inn, så kan vi prøve å bare endre litt på teksten på avanseserveren. Det er også en del av oppgaven denne uken å gjøre akkurat det. Først kan jeg ta apps install... Kanskje to her på Vemund, for det har jeg tydeligvis ikke gjort før. Appdate først. Først er å installere Apache-VM på Linux-VM. Apache2-webserver på Linux-VM. Når jeg går inn på porten på Linux-VM, så skal jeg få opp den Apache-serveren som står og kjører her. Før jeg gjør det, så skal jeg prøve nå å koble meg opp til containeren som står og kjører Apache. Den konteineren står nå på og kjører Apache til port 80. Men alt som sendes til 7878, vil sendes videre til den konteineren. Men det er jo ikke særlig nyttig å kjøre webserver hvis du ikke kan endre på innholdet. Det vi gjør i dag, er at vi går direkte inn på konteineren og endrer på innholdet der.", "source": "lecture"}
{"lecture_id": "linux7del19", "chunk_id": "linux7del19_0005", "start": 488.54, "end": 670.74, "token_count": 300, "text": "vil sendes videre til den konteineren. Men det er jo ikke særlig nyttig å kjøre webserver hvis du ikke kan endre på innholdet. Det vi gjør i dag, er at vi går direkte inn på konteineren og endrer på innholdet der. Det som er mer vanlig, og som vi skal gjøre neste uke, det er å gå... Ha et volum som er... Som ligger utenfor konteineren. Nå skal vi ta Dock Container PS. Da ser vi den konteineren som står og kjører. Det er da den der. Så kobler jeg meg inn til den konteineren. Og så går jeg til der hvor webseramen ligger. Den indeks-hotml-filen er den standardsiden man ser. Så kan jeg skrive f.eks. image fra OS70. Sånn. Nå skulle den WebServe-en servere. Jeg kan altså sjekke det lokalt ved å be om å bruke køen. En opplagt fordel med både container og VM-er, er at du kan installere hva du vil. Vi ser også at konteinere er veldig minimalistiske. De skal være så små som mulig. For å bruke minst mulig ressurser. Og så kan man tilpasse det med det man har.", "source": "lecture"}
{"lecture_id": "linux7del19", "chunk_id": "linux7del19_0006", "start": 599.48, "end": 764.1, "token_count": 295, "text": "Jeg kan altså sjekke det lokalt ved å be om å bruke køen. En opplagt fordel med både container og VM-er, er at du kan installere hva du vil. Vi ser også at konteinere er veldig minimalistiske. De skal være så små som mulig. For å bruke minst mulig ressurser. Og så kan man tilpasse det med det man har. Det tar litt tid. I mellomtiden skal jeg gå ut og sjekke webserveren, om den virker. Nå har vi satt på 78,78, så skal det fortsatt stå en webserver og kjøre. Nå skal den være endret til det vi... Skal vi se når den dukker opp hos dere. Da skal jeg refreshe. Sånn, og da ser vi dokker-image fra OS70. Det er den endringen som jeg gikk inn på dokker-konteineren og endret. Men da ser vi med det samme. Da får vi den default-pagen. Dette er nå en tjeneste fra webserveren på Linux. Med en gang jeg skriver 78, så default for en webserver er å koble seg til på port 80. Så hvis jeg eksplisitt skriver port 80 her, så kommer jeg til den samme siden.", "source": "lecture"}
{"lecture_id": "linux7del19", "chunk_id": "linux7del19_0007", "start": 738.9, "end": 849.34, "token_count": 293, "text": "Da får vi den default-pagen. Dette er nå en tjeneste fra webserveren på Linux. Med en gang jeg skriver 78, så default for en webserver er å koble seg til på port 80. Så hvis jeg eksplisitt skriver port 80 her, så kommer jeg til den samme siden. Men jeg kan generelt be om hvilken som helst port. Så hvis jeg nå... Det jeg gjør nå, egentlig, det er å be broseren om å koble seg til pepserveren på OS70 på port 7878. Når jeg gjør det, så er docky satt opp sånn at alt som sendes inn til port 7878, det videresender til docker-imaget til docky-containeren som står og kjører, på port 80. Og da ser vi. Dermed så får jeg opp den. Dermed får jeg opp webserveren som vi har laget på Dokkerinnsats. Skal vi bare helt til slutt se om... Ja, der var køllen ferdig. Sånn. På den måten så kan man teste... Teste at webserveren funker. Det er... i tesepipe så er det local host. Da får man kontakt med local host. Man kunne vel også gjort noe sånt?", "source": "lecture"}
{"lecture_id": "linux7del19", "chunk_id": "linux7del19_0008", "start": 807.08, "end": 924.9, "token_count": 242, "text": "Skal vi bare helt til slutt se om... Ja, der var køllen ferdig. Sånn. På den måten så kan man teste... Teste at webserveren funker. Det er... i tesepipe så er det local host. Da får man kontakt med local host. Man kunne vel også gjort noe sånt? Det fungerer også. Så på den måten så kan du enkelt teste om webserveren faktisk funker. Den med hostname, så er du sikrere. Dette er ikke linjevis. Det kan sjekke om webserveren virker. Hvis den virker, men du ikke kommer inn utenfra, da er det noe med hvordan du har startet... Hvordan du har startet... Skal jeg se... Jeg hadde vel... Nei, det var jo ikke her jeg gjorde det. Så er det Kontroll-P og Q, og så går jeg ut. Den kommandoen skulle jeg ha frem. Etter den kommandoen startet jeg ApacheBunt. Sånn at det blir portforwarding mellom 78 og 78.", "source": "lecture"}
{"lecture_id": "os9del6", "chunk_id": "os9del6_0000", "start": 0.0, "end": 98.68, "token_count": 293, "text": "Der har vi det nice vinduet, og de jobbene står fortsatt og kjører. Jeg stilte noen spørsmål før pause, og Christian hadde et godt svar på begge deler. Nemlig... Så lenge det ikke er noen andre jobber som brukes i EPU, Nice-verdien ha noe å si. For da er det ingen andre som trenger CPU. Og når det ikke er noen andre der, så trenger man ikke å være nice med de heller. Så dermed så kjører de med 100 % hele tiden. Men jeg spurte da også neste spørsmål hvordan kan man prøve å kjøre for prosesser? Nei, hvordan kan man vise effekten? Da foreslår Kristian å kjøre flere prosesser på samme CPU. Og bruke TASET med ulike nice-verdier. Det er også et veldig godt forslag, for da vil du kunne se den effekten. En annen måte å se den samme effekten på, er jo å fylle hele serveren med regnejobber. Da vil du få den samme effekten, men da begynner hele serveren... Jeg kjører dette på laptopen min, og her kjører jeg også OBS, Studio og Zoom.", "source": "lecture"}
{"lecture_id": "os9del6", "chunk_id": "os9del6_0001", "start": 73.76, "end": 185.44, "token_count": 293, "text": "En annen måte å se den samme effekten på, er jo å fylle hele serveren med regnejobber. Da vil du få den samme effekten, men da begynner hele serveren... Jeg kjører dette på laptopen min, og her kjører jeg også OBS, Studio og Zoom. Jeg tror jeg foretrekker det forslaget til Christian, og teste ut det. Hovedpoenget er at hvis man ser på Last Used CPU... Der... Så ser vi at... Ja, definitivt noen ganger så flytter seg litt. Så ser vi OBS og Zoom som også bruker mye. De kjører faktisk noen ganger på samme CPU. Men de kjører typisk på andre CPU-er enn regnejobbene. Og vil ikke regne jobbene. Trenger å være nice. Men det kan likevel være fint å ha. Hvis du f.eks. skal kjøre masse videoer, sånn som jeg har gjort noen ganger... Da kan det være nyttig å ha på nice, sånn at ikke systemet fryser når jeg kjører 18 forskjellige videojobber som står og kverner og render. Det er veldig tungt. Når jeg har sett på Nice, så...", "source": "lecture"}
{"lecture_id": "os9del6", "chunk_id": "os9del6_0002", "start": 161.92, "end": 269.92, "token_count": 291, "text": "masse videoer, sånn som jeg har gjort noen ganger... Da kan det være nyttig å ha på nice, sånn at ikke systemet fryser når jeg kjører 18 forskjellige videojobber som står og kverner og render. Det er veldig tungt. Når jeg har sett på Nice, så... Vil de være nice med andre jobber, sånn at systemet ikke blir så tungt. Men først og fremst så ser vi på dette for å se hvordan prioritering fungerer. Så da skal vi prøve å teste ut Kristians skriftforslag. Med å bruke task-sett. Så... Nå står jo de jobbene der og hopper frem og tilbake, så jeg kan ta... kanskje å drepe regnejobbene først. Og så kan jeg i stedet si TaskZ minus C... La oss si vi setter dem på prosessor 3. Så kan jeg ta Nice minus 19. Og... regnejobben... regn. Sånn. Og da... skal vi se om vi ser... Jeg starter kanskje. Skulle gjerne hatt med 'Last Use Super'. Vi har hatt med en større en. Der. Da ser vi den ene jobben.", "source": "lecture"}
{"lecture_id": "os9del6", "chunk_id": "os9del6_0003", "start": 240.0, "end": 358.68, "token_count": 300, "text": "Og... regnejobben... regn. Sånn. Og da... skal vi se om vi ser... Jeg starter kanskje. Skulle gjerne hatt med 'Last Use Super'. Vi har hatt med en større en. Der. Da ser vi den ene jobben. Som jeg ba om, så står den på tre. Men hva om jeg nå... setter én jobb til der? Og så gir jeg den en bitte litt nice én. Får jeg da noen effekt? Ja, jeg får en effekt, men den er så stor at jeg nesten ikke så regnejobben. Så kommer da den andre regnejobben. Den som har Nice 19, den kjører nå nesten ikke noe CPU. Den har 1,7 %, mens denne som er ganske... Bare lite grann nice. Nice er det én. Den får det aller meste. Hvis jeg nå kjører en default uten å bruke Nice i det hele tatt, Da ser vi... Da kommer soomobs høyere. Men her har vi nå regnejobbene. Og den jobben som har nice 0, sånn standard, den får 55 %. Nice 1. Vi ser den er litt nice med den andre regnejobben. Vi gir litt mindre. Mens den som er 19, den er super nice.", "source": "lecture"}
{"lecture_id": "os9del6", "chunk_id": "os9del6_0004", "start": 339.12, "end": 470.98, "token_count": 290, "text": "Men her har vi nå regnejobbene. Og den jobben som har nice 0, sånn standard, den får 55 %. Nice 1. Vi ser den er litt nice med den andre regnejobben. Vi gir litt mindre. Mens den som er 19, den er super nice. Så på denne måten fungerer Nice. Men vi hadde et annet problem før pause også. Jeg prøvde å sette Nice til 18 på en som hadde Nice-verdi 19. La oss si jeg er lei av at denne her... Nei, hva var den...? Denne her har så lav Nice-verdi, så jeg skal prøve en reneise. La oss si til pluss 5. Men da får jeg permission her, og som en påpekte i chatten... Kanskje det ikke er lov. Og det ser vi også at... I man-sidene så står det at... Skal vi se om jeg finner det... Slike endringer er irreversible... Setter da nice-verdien til 5. Egentlig litt rart. Skulle tro man kunne sette den til null, men sånn er det. Med sudo kan jeg også sette nice-verdien til noe negativt. Så jeg kan prøve med minus 5, f.eks.", "source": "lecture"}
{"lecture_id": "os9del6", "chunk_id": "os9del6_0005", "start": 450.0, "end": 554.4, "token_count": 285, "text": "Setter da nice-verdien til 5. Egentlig litt rart. Skulle tro man kunne sette den til null, men sånn er det. Med sudo kan jeg også sette nice-verdien til noe negativt. Så jeg kan prøve med minus 5, f.eks. Da fikk den nice-verdien her... Den der har nå minus 5. Men det ser faktisk ikke ut som den... ... likevel får noe mer slippehud. Jo... I forhold til regnejobbene så ser vi nå for den som har minus 5 her... Den får 63 %, mens de andre regnejobbene har 2016. Dette gir da en... Som er enda høyere enn 0, som er default. Vi snakket om 140 prioritetsklasser. Det er disse 40, fra nice-verdi minus 20, som er det høyeste, og opp til 19, det er de 40 prioritetsklassene som er for vanlige gyserprosesser, vanlige brukerprosesser. I tillegg har man 100 prioritetsplasser som er for realtime-prioritering. Det er typisk kjerneprosesser som skal gå veldig fort. Her står det RT og ikke noen nice-verdi.", "source": "lecture"}
{"lecture_id": "os9del6", "chunk_id": "os9del6_0006", "start": 528.12, "end": 601.2, "token_count": 240, "text": "og opp til 19, det er de 40 prioritetsklassene som er for vanlige gyserprosesser, vanlige brukerprosesser. I tillegg har man 100 prioritetsplasser som er for realtime-prioritering. Det er typisk kjerneprosesser som skal gå veldig fort. Her står det RT og ikke noen nice-verdi. Det betyr at den hører til de 100 prosessene som er en annen. Her ser dere migration og watchdog... Det er typisk systemprosesser. De har en annen prioritetsplass. Realtime er typisk... Generelt er det en prosess som må kunne utføres innen en viss frist. Du kan ha en real-time-prosess som i løpet av et hundre øyesekund må bli ferdig. Det er en annen prioritetsklasse, så de går over disse jusprosessene. Men brukerprosessene har da 40 prioritetsklasser, og med nice or not kan man flytte seg opp og ned i de prioritetsklassene. ...", "source": "lecture"}
{"lecture_id": "linux7del12", "chunk_id": "linux7del12_0000", "start": 0.0, "end": 114.06, "token_count": 289, "text": "Det kom et veldig godt spørsmål i chatten i pausen, om hvordan Dokker er nyttig. Og hvordan man bruker det i praksis. Og det er selvsagt ikke absolutt alle som bruker Dokker i sine løsninger eller containere. Vi har hatt en enorm vekst i bruken, spesielt i litt mer moderne tider. F.eks. sånn som finn.no. Jeg hadde en student som begynte der for et par år siden. Da var han overrasket over at de i veldig stor grad brukte dokker. Det mange bruker er kybernetes, som er et system for å orkestrere dokkerbruk. Sette opp store systemer med databaser, webservere, servere som regner statistikk osv. Sette opp det sammen sånn at det kjører og fungerer. Det er kubernetis. Men hver av de elementene vil bestå av konteinere som gjør sine oppgaver. Det man typisk gjør, er å skrive kode og så teste den ut i en dockercontainer. Den containeren vil, når man tester, være akkurat den samme som du kjører i produksjon. Det er nettopp det med å teste kode som man lager,", "source": "lecture"}
{"lecture_id": "linux7del12", "chunk_id": "linux7del12_0001", "start": 80.34, "end": 197.4, "token_count": 298, "text": "Men hver av de elementene vil bestå av konteinere som gjør sine oppgaver. Det man typisk gjør, er å skrive kode og så teste den ut i en dockercontainer. Den containeren vil, når man tester, være akkurat den samme som du kjører i produksjon. Det er nettopp det med å teste kode som man lager, helt og nøyaktig i samme miljø. Det å forenkle og sette opp det miljøet. At de kan kopieres og så kjøres i produksjon. Det er det som er kanskje det aller viktigste med dokker og containere. Vi kommer ikke så langt inn på det i denne uke, men jeg tenkte neste uke så... Så kommer vi mer inn på det. Altså definere hvilke biblioteker og hva... Alt som man trenger for å kjøre en viss applikasjon. Litt som JVM. Jo, det er... Det er helt riktig. Den har samme funksjon som JVM, som er Java virtuell maskin. JVM gjør det samme som virtuelle maskiner, som også Docker gjør. Den abstraherer bort det underliggende hardwaren. Samme måte som en classfile kan kjøres på forskjellige JVM-er.", "source": "lecture"}
{"lecture_id": "linux7del12", "chunk_id": "linux7del12_0002", "start": 167.88, "end": 266.42, "token_count": 272, "text": "Den har samme funksjon som JVM, som er Java virtuell maskin. JVM gjør det samme som virtuelle maskiner, som også Docker gjør. Den abstraherer bort det underliggende hardwaren. Samme måte som en classfile kan kjøres på forskjellige JVM-er. Du kan ha en JVM på Windows og du kan ha en JVM på Linux. Begge kan kjøre den samme classfile. De kan kjøre på forskjellig hardware og forskjellige operativstemmer. Likevel får du akkurat det samme miljøet for din applikasjon som du har utviklet. Hvis man skal utvikle en applikasjon og teste den for ekstremt mange forskjellige miljøer, så blir det veldig vanskelig. Det forenkler lokket med at du kan utvikle i forskjellige containere, men kanskje enda bedre at man kan være en som dette er den containeren vi bruker. Alle utviklere og i all drift og all testing så brukes nøyaktig dette miljøet. Det miljøet er da veldig lett å spre til alle som er innholdet.", "source": "lecture"}
{"lecture_id": "linux10del1", "chunk_id": "linux10del1_0000", "start": 0.0, "end": 103.14, "token_count": 294, "text": "Virtualisering. Når vi snakker om virtualisering på server- eller maskinnivå, så ser vi for oss virtualisering av en hel server eller en desktop. Det som virtualiseres, er all hardwaren til denne serveren. I denne figuren ser vi det vanlige bildet som vi har hatt tidligere i operativsystemer. Vi har hardware nederst, med SVPU, RAM, IO osv. Bildet vi startet med i vår, var at oppå her hadde vi et operativsystem som styrte alt. Men når vi snakker om virtualisering, så er det da en hypervisor som kjører oppå her. Og en hypervisor kan være en... En helt dedikert hypervisor, som i praksis vil inneholde et operativsystem. Eller så kan det være et operativsystem som har en del kjernemoduler som hjelper til med virtualiseringen. Uansett så vil det da være et lag mellom hardware og operativsystemer og applikasjoner som kjører på toppen. Så vi ser at denne hypervisoren her, den tilbyr tre grensesnitt. Med CPU, RAM og IO til operativsystemer. Dette er et bilde på at vi kjører tre virtuelle maskiner.", "source": "lecture"}
{"lecture_id": "linux10del1", "chunk_id": "linux10del1_0001", "start": 82.66, "end": 179.72, "token_count": 297, "text": "og applikasjoner som kjører på toppen. Så vi ser at denne hypervisoren her, den tilbyr tre grensesnitt. Med CPU, RAM og IO til operativsystemer. Dette er et bilde på at vi kjører tre virtuelle maskiner. De virtuelle maskinene her... For operativsystemet her ser det ut som det kjører på fysisk kalver. Det ser på en måte ut som operativsystemet her... Vi kan ikke se forskjell på om det kjører på hypervisor, et virtuelt grensenett, eller om det kjører direkte på rammen. Det er ikke helt sant. Det vil være mulig å finne ut, men i hvert fall sånn generelt med hypervisor av type 2, vi skal se på de typene senere, så er de lagd sånn at OS kan kjøre Helt uten endringer, rett på hypervisoren. Det betyr at da kan man ta en helt vanlig Ubuntu 1804 og boote opp på hypervisoren, og den kjører akkurat som om man hadde bootet den opp på hardware direkte. Det viktige hypervisorene gjør, er å simulere hardware, som gir nøyaktig samme grensenytt som hardware gjør.", "source": "lecture"}
{"lecture_id": "linux10del1", "chunk_id": "linux10del1_0002", "start": 153.6, "end": 265.68, "token_count": 277, "text": "Det betyr at da kan man ta en helt vanlig Ubuntu 1804 og boote opp på hypervisoren, og den kjører akkurat som om man hadde bootet den opp på hardware direkte. Det viktige hypervisorene gjør, er å simulere hardware, som gir nøyaktig samme grensenytt som hardware gjør. Ja, og som jeg sa, operativsystemene som kjører på en virtuell maskin, de tror de kjører på ekte hardware. Dette er ganske viktig sikkerhetsmessig også. Det gjør at denne type virtualisering er en sikker måte å fordele applikasjoner på VM-er. Så det betyr at denne VM-en her, den er veldig god. Det er litt annerledes i dere, for... Vi har sett på dokker i tidligere uker, og da kjøres prosessene på samme operativsystem. Det ligner på dette her, men da kan vi ha to forskjellige OS i hver sin dokkerinstans. Men de kjører ikke på noen Hypervisor, de kjører inne i samme operativsystem. Og der er skillelinjene mindre.", "source": "lecture"}
{"lecture_id": "linux2del9", "chunk_id": "linux2del9_0000", "start": 0.0, "end": 93.0, "token_count": 283, "text": "Da skal vi se på i litt mer detalj all informasjonen man får ut når man bruker kommandoen ls-l. Spesielt skal vi se på filrettigheter. Så hvis jeg taster ls-l, så ser vi at det kommer ut en masse informasjon her. Og den første informasjonen er det første tegnet. Hvis det er en fil, som filen som heter cmod her, en tom fil, så står det en strek. så står det en mappe. Og hvis det er en L, så er det en link. Deretter så kommer informasjon om rettigheter. Og da er det viktig å vite at dette er tre bolker. Tre grupper av tre tegn som gir rettigheter. De første tre tegnene, det gir rettighetene... Og eieren av filen, det er det brukernavnet som står her etter rettighetene. Hvis i dette tilfellet så er det brukeren Haugerud, som er meg, som eier filen. Og jeg har da disse rettighetene. Og R står for read, det er lov å lese. W står for write, skrive. Er en rettighet du trenger for å kunne kjøre et program.", "source": "lecture"}
{"lecture_id": "linux2del9", "chunk_id": "linux2del9_0001", "start": 68.68, "end": 157.28, "token_count": 285, "text": "Hvis i dette tilfellet så er det brukeren Haugerud, som er meg, som eier filen. Og jeg har da disse rettighetene. Og R står for read, det er lov å lese. W står for write, skrive. Er en rettighet du trenger for å kunne kjøre et program. Det har vi sett tidligere. Når vi skal lage skript, så må vi ha på denne X-en. Så de tre første tegnene, eller tegn fra to til to, tre og fire, de sier noe om rettighetene som jeg som bruker har. Og så kommer det tre tegn til, og det er en ny bolka av rettigheter. Read, write, execute. I dette tilfellet så er det da read. Og det disse rettighetene gjelder, det er drift. Og i dette tilfellet er det den gruppen som eier denne filen, eller som har rettigheter til denne filen. Og dette betyr at... Ja, f.eks. den her, den første filen, betyr at jeg som eier kan lese og skrive, men ikke 2000. Denne filen. Mens de som er med i gruppen Drift...", "source": "lecture"}
{"lecture_id": "linux2del9", "chunk_id": "linux2del9_0002", "start": 135.48, "end": 222.18, "token_count": 285, "text": "eller som har rettigheter til denne filen. Og dette betyr at... Ja, f.eks. den her, den første filen, betyr at jeg som eier kan lese og skrive, men ikke 2000. Denne filen. Mens de som er med i gruppen Drift... En gruppe er definert ved et sett av brukere som er med i gruppen. De som er med i gruppen Drift, de kan lese filen, men de kan ikke skrive til den og ikke kjøre den. Og så kommer de neste tre tegnene. De siste tre tegnene er rettigheter til alle andre. De som ikke er eier og ikke er med i drift. Rettigheten til alle andre brukere på systemet. Så kommer et tall som er antall hardlinks. Som har med hvor mange i filsystemet, hvor mange linker som går til det. Så hvis du har mapper, så kan du ha mange sånne linker. Det brukes ikke så mye. Så kommer brukernavnet eller eieren av dette gruppe. Neste tall er størrelsen. 4096 er en sånn standard størrelse for mappen. Men hvis jeg putter noen tegn inn i den filen, se og måt...", "source": "lecture"}
{"lecture_id": "linux2del9", "chunk_id": "linux2del9_0003", "start": 198.76, "end": 285.44, "token_count": 291, "text": "Så hvis du har mapper, så kan du ha mange sånne linker. Det brukes ikke så mye. Så kommer brukernavnet eller eieren av dette gruppe. Neste tall er størrelsen. 4096 er en sånn standard størrelse for mappen. Men hvis jeg putter noen tegn inn i den filen, se og måt... Kan gjøre sånn. Ekko, hei. Bare skriver ut hei, og så sender jeg det til se og måt. Hvis jeg nå tar LS-min selv, så ser vi at der står det fire. Og det er fordi det er fire tegn. Så dette er da størrelsen på filen. Og så kommer datoen hvor denne er... Dette er tidspunktet for sist den ble endret. Så når jeg endret den her, så fikk den et annet tidspunkt enn det den hadde der. Og helt og slett så kommer navnet. Så det vi skal se på nå, er hvordan vi... Vi skal se i detalj på rettighetene og hvordan vi endrer rettigheter. En vanlig måte å endre rettigheter på er å bruke tallkoder for å endre rettighetene. Det kan jeg vise ved å endre rettigheter.", "source": "lecture"}
{"lecture_id": "linux2del9", "chunk_id": "linux2del9_0004", "start": 257.8, "end": 352.04, "token_count": 296, "text": "Så det vi skal se på nå, er hvordan vi... Vi skal se i detalj på rettighetene og hvordan vi endrer rettigheter. En vanlig måte å endre rettigheter på er å bruke tallkoder for å endre rettighetene. Det kan jeg vise ved å endre rettigheter. Som vi har sett sider av tida at de trenger CMOD, change modes, for å endre rettigheter. Da kan jeg spesifisere tre tall. De tre tallene vil da være... La oss si jeg bruker 754. De vil være da rettighetene for... Først for brukeren, så for gruppen. Fem. Og så for alle andre. Og så... Ja, nå var det kanskje litt forvirrende at den... Jeg kan gjøre det på DIR2. Sånn. Nå endrer jeg da på mappen DIR2. Hvis jeg nå gjør LS-L, så ser vi at jeg har fått en liten endring her. Den der var fortsatt den samme. Hadde den koden... Denne ble også den samme, men den siste ble litt endret. Så når jeg gjør det på denne måten, så setter jeg koden. Så f.eks. hvis jeg setter 111 som kode,", "source": "lecture"}
{"lecture_id": "linux2del9", "chunk_id": "linux2del9_0005", "start": 328.06, "end": 419.7, "token_count": 288, "text": "Den der var fortsatt den samme. Hadde den koden... Denne ble også den samme, men den siste ble litt endret. Så når jeg gjør det på denne måten, så setter jeg koden. Så f.eks. hvis jeg setter 111 som kode, og så gjør Ellis min selv, så ser vi at der er bare X satt for alle. Og systemet dette gjøres på, er sånn at... Hvis vi konsentrerer oss om de tre siste... Så hvis det står en X der, så tilsvarer dette det binære tallet 1. Hvis jeg nå i stedet endrer modus til 222 på alt sammen... Og så ser... Så ser vi at det er dobbeltvedsatt. Og hvis vi ser på dette binært, så ser vi... Så tilsvarer dette her 010, og tallet 2. Og hva blir det da hvis jeg setter 3? Jo, da bør det være dobbelt ved x. For da... 3 tilsvarer 011. Så hvis jeg setter alt til 3, så ser vi at rettighetene blir dobbelt ved x. Og da er det klart at hvis jeg setter det til 4, så...", "source": "lecture"}
{"lecture_id": "linux2del9", "chunk_id": "linux2del9_0006", "start": 394.84, "end": 495.12, "token_count": 298, "text": "Og hva blir det da hvis jeg setter 3? Jo, da bør det være dobbelt ved x. For da... 3 tilsvarer 011. Så hvis jeg setter alt til 3, så ser vi at rettighetene blir dobbelt ved x. Og da er det klart at hvis jeg setter det til 4, så... Da bør rettigheten bli R strekk strekk. Det tilsvarer da tallet fire. Og så kan jeg fortsette sånn. Hvis jeg først er i gang, så kan jeg ta fem, fem, fem også. Og da ser vi... Da er det en firer, ingen toere og en ener. Så dette blir fem. R strek x. En kode som seks er også vanlig å bruke, for det gir da rw. Det er de to satt. Fire og to er seks. Og syv vil da være å sette alle rettigheter. For det vil da være syv tilsvarer én, én, én i rettigheter. Så på den måten så kan man sette hva man måtte ønske. La oss si jeg ønsker syv for... Eller syv for meg selv, fire for gruppen og ingenting for alle andre. Da ser vi at jeg har alle rettigheter.", "source": "lecture"}
{"lecture_id": "linux2del9", "chunk_id": "linux2del9_0007", "start": 465.68, "end": 560.84, "token_count": 288, "text": "For det vil da være syv tilsvarer én, én, én i rettigheter. Så på den måten så kan man sette hva man måtte ønske. La oss si jeg ønsker syv for... Eller syv for meg selv, fire for gruppen og ingenting for alle andre. Da ser vi at jeg har alle rettigheter. Mens de som er med i gruppen drift, de kan bare lese. Og alle andre har ingen rettigheter til denne filmen. Så dette er generelt sånn... Jeg anbefaler å sette rettigheter, for da setter du absolutt alle rettigheter. Du definerer med én kommando, ett tall, nøyaktig hvilke rettigheter filen eller mappen har. Så vi kan se litt på effekten av hvis jeg setter... Hvis jeg ikke gir eksekverbare rettigheter til en mappe... La oss si jeg setter... 4.00 får jeg mappen Deal 2. Sånn som det. Da kan jeg lese denne mappen, men hvis jeg prøver å gå dit, så får jeg permission denied fordi jeg må ha en X hvis jeg skal gå ned til... Hvis jeg skal få tilgang til mappen.", "source": "lecture"}
{"lecture_id": "linux2del9", "chunk_id": "linux2del9_0008", "start": 530.78, "end": 626.7, "token_count": 274, "text": "Hvis jeg ikke gir eksekverbare rettigheter til en mappe... La oss si jeg setter... 4.00 får jeg mappen Deal 2. Sånn som det. Da kan jeg lese denne mappen, men hvis jeg prøver å gå dit, så får jeg permission denied fordi jeg må ha en X hvis jeg skal gå ned til... Hvis jeg skal få tilgang til mappen. Jeg får ikke tilgang til å lese det som er inni der. Derimot, hvis jeg endrer... Så kjører vi da til... Skal vi se... XD er den siste, så 1. Så jeg setter 1.00 for mappen. Og så prøver du å gå dit. Så ser vi at jeg kommer inn. Men jeg får permission tonight. Og det er for å lese, for å lese. For jeg har ikke leserettigheter. Du ser jeg bare har X. Så det minste jeg trenger, er å ha X og R. Og det vil da være fire pluss én. Det blir da fem. Hvis jeg setter 5.00 på de to, så kan jeg gå til de to, og jeg kan se på det som er inne.", "source": "lecture"}
{"lecture_id": "os8del10", "chunk_id": "os8del10_0000", "start": 0.0, "end": 113.44, "token_count": 299, "text": "Hva da når et brukerprogram skal gjøre noe som... Som skal gjøre instruksjoner som ikke kan utføres fra Jus og Maud? Hvordan kan da brukerprogrammet få til det? Og det kan f.eks. være sånn som å lese noe fra disk. Sånn generelt så har jo operativsystemet full kontroll på disken. Men hvordan kan da et brukerprogram lese noe fra disken når den må utføre operasjoner som bare kan gjøres i kernel mode? Jo, der da systemcall kommer inn. Og det er rett og slett brukerkode som ber kjernen om hjelp ved hjelp av systemcall. Et systemkall er egentlig bare et API mot operativsystemkjernen. Det er et sett med operasjoner som et vanlig brukerprogram fra YSMOD kan be operativsystemkjernen om å gjøre. På samme måte som du har et API, et Application Programming Interface, mot moduler og programmer av alle mulige typer. Da er det liksom alle typer. Altså de operasjonene som det er mulig å få utført med dette programmet eller denne metoden. Men vi har et dilemma her hvis vi skal gjøre noe som krever kernal mode. Det kunne jo være sånn at man...", "source": "lecture"}
{"lecture_id": "os8del10", "chunk_id": "os8del10_0001", "start": 83.32, "end": 167.44, "token_count": 279, "text": "mot moduler og programmer av alle mulige typer. Da er det liksom alle typer. Altså de operasjonene som det er mulig å få utført med dette programmet eller denne metoden. Men vi har et dilemma her hvis vi skal gjøre noe som krever kernal mode. Det kunne jo være sånn at man... At brukerprogrammet kunne sette modusbytt til kernal mode, og så... Og så utføre det man trengte, og så skulle det switches tilbake. Men da får du igjen problemet. Hvis du kan gjøre switch til curl-mode, så kan bruksprosessen ta over og stoppe systemet. Så igjen må vi ha hjelp fra Harvey, og da er det en spesiell intensjon som heter trap. Og trap, det som er det fine med den, er at den switcher til curl-mode og hopper til kode for et systemkall i én og samme operasjon. Og det betyr at fra juicemode så kan du ikke da først hoppe til kernel mode, og så love å si... Ja, etterpå... Jeg lover. Jeg skal gjøre systemcall etterpå. Men dette må gjøres i én og samme operasjon.", "source": "lecture"}
{"lecture_id": "os8del10", "chunk_id": "os8del10_0002", "start": 145.44, "end": 237.08, "token_count": 295, "text": "og hopper til kode for et systemkall i én og samme operasjon. Og det betyr at fra juicemode så kan du ikke da først hoppe til kernel mode, og så love å si... Ja, etterpå... Jeg lover. Jeg skal gjøre systemcall etterpå. Men dette må gjøres i én og samme operasjon. Og for å få til noe i én og samme operasjon, så må man ha én instruksjon som gjør det. Så igjen så får man hjelp fra Hardware for å få til systemcall. Her er en oversikt over hvordan et systemkall foregår. Og da ser vi på venstre side her, så er vi i brukerminne. Og på høyre så har vi privilegert-minne. Og her er det vanlig brukerkode som kjører Jusemodes. Institusjon 1, 2, 3 osv. Og så... Skal gjøres et systemcall. Og det er systemcall nummer tre i API-et. Og sånn ser det ut i Lynix-API-et. Så er det systemcall. Den er nummerert da det var her. Og det finnes mange hundre systemcall. Men det er noen få som gjøres veldig ofte.", "source": "lecture"}
{"lecture_id": "os8del10", "chunk_id": "os8del10_0003", "start": 215.52, "end": 303.48, "token_count": 297, "text": "Og det er systemcall nummer tre i API-et. Og sånn ser det ut i Lynix-API-et. Så er det systemcall. Den er nummerert da det var her. Og det finnes mange hundre systemcall. Men det er noen få som gjøres veldig ofte. Og tredje systemkall, Sister Read, det er akkurat det jeg også leser fra disk. Og det kan man ikke gjøre i Use and Mode. Og det som skjer da, er at her kommer et system kalt Trap 3. Og da... En viktig del av systemkallet er den institusjonen Trap. For den switcher da til... Den switcher modusbit til Curl-mode. Samtidig som den hopper inn i en branching-tabell her og hopper til første kodelinje i det systemkallet. Så da, i én institusjon, så switches modus blitt. Og første institusjon for dette systemkallet legges inn i... Inn i institusjonsregisteret. Det er den neste institusjonen som skal gjøres. Det må vi hele tiden tenke på. Vi har i utgangspunktet bare én CPU som vi ser på, og det er bare én av gangen som kan gjøre instruksjoner.", "source": "lecture"}
{"lecture_id": "os8del10", "chunk_id": "os8del10_0004", "start": 287.52, "end": 386.08, "token_count": 295, "text": "Inn i institusjonsregisteret. Det er den neste institusjonen som skal gjøres. Det må vi hele tiden tenke på. Vi har i utgangspunktet bare én CPU som vi ser på, og det er bare én av gangen som kan gjøre instruksjoner. Så dermed må man ha en sånn hardware-hjelp fra trap for å kunne både hoppe inn, switche modusputt, switche modusputt og hoppe inn i neste instruksjon. Og på denne måten så får man full kontroll. Wimebranching-tabell, det er rett og slett bare en tabell Her ligger da adressen til Dar-i-Ram, som første institusjon i dette systemkallet ligger. Ja, dette er en illustrasjon fra Tanbaum på systemkall. Litt mer... Litt flere detaljer, men ideen er den samme. Vi har vanlige institusjoner her. Én, to, tre. Og så kaller man read. Og så må det gjøres en del under huden med å få riktige verdier inn i forskjellige registre osv. Men så er det da den trap to cornal. Da hopper man inn i kjernekodet, utfører systemkallet,", "source": "lecture"}
{"lecture_id": "os8del10", "chunk_id": "os8del10_0005", "start": 363.84, "end": 457.96, "token_count": 286, "text": "Vi har vanlige institusjoner her. Én, to, tre. Og så kaller man read. Og så må det gjøres en del under huden med å få riktige verdier inn i forskjellige registre osv. Men så er det da den trap to cornal. Da hopper man inn i kjernekodet, utfører systemkallet, Men det er masse som må holdes orden på her. At man må hoppe tilbake til riktig sted i use mode osv. Så det er en ganske kompleks operasjon. Men det viktige prinsippet, det er trap. At man da både switcher modusbytt og hopper til systemkalkon. I én og sammen institusjon. Her er noen eksempler på systemcall. Vi så et av de tidligere... var fork. Og det er typisk noe som er systemcall. Altså at man... Fork brukes i Linux til å sette i gang en ny prosess. Da er det klart... Det kan ikke et vanlig brukerprogram gjøre. Der må operativsystemet inn og styre. Vi skal bruke det litt senere når vi skal forke og snakke med child. Men dette er igjen sånn prosessmanagement.", "source": "lecture"}
{"lecture_id": "os8del10", "chunk_id": "os8del10_0006", "start": 429.84, "end": 531.6, "token_count": 289, "text": "Altså at man... Fork brukes i Linux til å sette i gang en ny prosess. Da er det klart... Det kan ikke et vanlig brukerprogram gjøre. Der må operativsystemet inn og styre. Vi skal bruke det litt senere når vi skal forke og snakke med child. Men dette er igjen sånn prosessmanagement. Så har vi sånn som filemanagement, som vi har sett på, med open, close, read, write, skrive til og fra filer. Disken og filsystemet, det er det operativstemmet som kontrollerer. Her må vi bruke systemcall for å oppnå det. Igjen så kunne vi hatt vanlige brukerprosesser som styrte dette fra use and bot, men da kunne man risikere å krasje hele disken og skrive over for andre brukere osv. Så er det sånn som directory and system management med MKDIR. Link... mount... Vi ser sånn som MKD-er. Det er en del av de Shell-kommandoene som faktisk heter det samme som systemcall. Og i C så er alle disse systemcallene implementert. Så dermed så kan man skrive C-programmer som direkte utfører systemcall mot Linux-kjernen.", "source": "lecture"}
{"lecture_id": "os8del10", "chunk_id": "os8del10_0007", "start": 503.8, "end": 615.28, "token_count": 296, "text": "Link... mount... Vi ser sånn som MKD-er. Det er en del av de Shell-kommandoene som faktisk heter det samme som systemcall. Og i C så er alle disse systemcallene implementert. Så dermed så kan man skrive C-programmer som direkte utfører systemcall mot Linux-kjernen. En del sånn diverse, sånn som Kill, for eksempel, som opplagt trengs et systemkall for å gjøre. Det kan heller ikke en brukerprosess gjøre mot f.eks. andre brukere. Ja, her er noen vindussystemkall. Jeg har satt opp en masse systemkall Dette er bare for å illustrere at alle moderne operativsystemer har en tilsvarende mekanisme med systemcall. Men ofte er ting ganske forskjellig, sånn som Windows 32. Har ikke fork i utgangspunktet. De har rett og slett en create process. Det er da et systemcall som lager en ny prosess. Akkurat som Linux har Read, så har Windows-operativstemme ReadFile for å lese data fra en fil. Men i prinsippet så virker Windows og andre operativstemmer på nøyaktig samme måte, at det må gjøre systemkall for å...", "source": "lecture"}
{"lecture_id": "os8del10", "chunk_id": "os8del10_0008", "start": 593.8, "end": 640.0, "token_count": 139, "text": "Akkurat som Linux har Read, så har Windows-operativstemme ReadFile for å lese data fra en fil. Men i prinsippet så virker Windows og andre operativstemmer på nøyaktig samme måte, at det må gjøre systemkall for å... Vanlige brukerprosesser må gjøre systemkall når de skal gjøre kjerneoperasjoner. Alt som har med å snakke med hardware, og alt som har med å styre prosesser. Det er typisk kjernevirksomhet som man er nødt til å gjøre systemcall for å få utført.", "source": "lecture"}
{"lecture_id": "linux6del8", "chunk_id": "linux6del8_0000", "start": 0.0, "end": 84.98, "token_count": 286, "text": "Vi skal nå se på noe som er kjempenyttig hvis man samarbeider på en fellesscreen på Linux. Hvis man samarbeider på f.eks. Linux VM, hvor flere har tilgang samtidig, så kan man sette opp en screen som to eller tre kan bruke samtidig, og gjøre kommandoer om hverandre. Hvis vi tenker oss nå at jeg er Haugerud på studiesesong, og så har vi her en... Og så er vi på samme gruppe. Så starter jeg med å logge meg inn på OS100. Her har jeg kanskje allerede en screen kjørende. Men jeg skal lage en felles-screen. Og da må jeg bruke opsjonen minus DM. Det for at den skal ligge i bakgrunnen. Og så må jeg bruke opsjonen... Nei, jeg kan starte sånn, men jeg kan bruke opsjonen Felles for å vise hvilken screen som er felles. Den skal da kunne deles. Så da har jeg startet en screen, men du ser jeg kobler meg ikke til. Den minus D-en gjør at man ikke kobler seg til. For det jeg nå skal gjøre, er ikke sånn at jeg kobler meg til den loop", "source": "lecture"}
{"lecture_id": "linux6del8", "chunk_id": "linux6del8_0001", "start": 65.42, "end": 160.28, "token_count": 290, "text": "for å vise hvilken screen som er felles. Den skal da kunne deles. Så da har jeg startet en screen, men du ser jeg kobler meg ikke til. Den minus D-en gjør at man ikke kobler seg til. For det jeg nå skal gjøre, er ikke sånn at jeg kobler meg til den loop og kobler meg til med minus R, men jeg skal koble meg til med minus X. Minus seks felles. Da har jeg nå en screen som er... Som andre kan koble seg til. Skreve ekko hei var for å se at nå... Vi kan se at det faktisk er denne screenen jeg kobler meg til. Så tenker vi også at denne stunten også har tilgang til group 100 med passord. Og kommer seg inn som gruppe 100, da kan denne studenten også se... OK, det er to screenere, felles og den andre. Nå skal jeg komme meg til den felles, men igjen med X. Og da ser vi at den studenten nå kommer inn i samme screen. Og de kan nå gjøre kommandoer om hverandre. Da kan den ene se hva den andre gjør, og det er lett å samarbeide med. Hvis man i tillegg har en lydkanal, så kan man prate sammen", "source": "lecture"}
{"lecture_id": "linux6del8", "chunk_id": "linux6del8_0002", "start": 135.88, "end": 187.2, "token_count": 158, "text": "Og da ser vi at den studenten nå kommer inn i samme screen. Og de kan nå gjøre kommandoer om hverandre. Da kan den ene se hva den andre gjør, og det er lett å samarbeide med. Hvis man i tillegg har en lydkanal, så kan man prate sammen og gjøre kommandoer, skrive skript osv. Starte skript her, og så... Alt vil nå være felles. Og den andre kan da ta over og skrive en linje i skriptet. Så dette er kjempenyttig hvis man... Er på samme gruppe og samarbeider om Linux-skjelvprosjekter.", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0000", "start": 0.0, "end": 106.6, "token_count": 300, "text": "Ok. Da skal vi begynne å se på det vi skal gjøre i dag. Aller først skal vi se litt på systemkall og timertics. Vi kunne jo starte aller først med sist. Da håper jeg dere har fått med dere den forelesningen med vafler. Og jeg lager vaffelrøre og foreleser samtidig. Og det er langt fra bare på tull. Jeg håper at den illustrerer på en god måte hvordan et operativsystem virker, og da spesielt scheduleren, som schedulerer mellom de prosessene som skal stå og kjøre. Så jeg vil bruke en del referanser til dette, f.eks. dette med cornal mode. Med en gang en timer interrupt kommer, så setter jeg på hjelp. Og da kjører jeg i kernel mode. Og da er det kjernen som stiller. Og det... Ja. Det er litt av det vi skal se på nå med systemcall. For som dere husker for eksempel når jeg skulle knuse egg... Det var typisk noe som man ikke kan gjøre i UseMove. Da må man inn og bruke hardware ressurser. Og da må man gjøre et systemcall. hvordan systemkall fungerer. Da skal vi se det i et terminalvindu. Her.", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0001", "start": 71.88, "end": 196.88, "token_count": 284, "text": "For som dere husker for eksempel når jeg skulle knuse egg... Det var typisk noe som man ikke kan gjøre i UseMove. Da må man inn og bruke hardware ressurser. Og da må man gjøre et systemcall. hvordan systemkall fungerer. Da skal vi se det i et terminalvindu. Her. Så... Her har jeg et se-program. Og det set-programmet... Det utfører et systemcall en rekke ganger. Så get pay-pay-id. Det er faktisk et systemcall. Og i C så er mange av Linux-systemcallene implementert direkte. Sånn at jeg kan utføre et systemcall direkte med en metode. Det er det umulig å kalle get payPay. Og det er da get parent ID. Så vi skal ikke bruke den i den, men vi skal bare se hva som skjer når man utfører ti millioner systemcall på kort tid. Så jeg kan da prøve å kompulere get payID, og så kan jeg kalle det get payPayID. Sånn. Sånn. Da får jeg et program som heter Get PPID. Og så kan jeg kjøre det. Da ser jo vi at det skjer ikke så mye.", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0002", "start": 169.72, "end": 276.76, "token_count": 290, "text": "Så jeg kan da prøve å kompulere get payID, og så kan jeg kalle det get payPayID. Sånn. Sånn. Da får jeg et program som heter Get PPID. Og så kan jeg kjøre det. Da ser jo vi at det skjer ikke så mye. Men det som skjer i bakgrunnen, er at vi kjører det 10 000 ganger. Men det jeg egentlig ønsker å se på, er hvor mye av dette foregår nå... Og hvor mye i Kölnmold. Så da kan jeg åpne en annen fil som heter... Hva kalte jeg den? Syss. Her er et lite program med syss.shell. Og det det gjør, det prøver å telle opp antall tics. Som kjøres. Og da er det antall tics i use-emboved og i curler-mode. Og vi har sett tidligere på Proc at her så ligger det informasjon dynamisk om hver prosess som kjøres. Og det dette programmet gjør, er at det først så ser det på en linje som inneholder CPU3 i ProcSat. Og denne linjen... Den inneholder all informasjon om TIX som kjøres av CPU3.", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0003", "start": 254.64, "end": 347.7, "token_count": 298, "text": "dynamisk om hver prosess som kjøres. Og det dette programmet gjør, er at det først så ser det på en linje som inneholder CPU3 i ProcSat. Og denne linjen... Den inneholder all informasjon om TIX som kjøres av CPU3. Og TIX, eller GIFFIS, som det ofte omtales, det er den minste tidsenheten, som typisk er et hundredels sekund. Den kan varieres, men i praksis vil jeg si at den ofte er et hundredels sekund. Og det er akkurat det samme som... Kjøkkenklokka jeg hadde i vaffelsimuleringen, som bruker ett minutt. Men i det virkelige tilfellet, eller i dette tilfellet, så bruker den da 100 sekunder. Og så er det i Proxats statistikk som teller opp hvor mange tics brukes i user mode, og hvor mange tics brukes i curl mode av systemet. Og det telles opp for hver prosess. Det er en... Vi har en oppgave denne uken. Dere skal se på hvor mange tics en regnejobb bruker. En regnejobb som regner hele tiden, bruker vanligvis 100 tics per sekund.", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0004", "start": 326.72, "end": 425.4, "token_count": 295, "text": "Og det telles opp for hver prosess. Det er en... Vi har en oppgave denne uken. Dere skal se på hvor mange tics en regnejobb bruker. En regnejobb som regner hele tiden, bruker vanligvis 100 tics per sekund. Så hvis dere teller opp for en regnejobb, bør det komme opp med ca. 100 for hvert sekund. For den kjører bare beregne-i. Men her, når vi gjør den get-paid-a, pluss noen andre instruksjoner, Så skal vi se at det blir litt forskjellig. Så vi kan prøve å kjøre den SUS. Da ser vi... Den skriver ut... Den skriver ut linjen for CPU3, og så kjører den... ... get payday, og så skriver den ut linjen igjen. Dermed kan vi se hvordan tallene øker. Og da ser vi at det er to tall som øker. Det er den, den kolonnen, og så er det den. Det kan være nyttig å vite hvordan... Hvordan vet jeg hva disse tallene er? Det er også nyttig i denne oppgaven dere har, men da kan man se på ManProk. Vi kan søke på akkurat de feltene i Prok.", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0005", "start": 390.0, "end": 487.08, "token_count": 282, "text": "Det er den, den kolonnen, og så er det den. Det kan være nyttig å vite hvordan... Hvordan vet jeg hva disse tallene er? Det er også nyttig i denne oppgaven dere har, men da kan man se på ManProk. Vi kan søke på akkurat de feltene i Prok. Her kan vi søke på Prokstat. Og under Prokstat så kan vi se at det står at det er linjer her. Da blir det veldig mye info. Vi kan ta med Prokstat, så skal vi se... Første delen av Prokstat er ganske ok. Her er et total... Oppsummert all statistikk for alle CPU-ene. Og så ser vi det for hver enkelt CPU nedover her. Så det vi ser på nå, er CPU3. Og så må man også vite hva kolonnene betyr. Og vi ser første kolonne er user. Det er time spent in user mode. Altså det er antall tics spent eller brukt i user mode. Og så er det andre kolonne er nice. Det er det ikke så mange av, men vi skal se på det senere i dag. Men så kommer den tredje kolonnen som er time spent in system mode.", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0006", "start": 463.96, "end": 574.84, "token_count": 296, "text": "Og vi ser første kolonne er user. Det er time spent in user mode. Altså det er antall tics spent eller brukt i user mode. Og så er det andre kolonne er nice. Det er det ikke så mange av, men vi skal se på det senere i dag. Men så kommer den tredje kolonnen som er time spent in system mode. Fjerdekolonnen Idol av den fjerdekolonnen er ofte veldig stor. Så den er størst. For stort sett så idler disse CPU-ene. Så de gjør ingenting. Så summen av Idol er vanligvis størst. Men vi ser da at vi kan konsentrere oss om user mode. Det er da antall tics som blir brukt... Av getPPID. Vi kan kjøre det en gang til. Og så... Ja. GetPPID, den bare står og gjør systemcall. Men vi kan jo se hva den der gjør. Så først så grepper vi på SUPU3. Da får vi ut den linjen her. Og det tallet her, 2 606 714, det er antall tics som er kjørt i user mode. Og så ser vi... Forskjellen her er at den blir 7071. Hvordan jeg søkte på ManPedge...", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0007", "start": 540.0, "end": 665.28, "token_count": 300, "text": "Da får vi ut den linjen her. Og det tallet her, 2 606 714, det er antall tics som er kjørt i user mode. Og så ser vi... Forskjellen her er at den blir 7071. Hvordan jeg søkte på ManPedge... Det er et godt spørsmål, så jeg kan ta det. Når jeg har en mann-side oppe, så taster jeg slash. Sånn. Og da står det en slash nederst til venstre, og så skriver jeg prok.stat. Og så kommer jeg dit. Hvis jeg skal finne neste, så taster jeg N. Men la oss si jeg ser på Stad, da. Så taster jeg N, så kan jeg bla meg nedover. Så det er veldig nyttig. Men jo, vi så på det tallet her. Vi kan kjøre den en gang til, vi. Så blir det litt lettere å se. Sånn, ja. Den har hoppet over fra 7000 her. Men her kan vi se... Usertics... 2608 920 minus usertics her... 574. Og det... Det burde bli 354 usertics.  Og det betyr 354 hundredels sekunder. Er det ikke det, kyss...? Nei, vent litt.", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0008", "start": 630.0, "end": 754.46, "token_count": 298, "text": "Den har hoppet over fra 7000 her. Men her kan vi se... Usertics... 2608 920 minus usertics her... 574. Og det... Det burde bli 354 usertics.  Og det betyr 354 hundredels sekunder. Er det ikke det, kyss...? Nei, vent litt. Det ble 26. Det er... 44 blir det vel. Nei, det kan det ikke bli. 46. Ja, det er litt tidlig for hoderegning. Det er forskjellen i user tics, og dette er antall hundredels sekunder som det programmet vi kjørte, brukte i user mode. Og så kan vi se på sys, og det er her. Det ser vi blir litt færre. Der har den kommet opp i 5000 der. Minus dette tallet. Så det blir 136. 149, skulle det bli... 149 sånn. Og det betyr 1,49 sekunder. Men så kan man jo også... For å teste dette her så kunne man kjøre time. 3.56 har det en som sier det. Ja, da har du sikkert rett i det. Nei, 56. Blir ikke det for mye? Ja, det er ikke så farlig. Vi kan se på dette tilfellet i stedet.", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0009", "start": 726.44, "end": 846.58, "token_count": 300, "text": "For å teste dette her så kunne man kjøre time. 3.56 har det en som sier det. Ja, da har du sikkert rett i det. Nei, 56. Blir ikke det for mye? Ja, det er ikke så farlig. Vi kan se på dette tilfellet i stedet. Nå kjører jeg i time på cyst.so, og da kan vi se nøyaktig hva disse tallene betyr, for her kommer det opp noe tilsvarende. Realtime 4,9 sekunder, user 3.531 og 1.418. Og disse skal da tilsvare hverandre. Og da kan vi forhåpentligvis se... Hvis vi nå prøver å trekke fra, da er det 180 pluss 172. Ja. Det skulle bli 3... Ja, jeg kan... Det jeg ofte gjør når jeg skal regne, er bare å... Jeg har lagd et lite program som regner for meg. Så jeg slipper å gjøre hoderegning. 3.52, ja. Det var en som hadde fått med seg det. 3.52 ble det riktige. Så kan vi ta antall tics i use mode minus antall tics nei, antall tics i kernel mode minus antall tics i kernel mode, er 141.", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0010", "start": 821.48, "end": 923.86, "token_count": 297, "text": "Så jeg slipper å gjøre hoderegning. 3.52, ja. Det var en som hadde fått med seg det. 3.52 ble det riktige. Så kan vi ta antall tics i use mode minus antall tics nei, antall tics i kernel mode minus antall tics i kernel mode, er 141. Og da ser vi... Dette stemmer med det som Time sier. Og det gjør det, for det er den... Det er liksom den samme informasjonen som Time bruker for å få opp. Så her... Dette er hundredels sekunder, så dette er 3,52. Så er det lite grann forskjell, og så er det 1,41. 3,52 i Use as Moved og 1,41 i System as Moved. Så alt i alt det dette betyr, det er at når vi kjører dette programmet... Så her gjør vi systemcall, og da ber vi systemkjernen gjøre dette her. Og da vil... I 1,41 sekunder så kjører vi i kernel mode. Og i 3.52 så kjører vi i use mode. Hvis jeg hadde gjort det tilsvarende her med en regnejobb, så ville man sett at man bare kjørte i...", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0011", "start": 893.88, "end": 1021.72, "token_count": 292, "text": "Så her gjør vi systemcall, og da ber vi systemkjernen gjøre dette her. Og da vil... I 1,41 sekunder så kjører vi i kernel mode. Og i 3.52 så kjører vi i use mode. Hvis jeg hadde gjort det tilsvarende her med en regnejobb, så ville man sett at man bare kjørte i... I rusebåt. Vi kunne jo teste det også. La meg da i stedet kjøre regn her. Da står vi og regner. Får håpe den ikke er altfor lang når mulig. Mulig den tar litt for lang tid. Den så ut til å ta litt lang tid, så jeg prøver på nytt med en kortere utgave. Og da ser vi... Da har det ikke skjedd noe i køllmod. Her er statistikken den samme. Ingen tics har blitt utført i køllmod. Mens her borte... Her er alle ticsene kjørt. Så da står han og kjører i jusemode heltid. Det er spørsmål om det blir samme tidsbruk hvis man kjører time alene. Det blir bitte lite grann forskjell siden du skriver ut prokk også,", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0012", "start": 983.88, "end": 1089.08, "token_count": 281, "text": "Mens her borte... Her er alle ticsene kjørt. Så da står han og kjører i jusemode heltid. Det er spørsmål om det blir samme tidsbruk hvis man kjører time alene. Det blir bitte lite grann forskjell siden du skriver ut prokk også, for det gjør også noen tics, men det er veldig få tics som går med til dette. Er dette fordi man må gå i curl-mode for å få gjort et suksessopphold? Ja, absolutt. Det er det. Så vi ser her når jeg kjører en regnejobb, sånn som dette, Da sier operativstemme at 'dette her er helt ufarlige greier'. 'Du trenger ikke noe disk eller noen ting', så du skal bare regne'. Så da kjører den prosessen i use mode hele tiden. Og dermed så ser vi at det er kun use mode tics som brukes. Og vi vil jo også se det samme... Det har vi sett tidligere når vi kjører regn sånn. Kun user mode som kjører. Mens når vi ser på denne get PPP-id, så er dette et systemkall.", "source": "lecture"}
{"lecture_id": "os9del3", "chunk_id": "os9del3_0013", "start": 1061.44, "end": 1095.0, "token_count": 96, "text": "Og dermed så ser vi at det er kun use mode tics som brukes. Og vi vil jo også se det samme... Det har vi sett tidligere når vi kjører regn sånn. Kun user mode som kjører. Mens når vi ser på denne get PPP-id, så er dette et systemkall. Og da går man inn i kjernen, og det er kjernen som utfører det.", "source": "lecture"}
{"lecture_id": "linux1del1", "chunk_id": "linux1del1_0000", "start": 0.0, "end": 97.3, "token_count": 300, "text": "Hva er Linux? Linux er et operativsystem. Et stort og komplisert program som styrer en datamaskin. Linux-kjernen ble opprinnelig lagd av Linus Thorvalds i 1991, mens Hansen var student. Og Gnu Linux er et mer korrekt navn på Linux. Egentlig bare operativstem, kjernen. Alle verktøyene rundt kjernen, sånn som et skjell og kompilator osv., det må man ha i tillegg til selve kjernen. Det finnes også en rekke andre distribusjoner, som Luntu og RedDat osv., og de lager sitt tilbehør på toppen av denne kjernen. Så ofte når man sier Linux... Så tenker man på alt som har med apparatuset mye å gjøre, inkludert kjernen. Strengt tatt så er Linux-kjernen i hvert fall det som Linus Thorvalds utviklet. Linux er mest brukt som server Wes. Noen få, sånn som meg, bruker det som desktop, men det er ikke så mye utbredt der. Det er først og fremst som servere at det er mye brukt. Linus er et unix-OS. Andre unix-OS er sånn som BSD, Solaris og AX.", "source": "lecture"}
{"lecture_id": "linux1del1", "chunk_id": "linux1del1_0001", "start": 73.82, "end": 168.96, "token_count": 292, "text": "Linux er mest brukt som server Wes. Noen få, sånn som meg, bruker det som desktop, men det er ikke så mye utbredt der. Det er først og fremst som servere at det er mye brukt. Linus er et unix-OS. Andre unix-OS er sånn som BSD, Solaris og AX. Det var noe som fantes for lenge siden. Altså, på 80-, 90-tallene så dominerte de verden når det gjaldt servere. Mens MacOS, altså operativsystemet som brukes som Mac, det er også et unix-operativsystem. I hvert fall halvdelen av det. Hvis du har en Mac, så kan du åpne en terminal, så får du en terminal som ligner veldig på det du har på et Linux-system. Operativsystemet Unix ble utviklet av Kent Homson og Dennis Ritchie i 1969. På 70- og begynnelsen av 80-tallet var Unix det som Linux har vært de siste 20 årene. En viktig del av givningsfilosofien er å sette sammen mange små programmer på mange måter. Og det er det vi kommer til å jobbe med å se på når vi bruker Linux fra kommandolinjen.", "source": "lecture"}
{"lecture_id": "linux1del1", "chunk_id": "linux1del1_0002", "start": 146.92, "end": 172.88, "token_count": 77, "text": "de siste 20 årene. En viktig del av givningsfilosofien er å sette sammen mange små programmer på mange måter. Og det er det vi kommer til å jobbe med å se på når vi bruker Linux fra kommandolinjen. Man har masse små programmer, og så setter man dem sammen på nye måter.", "source": "lecture"}
{"lecture_id": "os8del7", "chunk_id": "os8del7_0000", "start": 0.0, "end": 79.6, "token_count": 279, "text": "Ja, når det gjelder hypertrening... Ja, så... Jeg viste to eksempler på hypertrening sist, og det er kanskje det... De viktigste eksemplene, mens andre prosesser ligger midt imellom. Og det vi så på, var regnejobber, altså den rein eller... Eller et bæsjskript som bare heter rein. Da vi så to Sonyer og regnejobber på en hypertrainingkjerne, så vi at det tar nesten dobbelt så lang tid. For de må da bytte på å bruke alun. Men samtidig kjørte vi en annen prosess som var en rammeprosess, som hele tiden skrev til et RAI-ram. Og den så vi kunne i noen tilfeller kjøre nesten dobbelt så fort. Altså at det gikk like fort om man hadde to sånne. Hvis én sånn prosess kjører alene, klarer den ikke å utnytte alle ressursene. Dermed kan to sånne kjøre omtrent like fort som om de var alene på den kjernen. Så det er hovedhensikten med hypotrening.", "source": "lecture"}
{"lecture_id": "os8del7", "chunk_id": "os8del7_0001", "start": 57.08, "end": 87.0, "token_count": 107, "text": "Altså at det gikk like fort om man hadde to sånne. Hvis én sånn prosess kjører alene, klarer den ikke å utnytte alle ressursene. Dermed kan to sånne kjøre omtrent like fort som om de var alene på den kjernen. Så det er hovedhensikten med hypotrening. For mer normale programmer så ligger ofte svaret sånt et sted i midten der.", "source": "lecture"}
{"lecture_id": "os1del12", "chunk_id": "os1del12_0000", "start": 0.0, "end": 89.68, "token_count": 299, "text": "Dette er to viktige modig som vi kommer til å snakke mye om etter hvert. Her ser vi jeg prøver å gå litt dypere inn på hvor operativsystemet sitter. Da ser vi fortsatt så har vi hardware her nede. Men oppå der så sitter det masse software. Og på toppen så sitter det applikasjoner. Webrosere osv. Men så ser vi... Her på venstre side så ser vi user mode. Og dette er da programvare som kjører i såkalt user mode. Og det som er spesielt med user mode, er at da er det ikke... Da har man ikke alle rettigheter. Det er f.eks. ikke lov til å aksessere alle deler av ram eller internminne. Og det er ikke alle instruksjoner som kan utføres. Instruksjon som ikke kan utføres i usemode, det er holdt... Eller altså å be datamaskinen, hardware her, om å stoppe totalt. Og det ville vært kjedelig, for da kunne den som skrev en webbrovelse, liksom bare velge... Hvis brukeren lastet en spesiell side, så kunne en skru av datamaskinen. Så usemode er en...", "source": "lecture"}
{"lecture_id": "os1del12", "chunk_id": "os1del12_0001", "start": 64.24, "end": 155.34, "token_count": 282, "text": "Eller altså å be datamaskinen, hardware her, om å stoppe totalt. Og det ville vært kjedelig, for da kunne den som skrev en webbrovelse, liksom bare velge... Hvis brukeren lastet en spesiell side, så kunne en skru av datamaskinen. Så usemode er en... Ganske sterkt begrenset modus hvor programmene ikke har lov til å gjøre alle instruksjoner som Hardware kan utføre. Derimot, i cornerl mode... Der er alle instruksjoner mulig. Man kan aksessere alle deler av Hardware. Og operativsystemet må da naturlig nok kjøre i corner mode, for det må kunne... Akseptere alle deler av hardware. Må kunne gjøre absolutt alle operasjoner. Så dette kommer vi masse tilbake til, denne inndelingen. Det var én del, altså det å styre hardware. Men vi kan også si en annen viktig del som OS da gjør, er å forenkle. Og vi ser applikasjonsprogrammene her på toppen. De har et vakkert brukergrensenett mot operativsystemet.", "source": "lecture"}
{"lecture_id": "os1del12", "chunk_id": "os1del12_0002", "start": 134.12, "end": 194.88, "token_count": 228, "text": "Det var én del, altså det å styre hardware. Men vi kan også si en annen viktig del som OS da gjør, er å forenkle. Og vi ser applikasjonsprogrammene her på toppen. De har et vakkert brukergrensenett mot operativsystemet. Alt er pent og enkelt. De har enkle operasjoner, read disk f.eks. Så leser de en fil fra disk. Applikasjonsprogrammene ber operativsystemet lese en fil fra disk. Og da sørger operativsystemet for å snakke med hardware. Og her er en skikkelig ugly interface. Dette er veldig grisete saker. Når du skal snakke med hardware. Og ikke minst finnes det en masse forskjellige harddisker. Sånn at når du snakker med hardware, så er det en masse grums. Og alt dette grumset, det må operativstemme.", "source": "lecture"}
{"lecture_id": "os10del9", "chunk_id": "os10del9_0000", "start": 0.0, "end": 88.66, "token_count": 295, "text": "Så... Jeg skal begynne å se på Java-tråder. Tror ikke jeg rekker å se så veldig mye på det i praksis nå. Men det er veldig rett fram. Og det er et par oppgaver denne uken som går på å komplere en Java-regnejobb, og så kjøre den med flere tråder. Men det er noen sånne... Når man lager ja-adretts, som vi skal se på nå, så må man arve klassen til rett. Da får man noen tredje metoder. Den første er start, som liksom setter av plass for alt. På stack osv. Men den begynner ikke å kjøre tråden. Det er først når startmetoden nesten er ferdig, så kaller den rund. Som da setter i gang tråden til å jobbe med første institusjon. Så har vi en metode som heter GIO. Gi fra seg CPU-en. Det er ikke så vanlig å gjøre, for stort sett overlater man til operativsystemet man skal drivere, så at... Det er sjelden et poeng at tråden gir fra seg CPU-en på den måten. Prioritet kan man sette på tråden. Det skal vi se på senere i neste uke.", "source": "lecture"}
{"lecture_id": "os10del9", "chunk_id": "os10del9_0001", "start": 65.42, "end": 179.92, "token_count": 299, "text": "Det er ikke så vanlig å gjøre, for stort sett overlater man til operativsystemet man skal drivere, så at... Det er sjelden et poeng at tråden gir fra seg CPU-en på den måten. Prioritet kan man sette på tråden. Det skal vi se på senere i neste uke. Skrudderløsning... Der. Javar ble betraktet av OUS som bare én prosess. Og JVM måtte da skridulere til rådene selv. Og det var egentlig et ganske rart opplegg. For da måtte man bruke HIL og så videre for å gi fra seg SPU. Men da overlot man på en måte alt til brukeren. Så det som er standard, er native trends. Da vil Javar-trådene skriduleres av. Da kan vi sette i gang ti tråder, og så forventer du at operativsystemet skredulerer mellom dem. Hvis du har ti CPU-er, så får du en CPU hver. Hvis ikke, så multitasker operativsystemet. Jeg har hørt hele maskinen, så er det ikke helt nøyaktig spesifisert hvordan prioritet skal implementeres. Her vil du se noen store forskjeller mellom Linux.", "source": "lecture"}
{"lecture_id": "os10del9", "chunk_id": "os10del9_0002", "start": 155.52, "end": 255.92, "token_count": 291, "text": "at operativsystemet skredulerer mellom dem. Hvis du har ti CPU-er, så får du en CPU hver. Hvis ikke, så multitasker operativsystemet. Jeg har hørt hele maskinen, så er det ikke helt nøyaktig spesifisert hvordan prioritet skal implementeres. Her vil du se noen store forskjeller mellom Linux. Det er et AT-eksempel på at Java ikke er helt plattformuavhengig. På Linux-hjemmene så skal dere kunne installere JDK og kompilere Java-filer med java.calt.java, og så kjøre med Java-talk. Jeg har ikke sjekket hvilke nasjoner du får... Men det kan dere sjekke ut. Hva Isalem default jobber på. Rett til slutt... Det er én ting som er viktig å være klar over for variabler i Java-trådet. Og det er... Hvis man definerer en tråd, en variabel som static... Så vil den være den variabelen vi har felles for alle trådene. Så da har man en fellesvariabel. Hvis man ikke vedklarer den som static, bare som int id, så vil denne eksistere i hver tråd.", "source": "lecture"}
{"lecture_id": "os10del9", "chunk_id": "os10del9_0003", "start": 231.1, "end": 308.24, "token_count": 210, "text": "Og det er... Hvis man definerer en tråd, en variabel som static... Så vil den være den variabelen vi har felles for alle trådene. Så da har man en fellesvariabel. Hvis man ikke vedklarer den som static, bare som int id, så vil denne eksistere i hver tråd. Det ser omtrent ut som dette her. Vi har nå én java-prosess som inneholder på... Id vil være en egen variabel for hver tråd som du starter. Da kan man gi tråder av id like én i den første tråden og like to i den andre. Men den felles variabelen som ble deklarert som static kollektiv, den kan brukes til å telle opp antall tråder. For hver gang i løkka kommer konten igjen, og så skal man gi en ID til bære de trådene.", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0000", "start": 0.0, "end": 103.32, "token_count": 296, "text": "Ok. Da skal vi se på hvorfor ikke en prosess kan utnytte to CPU-er. Og problemstillingen her er nå spesielt det at man tenker at OK, her har jeg en... Det kan være en regnejobb, typisk, som bruker mye CPU. Og nå vil jeg kjøre den på en svær server som har 96 CPU-er. Og da gå fantastisk fort. Men det er ikke så lett å utnytte flere parallelle CPU-er. Flere forskjellige samtidige renhentede enhenter. Og det er som regel fordi at... Én prosess er ett dataprogram som skal kjøres. Det er som vi ser på denne illustrasjonen her. Det er at det er instruksjoner etter hverandre som bare står og kjører om og om igjen. Og for det første så vet ikke operativsystemet noe om hva som foregår inni denne koden. Den ser bare instruksjoner, og den sier til CPU-e. Sett i gang, kjør disse instruksjonene. Operativsystemet kan ikke vite noe om hva som egentlig foregår her. Det er det programmereren som het. Så derfor er det veldig vanskelig å gjøre noen fordeling her.", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0001", "start": 80.58, "end": 154.5, "token_count": 284, "text": "Den ser bare instruksjoner, og den sier til CPU-e. Sett i gang, kjør disse instruksjonene. Operativsystemet kan ikke vite noe om hva som egentlig foregår her. Det er det programmereren som het. Så derfor er det veldig vanskelig å gjøre noen fordeling her. Operativsystemet kan ikke si at OK, CPU1, du gjør instruksjon 1, 2, 3, og CPU2, du gjør 4 og 5. I prinsippet kunne man gjøre det, men da måtte man flytte hele prosessen fra CPU1 og over på CPU2. Hver gang du gikk fra 3 til 4. Og det ville bare... Det ville bare ta veldig mye tid. Så her er det på en måte opplagt at disse institusjonene må kjøre på samme CPU. For hele tiden er man avhengig av hva som skjedde i forrige institusjon. Man kan ikke kjøre dette uavhengig på en annen CPU. Og det vi ser her, er en veldig enkel implementasjon av... I Bonacci-rekken først legger du én inn i AX og én inn i BX.", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0002", "start": 135.84, "end": 209.0, "token_count": 292, "text": "For hele tiden er man avhengig av hva som skjedde i forrige institusjon. Man kan ikke kjøre dette uavhengig på en annen CPU. Og det vi ser her, er en veldig enkel implementasjon av... I Bonacci-rekken først legger du én inn i AX og én inn i BX. Og så på ledd 3 så ser du legg til AX til BX. Så da blir BX 2, og AX er fortsatt 1. Og så hopper du til neste ledd. Legg til BX til AX. Da legger du 2 pluss 1 er 3, så da blir AX 3. Og så hopper du opp til 3 igjen. Og sånn fortsetter det. Da blir BX lik 2 pluss 3 er 5. Og så på neste så blir AX lik... Tre pluss fem er åtte, og så... og så videre. Ja. Jeg ser forresten den Fibonacci-rekken her. Den så ikke veldig riktig ut. Én, én, to, tre, fem, skulle stå der, og åtte. Det blir et problem for oppgavene. Hva er feil i denne Fibonacci-rekken? Men hovedpoenget er at man kan ikke...", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0003", "start": 189.08, "end": 278.64, "token_count": 291, "text": "Ja. Jeg ser forresten den Fibonacci-rekken her. Den så ikke veldig riktig ut. Én, én, to, tre, fem, skulle stå der, og åtte. Det blir et problem for oppgavene. Hva er feil i denne Fibonacci-rekken? Men hovedpoenget er at man kan ikke... Utnytte to eller hundre prosessorer når du bare har ett program som kjører sånn som dette her... Det må kjøres sekvensielt. Det vi kunne få til, er hvis man som programmerer kan skrive kode som kan kjøres i parallell. Men det er opp til programmereren. Hvis programmeren kan klare å få til... Splitte opp denne koden, sånn at den kan kjøre på to steder samtidig, gjøre noen milliarder institusjoner på hvert sted, og så slå sammen resultatene. Da kan man utnytte to eller flere prosesser. Men i de fleste tilfeller så er det vanskelig. Og i et sånt tilfelle som dette her, hvor alt avhenger av forrige to-tre institusjoner, så vil det ikke være mulig å utnytte flere. Men i noen tilfeller så har man parallelliserbar kode.", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0004", "start": 255.44, "end": 342.0, "token_count": 299, "text": "Men i de fleste tilfeller så er det vanskelig. Og i et sånt tilfelle som dette her, hvor alt avhenger av forrige to-tre institusjoner, så vil det ikke være mulig å utnytte flere. Men i noen tilfeller så har man parallelliserbar kode. Og vi tenker oss et enkelt tilfelle sånn som dette her... At vi skal legge sammen en stor sum. Vi skal telle fra 1 pluss 2 pluss 3 pluss 4 opp til 2000. Nå er det klart. I akkurat i dette tilfellet så fins det en formel. Utled en formel som gir svaret her, som er 1 ganger 1 pluss 1,5, er det vel? Men det er jo ikke poenget. Poenget er at her skal vi gjøre en lang regneroperasjon. Vi skal gjøre den på denne måten. Og dette er da kode som opplagt er parallelliserbart. For da, hvis vi har en oppgave som er på denne måten her... Så kan vi f.eks. dele dette i to. Én CPU kan regne ut summen fra 1 til 1000, og en annen CPU kan regne ut summen fra 1001 til 2000.", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0005", "start": 322.48, "end": 413.84, "token_count": 297, "text": "For da, hvis vi har en oppgave som er på denne måten her... Så kan vi f.eks. dele dette i to. Én CPU kan regne ut summen fra 1 til 1000, og en annen CPU kan regne ut summen fra 1001 til 2000. Og så, etterpå at de to prosessene er ferdig, så kan man slå sammen resultatet, og så får man totalsummen. Og dermed har man klart å parallellisere koden, og dermed kan man utnytte flere CPU-er. Hvis man bare kjører et C-program som lager denne summen her... Og overleverer det lasteren i RAM og ber operativsystemet om å kjøre, så aner ikke operativsystemet noe om hva alle disse institusjonene i denne summen gjør. Så operativsystemet selv er overhodet ikke i stand til å utnytte at det har 48. Det går bare ikke, så man kan ikke forvente at operatørsystemet skal kunne sørge for at man utnytter alle CPU-ene. Og da er det programmereren selv som må sørge for parallellisering. Og da kunne man løse dette her med to prosesser eller to tråder.", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0006", "start": 390.0, "end": 488.64, "token_count": 299, "text": "Det går bare ikke, så man kan ikke forvente at operatørsystemet skal kunne sørge for at man utnytter alle CPU-ene. Og da er det programmereren selv som må sørge for parallellisering. Og da kunne man løse dette her med to prosesser eller to tråder. Og tråder skal vi se på mye senere i detalj. Vi skal se på ja. og P-treads i C, som vi da kan sette opp for å gjøre ting i parallelt. Vi har vel egentlig delvis sett på det når vi har gjort regnejobber i parallelt også. Da er det en sånn type regnejobb. Så setter vi opp akkurat like regnejobber på fire CPU-er ved å bare starte fire bæsjscript samtidig. Det vi ikke har gjort, er at vi ikke har slått sammen ressurser. Men det er en liten detalj som man kan få til. Et eksempel på når dette kan være nyttig, er passordkracking. Det var en student som syntes at den passordkrakking-algoritmen gikk litt tregt. Den tok jo over to minutter på studiesesong. At den klarte å dele opp... Dele opp det problemet i åtte like biter", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0007", "start": 458.68, "end": 557.72, "token_count": 288, "text": "Et eksempel på når dette kan være nyttig, er passordkracking. Det var en student som syntes at den passordkrakking-algoritmen gikk litt tregt. Den tok jo over to minutter på studiesesong. At den klarte å dele opp... Dele opp det problemet i åtte like biter og utnyttet da de åtte sekundene som var på PC-en. Og passord-cracking er typisk et problem som er parallelliserbart. Men hvis vi da setter i gang en skript som kjører gjennom alle de 17 000 passordene eller hva det er... Så kan ikke operativsystemet forstå dette her. At... Oi, dette her er jo parallelliserbart. Så intelligent er ikke operativsystemet. Det finnes noen kompilatorer som kan automatisk parallellisere på den måten. Så noen automatiske måter finnes det. Men stort sett så er det da programmereren som må se.  På hver CPU så kan jeg kjøre gjennom ett antall passord. Så fordeler jeg de jobbene likt. Og det er først da man kan virkelig utnytte at man har mange CPU. Og dette er viktig å kunne,", "source": "lecture"}
{"lecture_id": "os8del3", "chunk_id": "os8del3_0008", "start": 537.88, "end": 592.96, "token_count": 161, "text": " På hver CPU så kan jeg kjøre gjennom ett antall passord. Så fordeler jeg de jobbene likt. Og det er først da man kan virkelig utnytte at man har mange CPU. Og dette er viktig å kunne, for veldig ofte så kan man nå kjøre på servere som har mange CPU-er. Og da kan det være viktig å ha kode som utnytter... Hvis det er CPU-avhengig kode som man ønsker skal kjøre fort. Så dette er problemstillinger man ofte kommer ut for hvis man koder og er utvikling. Men det vi ser på, er liksom de prinsipielle delene av dette.", "source": "lecture"}
{"lecture_id": "os2del17", "chunk_id": "os2del17_0000", "start": 0.0, "end": 82.78, "token_count": 293, "text": "Den generelle metoden når man skal lage en bolsk funksjon og putte det inn i en CPU som man kan gjøre en operator, den anvender vi her i dette tilfellet. Vi skriver ned det bolske uttrykket for de to funksjonene. Altså for disse to funksjonene her. Og da bruker vi igjen samme metoden. For s så må vi ha med et ledd for hver gang den er én. Så f.eks. det første leddet her vil der være ikke x, ikke y, ganger... Altså ikke x, ganger, ikke y, ganger z. Og så, etter man har gjort det, så forenkler man med Bols galgebra. Eller noe som heter Carnot-diagram, som er en mer avansert måte som man kan utføre ganske kompliserte forenklinger med diagrammer. Vi tok et kurs i datamaskinarkitektur, og da brukte vi Carnot-diagrammer og lagde sånne kretser. Nå ser vi mer på prinsippene. Men etter at vi har forenklet, så kan vi da tegne en krets med det bortskrivne uttrykket. Som utfører nøyaktig den operasjonen vi ønsker.", "source": "lecture"}
{"lecture_id": "os2del17", "chunk_id": "os2del17_0001", "start": 60.02, "end": 133.74, "token_count": 291, "text": "Vi tok et kurs i datamaskinarkitektur, og da brukte vi Carnot-diagrammer og lagde sånne kretser. Nå ser vi mer på prinsippene. Men etter at vi har forenklet, så kan vi da tegne en krets med det bortskrivne uttrykket. Som utfører nøyaktig den operasjonen vi ønsker. Så først forenkler vi. Så dette er skrevet rett ned fra sansestabellen. Og det er det som dere må sitte igjen med. Har du en sannhetsstabell, så kan du bare skrive ned kretsen og tegne den og produsere den. Og sannhetsstabellen, det får du fra den logikken du ønsker. Så vi så nå at vi ønsket å kunne legge sammen tall. Og da skrev vi bare ned en sannhetsstabell med det innholdet. Og så så vi at det som da skal komme ut av S og C, ser jeg er carrie. Det er de to funksjonene der. Så kan man med Bols galgebra eller på andre måter vise at f.eks. den funksjonen her, den kan forenkles til dette uttrykket.", "source": "lecture"}
{"lecture_id": "os2del17", "chunk_id": "os2del17_0002", "start": 107.38, "end": 162.12, "token_count": 197, "text": "Og da skrev vi bare ned en sannhetsstabell med det innholdet. Og så så vi at det som da skal komme ut av S og C, ser jeg er carrie. Det er de to funksjonene der. Så kan man med Bols galgebra eller på andre måter vise at f.eks. den funksjonen her, den kan forenkles til dette uttrykket. Når man har gjort forenklinger på begge, så kan man begynne å tegne. Nå tegner jeg bare opp C-en. C-en vil la oss se sånn ut. Du får X, Y, Z inn fra venstre, og så får du C-en ut til høyre. Så kan man gjøre det tilsvarende med S. Og når man har fått til det, så kan man sette det sammen til en krets.", "source": "lecture"}
{"lecture_id": "linux4del3", "chunk_id": "linux4del3_0000", "start": 0.0, "end": 94.8, "token_count": 287, "text": "Det er en typisk feil som oppstår i script når man har filtester, og det skal vi se på nå. Vi tar utgangspunkt i dette scriptet som tester da om input... Eller første argument til programmet er en fil eller en mappe. Og da kan man spørre seg hva skjer hvis man... Ikke sende med noe argument i det hele tatt til henne. Til dette skriptet. Da burde hun skrive ut verken fil eller mappe. Men vi kan prøve. Så da kjører jeg skriptet sånn, uten argument. Hvis jeg har med et argument, fyll og tekst det, så oppfører det seg fint. Men hva skjer nå? Jo, da skriver det ut:\" Er en fil\". Det virker som testen slår til. Uten et argument. Da må vi gå inn og se på... Se på programmet igjen og se. Hva kan det komme av? Jo, da vil det jo stå her:\" if -f dollar fil\". Så det er litt merkelig at det slår til. Men det som det viser seg, er at en test hvor det bare står -f... Den returnerte tru, den er sann. Det blir sant når variabelen fil er to.", "source": "lecture"}
{"lecture_id": "linux4del3", "chunk_id": "linux4del3_0001", "start": 71.6, "end": 157.4, "token_count": 283, "text": "Jo, da vil det jo stå her:\" if -f dollar fil\". Så det er litt merkelig at det slår til. Men det som det viser seg, er at en test hvor det bare står -f... Den returnerte tru, den er sann. Det blir sant når variabelen fil er to. Det som generelt er fornuftig å gjøre, er å sette inn en sånn variabel i anfølgelsestegn. For da vil den teste på også en tom fil, eller et tomt argument. Det vil da gi falsk. Det som da skjer, er at den hopper videre til neste. Altså viser den den i stedet. Så vi kan teste at det er riktig. Da hopper den over er en fil, for den testen slo til. Og så velger den her en mappe. Så vi må også rette opp den hvis vi skal få et skript som funker i alle tilfeller. Så... Der. Hvis jeg klarer å... Sånn. Nå ser skriptet riktig ut. Så kan vi teste på nytt, og da får vi opp... Et fornuftig resultat. Så det er viktig å alltid ta to time.", "source": "lecture"}
{"lecture_id": "linux4del3", "chunk_id": "linux4del3_0002", "start": 127.84, "end": 239.0, "token_count": 290, "text": "hvis vi skal få et skript som funker i alle tilfeller. Så... Der. Hvis jeg klarer å... Sånn. Nå ser skriptet riktig ut. Så kan vi teste på nytt, og da får vi opp... Et fornuftig resultat. Så det er viktig å alltid ta to time. Et lignende tilfelle får man hvis man først prøver å teste ut hva innholdet av argumentet er. Så f.eks. så kan jeg prøve å sjekke... Dollar fil er lik... og så kanskje lik... ja, ordet... Ordet fil, på den måten. Den... ekko... Dollar fil er fil. Altså fil. Syns jeg. Hvis jeg bare har lyst til å teste den biten av en skript, så kan jeg legge på en exit, og da avslutter skriptet her. Og så får jeg ikke med resten. Så nå tester jeg bare den første delen her. Så ser vi og kjører på nytt. Hvis jeg nå tar test med fil, så ser vi... Ja, det slår til. Hvis jeg tar noe annet, så slår det ikke til, for da slo ikke den testen til.", "source": "lecture"}
{"lecture_id": "linux4del3", "chunk_id": "linux4del3_0003", "start": 220.64, "end": 276.8, "token_count": 204, "text": "Så nå tester jeg bare den første delen her. Så ser vi og kjører på nytt. Hvis jeg nå tar test med fil, så ser vi... Ja, det slår til. Hvis jeg tar noe annet, så slår det ikke til, for da slo ikke den testen til. Så ser vi... Oi, da får jeg en feilmelding. Da klarer ikke Shell å forstå hva som skjer, for da kommer det bare en er-lik-fil her. Og igjen så er det viktig å sette det argumentet i fil-testen i avslutningstegn, hvis det er en variabel som du skal teste på. Hvis jeg gjør det på denne måten, så vil man ikke få feilmeldinger. Hvis jeg kjører på nytt nå, så ser vi at det fungerer rimelig, og jeg får ingen feilmelding.", "source": "lecture"}
{"lecture_id": "os14del12", "chunk_id": "os14del12_0000", "start": 0.0, "end": 111.12, "token_count": 273, "text": "Dette programmet, som skriver til et RA. Og noe av det som er viktig å vite her nå, er hvordan et todimensjonalt RA, eller en matrise, lagres i ramm. Ofte bruker man matriser som dette, RABA, med to indekser, for å lagre data. I maskinlæring og AI, f.eks., har man ofte sånne store matriser som dette. Da er det viktig å vite hvordan et RAI er organisert. For det er på en måte et valg når du har to indekser. Hvordan skal de ligge etter hverandre i ramm? Da er jeg skrevet opp fasiten for C her nede. Kompulatorer for forskjellige språk. Men for å se, så er det sånn at ra00 ligger rett før ra01 og ra02. Så... Ja, dette er litt viktig for hele problemstillingen. Så jeg tenker vi skal... Vi kan prøve å tegne opp det også. Hvis jeg kaller bare r-eyet A. Jeg har A av A. B. Sånn som det der. Og så har vi ramme nedover her.", "source": "lecture"}
{"lecture_id": "os14del12", "chunk_id": "os14del12_0001", "start": 71.8, "end": 197.68, "token_count": 280, "text": "Så... Ja, dette er litt viktig for hele problemstillingen. Så jeg tenker vi skal... Vi kan prøve å tegne opp det også. Hvis jeg kaller bare r-eyet A. Jeg har A av A. B. Sånn som det der. Og så har vi ramme nedover her. Og da er det et veldig viktig poeng når vi skal kjøre dette her, at A av 00 er første poeng. Det ligger her. Og så kommer A av 01. Og så kommer A av 02. Og så videre nedover. Helt til vi kommer til... Har fylt opp liksom første delen av r-øyet. Så kommer vi til A av 10... Og så fortsetter den nedover dere. Og så kommer A2. Og så videre i det uendelige. Her ser vi med en gang at den fortsetter. At her kan det bli noe trøbbel eller noen forskjeller med hensyn på cash. For det er klart... Hvis jeg skriver ut på denne måten, med a av null først, og løper gjennom med 1, 2, 3, 0, 1, 2 og sånn,", "source": "lecture"}
{"lecture_id": "os14del12", "chunk_id": "os14del12_0002", "start": 180.0, "end": 268.8, "token_count": 286, "text": "At her kan det bli noe trøbbel eller noen forskjeller med hensyn på cash. For det er klart... Hvis jeg skriver ut på denne måten, med a av null først, og løper gjennom med 1, 2, 3, 0, 1, 2 og sånn, så vil det treffe bra med cash, for da vil hele den biten sendes ut i cash. Og... Det er det vi nå skal se på. Og da ser vi... Skal vi se hvordan jeg gjør det her... I det eksempelet her... så ser vi at... Ja, jeg har B, A... Kanskje jeg kan prøve å gjøre det sånn? Sette A først. For da... La oss si jeg skal prøve å få det til å gå så fort som mulig nå. A lik 0... Da er det den ytre forløkken der. Og da starter... Så starter jeg på A av 0, og da vil jeg få A av 0, A av 0, A av 01 osv. Så denne måten burde være den raskeste. Men da prøver vi. Komplerer og kjører. Ja... Jeg kan se om det er noen forskjell", "source": "lecture"}
{"lecture_id": "os14del12", "chunk_id": "os14del12_0003", "start": 234.66, "end": 329.96, "token_count": 294, "text": "Da er det den ytre forløkken der. Og da starter... Så starter jeg på A av 0, og da vil jeg få A av 0, A av 0, A av 01 osv. Så denne måten burde være den raskeste. Men da prøver vi. Komplerer og kjører. Ja... Jeg kan se om det er noen forskjell Stor O. Mer effektivt gode... Jo, det går fortere. Så ikke tenk på den siste... at jeg bruker stor O. Når jeg skal komplere etterpå på den andre måten, så bruker jeg fortsatt stor O. Og vi ser... Det går på 0,75 sekunder. Men så kan jeg prøve. Hva om jeg bytter om B og A? Og det er opplagt... Det er det samme jeg gjør hver gang. Jeg bare løper gjennom på litt forskjellige måter. Totalt sett så vil programmet gjøre akkurat det samme. Men da ser vi... Dette programmet, som vi gjør nok til det samme, det går... Ca. 8... Det bruker 8 ganger så lang tid. Og det er akkurat den effekten som vi da forutsa.", "source": "lecture"}
{"lecture_id": "os14del12", "chunk_id": "os14del12_0004", "start": 304.4, "end": 408.76, "token_count": 285, "text": "Totalt sett så vil programmet gjøre akkurat det samme. Men da ser vi... Dette programmet, som vi gjør nok til det samme, det går... Ca. 8... Det bruker 8 ganger så lang tid. Og det er akkurat den effekten som vi da forutsa. Her, i det første programmet, så tok vi og skrev til R-øyet på denne måten. Vi skrev ut hvert element som da ligger etter hverandre pent og pyntelig i ram, og det kan kjøres i hele bolker i cash og sendes av gårde. Neste forsøk så gjorde vi jo da noen enorme hopp fordi at vi måtte... Hoppe fra... Først skrev jeg A00, og så skrev jeg AA10. Og da måtte vi gjøre et svært hopp i ram herfra og hit, som var på 20 000. Og dermed ble det totalt cash miss. Og det kan vi da også se... Hvis vi kjører perf på dette her. Så vi kjører perf på det andre forsøket. Og her ser vi... Masse Minerfolds. Minner bare bygges opp. Det er kanskje ikke så forskjellig,", "source": "lecture"}
{"lecture_id": "os14del12", "chunk_id": "os14del12_0005", "start": 372.32, "end": 493.84, "token_count": 298, "text": "Og dermed ble det totalt cash miss. Og det kan vi da også se... Hvis vi kjører perf på dette her. Så vi kjører perf på det andre forsøket. Og her ser vi... Masse Minerfolds. Minner bare bygges opp. Det er kanskje ikke så forskjellig, men det er vel først og fremst cash misses som blir forskjellen her. Da må vi endre til det vi trodde var det beste. AB. Kompliere på nytt... og kjøre perf. Ja, da ser vi. Minor folds ble det samme. For i dette tilfellet så bruker vi jo akkurat like stor del av ramm. Så antall pages blir det samme. Så det gir ikke så stor tidsforskjell. Men her ser vi på cash misses. Her er det en stor forskjell. Her er det 29 millioner cash misses, så det er en god del. Men her oppe så ser vi... Dette tar tid, for det er 700 millioner cash misses. Det er også flere cash referanser. Altså der hvor du i det hele tatt... Her er det først og fremst en enorm forskjell i cash-bruken. Vi gjør akkurat det samme, men vi henter det fra et annet sted.", "source": "lecture"}
{"lecture_id": "os14del12", "chunk_id": "os14del12_0006", "start": 469.44, "end": 575.84, "token_count": 300, "text": "for det er 700 millioner cash misses. Det er også flere cash referanser. Altså der hvor du i det hele tatt... Her er det først og fremst en enorm forskjell i cash-bruken. Vi gjør akkurat det samme, men vi henter det fra et annet sted. Har det noe med at man bare legger ut 5? Det vi kunne gjøre, var bare for å gjøre det veldig eksplisitt, så kunne vi prøve å legge ut... Hva om vi legger ut A pluss B? Blir det noen annen forskjell på programmene? Men vi ser... Ja, det tok litt lengre tid. Men vi ser i Cashmisses så er det ikke noen forskjell. For det er... Du gjør det samme. Så da jeg prøvde å avkrefte det nå, var at kanskje de gjorde noe sånt smart triks med at det ligger et tall Men vi ser, selv når vi legger forskjellige tall, så er forskjellene de samme. Og vi får den samme forskjellen... ... med at det tar mye lengre tid. Og vi får omtrent det samme antall cash misses. Så det at vi la ut det femtallet, hadde ingen betydning.", "source": "lecture"}
{"lecture_id": "os14del12", "chunk_id": "os14del12_0007", "start": 540.0, "end": 589.0, "token_count": 131, "text": "Men vi ser, selv når vi legger forskjellige tall, så er forskjellene de samme. Og vi får den samme forskjellen... ... med at det tar mye lengre tid. Og vi får omtrent det samme antall cash misses. Så det at vi la ut det femtallet, hadde ingen betydning. Den store forskjellen var at i det ene tilfellet måtte vi hoppe langt i ramm. Og det passer dårlig med cash. I det andre tilfellet så lå alle dataene pent etter hverandre.", "source": "lecture"}
{"lecture_id": "os2del7", "chunk_id": "os2del7_0000", "start": 0.0, "end": 89.92, "token_count": 275, "text": "En liten repetisjon av and or not fra forrige gang. De skal vi da bruke hele tiden, når vi bygger de logiske funksjonene. Her ser vi and-tabellen. Og i digital teknikk er det vanlig å bruke et gangetegn - A ganger B. For dere som har hatt diskré matematikk, har dere typisk brukt dette tegnet. Det er samme operasjon. I bolsk algebra vil du ha uttrykk som dette. Alle disse uttrykkene stemmer også med vanlig algebra. Men dette er bolsk algebra. Dette er et symbol for en and-port. Det kommer a og b inn fra venstre, og ut på høyresiden får man a ganger b. Digitalteknikk skriver man det vanlig som A pluss B. Dere er kanskje vant til noen av dere? Er vant til A eller B på denne måten? Og igjen så er dette bolsk algebra. Null pluss null er null. Her ser vi at det er én forskjell. Dette ligner jo på vanlig algebra. Helt fram til hit. Én pluss én er én. Og der vil de fleste suse, som er vant til", "source": "lecture"}
{"lecture_id": "os2del7", "chunk_id": "os2del7_0001", "start": 73.16, "end": 136.4, "token_count": 208, "text": "Og igjen så er dette bolsk algebra. Null pluss null er null. Her ser vi at det er én forskjell. Dette ligner jo på vanlig algebra. Helt fram til hit. Én pluss én er én. Og der vil de fleste suse, som er vant til Men 1 pluss 1 er 1. Det betyr at hvis det kommer to enere inn i en ark-port, så skal det gå en ener ut også. Som vi så veldig nøye på hvordan man bygger fysisk. Den er veldig enkel. Kommer det null inn, så kommer det en ener ut. I digital teknikk vil en strek over... En variabel. Det vil bety not. I diskré matematikk brukte dere dette tegnet. Og det som er mer vanlig i logikk sånn generelt, så er dette tegnet for not. Men det betyr det samme.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0000", "start": 0.0, "end": 103.62, "token_count": 298, "text": "Ja, aller først så var det et spørsmål i pausen om innlogging på Linux-VM. Om jeg kunne gjenta det? Og det kan jeg gjøre. Det gikk kanskje litt fort. Nå har jeg også begynt å legge ut videoer fra før pause. Sånn som dere ser nå, så går det an å gå inn på den og så se... Se f.eks. sånn som det. Det ligger åtte minutter ut i første time. Hvordan logger man på på Linux-VM-ene? Men jeg tar det uansett en gang til. Så... Det var også spørsmål om grupper. Så vi kan ta det også hvis vi går inn på... Studentgruppene her. Så ser dere at det er OS-grupper. Og nå er det 96 grupper. Så for å få en... For å få tilgang til en Linux-VM, så må du melde deg inn i en gruppe. Her ser vi noen som allerede har kommet inn i 81 og 83. Så hvis du ennå ikke har fått tilgang, f.eks. ikke har levert obliger, så meld deg inn i OS84. Det du da får som OS84, det er da bare et passord. Så du får kun passordet, og da er tanken...", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0001", "start": 79.92, "end": 197.0, "token_count": 291, "text": "Her ser vi noen som allerede har kommet inn i 81 og 83. Så hvis du ennå ikke har fått tilgang, f.eks. ikke har levert obliger, så meld deg inn i OS84. Det du da får som OS84, det er da bare et passord. Så du får kun passordet, og da er tanken... At hvis du har passord 84, sånn som det, så skal du da logge deg inn som brukeren group 84. Og i tillegg så skal... Så er hosten som du skal inn på, det er OS84. Så sånn logger du deg inn til denne adressen. Vi kan ta først før vi logger oss inn, så kan vi f.eks. bruke ping. Da ser vi at den svarer på ping. Dette er en typisk måte man sjekker om en server er oppe på. Ved å pinge. Men så er det da viktig at du går inn på group.at.os84. Hvordan vi finner passordet? Jo, gå på OS-gruppen. Og så klikk på... annonsement. Jeg trodde kanskje man fikk det annonsementet i Apos også. Altså alt på gruppen. Hvis ikke, så gå inn på...", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0002", "start": 164.6, "end": 257.88, "token_count": 285, "text": "Men så er det da viktig at du går inn på group.at.os84. Hvordan vi finner passordet? Jo, gå på OS-gruppen. Og så klikk på... annonsement. Jeg trodde kanskje man fikk det annonsementet i Apos også. Altså alt på gruppen. Hvis ikke, så gå inn på... Gå inn på gruppen, og så klikk på annonsement der. Det skal jeg ikke gjøre, for der ligger da passordet til OS28. Det kom altså på Apos, ja. Så da... Hvis dere har slettet den e-posten, så gå inn i Gruppen og se på Announcements. Der ligger det bare en streng. Det er vel fire tegn og et tall og så fire nye tegn. Et lite ord og så et tall og så et annet ord. Så da logger dere inn som Group84. At Ords84. Og så er det... Hvis dere får opp noe sånt som dette her, så svar yes. Det er sånn typisk du får første gang du logger inn på en server. Og etterpå så lagrer den da Mac-adressen til den serveren. Så hvis du senere logger inn på den samme adressen,", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0003", "start": 240.0, "end": 323.98, "token_count": 282, "text": "Hvis dere får opp noe sånt som dette her, så svar yes. Det er sånn typisk du får første gang du logger inn på en server. Og etterpå så lagrer den da Mac-adressen til den serveren. Så hvis du senere logger inn på den samme adressen, og Mac-adressen er endret, altså adressen til nettverkskortet på nivå 2, på la-nivå, eternettadressen... Hvis den har blitt endret, så... Så kan det tyde på at det er en sånn man in the middle attack. Altså at noen prøver å gjøre noe lureri med IP-adressen og sende deg til et annet sted enn du skal, osv. Så derfor må man første gang svare bare yes på den, så kommer man inn. Du ser, nå kommer jeg direkte inn. Du må taste passord. Men jeg har lagt opp SSO-nøkler, sånn at jeg kommer inn på alle disse VM-ene. Sånn at jeg kan hjelpe til. Er du på gruppe 1, så logger du inn på denne måten. Ok. Vi så på Branch Prediction, og så vidt jeg husker,", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0004", "start": 288.66, "end": 407.9, "token_count": 292, "text": "Du ser, nå kommer jeg direkte inn. Du må taste passord. Men jeg har lagt opp SSO-nøkler, sånn at jeg kommer inn på alle disse VM-ene. Sånn at jeg kan hjelpe til. Er du på gruppe 1, så logger du inn på denne måten. Ok. Vi så på Branch Prediction, og så vidt jeg husker, så er det vel en oppgave uansett. Det kan være veldig nyttig å gå inn. Prøve å kjøre denne branch prediction og se hva som skjer. Men den effekten vi så i programmet, at det gikk fortere når man sorterte RE, det skyldtes altså at branch prediction traff oftere enn... Eller det traff egentlig hele tiden. Mens i andre tilfeller så måtte man veldig ofte gå tilbake, fordi man hadde bommet på branch prediction. Så måtte man gå tilbake. Og det tar opplagt ekstra tid. Da skal vi over på et annet tema. Vi skal ikke slippe... Vi skal ikke slippe... datamaskinarkitektur helt fullstendig ennå. Oppsummere kort datamaskinarkitektur. Så jeg finner riktige slides... Sånn.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0005", "start": 360.0, "end": 466.7, "token_count": 265, "text": "Og det tar opplagt ekstra tid. Da skal vi over på et annet tema. Vi skal ikke slippe... Vi skal ikke slippe... datamaskinarkitektur helt fullstendig ennå. Oppsummere kort datamaskinarkitektur. Så jeg finner riktige slides... Sånn. Følgene er veldig viktig å huske fra datamaskinarkitektur. CPU-en har ikke noe annet som hva maskininstitusjonene gjør, hva slags logikk det er inni der. Den bare følger institusjonene én for én. Som vi skal se senere, så vet heller ikke operativsystemet om den indre logikken i maskininstitusjonene. Men det viktige er at NCPU utfører bare én og én institusjon. Og så er det ingen én-til-én-forbindelse mellom institusjoner i høynivåkode og maskinkode. Vi har sett at en kompulator kan lage forskjellige typer maskinkode, så det er ingen garanti for hvordan maskinkoden ser ut.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0006", "start": 441.08, "end": 516.44, "token_count": 295, "text": "i maskininstitusjonene. Men det viktige er at NCPU utfører bare én og én institusjon. Og så er det ingen én-til-én-forbindelse mellom institusjoner i høynivåkode og maskinkode. Vi har sett at en kompulator kan lage forskjellige typer maskinkode, så det er ingen garanti for hvordan maskinkoden ser ut. Og i enkelte tilfeller så er det umulig å lage én linje maskinkode som gjør hele høynivåkoden. Så én linje kode i høynivåspråk fører ofte til mange maskininstitusjoner. I det ferdigkompliserte programmet. Så har vi også denne CPU-løkken. Den viser bare at CPU-en er en evig løkke. Wild not halved. Så lenge maskinen står på, så står den og kjører instruksjoner. Hvis den ikke har noen instruksjoner å gjøre, så gjør den en såkalt NOP. No operation. Altså at den bare står og slår i lufta. Etter hvert som det har kommet servere med veldig mange sippuer,", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0007", "start": 496.72, "end": 577.02, "token_count": 292, "text": "Wild not halved. Så lenge maskinen står på, så står den og kjører instruksjoner. Hvis den ikke har noen instruksjoner å gjøre, så gjør den en såkalt NOP. No operation. Altså at den bare står og slår i lufta. Etter hvert som det har kommet servere med veldig mange sippuer, så ville det tatt mye energi at alle står sånn og spinner og bruker energi på det. Da er det kommet nye features hvor du kan legge sippuer i dvale. Men i utgangspunktet så er det i hvert fall én som står og kontrollerer og slår i lufta helt til noe skjer. Enten det er kode som skal kjøres, eller at det kommer et interrupt. Det er viktig å ha med seg videre at når som helst så kan det komme et interrupt. F.eks. hvis man taster bokstaven A, så vil det da sendes en interrupt til CPU-en som sier at her har det kommet input fra en bruker. Eller kanskje det har kommet en pakke fra nettverket, eller annen input fra. Når som helst kan det skje et såkalt interrupt.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0008", "start": 551.32, "end": 666.74, "token_count": 295, "text": "F.eks. hvis man taster bokstaven A, så vil det da sendes en interrupt til CPU-en som sier at her har det kommet input fra en bruker. Eller kanskje det har kommet en pakke fra nettverket, eller annen input fra. Når som helst kan det skje et såkalt interrupt. Da må CPUN stoppe med å gjøre disse institusjonene. Så må den ta seg av interruptet. Men dette styres da i samarbeid med operativsystemet. Operativsystemet må ha et opplegg for å kunne behandle interrupter. Så jeg tenkte jeg bare tok en veldig kort introduksjon om operativsystemer og operativsystemhistorie. I operativsystemhistorien så... Den er ikke fullstendig. Men jeg bare tenkte å se litt på tidligere Microsoft og Unix' operativstemmer. Som kanskje har vært de mest sentrale. Operativsystemene, i hvert fall de siste 30 årene. Mac er også et sentralt operativsystem. Vi kommer innom det også. Men først en veldig kort oversikt over Microsoft Destop-OS og Server-OS. Og så tilsvarende for Unix og Linux. Dette er faktisk 40 år siden MS-DOS kom ut.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0009", "start": 630.0, "end": 727.34, "token_count": 280, "text": "Operativsystemene, i hvert fall de siste 30 årene. Mac er også et sentralt operativsystem. Vi kommer innom det også. Men først en veldig kort oversikt over Microsoft Destop-OS og Server-OS. Og så tilsvarende for Unix og Linux. Dette er faktisk 40 år siden MS-DOS kom ut. Det var et 16-bit-operativsystem. Etter hvert så ser vi at det kom 32-bits. Sånn rundt 2000 er vel kanskje enda en litt, nei... Vinos 95 var det noe 32-bits, og her omtrent så var det en sånn overgang fra Zipper med 16 til 32-bit. Etter hvert rundt år 2000 ble 64-bits vanlig. Det er det aller vanligste nå med 64-bits PU-er. Operativsystemet må da tilpasse seg, sånn at det kan løse alt med 64-bit. Det som gjorde Windows til en ekstrem suksess på 90-tallet, det var først og fremst at jeg hadde en veldig intuitivt og enkelt... Det gjorde at det etter hvert ble allemannseie å ha en PC.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0010", "start": 699.56, "end": 798.48, "token_count": 286, "text": "Operativsystemet må da tilpasse seg, sånn at det kan løse alt med 64-bit. Det som gjorde Windows til en ekstrem suksess på 90-tallet, det var først og fremst at jeg hadde en veldig intuitivt og enkelt... Det gjorde at det etter hvert ble allemannseie å ha en PC. Til å begynne med var operativsystemene ganske ustabile, mye mer enn Unix-serverne, som styrte alt på serversiden på denne tiden. Det var vel først rundt 2000 med XB at det virkelig fikk et bra og stabilt... Det som gjorde det, var at det kombinerte... Det hadde samme kjerne som endte 5-1. Man skrev rett og slett hele Operativstemme om helt fra scratch. Så det var et helt annet Operativstemme enn en DOS-operativstemme som kom 20 år senere. Så er Vindow 7 altså en veldig stabil versjon. Nå er det Windows 10 som gjelder, som kom for fem-seks år siden, 2015. Tidligere ser vi at det kom hele tiden nye versjoner med XB, Vista 7, Windows 8 osv.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0011", "start": 774.16, "end": 874.96, "token_count": 298, "text": "Så er Vindow 7 altså en veldig stabil versjon. Nå er det Windows 10 som gjelder, som kom for fem-seks år siden, 2015. Tidligere ser vi at det kom hele tiden nye versjoner med XB, Vista 7, Windows 8 osv. Og Windows 10. Men nå ser det ut som man bare har mindre endringer på Windows 10. Opprinnelig så hadde det med året å gjøre. Altså sånn... Windows 2000 kom i år 2000. Windows 10 var en god stund etter 2010. Men det som kanskje er viktigere, er at tidligere så lagde man, når man lagde software generelt, så hadde man sånne store releaser med store endringer. Nå kommer det en ny release av Windows. Dette programmet testet man og holdt på i et par år, og så fikk man en release. Nå er det mye mindre endringer i operativsystemene. Man tester ut endringene og releaser hele tiden. Eller mye oftere enn tidligere. Det samme gjelder Linux-distribusjoner og Linux-kjernen også. Man kommer helt inn med mange... Små endringer som kontinuerlig blir testet.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0012", "start": 855.68, "end": 953.44, "token_count": 298, "text": "Man tester ut endringene og releaser hele tiden. Eller mye oftere enn tidligere. Det samme gjelder Linux-distribusjoner og Linux-kjernen også. Man kommer helt inn med mange... Små endringer som kontinuerlig blir testet. Det er også en generell utvikling i software development. Her er det diverse av Windows ti versjoner. Jeg har ikke fått med den siste. Den kom i siste halvdel av 2020. Det er mulig det har kommet noen enda nyere der. ... og sjekke ut. Spørsmål i chatten om du anbefaler Linux eller Windows. Jeg har rett person til å spørre. Jeg anbefaler Linux. En av de få som alltid har kjørt Linux. Eller iallfall så lenge Linux har eksistert. Jeg kjører jo Windows også, og jeg har en gammel Mac. Men jeg anbefaler Linux fordi man... Har veldig stor frihet. Man kan mekke og hacke og legge inn hva som helst. Det har jo sine ulemper også. Det er klart, hvis man gjør for mye krumspring, så kan ting også gå galt. Men man har en veldig stor frihet, og så er alt åpen kildekode.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0013", "start": 930.0, "end": 1023.96, "token_count": 287, "text": "Har veldig stor frihet. Man kan mekke og hacke og legge inn hva som helst. Det har jo sine ulemper også. Det er klart, hvis man gjør for mye krumspring, så kan ting også gå galt. Men man har en veldig stor frihet, og så er alt åpen kildekode. Det har også endret seg når det gjelder... Tidligere var Windows helt lukket, men nå er det åpen kildekode. Hvilken Linux-distry du liker best... Der har jeg ikke så veldig sterke preferanser. Stort sett alltid brukt Ubuntu, for det er enkelt og greit. Og det er mye brukt. Debian har jeg brukt også, som er litt renere, på en måte. Ikke har så mye kommersiell og ekstern programvare. Men ellers har jeg tror Red Hat et veldig stabilt operativsystem. Det har jeg ikke brukt veldig mye. Vi brukte noe på serveren her. Når det gjelder Windows eller Linux, så er det klart det har hver sine bruksområder. Stort sett ikke så veldig mange som kjører Linux. Men det fungerer veldig greit å kjøre det i dag.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0014", "start": 1003.44, "end": 1094.56, "token_count": 287, "text": "Det har jeg ikke brukt veldig mye. Vi brukte noe på serveren her. Når det gjelder Windows eller Linux, så er det klart det har hver sine bruksområder. Stort sett ikke så veldig mange som kjører Linux. Men det fungerer veldig greit å kjøre det i dag. Det var mye verre sånn rundt 95, over 2000. Når du da kjørte Linux, så fungerte det veldig dårlig i samarbeid med Windows, f.eks. Men nå så går det ganske greit med alt, liksom... Man kan oppnå stort sett det samme med en Linux desktop som en Windows. Kanskje spill er fortsatt litt forskjellig, fordi Gui i Linux kjører i use of space. Mer om det senere. Men på den annen side så er det ikke så stor forskjell lenger på hva slags destop man har. Fordi i større og større grad så bruker man jo nettapplikasjoner som er nettbaserte. For å kunne kjøre alle applikasjoner som e-post og dokumentbehandling osv. Sånn rundt 2000 så var det virkelig sånn religionskrig mellom Windows og Linux osv.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0015", "start": 1062.56, "end": 1161.36, "token_count": 294, "text": "Men på den annen side så er det ikke så stor forskjell lenger på hva slags destop man har. Fordi i større og større grad så bruker man jo nettapplikasjoner som er nettbaserte. For å kunne kjøre alle applikasjoner som e-post og dokumentbehandling osv. Sånn rundt 2000 så var det virkelig sånn religionskrig mellom Windows og Linux osv. Men det har nok glattet seg litt ut etter hvert, fordi det ikke har så stor betydning når alt kjøres på nett. Ja... Microsoft har også en serverside. Når de første kom i 1993, så var de en veldig liten minoritet blant serverne. De aller fleste kjørte Unix-servere på den tiden, og etter hvert Linux. Men nå, særlig siden 2010, så har Windows-server blitt mer og mer brukt. Så nå kjører du Windows-server i mange serverrom. Ofte i kombinasjon med Linux-servere. Men fortsatt er nok Linux enda større. Vi skal se på noen tall senere, altså på serversiden, når det gjelder servere som drifter webservere over hele verden f.eks. Så er antallet Linux-servere litt større.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0016", "start": 1140.0, "end": 1245.2, "token_count": 292, "text": "Ofte i kombinasjon med Linux-servere. Men fortsatt er nok Linux enda større. Vi skal se på noen tall senere, altså på serversiden, når det gjelder servere som drifter webservere over hele verden f.eks. Så er antallet Linux-servere litt større. Noe som er viktig både på Linux- og Microsoft-siden, er virtualisering. Azure kjører Windows-servere i storskala virtuelt. Unix operativstemmer. Det er på en måte en helt annen verden. Det... Ja, men opprinnelig, sånn på 80-tallet, så var Unix på en måte der Linux var for ti år siden. Nytt og spennende og åpen kildekode og brukt på universiteter osv. Så utviklet det seg til kommersielle 64-bit-OS. Da var det filmer som IBM, Sun, HP, Silicon Graphics og andre som bygde egne Unix operativsystemer. De hadde egen hardware med helt egne institusjoner osv. Og så hadde de et eget operativsystem. Så hadde Sun spark-prosessorer og også sitt eget operativsystem. Så det var mange forskjellige operativsystem, og de konkurrerte med hverandre.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0017", "start": 1230.0, "end": 1333.8, "token_count": 298, "text": "De hadde egen hardware med helt egne institusjoner osv. Og så hadde de et eget operativsystem. Så hadde Sun spark-prosessorer og også sitt eget operativsystem. Så det var mange forskjellige operativsystem, og de konkurrerte med hverandre. Det endte etter hvert med at Linux tok over rollen til alle disse her, og nå er det veldig få av den type Unix-operativsystem som eksisterer. De som kjører ute i serverom, er Linux- eller Windows-servere. Det var disse frie Unix-kronene som etter hvert tok over. Som da var åpen kildekode-varianter av de store kommersielle Unix-systemene som var lukket. Og der var også lukket kildekode. Spesielt Linux er åpen kildekode og har tatt over veldig mye av... Det som er i selve verden. Spesielt sånn HP, high performance computing, så er alle de tusen raskeste high performance computerne bygd på Linux. Ja, Macoa er også delvis bygd på Linux. Mac-kjernen Darwin, den bygger delvis på friBSD. Så sånn sett kan du si at Mac har noe av Unix i seg. Og vi kan også se at f.eks. hvis du har en Mac,", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0018", "start": 1299.84, "end": 1409.98, "token_count": 299, "text": "så er alle de tusen raskeste high performance computerne bygd på Linux. Ja, Macoa er også delvis bygd på Linux. Mac-kjernen Darwin, den bygger delvis på friBSD. Så sånn sett kan du si at Mac har noe av Unix i seg. Og vi kan også se at f.eks. hvis du har en Mac, så kan du bare kjøre et vanlig skjell, et bærskjell. Så det er ganske tett integrert med Linux. Ikke så veldig stort forsøk. En liten gjennomgang av Linux-historie. Nå skal vi gå inn på et helt nytt tema, nemlig multitasking. Aller først skal vi for tredje gang se på CPU-løkken. Det er dette vi må ha med videre. CPU-en står da bare og om og om igjen kjører instruksjoner. Det vi skal se litt nærmere på nå, er interrupt request. For en gang iblant så kan det komme et fysisk interruptororkest, f.eks. ved at jeg taster på tastaturet sånn. Maskinen må da reagere på den inntastingen veldig hurtig. Og det som da skjer, er at CPU-en avbrytes i sin evige løkke.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0019", "start": 1387.56, "end": 1469.96, "token_count": 291, "text": "For en gang iblant så kan det komme et fysisk interruptororkest, f.eks. ved at jeg taster på tastaturet sånn. Maskinen må da reagere på den inntastingen veldig hurtig. Og det som da skjer, er at CPU-en avbrytes i sin evige løkke. Og så håndterer den da det signalet. Ofte bruker sepunden noen mikrosekunder på å fullføre det den er i gang med. Og så hopper den til en interrupt-rutine, som da sørger for at den piltasten som jeg trykket på, at den har en effekt. Men sepunden må avbrytes for å håndtere det signalet. Og da må man... Lagre adressen til neste institusjon og så hoppe til en interrupt-rutine. Det blir litt sånn som å gjøre et kall på en rutine, men her er det en fysisk interrupt som sendes inn, og så gjøres det da kall på rutinen. Og hvert interrupt, eller IRQ, har sin egen rutine som man da hopper til. Så det er én rutine hvis det kommer noe fra tastaturet, en annen hvis det kommer fra nettverket.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0020", "start": 1449.68, "end": 1553.06, "token_count": 295, "text": "men her er det en fysisk interrupt som sendes inn, og så gjøres det da kall på rutinen. Og hvert interrupt, eller IRQ, har sin egen rutine som man da hopper til. Så det er én rutine hvis det kommer noe fra tastaturet, en annen hvis det kommer fra nettverket. Hvis det kommer fra mikrofonen osv. Vi skal se på multitasking. For å forstå multitasking er det viktig å vite hvordan minne eller ramm er koblet sammen med prosesser. Vi skal senere fokusere på ramm... Det vi trenger å vite nå, er at det finnes flere deler i ramm som er tildelt en prosess. Dette som vi viser bildet her nå, det er én bit av ramm som er tilordnet én prosess. Operativsystemet er også en egen prosess, og vil også ha en egen del av rammen. Den viktigste biten er kanskje koden, eller teksten, som vi ser her nede. Unnskyld. Koden, det er da maskininstruksjonene som prosessen skal kjøre. Som ligger etter hverandre. Institusjon for institusjon. Så det typiske som skjer når en prosess kjører,", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0021", "start": 1530.0, "end": 1624.66, "token_count": 296, "text": "Den viktigste biten er kanskje koden, eller teksten, som vi ser her nede. Unnskyld. Koden, det er da maskininstruksjonene som prosessen skal kjøre. Som ligger etter hverandre. Institusjon for institusjon. Så det typiske som skjer når en prosess kjører, er at man starter på første institusjon til prosessen, og så løper den nedover. Men så har vi sett at vi hele tiden har variabler i programmet, som brukes og skrives til ram. Og da i heapen, som går fra koden her og oppover... Det er satt av masse plass til heapen, sånn at den kan utvide seg. For her kan man dynamisk legge inn nye variabler, nye RA f.eks. Det legges da på heapen. Stacken er et område hvor lokale variabler legges. F.eks. hvis du gjør et funksjonskall, så legger du på stacken returverdien fra det funksjonskallet, som at man vet hvor man skal tilbake. Så da er det enkelt å bare gå inn der, så plukker du opp returverdien, I tillegg er det vanlig å ha en MM-mapp,", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0022", "start": 1601.36, "end": 1705.44, "token_count": 284, "text": "F.eks. hvis du gjør et funksjonskall, så legger du på stacken returverdien fra det funksjonskallet, som at man vet hvor man skal tilbake. Så da er det enkelt å bare gå inn der, så plukker du opp returverdien, I tillegg er det vanlig å ha en MM-mapp, som er en avbildning av filer og devices inn i ramm. Men dette er igjen for at ting skal gå fortere. Så er det en kopi av noe av det som ligger på disk, sånn at man skal ha raskere aksess. Men først og fremst så er det kode, og heap er det vi snakker om. Her ligger alle variabler, og her ligger instruksjoner. Singeltasking.os. Tidligere så var det dette som var måten datamaskiner kjørte på. Man hadde bare... Man kjørte bare én oppgave av gangen. Enten var det brukerprogrammet som kjørte den, eller OS. Og da ser vi... For selv om det var singeltasking... Singeltasking betyr at det da er bare én prosess som kan kjøre av gangen.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0023", "start": 1676.56, "end": 1783.84, "token_count": 296, "text": "Man kjørte bare én oppgave av gangen. Enten var det brukerprogrammet som kjørte den, eller OS. Og da ser vi... For selv om det var singeltasking... Singeltasking betyr at det da er bare én prosess som kan kjøre av gangen. Det typiske som skjedde når man kjørte singeltasking OS... For at operativsystemet startet opp først. Og så hadde man da ett brukerprogram. Og når dette skulle kjøre, så satte OS i gang brukerprogrammet og kjøre. Og så hadde da Device-minne, Skjerm-minne osv., Brukerdata eller Keep og Stack. Det var da bare én prosess som kunne kjøre av gangen. Et sånt batch-computing... Du hadde kanskje en rein operasjon som kunne ta en halvtime, og da satte operativstemmet i gang denne operasjonen. Og så kjørte den til den var ferdig, og så kunne neste program starte. Men alle moderne systemer har multitasking, og det er da et system som kan... Den får N, et antall programmer, til å kjøre samtidig. Så sånn som her, så har vi et operativsystem som har to prosesser som kjører samtidig.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0024", "start": 1756.32, "end": 1857.76, "token_count": 289, "text": "Og så kjørte den til den var ferdig, og så kunne neste program starte. Men alle moderne systemer har multitasking, og det er da et system som kan... Den får N, et antall programmer, til å kjøre samtidig. Så sånn som her, så har vi et operativsystem som har to prosesser som kjører samtidig. Og det måten operativsystemet får til det på, det er at den deler opp tiden. Altså gir den litt tid til hver prosess, sånn at det ser ut som de kjører samtidig. Men egentlig så kjører de annenhver gang. Så ser det ut som de kjører samtidig, og det er rett og slett multitasking. Men vi ser... Hver prosess vil ha sitt eget område med heap og stack og program eller tekst eller kode. Og også IO-områder, altså for å snakke med disk, ta imot fra tastatur osv. Så hver prosess har da et sånt område på ramm. Multitasking er det systemet som operativsystemet bruker for å kjøre prosesser samtidig. Hovedideen her er at CPU-tiden blir delt opp i små biter.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0025", "start": 1821.08, "end": 1942.68, "token_count": 292, "text": "ta imot fra tastatur osv. Så hver prosess har da et sånt område på ramm. Multitasking er det systemet som operativsystemet bruker for å kjøre prosesser samtidig. Hovedideen her er at CPU-tiden blir delt opp i små biter. Og en liten bit av tiden man kan kjøre, er et hundredels sekund. Og da har man en såkalt round robin queue. Og så har man en hardware-timer. Skal se på dette i detalj. Hvert hundredels sekund så sender et interrupt-signal til Sippu. Og så starter man opp den første... Den første OS-institusjonen. Den legges da i... Og så lar OS hver prosess etter tur bruke CPU-en. CPU-en går da på rundgang mellom alle prosesser som ønsker å kjøre. Så det kan se ut noe sånt som dette her. Her har vi tre prosesser, P1, P2, P3, som kjører etter hverandre. Millisekunder er ett tusendels sekund. En typisk tid P1 kjører, er i ti millisekunder. Altså ett hundredels sekund. Men på ett hundredels sekund kan én prosess som står og kjører,", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0026", "start": 1909.0, "end": 2004.12, "token_count": 298, "text": "Her har vi tre prosesser, P1, P2, P3, som kjører etter hverandre. Millisekunder er ett tusendels sekund. En typisk tid P1 kjører, er i ti millisekunder. Altså ett hundredels sekund. Men på ett hundredels sekund kan én prosess som står og kjører, gjøre millioner, for ikke å si milliarder, av institusjoner. Millioner av institusjoner kan den gjøre. Og da får operativstemme, får dette til å se ut som om alle disse tre prosessene kjører samtidig. Men i virkeligheten, når du bare har én CPU, så er det bare én prosess som kjører av gangen. Så P1 kjører i 10 mil eller sekunder, så kommer det en Context Switch. Det er ganske omfattende. Da må OS lagre alt om denne prosessen her. Husker det er et levende liv som leves. Så alt som eksisterer om Prosess 1, det må lagres. Alle verdier i registeret, f.eks. Alt den har i ramm, er allerede lagret i ramm. Men all kontekst, all info om den prosessen, det må lagres.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0027", "start": 1980.0, "end": 2079.12, "token_count": 299, "text": "Husker det er et levende liv som leves. Så alt som eksisterer om Prosess 1, det må lagres. Alle verdier i registeret, f.eks. Alt den har i ramm, er allerede lagret i ramm. Men all kontekst, all info om den prosessen, det må lagres. Og så må all konteksten til P2, den må lastres inn. F.eks. hvilke verdier registerene hadde når P2 stoppet sist. Sånn fortsetter det. Man bytter med Context Switcher hele veien, og så kommer P1 inn igjen. Og så bytter de om å kjøre på denne nå. PCB er prosesskontrollblokk. Det er da en blokk i ramm som inneholder all den informasjonen som trengs om en... CPU-registeret f.eks. peker etter stack-prosess-tilstand. Om den venter på noe, f.eks. Alle prosesser har en payday. Eier, prioritet osv. Masse informasjon som må lagres om hver enkelt prosess. Den operasjonen som operativsteamet gjør for å bytte om på prosesser, CPU-skjeduling er å fordele CPU-tid mellom prosessene. Det kalles ofte også timesharing.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0028", "start": 2048.38, "end": 2143.88, "token_count": 288, "text": "Om den venter på noe, f.eks. Alle prosesser har en payday. Eier, prioritet osv. Masse informasjon som må lagres om hver enkelt prosess. Den operasjonen som operativsteamet gjør for å bytte om på prosesser, CPU-skjeduling er å fordele CPU-tid mellom prosessene. Det kalles ofte også timesharing. Ved hvert timer interrupt så vurderer operativsteamet om scheduleren skal kalles. For at ting skal gå fortere, så er det ikke alltid at man gjør et bytte. Som vi ser hvis vi går tilbake her. Hvis verken P1 eller P3 ønsker å bruke CPU-en, så kan det være at P2 bare fortsetter. For å få kontekstswitch-tiden til å gjøres så raskt som mulig, så er det noen ganger man bare sjekker. Nei, ok, ingen andre ønsker å kjøre. Da bare fortsetter P2. Men det er da scheduleren, som er en del av operativsystemet. Den avgjør hvilken prosess som skal velges, når den blir kalt. Det å switche fra én prosess til en annen, kalles en context switch.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0029", "start": 2120.36, "end": 2213.28, "token_count": 288, "text": "Nei, ok, ingen andre ønsker å kjøre. Da bare fortsetter P2. Men det er da scheduleren, som er en del av operativsystemet. Den avgjør hvilken prosess som skal velges, når den blir kalt. Det å switche fra én prosess til en annen, kalles en context switch. All informasjonen må da først lagres for P1 og så hentes inn for P2. Så dette tar tid, og det er litt overhead å gjøre denne context switchen. Her ser vi alt som skjer i en kontekst-switch. Hvis vi tenker oss at prosess 1 kjører, og så switcher vi til prosess 2. Da vil jo prosess 1 bruke CPU-en. Og midt inni en operasjon, så kan det være at AX er lik 5. Neste institusjon som skal utføres, kan kanskje være at AX skal legges ut igjen. Verdien på AX må da lagres for prosessen. Så det er en ganske komplisert prosess, en context stetch. Det er jo en masse andre register og informasjon som må lagres av prosessen. Men all denne informasjonen for prosess 1 lages da i ramm i PCB1.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0030", "start": 2190.0, "end": 2285.24, "token_count": 299, "text": "Verdien på AX må da lagres for prosessen. Så det er en ganske komplisert prosess, en context stetch. Det er jo en masse andre register og informasjon som må lagres av prosessen. Men all denne informasjonen for prosess 1 lages da i ramm i PCB1. Neste prosess som skjer, er at PCB2 må lastes inn. All informasjon fra PCB2 må da lastes inn i alle områder som beskriver den kjørende prosessen. Operativstemme ordner ikke alt dette her. For vi ser noe sånt som å laste inn alle verdier av institusjoner. Det blir litt vanskelig, for du må jo bruke registrene... for å kjøre programmet. Hvis operativstemme skulle gjøre det, så ville operativstemme også endre registerverdiene. Så der er det hardwareoperasjoner som kommer inn, som på én smell bare legger inn alle verdiene fra et lager. Sånn at dette blir én operasjon. Så kan man hoppe til neste institusjon. Da står det lagret PC et eller annet sted. Det siste som skjer etter at all informasjon er lagt til, er at da hopper man til programkontoren som kjører neste instruksjon.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0031", "start": 2262.06, "end": 2363.08, "token_count": 291, "text": "Sånn at dette blir én operasjon. Så kan man hoppe til neste institusjon. Da står det lagret PC et eller annet sted. Det siste som skjer etter at all informasjon er lagt til, er at da hopper man til programkontoren som kjører neste instruksjon. Ja... Multitasking i praksis... Vi skal se veldig kort på hvordan vi kan kjøre programmer, og hvordan det ser ut når vi kjører såkalt CPU. Veldig mange vanlige programmer bruker ikke noe særlig CPU. Det er ikke så mye de gjør. Ofte så venter de på noe input fra brukeren. En teksteditor f.eks. den venter hele tiden på klikk fra brukeren. Så finnes det andre CPU-avhengige prosesser. F.eks.... Et regneprogram. Det vil bruke CPU-en hele tiden. Så noe som man utnytter i en multitasking, er at veldig mange prosesser står egentlig bare og venter på CPU. Det gjør ikke så veldig mye. Men vi skal først se på såkalte CPU-avhengige prosesser. Det er prosesser som da hele tiden står og regner. Her er et enkelt cellscript.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0032", "start": 2342.88, "end": 2432.12, "token_count": 290, "text": "veldig mange prosesser står egentlig bare og venter på CPU. Det gjør ikke så veldig mye. Men vi skal først se på såkalte CPU-avhengige prosesser. Det er prosesser som da hele tiden står og regner. Her er et enkelt cellscript. Som egentlig bare er en løkke som står og legger sammen tall. Sum pluss er like i. Det gjør dette skriptet om og om igjen. Det er en typisk CPU-avhengig prosess. Som hele tiden vil prøve å bruke så mye CPU-en bare kan. For å bli fortest mulig ferdig. Hvis du har flere sånne prosesser på en enkelt CPU, så må de hele tiden bytte opp. Vi skal straks se på det. Men aller først, så har man også i tillegg prosesser som er IO-bound. Eller som er som hele tiden venter på og bruker input og output. Det er sånn som webbroser og teksteditorer og regneark og sånn som stort sett ikke gjør så veldig mye. Det fine med multitasking er at da kan man hele tiden kombinere... Den type programmer. For hvis man bare hadde en sekvensiell CPU,", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0033", "start": 2404.46, "end": 2494.28, "token_count": 296, "text": "Eller som er som hele tiden venter på og bruker input og output. Det er sånn som webbroser og teksteditorer og regneark og sånn som stort sett ikke gjør så veldig mye. Det fine med multitasking er at da kan man hele tiden kombinere... Den type programmer. For hvis man bare hadde en sekvensiell CPU, som hele tiden måtte gjøre først A og så B... Hvis man hadde to prosesser, så ville hele de oppgavene... Her er det én prosess A, som først gjør CPU, så bruker den IO, og så CPU. Hvis vi skal gjøre det etter hverandre, så måtte det pent vente på. Men her kan operativstem utnytte det at Prosess A trenger CPU. Men så gjør den noe i henne, kanskje den skriver til RAM eller leser fra disk. Og da kan jo Prosess B bruke CPU-en. Da blir den prosessa kastet ut. Og så hives Prosess B inn i CPU-en, og så bytter de på sånn. Og dette er multitasking, og det gjør at man... Selv på én CPU kan man ha en rekke prosesser som står og kjører samtidig, uten at den blir overbelastet.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0034", "start": 2466.04, "end": 2608.5, "token_count": 296, "text": "Og da kan jo Prosess B bruke CPU-en. Da blir den prosessa kastet ut. Og så hives Prosess B inn i CPU-en, og så bytter de på sånn. Og dette er multitasking, og det gjør at man... Selv på én CPU kan man ha en rekke prosesser som står og kjører samtidig, uten at den blir overbelastet. Jeg har brukt mye tid her, men hvis dere holder ut, så skal jeg veldig kort kjøre en demo av multitasking på en server. Skal vi se. Så da... Hopper vi hit... Oi. Nei, det fungerte ikke så bra. Da får vi... Et lite øyeblikk. Der, kanskje. Der var vi inne. Ok, nå... Vi kan rydde opp litt her. Nå er jeg inne på én server. Og så skal jeg bare kjøre en... Jeg har en liten regnejobb. Har et program som heter Adopt-Alt. Som er CPU-avhengig. Og som bare står og bruker CPU. Da kan jeg samtidig kjøre Topp. Da ser vi... Topp viser nå øverst en linje med det programmet som kjører. Vi kan også ta tiden på programmet med time.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0035", "start": 2581.04, "end": 2681.32, "token_count": 297, "text": "Som er CPU-avhengig. Og som bare står og bruker CPU. Da kan jeg samtidig kjøre Topp. Da ser vi... Topp viser nå øverst en linje med det programmet som kjører. Vi kan også ta tiden på programmet med time. Jeg starter på nytt, og da ser vi øverst der... Så er det en prosess som står og kjører. Og den ser vi bruker 100 % CPU. Hvis jeg taster tallet én i topp, så ser vi at det kommer fram én CPU her oppe. Og her er det bare CPU0. Så dette er en server som bare har én enkelt CPU. Det er det nesten umulig å få tak i. Altså alle dagens servere eller CPU-er har minst to CPU-er. Denne her har egentlig åtte CPU-er, men jeg har bare skrudd av de andre for å vise denne demoen her. Så det man kan gjøre, det er å kjøre... Prøv se hva som skjer. Jeg kjører nå to regneoppgaver samtidig. Da legger jeg henne i bakgrunnen sånn... To stykker. Og da ser vi... Her er det nå to prosesser som heter adopt out.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0036", "start": 2651.72, "end": 2749.1, "token_count": 286, "text": "men jeg har bare skrudd av de andre for å vise denne demoen her. Så det man kan gjøre, det er å kjøre... Prøv se hva som skjer. Jeg kjører nå to regneoppgaver samtidig. Da legger jeg henne i bakgrunnen sånn... To stykker. Og da ser vi... Her er det nå to prosesser som heter adopt out. Og vi ser de deler nå likt på CPU-en. Disse to her... Her er det en rad som sier CPU. Her ser vi hver av de for 50 %. Hvis jeg nå starter en til, så ser vi... Da kommer den inn også. Men da får hver av de 33 %. Da deler de likt på den ene CPU-en. Sånn fungerer multitasking når man bare har én CPU. De deler da på CPU-en. De kjører halvparten hver, men de kjører ca. ett hundredels sekund hver. Og så bytter de på hvem som kjører. Hele tiden bytter operativstemme frem og tilbake mellom de to prosessene. Så skal vi veldig kort se på hva som skjer hvis jeg nå starter opp én CPU til på denne serveren.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0037", "start": 2726.06, "end": 2825.92, "token_count": 286, "text": "Og så bytter de på hvem som kjører. Hele tiden bytter operativstemme frem og tilbake mellom de to prosessene. Så skal vi veldig kort se på hva som skjer hvis jeg nå starter opp én CPU til på denne serveren. Jeg kan gjøre det. Men nå startet jeg opp en server til. Nei, en CPU til. Hvis jeg nå taster én, så ser vi at jo, her dukker det opp to CPU-er. Så nå har denne serveren tilgang til to CPU-er. Og hva skjer da hvis jeg starter to programmer samtidig? Jo, da ser vi her oppe... Så ser vi at... Nå jobber disse prosessene på hver sin CPU. Den får 100 % på den ene CPU-en, og den får 100 % på den andre. Men da vil det bli sånn at hvis jeg nå starter tre prosesser av den typen, så får de ca. 67 % hver. Da fordeler de CPU-tiden seg imellom på den måten. Og det går også an å se nøyaktig hvordan det skjer. Skal vi se om jeg er rask nok til å få til det. La oss si jeg starter tre prosesser her.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0038", "start": 2796.96, "end": 2893.4, "token_count": 298, "text": "så får de ca. 67 % hver. Da fordeler de CPU-tiden seg imellom på den måten. Og det går også an å se nøyaktig hvordan det skjer. Skal vi se om jeg er rask nok til å få til det. La oss si jeg starter tre prosesser her. Så ved å taste F så kan jeg gå inn i Topp. Jeg tastet nå F. Og så kan jeg gå ned og finne Last Use CPU. Så ser vi helt ytterst her, så har vi fått et nytt felt hvor det står 1.0.0. Nå var jeg litt sein, jeg kan starte på nytt. Starter nå tre A.8.-prosesser. Helt til høyre her så ser vi en null og en ener. Og da ser vi at de bytter på. Noen ganger så kjører begge på CPU1 og én på CPU0. Og så andre ganger så kjører begge på CPU0. Typisk så kjøres da én prosess på hver av CPU-ene, og så vil den tredje prosessen bytte mellom. Nei, det er ikke helt riktig. Fordi operativstemme har en scheduler som kalles fair scheduler. Så når tre prosesser kjøres på denne måten her...", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0039", "start": 2871.28, "end": 2974.92, "token_count": 292, "text": "Typisk så kjøres da én prosess på hver av CPU-ene, og så vil den tredje prosessen bytte mellom. Nei, det er ikke helt riktig. Fordi operativstemme har en scheduler som kalles fair scheduler. Så når tre prosesser kjøres på denne måten her... Det som i praksis skjer, er at alle tre bytter likt. Hver prosess får ca. to tredjedeler CPU-tid, hvor den har tilgang til CPU-tid. Og på den måten får de i snitt 67 % CPU-tid. OK. Da tenker jeg dere er passe slitne, så da skal vi slutte der. Men det er noen oppgaver denne uken som går ut på dette her. Nå kjørte jeg et CPU-program, men man kan også kjøre regn her. Det er det regneprogrammet jeg viste. Det vil oppføre seg på samme måte. Hvis jeg kjører et par regneprogram, så får de hver sin CPU. I snitt 67 % CPU hver. Fordi operativsystemene da bytter om på hvilken CPU de bruker. Sånn teoretisk så vi i dag mest på operativsystemer hvordan de kjører på én CPU.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0040", "start": 2944.88, "end": 3042.04, "token_count": 295, "text": "Hvis jeg kjører et par regneprogram, så får de hver sin CPU. I snitt 67 % CPU hver. Fordi operativsystemene da bytter om på hvilken CPU de bruker. Sånn teoretisk så vi i dag mest på operativsystemer hvordan de kjører på én CPU. Men det er klart operativsystemet også da kunne gå inn og fordele prosesser på de forskjellige CPU-ene, som vi så vidt så på her. Så i oppgaven denne uken så skal dere teste ut dette her. Både på studio SSO og kjøre regnejobber. Men også på... Også på de Linux-VM-ene. Og der er det litt annerledes, for hvis på Linux-VM-ene... Hvis dere gjør topp der og taster én, så vil dere se at dere har noe sånt som 96 CPU-er. Men de konteinerne dere har, er satt opp sånn at de bare får tilgang på to CPU-er. Eller i snitt så får de så mye CPU-tilgang. Det er da begrenset på en annen måte. Ikke sånn som med fysiske servere, hvor du har fire CPU-er, og de er de du har.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0041", "start": 3017.88, "end": 3106.66, "token_count": 287, "text": "Men de konteinerne dere har, er satt opp sånn at de bare får tilgang på to CPU-er. Eller i snitt så får de så mye CPU-tilgang. Det er da begrenset på en annen måte. Ikke sånn som med fysiske servere, hvor du har fire CPU-er, og de er de du har. Men med virtuelle maskiner og med konteinere så kan man... Da kan man tildele et antall sepur. Med dockercontainere blir man tildelt en prosentdel. De dere har, er tildelt sånn at de får i snitt to sepur å kjøre på. Mens på studiesesong har hver VM fire sepur som man kan kjøre på. I oppgavene denne uken. Da er spørsmålet om dette var en CPU-avhengig prosess. Kunne gjentatt noen prosesser som ikke er så avhengige av CPU-er. Ja, det er det. Egentlig de fleste prosesser er ikke avhengige av CPU-er. De står bare og venter på at noe skal skje, sånn som en teksteditor. Hvis du skriver veldig fort, så får den kanskje hvert ti tegne sekunde.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0042", "start": 3088.38, "end": 3188.12, "token_count": 296, "text": "Kunne gjentatt noen prosesser som ikke er så avhengige av CPU-er. Ja, det er det. Egentlig de fleste prosesser er ikke avhengige av CPU-er. De står bare og venter på at noe skal skje, sånn som en teksteditor. Hvis du skriver veldig fort, så får den kanskje hvert ti tegne sekunde. At det skjer hvert tiendedels sekund... Da kan man gjøre en million instruksjoner i mellomtid. F.eks. en webbroser også. Selv om det er en del prosessering den må gjøre, så bruker den ikke 100 % CPU. Det kan man se på topp her. På den Linux-maskinen som kjører. Sånne som R-server. Bruker nesten ikke noe CPU. Så en gang iblant kommer det opp noen programmer som bruker litt CPU. Men hvis du ser på sånne som OBS Studio... Vi kan se på den maskinen jeg sitter på. Ja... Nå får jeg ikke opp det. Vi kan se på det neste gang. Litt mer i det... Vi skal fortsette å kjøre prosesser og se på multitasking. Men det ser vi at vi har brukt et kvarter over tiden. Så nå trenger vi en pause.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0043", "start": 3167.88, "end": 3242.6, "token_count": 207, "text": "Ja... Nå får jeg ikke opp det. Vi kan se på det neste gang. Litt mer i det... Vi skal fortsette å kjøre prosesser og se på multitasking. Men det ser vi at vi har brukt et kvarter over tiden. Så nå trenger vi en pause. Så da stopper vi der, og så ser vi mer på multitasking neste uke. Jo, jeg fikk i pausen beskjed av... At Ine er sykemeldt... Så hun er ikke her i dag, men det vil... Likevel så har vi to studentassistenter. Jeg håper Berrecutt er her i dag. Kan du høre meg, Berrecutt? Nei, vi får se. Han dukker opp. Jeg skal i hvert fall lage breakout rooms. Meg og to studenter, så gå inn der og spør om hjelp hvis dere står fast. Men da stopper vi der.", "source": "lecture"}
{"lecture_id": "linux5del3", "chunk_id": "linux5del3_0000", "start": 0.0, "end": 89.76, "token_count": 285, "text": "Jeg skal nå se på command and fine, som kan brukes til å finne filer på Linux-systemet. Så syntaksen til fine er at man først må si hvor man ønsker å finne filene. Her sier jeg prikk, altså i mappen jeg står i. Så må man spesifisere hva slags filer man ønsker å finne. Jeg skal prøve å finne alle dotsy filer, alle som begynner på et eller annet og slutter på c. Så kan jeg prøve å spesifisere litt mer spesifikt hvilken mappe jeg skal lete i. Her finner jeg alle i OS-mappen. Og her finner jeg alle nede i Old i OS-mappen. Man kan også spesifisere nøyaktig filnavnet på denne måten. Da kan jeg f.eks. si alle filer på mitt hjemmeområde som heter sum.c. Da finner jeg alle de der. Det finnes en annen metode som heter locate. Og hvis jeg bruker kommandoen locate sum.c, så finner jeg alle filer på systemet som heter noe som inneholder sum.c. Ikke nødvendigvis nøyaktig sum.c.", "source": "lecture"}
{"lecture_id": "linux5del3", "chunk_id": "linux5del3_0001", "start": 67.32, "end": 168.4, "token_count": 277, "text": "Da finner jeg alle de der. Det finnes en annen metode som heter locate. Og hvis jeg bruker kommandoen locate sum.c, så finner jeg alle filer på systemet som heter noe som inneholder sum.c. Ikke nødvendigvis nøyaktig sum.c. Den locate-kommandoen er avhengig av at det er en oppdatert locate-database. Og den kan da være litt kjappere, mens fine funker alltid. Og den letter helt fra scratch gjennom alle mappene. En annen måte å bruke fine på som er veldig nyttig, det er å bruke fine i forhold til tid. når en fil har vært endret. F.eks. hvis du vet at du har en fil som har blitt endret på et eller annet tidspunkt, så kan man spesifisere det. Og da er det en opsjon som heter \"-newer\", newer-MT. MT står her for Modified Time. Så skal vi finne da filer som er... Endret tidligere enn gitt dato. Eller det vil si... Med nyere MT så vil du da finne filer som er endret etter denne datoen.", "source": "lecture"}
{"lecture_id": "linux5del3", "chunk_id": "linux5del3_0002", "start": 135.66, "end": 250.04, "token_count": 297, "text": "Og da er det en opsjon som heter \"-newer\", newer-MT. MT står her for Modified Time. Så skal vi finne da filer som er... Endret tidligere enn gitt dato. Eller det vil si... Med nyere MT så vil du da finne filer som er endret etter denne datoen. Så vi kan f.eks. se... 8. eller 6. februar... Oi. 6. februar. Jeg skal finne alle filer som er modifisert etter det. Det er litt vanskelig å se når det er modifisert, så man kan legge på en minus LS, som kan legge på alle fine kommandoer. Da ser jeg her eksplisitt at dette er bare filer som er etter 6.2. Så jeg kan f.eks. gjøre sånn. Og da finner jeg alle fra 8.2. Så nå kan jeg spesifisere tidspunktet. La oss si jeg sier alle som er nyere enn dette tidspunktet. Alle filer som er nyere enn 8.2.2021 klokka 22.00. Da ser vi at jeg får akkurat bare disse her fra 22.06,03 og 06. Etter 22.00 8.2.", "source": "lecture"}
{"lecture_id": "linux5del3", "chunk_id": "linux5del3_0003", "start": 224.88, "end": 322.7, "token_count": 287, "text": "La oss si jeg sier alle som er nyere enn dette tidspunktet. Alle filer som er nyere enn 8.2.2021 klokka 22.00. Da ser vi at jeg får akkurat bare disse her fra 22.06,03 og 06. Etter 22.00 8.2. Så kan det kanskje være at du vet et tidspunkt som du gjorde noen endringer. Og da kan det være en... Da kan man legge inn... Det skal være nyere enn dette tidspunktet. Enn for eksempel... Vi kan si at det skal være nyere enn 20 klokka 8. Og så skal det ikke være nyere enn 22. Og da ser jeg at da får jeg alle tidspunkt som er mellom dette, klokka 208. februar, og klokka 22. Så den her er 2023-2116. Så disse tre filene ble modifisert mellom de to tidspunktene. Så hvis man da vet om at man har gjort noen endringer på et helt spesielt tidspunkt, så kan man med denne enkle, lille konstruksjonen så kan man finne nøyaktig de filene.", "source": "lecture"}
{"lecture_id": "linux12del11", "chunk_id": "linux12del11_0000", "start": 0.0, "end": 132.44, "token_count": 284, "text": "GetDate gir datoen nå. Eller dato, det gir dato og klokkeslett. Dette er et såkalt datetime object. Igjen så kan man sende dette til getmember og se hva det egentlig inneholder. Da ser vi det inneholder en rekke properties, sånn som year og... I tillegg har det en rekke metoder, f.eks. add og add days. Det kan være nyttig, for da kan man på en enkel måte legge til en dag eller legge til en time. Sånn generelt, på samme måte som andre kommandolett, så kan man da f.eks. Skrive time og year på den måten. Ja. Så kan man også definere... definere datoer. Det vi skal gjøre nå, er å definere en dato, og så skal vi etterpå dra ut dette som et objekt. Og så skal vi se på hvordan vi kan manipulere på dette. Men la oss si vi ønsker å legge inn en dato med et visst år. 2017... med måned fem. Og dag 17. Get day, hva er feil...? Get date. Og da ser vi at vi får 17. mai 2017, som da var på en onsdag.", "source": "lecture"}
{"lecture_id": "linux12del11", "chunk_id": "linux12del11_0001", "start": 90.0, "end": 229.82, "token_count": 296, "text": "Men la oss si vi ønsker å legge inn en dato med et visst år. 2017... med måned fem. Og dag 17. Get day, hva er feil...? Get date. Og da ser vi at vi får 17. mai 2017, som da var på en onsdag. Så vi får et klokkeskjøtt der, 11.55, men det er fordi jeg... Vi får da klokkeskjøtt som er nå. Og la oss si jeg ønsker klokka 16.01 på 17. mai. Så kan jeg sette den helt nøyaktig. Sånn, f.eks. Da kan jeg spesifisere en dato. Helt spesifikt. Det fins mange litt lettere måter å gjøre det på. Definerer det samme ved 17.0.2017 klokka... 16.00. Sånn. Igjen så får vi riktig dato. Men nå skal vi prøve å... Siden dette er objekter, så skal vi prøve å manipulere litt på objektene. Så vi kan starte opp med f.eks. å si at no - det er get date. Da har vi et objekt som vi ikke kan ta ut year på, men year. Sånn.", "source": "lecture"}
{"lecture_id": "linux12del11", "chunk_id": "linux12del11_0002", "start": 200.32, "end": 341.28, "token_count": 299, "text": "Men nå skal vi prøve å... Siden dette er objekter, så skal vi prøve å manipulere litt på objektene. Så vi kan starte opp med f.eks. å si at no - det er get date. Da har vi et objekt som vi ikke kan ta ut year på, men year. Sånn. År 2020. Men dette objektet her... Det kan vi nå manipulere på. Vi så vi hadde en metode som het ad. Så her kan vi lett da lage... Lage i går, for i går det vil da være... now. Og så kan vi da bruke metoden ad... ad days. Nå kunne jeg tabbe gjennom hvilke metoder jeg har. Jeg startet med Nav, bare. Hvis jeg begynner å tabbe da, så går jeg gjennom alle propertiste metoder. Men jeg ønsker et add og mer spesifikt add days. Hvis jeg skal ha yesterday, så må jeg adde minus én da. Så ser vi at det var... Det var i går. Så kan jeg jo ta en tomorrow. Det blir da lørdag. Så kan jeg også... Legge på en time... Nei, jeg må jo være 17-19 nå. Skal vi se hvis jeg kan den oppå.", "source": "lecture"}
{"lecture_id": "linux12del11", "chunk_id": "linux12del11_0003", "start": 300.0, "end": 392.68, "token_count": 214, "text": "Så ser vi at det var... Det var i går. Så kan jeg jo ta en tomorrow. Det blir da lørdag. Så kan jeg også... Legge på en time... Nei, jeg må jo være 17-19 nå. Skal vi se hvis jeg kan den oppå. Nei. Add over. Den finnes tydeligvis ikke. Så da må jeg begynne å lete i metodene for å finne ut hvordan man gjør det. Da... En måte kan være å... ... å tabbe igjennom. En annen måte kan være å se i get numbers. Men her tabbet jeg igjennom, og så ser jeg add. Det var ikke add over, men det var add overs. Så da kan jeg prøve å legge til én time. Og dollar ho nå vil da være om én time. Så på den måten så er det veldig lett. Lett å manipulere på...", "source": "lecture"}
{"lecture_id": "linux5del12", "chunk_id": "linux5del12_0000", "start": 0.0, "end": 93.78, "token_count": 284, "text": "Vi skal nå se på et vanlig problem når man bruker vile og read til å løpe gjennom data spesielt fra en kommando og ikke fra en fil. Så la oss si vi prøver og... eller ønsker å ta alle PID-ene fra PSA og X og legge inn i et radi. Å få ut PID-ene fra AoX på er å bruke AUK. Og sende det da til et program med AUK. Jeg har en litt spesiell syntaks på denne måten. Men inni her så kan man da printe ut elementet, f.eks. element 3. Eller i vårt tilfelle ønsker vi å få ut PID. Så det vil printe ut element nummer to. Når man skal gjøre noe sånt, så kan det ofte være lurt å teste... Er det dette som er forut? Ja, da ser vi den virker. Det gir meg payday-en. Så jeg skal da pipe det til en Wild-konstruksjon, hvor jeg skal lese linje for linje payday. Dette vil da inne i wildlucken, så vil dollar-payday nå være payday-en. Så kan jeg kanskje ønske å... Så trenger jeg en indeks til r-øyet.", "source": "lecture"}
{"lecture_id": "linux5del12", "chunk_id": "linux5del12_0001", "start": 68.72, "end": 178.6, "token_count": 294, "text": "Så jeg skal da pipe det til en Wild-konstruksjon, hvor jeg skal lese linje for linje payday. Dette vil da inne i wildlucken, så vil dollar-payday nå være payday-en. Så kan jeg kanskje ønske å... Så trenger jeg en indeks til r-øyet. Så kan jeg si OK, la meg lage et payday-r-øy. Og her kan jeg da legge inn payday-r av dollar i. Det vil jeg skal være lik dollar payday. Så da får jeg et r-øy med alle payday-ene. Jeg kan f.eks. prøve å skrive ut antall elementer i dette jeg har laget. Antall elementer... Og det er jo da igjen en spesiell konstruksjon. Må ha P i D, R og så alfakrøll. Dette ble fortsatt ikke helt riktig. Vi må også ha krøllparenteser. Som vi alltid må ha når vi skal skrive ut vr-et. Dette burde da gi antall elementer. Så kan vi save og prøve å kjøre det. Det heter.pipe.chat. Og vi kjører det, men antall elementer kommer ikke ut. I første omgang så ser vi at vi har én ting som mangler.", "source": "lecture"}
{"lecture_id": "linux5del12", "chunk_id": "linux5del12_0002", "start": 153.82, "end": 244.8, "token_count": 286, "text": "Dette burde da gi antall elementer. Så kan vi save og prøve å kjøre det. Det heter.pipe.chat. Og vi kjører det, men antall elementer kommer ikke ut. I første omgang så ser vi at vi har én ting som mangler. Vi kan ha en hashtag for å få ut antall elementer. Selv om vi prøver da igjen, så sier vi det hjelper. Men antall elementer er null. Så det virker som dette er et tomt array. Og det virker litt merkelig, så vi kan prøve å gå inn i wirelocken. Nå skal vi se... Har vi ikke fått ut noen elementer her? Og så kan vi se om vi får ut noe. Ja, og da viser det seg... Vi får ut verdier her, så et antall elementer burde vært 311. Men her er det et problem, og det er det vanlige problemet som oppstår når man prøver å pipe noe fra en prosess, altså opput fra en prosess inn til en sånn valgkonstitusjon. Så vil denne valgkonstitusjonen, Den vil lage et eget subskjell, og alt som foregår inni her,", "source": "lecture"}
{"lecture_id": "linux5del12", "chunk_id": "linux5del12_0003", "start": 228.36, "end": 310.0, "token_count": 297, "text": "som oppstår når man prøver å pipe noe fra en prosess, altså opput fra en prosess inn til en sånn valgkonstitusjon. Så vil denne valgkonstitusjonen, Den vil lage et eget subskjell, og alt som foregår inni her, foregår i det skjellet, og så avsluttes skjellet. Og etterpå så vil man ikke da ha de datakonstruksjonene, den datastrukturen, som ble lagd der inne. I dette tilfellet et ri. Så etterpå så har ikke det ri noen verdi. Hvis man gjør tilsvarende med en fil, og sender verdien av en fil inn, så fungerer det. Det første er å lage en temporær fil. Istedenfor å pipe til konstruksjonen, så kan vi sende inn filen til konstruksjonen på denne måten. Hvis vi nå prøver å kjøre, så ser vi at vi får ut antall elementer 310. Som er det riktige antallet elementer. Da kan vi altså fjerne denne her. En annen konstruksjon som kan brukes i tilfeller som dette, det er å i stedet for å lage", "source": "lecture"}
{"lecture_id": "linux5del12", "chunk_id": "linux5del12_0004", "start": 284.78, "end": 380.6, "token_count": 281, "text": "Hvis vi nå prøver å kjøre, så ser vi at vi får ut antall elementer 310. Som er det riktige antallet elementer. Da kan vi altså fjerne denne her. En annen konstruksjon som kan brukes i tilfeller som dette, det er å i stedet for å lage en temporær fil, så har vi en konstruksjon som ser sånn ut. De tre tegnene her utgjør en såkalt prosess substitution. Bytter ut den prosessen og avput-en med en fil. Denne konstruksjonen vil tilsvare at man temporært legger dataene i en fil, og så sender videre. Dermed kan man gjøre dette direkte. Hvis jeg nå legger inn den prosessen uten å bruke en fil, så vil dette tilsvare at man piper til vial-prosessen. Men nå vil dette her se ut som en fil. Og dermed så fungerer det. Så kan jeg prøve igjen og serve den, altså kjøre det. Og da ser vi at det fungerer som det skal. Riktignok ble av tallelementer én mindre, men her er det...", "source": "lecture"}
{"lecture_id": "linux5del12", "chunk_id": "linux5del12_0005", "start": 360.0, "end": 425.76, "token_count": 160, "text": "Og dermed så fungerer det. Så kan jeg prøve igjen og serve den, altså kjøre det. Og da ser vi at det fungerer som det skal. Riktignok ble av tallelementer én mindre, men her er det... Dette er dynamisk og flytende, så det kan endre seg fra gang til gang. I dette tilfellet kan det også være fordi man får et ekstra element i prosesslistingen når man skriver ut til en temporær film. Men uansett - dette vil gjøre at man kan løpe gjennom r-ene og direkte legge output Inn i RE og få ut PID-ene slik man ønsker.", "source": "lecture"}
{"lecture_id": "linux5del7", "chunk_id": "linux5del7_0000", "start": 0.0, "end": 78.0, "token_count": 169, "text": "Man kan lese input fra bruker med kommandoen read. Så skal jeg lage et lite skrift som bruker den. Og da kan man først skrive ut at man - la oss si - ønsker et svar. På den måten. Og så kan man lese det svaret med read. Svar vil da legge svaret inn i en variabel... svar. Og så kan man skrive at du svarte dollar... dollar svarer. Så kan vi prøve å kjøre det skriptet. Da ble jeg bedt om å svare. Du svarte svaret kommer ut, da. Så kan man forbedre denne litt ved å legge til minus N. Da ser man at input kommer direkte sånn.", "source": "lecture"}
{"lecture_id": "os7del11", "chunk_id": "os7del11_0000", "start": 0.0, "end": 106.24, "token_count": 292, "text": "75 % av dere har gått for 22,5 sekunder, og det er veldig bra, for det... Det er i hvert fall det jeg trodde svaret skulle bli. Så vi kan gjøre to ting. Vi kan kjøre det her. Og mens det står og kjører, så kan vi prøve å regne på det. Så utgangspunktet... Det var at vi hadde... Fem prosesser. Prosesser... Og hver av de bruker 18 sekunder. Og så har vi da fire CPU-er som de fem prosessene skal fordeles på. De vil jo da kjøre parallell, men så må nummer fire settes på en av de andre sippuene. Og da, som vi så tidligere, så er dette bare et øyeblikksbilde. Man bytter da på hvilke sippuer som har to prosesser av gangen. Sånn at totalt sett så fordeles tiden likt. Og da... Ja, det kan være litt sånn... Det kan være flere måter å regne det ut på. Men det som jeg tenker kanskje er den enkleste måten, er å bruke andre måter. Det er at hvis du har fem prosesser som skal kjøre i 18 sekunder,", "source": "lecture"}
{"lecture_id": "os7del11", "chunk_id": "os7del11_0001", "start": 84.64, "end": 189.12, "token_count": 289, "text": "Og da... Ja, det kan være litt sånn... Det kan være flere måter å regne det ut på. Men det som jeg tenker kanskje er den enkleste måten, er å bruke andre måter. Det er at hvis du har fem prosesser som skal kjøre i 18 sekunder, så trenger de... Hver av de trenger 18 CPU-sekunder. Så vi kan regne oss i 5 CPU ganger 18 sekk... CPU-sekunder trenger man for å utføre de jobbene ferdig. Og 5 ganger 18... 5 og 48... Det skulle bli 90 CPU-sekk. Og da... Når du har 90 CPU-sekunder, og så skal du dele det på 4 CPU-er. De må jo fordeles på fire sepuer, for hvis alle de fire sepuene kjører så mye de kan av de 90 sepu-sekundene hele tiden, så vil det bli fordelt på den måten der. Og dermed får man 90 fjerdedelssekund. Og 90 fjerdedels er 45,5... Og det blir da 22,5 sekunder. Så det er derfor... veldig bra at tre fjerdedeler av dere", "source": "lecture"}
{"lecture_id": "os7del11", "chunk_id": "os7del11_0002", "start": 158.8, "end": 258.96, "token_count": 292, "text": "så vil det bli fordelt på den måten der. Og dermed får man 90 fjerdedelssekund. Og 90 fjerdedels er 45,5... Og det blir da 22,5 sekunder. Så det er derfor... veldig bra at tre fjerdedeler av dere har kommet fram til at dette bør ta 22,5 sekunder. Så kan vi også se på fasiten. Jeg tror ikke den er helt 22,5 sekunder. Men vi kan se... Ja, vi ser... Her var det faktisk ikke så veldig fair. Den stopper, ser du det, sultne. Her var det litt forskjell i CPU-bruken. Det burde jo vært 80 %, men den her hadde faktisk fikk 88 %. Så den var nede i 21 sekunder, mens denne fikk bare 76 og var oppe i 24. Så her var ikke schedulerne helt feil. Det varierer litt også om det er mye annen trafikk på. Men vi ser røffelig i snitt så ville blitt 22,5 hvis operativstemma hadde klart å fordele dette helt likt. Men her kan vi også se et eksempel på det spørsmålet som kom tidligere.", "source": "lecture"}
{"lecture_id": "os7del11", "chunk_id": "os7del11_0003", "start": 235.84, "end": 297.0, "token_count": 182, "text": "Det varierer litt også om det er mye annen trafikk på. Men vi ser røffelig i snitt så ville blitt 22,5 hvis operativstemma hadde klart å fordele dette helt likt. Men her kan vi også se et eksempel på det spørsmålet som kom tidligere. Her ser vi at hvis man legger sammen user og system, så blir jo ikke det real i det hele tatt. Og i hvert fall ikke her. Dette totalen her er hvor mye CPU-tid den prosessen her trenger. Og dette tallet her kommer da rett og slett fram for at... Dette er i hvor mange prosent den faktisk hadde. Og dermed så tar realtiden mye lengre. Den blir da 24 sekunder.", "source": "lecture"}
{"lecture_id": "os7del16", "chunk_id": "os7del16_0000", "start": 0.0, "end": 122.26, "token_count": 290, "text": "Jo, vi har sett at operativsystemet fordeler prosesser på CPU-er. Men nå skal vi se på en metode vi kan bruke for å selv spesifisere hvilken CPU en oppgave skal kjøres på. Og det kan vi gjøre med TaskSet. Og da kan vi... Men programmet Tasset er et verktøy som gjør at vi kan si... Tasset minus C null sier plasser den følgende jobben på CPU0. Så når jeg kjører denne regnejobben her nå, så sier jeg:\"Den skal så på CPU0.\" Og kanskje... Ja... Hvis vi kjører AgeStop, kan vi kjøre Toppe og så skru på Last Used CPU. For å se hvor den kjører.  Der har vi med Last Jus CPU. Så sier jeg start den på tasset, kjør den på prosessor 0, og da ser vi - den kommer på prosessor 0. Hvis jeg i stedet sier kjør den på prosessor 1, så ser vi - da starter den å kjøre på 1. Vi gjør noen interessante eksperimenter, for da kan vi eksplisitt saye at nå vil jeg kjøre begge regnejobbene på prosessor 1.", "source": "lecture"}
{"lecture_id": "os7del16", "chunk_id": "os7del16_0001", "start": 100.34, "end": 216.82, "token_count": 300, "text": "Hvis jeg i stedet sier kjør den på prosessor 1, så ser vi - da starter den å kjøre på 1. Vi gjør noen interessante eksperimenter, for da kan vi eksplisitt saye at nå vil jeg kjøre begge regnejobbene på prosessor 1. La oss bruke adatat, som er litt raskere. La oss si nå at jeg skal starte to regnejobber. Men så vil jeg da time task-sett. Og så vil jeg sette begge på null. Sånn. Og nå vil begge de to regnejobbene kjøre på... ... på samme prosessor. Og da ser vi... Da brukte de... Da får de bare 50 % CPU. Fordi da har jeg eksplisitt satt dem på den samme CPU-en. Hvis jeg i stedet hadde satt de på CPU1 og -2 på den måten, da ville de to regnejobbene kjørt på hver sin CPU. Da gjør vi sånn som operativsystemet ville ha gjort det. Satt de på hver sin CPU, og det går da dobbelt så fort. Helt til slutt så kan vi se litt på... Se litt på hvordan man kan... Finne ut hvilke CPU-er som tilhører hvilken...", "source": "lecture"}
{"lecture_id": "os7del16", "chunk_id": "os7del16_0002", "start": 186.12, "end": 295.28, "token_count": 295, "text": "Da gjør vi sånn som operativsystemet ville ha gjort det. Satt de på hver sin CPU, og det går da dobbelt så fort. Helt til slutt så kan vi se litt på... Se litt på hvordan man kan... Finne ut hvilke CPU-er som tilhører hvilken... Nei... Hvilke par det er av CPU-er som er hyperthroding. Denne Threadsiblings-list som jeg lister her, det er en liste over hvilke CPU-er som hører sammen. I dette tilfellet så er det CPU-110 og -4 som egentlig er 30 deciblings. Som er de to som da deler på aluen. Helt til slutt så kan vi prøve å se om det er tilfellet. For jeg kan... Først kan jeg kjøre regnejobber på denne måten. Den første settes på CPU1, og den andre settes på CPU2. Hvor lang tid tar det nå å kjøre den regnejobben? Jo, det tar 18 sekunder. Men så kan jeg i stedet si... OK, nå vil jeg eksplisitt sette de to jobbene på 0 og 4. Dette betyr nå... Kjørte den ene på null, og kjørte den andre på fire.", "source": "lecture"}
{"lecture_id": "os7del16", "chunk_id": "os7del16_0003", "start": 271.84, "end": 348.32, "token_count": 289, "text": "Hvor lang tid tar det nå å kjøre den regnejobben? Jo, det tar 18 sekunder. Men så kan jeg i stedet si... OK, nå vil jeg eksplisitt sette de to jobbene på 0 og 4. Dette betyr nå... Kjørte den ene på null, og kjørte den andre på fire. Og det var ikke tilfeldig valg, for nå har jeg bedt dem om å kjøre regnejobbene på den samme hyperthreading CPU-en. Så nå er det null og fire. De er siblings. Det betyr de deler på en del av hardwaren, inkludert CPU-en. Så nå ser vi straks at dette tar lengre tid. De står på 0 og 4. Kunne du se at de står på 0 og 4 her? Men tiden det tok... Den var nå... Den ble da plutselig så godt som doblet. Og det er fordi 0 og 4... Det er akkurat samme kommandoen her. 1 og 2. I stedet her så kjører de på 0 og 4. Og da er de på samme hypertrenings-IPU. Og da må de bytte på å dele aluen.", "source": "lecture"}
{"lecture_id": "os7del16", "chunk_id": "os7del16_0004", "start": 326.76, "end": 427.44, "token_count": 299, "text": "Men tiden det tok... Den var nå... Den ble da plutselig så godt som doblet. Og det er fordi 0 og 4... Det er akkurat samme kommandoen her. 1 og 2. I stedet her så kjører de på 0 og 4. Og da er de på samme hypertrenings-IPU. Og da må de bytte på å dele aluen. Og dermed så går det dobbelt så lang tid å få det ferdig. OK... Jeg ser det er noen spørsmål i chatten her. Hadde også tatt fire sekunder om du kun kjørte ett, ja. Det var litt tilbake her. Men hvis jeg bare kjører én, så tar det også fire sekunder. Så om man kjører... Så... Hvis jeg bare kjører én prosess sånn som dette, så tar det fire sekunder. Og hvis jeg da kjører fire uten noe task-sett eller noe som helst... Hvis jeg ikke bruker task-sett... Og kjører... fire prosesser... Så er dette fire helt uavhengige CPU-er. Og de bruker da like lang tid som om vi kjører én. Vi kan se noen ganger at det tar litt mer tid.", "source": "lecture"}
{"lecture_id": "os7del16", "chunk_id": "os7del16_0005", "start": 399.96, "end": 482.0, "token_count": 255, "text": "Hvis jeg ikke bruker task-sett... Og kjører... fire prosesser... Så er dette fire helt uavhengige CPU-er. Og de bruker da like lang tid som om vi kjører én. Vi kan se noen ganger at det tar litt mer tid. Det er fordi at da kjører du 100 % på alle fire CPU-ene på en server. Og det er alltid noe prosesseringskraft som trengs på en server for å styre alle andre prosesser. Du ser at det går litt mer tid. Men generelt sett så tar det omtrent fire sekunder. Om du kjører på én, eller om du kjører på fire. Men som vi har sett, når vi da kjører på alle åtte, så tar det nesten dobbelt så lang tid fordi det egentlig er hypentreding. AMD har det samme som på din AMDoc-serveren som dere har containere. Den har også... Hypertrening, eller AMDs hypertrening, som er SMT. Simultaneous Multitreading. Det er det også på den serveren.", "source": "lecture"}
{"lecture_id": "linux4del12", "chunk_id": "linux4del12_0000", "start": 0.0, "end": 108.64, "token_count": 300, "text": "Vi skal nå se litt på en helt spesiell mappe som heter Prock. Og den ser ut som en vanlig mappe med filer. Vi kan ta ls-prock slash-prock. Den ligger øverst i roten. Den inneholder da en masse mapper og filer, ser det ut som.  F.eks. inneholder den en mappe som heter CPU-info. Som er ganske lang. Den inneholder da informasjon om CPU-en som kjører på den maskinen. Her er en intel CH. Og masse annen informasjon om CPU-en. Så har den f.eks. mer info. Sånn som... Meminfo, som sier hvor mye minne du har, og masse andre minneparametere. 32 gigabyte-minne, gigabyte-minne og en rekke andre minneparametere, som vi kommer tilbake til litt senere. Men egentlig så er ikke slash-prock et vanlig fil-system. Det som ligger i prock, er dynamisk. Så det er et slags sånn... Vinduet inn til operativstemfjernen hvor man kan hente ut verdier. Og det er også mulig å sette verdier. Nå skal vi først se på... Inni Proc så sto det masse tall. Og hver av disse tallene er en prosess i det.", "source": "lecture"}
{"lecture_id": "linux4del12", "chunk_id": "linux4del12_0001", "start": 79.6, "end": 192.52, "token_count": 290, "text": "Det som ligger i prock, er dynamisk. Så det er et slags sånn... Vinduet inn til operativstemfjernen hvor man kan hente ut verdier. Og det er også mulig å sette verdier. Nå skal vi først se på... Inni Proc så sto det masse tall. Og hver av disse tallene er en prosess i det. Så for hver prosess så er det en egen mappe i Proc som inneholder... Vi kan prøve å se hvordan det ser ut ved å prøve å kjøre en wildlucky som skriver ut payday-en. Der ser vi prosessen her. En payday 13.76. Da skal det finnes en egen mappe som starter på 13.3. Det er en mappe, så vi kan ta LS på den. Der ser vi det ligger en masse informasjon. For eksempel så skal det ligge et navn på kommandolinjen. Som kjøres. Nå tok vi LS, men vi setter CAT på den. Det er den kommandoen som da ble kjørt for å sette i gang denne payday. Og da ser vi at dette er dynamisk. Det er informasjon som du... Ikke ligger i filmen, men som du henter ut direkte fra kjernen.", "source": "lecture"}
{"lecture_id": "linux4del12", "chunk_id": "linux4del12_0002", "start": 167.48, "end": 270.0, "token_count": 300, "text": "Som kjøres. Nå tok vi LS, men vi setter CAT på den. Det er den kommandoen som da ble kjørt for å sette i gang denne payday. Og da ser vi at dette er dynamisk. Det er informasjon som du... Ikke ligger i filmen, men som du henter ut direkte fra kjernen. Det vi også kan prøve da, er å se på en spesiell fil her som heter STAT, som hver prosess har. Den inneholder en del sånn informasjon om prosessen som kjører. En av de er hvor mye tid den bruker, eller hvor mye tid den har brukt. Mer presist så gir den antall tics som prosessen har brukt i use mode og corner mode. Og en tic er på et hundredels sekund. Så her er det masse detaljer om prosessen. Det kan vi se på ved å... Vi kan bruke en kommando som heter watch. Watch gir verdien av kommandoen du gir etterpå, hvert andre sekund. Eller, du kjører den hvert andre sekund, og så kan vi se hvordan verdiene utvikler seg. Her er et par verdier som faktisk endrer seg. Dette er antall tics i use mode og i kernel mode. For denne prosessen. Den bruker ganske mange tics.", "source": "lecture"}
{"lecture_id": "linux4del12", "chunk_id": "linux4del12_0003", "start": 241.14, "end": 291.36, "token_count": 160, "text": "Watch gir verdien av kommandoen du gir etterpå, hvert andre sekund. Eller, du kjører den hvert andre sekund, og så kan vi se hvordan verdiene utvikler seg. Her er et par verdier som faktisk endrer seg. Dette er antall tics i use mode og i kernel mode. For denne prosessen. Den bruker ganske mange tics. 100 tics tilsvarer 1 sekund med CPD-tid. Det er fordi denne står og kjører. Så alt i alt så gir... Så ligger det under PROK en masse informasjon om systemet, alle prosessene og alt som foregår inni datamaskinen.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0000", "start": 0.0, "end": 97.12, "token_count": 294, "text": "Og så skal vi se på dette i praksis. Da skal jeg gjøre en demo hvor jeg kjører på de følgende fem plattformer her. For det første så har jeg laptopen min, som er en Linux ubundet til 1804. Den har en Intel Zeon-prosessor, som er den vi har kjørt eksempler på i hele vår. Det er viktig å ha klart for seg. Intel og IMD, de CPU-ene, begge de har X86-institusjoner. Så har jeg noen forskjellige Java-versjoner. Java 11 og Python 36 på denne. Det er et viktig poeng etter hvert, når vi kjører på andre Java-versjoner, at Java er til dels avhengig av versjoner. Spesielt så er det noen ganger gamle Java-programmer ikke virker på... Eller... Eldre Java-programmer virker på nyere, men hvis man kompilerer på en nyere Java-versjon, så virker de ikke alltid på de gamle. Men det skal vi se på. Så neste plattform jeg har, er en gammel Mac, en gammel Macbook Pro. Den kjører Mac Macclus T med Darwin-kjerne. Det er en Unix av art, men det er en variant av Unix.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0001", "start": 74.42, "end": 193.16, "token_count": 298, "text": "så virker de ikke alltid på de gamle. Men det skal vi se på. Så neste plattform jeg har, er en gammel Mac, en gammel Macbook Pro. Den kjører Mac Macclus T med Darwin-kjerne. Det er en Unix av art, men det er en variant av Unix. Derfra har man typisk et bachel i pointback. Men det er samtidig en del forskjeller. Men CPU-en er en Intel core-duo som også kjører X86-institusjoner. Python er forskjell på Python 3 og Python 2. Men jeg skal se at Python er i større grad uavhengig av versjoner. Og så har jeg en Del-server med en AMD CPU. Det er en svær server med 48 CPU-er. Altså kjøre på X86. I tillegg er jeg valgt av Python 2.7. Så kom vi nå som er faktisk en nyhet av året. Selv om den ikke er helt nytt. Og det er... Dette er en Linux ubundet til 2004, men den kjører på en Arm CPU. Vanligvis brukes Arm i mobiler, og derfor er de konstruert sånn at de bruker mindre strøm og er ganske sånn lettvekt når det gjelder drift.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0002", "start": 163.68, "end": 251.08, "token_count": 285, "text": "Selv om den ikke er helt nytt. Og det er... Dette er en Linux ubundet til 2004, men den kjører på en Arm CPU. Vanligvis brukes Arm i mobiler, og derfor er de konstruert sånn at de bruker mindre strøm og er ganske sånn lettvekt når det gjelder drift. Men tradisjonelt så har man alltid kjørt Exo-86... Ikke alltid. De siste 10-15 årene så har Exo-86 vært dominerende i serverrommet, men nå har det også begynt å komme arm-baserte servere. Så dette er en sånn arm-basert server. Jeg kjører i Amazon Elastic Cloud, så dette er en cloudserver som jeg har kjøpt en VM på. Så dette er da VM-er som man betaler per måned. Koster ikke veldig mye for én. Kjøper du en stor en, så koster det en del. Den siste plattformen er en Windows Server 2019, som er også SE2. Også Amazon Cloud. Men den kjører på en Intel Seon Sippu. Altså den samme Sippuen som her oppe.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0003", "start": 227.8, "end": 329.92, "token_count": 293, "text": "Koster ikke veldig mye for én. Kjøper du en stor en, så koster det en del. Den siste plattformen er en Windows Server 2019, som er også SE2. Også Amazon Cloud. Men den kjører på en Intel Seon Sippu. Altså den samme Sippuen som her oppe. Ikke helt samme, men samme Sippu-familie. Og igjen X86, Java 8 og Python 39. Så dette er de forskjellige plattformene. Og så skal jeg nå prøve å gå inn på de... Hvis jeg kompilerer alt på denne... Hello.c, hello.java, hello.python og hello.bash. Så kopierer jeg de til alle fire plattformene. Og så skal vi se hva som fungerer hvor. Jeg håper du etter pause har fått til en liten poll på dette her. Så det er viktig å følge godt med hva som skjer. Men da skal vi gå over og se på... Ja... Håper dere er i stand til å se dette. Her er jeg nå i en mappe som heter Hello. Og i denne mappen så har jeg... For det første så har jeg de fire programmene. Skal ta de først.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0004", "start": 300.0, "end": 426.56, "token_count": 285, "text": "Men da skal vi gå over og se på... Ja... Håper dere er i stand til å se dette. Her er jeg nå i en mappe som heter Hello. Og i denne mappen så har jeg... For det første så har jeg de fire programmene. Skal ta de først. Hello.c. Det er da et C-program. Hello.java. Det er et Java Hello World. Og så har jeg hello.python. Og til slutt hello.person. Så tanken er nå å kopiere disse over til de andre plattformene. Et skjedskrift som heter dysts.shell. Og det det gjør, er å kopiere hele denne mappen som jeg nå står i, den hello, til de andre plattformene. Dette er AMD-serveren. Dette er MacWiston. Dette er Arm-serveren. Og dette er Windows-serveren. Og Amazon Cloud. Men før jeg gjør det, så er da hele ideen at jeg skal kompilere... Kompilere og kjøre programmene her. Og da har jeg et lite skript som heter Compile. Jeg vil bare se programmet og Java-programmet som må kopieres først. GCCHL.c har vi sett mange ganger. Og så JavaCHL.java. Javafiler på Linux.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0005", "start": 398.5, "end": 507.96, "token_count": 288, "text": "Kompilere og kjøre programmene her. Og da har jeg et lite skript som heter Compile. Jeg vil bare se programmet og Java-programmet som må kopieres først. GCCHL.c har vi sett mange ganger. Og så JavaCHL.java. Javafiler på Linux. Og når man gjør det, så lages det en hello.class. Så det er den vi da sender over. Så hvis jeg kjører compile, så komplerer jeg altså hello.c. Så jeg får en ny versjon av det. Og tanken nå er at nå skal jeg kopiere alle disse over til de andre plattformene. Der har jeg satt opp SSO-nøkler, sånn at vi ser at de kopierer over til alle plattformene. Og så på Windows har jeg satt opp SSO-nøkler. Det går an å gå inn på Windows med SSO også. Vi skal se på det senere. Og det er litt mer knot å sette opp SOS-nøkler på Windows, men det er mulig å få til. Og så kan vi gå rundt på de andre plattformene og se hvordan det ser ut å kjøre de fire programmene. Da hopper vi først ned hit til AMD-serveren.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0006", "start": 480.0, "end": 596.0, "token_count": 299, "text": "Og det er litt mer knot å sette opp SOS-nøkler på Windows, men det er mulig å få til. Og så kan vi gå rundt på de andre plattformene og se hvordan det ser ut å kjøre de fire programmene. Da hopper vi først ned hit til AMD-serveren. Kjøre Linux bunt til 1604 på en AMD Oppdron. Ops... Skal vi prøve å få det vinduet? Å, nei. Ikke gjøre noe helt galt, det. Oi. Jeg får klare meg med det lille vinduet. Jeg trodde jeg skulle ha fått det litt større, men der, kanskje. Jeg kan ta det én av gangen. Jeg kan først starte med Adopt. Nå har jeg kompilert her oppe... På Linux med Intel har jeg kompilert Adopt. Så kopierer jeg over hit, og så kjører jeg det her på AMD-serveren. Ja... Dette var ikke så rart. For her kjører jeg oddotout. Men jeg har ikke gått inn i mappen, så jeg må inn i hello. Så dette beviser ikke så veldig mye. Men nå er jeg inne i mappen. Og du kan se jeg har alle de samme... Alt er kopiert over hit.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0007", "start": 570.0, "end": 657.88, "token_count": 293, "text": "Ja... Dette var ikke så rart. For her kjører jeg oddotout. Men jeg har ikke gått inn i mappen, så jeg må inn i hello. Så dette beviser ikke så veldig mye. Men nå er jeg inne i mappen. Og du kan se jeg har alle de samme... Alt er kopiert over hit. Så nå kan jeg prøve å kjøre oddotout. Og da så vi faktisk... Det fungerer. Det betyr ikke at C er plattform uavhengig, for hele poenget er at dette er samme plattform. Det er Linux på Exo-86. Så selv om det er en annen ubundet versjon og det er en annen prosessor, AMD, i stedet for Intel, så har begge Exo-86 institusjoner, og da fungerer det å bare kopiere over all date out på den måten. Ja, jeg kan kjøre eksplisitt, så vi kan ta Java hello også. Når jeg kjører Java hello, så ser vi at jeg får noen feilmeldinger. Og det... Man skulle tro dette fungerte, men det er en sånn... Hvis man leser feilmelding i øyet, så er det en sånn versjons...", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0008", "start": 630.0, "end": 738.8, "token_count": 286, "text": "Ja, jeg kan kjøre eksplisitt, så vi kan ta Java hello også. Når jeg kjører Java hello, så ser vi at jeg får noen feilmeldinger. Og det... Man skulle tro dette fungerte, men det er en sånn... Hvis man leser feilmelding i øyet, så er det en sånn versjons... Problemet her er at jeg har kompilert Hello.ThatWorld med Java11. Og så prøver jeg å kjøre det på Java8. Og det er ikke backover-compatible, så da fungerer ikke det. Så sånn sett kan man si at Java ikke er fullstendig plattformuavhengig. Litt plattformavhengighet ser vi at det er. Men jeg kan kjøres og teste Python. Det fungerer fint. Og... og bæsj fungerer også fint. Det er ikke så overraskende. Så oppsummert, hvis jeg kjører, Python og bæsj og Adopt-out fungerer, men ikke Ikiyawa. Til MacOS. Så kan jeg prøve å huske å gå inn her. Nå er jeg inne i riktig mappe i MacOS. Jeg har kopiert over alle de samme filene.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0009", "start": 705.82, "end": 823.0, "token_count": 297, "text": "Så oppsummert, hvis jeg kjører, Python og bæsj og Adopt-out fungerer, men ikke Ikiyawa. Til MacOS. Så kan jeg prøve å huske å gå inn her. Nå er jeg inne i riktig mappe i MacOS. Jeg har kopiert over alle de samme filene. Så kan jeg prøve å kjøre Adataut her. Og det går dårlig. Jeg får Cannot Execute Binot. Og det er ikke så rart når man tenker seg om, fordi selv om dette er en Intel-CPU med X86-institusjoner, så er det et annet operativstem. Det er MacOST. Og A.out prøver å snakke med Linux-stjernen. Og dermed så går dette dårlig. Med Java så har vi samme problemet. Dette er Java 6, en eldre Java-versjon, så den kjenner ikke igjen den nyere Java 11-klasse-filmen. Python derimot... Den går fint. Men hva så med bæsj? Ikke så helt opplagt. Det er bare en standard kommandolinje. Jo, Macbook har bæsj installert, Ok. Da skal vi over på ARM. Etter pausen kan vi se litt mer på det.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0010", "start": 791.08, "end": 906.04, "token_count": 292, "text": "Python derimot... Den går fint. Men hva så med bæsj? Ikke så helt opplagt. Det er bare en standard kommandolinje. Jo, Macbook har bæsj installert, Ok. Da skal vi over på ARM. Etter pausen kan vi se litt mer på det. Men poenget er at de underleggende maskininstruksjonene her, CPU-ene som vi kjører på, den er helt forskjellig. Har et helt annet instruksjonssett. Hvis jeg prøver å kjøre adatatet, så ser vi at jeg får en... ... exec format error. Til tross for at det er akkurat samme operatise, Linux i bunter, mer eller mindre samme kjerne, men i motsetning til her nede på AMD server, så kjører ikke adatatet. Det er rett og slett fordi her er det arm-instruksjoner. Det er helt binary. Jeg har et eksempel på hvordan disse gjør ut... I mappen over her. En sum.s som er kompilert her. Og her er en instruksjon... Den er ikke så veldig forskjellig, men... Dette er bare én institusjon, men vi har andre navn på registeret.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0011", "start": 883.88, "end": 1004.1, "token_count": 300, "text": "I mappen over her. En sum.s som er kompilert her. Og her er en instruksjon... Den er ikke så veldig forskjellig, men... Dette er bare én institusjon, men vi har andre navn på registeret. Og det er andre institusjoner. Dermed er det umulig å ta en av-og-tat-fill, eller hvilke som helst andre programmer som er komplimert med CSI. Det kan man ikke bare kopiere over og kjøre på en maskin som har en armplattform. Og Java funker fint her. Og det er fordi at her er det Java 14. Så den er såpass ny at den... Den er faktisk nyere enn Java 11. Så den tolker fint. Hetten kjører også fint. Og det er jo ubuntu, så... Og bæsjkrittet kjører også fint. Så til slutt så skal vi over på vindos. Og her har vi også kopiert over alle fillene. Dere har kanskje merket at jeg har kjørt LS, og det er fordi dette er vindos påforskjell. Her finnes det alias for veldig mange Linux-kommandoer. Sånn at man kan bruke Linux-kommandoer når man jobber med PowerShed.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0012", "start": 972.8, "end": 1095.52, "token_count": 298, "text": "Og her har vi også kopiert over alle fillene. Dere har kanskje merket at jeg har kjørt LS, og det er fordi dette er vindos påforskjell. Her finnes det alias for veldig mange Linux-kommandoer. Sånn at man kan bruke Linux-kommandoer når man jobber med PowerShed. Så her har vi sammen med HelloOz og andre. Alt er kopiert over, men da kan jeg prøve å kjøre adopt-out. Det er ikke prikk-bakslasj, er det selvfølgelig prikk-slasj. Jeg får ingenting, men jeg får i hvert fall ikke ut Hello World. Jeg kunne prøvd å gjøre noe sånt som å kalle ad.exe. For Windows er veldig sånn institusjonsnett... Nei, avhengig av extension på fillene. Men... Det eneste jeg får beskjed om, er at ad.exe gikk feil. Man kan ikke kjøre den... Man klarer ikke å kjøre den filen. Det er da fordi AdoDot snakker med Linux-operativsystemet. Så da er det ikke så rart at den ikke kjører. At dette ikke fungerer? Og det er til tross for at det er akkurat samme CPU.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0013", "start": 1053.84, "end": 1169.96, "token_count": 292, "text": "Man klarer ikke å kjøre den filen. Det er da fordi AdoDot snakker med Linux-operativsystemet. Så da er det ikke så rart at den ikke kjører. At dette ikke fungerer? Og det er til tross for at det er akkurat samme CPU. Det er en Intel CON CPU, akkurat som vi har komplert for her. Så maskininstitusjonene er i grunnen riktige, men her er problemet igjen at... Så treffer den Windows-server, og da fungerer ingenting. Så dermed vil det ikke fungere. Java, derimot, kunne man i prinsippet tenke fungerte. Men igjen så er det rundtime-problemet. Når du går fra versjon 11 ned til versjon 8, så fungerer det ikke. Den fungerer fint. Den kjører på... ja, det er Pyton 3936, så det er ikke så rart at den kjører, men den oppfører seg fint. Så helt til slutt... Hva med LOD-bæsj? Det skjer ikke noe der, men hvis jeg eksplisitt kjører sånn som før... LOD-bæsj, så ser vi at det faktisk fungerer.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0014", "start": 1147.12, "end": 1265.0, "token_count": 292, "text": "så det er ikke så rart at den kjører, men den oppfører seg fint. Så helt til slutt... Hva med LOD-bæsj? Det skjer ikke noe der, men hvis jeg eksplisitt kjører sånn som før... LOD-bæsj, så ser vi at det faktisk fungerer. Men det er fordi her har jeg isolert bæsj. Dvs. jeg har isolert den Linux-modulen sånn at jeg har... Så at jeg har et bæsjer, så jeg kan starte bæsjeret og kjøre Linux-kommandoer som LS-l. Om jeg prøver å kjøre A.alt her... Inne i Linux-submodulen. Jo. Det fungerer faktisk. Her er det på en måte native Linux som kjører direkte på X86. For når jeg starter perset her inne, så får jeg opp et ekte... Det er faktisk en Linux-kjerne som kjører... Det er vel en... Jeg er ikke sikker på detaljene, om det er en virtuell maskin, men det er iallfall en ekte Linux-kjerne som kjører, sånn at man kan kjøre native Linux-programmer på denne vindussurferen. Håper ingen har savnet her.", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0015", "start": 1234.76, "end": 1363.72, "token_count": 300, "text": "Det er vel en... Jeg er ikke sikker på detaljene, om det er en virtuell maskin, men det er iallfall en ekte Linux-kjerne som kjører, sånn at man kan kjøre native Linux-programmer på denne vindussurferen. Håper ingen har savnet her. Spørsmål i slutten. Ja. Spørsmål i slutten. Flott. Hvorfor funket bæsj på den ene Linux-en og ikke den andre Linux-serveren? Skal vi se... Den fungerte vel på begge Linux-serverne. Jo, hvis vi oppsummerer, så... Den fungerte her. Og... og her. Og også på Mac fungerte den. Ja, her kjørte jeg òg. Så... Ine, forstod du spørsmålet? Nei... Jeg trodde jeg skulle si fra. Flott. Nei, det var denne her... Det var bare at jeg skrev feil. Så det var ikke Linux sin feil. Det var min feil som skrev noe feil. Kjørte Adoptat på Linux-serveren mellom det? Nå skal vi se. Ja, faktisk. Og det var jeg litt... Det er ikke helt opplagt. Men her har vi bare tatt en adotat, så kopiert rett over", "source": "lecture"}
{"lecture_id": "os10del3", "chunk_id": "os10del3_0016", "start": 1336.26, "end": 1392.0, "token_count": 183, "text": "Så det var ikke Linux sin feil. Det var min feil som skrev noe feil. Kjørte Adoptat på Linux-serveren mellom det? Nå skal vi se. Ja, faktisk. Og det var jeg litt... Det er ikke helt opplagt. Men her har vi bare tatt en adotat, så kopiert rett over fra Linux-sipput på Intel, komplert for Intel-sippu, og så kopiert over hit. Og det er da fordi alt er likt. Det er samme operativstemme, og så er instruksjonssettet det samme. Så om du komplerer... Her kopiert tilbake så får du også den samme effekten. Ja, det er riktig konkludert. Begge er X86-prosesser.", "source": "lecture"}
{"lecture_id": "os3bdel4", "chunk_id": "os3bdel4_0000", "start": 0.0, "end": 89.96, "token_count": 299, "text": "Tellere. En annen viktig ting som man trenger for å lage en hel CPU, nå har vi nesten fått med alt, det er tellere. Og det er da en enhet som er sånn, Haus, dette er et eksempel fra den simulatoren. Dette er da en teller som starter på 0, 0, og så teller den 0, 1, 1, 0, 1, 1. Når den har kommet til 3, så starter den på nytt igjen. Så blir det 00, 01, 10, 11. Så fortsetter den sånn iduettelig. Så denne teller fra 0 til 3. For å lage større tall, så kan du bare... Så kan man faktisk bruke denne tilsvarende konstruksjonen. Bare legge på flere sånne, så vil man kunne se at... At da kan man lage tellere med 64-bit, f.eks. Men igjen, for å lage denne konstitusjonen... Her er en X-orport. Som er en år-port med en night etter. For å lage denne konstitusjonen... Igjen så setter man opp Sand-Esabel, for man vet hvordan en klokke skal virke. Og så...", "source": "lecture"}
{"lecture_id": "os3bdel4", "chunk_id": "os3bdel4_0001", "start": 60.0, "end": 113.72, "token_count": 154, "text": "At da kan man lage tellere med 64-bit, f.eks. Men igjen, for å lage denne konstitusjonen... Her er en X-orport. Som er en år-port med en night etter. For å lage denne konstitusjonen... Igjen så setter man opp Sand-Esabel, for man vet hvordan en klokke skal virke. Og så... Så kommer man fram til denne logikken, som er relativt enkel. Og ut fra det kan man lage vilkårlig store tellere. Så nå har vi med dette fått egentlig alle de viktigste bitene som skal til for å lage en hel Sippu.", "source": "lecture"}
{"lecture_id": "linux7del10", "chunk_id": "linux7del10_0000", "start": 0.0, "end": 148.68, "token_count": 296, "text": "Det er mulig å laste ned imager. Hvis jeg kjører Docker container run, så både lastes ned og startes imager. I dette tilfellet Docker pull alpine. Nei, altså et standard skrivebordsprogram er ikke en dokkerinstans. Et standard skrivebordsprogram er mer sånn klassisk at det er et underliggende operativstem, og så er det en prosess som kjører på operativ. Det som er veldig spesielt med dokker, er at det typisk bare kjører én eneste tjeneste. F.eks. en regneoppgave eller en webserver eller en database. Men det eneste dockerinstansen gjør, er å kjøre den tjenesten. Som man så kan kjøre. Ja... I neste runde skal vi teste ut noen av disse her. Vi kan bare se kort på hva man kan gjøre. Den kommandoen her, den starter opp alpine. Alpine er en liten... Alpine er en liten Linux-versjon som er veldig lett. Ubuntu er stor, mange gigabyte, men Alpine er veldig liten og lett. Men det som skjer, er at man starter opp Alpine, gjør LS-L, og så stopper hele containerne. Tilsvarende her så starter man Alpine og bare skriver ut.", "source": "lecture"}
{"lecture_id": "linux7del10", "chunk_id": "linux7del10_0001", "start": 120.0, "end": 220.0, "token_count": 273, "text": "Alpine er en liten Linux-versjon som er veldig lett. Ubuntu er stor, mange gigabyte, men Alpine er veldig liten og lett. Men det som skjer, er at man starter opp Alpine, gjør LS-L, og så stopper hele containerne. Tilsvarende her så starter man Alpine og bare skriver ut. Et skrivebordsprogram har flere dokkere som kjører? Nei, det er på en måte helt forskjellige greier. Det spørs hva du mener med et skrivebordsprogram. Men generelt så kan du kjøre mange dokkere og mange dokkerinstanser samtidig. Ni webservere som er uavhengige av hverandre og som kjører dokker. Men det viktige med det oppsettet er at i praksis så bruker alle de ni den annerledes kreativsystemet som er det samme. I tidligere tider, når man da brukte VM-er, det gjør man fortsatt, så... Starter man ti VM-er, starter man hele OL for hver av de VM-ene. Det tar mye tid og mye ressurser. Det er den største forskjellen.", "source": "lecture"}
{"lecture_id": "linux8del6", "chunk_id": "linux8del6_0000", "start": 0.0, "end": 88.66, "token_count": 286, "text": "Først og fremst skal vi se på dokkefiles. Men før det så skal vi prøve å se litt på volumes. Og generelt hvordan man får dokkefilene... Nei, får konteinerne til å koble seg opp mot det lokale filsystemet. For da kan man... Hvis man kobler en dokkefil til... Så kan man da koble løs containeren, sånn at den er en uavhengig enhet som raskt kan startes og stoppes. For hele tiden ønsker man å ha konteinere uavhengige. De skal gjerne gjøre så lite som mulig. Typisk så kjører en container én prosess. F.eks. én webserver, eller én applikasjon som skal testes og kjøres. Men vi vil gjerne kunne stoppe starten. Og gjerne kaste den også, bygge den på nytt. Uten at innholdet blir kastet. Så derfor skal vi nå begynne å se litt på volumer og hvordan man kobler til eksterne filer til en dokkerinstans. Dokkerinstans er da det samme som en container. Så det er en annen måte å si container på. Da skal jeg...", "source": "lecture"}
{"lecture_id": "linux8del6", "chunk_id": "linux8del6_0001", "start": 60.02, "end": 186.3, "token_count": 286, "text": "Og gjerne kaste den også, bygge den på nytt. Uten at innholdet blir kastet. Så derfor skal vi nå begynne å se litt på volumer og hvordan man kobler til eksterne filer til en dokkerinstans. Dokkerinstans er da det samme som en container. Så det er en annen måte å si container på. Da skal jeg... I stedet dele slidene til Mike Long, som vi så på sist. Vi har en ca. 20 slider til. Da skal vi se på volumer. Ja... Dukkevolum, det er da... Som jeg sa, det er en mappe. Eller en fil som man bruker for å koble opp varige filer til en dokkeinstans. Sånn at man kan... Sånn at en... Selv om man da dreper og til og med avslutter. ... så kan man bruke de samme filene senere. Ved å bygge en ny container fra et nytt image og koble opp mot de samme filene. Så kan de også deles mellom containere. Det er et par-tre måter å gjøre dette på. Det er som en link. Du kan ha en fil eller mappe her i containeren", "source": "lecture"}
{"lecture_id": "linux8del6", "chunk_id": "linux8del6_0002", "start": 156.48, "end": 261.18, "token_count": 294, "text": "Ved å bygge en ny container fra et nytt image og koble opp mot de samme filene. Så kan de også deles mellom containere. Det er et par-tre måter å gjøre dette på. Det er som en link. Du kan ha en fil eller mappe her i containeren som peker direkte på en mappe på filsystemet på hosen du kjører containeren. Da kan du endre på filene på hosen, og så endres det i containeren. En litt mer abstrakt og foretrukket metode er volum. Et volum, det defineres av dokker-dimen. Så da er det dokker som står og styrer. Dette kan i større grad gjøre at konteinere kan dele data med hverandre også. Så dette er en litt mer abstrakt måte å styre filer på. Som også er styrt av dokker. Sånn at det er dokker som styrer dette. Så kan jeg altså montere direkte minne, det kommer ikke vi til å se på. De to måtene vi skal se på, er bind-mounts... Det er da direkte å binde hosen. Når man starter en container... Docky container run... Så legger man på den opsjonen minus v.", "source": "lecture"}
{"lecture_id": "linux8del6", "chunk_id": "linux8del6_0003", "start": 231.46, "end": 341.52, "token_count": 298, "text": "Så kan jeg altså montere direkte minne, det kommer ikke vi til å se på. De to måtene vi skal se på, er bind-mounts... Det er da direkte å binde hosen. Når man starter en container... Docky container run... Så legger man på den opsjonen minus v. Og slash house dir er da filsystemet her på hosen. I vårt tilfelle er det på Linux v. Og så slash-app. Det er da filsystemet i containeren. Så det vi skal gjøre etterpå, er å koble det til vår WWW hotml på containeren. Koble det til et filsystem her, sånn at vi kan endre innholdet på webserveren mens den kjører. Dette gjør det samme med et volum, men da må vi først gi dokker. Kreere et volum med docker volum create, og så navnet på volumet. Men det er fortsatt litt tilsvarende. Den vil da i praksis ligge på i fyllsystemet her, men den kan da styres av docker. Så vi skal straks ta en pause, men vi ser her... Hvis dere vil prøve på dette i pausen, Og starte å gjøre oppgaver. Før vi tar pause... Det er noen volum...", "source": "lecture"}
{"lecture_id": "linux8del6", "chunk_id": "linux8del6_0004", "start": 313.12, "end": 400.0, "token_count": 243, "text": "Den vil da i praksis ligge på i fyllsystemet her, men den kan da styres av docker. Så vi skal straks ta en pause, men vi ser her... Hvis dere vil prøve på dette i pausen, Og starte å gjøre oppgaver. Før vi tar pause... Det er noen volum... Volume, best practices. Container should be ephemeral. Og det betyr at de skal være bruk og kast. Altså de skal ikke være evigvarende. Det er liksom hele filosofien. Men dette er et litt mer sånn avansert råd. Avoid monting directories from the host in production. Det som er en kanskje enda bedre måte å gjøre dette på, er å ha egne containere som inneholder data. Og som det står her, dette er hvordan det er brukt i Kates K8S. Det er da en forkortelse for Kubernet. Men det vi skal se på i dag, er hvordan vi faktisk monterer pilsystemer fra Håsen inn i...", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0000", "start": 0.0, "end": 128.88, "token_count": 291, "text": "Det var en dårlig start på opptaket. Vi må tilbake... Nei. Ja, dette blir kuttet fra opptaket. Som vi ser, så har vi ikke så mange uker igjen med kursinnhold. Det blir... Det er muligens at vi kommer til å fortsette... Skal vi se på det løpet. Tirsdag 27. Jeg tror det er litt kort tid med bare én forelesning til internminet, og så disker og filsystemer. Så det er mulig det forlenges inn til tirsdag 27. Men det kommer ikke til å bli så veldig mye mer på den praktiske delen. Jeg annonserte DockerHub før påske, men har i hvert fall utsatt det. Det er uansett ikke veldig mye mer vi skal snakke om... Snakke om dokker. Eller ekstra soff om dokker. Men det kommer en runde til med Powershell. Windows Powershell. Der var det en digital forelesning som ble lagt ut i påsken. Og så kommer det en til i løpet av morgendagen. Og det er en... Eller praktisk del. Om å skrive Powershell-script og å bruke Powershell fra kommandolinje.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0001", "start": 100.6, "end": 228.96, "token_count": 290, "text": "Men det kommer en runde til med Powershell. Windows Powershell. Der var det en digital forelesning som ble lagt ut i påsken. Og så kommer det en til i løpet av morgendagen. Og det er en... Eller praktisk del. Om å skrive Powershell-script og å bruke Powershell fra kommandolinje. En ting som er fint med Powershell, er at den ligner veldig på Linux på bæsj selv. Så det er inspirert av det. Sånn at veldig mange kommandoene kan du faktisk bruke direkte. Sånn som CP og MV og mange andre kommandoer. Sånn at man i noen tilfeller kan ta Shellscript og bare paste inn og kjøre som på Shellscript. Så det er også da mange oppgaver denne uken som går på det med PowerShell. Oi. Nå ser jeg det henger her. Det var en som sa at det hadde vært noe trøbbel med... At nettsiden hadde vært nede. Det må jeg sjekke et øyeblikk. Nei... Er det noe trøbbel hos meg? Eller er det andre som har problemer med å se nettsiden også? Den fungerer fint her. Ja, det var bra. Du kommer inn.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0002", "start": 184.36, "end": 307.96, "token_count": 299, "text": "At nettsiden hadde vært nede. Det må jeg sjekke et øyeblikk. Nei... Er det noe trøbbel hos meg? Eller er det andre som har problemer med å se nettsiden også? Den fungerer fint her. Ja, det var bra. Du kommer inn. Ja, da er det et eller annet problem hos meg. Men det kan vi... Alle kommer rett inn, bortsett fra meg. Ja, ja. Vi kan... Ja, jeg kan se på det i pausen. Men i hvert fall, det er oppgaver denne uken... Oi. Der skjedde det noe. Nå kan jeg kanskje komme inn. Der, ja. Det er oppgaver denne uken som går på Windows PowerShell. Og for de av dere som kjører Windows-laptoper, så... Kan dere gjøre de aller fleste av oppgavene direkte. Men det er noen oppgaver med å lage nye brukere osv. Og så er det noen oppgaver med Windows Register. Da kan det være greit for å være sikker på ikke å ødelegge noe på eget oppsett, så kan det være greit å bruke en Virtual Box Windows VM. Men det står instruksjoner her også på hvordan den kan installeres og settes opp.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0003", "start": 279.44, "end": 379.08, "token_count": 294, "text": "Og så er det noen oppgaver med Windows Register. Da kan det være greit for å være sikker på ikke å ødelegge noe på eget oppsett, så kan det være greit å bruke en Virtual Box Windows VM. Men det står instruksjoner her også på hvordan den kan installeres og settes opp. Videre er det en... Etter de powercel-oppgavene så er det oppgaver om det vi snakker om i dag. Og her ser vi... Et skript som dette her kan kjøres omtrent direkte. Så veldig mye er likt, fordi det er lagd alias i PowerShell som gjør mange av de samme kommandoene. Så når vi først kan binde bæsjskrift, så kan du også mye PowerShell. Masse kan overføres direkte. Og så etter hvert så er det oppgaver. I dag så er det Javatrå-oppgaver og diverse oppgaver rundt synkronisering. Og serialisering. Så er det bl.a. noen litt mer vanskelige teoretiske oppgaver. Men det skal vi se på først i forløsningene. Så det... Temaet i dag er generell synkronisering.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0004", "start": 354.56, "end": 440.08, "token_count": 289, "text": "og diverse oppgaver rundt synkronisering. Og serialisering. Så er det bl.a. noen litt mer vanskelige teoretiske oppgaver. Men det skal vi se på først i forløsningene. Så det... Temaet i dag er generell synkronisering. Vi skal spesielt se på Synchronized i Java for å se hvordan vi kan synkronisere den Java-koden som vi hadde før påske, som... Han talte opp en saldo, og to tråder ødela for hverandre. Når et program ikke synkroniserer riktig, ser vi ofte at det ikke er tread safe. Det betyr at trådene kan ødelegge for hverandre. Synchronized er en metode som kan brukes for å synkronisere og gjøre et trådprogram tread safe. Så skal vi til slutt i dag se på deadlock. Det kan oppstå når man fortvilet prøver å synkronisere mange prosesser. Og det gjør man typisk alt ved at de venter på hverandre. Men hvis flere prosesser venter f.eks. i en ring, en sirkel, på hverandre, så kan det oppstå deadlock, og da kommer ingen videre.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0005", "start": 420.0, "end": 501.4, "token_count": 286, "text": "Det kan oppstå når man fortvilet prøver å synkronisere mange prosesser. Og det gjør man typisk alt ved at de venter på hverandre. Men hvis flere prosesser venter f.eks. i en ring, en sirkel, på hverandre, så kan det oppstå deadlock, og da kommer ingen videre. Og det er et problem man må være klar over når man begynner å programmere og synkronisere tråder eller prosesser. Så det er... Det er temaet i dag. Ja. Det er et godt spørsmål i chatten om... ... uke 14 er obligatorisk. Det var fint du spurte om, for det... Nei, uke 14 er ikke obligatorisk. Så Oblig3... Det kommer en mappe for å levere Oblig3 i dag. Og alt som skal inngå i Oblig3, det er akkurat... Altså fra før påske. Så det står her uke tolv. Denne ukens oppgaver. Det er de siste som skal være med i innleveringen. Derfor er det... Jeg har kanskje ikke skrevet noe om det, men vi... Jo. Her står det en kommentar om dette.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0006", "start": 480.0, "end": 559.16, "token_count": 288, "text": "Altså fra før påske. Så det står her uke tolv. Denne ukens oppgaver. Det er de siste som skal være med i innleveringen. Derfor er det... Jeg har kanskje ikke skrevet noe om det, men vi... Jo. Her står det en kommentar om dette. Disse innleveringene er ikke obligatoriske, så de som har merket opplegg, bare betrakt dem som de viktigste. Og få med seg for å forberede seg til eksamen. Altså det som er mest eksamensrelevant. Så når det står oblig her, sånn som her, så betyr det ikke at det skal være med i noen oblig-innlevering. Men det skal... Det er det som er det viktigste. Og jeg snakket med studentene om det. Det kan godt være at vi kan få til... Vi kan legge opp en innlevering. Sånn at dere kan frivillig levere inn og få tilbakemeldinger på det som er anførselstegn-obliger. Så hvis det er noe interesse for det, så si gjerne ifra. Så kan vi prøve å få til en sånn ordning, så dere får tilbakemelding", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0007", "start": 540.0, "end": 641.2, "token_count": 294, "text": "Sånn at dere kan frivillig levere inn og få tilbakemeldinger på det som er anførselstegn-obliger. Så hvis det er noe interesse for det, så si gjerne ifra. Så kan vi prøve å få til en sånn ordning, så dere får tilbakemelding på en sånn måte som dere har fått på de virkelige obligatoriske oppgavene. Men altså opp til alt oppgaver til og med uke tolv. Og de er obligatoriske. Ja, der ser jeg Ine også har kommet seg opp etter ferien. Det kan være tungt for flere, det, Ine. Så det er veldig bra du er her. Da kan dere spørre Ine. Enten vi må spørre til alle eller bare til Ine. Eventuelt ting som er veldig viktig, tar vi i pausen. Ok. Da skal vi se på dagens MR. Så vi skal først snakke litt teoretisk, noen slider... Og en del litt sånn teoretiske slider om hvordan man kan løse Mutex-problemer. Vi så konkret på forrige gang. Og så... kommer vi kanskje litt tilbake til X86-instruksjonen Lock", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0008", "start": 614.16, "end": 713.84, "token_count": 277, "text": "Så vi skal først snakke litt teoretisk, noen slider... Og en del litt sånn teoretiske slider om hvordan man kan løse Mutex-problemer. Vi så konkret på forrige gang. Og så... kommer vi kanskje litt tilbake til X86-instruksjonen Lock og se på det vi gjorde der. Det var et par ting vi ikke gjorde der som vi skal se på. Spesielt så vi ikke direkte på hva som skjer hvis det ikke bare er én instruksjon. Vi så på Lock før påske. Som var... som endret på en feltsvariabel. Og likevel så ble det problemer. Så vi skal se litt mer på det. Og så skal vi se på igjen noe generelt om synkronisering, med semaforer blant annet. Så semaforer skal vi se på i dag. Og så skal vi mot slutten synkronisere det Java-programmet vi hadde sist. Og helt til slutt i dag skal vi se på deadlock. Men vi starter... Vi starter med kritiske avsnitt. Kritisk avsnitt er det avsnittet i koden som er helt avgjørende", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0009", "start": 677.24, "end": 774.96, "token_count": 291, "text": "med semaforer blant annet. Så semaforer skal vi se på i dag. Og så skal vi mot slutten synkronisere det Java-programmet vi hadde sist. Og helt til slutt i dag skal vi se på deadlock. Men vi starter... Vi starter med kritiske avsnitt. Kritisk avsnitt er det avsnittet i koden som er helt avgjørende når det gjelder synkronisering. Og det er da typisk når man aksesserer en felles felles. Vi har sett på en problemstilling hvor vi har en felles variabel saldo, hvor vi hadde en felles variabel saldo som én prosess økte med 1 mill. og en annen prosess, P1, minket med 1 mill. Så så vi da på hvordan dette kunne gjøre at saldoen... at det forsvant 1 mill. Det er jo opplagt uheldig. Og akkurat den kodebiten hvor den milden forsvinner, det er når saldoen oppdateres. Og dette kalles kritisk avsnitt. Så det som er helt avgjørende, er at en prosess som er inni et kritisk avsnitt, den må kunne fullføre det helt alene,", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0010", "start": 754.56, "end": 837.92, "token_count": 293, "text": "Og akkurat den kodebiten hvor den milden forsvinner, det er når saldoen oppdateres. Og dette kalles kritisk avsnitt. Så det som er helt avgjørende, er at en prosess som er inni et kritisk avsnitt, den må kunne fullføre det helt alene, uten at da noen andre endrer på saldoen. Serialiseringen må da sørge for at det kritiske avsnittet gjøres bare av én prosess av gangen. Og vi begynte å se på metoder som kan gjøre dette her. Så vi hadde en lock-instruksjon som var sånn. Og den hindret da at andre prosesser endret på saldoen. Det gjorde vi med P-treads. Det som også var avgjørende da, var at vi låste minnebussen. Altså bussen ut til RAM. For det er det som er avgjørende når du har tråder som kjører på forskjellige CPU-er. Så er det ikke så lett å koordinere dem. For da opererer de totalt samtidig og helt uavhengig av hverandre. Hvis begge kjører på samme CPU, så har du tross alt en context switch.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0011", "start": 819.72, "end": 910.64, "token_count": 288, "text": "For det er det som er avgjørende når du har tråder som kjører på forskjellige CPU-er. Så er det ikke så lett å koordinere dem. For da opererer de totalt samtidig og helt uavhengig av hverandre. Hvis begge kjører på samme CPU, så har du tross alt en context switch. Selv om det kan bli trøbbel der òg. Men når du er på forskjellige CPU-er, så må minnebussen låses for at ikke to prosesser skal hente ut en kode eller samtidig endre. Eller det vil si at ikke begge skal hente ut den nåværende verdien, og så skrive tilbake uten å koordinere med den andre. Men hvis du kjører selv, hvis du kjører på samme CPU, så har vi sett at én instruksjon sånn som dette her... Den fører faktisk til minst to instruksjoner på maskinnivå. På assembly-nivå. Og det er det operativsystemet ser. Så når operativsystemet skedulerer to prosesser... Selv på samme CPU så kan det da komme en context switch midt inne i denne oppdateringen.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0012", "start": 882.16, "end": 975.64, "token_count": 281, "text": "Den fører faktisk til minst to instruksjoner på maskinnivå. På assembly-nivå. Og det er det operativsystemet ser. Så når operativsystemet skedulerer to prosesser... Selv på samme CPU så kan det da komme en context switch midt inne i denne oppdateringen. Og da kan det som Prosess 2 utfører av institusjoner, det kan da bli ødelagt av den andre fordi de ikke koordinerer. Og fordi det kan komme context switch midt inne i kritisk avsnitt. For da blir kritisk avsnitt større enn én linje. er en maskininstitusjon, så vil vi ikke få det problemet med context-witching på samme SPU. Men problemet kan likevel oppstå når vi har flere SPU. Nå skal jeg se på noen metoder for å... ... for å behandle kritiske avsnitt. Med disse metodene skal vi sikre oss at bare én prosess eller én tråd av gangen utfører sitt kritiske avsnitt før en annen prosess gjør det. I prinsippet kan det være ti tråder som samtidig ønsker å gå inn", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0013", "start": 954.88, "end": 1041.06, "token_count": 287, "text": "... for å behandle kritiske avsnitt. Med disse metodene skal vi sikre oss at bare én prosess eller én tråd av gangen utfører sitt kritiske avsnitt før en annen prosess gjør det. I prinsippet kan det være ti tråder som samtidig ønsker å gå inn i et kritisk avsnitt, men det avgjørende her er bare én av gangen. En veldig direkte måte å sørge dette for, det er å skru av interrupts. Skrur jeg av interrupts, så er du sikker på at... Da er du sikker på at det ikke kommer noen context switch, i hvert fall på denne CPU-en. Igjen så kan det være trøbbel med andre CPU-er. Men hvis vi er på samme CPU, så kan vi sikre et kritisk asynytt ved at først disse blir interrupts. Og så enable interrupts etterpå. For da er vi... Selv om dette kritiske avsynet da består av flere maskininstitusjoner, så er man likevel sikker på at ingen... Det kan ikke skje noe context-witch, for interrupt er skrudd av. Og husker interrupts det... Eller context-witcher...", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0014", "start": 1023.0, "end": 1103.72, "token_count": 296, "text": "For da er vi... Selv om dette kritiske avsynet da består av flere maskininstitusjoner, så er man likevel sikker på at ingen... Det kan ikke skje noe context-witch, for interrupt er skrudd av. Og husker interrupts det... Eller context-witcher... Det skjedde ved at det kommer en timer-interrupt. Så man ikke behandler det timer-interrupten med en gang, men venter til koden er ferdig. Så vil det ikke kunne skje... Da vil ingen kunne avbryte knyttet gassnett. Dette er OK for en OUS-kjerne. Det er kode i OUS-kjernen som skrur av interrupts for å være helt sikker på å fullføre et kritisk gassnett. Men det ville vært veldig kritisk hvis brukerprosesser kunne gjøre dette her, for da kunne de straks ta over styringen. Så dette... Dette er OK for en O-stjerne, men generelt kan man ikke gi en slik metode til en vanlig brukerprosess. Metode B, som man da må bruke på brukerprosesser, det er å lage en slags lås. Det er litt sånn som den lock-instruksjonen som vi har sett på.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0015", "start": 1080.0, "end": 1180.48, "token_count": 293, "text": "Dette er OK for en O-stjerne, men generelt kan man ikke gi en slik metode til en vanlig brukerprosess. Metode B, som man da må bruke på brukerprosesser, det er å lage en slags lås. Det er litt sånn som den lock-instruksjonen som vi har sett på. Man lager en lås, sånn at bare én prosess av gangen har tilgang til fellesdata. Generelt kalles en slik lås Mutex. Det står da for Mutual Exclusion. På norsk betyr det gjensidig utelukkelse. Man sørger for å utelukke hverandre. Dette er den mest brukte metoden generelt. Det fins mange implementasjoner av det, og vi skal se noen eksempler på implementasjoner. Men... det som er viktig her, er at man må da utelukke alle andre. Og... Ja, en mutex... Den lockwool-funksjonen vi hadde, den gjelder bare for én institusjon. Men en mutex generelt, det er på en måte Så lenge man beholder den nøkkelen, er man inne i kritiske avsnitt, og da kan ingen andre komme inn i kritiske avsnitt og gjøre noe.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0016", "start": 1154.32, "end": 1254.24, "token_count": 289, "text": "Ja, en mutex... Den lockwool-funksjonen vi hadde, den gjelder bare for én institusjon. Men en mutex generelt, det er på en måte Så lenge man beholder den nøkkelen, er man inne i kritiske avsnitt, og da kan ingen andre komme inn i kritiske avsnitt og gjøre noe. Så det kan vare lenger enn en enkelt institusjon. Og dermed så kan det også brukes til å serialisere kode som har mer enn én institusjon i kritiske avsnitt. Her er et lite Linux-eksempel på... Som viser den i et annet tilfelle, hvor man bruker en lås. Og det ligner på lokk og Mutex, dette også. Og det er en teknikk man ofte bruker for å si fra at... ... nå bruker jeg denne filen. Ingen aner om å bruke den. Så gjøres det ved at man lager en lokk per bruker. Så hvis man driver og leser og skriver e-post til denne brukeren... For alle e-postene i Sendmail, det er bare en stor fil med e-poster. Og hvis man får e-post eller gjør noen endringer på den filen,", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0017", "start": 1230.0, "end": 1318.72, "token_count": 292, "text": "Så gjøres det ved at man lager en lokk per bruker. Så hvis man driver og leser og skriver e-post til denne brukeren... For alle e-postene i Sendmail, det er bare en stor fil med e-poster. Og hvis man får e-post eller gjør noen endringer på den filen, så lager Linux-systemet en sånn lokk-fil. For at andre prosesser ikke endrer på innboksen. Da må alle prosesser som skal endre på denne filen... Altså på... ikke på lokkfilen, men på innholdet i mailen... Det er en annen fil, som kanskje heter Var Mail Haugerud. Så sjekker da bare prosessene. Finnes den filen her? Nei, hvis den ikke finnes, OK, da kan jeg gjøre endringer. Den kan gjøre å stå i en venteløkke og sjekke om filen gjøres, og så gå inn hvis den ikke finnes. Det er et enkelt eksempel på en lokk. Men vi skal se at et sånt system er ikke helt bombesikkert. For igjen så kan du få trøbbel med contact switcher. I Windows så har vi akkurat den samme problemstillingen.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0018", "start": 1297.76, "end": 1389.92, "token_count": 288, "text": "og så gå inn hvis den ikke finnes. Det er et enkelt eksempel på en lokk. Men vi skal se at et sånt system er ikke helt bombesikkert. For igjen så kan du få trøbbel med contact switcher. I Windows så har vi akkurat den samme problemstillingen. Det har to funksjonskall, enter critical section og leave critical section, som er da igjen et tilbud til programmerere å lage kritiske avsnitt. Og disse funksjonskallene vil da sørge for at etter enter critical section, så vil ingen andre prosesser, heller ikke på andre CPU-er, vil endre på... Endre på de felles variablene. Det som typisk er felles, det ligger i ramm. Så igjen så vil disse funksjonskallene låse av bussen, sånn at man har enerett på å endre de områdene av ramm som man ser på. Det er klart, dette forsinker alle jobber som er... Som kjører i parallell. Vi kjører i parallell for å få det til å gå fortere. Hvis det er veldig mye synkronisering, så vil det gå saktere.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0019", "start": 1363.68, "end": 1459.16, "token_count": 298, "text": "sånn at man har enerett på å endre de områdene av ramm som man ser på. Det er klart, dette forsinker alle jobber som er... Som kjører i parallell. Vi kjører i parallell for å få det til å gå fortere. Hvis det er veldig mye synkronisering, så vil det gå saktere. Men dette er da opp til programmereren å lage et system som er smart nok, og som ikke bruker altfor mye tid i kritiske avsett. Ja, vi har allerede sett på LOC, på X86-institusjonen LOC. Og som vi skal se senere, så trenger man... For å lage en effektiv løsning, så trenger man hjelp fra hardware. Men det går også an å lage softwareløsninger som... Selv om de kjører på... Eller selv om det kan komme en context switch, som sørger for en mutex. Og hvis vi tenker at vi ønsker en softwareløsning, ja... Da... Vi ønsker oss gjerne å ha to funksjoner eller metoder sånn som dette - getmutex og release-mutex. Og getmutex, den metoden ønsker vi skal hente en lokk. Vi skal hente en nøkkel.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0020", "start": 1434.92, "end": 1528.64, "token_count": 297, "text": "Og hvis vi tenker at vi ønsker en softwareløsning, ja... Da... Vi ønsker oss gjerne å ha to funksjoner eller metoder sånn som dette - getmutex og release-mutex. Og getmutex, den metoden ønsker vi skal hente en lokk. Vi skal hente en nøkkel. Og så sier vi da at nå har jeg denne nøkkelen. Ingen andre må ta den. Ingen andre kan ta den. Så da kan jeg utføre mitt kritiske avsnitt. Så... Etterpå kan jeg gi fra meg nøkkelen. Og dette virker jo enkelt og greit. Så da burde man egentlig ha løst hele problemet. Men vi skal se at det er ikke så enkelt som man skulle tro. Så dette er første forsøk på å lage en software musex. De andre forsøkene er det oppgaver om denne uken. Så se på de oppgavene senere. Men vi skal se på dette første forsøket, som er liksom det enkleste man kan få til, og som tilsvarer det å lage en maillock. Vi hadde et eksempel hvor vi lagde en fil, og så sjekker alle andre prosesser om den filen finnes.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0021", "start": 1506.24, "end": 1611.08, "token_count": 297, "text": "Men vi skal se på dette første forsøket, som er liksom det enkleste man kan få til, og som tilsvarer det å lage en maillock. Vi hadde et eksempel hvor vi lagde en fil, og så sjekker alle andre prosesser om den filen finnes. Det er egentlig det tilsvarende, men vi får det samme problemet. Vi tenker oss at vi har en static boolen lock. Det er da en felles variabel som er tru eller fals. Og den er static i betydning av at to eller flere prosesser kan aksessere den. Vi skal ha kode som sikrer denne lokken. Og da kan vi gjøre det på denne måten her. Vi kan si getmutex-lokk... Den kan være sånn at... Dette er en litt spesiell konstruksjon, men den funker i Java, f.eks. Og det er vile lock. Og så kommer det bare to parenteser. Og de to parentesene, de er... De gjør ingenting. Og det er faktisk en maskininstitusjon som gjør ingenting, og den heter NOP - No Operation. Så vild lock, og så ingenting. Det den gjør, det er at den bare tester om og om igjen om lock er true.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0022", "start": 1584.84, "end": 1675.52, "token_count": 292, "text": "Og de to parentesene, de er... De gjør ingenting. Og det er faktisk en maskininstitusjon som gjør ingenting, og den heter NOP - No Operation. Så vild lock, og så ingenting. Det den gjør, det er at den bare tester om og om igjen om lock er true. Den tester om og om igjen om lock er true eller false. Hvis lock er true, så går den inn i løkka og gjør ingenting. Det den da gjør, er at den hele tiden sjekker om lock er true. Så den står her og gang på gang tester. Er lock true? Er lock true? Er lock true? Og hele tiden, hvis... Hvis lock er true, så står den og venter. Og da er det klart. Der vil den stå evig. Med mindre det er... Det er andre prosesser som aksepterer denne lokken og setter den til false. Så hvis ingen andre har satt denne til false før, så vil den første prosessen som gjør GetMuteX, den vil gå inn... Lock er false, så da hopper den over denne her og så setter den locklike true. Og da er det trygt, for da kan den gå inn i sitt kritiske avsnitt.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0023", "start": 1656.12, "end": 1735.54, "token_count": 282, "text": "Så hvis ingen andre har satt denne til false før, så vil den første prosessen som gjør GetMuteX, den vil gå inn... Lock er false, så da hopper den over denne her og så setter den locklike true. Og da er det trygt, for da kan den gå inn i sitt kritiske avsnitt. For den har nå gått inn, satt locklike true. Det er som å skru på en lås. Det er som om man går inn på et toalett og vrir på låsen, for da er det et signal til alle andre. Da er det rødt. Ingen kan komme inn her. Da er det safe. Så hvis en annen prosess kommer inn og også prøver å gjøre get mutex før det kritiske avsnittet, så vil den komme inn og så se... Da må jeg stå her og vente. Og den står og venter og venter helt til den første prosessen som kom inn, har releaset Mutex. Først gjør man get Mutex, hente låsen, så Kritisk avsnitt, og så release Mutex. Så når da prosess nummer to er ferdig med å sette Kritisk avsnitt, så vil den release Mutex.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0024", "start": 1713.76, "end": 1835.28, "token_count": 298, "text": "helt til den første prosessen som kom inn, har releaset Mutex. Først gjør man get Mutex, hente låsen, så Kritisk avsnitt, og så release Mutex. Så når da prosess nummer to er ferdig med å sette Kritisk avsnitt, så vil den release Mutex. Og det gjør den ved å sette locklick-folds. Og da vil de som måtte da De vil da komme inn i Kritisk Asenytt, og så vil de sette lock-lick, tror jeg. Så dette ser ut som det perfekte opplegg. Men her er det et problem. Jeg har stilt et spørsmål her. Dette burde sikre at to prosesser ikke er i Kritisk Asenytt samtidig. Vi kan få et problem her, og det er hvis... Hva skjer hvis det kommer en context switch? Vi tenker oss at disse kjører på samme CPU. Hva om det kommer en context switch rett etter at denne prosessen har testet om... Om lock er false. Vi antar at lock er false. Og så vil jeg jo... En sånn test består av flere deler. Første del må hente inn verdien og legge et register. Og så må den, etter at den har hentet den inn,", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0025", "start": 1789.32, "end": 1897.44, "token_count": 283, "text": "Hva om det kommer en context switch rett etter at denne prosessen har testet om... Om lock er false. Vi antar at lock er false. Og så vil jeg jo... En sånn test består av flere deler. Første del må hente inn verdien og legge et register. Og så må den, etter at den har hentet den inn, gjøre en compare, sammenligne den verdien med null, f.eks. Og så må den, etter en compare, hoppe, avhengig av verdien. Men det der utføres i minst to institusjoner. Så hva skjer om det kommer en context switch nøyaktig etter at den har hentet inn verdien? Jo, da fryser selv den prosessen. Det neste den vil gjøre, er å sette lock like through og gå inn i kritisk avsnitt. Men når denne første prosessen kommer i en fryser, og så kommer prosess nummer to inn, da er jo lokk fortsatt false. Så den prosess nummer to, den vil enkelt og greit bare hoppe over den løkka. Lock er false. Men da er det for sent, for da er P1 allerede inne i kritiske avsnitt.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0026", "start": 1877.14, "end": 1960.12, "token_count": 294, "text": "og så kommer prosess nummer to inn, da er jo lokk fortsatt false. Så den prosess nummer to, den vil enkelt og greit bare hoppe over den løkka. Lock er false. Men da er det for sent, for da er P1 allerede inne i kritiske avsnitt. Og så kommer P2 etter, og den går også inn i kritiske avsnitt. Og da er vi tilbake til de gamle problemene. Hvis akkurat dette inntreffer, så kan begge to kjøre kritiske avsnitt samtidig. Så derfor så fungerer rett og slett ikke denne software-løsningen. Den vil fungere stort sett, bortsett fra hvis det kommer et kritisk avsnitt nøyaktig etter violet lock. Nøyaktig etter at verdien er hentet inn til registrene, men rett før den hopper på grunnlag av denne verdien. Så derfor er ikke denne god nok. Og i øvingsoppgavene så... Så kommer det et par andre nye forsøk som er litt... Og til slutt kommer man fram til Peterson-algoritmen, som kom i gang på 80-tallet, som er en perfekt software-mytex-løsning.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0027", "start": 1937.08, "end": 2038.88, "token_count": 292, "text": "Så derfor er ikke denne god nok. Og i øvingsoppgavene så... Så kommer det et par andre nye forsøk som er litt... Og til slutt kommer man fram til Peterson-algoritmen, som kom i gang på 80-tallet, som er en perfekt software-mytex-løsning. Men den er litt tungvint, og du trenger litt kode. Men den kan man bruke. Men i praksis, sånn som med operativstemme og sånn som med Java Traws osv., Hvor man får hjelp fra hardware. Og det sikrer i tillegg at man lokker databussen. Så de metodene er da enda bedre. Ja, så... Harway støtter Mutex. I de softwareløsningene som vi har sett på, de krever litt kode. Og i tillegg bruker de alle sammen. Buzzy waiting. Buzzy waiting er dette med at man står og venter. Og da bruker man CPU-en. Man gjør NOP-institusjoner om og om igjen. Og det er en litt effektiv måte å vente på. Men det kalles da generelt buzzy waiting. Så i praksis så brukes... Blant annet pga. det så brukes som oftest", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0028", "start": 2010.0, "end": 2096.94, "token_count": 283, "text": "Buzzy waiting. Buzzy waiting er dette med at man står og venter. Og da bruker man CPU-en. Man gjør NOP-institusjoner om og om igjen. Og det er en litt effektiv måte å vente på. Men det kalles da generelt buzzy waiting. Så i praksis så brukes... Blant annet pga. det så brukes som oftest Løsninger. Og de kan lages... En sånn hardway-støttet løsning kan lages hvis man har en institusjon som f.eks. TestAndSet TSL. Det er da en institusjon som gjør begge de to operasjonene som vi snakket om på forrige slide, nemlig å teste verdien og endre den. I én og samme institusjon. Det er viktig at det er én og samme institusjon. For det gjør at det ikke kan komme... ... ikke kan komme en kontekst-switch mens dens institusjon utføres. Og en test-and-set vil i tillegg låse minnebussen ut i RAM, sånn at ikke andre CPU-er kan lese verdien. Da kan man implementere GetMuteX på følgende måte. ", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0029", "start": 2070.0, "end": 2166.32, "token_count": 297, "text": "For det gjør at det ikke kan komme... ... ikke kan komme en kontekst-switch mens dens institusjon utføres. Og en test-and-set vil i tillegg låse minnebussen ut i RAM, sånn at ikke andre CPU-er kan lese verdien. Da kan man implementere GetMuteX på følgende måte.  Man har da Vile test and set lock. Og denne operasjonen, det er bare da én institusjon. Og midt inni den institusjonen så kan det ikke komme en context switch. Og siden den i tillegg låser minnebussen, så er man da bombesikker på at bare denne end-prosessen kommer inn i kritisk avsnitt av gangen. Og dette er da en perfekt løsning. Vi så forrige gang på X86-institusjonen LOC. Og det... Den LOC-institusjonen, den utføres før en kritisk institusjon. Den koden vi hadde sist, var at vi først hadde LOC, og så hadde vi en ad, eller en ink. Og den gjør at man låser av minnebussen, sånn at ingen andre CPU-er heller. Får endre den verdien, den minneadressen, som man bruker.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0030", "start": 2135.52, "end": 2223.72, "token_count": 290, "text": "Den LOC-institusjonen, den utføres før en kritisk institusjon. Den koden vi hadde sist, var at vi først hadde LOC, og så hadde vi en ad, eller en ink. Og den gjør at man låser av minnebussen, sånn at ingen andre CPU-er heller. Får endre den verdien, den minneadressen, som man bruker. Alle andre minneadresser kan brukes, men ikke akkurat den. Det sikrer da at institusjonen etter lokk... Den vil være den eneste som kan endre på den variabelen som kommer etter lokkinstitusjonen. Sørger da for at det kritiske avsnittet fullføres uten at noen andre tråder kommer inn. Dette fungerer bare hvis det kritiske avsnittet kun er én enkel institusjon. Men det kan det ofte være. Man kunne i prinsippet bruke en sånn walkie-institusjon til å lage en mutex. Men da bruker man heller en test-and-set-institusjon. Og test-and-set-institusjon er også en X86-institusjon. Hvis man skal lese om dette, så kan man slå opp i Intels 86-manual.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0031", "start": 2203.84, "end": 2315.32, "token_count": 300, "text": "Man kunne i prinsippet bruke en sånn walkie-institusjon til å lage en mutex. Men da bruker man heller en test-and-set-institusjon. Og test-and-set-institusjon er også en X86-institusjon. Hvis man skal lese om dette, så kan man slå opp i Intels 86-manual. Der står det om hvordan denne lokkinstruksjonen låser av. Låser av bussen og hindrer at noen andre endrer på verdi. Som sagt så var det et par ting vi ikke gjorde da vi så på den forrige gang. Så jeg tenker vi skal gå tilbake til den. Repetere hva vi gjorde sist. Og så skal vi... Og så skal vi... gjøre en annen... Jo, vi skal gjøre noe som vi ikke så på sist. Et spørsmål i chatten her. Test1set funker også hvis det er snakk om prosess på forskjellige CPU-er. Den låser også minnebussen, sånn at da er det ingen andre som heller kan endre på den verdien i RAM, hvor lokkvariabelen er lagret. Så vi kan kjøpt repetere... Skal vi se... Vi kan raskt se på hva vi gjorde forrige gang.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0032", "start": 2276.92, "end": 2400.02, "token_count": 291, "text": "Den låser også minnebussen, sånn at da er det ingen andre som heller kan endre på den verdien i RAM, hvor lokkvariabelen er lagret. Så vi kan kjøpt repetere... Skal vi se... Vi kan raskt se på hva vi gjorde forrige gang. Først og fremst hadde vi ett program, to program, tred.c, som en rekke ganger, ti millioner ganger allerede... Hundre millioner ganger. Så utfører det én linje. Og den én-linje-operasjonen... ... det eneste den gjør, er at den øker verdien på en fellesvariabel svar med én. Og i dette Main-programmet så ser vi at vi har to tråder. Og de to trådene, de utfører den INK-operasjonen. Det blir to tråder som 100 mill. ganger øker trådverdien med 1. Og det man skulle tro da, det var at... De to trådene til slutt da skulle få den fellesvariabelen til å være 200 mill. Men vi kan se hvordan det ser ut. Hvis vi kompilerer... Og så kjører vi AdoptOut.", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0033", "start": 2371.36, "end": 2495.8, "token_count": 293, "text": "Og det man skulle tro da, det var at... De to trådene til slutt da skulle få den fellesvariabelen til å være 200 mill. Men vi kan se hvordan det ser ut. Hvis vi kompilerer... Og så kjører vi AdoptOut. Så ser vi at... Og dette så vi forrige gang. Resultatet blir aldri 200 000, sånn som vi ønsket det skulle bli. Og da... Det vi gjorde da, var at vi... Jo, vi var... For det første så var vi ikke sikre på om denne institusjonen ble utført bare som én linje. Fordi det var jo en sånn svar pluss, pluss. Så det kunne føre til flere linjer. Så for å være helt sikker på det, så kompilerte vi Tred.c Med denne assembly-koden, hvor du har én linje som øker svar med én. Så... Hvis vi gjør det om igjen, komplerer den sammen med minMoldatS, så så vi fortsatt at likevel... så ble svaret forskjellig hver gang. Men det er da vi kan komme inn med en... Med instruksjon lokk. Denne instruksjonen låser minnebussen,", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0034", "start": 2466.46, "end": 2574.76, "token_count": 296, "text": "Så... Hvis vi gjør det om igjen, komplerer den sammen med minMoldatS, så så vi fortsatt at likevel... så ble svaret forskjellig hver gang. Men det er da vi kan komme inn med en... Med instruksjon lokk. Denne instruksjonen låser minnebussen, sånn at neste gang så er det kun én tråd som kan endre på den verdien. Så hvis vi da kompilerer den på nytt, og kjører... Så ser vi nå så tar det litt lengre tid. Og det er fordi det foregår noe synkronisering. Men heldigvis så blir svaret riktig hver eneste dag. Men... Det vi da ikke så på sist, varer hva skjer om vi kjører dette her på... Jo, vi så også på det sist. Hva skjer om vi setter disse her på samme SUPU? Den gjør nå at begge må kjøre på samme CPU. Da ser vi... Jo, det fungerer fortsatt som det skal, selv om de kjører på samme CPU. Det at vi kjører på samme CPU, det kan vi også se med time. Hvis det tar time... Hvis det tar time når de kjører på hver sin...", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0035", "start": 2552.64, "end": 2670.84, "token_count": 294, "text": "Da ser vi... Jo, det fungerer fortsatt som det skal, selv om de kjører på samme CPU. Det at vi kjører på samme CPU, det kan vi også se med time. Hvis det tar time... Hvis det tar time når de kjører på hver sin... Så ser vi her... Her er det 189 % CPU-tid. Og det er et tydelig tegn på at... Jo, de kjører faktisk på hver sin CPU. Mens når jeg setter dem med Tasset, så ser vi at de kjører på samme CPU og får bare 100 %. Så... Men det med time... Det var bare for å vise eksplisitt at typisk... Hvis du setter i gang to tråder, så kjører de på hver sin CPU. De deler ikke på CPU-en til. Skal vi se... Men det vi skal se på nå, det er... Hva om vi skriver kode som... Denne endringen i to operasjoner. Så... Her er det... Dette er assembly-kode som er generert av GCC. Og det som var problemstillingen, var at vi vet ikke... Genererer GCC kode som utfører den økningen av svar? I én enkel institusjon, eller er det flere?", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0036", "start": 2645.12, "end": 2737.48, "token_count": 289, "text": "Så... Her er det... Dette er assembly-kode som er generert av GCC. Og det som var problemstillingen, var at vi vet ikke... Genererer GCC kode som utfører den økningen av svar? I én enkel institusjon, eller er det flere? Her har jeg skrevet kode som eksplisitt gjør dette her i tre operasjoner, sånn som man kan risikere. Så dette her er da tre operasjoner for å endre svar. Man flytter først svarvarabelen over eax, og så øker man eax, og så flytter man svaret ut igjen. Og hvis vi kjører denne koden, så skal vi se at... Da... Da kan man også få problemer hvis man... Hvis man har en context switch. Altså hvis man med tassett tvinger begge til å kjøre på samme SUP, men likevel kan man få problemer. Men jeg ser... Nå er vi godt over tiden. Så vi tar en... Vi tar en pause, så skal vi etter pausen se på... Skal vi sammenligne... Hva skjer når vi kjører kode hvor dette her er tre instruksjoner, og sammenligne med det vi har sett før,", "source": "lecture"}
{"lecture_id": "os12time1", "chunk_id": "os12time1_0037", "start": 2715.04, "end": 2763.24, "token_count": 159, "text": "Men jeg ser... Nå er vi godt over tiden. Så vi tar en... Vi tar en pause, så skal vi etter pausen se på... Skal vi sammenligne... Hva skjer når vi kjører kode hvor dette her er tre instruksjoner, og sammenligne med det vi har sett før, når vi bare har én enkelinstruksjon som endrer på verdien? Vil det da ha noe å si når du kjører med tasset og tvinger begge til å kjøre på samme super? Og det skal vi se at det er en forskjell. Men det kommer vi til etter pause. Hva er det som er så spesielt med denne filmen?", "source": "lecture"}
{"lecture_id": "linux5del10", "chunk_id": "linux5del10_0000", "start": 0.0, "end": 132.14, "token_count": 295, "text": "Tilsvarende kan denne teknikken f.eks. brukes til å lese fra PCAWX. PCAWX vil da ha en rekke... Skriv litt... En rekke linjer, som starter med brukernavn, så UD, altså en del forskjellig informasjon om prosessene. Så vi kan prøve å lage nå en tilsvarende konstruksjon som utfører PSAOX, og så pipe alle dataene til valgkonstruksjonen. Nå vil jo da feltene være noen andre. Men det første feltet er fortsatt brukernavnet. Og så etter brukernavnet så kommer... La oss si nå at vi ikke er interessert i resten, så kan vi bare si... Bare kalle resten for X. Da vil resten av linjen tilhøre X. Så... Da kan vi se... Har... Har prosess... Har prosess payday. På den måten. Da skal vi ikke sende inn passord. Og sånn kan vi løpe gjennom alle prosesser. Da kjører vi wire.shell og så sender vi den til MORE. Den begynner nå øverst, brukernavn User har Prosess by ID. Det er fra den første linja, men dette er brukernavn Ruth, har Prosess 1 osv.", "source": "lecture"}
{"lecture_id": "linux5del10", "chunk_id": "linux5del10_0001", "start": 104.56, "end": 223.8, "token_count": 292, "text": "Og sånn kan vi løpe gjennom alle prosesser. Da kjører vi wire.shell og så sender vi den til MORE. Den begynner nå øverst, brukernavn User har Prosess by ID. Det er fra den første linja, men dette er brukernavn Ruth, har Prosess 1 osv. Hvis vi f.eks. ønsker å få ut... Navnet på programmet, så kan vi legge inn... Da er det et antall felter før... Den siste er Prog. Skal vi se om dette blir riktig. Vi kan prøve oss frem. Har prosess... Det så ikke riktig ut. Da kan vi igjen se hva PSA og X egentlig gir. Så PayD, og så er det én, to, tre, fire, fem, seks, syv... åtte felter. Så da kan vi gå tilbake til skriptet og se hvor mange felter vi må legge inn før programmet kommer. Og det var én, to, tre, fire... Ja, det ser ut som åtte. Bra. Én til, da. Ja. Nå ser vi hva som var feil. Vi skriver fortsatt ut \"-pady\". Vi må skrive -prog. Sånn. Hvis vi kjører nå...", "source": "lecture"}
{"lecture_id": "linux5del10", "chunk_id": "linux5del10_0002", "start": 193.3, "end": 321.36, "token_count": 295, "text": "hvor mange felter vi må legge inn før programmet kommer. Og det var én, to, tre, fire... Ja, det ser ut som åtte. Bra. Én til, da. Ja. Nå ser vi hva som var feil. Vi skriver fortsatt ut \"-pady\". Vi må skrive -prog. Sånn. Hvis vi kjører nå... Så ser vi brukerne rundt, har prosess, Espen innitt, osv. nedover. For hver bruker. Bruker han Haugerud, har prosessbæsj der. Så på den måten så kan man løpe gjennom alle elementene i PSA og X. Så kan man jo i tillegg... Så kan dette brukes da til å f.eks. sjekke if... Er lik... La oss si høyre. Sånn som det. Så kan vi akkurat for den brukeren... Så kan vi skrive ut verdien... Eller navnene på programmet. Sånn. Hvis vi nå stopper den og kjører... Så får vi igjen en syntaksfeil. Der står det 'iften'... Ja, her skal man se at her er det mangler en apostrof. Jeg kan altså se på fargene på auditoren.", "source": "lecture"}
{"lecture_id": "linux5del10", "chunk_id": "linux5del10_0003", "start": 292.44, "end": 383.38, "token_count": 236, "text": "Sånn. Hvis vi nå stopper den og kjører... Så får vi igjen en syntaksfeil. Der står det 'iften'... Ja, her skal man se at her er det mangler en apostrof. Jeg kan altså se på fargene på auditoren. Hvis jeg kjører nå, så får jeg ut ingen. Og det... var merkelig, for noen av prosessene har brukerne høyere. Og da ser vi hva som er feil her. Her er det mangler en dollar. Da kjører vi på nett. Og da ser vi at her skrives det bare ut prosesser. Du får de linjene hvor man har brukernavn Høyre. Så kun de skrives ut. Så på den måten kan man løpe gjennom PSA og X, etc. password og alle andre typer filer med en wireløkke, og så kan man behandle linje for linje. Den type skript er genelt veldig nyttig å kunne skrive.", "source": "lecture"}
{"lecture_id": "os1del16", "chunk_id": "os1del16_0000", "start": 0.0, "end": 78.1, "token_count": 294, "text": "Ja. Her ser vi utskrift fra topp i Linux. Og det viser da alle de prosessene som står her og kjører. Og hvor lenge de har levd. Eller det vil si da hvor lenge de har kjørt. Mye tid de har brukt, mye CPU de bruker osv. Og det ser veldig likt ut på Windows. Akkurat det samme med ID-er osv. Så dette er sånt som vi skal se på. Vi skal se på disse utskriftene senere i detalj, og hva alt betyr. Et annet prinsipp som er veldig viktig når det gjelder operativsystemer, det er abstraksjon og hierarkier. Det er nemlig det at man har bokser på høynivå, der har man oversikten. Dette kan være hele operativsystemet, kanskje. Og så tar man ut en del av operativsystemet som kanskje har med Hvordan fordeles CPU-tid? Og så går man enda lenger ned og ser på detaljene inni her. Dette er ekstremt viktig. Det vet dere fra f.eks. objektorientert programmering. At man lager moduler som gjør akkurat det man skal.", "source": "lecture"}
{"lecture_id": "os1del16", "chunk_id": "os1del16_0001", "start": 55.0, "end": 139.44, "token_count": 287, "text": "Og så tar man ut en del av operativsystemet som kanskje har med Hvordan fordeles CPU-tid? Og så går man enda lenger ned og ser på detaljene inni her. Dette er ekstremt viktig. Det vet dere fra f.eks. objektorientert programmering. At man lager moduler som gjør akkurat det man skal. Og så bygger man opp hierarkier av denne type systemer. Ikke mens hardware, som vi skal begynne å se på nå, så er det... Så er det veldig bygd opp av denne type abstraksjoner. Om man sier OK, dette er en liten boks som gjør sånn og sånn, så bygger vi et stort hele av masse små bokser. Et Linux-eksempel på hierarki, det er hvis man gjør en kommando sånn som dette... Cat, it's message of today. Det er en kommando som bare skriver ut litt tekst som ligger i den filen. For å få til det, så gjøres det en rekke systemcall. Dette er systemcall som er API til Linux-kjernen. F.eks. gjør man open, read, close og en mengde andre systemcall.", "source": "lecture"}
{"lecture_id": "os1del16", "chunk_id": "os1del16_0002", "start": 111.72, "end": 190.28, "token_count": 204, "text": "Cat, it's message of today. Det er en kommando som bare skriver ut litt tekst som ligger i den filen. For å få til det, så gjøres det en rekke systemcall. Dette er systemcall som er API til Linux-kjernen. F.eks. gjør man open, read, close og en mengde andre systemcall. Med kommandoen strace. Hvis man utfører den, så får man se alle... Her er det listet opp. Kjør en kommando, uname, break, access, open, old, close osv. Les filen. Det er en rekke systemcall som under huden på den ene kommandoen. Så ligger det en rekke systemcall. Alle applikasjonsprogrammer gjør. De snakker med operativsystemet gjennom den typen systemkall når de skal gjøre noe spesifikt med Hardware.", "source": "lecture"}
{"lecture_id": "os4del14", "chunk_id": "os4del14_0000", "start": 0.0, "end": 111.92, "token_count": 287, "text": "Det vi skal se på da aller først, det er et C-program som summerer. Så her har jeg et C-program som egentlig gjør akkurat det samme som vi kjørte i simuleringen vår, nemlig den S-løkken som går. Den går tre ganger. Eller faktisk... Hvor mange ganger går denne her? Den starter på I lik null. Så den går en ekstra gang hvor den ikke legger til noe. Så det hadde vel egentlig vært riktigere å starte på én her, hadde ikke det? Hvis jeg starter på 1, så gjør den det samme som vår simulering. Altså den starter med i lik 1, og s er initiert til 0. Og så økes den første runde, så blir den 1. Så legges i lik 2, så legges 2 til, så blir det 3. Så går i opp i lik 3, og så legges den til, så får vi resultatet 6. Vi skal se hvordan dette utføres når vi kompilerer og kjører dette programmet. Hvordan blir egentlig maskinkoden? Da er det viktig å vite at når man deklarerer en variabel, s lik 0 her,", "source": "lecture"}
{"lecture_id": "os4del14", "chunk_id": "os4del14_0001", "start": 84.2, "end": 191.18, "token_count": 294, "text": "Så går i opp i lik 3, og så legges den til, så får vi resultatet 6. Vi skal se hvordan dette utføres når vi kompilerer og kjører dette programmet. Hvordan blir egentlig maskinkoden? Da er det viktig å vite at når man deklarerer en variabel, s lik 0 her, så tilordnes det en adresse i ramm til denne variabelen. Den er på 4 byte, eller 32 bit. Og det igjen er bare en konvensjon. I C så skal integer være 4 bite, eller 32 bit. Det samme med tallet her, I. Den er også 4 bite. Men så har man andre variabler. F.eks. så går det an å lage en long-long int, som er 64 bit. Så når det lages plass til denne variabelen her i ramm, så settes det av fire bites som ligger rett etter hverandre. Og det... Når man da skal aksessere den variabelen, så sender man ut på bussen en adresse. Adresse 100.045. Der ligger vår variabel. Og så er det fire bite etter hverandre som ligger der. OK... Jeg kunne ha skrevet dette, all koden, inne i Maine.", "source": "lecture"}
{"lecture_id": "os4del14", "chunk_id": "os4del14_0002", "start": 160.76, "end": 269.92, "token_count": 292, "text": "Og det... Når man da skal aksessere den variabelen, så sender man ut på bussen en adresse. Adresse 100.045. Der ligger vår variabel. Og så er det fire bite etter hverandre som ligger der. OK... Jeg kunne ha skrevet dette, all koden, inne i Maine. Men det er lov å definere eller deklarere funksjoner på denne måten. Så nå har jeg gjort det for å kunne skille ut dette fra Maine. Hva skjer med akkurat denne koden? Hvordan ser den ut i maskinkode? Men før vi kommer så langt, så kan vi vise hvordan vi komplerer og kjører dette programmet. Sum.ce. Og så kan jeg kalle det SUM. Ja, det er spørsmålet hvorfor det står int-main og ikke void-main. Det er et litt for vanskelig spørsmål. Det fungerer hvis du skriver void main også, så vidt jeg husker. Men... Jeg tror det er en konvensjon fordi den returnerer et... Main returnerer et tall. Altså den returnerer en integer. Men det... Jo, det er mulig jeg returnerer det til operativstemme som en sånn feilkode etter at det har kjørt.", "source": "lecture"}
{"lecture_id": "os4del14", "chunk_id": "os4del14_0003", "start": 247.0, "end": 310.28, "token_count": 181, "text": "Men... Jeg tror det er en konvensjon fordi den returnerer et... Main returnerer et tall. Altså den returnerer en integer. Men det... Jo, det er mulig jeg returnerer det til operativstemme som en sånn feilkode etter at det har kjørt. At Maine da returnerer en integer-feilkode. Jeg tror det er det det kommer av. OK. Mens jeg kopierer programmet og kjører det, så ser vi at de får sum lik 6. Og siden vi var inne på det, skjer det noe annerledes hvis vi... Hvis vi starter med ild i knull? Nei. Det bør være det samme. Det er bare egentlig en overflødig linje. Så vi kan like gjerne starte på én.", "source": "lecture"}
{"lecture_id": "linux2del2", "chunk_id": "linux2del2_0000", "start": 0.0, "end": 80.46, "token_count": 282, "text": "Når man jobber med et Linux-skjell, så kan det ofte ta litt lang tid å fullføre kommandoene, spesielt hvis det er lange kommander og lange pilnavn osv. Og da fins det noen smarte triks som er veldig nyttige å lære seg. Én ting er hvis man har gjort en kommando tidligere, og så ønsker man å gjøre den på nytt.  Og så vet man at en eller annen gang tidligere har man gjort det. Den sakte måten er å skrive history. History sånn som det er. Og den gir da alle kommandoer du har hatt tidligere. Men da kan man jo bla seg tilbake i den. Men det tar mye tid. Eventuelt så kan man gjøre history, og så pipe den til more. Og så bla seg gjennom alle for å finne den kommandoen man ønsker. Men da er det et fint tips, og det er å bruke kontroll-r for å lete seg rekkerskift bakover i kommandoene. Så hvis jeg nå taster kontroll-r her... Og så husker jeg kanskje at jeg hadde en for-kommando en gang, som jeg gjorde.", "source": "lecture"}
{"lecture_id": "linux2del2", "chunk_id": "linux2del2_0001", "start": 63.72, "end": 152.18, "token_count": 297, "text": "Men da er det et fint tips, og det er å bruke kontroll-r for å lete seg rekkerskift bakover i kommandoene. Så hvis jeg nå taster kontroll-r her... Og så husker jeg kanskje at jeg hadde en for-kommando en gang, som jeg gjorde. Så taster jeg inn for, eller begynner å taste inn for, men da kommer det forslaget opp. Så kan jeg taste kontroll her en gang til og bla meg bakover i tidligere kommandoer. Når jeg har funnet en riktig, så kan jeg taste return med en gang og gjøre kommandoen, eller så kan jeg gå inn og editere den, kanskje endre den til seks, og så taste return og utføre den kommandoen som jeg har gjort tidligere. Så det er en veldig nyttig måte for å lete seg tilbake i tidligere kommandoer. En annen ting som er nyttig, er hvis man har veldig lange navn. F.eks. når man skal flytte seg i kataloger. La oss si jeg skal flytte meg til en katalog som begynner på KJ og har et kjempelangt navn. Så kan jeg skrive KJ, og så kan jeg trykke på Tab.", "source": "lecture"}
{"lecture_id": "linux2del2", "chunk_id": "linux2del2_0002", "start": 117.1, "end": 200.5, "token_count": 292, "text": "En annen ting som er nyttig, er hvis man har veldig lange navn. F.eks. når man skal flytte seg i kataloger. La oss si jeg skal flytte meg til en katalog som begynner på KJ og har et kjempelangt navn. Så kan jeg skrive KJ, og så kan jeg trykke på Tab. Hvis det er entydig, så kommer kjempelangt navn opp. Hvis det ikke er entydig, så må jeg trykke Tab to ganger. Da ser vi at det er to alternativer her. Kjempelangt navn eller kjipt, som er en annen mappe. Hvis jeg da skriver en E, så blir kjempelangt navn entydig. Da kan jeg taste Tab igjen, og så kan jeg bare gå ned ved å taste 3... Så det gjør det mye raskere å fylle ut navn. Så bare tast TAB én eller to ganger, så får du det du trenger. Eller du får de alternativene du trenger. Tilsvarende hvis jeg har en vedtatt kommando som begynner på NETT, så... La oss si jeg skal kjøre Nettstat, som er en nettverkskommando.", "source": "lecture"}
{"lecture_id": "linux2del2", "chunk_id": "linux2del2_0003", "start": 183.54, "end": 239.78, "token_count": 207, "text": "Så bare tast TAB én eller to ganger, så får du det du trenger. Eller du får de alternativene du trenger. Tilsvarende hvis jeg har en vedtatt kommando som begynner på NETT, så... La oss si jeg skal kjøre Nettstat, som er en nettverkskommando. Så kan jeg taste NETT og så TAB. Hvis det ikke kommer noe da, så betyr det at den ikke er entydig. Da får jeg se alle kommandoer som begynner på netstat. Så er det netstat. Da fortsetter jeg å ta sånn, taster S og så tabb en gang til. Da får jeg netstat, så kan jeg taste return, så får jeg kjørt den kommandoen. Så hvis du kan de to triksene, så går ting veldig mye raskere enn når du jobber på kommando. Og flere.", "source": "lecture"}
{"lecture_id": "os13del5", "chunk_id": "os13del5_0000", "start": 0.0, "end": 113.24, "token_count": 287, "text": "Internmin og cash. Vi har vært borti både internmin og cash tidligere i en del sammenhenger. Men vi skal nå se spesifikt på det som spesielt har med ramme å gjøre. Ikke så mye på cash, men vi skal se hvordan ram oppfører seg, Hva skjer når programmer lager store RA og bruker store mengder ram, og hvordan organiseringen av ram, ikke minst hvordan det skjer i operativsystem. Og jevnt så skjer det i nært samarbeid med hardware. Det er mange hardware-spesifikke instruksjoner og konstruksjoner. Ikke minst... MMU, som er lagd i hardware for at det å bruke ramm skal gå fort. Og veldig mye av dette skyldes at ramm i utgangspunktet er relativt tregt. Cash er mye raskere, eller S-ramm er mye raskere enn D-ramm. Så det har vi sett på tidligere. Vi har da lagt inn cash for at man skal hurtigere kunne snakke med RAM. Men utgangspunktet RAM - Random Access Memory... Det høres ut som et litt rart begrep - Random Access.", "source": "lecture"}
{"lecture_id": "os13del5", "chunk_id": "os13del5_0001", "start": 81.44, "end": 179.28, "token_count": 288, "text": "Cash er mye raskere, eller S-ramm er mye raskere enn D-ramm. Så det har vi sett på tidligere. Vi har da lagt inn cash for at man skal hurtigere kunne snakke med RAM. Men utgangspunktet RAM - Random Access Memory... Det høres ut som et litt rart begrep - Random Access. Men hovedpoenget med begrepet Random Access er at... Det er minnet hvor det går like fort å hente ethvert bite, uavhengig av hvor det ligger. Så hvis du skal hente bite nummer 1000, så... Med ram eller Random Access så betyr det at det går like fort å hente bite nummer 1000-1000. Uansett hvor det ligger i ram, så går det like fort å hente det. Og det er i og for seg riktig for en standard konstruksjon av ram, men i praksis så vil det ta forskjellig tid å hente en gitt bite. F.eks. en variabel svar som man har i et C-program. Hvis man skal gå ut i ram og hente den, så vil det være forskjellig hvor lang tid det tar. Det er først og fremst pga. cash.", "source": "lecture"}
{"lecture_id": "os13del5", "chunk_id": "os13del5_0002", "start": 152.14, "end": 230.0, "token_count": 295, "text": "men i praksis så vil det ta forskjellig tid å hente en gitt bite. F.eks. en variabel svar som man har i et C-program. Hvis man skal gå ut i ram og hente den, så vil det være forskjellig hvor lang tid det tar. Det er først og fremst pga. cash. Hvis du nylig har hentet den verdien, så vil den ligge i cash. Og cash er hurtigminne, og da går det hurtigere å hente. Sånn sett er det ikke random access i forhold til om du henter en variabel eller en bite som ikke har vært i minnet på lang tid. Da vil det gå raskt å hente den. Et annet tilfelle vi har hvor det er forskjell på tiden, det er med såkalt nummanoder. Hvis du har servere som har... Mange CPU-er, altså sånn titalls CPU-er, sånn som noen av de vi har sett på, med 48 CPU-er. Eller sånn som den serveren som dokkecontainerne kjører i, Linux-VM-ene, som vi kaller de, den har 60 CPU-er eller noe sånt. Den er da... Den har da et system av numanoder.", "source": "lecture"}
{"lecture_id": "os13del5", "chunk_id": "os13del5_0003", "start": 210.56, "end": 292.82, "token_count": 296, "text": "sånn som noen av de vi har sett på, med 48 CPU-er. Eller sånn som den serveren som dokkecontainerne kjører i, Linux-VM-ene, som vi kaller de, den har 60 CPU-er eller noe sånt. Den er da... Den har da et system av numanoder. Og det betyr at det er en slags cluster av CPU-er. Som tilhører spesielle noter. Og disse notene har da ram som ligger nærmere de notene. Rent og slett fysisk nærmere, sånn at de har raskere aksess. De har en egen minnebuss ut dit. Så NVE Super Kan hente da bites fra hele ram, men i noen tilfeller vil det ta lengre tid, fordi de ikke sitter på den nummadoden som de... Som de selv hører til. Og da vil heller ikke RAN være helt random. Men standard RAM er random access. Det går like lang tid å hente hver bite. Og dette er veldig forskjellig fra harddisker, som vi skal se på senere. Iallfall spinnende, tradisjonelle harddisker. Der er det avhengig av hvor lesehodet til harddisken står, osv.", "source": "lecture"}
{"lecture_id": "os13del5", "chunk_id": "os13del5_0004", "start": 271.4, "end": 355.48, "token_count": 285, "text": "Men standard RAM er random access. Det går like lang tid å hente hver bite. Og dette er veldig forskjellig fra harddisker, som vi skal se på senere. Iallfall spinnende, tradisjonelle harddisker. Der er det avhengig av hvor lesehodet til harddisken står, osv. En gitt del av minnet. Ok. Men som vi har sett tidligere... CPU, register og cash, det er laget av S-ram, static-ram. Og det består av seks temastiske historier. Jeg har sett på konstruksjonen av det tidligere. Og det er ekstremt hurtig, og det er statisk. Altså, det trenger ikke å oppfriskes. Ram eller internmine, derimot, det er laget av D-ram. Dynamic ram. Og det er en mye enklere konstruksjon. Det består bare av én transistor, og så er det én kondensator. En kondensator, det er da et lite element som kan holde på ladning. Så... Det holder på statisk ladning. Litt sånn som en ballong som du gnir på, så får du statisk ladning.", "source": "lecture"}
{"lecture_id": "os13del5", "chunk_id": "os13del5_0005", "start": 336.0, "end": 423.56, "token_count": 292, "text": "Det består bare av én transistor, og så er det én kondensator. En kondensator, det er da et lite element som kan holde på ladning. Så... Det holder på statisk ladning. Litt sånn som en ballong som du gnir på, så får du statisk ladning. En kondensator kan da holde en liten ladning, og det vil da være en én eller null. Så hvis du har ladning, så er det én, og hvis du ikke har ladning, så er det null. Men denne ladningen, den siver sakte ut, så den må oppfriskes ca. ti ganger i sekundet. Så da må man ha en liten loop som går og oppfrisker alle verdiene i ram hele tiden. Det betyr jo opplagt at hvis man skrur av en maskin, så forsvinner alt som er i ram. Ingenting av det som er i ram, blir lagret. Selvfølgelig ikke det i registeret heller. Så det betyr at alt som skal lagres permanent, det må lagres på disk. På harddisker, der ligger det permanent. Å synkronisere deram. Men... Ja, for kanskje sånn 15-20 år siden", "source": "lecture"}
{"lecture_id": "os13del5", "chunk_id": "os13del5_0006", "start": 396.08, "end": 480.02, "token_count": 266, "text": "Selvfølgelig ikke det i registeret heller. Så det betyr at alt som skal lagres permanent, det må lagres på disk. På harddisker, der ligger det permanent. Å synkronisere deram. Men... Ja, for kanskje sånn 15-20 år siden så ble det vanlig å synkronisere deram sånn at lesing og skriving var synkronisert med en ekstern klokke. Sånn som det alltid har vært i CPU-en. Der har vi en klokke. Men det er også en klokke ut mot databussen. Sånn at man synkroniserer lesing og skriving. Og da finnes det forskjellige versjoner av RAM. Alle nye er DDR5. DDR4 var den forrige. DDR står for Double Data Rate. Så alt dette er SDRAM, men det har vært versjoner som har kommet, som har vært mer og mer effektive. Og den typiske forskjellen er at de har høyere klokkefrekvens. Sånn at de raskere kan overføre data.", "source": "lecture"}
{"lecture_id": "linux1del3", "chunk_id": "linux1del3_0000", "start": 0.0, "end": 96.2, "token_count": 289, "text": "Som du ser, befinner jeg meg nå på en Windows-maskin. Det er en virtual box windows som jeg kjører. Det er den samme som ligger i oppgave én, eller i de første UK-oppgavene. Så blir de som har Mac, bedt om å installere en virtual box windows. Og der den kjører fra. Det jeg har tenkt å se på nå, er hvordan man Logger seg inn fra Windows til StudySSH, som dere trenger å gjøre oppgaver i uke to. Så hvis jeg nå prøver å kjøre Putty, som er det programmet som jeg anbefaler at dere bruker for å logge dere inn med SH til en Linux-server fra Windows, så ser vi at den fins ikke her. Så... Hvis du ikke har Putty installert, så kan du installere den. Da er det egentlig bare å søke på Putty. Den første linken, så er det en som står det 'downloade', putty here. Så kan du gå dit. Kan du bruke en sånn installasjonsopplegg? Det enkleste er kanskje bare å ta den 64-bits-putty.xo her. Da legger jeg den på desktopen, så har man den til senere.", "source": "lecture"}
{"lecture_id": "linux1del3", "chunk_id": "linux1del3_0001", "start": 70.96, "end": 167.4, "token_count": 300, "text": "Den første linken, så er det en som står det 'downloade', putty here. Så kan du gå dit. Kan du bruke en sånn installasjonsopplegg? Det enkleste er kanskje bare å ta den 64-bits-putty.xo her. Da legger jeg den på desktopen, så har man den til senere. Da har jeg putty her oppe. Så kjører jeg putty. Bare dobbeltklikker og rønner. Og det... Nå er alt klart til å logge inn på Study SSO. Det man trenger å gjøre da, er å skrive inn hosename for Study SSO. Så må man faktisk bruke HiOA. Jeg tror ikke DNS er oppdatert, sånn at OsloMet virker, men denne funker iallfall. Det er på port 22, som er default, når man bruker SSH. Så egentlig bare skriv inn den, og så return eller klikk open. Så får man en melding her. Det er altså man gjør. Gjerne for første gang man logger inn på en Linux-server, på en SSO-server, som er en sånn sikkerhet... En sånn ekstra sikkerhet for at det ikke er en man-in-the-middle-attack.", "source": "lecture"}
{"lecture_id": "linux1del3", "chunk_id": "linux1del3_0002", "start": 139.34, "end": 227.8, "token_count": 275, "text": "Så egentlig bare skriv inn den, og så return eller klikk open. Så får man en melding her. Det er altså man gjør. Gjerne for første gang man logger inn på en Linux-server, på en SSO-server, som er en sånn sikkerhet... En sånn ekstra sikkerhet for at det ikke er en man-in-the-middle-attack. Men når det er første gang, så kan du svare yes på den. Hvis det samme skjer andre gang, så kan man kanskje være litt mer obs. Men iallfall. Log inn ASS og det du gjør der, og så skriv inn studentnummeret ditt. Jeg har en testbruker, S318329, så du skriver inn det studentnummeret. Og så må du ikke legge på at oslomett osv. Hvis man gjør det, så kommer man inn, men da blir det noe trøbbel med innloggingen, sånn at man ikke kan endre på... lage nye filer osv. Så du bruker bare studentnummeret og så det samme passordet som du har på Kalmas og overalt ellers. Skal vi se om jeg får til det her.", "source": "lecture"}
{"lecture_id": "linux1del3", "chunk_id": "linux1del3_0003", "start": 194.76, "end": 293.12, "token_count": 276, "text": "Og så må du ikke legge på at oslomett osv. Hvis man gjør det, så kommer man inn, men da blir det noe trøbbel med innloggingen, sånn at man ikke kan endre på... lage nye filer osv. Så du bruker bare studentnummeret og så det samme passordet som du har på Kalmas og overalt ellers. Skal vi se om jeg får til det her. Sånn, ja. Hvis du skriver riktig passord, så kommer du da inn på Studiesse. Så. Hvis det er behov for det, så kan man endre på fonter i Putty. Jeg kan vise deg denne første der inne. Her er det en... Det gjorde nå å være høyre-klikke her oppe. Ja, jeg må opp på den baren der, og så høyre-klikke. Og så er det window appearance her. Der kan man endre fond. For eksempel jeg skrur 14, Apply... Så får jeg litt større fonder. Så kan jeg utføre Windows... Ikke Windows, men Linux-kommandoer i cellet, som Pwd, Ls, LS-l osv.", "source": "lecture"}
{"lecture_id": "os14del5", "chunk_id": "os14del5_0000", "start": 0.0, "end": 104.28, "token_count": 288, "text": "Her tenkte jeg å kjøre en Vram-test. Dette er også en av oppgavene denne uken. Å kjøre dette RAM... RAM-SMP. RAM-Speed. Hvis vi kjører det uten argumenter som dette, ser vi at vi får litt info om... Men vi ser vi trenger å ha en minus B id. Sånn generelt når... Hvis opsjoner står i parenteser, så er det opsjoner. Man kan velge å ikke ta dem med, men opsjoner som ikke står i parenteser, de må være med. Så vi ser her... For å få dette til å kjøre, må vi bruke den minus B. Og minus B1... Den gjør da en test hvor man skriver til RAM. Vi kan teste og lese etterpå. Så dette er da min Linux-desktop som står nede på OsloNet. Som jeg kjører denne testen i. Og det som skjer nå, er at vi... Og skrive til ram akkurat på samme måte som vi gjorde i det forrige programmet. Vi har et svært array, og så skriver vi bite for bite til det arrayet. Og vi ser... Det er noe sånt som åtte gigabyte med ram som skrives.", "source": "lecture"}
{"lecture_id": "os14del5", "chunk_id": "os14del5_0001", "start": 74.32, "end": 166.88, "token_count": 294, "text": "Som jeg kjører denne testen i. Og det som skjer nå, er at vi... Og skrive til ram akkurat på samme måte som vi gjorde i det forrige programmet. Vi har et svært array, og så skriver vi bite for bite til det arrayet. Og vi ser... Det er noe sånt som åtte gigabyte med ram som skrives. Og... Men forskjellen er størrelsen på blokkene som skrives. Så i førstelinja her så skriver man bare... Én kilobite av gangen. Altså, man har en løkke som går gjennom... Da blir det 250 bite, sånn at det blir én kilobite totalt. Og så skrives det veldig hurtig til ramm. Og så måles hastigheten. Det går veldig fort. 26 000 megabyte per sekund. Altså 27 eller 30 gigabyte i sekundet. Så... Det går unna. Hvis du skal streame noe, f.eks., så kan du... Ja... Du kan streame kanskje 4 megabit per sekund, og det er bare bit. Dette er bite, og så er det giga. Så det er 30 gigabyte per sekund.", "source": "lecture"}
{"lecture_id": "os14del5", "chunk_id": "os14del5_0002", "start": 137.64, "end": 220.28, "token_count": 287, "text": "Altså 27 eller 30 gigabyte i sekundet. Så... Det går unna. Hvis du skal streame noe, f.eks., så kan du... Ja... Du kan streame kanskje 4 megabit per sekund, og det er bare bit. Dette er bite, og så er det giga. Så det er 30 gigabyte per sekund. Så dette går veldig, veldig hurtig. Men litt av poenget her med denne testen er at vi ser det går veldig hurtig til å begynne. Men så begynner det å gå litt saktere. Her er det 29 000, så går det ned til 28 000, 27 000 her... 25 000. Og så dropper det enda mer. Og her nede så ser vi at vi er nedi en fjerdedel av den opprinnelige hastigheten. Og dette har da... Dette er da på grunn av cash. Dette er cash-størrelsene. Skriver en liten blokk, så får den plass i LN-cash. Skriver vi en litt større blokk, så får den plass i L2-cash. Og så må vi kanskje ut i L3-cash her ute.", "source": "lecture"}
{"lecture_id": "os14del5", "chunk_id": "os14del5_0003", "start": 202.92, "end": 288.28, "token_count": 291, "text": "Dette er cash-størrelsene. Skriver en liten blokk, så får den plass i LN-cash. Skriver vi en litt større blokk, så får den plass i L2-cash. Og så må vi kanskje ut i L3-cash her ute. Det vi trenger å vite da, er hvor stor er cash på denne maskinen her. Og da... Det jeg gjorde nå, var kommandoen LSCPU. Og den gir cash-størrelsene. Og da ser vi... L1-cash er 32K for data og instruksjoner. Det er data. I er instruksjoner. Og dette vil jo være typisk... Her skrives, og dette vil typisk være data. Så da har vi 32K i L1 og 256K i L2 og 8 mega i L3. Så da kan vi prøve. Vi skal prøve å se... Er det noen forskjell på... Er det noen stor forskjell ved 32K og 256K? Det er ikke så veldig stor forskjell. Vi kan se at det begynner å droppe litt ved 32K, for da må den over på L2. Men det ser ut som... Når du skriver de store mengdene her,", "source": "lecture"}
{"lecture_id": "os14del5", "chunk_id": "os14del5_0004", "start": 268.24, "end": 365.0, "token_count": 298, "text": "Er det noen stor forskjell ved 32K og 256K? Det er ikke så veldig stor forskjell. Vi kan se at det begynner å droppe litt ved 32K, for da må den over på L2. Men det ser ut som... Når du skriver de store mengdene her, så ser det ut som L2 også er veldig effektiv. Men så begynner det å bli større enn L2. Nå i dag faller det litt i hastighet. Men så ser vi her mellom 4 og 8. Der begynner det å bli en stor forskjell. Da begynner vi å komme over 8K. Da ser vi at hastigheten har blitt halvert. Og det er fordi da får ikke de blokkene plass i... Ikke engang i L3. Så da må du begynne å lese direkte fra disken... Nei, direkte fra ram, og da begynner man å komme ned på den... Det som du kan kalle den ekte rammehastigheten. Altså at du må helt ut i ramm og... Hentedataene. Da faller hastigheten med i hvert fall en faktor på fire. Muligens enda mer hvis vi hadde skrevet enda større blokker.", "source": "lecture"}
{"lecture_id": "os14del5", "chunk_id": "os14del5_0005", "start": 344.36, "end": 421.36, "token_count": 227, "text": "Det som du kan kalle den ekte rammehastigheten. Altså at du må helt ut i ramm og... Hentedataene. Da faller hastigheten med i hvert fall en faktor på fire. Muligens enda mer hvis vi hadde skrevet enda større blokker. Så vi kan prøve å lese også. Minus B2. Da leser vi fra ramma. Og vi ser det går enda fortere. Vi ser igjen så vi får 1 KB. Den er kanskje for liten igjen til at det skal gå fort nok. Når det kommer opp i 2, så ser vi det kommer opp i 60 GB per stykke. Men igjen så ser vi den samme effekten. Det faller litt... ... litt etter 32K, eller den cash-størrelsen. Og så faller det veldig mye etter 8K. Fra 50 og ned til 20, omtrent. Så det er en stor faktor.", "source": "lecture"}
{"lecture_id": "linux3del1", "chunk_id": "linux3del1_0000", "start": 0.0, "end": 93.12, "token_count": 299, "text": "Skjellvariabler er variabler som man kan sette i skjellet. Det er omtrent som variabler i et program. Man definerer variablene, og så kan man bruke det senere i programmet. Måten man setter det på i et Linux-skjell, er sånn som dette her. Du skriver et varabelnavn, OS, og så setter du det lik Linux. Men det som er spesielt i skjellet, er at man skal bruke den variabelen. Så skriv jeg ekko. Så må man ha med dollartegn for å få ut verdien på variabelen. Så ecco dollar os, det gir oss da den variabelen vi definerte. Så må man passe på å ikke ha mellomrom. Skjellet er veldig bar på syntaks. Hvis jeg gjør det, så får jeg passe på Der gjør jeg command.notfound, for jeg har et mellomrom der. Og der også gjør det at jeg får command.notfound. Det man tilordner, må komme rett etter likhetstegnet. Så i tillegg, hvis man prøver å... Hvis man prøver å skrive noe mer, f.eks. OSR lik Linus... Web, for eksempel. Sånn som det.", "source": "lecture"}
{"lecture_id": "linux3del1", "chunk_id": "linux3del1_0001", "start": 64.8, "end": 168.08, "token_count": 291, "text": "Og der også gjør det at jeg får command.notfound. Det man tilordner, må komme rett etter likhetstegnet. Så i tillegg, hvis man prøver å... Hvis man prøver å skrive noe mer, f.eks. OSR lik Linus... Web, for eksempel. Sånn som det. Så ser jeg at jeg får en command not found, men det er fordi jeg har et mellomrom her. Så den tolker dette som to kommandoer. Så OS vil fortsatt være Satellinux. Men det jeg ønsker, er å få begge ordene med. Og da må jeg sette begge ordene inn i en parentes, og da får vi det som vi ønsker. Eller så kan det være en liten ting med variabler hvis man ønsker å skrive ut noe sånt som Ecco... OS... Og så Linux, Deb f.eks.... OS. Sånn. Og så fungerer det som det skal. Men hvis man prøver å sette bokstaver rett etter her... SOS - hvis man ønsker å skrive det. Da får man plutselig ingenting. Og det er fordi da skjønner ikke skjellet at dette er en variabel.", "source": "lecture"}
{"lecture_id": "linux3del1", "chunk_id": "linux3del1_0002", "start": 150.0, "end": 217.44, "token_count": 238, "text": "Og så fungerer det som det skal. Men hvis man prøver å sette bokstaver rett etter her... SOS - hvis man ønsker å skrive det. Da får man plutselig ingenting. Og det er fordi da skjønner ikke skjellet at dette er en variabel. Bare tolker skjellet som at hele dette er en variabel. I akkurat sånne tilfeller går det an å legge inn krøllparenteser rundt variabelen. Og dermed får man ut akkurat det man ønsker. Linux DEB SOS. At den tekststrengen kommer rett etter. Generelt så kan man også fjerne en definisjon med UNSET. Så hvis jeg nå skriver ut det, så kommer det bare SOS. Så kan man i tillegg, med Z, så kan man liste alle variabler som er definert i skjellet. For det er ganske mange som er definert. Så får man en lang liste over alt som er definert av varabler.", "source": "lecture"}
{"lecture_id": "os5del2", "chunk_id": "os5del2_0000", "start": 0.0, "end": 85.0, "token_count": 260, "text": "I dag er temaet C og maskinkode. Det er tema første time, og så skal vi se på pipelining og superskalære prosessorer i andre time. Og da skal vi gå hakket videre fra den skalære prosessoren som vi hadde i simuleringen. En skalær er altså en prosessor som gjør én ting av gangen. Så skal vi se på moderne CPU-er som faktisk selv innen den samme enkle CPU-en innen en core gjør ting i parallell. Men det kommer vi til å stikke ut i andre time. Først skal vi fortsette å se på sammenhengen mellom høynivåkode og maskinkode. Og dette er det viktig å ha med seg senere i kurset, for da... Da skal vi se hvordan operativsystemer styrer prosesser. Og i mange tilfeller så er det helt avgjørende hvordan hardwaren under virker. For operativsystemet må også styre hvor mange CPU-er man har, og hyperthreading og... Ja, til en viss grad også det med pipelining er viktig for operativsystemer.", "source": "lecture"}
{"lecture_id": "os6del9", "chunk_id": "os6del9_0000", "start": 0.0, "end": 104.32, "token_count": 296, "text": "I operativsystemhistorien så... den er ikke fullstendig. Men jeg har bare tenkt å se litt på tidligere Microsoft og Unix-operativsystemer. Som kanskje har vært de mest sentrale operativsystemene, i hvert fall de siste 30 årene. Mac er også et sentralt operativsystem. Først en kort oversikt over Microsoft Destop-OS og Server-OS. Og så tilsvarende for Unix og Linux. Ja. Destop-OS... Jeg sa 30 år, men dette er faktisk 40 år siden. MS-DOS kom ut. Det var et 16-bitt operativsystem. Etter hvert så ser vi at det kom 32 bits, sånn rundt 2000 er vel kanskje enda litt. Nei, under Vinos 95 var det noe 32-bits. Og her omtrent så var det en sånn overgang fra CPU-er med 16 til 32-bit. Og så etter hvert rundt år 2000 så ble 64-bits vanlig. Det er det aller vanligste nå med 64-bits CPU-er. Systemet må da tilpasse seg sånn at det kan løse alt med 64-bit. Det som gjorde Windows til en ekstrem suksess på 90-tallet,", "source": "lecture"}
{"lecture_id": "os6del9", "chunk_id": "os6del9_0001", "start": 79.82, "end": 172.36, "token_count": 293, "text": "Og så etter hvert rundt år 2000 så ble 64-bits vanlig. Det er det aller vanligste nå med 64-bits CPU-er. Systemet må da tilpasse seg sånn at det kan løse alt med 64-bit. Det som gjorde Windows til en ekstrem suksess på 90-tallet, det var først og fremst at det hadde en veldig intuitivt og enkelt brukergrensenett, som gjorde at det etter hvert ble allemannseie å ha en PC. Ganske så ustabile. Mye mer ustabile enn de Unix-serverne som styrte alt på servicesiden på denne tiden. Det var vel først kanskje rundt 2000 med XB at det virkelig fikk en bra og stabil... Et godt og stabilt Windows-operativsystem. Og det som gjorde det, var at det kombinerte... Det hadde samme kjerne som endte 5-1, så det var en... Man skrev rett og slett hele operativstemmen helt fra scratch. Så det var en helt annen operativstemme enn en DOS-operativstemme som kom 20 år senere. Så er Windows 7 altså en veldig stabil versjon. Og nå er det Windows 10 som gjelder,", "source": "lecture"}
{"lecture_id": "os6del9", "chunk_id": "os6del9_0002", "start": 150.0, "end": 249.6, "token_count": 294, "text": "Man skrev rett og slett hele operativstemmen helt fra scratch. Så det var en helt annen operativstemme enn en DOS-operativstemme som kom 20 år senere. Så er Windows 7 altså en veldig stabil versjon. Og nå er det Windows 10 som gjelder, som kom for fem-seks år siden, 2015. Tidligere ser vi at det kom hele tiden nye versjoner med XB, Vista, 7, Windows 8 osv. Og Windows 10. Men nå ser det ut som man bare har mindre endringer på Windows 10. Sånn at det ikke kommer noen Windows 12 eller 13 eller... Opprinnelig hadde det med året å gjøre. Vindows 2000 kom i år 2000. Windows 10 var et godt stykke etter 2010. Men det som kanskje er viktigere, er at tidligere når man lagde software generelt, så hadde man sånne store releaser med store endringer. Og det kunne ta kanskje et par år. Nå kommer det en ny release av Windows. Og dette programmet testet man og holdt på i et par år, og så fikk man en release. Man tester ut endringene og releaser hele tiden.", "source": "lecture"}
{"lecture_id": "os6del9", "chunk_id": "os6del9_0003", "start": 222.64, "end": 321.0, "token_count": 299, "text": "så hadde man sånne store releaser med store endringer. Og det kunne ta kanskje et par år. Nå kommer det en ny release av Windows. Og dette programmet testet man og holdt på i et par år, og så fikk man en release. Man tester ut endringene og releaser hele tiden. Eller mye oftere enn tidligere. Det samme gjelder Linux-distribusjoner og Linux-kjernen også. Man kommer hele tiden med mange små endringer som kontinuerlig blir testet. Det er også en generell utvikling i software development. Ja... Her er det diverse Windows 10-versjoner. Ja, altså jeg har ikke fått med den siste. Den kom i siste halvdel av 2020. Mulig det har kommet noen enda nyere der. Der må dere ut på Wiki og sjekke ut. Spørsmålet i Chetn anbefaler du Linus eller Windows? Ja, jeg har rett personlig. Jeg anbefaler Linux. En av de få som alltid har kjørt Linux. Eller iallfall så lenge Linux har eksistert. Jeg kjører jo Windows også, og jeg har en gammel Mac. Men jeg anbefaler Linux fordi man har veldig stor frihet.", "source": "lecture"}
{"lecture_id": "os6del9", "chunk_id": "os6del9_0004", "start": 291.8, "end": 384.98, "token_count": 299, "text": "Spørsmålet i Chetn anbefaler du Linus eller Windows? Ja, jeg har rett personlig. Jeg anbefaler Linux. En av de få som alltid har kjørt Linux. Eller iallfall så lenge Linux har eksistert. Jeg kjører jo Windows også, og jeg har en gammel Mac. Men jeg anbefaler Linux fordi man har veldig stor frihet. Altså man kan mekke og hacke og legge inn hva som helst. Det har jo sine ulemper også. Det er klart at hvis man gjør for mye krumspring, så kan ting også gå galt. Men man har en veldig stor frihet, og så er alt åpen kildekode. Det har også endret seg når det gjelder Windows. Tidligere var Windows helt lukket, men nå er det åpen kildekode. Altså vinduskjerne, altså åpen kildekode. Ja, der har jeg ikke så veldig sterke preferanser. Jeg har stort sett alltid brukt Ubuntu, for det er enkelt og greit. Og det er mye brukt. Debbian har jeg brukt også, som er litt renere, på en måte. Ikke har så mye kommersiell og ekstern programvare.", "source": "lecture"}
{"lecture_id": "os6del9", "chunk_id": "os6del9_0005", "start": 360.0, "end": 448.88, "token_count": 285, "text": "Ja, der har jeg ikke så veldig sterke preferanser. Jeg har stort sett alltid brukt Ubuntu, for det er enkelt og greit. Og det er mye brukt. Debbian har jeg brukt også, som er litt renere, på en måte. Ikke har så mye kommersiell og ekstern programvare. Men ellers har jeg hørt Red Hat, et veldig... Stabilt operativsystem. Det har jeg ikke brukt veldig mye. Vi har brukt det noe på serveren her. Når det gjelder Windows eller Linux, så er det klart... Det har hver sine bruksområder. Det er ikke så mange som kjører Linux. Men det fungerer veldig greit å kjøre det i dag. Det var mye verre sånn rundt 95... Over 2000. Da jeg kjørte Linux, så fungerte det veldig dårlig i samarbeid med Windows f.eks. Men nå så går det ganske greit med alt, liksom... Man kan oppnå stort sett det samme med en Linux-desktop som en Windows-desktop. Kanskje spill er fortsatt litt forskjellig, fordi GUI i Linux kjører use-of-space.", "source": "lecture"}
{"lecture_id": "os6del9", "chunk_id": "os6del9_0006", "start": 420.0, "end": 513.64, "token_count": 279, "text": "Da jeg kjørte Linux, så fungerte det veldig dårlig i samarbeid med Windows f.eks. Men nå så går det ganske greit med alt, liksom... Man kan oppnå stort sett det samme med en Linux-desktop som en Windows-desktop. Kanskje spill er fortsatt litt forskjellig, fordi GUI i Linux kjører use-of-space. Men på den annen side så er det ikke så stor forskjell lenger på hva slags desktop man har, fordi i større og større grad så bruker man jo nettapplikasjoner som er nettbaserte. Sånn at man egentlig bare trenger en browser for å kunne kjøre alle applikasjoner som e-post og dokumentbehandling osv. Religionskrig mellom Windows og Linux osv., men det har nok glattet seg litt ut etter hvert, fordi det ikke har så stor betydning når alt kjøres på nett. Microsoft har også en serverside, så de har lenge hatt Microsofts servere. Når de første kom sånn i 1993, så var de en veldig liten minoritet blant serverne. De aller fleste kjørte Og etter hvert Linux.", "source": "lecture"}
{"lecture_id": "os6del9", "chunk_id": "os6del9_0007", "start": 486.74, "end": 567.56, "token_count": 229, "text": "etter hvert, fordi det ikke har så stor betydning når alt kjøres på nett. Microsoft har også en serverside, så de har lenge hatt Microsofts servere. Når de første kom sånn i 1993, så var de en veldig liten minoritet blant serverne. De aller fleste kjørte Og etter hvert Linux. Men nå, særlig siden 2010, så har Windows-server blitt mer og mer brukt. Så nå kjører du Windows-server i mange serverrom. Ofte da i kombinasjon med Linux-servere. Men fortsatt er nok Linux enda større. Jeg skal se på noen tall senere. Når det gjelder servere som drifter webservere over hele verden, f.eks., så er antall Linux-servere litt større. Noe som er viktig både på Linux- og Microsoft-siden, er virtualisering. HyperW er vindusservere. Azure kjører vindusservere i storskala virtuelt.", "source": "lecture"}
{"lecture_id": "linux2del10", "chunk_id": "linux2del10_0000", "start": 0.0, "end": 104.28, "token_count": 298, "text": "En alternativ måte å sette filerettigheter, er å gi ekstra rettigheter til en gruppe eller alle, eller eieren. Så for eksempel her, så har vi sett de to. Dette vil da være 755. Så jeg kan ha for eksempel... Jeg vil velge å også gi alle... skriverettigheter. A står for alle, og så kan jeg si at alle skal kunne skrive til denne mappen. Hvis jeg nå lister, så ser vi at alle har nå fått skriverettigheter. Og med minus så kan jeg fjerne. Men la oss si jeg bare ønsker å fjerne frem gruppen. Gjør jeg det sånn... Gruppe mister da skriverettigheter. Og så kan jeg f.eks. Ja, jeg kan si user og gruppe. Da ser vi altså at user også har mistet skriverettigheter. Så dette er en alternativ måte å sette rettigheter på, men noe som er en litt ulempe med denne, Dette avhenger da av hvilke rettigheter de har fra før. Eller sluttresultatet vil da være avhengig av hva man har fra før. Men i noen tilfeller så kan det være praktisk å gjøre dette her,", "source": "lecture"}
{"lecture_id": "linux2del10", "chunk_id": "linux2del10_0001", "start": 83.88, "end": 182.8, "token_count": 294, "text": "Så dette er en alternativ måte å sette rettigheter på, men noe som er en litt ulempe med denne, Dette avhenger da av hvilke rettigheter de har fra før. Eller sluttresultatet vil da være avhengig av hva man har fra før. Men i noen tilfeller så kan det være praktisk å gjøre dette her, sånn at man gir og tar fra rettigheter fra noen med user, gruppe eller odder, som er den siste gruppen her, eller a, som er alle. Siste ting når det gjelder rettigheter, det er Jumask. Jumask er vanligvis Default 0022. Og det denne betyr, er hvis man lagrer en ny fil... Så bestemmer Jumask default-rettighetene. Og Jumask er et slags filter. Så hvis jeg sier 0027, så betyr det at det siste sifferet her er rettighetene til brukere. Nei, til alle andre. Så hvis jeg lager nå en ny fil, så ser vi at denne nye filen her har nå ingen rettigheter for alle andre. Og det er det syvtallet. Det maskerer og tar bort alle... Bortsett fra å lese.", "source": "lecture"}
{"lecture_id": "linux2del10", "chunk_id": "linux2del10_0002", "start": 156.4, "end": 242.88, "token_count": 246, "text": "er rettighetene til brukere. Nei, til alle andre. Så hvis jeg lager nå en ny fil, så ser vi at denne nye filen her har nå ingen rettigheter for alle andre. Og det er det syvtallet. Det maskerer og tar bort alle... Bortsett fra å lese. Mens den toeren, den vil da gi nøyaktig de rettighetene, bare lese. Mens null gir for filer, lese og skrive. Og så er det tilsvarende for mapper, selv om det er litt annerledes. Men hvis jeg nå lager en mappe-dill, så ser vi altså at den nye mappen har ingen rettigheter. At umask for alle andre er null, og ikke den toeren som den er default. Dere kan se i notatene en tabell over hva umask betyr for alle tilfeller. Men det er iallfall viktig at man vet at umask er det som bestemmer hva som skjer med når man lager nye filer... En Linux-maskin.", "source": "lecture"}
{"lecture_id": "os4del18", "chunk_id": "os4del18_0000", "start": 0.0, "end": 97.08, "token_count": 295, "text": "Da kan vi til slutt se litt på hvordan denne koden virker. Hva er det som egentlig skjer her? Først i koden her så er det bare litt info. Jeg har oppsummert noen av de størrelsene som man bruker i Assembly. B står for Bite, 8-bit. L er long, 32-bit eller har 4 bytes, og Q er code, 64-bit eller 8-bites. Så har man da tilsvarende registre som er av forskjellig størrelse. Som jeg sa, så har man tradisjonelt AX, BX, CX og DX. Og så har man en slags... 8-bit-registeret. Ah og Al, og da omtaler man egentlig... Første og andre, altså high or low av de 16-bitene i AX. Så med Extended AX, som er 32-bit... De første CPU-ene var på 4-bit. Etter hvert som var det vanlig med 16-bits CPU-er. Men så kom 32-bits, og da måtte man utvide registrene. Så kom, sånn rundt 2000, så kom 64-bits CPU-er. Da måtte man utvide til 64-bit. Det som jeg bruker her, er som vi ser RCX.", "source": "lecture"}
{"lecture_id": "os4del18", "chunk_id": "os4del18_0001", "start": 75.72, "end": 167.68, "token_count": 297, "text": "Etter hvert som var det vanlig med 16-bits CPU-er. Men så kom 32-bits, og da måtte man utvide registrene. Så kom, sånn rundt 2000, så kom 64-bits CPU-er. Da måtte man utvide til 64-bit. Det som jeg bruker her, er som vi ser RCX. Det er et 64-bits reaser, så det er litt overkill når vi bare snakker om så små tall. Men vi ser jeg gjør akkurat det samme som i simuleringen. Jeg legger først tallet 3 i R6. Med move-kommandoer så legger jeg tallet 1 i add-x. Den er sånn at tallet 3... Dette er bare en konstant. Hvis det står en dollar, så kommer den konstant etterpå. Så dette er tallet 3. I tillegg må man ha en prosent foran registeret når man omtaler et register. Så jeg legger nå 3 i iCX, 1 i DX, 0 i BXAX. Så begynner jeg å kjøre en lucky. Det første jeg gjør her, er add DX til BX. Og det betyr da egentlig... Ta verdien i RBX og så legg til RDX.", "source": "lecture"}
{"lecture_id": "os4del18", "chunk_id": "os4del18_0002", "start": 133.06, "end": 223.8, "token_count": 298, "text": "I tillegg må man ha en prosent foran registeret når man omtaler et register. Så jeg legger nå 3 i iCX, 1 i DX, 0 i BXAX. Så begynner jeg å kjøre en lucky. Det første jeg gjør her, er add DX til BX. Og det betyr da egentlig... Ta verdien i RBX og så legg til RDX. Og det er da en I pluss pluss. Jeg kunne gjort dette med en Operasjon INK. Da ville det hatt den samme effekten. Men jeg gjør det som i simuleringen. Og så fortsette. Add RAX til RAX. Det betyr da ta RAX lik RAX pluss RBX. Og det er den summen. Ta S og så legg til I. Og så kommer sammenligningen. Jeg sammenligner nå R6 og RBX. Og R6, det ser vi i det tallet i den løkka jeg hadde. Så den avgjør hvor langt løkka går. Så da jeg endret den til 4, så gikk den én runde. Og så... Det kommer først som Compare, er i lik tre. Og så Jump, not equal. Hvis de ikke er like, så hopp opp til Start.", "source": "lecture"}
{"lecture_id": "os4del18", "chunk_id": "os4del18_0003", "start": 199.48, "end": 285.48, "token_count": 290, "text": "Og R6, det ser vi i det tallet i den løkka jeg hadde. Så den avgjør hvor langt løkka går. Så da jeg endret den til 4, så gikk den én runde. Og så... Det kommer først som Compare, er i lik tre. Og så Jump, not equal. Hvis de ikke er like, så hopp opp til Start. Og her står det en Label Start. Det er da... I virkeligheten så vil dette programmet ligge i ramm når det er kompilert, og da er dette en adresse som den hopper opp til. Akkurat som i simulering. Så når alt er ferdig, så returnerer man. Og da kan man endre på koden her. For eksempel så sa jeg... rbx erlik rbx pluss rdx. Det kunne man jo for eksempel i stedet. Så kunne jeg bare si incrbx her. Det betyr øk rbx med én. Så kan jeg da teste. Det er veldig lett. Jeg kan teste nå om dette gikk bra. Kopulerer først assembler-koden, så linker jeg med main. Og så kjører jeg. Ja, det gikk faktisk bra.", "source": "lecture"}
{"lecture_id": "os4del18", "chunk_id": "os4del18_0004", "start": 260.12, "end": 297.0, "token_count": 115, "text": "Så kunne jeg bare si incrbx her. Det betyr øk rbx med én. Så kan jeg da teste. Det er veldig lett. Jeg kan teste nå om dette gikk bra. Kopulerer først assembler-koden, så linker jeg med main. Og så kjører jeg. Ja, det gikk faktisk bra. Jeg oppnådde det samme med en annen institusjon, nemlig INK. Som er increment. Den bare øker RBX med én.", "source": "lecture"}
{"lecture_id": "linux6del6", "chunk_id": "linux6del6_0000", "start": 0.0, "end": 76.92, "token_count": 299, "text": "Nå skal jeg se på hvordan man kan sette opp passordløs innlogging fra neste DSOS til RUT på Linux-VM. Altså til RUT-brukeren på Linux-VM. Og hvis man ikke har gjort det før, så kan man da starte med å sette opp passordløs tilkobling til den vanlige OS-brukeren. Og som jeg har sett tidligere, så kan man gjøre det, så kan man gjøre det tidligere, så kan man gjøre det tidligere, så kan man gjøre det tidligere, så kan man gjøre det tidligere, så kan man gjøre det til passordløs tilkobling til den vanlige OS-brukeren. Og som jeg har sett tidligere, så kan man gjøre det, og sette opp passordlørløs tilkobling til den vanlige OS-brukeren. Så har jeg nå en brukergruppe 100. Så da kan jeg legge over den, og da må jeg taste passordet. Da kan jeg prøve å gå direkte inn uten å tasse passordet. Sånn. Da kan vi se på hva som skjedde da jeg gjorde dette her. Altså da jeg fikk til passordløs tilkobling.", "source": "lecture"}
{"lecture_id": "linux6del6", "chunk_id": "linux6del6_0001", "start": 40.3, "end": 147.84, "token_count": 295, "text": "Så da kan jeg legge over den, og da må jeg taste passordet. Da kan jeg prøve å gå direkte inn uten å tasse passordet. Sånn. Da kan vi se på hva som skjedde da jeg gjorde dette her. Altså da jeg fikk til passordløs tilkobling. Eller SSO-innlogging med SSO-nøkler. Det som skjedde, var at en fil som blir generert med ssokeegan.idrsa.pup, Det er den public-nøkkelen. Det er min public-nøkkel. Den ser sånn ut. Og det som skjer, er at denne kopieres over til Linux-VM. Så det skjer med SSH copy-ID. Derimot... Den private nøkkelen, den ligger også i.so. Jeg vil ikke vise den frem engang. Kopierer man den, så kan man få adgang til alle steder hvor jeg har adgang. Men den ligger i den filen, IDRSA. Så den må man være veldig forsiktig med. Den må ikke andre få tilgang til. Nøkkelen er ikke så nøye, for der den legger, der får du tilgang. Og om noen andre skulle legge den et annet sted, så får du tilgang.", "source": "lecture"}
{"lecture_id": "linux6del6", "chunk_id": "linux6del6_0002", "start": 126.72, "end": 223.64, "token_count": 292, "text": "Men den ligger i den filen, IDRSA. Så den må man være veldig forsiktig med. Den må ikke andre få tilgang til. Nøkkelen er ikke så nøye, for der den legger, der får du tilgang. Og om noen andre skulle legge den et annet sted, så får du tilgang. For å få tilgang dit du skal. Så vi kan nå gå inn og se om dette faktisk har skjedd, hvis vi logger inn her. Da slipper jeg å taste passord, og så kan vi se... Ligger faktisk den nøkkelen her i Authorized Keys? Ja, det er den nøkkelen her som ligger der. Og fordi den nøkkelen ligger der, Så kan jeg også få direkte tilgang. Det jeg skal prøve å gjøre nå, er å også få tilgang direkte som Ruth. Men Ruth har ikke noe eget passord her på Linux-VM. Så dermed kan du ikke bruke den samme teknikken med å bruke SSO-copy-ID. Men siden vi allerede har fått denne over her, så kan vi gjøre... Altså kopiere denne filen til Ruth. Og da vil Ruth også få adgang. Hvis jeg kopierer hele filen, så må jeg være oppmerksom på", "source": "lecture"}
{"lecture_id": "linux6del6", "chunk_id": "linux6del6_0003", "start": 199.92, "end": 303.8, "token_count": 295, "text": "Så dermed kan du ikke bruke den samme teknikken med å bruke SSO-copy-ID. Men siden vi allerede har fått denne over her, så kan vi gjøre... Altså kopiere denne filen til Ruth. Og da vil Ruth også få adgang. Hvis jeg kopierer hele filen, så må jeg være oppmerksom på at da får også de andre som har her, tilgang. Så for å gjøre det veldig eksplisitt, så kan man også bare kopiere den strengen direkte inn i Autorized Keys hos Ruth. Eller Public Ease for de som får alga. Så... Det jeg da kan gjøre, er først å gå inn som Ruth. Og så CD-er går jeg hjem til Ruth. Og hjem til Ruth, det er i DotRuth. Og så må jeg sjekke først... Fins det en DotSSH her? Nei, det gjør det ikke. Det fins ikke noen.ssh. Og for å få rettigheter og sånn riktig kan det mest praktiske også rett og slett være å kjøre en ssh-key. Jen for Ruth, for da opprettes mappen. Vi ser da lages også en idrsa og idrsa.pub, men vi skal ikke bruke de nå. Å bruke denne mappen her.", "source": "lecture"}
{"lecture_id": "linux6del6", "chunk_id": "linux6del6_0004", "start": 270.02, "end": 371.68, "token_count": 294, "text": "Det fins ikke noen.ssh. Og for å få rettigheter og sånn riktig kan det mest praktiske også rett og slett være å kjøre en ssh-key. Jen for Ruth, for da opprettes mappen. Vi ser da lages også en idrsa og idrsa.pub, men vi skal ikke bruke de nå. Å bruke denne mappen her. Det vi skal bruke den til, er å kopiere over Otterize Keys fra... ... fra group 100. Hvis jeg får den inn her, så vil alle som har tilgang, inn som group 100, og så vil det komme rett inn som Ruth. Sånn. Og så kan det være lurt å sjekke om rettighetene er riktig. Og rettighetene, de skal være sånn som de er for Grupp 100. Og vi ser Othrice Keys har disse rettighetene. Og så har vi da de samme rettighetene som Ruth. Så da ser alt ut til å være i orden. Så nå kan jeg gå ut igjen.  Og så, istedenfor å prøve å logge inn som group100, så kan jeg prøve å gå rett inn som brut. Og det får jeg nå lov til fordi jeg har lagt inn min ID rsa.pub,", "source": "lecture"}
{"lecture_id": "linux6del6", "chunk_id": "linux6del6_0005", "start": 357.84, "end": 450.64, "token_count": 291, "text": " Og så, istedenfor å prøve å logge inn som group100, så kan jeg prøve å gå rett inn som brut. Og det får jeg nå lov til fordi jeg har lagt inn min ID rsa.pub, min public key, i.authorized keys og slutt. Men da må jeg altså, siden jeg la inn hele denne filen, så må jeg nå også være klar over at den som har denne private ID-en, Så hvis jeg f.eks. ønsker å ta bort den, så kan jeg bare fjerne den linjen. Kontroll-K, fjerner en linje. Og nå har jeg bare den Stud.SSH-tilgangen. Men den er fortsatt ille. Nå kan jeg gå direkte inn som Ruth. Og alt det krever, er da at public key må ligge i.sh. Så får man direkte tilgang. Generelt så bør man være litt forsiktig med å bruke Rute-kontoen direkte. Men på dokkecontainere og virtuelle maskiner, så er det ikke så farlig som det er på fysiske servere, som er tenkt å stå lenge. Dokkecontainere er raske å bygge på nytt og starte opp. Så kan man bygge opp på nytt.", "source": "lecture"}
{"lecture_id": "linux6del6", "chunk_id": "linux6del6_0006", "start": 427.54, "end": 482.42, "token_count": 193, "text": "Men på dokkecontainere og virtuelle maskiner, så er det ikke så farlig som det er på fysiske servere, som er tenkt å stå lenge. Dokkecontainere er raske å bygge på nytt og starte opp. Så kan man bygge opp på nytt. Det gjelder også de dokkekonteinerne vi bruker i OS-kurset. Men husk på at da vil alt dere har lagret, bli borte. Så ta hele tiden backup av skript og kanskje history og hvilke kommandoer dere har gjort, slik at dere alltid til enhver tid har alt som har blitt gjort i disse vemmene. Sånn at dere ikke risikerer å miste dem hvis de skulle. Eller bli ødelagt, og må bygges på nytt.", "source": "lecture"}
{"lecture_id": "os13del8", "chunk_id": "os13del8_0000", "start": 0.0, "end": 97.84, "token_count": 297, "text": "Som kunne lagres i registeret. Og det har vi sett på tidligere. At vi har brukt Move f.eks. for å flytte noe fra RAM og inn i de interne registrene i CPU-en. Og da har vi brukt registeret sånn som prosent-RSP, som er da en peker... Prosent-RSP peker til toppen av stacken. Så innholdet av det registeret er da en... Er da en adresse som peker til toppen av stacken. Altså toppen av stacken her, det er én spesifikk adresse. Det er et til spørsmål i chatten her. Ja. GDDR... Ja, det er vel... Sånn GPU-ram... Det er jeg ikke sikker på. Men det høres veldig sånn ut. At det er grafikkram... Jeg kan sjekke ut det i pausen. Ja... Jo, et annet eksempel på adresserom, det er sånn som IP-adresser. Da har vi alle adresser fra 000 til 255, 255, 255, 255. Da er det en spesifikk betydning av adresser. Alle IP4-adresser må ligge innenfor dette adresserommet. Og det er fordi man måtte begynne med IPV6,", "source": "lecture"}
{"lecture_id": "os13del8", "chunk_id": "os13del8_0001", "start": 78.16, "end": 169.04, "token_count": 286, "text": "det er sånn som IP-adresser. Da har vi alle adresser fra 000 til 255, 255, 255, 255. Da er det en spesifikk betydning av adresser. Alle IP4-adresser må ligge innenfor dette adresserommet. Og det er fordi man måtte begynne med IPV6, fordi det var til slutt ikke nok adresser i adresserommet. Samme problemstillingene har man i internminet. Generelt så er det veldig enkelt adresserom for internminet. Det går bare fra null til maks. Men så trenger man å... Og ha et register for å lagre en adresse. Til å begynne med hadde man 16-bits CPU-er. Og da hadde du en registerstørrelse på 16 bit. Og da... Hvis du da skulle lagre alle adressene, så er det i 16-bit bare plass til to i 16-adresser. Og det er 64K. Og derfor er det mange sånne gamle computere... Kommodore 64 osv. For da hadde de et adresserom som var på 64 000. Og der kunne man lagre 64 kB, og det var punktet.", "source": "lecture"}
{"lecture_id": "os13del8", "chunk_id": "os13del8_0002", "start": 143.12, "end": 256.48, "token_count": 293, "text": "så er det i 16-bit bare plass til to i 16-adresser. Og det er 64K. Og derfor er det mange sånne gamle computere... Kommodore 64 osv. For da hadde de et adresserom som var på 64 000. Og der kunne man lagre 64 kB, og det var punktet. Etter hvert så fikk man 32-bitsregisteret. Og da hadde man to i 32. adresser. Og det er fire. Det var også et sånt problem med 32-bits CPU-er. Hvis man kjørte Linux og hadde mer enn 4 GB ram, så fikk man straks et problem. Mange av de CPU-ene støttet ikke det å bruke 4G-ram. Så etter hvert kom det 64-bits-registeret, Selv to opphøyde 48 gir 256 terabyte. Så det er mer enn nok for rammedelen. Så da er det ikke noe problem med antall bit i registrene. Men generelt så må du da kunne ha et register som kan lagre alle adressene i Iran. Virtuelt adresserom... Vi deler da... Vi har et fysisk adresserom. Det er liksom alle adressene fra null til maks.", "source": "lecture"}
{"lecture_id": "os13del8", "chunk_id": "os13del8_0003", "start": 221.62, "end": 328.92, "token_count": 294, "text": "Så da er det ikke noe problem med antall bit i registrene. Men generelt så må du da kunne ha et register som kan lagre alle adressene i Iran. Virtuelt adresserom... Vi deler da... Vi har et fysisk adresserom. Det er liksom alle adressene fra null til maks. Men generelt så er det ikke plass i alle programmer i internminnet på en gang. Hvis du har veldig mange programmer, så må de til en viss grad lastes inn og ut. Så er det veldig nyttig å kunne ha et virtuelt adresserom, for at man da dynamisk kan velge hvilke biter av et program som er med. Sånn man organiserer det, er at hvert enkelt program får et adresserom fra null til maks. F.eks. til 4G, hvis det er 32-bits adresser. Hver prosess lokalt tror at den har tilgang til alt dette minnet. Den har et kjempesvært adresserom. Men i virkeligheten så... Så ligger noe av dette minnet i ramm, og andre ligger på disken. Eller andre deler er ikke i bruk i det hele tatt. Så disse logiske adressene, de brukes overalt hvor...", "source": "lecture"}
{"lecture_id": "os13del8", "chunk_id": "os13del8_0004", "start": 306.22, "end": 403.92, "token_count": 297, "text": "Den har et kjempesvært adresserom. Men i virkeligheten så... Så ligger noe av dette minnet i ramm, og andre ligger på disken. Eller andre deler er ikke i bruk i det hele tatt. Så disse logiske adressene, de brukes overalt hvor... som programmet refererer til nå, f.eks. en institusjon som dette... Move1023 til AL. Det sier move det som ligger i minneadresse 1023, inn i registeret AL. Men 1023 er da den virtuelle adressen. Det er ikke den faktisk fysiske adressen. Opprinnelig, i de aller første datamaskinene, brukte man ikke et virtuelt adresserom. Og da var 1023 bite nummer 1023 i ramma. Men nå har vi et system hvor alle disse adressene hele tiden oversettes til fysiske adresser. Og dette gjøres da av MMU, som vi skal se på i detalj. Memory Management Unit. Og siden dette gjøres ved... Om ikke hver institusjon, så hver eneste gang man adresserer RAM i det hele tatt, så må denne oversettelsen gjennomføres. Og det betyr at det må gå ekstremt raskt, for...", "source": "lecture"}
{"lecture_id": "os13del8", "chunk_id": "os13del8_0005", "start": 383.18, "end": 441.0, "token_count": 170, "text": "Memory Management Unit. Og siden dette gjøres ved... Om ikke hver institusjon, så hver eneste gang man adresserer RAM i det hele tatt, så må denne oversettelsen gjennomføres. Og det betyr at det må gå ekstremt raskt, for... For dette skjer hele tiden. Så alle programmer som snakker med minnet, de må få sin virtuelle adresse oversatt til den fysiske, og det skjer... Og da har man ikke noe tid til å bruke CPU-sykler på å få dette til. Så dette må nærmest lagres i hardware. Og det er nettopp det MMU er. Det er hardware som oversetter fra virtuelle adresser til fysiske adresser.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0000", "start": 0.0, "end": 118.36, "token_count": 299, "text": "Ja, god morgen, alle sammen. Kjempehyggelig å se at dere er så mange av dere som har kommet dere opp. Kommer på forelesning. Det er veldig hyggelig. Og som sagt, jeg tror det er kjempebra å ha noen sånne faste punkter. For det ser ut som det fortsatt kommer til å bli digital undervisning frem til påske. Men forhåpentligvis så vil vi i hvert fall da kunne starte med fysisk undervisning. I dag så er det lagt ut oppgaver, sånn at man kan faktisk gjøre ferdig første obligg. Og levere inn det. Det har alltid gått med ting som er ferdig. Hvis du ligger litt i forkant, så prøv å få ferdig obliggen så snart du klarer. Jeg tenkte å starte med å si litt praktisk om det, men før jeg kommer så langt, så spør gjerne i skjetten underveis eller på timen. Og spesielt hvis det er noe... Hvis det er noe viktig, så f.eks. at dere ikke hører meg, eller at det er opplagt noe som er galt, så er det kjempefint om dere bare tar av lyden.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0001", "start": 97.28, "end": 197.02, "token_count": 281, "text": "så spør gjerne i skjetten underveis eller på timen. Og spesielt hvis det er noe... Hvis det er noe viktig, så f.eks. at dere ikke hører meg, eller at det er opplagt noe som er galt, så er det kjempefint om dere bare tar av lyden. Det kan dere uansett gjøre når som helst. I tillegg så kommer Ine i dag og kommer til å sitte og hjelpe meg med chatten og svare på alt som er av spørsmål. Kan ikke se at hun er her ennå. Hatt litt problemer med laptopen sin, men hun er der forhåpentligvis snart. OK, aller først.... Så skal vi se litt på obliggene. Skal si litt mer om det og grupper osv. Det blir litt praktisk å starte med. Da skal vi se på denne. Her er kanalsrommet. Som dere ser, så har det kommet oblikktider. Den første er satt. De andre skal jeg tilpasse med. Si gjerne fra også, hvis dere allerede nå ser at dette kolliderer, så kan vi flytte på innleveringer sånn at det passer best for dere.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0002", "start": 165.9, "end": 262.56, "token_count": 300, "text": "Her er kanalsrommet. Som dere ser, så har det kommet oblikktider. Den første er satt. De andre skal jeg tilpasse med. Si gjerne fra også, hvis dere allerede nå ser at dette kolliderer, så kan vi flytte på innleveringer sånn at det passer best for dere. Dere har litt forskjellige fag også, så det er ikke så lett å få til for alle. Men vi prøver å få det til så bra som mulig. Men først og fremst så ligger første opplegg her. Og her står det en tekst om den. Opplegget er sånn at alle oppgaver som er merket rødt med Oblig i de første oppgavene, til og med uke fire, det utgjør den første obligatoriske oppgaven. Og alle de har lagt ut nå, så det inkluderer da oppgaver i neste uke. Dere skal... Ine er tilgjengelig i chatten. Kjempebra, Ine. Dere skal levere dette som grupper. Vi anbefaler grupper på to og tre. Det kan være mulig å være ene, hvis dere er alene. Hvis dere ikke har noen å jobbe sammen med eller andre forhold, anbefaler vi å jobbe i grupper.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0003", "start": 233.72, "end": 319.52, "token_count": 288, "text": "Dere skal... Ine er tilgjengelig i chatten. Kjempebra, Ine. Dere skal levere dette som grupper. Vi anbefaler grupper på to og tre. Det kan være mulig å være ene, hvis dere er alene. Hvis dere ikke har noen å jobbe sammen med eller andre forhold, anbefaler vi å jobbe i grupper. Noen som tidligere har jobbet i gruppe på fire, og til og med på fem. Vi anbefaler det ikke, men hvis dere er en sammensveiset gruppe, så går det altså an. Uansett om dere er én eller to eller opp til fem, så skal dere levere som en av OS-gruppene. OS 123. Og hvis man går inn på people, personer, er det der, så ser man at det er en... Her er en meny som heter OS her oppe. Og da ser vi at her er det en rekke OS1 og OS2-grupper nedover. Vi ser en del av dere har allerede meldt dere inn i grupper. Men da er det veldig fint om... Når dere fortsetter å gjøre det, så melder dere inn i første tomme gruppe. Her ser vi OS6 er nå den første tomme.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0004", "start": 298.4, "end": 389.16, "token_count": 291, "text": "Og da ser vi at her er det en rekke OS1 og OS2-grupper nedover. Vi ser en del av dere har allerede meldt dere inn i grupper. Men da er det veldig fint om... Når dere fortsetter å gjøre det, så melder dere inn i første tomme gruppe. Her ser vi OS6 er nå den første tomme. Så hvis dere skal lage en gruppe nå, så tar dere OS6. Og da, etter at dere har laget gruppe, så leverer dere inn obliger som den gruppen. Og det kan være selv om det da er sånn som her, bare én student, så leverer du likevel inn sånn gruppe. Etter hvert skal dere få VM-er, virtuelle maskiner, eller aktisk dokker, virtuelle maskiner. Og da vil dere få utlevert passord osv. i disse gruppene. Dette står også på kurssiden. Her ser vi. Dette er de fire første ukene. Vi er nå her i uke tre. Så dette er oppgavene vi skal jobbe med i dag. Men du kan allerede nå gå i gang med uke fire-oppgavene. Fristen for obligasjonen er ikke i neste uke, men i uken etter.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0005", "start": 363.72, "end": 454.5, "token_count": 294, "text": "Her ser vi. Dette er de fire første ukene. Vi er nå her i uke tre. Så dette er oppgavene vi skal jobbe med i dag. Men du kan allerede nå gå i gang med uke fire-oppgavene. Fristen for obligasjonen er ikke i neste uke, men i uken etter. Så at dere har litt tid på å få de siste oppgavene ferdige. Her står det egentlig bare den samme teksten som på KANDAS. Og det er det jeg tror dere trenger å vite om oppgavene. I dag så skal vi, som det står her, se på vipper og registre. Det er altså hvordan lagre bits i en CPU. Så skal vi se på CPU-arkitektur. Og det som egentlig er ganske fantastisk, er at vi skal bygge... Vi skal ikke bygge, men vi skal se på hele arkitekturen til en CPU. Hvordan den virker helt fra transistornivå og oppover. Og oppover, det betyr at vi skal være i stand til å implementere... Det vi implementerer, er en liten forløkke. Men i prinsippet gjelder akkurat det samme for all mulig kode.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0006", "start": 431.2, "end": 525.16, "token_count": 294, "text": "Hvordan den virker helt fra transistornivå og oppover. Og oppover, det betyr at vi skal være i stand til å implementere... Det vi implementerer, er en liten forløkke. Men i prinsippet gjelder akkurat det samme for all mulig kode. Så all mulig kode kan i prinsippet implementeres på den simuleringen vi har. Ja. Ellers så er det... tema fra digitale forelesninger i forrige uke, som da ukens oppgaver... Det er litt diverse Linux-kommandoer. Også noen små sånne triks for å jobbe raskere i skjellet. Det er det viktig å få med seg. Kan se kjapt på de òg. Her er det tidsbesvarende triks i et Linux-skjell. Det er det nyttig å få med seg for å kunne jobbe litt raskere og mer effektivt. Så er det litt diverse... Mye filbehandling. Litt om orientering osv. Så er det ett punkt som er viktig her, og det er med filrettigheter. Det er det viktig å kunne sette på et Linux-system. Som vanlig så la jeg på onsdag ut diverse demoer rundt disse temaene.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0007", "start": 503.72, "end": 611.86, "token_count": 300, "text": "Mye filbehandling. Litt om orientering osv. Så er det ett punkt som er viktig her, og det er med filrettigheter. Det er det viktig å kunne sette på et Linux-system. Som vanlig så la jeg på onsdag ut diverse demoer rundt disse temaene. Så her kan dere jobbe som dere vil. Enten kan dere gå inn og se på demoene først, og så gjøre oppgaver, eller så kan dere kanskje starte på oppgavene. Hvis dere står fast, så kan dere gå tilbake og se hvordan jeg gjør det her. Men det aller viktigste er at dere faktisk gjør disse oppgavene, og får til det praktiske. For dette er stoff som du trenger å øve og prøve og feile litt for å få det inn i fingeren. OK. Da skal vi gå til dagens sema. Vipper og registre. Og datamaskinarkitektur. Først en kort oppsummering av hva vi gjorde sist. Veldig små brytere. Det kommer en ledning inn til bryteren som skrur den av og på. Er den på, leder transistoren strøm. Er den av, leder transistoren ikke strøm. Veldig enkelt.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0008", "start": 577.86, "end": 669.76, "token_count": 274, "text": "Først en kort oppsummering av hva vi gjorde sist. Veldig små brytere. Det kommer en ledning inn til bryteren som skrur den av og på. Er den på, leder transistoren strøm. Er den av, leder transistoren ikke strøm. Veldig enkelt. Dette enkle prinsippet kan man da bruke til å lage logiske porter. Og med logiske porter så kan man implementere and or not. Og man kan implementere alle logiske sammenhenger. Dette brukes av en datamaskin for å lage en maskin som gjør nøyaktig det vi ønsker den skal gjøre. Vi ønsker den skal gjøre forskjellige institusjoner. Som f.eks. å legge sammen to tall, trekke fra hverandre tall, sammenligne to tall, osv. Og når man har klart for seg hvilken funksjon man skal ha. I forrige gang så vi på dette med å addere to tall. Da så vi på algoritmen for å addere to tall. Da fant vi ut at en bit av algoritmen kan vi ta ut og lage en logisk krets av.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0009", "start": 650.58, "end": 725.9, "token_count": 292, "text": "Og når man har klart for seg hvilken funksjon man skal ha. I forrige gang så vi på dette med å addere to tall. Da så vi på algoritmen for å addere to tall. Da fant vi ut at en bit av algoritmen kan vi ta ut og lage en logisk krets av. Det første man gjør, er å skrive ned en sannhetsstabell som viser logikken systemet skal ha. Og så så vi at ut ifra en sandstabell, så kan man skrive rett ned en krets med and or and not-porter. Det er en veldig rett frem-metode for å gjøre det. Etter at man har gjort det, så kan det bli ganske komplekse kretser. Men da kan disse forenkles med bolskalgebra. Og når man har gjort det, så har man en logisk rets som man kan tegne opp. Man kan sende den til en produsent, og så kan man få et kretskort som gjør nøyaktig det man ønsker. Man lager som regel ikke et kretskort av bare en liten av dere, som vi gjorde sist. Men man har en litt større krets. Men prinsippet er akkurat det samme.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0010", "start": 708.46, "end": 798.36, "token_count": 299, "text": "Man kan sende den til en produsent, og så kan man få et kretskort som gjør nøyaktig det man ønsker. Man lager som regel ikke et kretskort av bare en liten av dere, som vi gjorde sist. Men man har en litt større krets. Men prinsippet er akkurat det samme. Vi så på én liten boks. Hemmeligheten med å lage en hel CPU er at man tar mange av den typen bokser og setter sammen til en stor og kompleks enhet. Det vi lagde sist, var en krets med en logisk krets som aderer tall. Avdelingskrets. Så dette var på en måte sluttresultatet fra forrige time. Logisk sett så var dette sluttresultatet. Og det vi har oppnådd, er at vi har lagd... Et lite kretssystem, bare ved hjelp av logikk og enkle brytere, A- og påbrytere, som er sånn at hvis vi sender inn fire bit A og fire bit B inn til denne maskinen, så uansett verdien på nullerne og enerne her, så får man ut summen C av A pluss B. I dette eksempelet her så står det tallet seks, både A og B.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0011", "start": 768.44, "end": 850.74, "token_count": 291, "text": "Et lite kretssystem, bare ved hjelp av logikk og enkle brytere, A- og påbrytere, som er sånn at hvis vi sender inn fire bit A og fire bit B inn til denne maskinen, så uansett verdien på nullerne og enerne her, så får man ut summen C av A pluss B. I dette eksempelet her så står det tallet seks, både A og B. Og det som kommer ut, det er en ener, toer, firer og en åtter. Så det er åtte pluss fire. Det er tolv som kommer ut. Og det er det riktige svaret i dette tilfellet. Det vi kanskje ikke sa så mye om sist, er at det er et opplagt problem her. Hva om man legger sammen et stort tall? La oss si vi har enere på alle her. Det blir tre pluss tolv. Det blir 15. Hvis man legger sammen 15 pluss 15, så får man jo 30. Men det største tallet som kan lages eller vises med 4-bit, det er jo 15. Så her skjer det noe galt. Og da får man en såkalt overflow. Og det fører ofte til problemer.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0012", "start": 828.44, "end": 921.94, "token_count": 299, "text": "Hvis man legger sammen 15 pluss 15, så får man jo 30. Men det største tallet som kan lages eller vises med 4-bit, det er jo 15. Så her skjer det noe galt. Og da får man en såkalt overflow. Og det fører ofte til problemer. Men sånn er det. Hvis man regner med 32-bitstall, f.eks., så... Hvis man tar med pluss og minus, så kan de maks representere to milliarder. Hvis man da utfører et regnsyke i et C-program eller et annet program hvor resultatet blir høyere enn to milliarder, så får du en feil. Da kan man plutselig risikere å få ut et negativt tall når man legger sammen to store tall. Så dette gjelder for alle systemer, men man må bare ha nok prøver. Sånn at man kan få representert så store tall som mulig, eller som man behøver. Og så ser vi at vi egentlig bare trenger ett bit til, så kan vi representere summen av alle fire bits tall. Men nå kommer det vi trenger å gjøre videre. Det er problemer av denne kretsen. Og det er jo ikke alltid vi skal legge sammen.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0013", "start": 888.44, "end": 978.42, "token_count": 286, "text": "Sånn at man kan få representert så store tall som mulig, eller som man behøver. Og så ser vi at vi egentlig bare trenger ett bit til, så kan vi representere summen av alle fire bits tall. Men nå kommer det vi trenger å gjøre videre. Det er problemer av denne kretsen. Og det er jo ikke alltid vi skal legge sammen. Så derfor så lager man da heller en litt mer kompleks krets, som kan gjøre flere ting på en gang. Og det man lager da, er en alu, og det skal vi snakke mye om i dag. Arithmetic Logic Unit står ALU for. Altså en aritmetisk og logisk enhet. Den kan både gjøre aritmetikk, altså legge sammen og trekke fra osv. Og i tillegg gjøre logikk, sammenligne og ande over osv. Det smarte trikset her er at det viser seg at en del kretser kan ligne litt på hverandre. F.eks. hvis du skal trekke fra, så kan du bruke addisjon. Altså gjøre noen smarte triks med to-ord-kompliment, som er en måte å representere.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0014", "start": 953.5, "end": 1030.6, "token_count": 278, "text": "Og i tillegg gjøre logikk, sammenligne og ande over osv. Det smarte trikset her er at det viser seg at en del kretser kan ligne litt på hverandre. F.eks. hvis du skal trekke fra, så kan du bruke addisjon. Altså gjøre noen smarte triks med to-ord-kompliment, som er en måte å representere. Hvis du representerer negative tall med to i kompliment, så kan man nesten bruke akkurat det samme som en adderer. Og så får man inn fortegnene også. Tilsvarende med andre komponenter. Man kan bruke litt av de andre portene, sånn at det blir mer effektivt. Så kommer det smarte at man putter inn noen kontrollbitt i aluen. Her står det S0 og... Og i dette tilfellet så har jeg lagd en alu som er sånn at... Ja, f.eks. hvis S0 er 0 og Sn er lik 1, så adderer denne kretsen. Det er bare noe man definerer. Men hvis begge to er 0, så kanskje så utføres a minus b.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0015", "start": 1008.44, "end": 1104.22, "token_count": 293, "text": "Og i dette tilfellet så har jeg lagd en alu som er sånn at... Ja, f.eks. hvis S0 er 0 og Sn er lik 1, så adderer denne kretsen. Det er bare noe man definerer. Men hvis begge to er 0, så kanskje så utføres a minus b. Og hvis det er to e-er inne her, så kanskje det som kommer ut da, er... Og det er tilfellet i... det tilfellet her, at det som kommer ut av C, er A pluss 1. Det er increment, altså man øker verdien med 1. Ja, det er spørsmål når du ser slides. Ja, det... Det er fint at de fleste ser slides. Det er meningen. På denne måten så kan man få kretsen til å gjøre akkurat det den operasjonen man ønsker, ved å sette inn kontroll dit. Det er viktig å ha med seg videre når vi skal bygge opp en CPU. Så bruker vi nøyaktig den biten der. Det er dette som fører til såkalte instruksjoner, eller maskininstruksjoner. Disse bitene kontrollerer nøyaktig hva Alun gjør.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0016", "start": 1085.52, "end": 1171.24, "token_count": 299, "text": "Det er viktig å ha med seg videre når vi skal bygge opp en CPU. Så bruker vi nøyaktig den biten der. Det er dette som fører til såkalte instruksjoner, eller maskininstruksjoner. Disse bitene kontrollerer nøyaktig hva Alun gjør. For Alun, det er virkelig hjernen til CPU-en. Og CPU-en er hjernen til datamaskinen. Så det er her det skjer. All logikk og alt som du programmerer, det vil til syvende og sist utføres inni Alun. Alle operasjoner, som å addere, som vi så på. Riktignok med 3D-er, men subtrahere, eller subtrahere, det er å trekke fra. Og increment eller pluss-pluss, decrement. Skulle være minus-minus, altså du trekker fra én. Og litt mer komplekse operasjoner som å multiplisere og dividere. De aller enkleste allene kan ikke multiplisere og dividere. Hvis de skal lage noen små multiplikasjoner, så må de legge sammen mange ganger. Men i de mer komplekse aluene så har man en egen krets som multipliserer.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0017", "start": 1149.48, "end": 1237.72, "token_count": 292, "text": "Og litt mer komplekse operasjoner som å multiplisere og dividere. De aller enkleste allene kan ikke multiplisere og dividere. Hvis de skal lage noen små multiplikasjoner, så må de legge sammen mange ganger. Men i de mer komplekse aluene så har man en egen krets som multipliserer. Dividerer tar enda litt mer tid. Men det betyr at disse operasjonene kan ta litt lengre tid enn av dere. De første her er aritmetiske operasjoner. Så de tre siste er logiske. Så det er den logiske delen med logiske operasjoner. Skift, f.eks., som flytter alle bitt i én retning, det skal vi se på etterpå. Noe som man hele tiden gjør, f.eks. en GIF-test, er å sammenligne to størrelser. Finne ut om de er like eller forskjellige, eller om den ene er større eller mindre enn den andre. De spesifiserer ofte 16 operasjoner til denne Alu. Ofte har de enda flere operasjoner. Dette er et tidlig Alu-design på en maskin som het Edzak-2.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0018", "start": 1206.72, "end": 1307.12, "token_count": 288, "text": "Finne ut om de er like eller forskjellige, eller om den ene er større eller mindre enn den andre. De spesifiserer ofte 16 operasjoner til denne Alu. Ofte har de enda flere operasjoner. Dette er et tidlig Alu-design på en maskin som het Edzak-2. Som ble lagd i 1958. Dette var akkurat på overgangen til man begynte med transistorer. Men disse maskinene hadde radiorør. Et helt sånt radiorør tilsvarer en transistor. Da sier seg selv at da ble disse maskinene ganske enormt store. Men sånn så det ut. Det er ikke så langt tilbake. Men det illustrerer den enorme revolusjonen som transistoren gjorde, hvor vi kan få i dag milliarder av sånne transistorer inn på en liten brikke. Ja, nå er vi ferdig med en viktig del av Alun. Men den neste viktige nå er å kunne lagre dataene. Hvis vi går tilbake her, så ser vi... Jeg har ikke sagt noe om hvordan man lagrer disse bitene her. Men opplagt så trenger vi i en CPU utenpå Alun...", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0019", "start": 1278.44, "end": 1374.48, "token_count": 282, "text": "Ja, nå er vi ferdig med en viktig del av Alun. Men den neste viktige nå er å kunne lagre dataene. Hvis vi går tilbake her, så ser vi... Jeg har ikke sagt noe om hvordan man lagrer disse bitene her. Men opplagt så trenger vi i en CPU utenpå Alun... Lagerenheter hvor vi kan lagre tall og størrelser. Det kan også være en representerende bokstav, men vi må i hvert fall ha en lagerenhet som lagrer en rekke med bitt. Det kalles et register, og det er da en veldig viktig komponent i NCPU. I tillegg at denne må kunne lagre tall, så må den være veldig rask. Disse portene her, disse logiske portene, de er ekstremt raske. Så... Så den beste løsningen er å lage disse registrene av samme teknologi som man lager enda flere porter, nemlig med transistorer. Og det er det mulig å få til. Man kan i prinsippet... På den enkleste måten. Måten å tenke seg å lagre null og én, er å lagre en liten mengde med ladning.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0020", "start": 1351.96, "end": 1433.58, "token_count": 298, "text": "av samme teknologi som man lager enda flere porter, nemlig med transistorer. Og det er det mulig å få til. Man kan i prinsippet... På den enkleste måten. Måten å tenke seg å lagre null og én, er å lagre en liten mengde med ladning. Med elektrisk ladning. Akkurat som du gnir på en ballong, så har den positiv ladning. Og så kan du ta på den, så får du et lite støt, og da lader du ut ballongen. Da kunne du tenke deg at en ballong med ladning én, den er en ener. Og ladning null er en null. Teknologien brukes i ram, som vi skal se på senere. Det er noen problemer med ram. For det første at det ikke er like hurtig som porter. Og for det andre så må de refreshes. Man må lade dem opp kanskje sånn ti ganger i sekundet, hvis du skal beholde den ene. Derfor bruker man ikke dette i CPU-er, men man bruker i stedet såkalte vipper, eller flip-flops på engelsk. En konstitusjon som ved hjelp av korter gjør at man kan lagre nuller og enere.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0021", "start": 1411.52, "end": 1494.88, "token_count": 293, "text": "Man må lade dem opp kanskje sånn ti ganger i sekundet, hvis du skal beholde den ene. Derfor bruker man ikke dette i CPU-er, men man bruker i stedet såkalte vipper, eller flip-flops på engelsk. En konstitusjon som ved hjelp av korter gjør at man kan lagre nuller og enere. Vi skal se på i detalj hvordan man gjør det. Og det er mye raskere enn RAM. Det er ikke ekstremt, det er i hvert fall en faktor ti. Og kanskje mer i nå tilfelle. Men en faktor ti er mye. Og et 64-bit-register, f.eks., det består da av 64 VIP-er. En vippe er én enhet som kan lagre en null eller en ener. Det er ikke så enkelt å bare lage en lagringsenhet av porter. Men noe som vi må få til, er å lage en lukket krets. Det er eneste måten vi kan lagre noe, ellers er port bare input og output. Men vi ønsker å lagre det. Dermed må vi sette opp en lukket krets. Dette er det første forsøket vårt på å lagre en bit.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0022", "start": 1471.9, "end": 1558.04, "token_count": 286, "text": "Men noe som vi må få til, er å lage en lukket krets. Det er eneste måten vi kan lagre noe, ellers er port bare input og output. Men vi ønsker å lagre det. Dermed må vi sette opp en lukket krets. Dette er det første forsøket vårt på å lagre en bit. Det jeg skal gjøre nå, er å prøve å feile og så utvikle en konstruksjon som kan lagre en bit. Og q er da liksom den lagrede enheten. Så i dette tilfellet, i denne kretsen her, så lagrer vi en ener. Dette er en notport. Så kommer en null inn her, og så går den enere ut. Så ser vi at vi har koblet output fra den notporten til input på den som står under. Da ser vi for en litt lur krets. Det kommer en ener inn her, og da vil det gå en null ut. Så går en null inn der, og så kommer det en ener ut. Så her har vi konstruert en krets som inneholder en ener. Hva er problemet, er spørsmålet. Jo, problemet her er at det er vel og bra at vi har den eneren,", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0023", "start": 1537.24, "end": 1616.6, "token_count": 297, "text": "og da vil det gå en null ut. Så går en null inn der, og så kommer det en ener ut. Så her har vi konstruert en krets som inneholder en ener. Hva er problemet, er spørsmålet. Jo, problemet her er at det er vel og bra at vi har den eneren, men dette er en lukket krets, så der vil det bare bli stående en ener for evig og alltid. Så på en eller annen måte må vi kunne endre på denne verdien. Og da kommer neste forsøk. Her har vi en litt mer komplisert krets, hvor vi da kan endre en bitt-verdi. Etter pause tenkte jeg å ta en poll hvor vi får noen spørsmål fra dette. Så her gjelder det å følge med. Det ser jo litt komplisert ut. Men det er egentlig ikke så komplisert. Her fremme har vi den samme konstitusjonen med not-porter. Men i tillegg, for å kunne legge inn en verdi, altså verdien d, det er den som vi ønsker å lagre, så har vi satt opp et system med to år. Da kan man overbevise om at hvis man setter inn en null her, så lagres en null.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0024", "start": 1591.98, "end": 1673.2, "token_count": 300, "text": "Her fremme har vi den samme konstitusjonen med not-porter. Men i tillegg, for å kunne legge inn en verdi, altså verdien d, det er den som vi ønsker å lagre, så har vi satt opp et system med to år. Da kan man overbevise om at hvis man setter inn en null her, så lagres en null. Hvis man setter inn en ener, så lagres en ener. Vi kan jo se på hva som skjer hvis man setter inn en null. Jo, da kommer det en null inn her. Går inn i notporten. Da må det bli en ener her. Og så vet vi det at når det kommer en ener inn i en overport, så vil det alltid komme en ener ut. Det kommer en ener inn her, så uansett hva som er der, så kommer det en ener ut. Dermed får vi lagt inn denne verdien null i denne kretsen. For det kommer en ener inn her, og da blir det en null der. Så får vi på samme måte som tidligere at det er en lukket krets. Det går en null inn i denne orporten, og så kommer det en null herfra. Da er det null som går videre, og så blir det en ener der. Og en og en gir 1 og 0 osv.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0025", "start": 1658.1, "end": 1739.24, "token_count": 294, "text": "Så får vi på samme måte som tidligere at det er en lukket krets. Det går en null inn i denne orporten, og så kommer det en null herfra. Da er det null som går videre, og så blir det en ener der. Og en og en gir 1 og 0 osv. Og hvis man da ønsker å switche og legger inn en ener her, så får vi akkurat det motsatte. Og da vil det til slutt bli en ener her. Det som skjer da, er at da kommer det en ener inn her. En ener inn i en orfort vil alltid gi en ener. Så kommer det null her. Og da kommer det null inn der. Da kommer det to nuller inn der. Så på samme måte så funker den også. Men hva er problemet nå? Problemet nå er ikke like lett å se, men det vi skulle ønske, er at man på en måte kan skru av innvirkningen fra denne D-en. Man ønsker å ha en vippe, eller en lagerenhet, som er sånn at... Hvis vi setter på en null her, så lagres nullen. Men så skulle man ønske å på en måte skru av kretsen, sånn at den nullen blir bevart.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0026", "start": 1716.24, "end": 1803.4, "token_count": 278, "text": "er at man på en måte kan skru av innvirkningen fra denne D-en. Man ønsker å ha en vippe, eller en lagerenhet, som er sånn at... Hvis vi setter på en null her, så lagres nullen. Men så skulle man ønske å på en måte skru av kretsen, sånn at den nullen blir bevart. Uansett om d-en her endres. Så jeg ønsker å ha et system som er sånn at om jeg endrer d-en til 1 her nå, så kan jeg velge at vippen, eller det registeret som holder denne verdien, det skal være uendret. Med en gang de gjør en endring her, så forplanter den endringen seg. Og så lager vi en annen bit. Så dette er foreløpig løsningen. Det er en såkalt de-loch, eller de-latch på engelsk. Det er en enhet som lager et bitt. Men i tillegg... Så kan man velge å skru av enheten, sånn at den ikke reagerer på input. Vi har fått inn en C her i tillegg. Den virker sånn, det er en kontrollenhet.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0027", "start": 1782.92, "end": 1888.0, "token_count": 293, "text": "Det er en enhet som lager et bitt. Men i tillegg... Så kan man velge å skru av enheten, sånn at den ikke reagerer på input. Vi har fått inn en C her i tillegg. Den virker sånn, det er en kontrollenhet. Den er sånn at hvis jeg liker én, så vil verdien som kommer inn på det her, den vil lagres. Og hvis jeg liker null, så vil denne lagrede verdien beholdes, helt uavhengig av hva som kan skje. Det har vi fått til ved å endre litt på den forrige. Vi har lagt inn to and-porter. Ellers så er de to ord-portene her. Vi ser tilbake. Konstruksjonen er helt lik, bortsett fra at vi har lagt inn to and-porter. Og da kan man igjen overbevise seg selv om at vi ser lik én. Da vil denne løsningen virke akkurat som den forrige løsningen. For vi vet at med and... Hvis det kommer en ener inn i en and-port, så... Jo, så er det den andre verdien som gir upput, f.eks.. Hvis... Hvis det kommer en 1 inn her og en ener inn der,", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0028", "start": 1855.52, "end": 1966.44, "token_count": 292, "text": "For vi vet at med and... Hvis det kommer en ener inn i en and-port, så... Jo, så er det den andre verdien som gir upput, f.eks.. Hvis... Hvis det kommer en 1 inn her og en ener inn der, så får man en ener ut. Men det er ikke helt riktig. Hvis det kommer en null inn, så kommer det alltid en null ut. For å overbevise om at denne virker, så kan vi kanskje se på... Hva skjer f.eks. hvis 1 er 1, og denne nå skal virke og skal endre? Hva skjer da med kretsen? Jo, hvis det kommer en ener inn på det og CL1, så kommer det en ener inn der. Og samtidig vil det da komme null inn der. Og da vil kretsen fungere akkurat som. Som denne her, på samme måte. Men så ser vi i c-lik null. Da skrur vi på en måte av innvirkningen fra kretsen. For i c-lik null, så vil det komme en null inn i begge endeportene. Og da går det null videre til begge årportene. Og når det kommer null inn i begge årportene, så vil denne kretsen", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0029", "start": 1947.26, "end": 2036.72, "token_count": 287, "text": "Da skrur vi på en måte av innvirkningen fra kretsen. For i c-lik null, så vil det komme en null inn i begge endeportene. Og da går det null videre til begge årportene. Og når det kommer null inn i begge årportene, så vil denne kretsen Den blir helt isolert, så den vil ikke endre seg, uansett om man endrer på det. Så man kan overbevises om det er slik kretsen virker. Det er egentlig bare å prøve alle kombinasjoner. Men det aller viktigste er bare å vite at sånn funker den kretsen. Hvis c er lik 1, så leser den impet-verdien og lagrer den. Hvis det er lik null, så beholdes verdien som er lagret, uavhengig av hva det er. Og så ser vi det som vi hele tiden gjør i datamaskinarkitektur. Vi lager da en liten sånn logisk boks som inneholder alt dette. Akkurat som vi lagret den aritmetiske enheten. Akkurat som vi lagde den Adereren. Vi lagde en kompleks aderer og en liten boks.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0030", "start": 2008.38, "end": 2087.46, "token_count": 278, "text": "Og så ser vi det som vi hele tiden gjør i datamaskinarkitektur. Vi lager da en liten sånn logisk boks som inneholder alt dette. Akkurat som vi lagret den aritmetiske enheten. Akkurat som vi lagde den Adereren. Vi lagde en kompleks aderer og en liten boks. Og så etterpå, når vi logisk skal sette det sammen, er det lett å bruke disse boksene. Det er spørsmål i kretsen om... I disse lukkede kretsene, hvordan kommer verdien ut? Går de ikke rundt og rundt i evighet? Jo, de går på en måte rundt og rundt i en evighet. Det er sånn vi ønsker å lagre f.eks. denne kretsen her. Her vil den gå rundt og rundt i evighet, og vi beholder den eneren. Men når vi lager en krets sånn som dette her, så kan vi koble det sammen. Og da vil vi se at når vi setter selik 1 og endrer på intetverdien det, så vil vi få en endring her. Og dermed så får man en endring.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0031", "start": 2064.86, "end": 2147.16, "token_count": 280, "text": "Her vil den gå rundt og rundt i evighet, og vi beholder den eneren. Men når vi lager en krets sånn som dette her, så kan vi koble det sammen. Og da vil vi se at når vi setter selik 1 og endrer på intetverdien det, så vil vi få en endring her. Og dermed så får man en endring. Og da endres systemet hele tiden, og det er nøyaktig det som skjer i en CPU. Men det skal vi se på i detalj. Ja. Det er også et spørsmål om problemene i de to første kretsene. Vi har et par oppgaver som vi skal se på, men jeg kan si det kjapt. Her er problemet her. Det er at man ikke kan endre på verdien. Hvis man først har en ener inn her, så er det umulig å endre på den eneren og gjøre den til null. Så dermed legger vi på dette systemet for å kunne endre verdien. Og nå har vi et system som kan endre verdi. Nå er det null her. Da lagres den nullen. Hvis jeg endrer den til én, så kommer det en ener her.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0032", "start": 2125.68, "end": 2216.96, "token_count": 292, "text": "så er det umulig å endre på den eneren og gjøre den til null. Så dermed legger vi på dette systemet for å kunne endre verdien. Og nå har vi et system som kan endre verdi. Nå er det null her. Da lagres den nullen. Hvis jeg endrer den til én, så kommer det en ener her. Er at med én gang jeg gjør en endring her, så endres verdien seg. Men jeg ønsker å ha en lagerenhet som man på en måte kan skru av. Sånn at den lagrede enheten bare forblir der, uten å endres. Og for å få til det, så trenger man en litt mer kompleks struktur. Nemlig en bryter, en kontroller C som skrur av og på det. At man kan lagre data. Så skal vi prøve å bruke disse fire delåsene for å gjøre noe praktisk med det. For det oppstår faktisk fortsatt et problem. Selv etter at vi har lagd den fine devicen her, så har vi fortsatt et problem. Ja, og det er et litt mer komplekst problem. Men vi ser... Dette er måten man setter sammen biter på. Man kabler dem sammen.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0033", "start": 2192.84, "end": 2292.72, "token_count": 295, "text": "For det oppstår faktisk fortsatt et problem. Selv etter at vi har lagd den fine devicen her, så har vi fortsatt et problem. Ja, og det er et litt mer komplekst problem. Men vi ser... Dette er måten man setter sammen biter på. Man kabler dem sammen. Så her ønsker jeg å lage et såkalt skiftregister. Hvor vi har lagret 1.0, 1.0. Og så ønsker vi at... Ved å skru på den bryteren her, så ønsker jeg å flytte... Alle byttene til høyre. Sånn at den nullen kommer inn her. Eneren skyver seg over dit, null over dit og én over dit. Sånn at vi utfører da operasjonen ved å gå fra 1010 til 0101. Og den operasjonen er faktisk da å dele på to, hvis man tenker på dette som et tall. Denne konstitusjonen ser jo helt fin ut, fordi vi husker at Q er det som lagres. Så hvis vi f.eks. ser på den siste enheten her, som har lagret en null. Så ser vi at den leser en ener. Verdien på den latchen, den låsen, som står til...", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0034", "start": 2264.32, "end": 2353.72, "token_count": 299, "text": "Denne konstitusjonen ser jo helt fin ut, fordi vi husker at Q er det som lagres. Så hvis vi f.eks. ser på den siste enheten her, som har lagret en null. Så ser vi at den leser en ener. Verdien på den latchen, den låsen, som står til... Det er en ener. Og den kommer inn som input på det. Og så lenge c er lik 1, så vil den da lese den verdien. Da vil den få en ener. På samme måte så vil denne her lese den nullen og få en null. Denne vil lese eneren og få en 1. Denne leser 0 og får en 0 der. Og da vil det etterpå... Så vil det stå 0, 1, 0, 1. Og så kan vi da tenke oss at... Nøyaktig når jeg har gjort det, så skrur vi av C. Setter den til null, og dermed har vi utført den skiftoperasjonen. Men så er det et problem, og det som er problemet, er timing. Jeg sa at vi etter en stund så skrur vi av den eneren her. Setter den til null. Men da er spørsmålet hvordan får vi riktig timing her?", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0035", "start": 2329.12, "end": 2425.6, "token_count": 293, "text": "Setter den til null, og dermed har vi utført den skiftoperasjonen. Men så er det et problem, og det som er problemet, er timing. Jeg sa at vi etter en stund så skrur vi av den eneren her. Setter den til null. Men da er spørsmålet hvordan får vi riktig timing her? Og det er en del av problemet. For dette er jo fysiske komponenter, så når man skrur på den eneren og får den til å virke, så vil det ta bitte litt tid. Kanskje i underkant av et nanosekund, når disse komponentene er ekstremt små. Men likevel litt tid. Fra denne nullen proposisjonen, Det er strøm... Bitte små strømmer som strømmer. Propagerer sånn at den blir til en null å lagre seg. Det tar litt tid. Dermed kan det være litt forskjell i hvor lang tid det tar. Dette kan være enda større forskjeller hvis disse enhetene ikke er like. Da kan det virkelig være en avgjørende forskjell i tid på. Hvor lang tid det tar før den strømmer herfra og hit. Og med en gang det skjer, så får man et problem med at...", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0036", "start": 2405.84, "end": 2501.98, "token_count": 291, "text": "Dette kan være enda større forskjeller hvis disse enhetene ikke er like. Da kan det virkelig være en avgjørende forskjell i tid på. Hvor lang tid det tar før den strømmer herfra og hit. Og med en gang det skjer, så får man et problem med at... Vi ser denne leser jo en ener. Men hva om den nullen har propagert hit før den her har rukket å lese eneren? Da vil den å lese null. Og hvis man har en liten usikkerhet i tiden her, så vil ikke det. I tidligere år hvor vi hadde fysiske forelesninger, så prøvde jeg å illustrere dette. Ved at dere som studenter ble stilt opp i en rekke, sånn som dette. Med jenter og gutter. Fant ikke noen gode studentillustrasjoner, så det ser jo ikke sånn ut.  Ideen var da at man setter opp åtte menneskelige delåser på rad. Hvor en arm opp, sånn som de to her, det betyr en ener. Og en arm ned, det betyr en null. Og ideen var da at disse menneskene skulle virke som vipper. Og opplegget var da sånn at hun som står sist her,", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0037", "start": 2476.52, "end": 2566.0, "token_count": 290, "text": "Ideen var da at man setter opp åtte menneskelige delåser på rad. Hvor en arm opp, sånn som de to her, det betyr en ener. Og en arm ned, det betyr en null. Og ideen var da at disse menneskene skulle virke som vipper. Og opplegget var da sånn at hun som står sist her, hun skal da se på den personen som står foran seg. Nei, det var faktisk motsatt. Han som står her, han skal se på hun som står til høyre for seg. For dette skal også være et skifteregister. Og så her er det null, hun har armen nede, og da skal han ta armen. Hun ser på han, så hun skal fortsette å holde armen opp. Han skal se på henne og skal løfte opp hånden, sånn at man får et skift. Altså at de to enerne går til venstre. Det viser seg når man setter opp dette og gjør det i praksis, så fungerer det veldig dårlig. Fordi det alltid er litt forskjell, når et menneske gjør noe sånt, i hvor lang tid man bruker. Og det som hele tiden oppstår da,", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0038", "start": 2537.92, "end": 2639.76, "token_count": 298, "text": "Altså at de to enerne går til venstre. Det viser seg når man setter opp dette og gjør det i praksis, så fungerer det veldig dårlig. Fordi det alltid er litt forskjell, når et menneske gjør noe sånt, i hvor lang tid man bruker. Og det som hele tiden oppstår da, er sånn som her, at det er to enere, og så plutselig blir det tre enere, for du får en ener til. Og det kan være fordi det er forskjell i hvor fort hun som står her, ser den hånden her. Så... Hvis han løfter den hånden veldig fort opp fordi han ser hunna-hånden i været, så vil hun plutselig ta hånden opp. Og dermed så oppstår det en bit som kommer ut fra ingenting. Og dette er opplagt... Dette er opplagt ikke bra for en sånn enhet. Dette gjør at man overhodet ikke kan stole på et sånt skifteregister. Så da kommer den siste fiksen som gjør at man får en enhet man kan stole på. Og det er en såkalt D-vippe. Det man gjør da, er at man setter sammen to låser.", "source": "lecture"}
{"lecture_id": "os3", "chunk_id": "os3_0039", "start": 2615.28, "end": 2707.62, "token_count": 239, "text": "Dette gjør at man overhodet ikke kan stole på et sånt skifteregister. Så da kommer den siste fiksen som gjør at man får en enhet man kan stole på. Og det er en såkalt D-vippe. Det man gjør da, er at man setter sammen to låser. Dette er Hausser'n Master og Slave. Det er to låser som man... Dette er den endelige enheten som man lagrer på. Men jeg ser klokka er kvart over ni nå, så vi tar en pause der. Og så skal vi se mer på hva som gjør at denne vippen virker som den skal. At vi dermed kan bruke dette som en lagerenhet i en CPU. Og dette er den virkelige lagerenheten i en CPU. Hvis vi setter sammen 64 sånne, så får vi et 64-bits-register som man har i en CPU. Men vi tar en pause der, og så ser vi på det etter pausen. Skal jeg prøve å stoppe recording her?", "source": "lecture"}
{"lecture_id": "linux3del7", "chunk_id": "linux3del7_0000", "start": 0.0, "end": 93.5, "token_count": 285, "text": "Omdirigering til og fra filer benytter man seg ofte av i Linus. Så vi skal se litt på det nå. Hvis jeg skriver ekko hei, så går det til standard out. Og det er da ut i terminalvinduet. Så kan jeg i stedet omdirigere dette til en fil. På denne måten. Da ligger innholdet... Hei, det ligger da i den filen. Hvis jeg gjør dette en gang til, så vil innholdet i filen overskrives. Så hvis jeg ser på filen nå, så ser vi at den er blitt avskrevet. Veldig eksplisitt. Legger inn 'hei 2'. Den legges inn i filen. Men nå, hvis jeg ønsker at 'hei' skal komme i tillegg, så kan jeg legge på to større tegn. I tillegg til det som ligger der fra før. Generelt kan det ofte være nyttig å kunne omdirigere feilmeldinger. Og mens standard out er kanal 1, så er standard error er kanal 2. Så vi kan prøve f.eks. med vilje å skrive ekkohøy feil. For en feilmelding.", "source": "lecture"}
{"lecture_id": "linux3del7", "chunk_id": "linux3del7_0001", "start": 64.54, "end": 179.98, "token_count": 293, "text": "Generelt kan det ofte være nyttig å kunne omdirigere feilmeldinger. Og mens standard out er kanal 1, så er standard error er kanal 2. Så vi kan prøve f.eks. med vilje å skrive ekkohøy feil. For en feilmelding. Så kan jeg tenke meg at jeg ønsker å legge feilmeldingen i en fil. Men det funker ikke helt som man skulle ønske. For det som skjer, er at det bare er Standard1, eller Kanal1, StandardAlt, som sendes til ErdoTekst. Fortsatt ut til sin standard, som er ut til terminalen. For å få sendt selve fernmeldingen... Det man kan gjøre da, er å legge på 212, som betyr send kanal 2 til r.text. Hvis jeg gjør det, så ser vi at da får jeg r.text inne i denne filmen. Så kan det også gå an å sende standard-out til ett sted og standard-error til et annet sted. Og det med følgende konstruksjon... Da kan vi si... At vanlig opphold, standard-out av denne kommandoen, skal til her og tekste. Og eventuelt feil skal til r-da-tekste.", "source": "lecture"}
{"lecture_id": "linux3del7", "chunk_id": "linux3del7_0002", "start": 158.46, "end": 254.48, "token_count": 296, "text": "og standard-error til et annet sted. Og det med følgende konstruksjon... Da kan vi si... At vanlig opphold, standard-out av denne kommandoen, skal til her og tekste. Og eventuelt feil skal til r-da-tekste. Og i dette tilfellet så kom feilnett. Hvis jeg hadde skrevet ekko riktig... Så får jeg ikke noe feil, men da får jeg output til heitvott-teksten. Og denne konstruksjonen er veldig nyttig. Da kan man styre nøyaktig hvor man vil ha feilmeldingene. Har en eller annen kommando, og så ønsker man ikke å ta vare på feilmeldingene... Man vet det kommer en masse feilmeldinger, sånn som i denne her... Så i stedet for å sende ut en fil, så kan man sende det til en device som heter dev.0. Og dev.0 er et slags sort hull. Alt man sender dit, blir bare borte. Men i praksis så betyr det bare glem alt av feilmeldinger. Det skal ikke ses i det hele tatt, og det skal ikke lagres noe sted. En annen måte å utføre den kommandoen som sender denne her...", "source": "lecture"}
{"lecture_id": "linux3del7", "chunk_id": "linux3del7_0003", "start": 231.1, "end": 351.68, "token_count": 291, "text": "Alt man sender dit, blir bare borte. Men i praksis så betyr det bare glem alt av feilmeldinger. Det skal ikke ses i det hele tatt, og det skal ikke lagres noe sted. En annen måte å utføre den kommandoen som sender denne her... Som sender både StandardOut og StandardAut til samme sted... Det er en litt kortere måte. Den her. Den betyr send både kanal 1 og kanal 1. Så her får vi, uansett om den er riktig eller ikke, så får vi... Enten feilmelding eller den riktige output i r.tekstene. Det finnes en annen måte å omdirigere på også. Hvis jeg f.eks.... Jo, hvis jeg tar LS på noe på en mappe som ikke finnes... LS finnes ikke, så... Og så ønsker jeg kanskje den skulle ut hit. Så har vi sett at jeg kan kanalisere... Jeg kan kanalisere error til en annen tid. Men en annen konstruksjon, det er å si... Kanal 2-error, det skal jeg sende til samme sted som 1. På denne måten. Så det betyr... Send error til samme sted som 1.", "source": "lecture"}
{"lecture_id": "linux3del7", "chunk_id": "linux3del7_0004", "start": 325.04, "end": 438.84, "token_count": 295, "text": "Jeg kan kanalisere error til en annen tid. Men en annen konstruksjon, det er å si... Kanal 2-error, det skal jeg sende til samme sted som 1. På denne måten. Så det betyr... Send error til samme sted som 1. Og da vil jeg få feilmeldingene i... Nei, det fikk jeg ikke. For der er det en liten feil i notatene. Denne konstitusjonen er ikke riktig. Vi skal sende to til Å1. Altså Å1 er adressen til 1. Så hvis jeg gjør det på denne måten, den riktige måten, så vil... Feilmeldingene sendes til samme sted som én. Og da får jeg den feilmeldingen ut der. Så kikk på notatene og se hvor er det en liten feil? Nemlig at man bruker denne konsesjonen. Den fungerer ikke. Og én, det er på en måte adressen. Samme adresse som kanal 1. Nyttig å bruke når man ønsker å pipe på feilmeldinger. For eksempel så... Ja, så kan det være... La oss si jeg ønsker å finne...", "source": "lecture"}
{"lecture_id": "linux3del7", "chunk_id": "linux3del7_0005", "start": 403.12, "end": 509.88, "token_count": 292, "text": "Nemlig at man bruker denne konsesjonen. Den fungerer ikke. Og én, det er på en måte adressen. Samme adresse som kanal 1. Nyttig å bruke når man ønsker å pipe på feilmeldinger. For eksempel så... Ja, så kan det være... La oss si jeg ønsker å finne... På denne maskinen... alt som heter noe med passord. Vanligvis når du gjør en sånn kommando, så leter den masse, og så kommer det en haug med 'permission denied'. Da kunne det være greit å peipe vekk de. Da kan man tenke seg at ok, jeg bare... Jeg vil... Grep minus V. Den fjerner alt som har noe med passive D å gjøre. Med 'permission' fra alle de setningene som kom, så var det 'permission denied'. Hvis jeg prøver dette, så ser vi at det funka dårlig. Permission er fortsatt med. Men da fins det igjen en konstruksjon, eller den samme konstruksjonen, så der kan vi legge på den her. Vi sier jeg vil sende to til samme sted som kanal 1. Og kanal 1 blir pipet videre til grep.", "source": "lecture"}
{"lecture_id": "linux3del7", "chunk_id": "linux3del7_0006", "start": 488.08, "end": 583.24, "token_count": 286, "text": "Permission er fortsatt med. Men da fins det igjen en konstruksjon, eller den samme konstruksjonen, så der kan vi legge på den her. Vi sier jeg vil sende to til samme sted som kanal 1. Og kanal 1 blir pipet videre til grep. Og dermed så fungerer det. Da får jeg filtrert bort alle linjer som har permission i seg. Det jeg gjorde, var at jeg la på den konstruksjonen. Før standard 1 sendes til pipen, så sendes alt som da skal til standard R, den sendes til kanalen. Og så vinner det til grepet. En litt lignende konstruksjon kan man bruke iScript. Jeg har lagd et veldig kort script der som heter r.shell. Og det bare skriver ut ekko-error. Vanligvis, hvis man skriver ut ekko-error, så kommer det til standard 1. Men denne konstruksjonen sier at alt som går til standard 1, det skal videresendes. Så da betyr det at dette blir en feilmelding som går ut i kanal 2. Hvis jeg nå kjører dette, så kommer error ut.", "source": "lecture"}
{"lecture_id": "linux3del7", "chunk_id": "linux3del7_0007", "start": 557.78, "end": 636.6, "token_count": 266, "text": "Vanligvis, hvis man skriver ut ekko-error, så kommer det til standard 1. Men denne konstruksjonen sier at alt som går til standard 1, det skal videresendes. Så da betyr det at dette blir en feilmelding som går ut i kanal 2. Hvis jeg nå kjører dette, så kommer error ut. Og det ville det gjort hvis jeg bare hadde echoet der inne. For den både standard in og standard er går til terminal default. Men nå kan jeg si ok, jeg vil ta error fra denne... Fra denne kommandoen å sende til r.exc. Og da ser vi at det funker som det skal. r.exc inneholder nå feilmeldingen fra dette skriftet. Så dette er en måte å eksplisitt sende feilmeldinger til kanal 2 på. Og det gjøres ved den konstruksjonen. Det er ikke så veldig ofte man bruker disse konstruksjonene, men det kan være nytt en gang iblant. Hvis du møter et skript hvor disse er brukt, så er det greit å vite hva de betyr.", "source": "lecture"}
{"lecture_id": "os14del14", "chunk_id": "os14del14_0000", "start": 0.0, "end": 82.12, "token_count": 288, "text": "Først så kjørte jeg den raske versjonen, 0,9 sekunder, som tok matrissen på riktig måte. Da fikk jeg bare én kontekst-witch. Og så var det spørsmål om hvorfor jeg fikk 204 kontekst-witcher her. Og det første man kan si, er at programmet kjører seks ganger så lenge. Så da burde det naturlig være flere kontekst-witcher. Kontekst-witcher skjer når... Man... Når flere prosesser kjører på samme CPU, og her konkurrerer de bl.a. med OBS og med Zoom, og de kjører en masse prosesser, så det vil nok bli noen context switcher en gang iblant. Men så prøvde jeg å kjøre programmet om igjen, og da fikk jeg åtte context switcher og seks context switcher. Så jeg ser at det... Det var nok litt tilfeldig at det ble så veldig mange. Akkurat der. Der ble det tolv. Mens hvis jeg... Kjører du på nytt den raske, så ser vi også at det er noen context sitcher der. Men jeg tror da, som sagt, at det var litt tilfeldig.", "source": "lecture"}
{"lecture_id": "os14del14", "chunk_id": "os14del14_0001", "start": 53.56, "end": 155.5, "token_count": 284, "text": "og seks context switcher. Så jeg ser at det... Det var nok litt tilfeldig at det ble så veldig mange. Akkurat der. Der ble det tolv. Mens hvis jeg... Kjører du på nytt den raske, så ser vi også at det er noen context sitcher der. Men jeg tror da, som sagt, at det var litt tilfeldig. At det ble veldig mange context sitcher. Jeg kjører et par ganger til. Ja, der var det oppe i 95. Men context switcher er jo da noe man ikke kan forutsi. Det vil variere fra gang til gang. Og det vil jo også... Det er jo et poeng at det kan ta lengre tid hvis det er mange context switcher, for da blir cash ødelagt for den... Den prosessen. Så vi kan se om det... Det ser ut som det er noen forskjell på hvor lang tid det tar når det er mange kontekst-switcher. Skal vi se... I det tilfellet overtok her oppe. Du kan kanskje se en antydning. 5,46 sekunder. De kontekst-switchene tar litt ekstra tid. Og ødelegger cash, sånn at det tar litt ekstra tid.", "source": "lecture"}
{"lecture_id": "os14del14", "chunk_id": "os14del14_0002", "start": 132.2, "end": 182.0, "token_count": 202, "text": "når det er mange kontekst-switcher. Skal vi se... I det tilfellet overtok her oppe. Du kan kanskje se en antydning. 5,46 sekunder. De kontekst-switchene tar litt ekstra tid. Og ødelegger cash, sånn at det tar litt ekstra tid. Men i det tilfellet så ødelegger jo programmet cash for seg selv hele tiden. Men alt i alt, som svar på spørsmålet... Det var nok tilfeldig at det var så veldig mange. Antall kontekstvitsjer varierer veldig med hvor mange andre prosesser som kjører. Så det er litt tilfeldig dette inn i bildet. Så jeg tror først og fremst at når en kjører lenger, så er det flere kontekstvitser. Takk for oppmerksomheten.", "source": "lecture"}
{"lecture_id": "os5del5", "chunk_id": "os5del5_0000", "start": 0.0, "end": 100.86, "token_count": 296, "text": "Her har jeg en kode som heter 1-linje. Og det er kode som... som viser én linje i... Én linje i... høynivåkode. Og det som er fokus her, det er at vi skal se at det ikke er en én-til-én-avhengighet. Fra høynivåkode til maskinkode. Så vi kan se på strukturen av dette programmet først, sånn at vi skjønner hvordan det virker. For det første så har vi da en ekstern metode som heter 1-linje. Og dette er min, main, og den kaller da 1-linje. Så igjen så skal vi fokusere på koden i 1-linje. Og se hvordan den ser ut. Og en linje.c. Den ser rett og slett sånn ut. Så... Her ser vi. Det er et veldig enkelt svar som regner ut meningen med livet. Som dere vet er svar på at meningen med livet er 42. Så denne regner ut dette svaret. Og det gjør vi ved å bare sette opp to variabler - svar og memoar. Det er altså en variabel i minnet. Begge to.", "source": "lecture"}
{"lecture_id": "os5del5", "chunk_id": "os5del5_0001", "start": 77.48, "end": 171.8, "token_count": 300, "text": "som regner ut meningen med livet. Som dere vet er svar på at meningen med livet er 42. Så denne regner ut dette svaret. Og det gjør vi ved å bare sette opp to variabler - svar og memoar. Det er altså en variabel i minnet. Begge to. Og så gjør vi én institusjon her, som er svar er lik svar pluss memoar. Og det som er det viktigste med det vi gjør nå, er at...  Én sånn linje i høyneverkode. Denne kan umulig gi en enkel linje i maskinkode. Det er ikke mulig fordi det ikke finnes instruksjoner som gjør en så kompleks operasjon i X86-instruksjonssettet. Alt dette må jo oversettes til X86-instruksjoner som utføres. Grunnen til at dette er viktig, er at når vi senere skal se på sånn som multitreading, Og det å switche ut prosesser... Da skal vi ta en prosess, og så skal vi stoppe den midt i det programmet den gjør, og så skal vi sette i gang andre prosesser på samme CPU. Da er det veldig viktig for operativsystemet å ha kontroll på", "source": "lecture"}
{"lecture_id": "os5del5", "chunk_id": "os5del5_0002", "start": 145.24, "end": 250.56, "token_count": 298, "text": "Og det å switche ut prosesser... Da skal vi ta en prosess, og så skal vi stoppe den midt i det programmet den gjør, og så skal vi sette i gang andre prosesser på samme CPU. Da er det veldig viktig for operativsystemet å ha kontroll på hvilken prosess er det som gjør hva? Hvilken funksjon denne prosessen gjør, osv. Da er det som programmerer, og når vi ser på det selv, er det lett å tenke sånn at... Her har vi det programmet som prosessen kjører, og her utføres det én institusjon, og den er denne linjen. Men i virkeligheten så utfører prosessene ikke høynivåkode, men de utfører maskinkode. Så det vi skal se på nå, er hvordan denne ene linjen med høynivåkode Flere linjer med maskinkode. Og det vi må gjøre da, er... Vi må prøve oss igjen og kompilere den. Og så må vi se hvordan maskinkode GCC lager. Så... Det jeg skal prøve nå, er å be GCC lag maskinkode. Denne C-koden. Og så kan jeg se på den. Ja, igjen så ser vi at...", "source": "lecture"}
{"lecture_id": "os5del5", "chunk_id": "os5del5_0003", "start": 212.66, "end": 341.0, "token_count": 286, "text": "Vi må prøve oss igjen og kompilere den. Og så må vi se hvordan maskinkode GCC lager. Så... Det jeg skal prøve nå, er å be GCC lag maskinkode. Denne C-koden. Og så kan jeg se på den. Ja, igjen så ser vi at... Her brukes da hele tiden referanser til minnet. Sånn som den første linjen her. Legg 32 i... på denne. Og 32, det var den første. Så legger vi ut den. Og så ser vi at denne verdien, altså det titallet, det legges i IX. Og så gjøres den adlong, verdien i IX. Den har vært ti. Den verdien som lå i variabelen... Skal vi se... Hva var det vi kalte den variabelen? Svar. Så opplegget er nå... Kompilatoren bestemmer seg for at denne adressen... Denne adressen, her skal variabelens svar ligge. Minus åtte bite fra toppen av området ram. Der skal variabelen svar ligge. Og menvar, den skal ligge fire bite fra toppen. Så de får nå hver sin plass i ram.", "source": "lecture"}
{"lecture_id": "os5del5", "chunk_id": "os5del5_0004", "start": 320.76, "end": 407.84, "token_count": 287, "text": "Denne adressen, her skal variabelens svar ligge. Minus åtte bite fra toppen av området ram. Der skal variabelen svar ligge. Og menvar, den skal ligge fire bite fra toppen. Så de får nå hver sin plass i ram. Og så ser vi... Der legges tallet 10 i eax med movel. Og så ser vi man adel... Altså legg til eax til variabelen svar. Svaret 42 ligger her i RAM. Programmet flytter nå svar inn til EAX. Hvorfor gjør det det? Jo, det er fordi når du returnerer en metode, en funksjon, en C-funksjon, så forventes det av C at svaret, returverdien, ligger i EAX. Dermed oppfører rutinen seg som den skal. Her ser vi... Jo, her... Her er den linjen som i høynivåkode var én linje. Den er da oversatt til tre linjer av kompulatoren. Man vet ikke hva kompulatoren gjør. Vanligvis vet man ikke det. Så man må alltid regne med at kompulatoren kan dele det opp i flere linjer.", "source": "lecture"}
{"lecture_id": "os5del5", "chunk_id": "os5del5_0005", "start": 385.24, "end": 468.32, "token_count": 300, "text": "Her er den linjen som i høynivåkode var én linje. Den er da oversatt til tre linjer av kompulatoren. Man vet ikke hva kompulatoren gjør. Vanligvis vet man ikke det. Så man må alltid regne med at kompulatoren kan dele det opp i flere linjer. Når vi senere skal drive med multitasking, kan ikke operativsystemet vite Den switcher. Eller det vil si... Operativsømme vet når når det switcher fra en prosess til en annen. For nå kan vi tenke oss at denne prosessen står og kjører, og så kommer det kanskje en annen prosess, som er en webserver, som skal gjøre noe helt annet. Men denne prosessen som står her og kjører, den må stoppes her og fryses. Og så må den etterpå gjøre neste operasjon. Det kan være avgjørende for om programmet virker som det skal. Vi skriver til og fra minne, og da kan det være andre programmer som bruker den samme variabelen med minne. Og da kan de bli sure, hvis ikke de gjør det i riktig rekkefølge. Dermed er det veldig viktig at én sånn institusjon kan føre til", "source": "lecture"}
{"lecture_id": "os5del5", "chunk_id": "os5del5_0006", "start": 450.78, "end": 552.84, "token_count": 293, "text": "Vi skriver til og fra minne, og da kan det være andre programmer som bruker den samme variabelen med minne. Og da kan de bli sure, hvis ikke de gjør det i riktig rekkefølge. Dermed er det veldig viktig at én sånn institusjon kan føre til flere institusjoner i maskinkoden som virkelig kjøres. Som jeg er nødt til å være klar over og forholde seg til. Generelt kan man ikke vite hvordan det fungerer, men kan man på en måte tvinge Jesus og Jeg til å bare lage én linje? Og i dette tilfellet så kan man ikke det heller. Man kan ikke det heller fordi... Som jeg har sagt tidligere, så er ikke det mulig å ha en sånn operasjon. Men vi kan se hva... Vi kan spørre GCC. Hvis du skal lage raskest mulig kode av denne funksjonen her, hvordan vil den se ut? Da ber vi om det, og så ser vi på den. Ja... Da får vi det samme problemet igjen. Vi får på en måte ikke se den koden, fordi at her så ser vi... Uansett hva vi måtte finne på her, så får vi flytte det opp.", "source": "lecture"}
{"lecture_id": "os5del5", "chunk_id": "os5del5_0007", "start": 520.76, "end": 574.98, "token_count": 114, "text": "Da ber vi om det, og så ser vi på den. Ja... Da får vi det samme problemet igjen. Vi får på en måte ikke se den koden, fordi at her så ser vi... Uansett hva vi måtte finne på her, så får vi flytte det opp. Så det er en gøy liten start der, og jeg liker det. Men... Men generelt så... Vil det være umulig å lage en kodelinje som adrerer sammen to tall?", "source": "lecture"}
