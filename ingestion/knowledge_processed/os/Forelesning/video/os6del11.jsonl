{"lecture_id": "os6del11", "chunk_id": "os6del11_0000", "start": 0.0, "end": 209.86, "token_count": 589, "text": "Ok. Det var en liten gjennomgang av Linux-historie. Nå skal vi gå inn på et helt nytt tema, nemlig multitasking. Aller først skal vi for tredje gang se på CPU-løkken. Det er dette vi må ha med videre. Og om og om igjen kjører instruksjoner. Det vi skal se litt nærmere på nå, er interrupt request. For en gang iblant så kan det komme et fysisk interrupt-orkest. F.eks. ved at jeg taster på tastaturet sånn. Maskinen må da reagere på den inntastingen veldig hurtig. Og det som da skjer, er at... Den avbrytes i sin evige løkke, og så håndterer den det signalet. Ofte brukes det pund noen mikrosekunder på å fullføre det den er i gang med. Og så hopper den til en interrupt rutine, som da sørger for at den piltasten som jeg trykket på, at den har en effekt. Den må avbrytes for å håndtere signalet. Da må man lagre adressen til neste institusjon, og så hoppe til en interrupt-rutine. Det blir litt som å gjøre et kall på en rutine, men her er det en fysisk interrupt som sendes inn, og så gjøres det kall på rutinen. Hvert interrupt eller IRQ har sin egen rutine som man da hopper til. Noe fra tastaturet, en annen hvis det kommer fra nettverket, en tredje hvis det kommer fra mikrofonen, osv. Vi skal se på multitasking. For å forstå multitasking er det viktig å vite hvordan minne eller ramm er koblet sammen med prosesser. Vi skal fokusere på ramm direkte, og da skal vi se mer på dette. Men det vi trenger å vite nå, er at det finnes flere deler i ramm som er tildelt en prosess. Dette som vi viser bildet her nå, det er én bit av ramm som er tilordnet én prosess. Operativsystemet er også en egen prosess. Den viktigste biten er kanskje koden eller teksten, som vi ser her nede. Unnskyld. Koden, det er da maskininstruksjonene som prosessen skal kjøre. Som ligger etter hverandre. Institusjon for institusjon. Det typiske som skjer når en prosess kjører, er at man starter på første institusjon til prosessen.", "source": "lecture"}
{"lecture_id": "os6del11", "chunk_id": "os6del11_0001", "start": 166.72, "end": 382.64, "token_count": 578, "text": "Dette som vi viser bildet her nå, det er én bit av ramm som er tilordnet én prosess. Operativsystemet er også en egen prosess. Den viktigste biten er kanskje koden eller teksten, som vi ser her nede. Unnskyld. Koden, det er da maskininstruksjonene som prosessen skal kjøre. Som ligger etter hverandre. Institusjon for institusjon. Det typiske som skjer når en prosess kjører, er at man starter på første institusjon til prosessen. Så er det gjerne en loop her, så den hopper opp og ned. Men så har vi sett at vi hele tiden har variabler i programmet, som brukes og skrives til ram. Og da i heapen, som går fra koden her og oppover, er det satt av masse plass til heapen, sånn at den kan utvide seg. For her kan man dynamisk legge inn nye variabler. De legges da på heapen. Stacken, det er et område hvor lokale variabler legges. F.eks. hvis du gjør et funksjonskall, så legger du på stacken returverdien fra det funksjonskallet, så man vet hvor man skal tilbake. Da er det enkelt å bare gå inn der. Så plukker du opp... I tillegg er det vanlig å ha en MM-mapp, som er en avbildning av filer og deviser inn i ramm. Men dette er igjen for at ting skal gå fortere. Så er det en kopi av noe av det som ligger på disk, sånn at man skal ha raskere aksess. Og Jeep, det er det vi snakker om. Her ligger alle variabler. Og her ligger instruksjonene. Tidligere så var det dette som var måten datamaskiner kjørte på. Man hadde bare... Man kjørte bare én oppgave av gangen. Så enten var det brukerprogram som kjørte, eller OS. Og da ser vi for... Selv om det var singeltasking, betyr det at det da er bare én prosess som kan kjøre av gangen. Det typiske som skjedde når man kjørte singeltasking OS, var at operativsystemet startet opp først. Og så hadde man da ett brukerprogram. Og når dette skulle kjøre, så satte OS i gang brukerprogrammet og kjøre.", "source": "lecture"}
{"lecture_id": "os6del11", "chunk_id": "os6del11_0002", "start": 330.0, "end": 551.88, "token_count": 581, "text": "Man kjørte bare én oppgave av gangen. Så enten var det brukerprogram som kjørte, eller OS. Og da ser vi for... Selv om det var singeltasking, betyr det at det da er bare én prosess som kan kjøre av gangen. Det typiske som skjedde når man kjørte singeltasking OS, var at operativsystemet startet opp først. Og så hadde man da ett brukerprogram. Og når dette skulle kjøre, så satte OS i gang brukerprogrammet og kjøre. Og så hadde da Device-minne, Skjerm-minne osv. brukerdata eller Heap. Alle disse bitene hadde det. Men det var da bare én prosess som kunne kjøre av gangen. En sånn batch computing... Du hadde kanskje en rein operasjon som kunne ta en halvtime. Og da satte operativstemmet i gang denne operasjonen. Og så kjørte den til den var ferdig, og så kunne neste program starte. Men alle moderne systemer har mulighet... Det er et system som kan få et antall programmer til å kjøre samtidig. Så her har vi et operativsystem som har to prosesser som kjører samtidig. Måten operativsystemet får til det på, det er at den deler opp tiden. Altså gir den litt tid til hver prosess, sånn at det ser ut som de kjører samtidig. Egentlig kjører de hand i gang, men for prosessene ser det ut som de kjører samtidig, og det er rett og slett multitasking. Men vi ser at hver prosess vil ha sitt eget område med heap og stack og program eller tekst eller kode, og også IO-områder. Altså for å snakke med disk, ta imot fra tastatur osv. Og multitasking, det er da det systemet som operativsystemet bruker for å kjøre prosesser samtidig. Hovedideen her er at CPU-tiden blir delt opp. Typisk størrelse på en liten bit av tiden man kan kjøre, er et hundredels sekund. Da har man en såkalt round robin-kø, og så har man en hardware-timer. Skal se på dette i detalj. Hvert hundredels sekund så sender et interrupt-signal til SIPPU. Så starter man opp den første... Den legges da i institusjonsregisteret. Og så lar OUS hver prosess etter tur brukes i PUN.", "source": "lecture"}
{"lecture_id": "os6del11", "chunk_id": "os6del11_0003", "start": 497.96, "end": 557.8, "token_count": 144, "text": "Hovedideen her er at CPU-tiden blir delt opp. Typisk størrelse på en liten bit av tiden man kan kjøre, er et hundredels sekund. Da har man en såkalt round robin-kø, og så har man en hardware-timer. Skal se på dette i detalj. Hvert hundredels sekund så sender et interrupt-signal til SIPPU. Så starter man opp den første... Den legges da i institusjonsregisteret. Og så lar OUS hver prosess etter tur brukes i PUN. Så CPU-en går da på rundgang mellom alle prosesser som ønsker å kjøpe.", "source": "lecture"}
