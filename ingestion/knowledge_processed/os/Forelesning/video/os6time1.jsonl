{"lecture_id": "os6time1", "chunk_id": "os6time1_0000", "start": 0.0, "end": 190.24, "token_count": 584, "text": "Ja, før vi starter i dag, så er det noen praktiske ting som vi skal se på først. Ja. Brunch Prediction, det er det vi skal holde på med i dag. Men aller først til oversikten over kurset. Da er vi kommet. Vi er nå i uke seks. Det er et par ting som er nytt her. Først og fremst er det MC1. Som er da en obligatorisk multiple choice-test. Det har tatt litt tid å få ut den også, fordi det har vært problemer med SSH-innlogging på studentserverne. Ikke StudioSSH, men en annen server. Så... Men det er relaterte problemer. Så hvis det skulle være noen problemer med innlogging, så si ifra med en gang. Det har vært litt problemer tidligere, men jeg håper det fungerer som det skal nå. Det er delvis av historiske årsaker at vi har dette multipurpose-systemet, men jeg har bygd opp en svær database med spørsmål der. Og også mot slutten så skal vi ha en... Så er det en World of Operating Systems. Som er en slags konkurranse hvor man kan oppnå levels ved å svare på i dette systemet. Men uansett... Så tidlig som mulig, gå gjennom og gjør denne flervalgstesten. Først og fremst så er det en tilbakemelding på hvor dere sår, hva dere har fått med dere av pensum. I tillegg kan det være ganske nyttig fram til eksamen, for vanligvis så dukker det opp noen spørsmål fra disse full price-spørsmålene. Noen ganger helt de samme, andre ganger en variant som ligner. Oppgavene er fra kursets fire uker. Den første oblingen er det mest om Linux og verskommandoer. Du må svare på minst syv av ti riktige spørsmål. Du må ha syv av ti riktige. Og så kan du være litt uheldig med spørsmålene. Noen er vanskeligere enn andre. Men ikke for tidlig hvis du ikke får det til. Da er tanken at du skal ta kontakt med en student og sånt. Og nå, typisk, så må du da gå inn i et break-off-room hvis du er på en lab-dag. Bruk labdagen til å gå inn i breakover-room, snakke med studentassistent, og se på spørsmålene. Så gir studentene deres mulighet til å få en ny sjanse.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0001", "start": 156.32, "end": 340.28, "token_count": 591, "text": "Noen er vanskeligere enn andre. Men ikke for tidlig hvis du ikke får det til. Da er tanken at du skal ta kontakt med en student og sånt. Og nå, typisk, så må du da gå inn i et break-off-room hvis du er på en lab-dag. Bruk labdagen til å gå inn i breakover-room, snakke med studentassistent, og se på spørsmålene. Så gir studentene deres mulighet til å få en ny sjanse. Ja, så i tillegg... Det var noe annet fornuftig jeg skulle si om disse testene. Jo, dere får nye sjanser. Men det er viktig å... Gjør de så snart som mulig, sånn at dere får tid til å få nye sjanser. Hvis det er én type spørsmål dere bommer på, så er det kanskje fornøyd å jobbe litt mer med oppgavene rundt de. Så kan dere, før dere begynner på de nye sjansene... Ok, det var multiple choice. Var det noe annet... Ja, Oblique 2 står og lyser her nede i det fjerne. Det er ikke så lenge til. Den har da frist... skal vi se... fredag 5. mars. Så det er en stund til, men alle oppgavene til Oblikk 2 ligger nå ute. Så Oblikk 2 består av fem-, seks- og syvoppgavene herfra. Så vil det da etter påske komme en Oblikk 3 med oppgaver fra de fire. Sånn er det standardopplegget. En annen ting... Oppgavene denne uken, de har ligget ute en uke. Men disse, oppgavene til neste uke, som er uke syv... Det er da de siste som inneholder obligoppgaver. Men temaet derfra har vi ikke snakket om ennå. Det snakker vi delvis om i neste uke og delvis denne uken. Og her står det Linux-VM-er. Så det er nyttig og viktig i dag. Så jeg skal bruke litt tid helt til starten å se på de Linux-VM-ene, sånn at dere kan komme i gang med dem. Jeg har kanskje merket at dere har fått en annonsement i OS-gruppene. Der står det et passord. Det står ikke så mye annet. Men det er det passordet dere trenger for å kunne bruke Linux-VM-ene.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0002", "start": 300.86, "end": 466.68, "token_count": 582, "text": "Det snakker vi delvis om i neste uke og delvis denne uken. Og her står det Linux-VM-er. Så det er nyttig og viktig i dag. Så jeg skal bruke litt tid helt til starten å se på de Linux-VM-ene, sånn at dere kan komme i gang med dem. Jeg har kanskje merket at dere har fått en annonsement i OS-gruppene. Der står det et passord. Det står ikke så mye annet. Men det er det passordet dere trenger for å kunne bruke Linux-VM-ene. Mer om dette står øverst i uke seks. Her står det litt om multiple-soice-testen. Og så står det her om Linux-VM-ene. Jeg kaller det Linux-VM-er. Virtuelle maskiner. Egentlig er det faktisk dokkecontainere, men det er på en måte halvveis virtuelle maskiner. Fordi de dokkecontainerne bruker et opplegg som heter Sysbox, som er et slags system som isolerer dokkecontainerne i større grad. Vi kommer tilbake til dokkecontainerne senere i kurset, og da skal dere kjøre dokkekonteinere og starte og stoppe og bygge osv.. Vi skal snakke mer om hvordan det henger sammen, men sånn foreløpig så... Eller generelt så er et problem med dokkecontainere at de kjører direkte på operativstemme og har tilgang til operativstemme på serveren som de kjører. I motsetning til virtuelle maskiner. Men disse dokkecontainerne som kjører Sysbox, de er containet enda sterkere. Altså de er isolert mer fra serveren under. Så... Dermed får man en look and feel som om det var en virtuell maskin. Sånn som StudySSO. StudySSO er en ekte virtuell maskin som kjører KVM, og som kjører på en fysisk server. Og de tingene her er det litt viktig å ha med i... Skal vi se... Er det denne ukens oppgaver? Hvor det er... Jo, det er i denne ukens oppgaver hvor dere skal kjøre... Kjøre mange prosesser på samme VM eller på Studio SSO for å se hvordan disse serverne tildeler CPU-er... Eller operativsystemet tildeler CPU-er til prosessene. Skredulerer. Og det skal vi snakke masse om.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0003", "start": 427.16, "end": 631.36, "token_count": 594, "text": "som kjører KVM, og som kjører på en fysisk server. Og de tingene her er det litt viktig å ha med i... Skal vi se... Er det denne ukens oppgaver? Hvor det er... Jo, det er i denne ukens oppgaver hvor dere skal kjøre... Kjøre mange prosesser på samme VM eller på Studio SSO for å se hvordan disse serverne tildeler CPU-er... Eller operativsystemet tildeler CPU-er til prosessene. Skredulerer. Og det skal vi snakke masse om. Men aller først så skal vi se litt i praksis på disse Linux-VM-ene. at for å få tilgang til en Linux-VM, så må dere være i en OS-gruppe. Hvis dere f.eks. er i OS-gruppe 13, så kan dere da logge dere inn med SSO. På tilsvarende måte som dere gjør til Study SSO, med Putty eller på andre måter med et skjell fra Mac Linux. Eller fra en Linux-laptop. Eller fra Study SSO, hvis dere er der inne. OS13 er da hosten. Det er navnet på VM-en. Og Group 13 er brukernavnet. Så jeg kan ta og se på hvordan det ser ut i praksis. Hvis jeg nå går til riktig vindu i... Skal vi se... Litt mange under her. Her har jeg et vindu i Studio SSO. Så kan vi tenke oss at dere enten er i Studio SSO, eller at dere logger direkte inn med putt-id. Begge deler går. Det skal gå an å logge seg inn hjemmefra også. Denne her er ikke innenfor Dere må ikke bruke... Hva heter det... VPN. Dere må ikke bruke Oslo-mette-VPN for å komme inn til disse. Så jeg har tatt en gruppe som er nummer 100. Så jeg må da logge meg på som group 100. Dere må gjerne prøve dette her nå. Passordet dere skal ha for group 100, eller group 13, På OS-gruppen. Så hvis dere er OS100... Hvis dere var OS100, så vil dere gå inn i den gruppen og se på en navnsvenn som ligger der. Da kan dere plukke ut passordet. Dette er felles for alle som er på gruppen. Og så er urlenvelab.cs.joa.no... Tror ikke OsloMet funker, men Joa skal funke. Så må dere skrive passordet som dere har fått.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0004", "start": 591.26, "end": 816.46, "token_count": 582, "text": "Passordet dere skal ha for group 100, eller group 13, På OS-gruppen. Så hvis dere er OS100... Hvis dere var OS100, så vil dere gå inn i den gruppen og se på en navnsvenn som ligger der. Da kan dere plukke ut passordet. Dette er felles for alle som er på gruppen. Og så er urlenvelab.cs.joa.no... Tror ikke OsloMet funker, men Joa skal funke. Så må dere skrive passordet som dere har fått. Se om jeg husker passordet jeg har fått... ja. Og da kommer dere inn på VM-en. Og da er det plutselig et Linux-shell på samme måte som... Ja, ligner veldig på Studies også. Det kjører... Det er en helt ny versjon av Umuntu. Mulig den er nyere enn den på StudeSOS. Og her kan dere da gjøre alt mulig som dere har gjort hittil på StudieSOS, men dere kan da gjøre enda mer. Og det er det viktig å være klar over. Her er dere... Dere har RUT-aksess, så dere kan gjøre Sudo-SU. Og så skrive passordet på nytt. Da ser du... Vips, så er det RUT på systemet. Og da kan dere gjøre alt dere måtte ønske. For eksempel å installere. Kjøre AppGetUpdate før dere installerer. Så kan dere installere hva som helst som dere... Eller som dere trenger i oppgavene. Tvert i oppgavene kommer det noen instruksjoner om å installere screen og Kron og en del forskjellig annet. Det er også en oppgave... Er det denne uken eller kanskje neste uke? Hvor dere blir bedt om å installere en webserver. Og det... Jeg tror jeg har gjort det allerede her, så vi kan kikke på det. Hvis jeg... Skal vi se... Hvis jeg skriver inn nå OS100 her... Dere kan endre på å styre som dere vil. Legg merke til at dette er jo en... Dette er nå en public IP. Så ifconfig... Oi, nå må jeg tilbake. Nå er jeg inne på OS100 igjen. Ifconfig viser... Info om nettet. Og her ser vi at dette er en public IP. Hvis du er OS1, så har du public ippe 13120.101 og 102 for OS2 osv.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0005", "start": 746.36, "end": 978.52, "token_count": 576, "text": "Skal vi se... Hvis jeg skriver inn nå OS100 her... Dere kan endre på å styre som dere vil. Legg merke til at dette er jo en... Dette er nå en public IP. Så ifconfig... Oi, nå må jeg tilbake. Nå er jeg inne på OS100 igjen. Ifconfig viser... Info om nettet. Og her ser vi at dette er en public IP. Hvis du er OS1, så har du public ippe 13120.101 og 102 for OS2 osv. Og det er veldig viktig å være klar over at denne ippen her, den nås av alle. Sånn at her er det helt tiden folk som prøver å... Prøver å logge seg på. Vi kan se om... Den kjører autodelog... Det kan vi se på senere. Men uansett... Alle har tilgang herfra, og det vil foregå hele tiden en del... Eller - SSH-skanning foregår det hele tiden. Dvs. at man prøver å logge seg på og gjette passordet til... Så det betyr at hvis du lager en konto med brukernavn test og passordtest, ikke gjør det, for da vil veldig snart noen hacke seg inn, ta over maskinen din, VM-en din, og kanskje knytte den opp til et botnett. Og ikke minst når den begynner å skanne utover, og da får vi masse problemer med Uninett og gud vet hva. Veldig forsiktig med brukernavn og passord. Neste uke er det en oppgave hvor dere skal lage et brukernavn. Eller dere skal lage tilsvarende brukernavn som dere har på studio SSO, og sette passord. Det hjelper veldig å ha sære brukernavn som S123456. Men sett også et godt passord. Og for all del, ikke bruk brukernavn som Linux eller Rubunto Da er det straks noen... i hvert fall i Bayani i løpet av timer noen som kommer inn og tar over IP-en. Så vær generelt obs, for den vemen er ute i den store verden og har veldig lite beskyttelse. Ok... Noen spørsmål til disse vemene? Nei... Men prøv det ut. Si gjerne fra i chatten eller i pausen hvis dere ikke får ting til å funke. Vi skal se på det på laben i dag også. Ja, så test det ut.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0006", "start": 926.36, "end": 1146.98, "token_count": 600, "text": "Da er det straks noen... i hvert fall i Bayani i løpet av timer noen som kommer inn og tar over IP-en. Så vær generelt obs, for den vemen er ute i den store verden og har veldig lite beskyttelse. Ok... Noen spørsmål til disse vemene? Nei... Men prøv det ut. Si gjerne fra i chatten eller i pausen hvis dere ikke får ting til å funke. Vi skal se på det på laben i dag også. Ja, så test det ut. Ja... Det er et spørsmål om det er... at det ikke er noen OS-grupper nå, ja. Jo, det er sant... Alle OS-gruppene fram til OS8 ble fulgt opp. Men nå har jeg lagd noen ekstra OS-grupper. Det er i hvert fall 16 til opp til OS96. Så hvis du ikke er med i en OS-gruppe, f.eks. hvis du ikke leverer obliger, tar faget om igjen, så meld deg da inn i en OS-gruppe, en av de ledige. Bruk VM-en som er tilordnet deg. Alle de 96 første har allerede fått en VM. Dette er et helt nytt eksperiment. I fjor hadde vi virtuelle maskiner og noen fysiske servere, men de serverne begynte å bli gamle og begynte å knekke. Derfor har vi en ny server. Og så har jeg bygd dette opplegget som er helt nytt. Vi har ikke testet det live. Så vær obs på at ting kan gå galt, og si gjerne fra. Men vi håper det fungerer som det skal. Ok, da... tror jeg har fått med meg det meste av det praktiske. Så da skal vi hoppe til... Dagens tema... Og i dag så skal vi snakke om branch prediction. Vi skal fortsette litt der vi slapp sist, men først og fremst skal vi se på multitasking. Først skal vi ha en generell innføring om multitasking, hva det er, og hvordan det teoretisk sett fungerer. Og til slutt i dag så skal vi se på multitasking på forskjellige servere Dette med multitasking skal vi fortsette med i neste uke, og se på en del forskjellige praktiske problemer og løsninger relatert til multitasking. Aller først lite gram om hva vi holdt på med sist. En linje høynivåkode kan gi mange linjer assembly- eller maskinkode. Det trenger vi nå når vi i dag skal begynne med multitasking.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0007", "start": 1095.16, "end": 1304.68, "token_count": 584, "text": "hva det er, og hvordan det teoretisk sett fungerer. Og til slutt i dag så skal vi se på multitasking på forskjellige servere Dette med multitasking skal vi fortsette med i neste uke, og se på en del forskjellige praktiske problemer og løsninger relatert til multitasking. Aller først lite gram om hva vi holdt på med sist. En linje høynivåkode kan gi mange linjer assembly- eller maskinkode. Det trenger vi nå når vi i dag skal begynne med multitasking. For da må vi multitaske mellom kodelinjer fra forskjellige prosesser. Generelt er kompilering av høynivåkode til maskinkode en veldig komplisert prosess. Det er vanskelig å skrive en kompulator som kan kompilere alle... Derimot er kompulering av assembler til maskinkode veldig rett frem. Det er bare linje for linje å oversette. Så alle kan skrive en assembler, men ikke alle kan skrive en kompulator. I hvert fall ikke uten videre. Det tar et halvt år. I tillegg så vi på sist at én enkelt assemblerinstitusjon, én maskininstitusjon, er delt opp i mikrooperasjoner. Det gjøres faktisk parallelt i pipelines. Og det er akkurat det vi skal se litt på i dag. Aller først... Branch prediction. Og branch prediction er en slags konsekvens av... Av det vi så på forrige gang, at vi bruker for det første... Pipelining er at man deler én institusjon. Da tenker vi på en institusjon som ADD-AX til svar. Altså legge til verdien i registeret AX til svar i ram. Denne operasjonen, i maskinkode, så er det én maskininstitusjon. Men denne deles opp i mange mikroinstruksjoner. Først hentes den inn, så deles den opp i små deler og utføres. For det er flere ting som skal gjøres. Man må hente inn verdien fra RAM inn i et temporært register. Så må man legge til, og så må det resultatet legges ut igjen. Vi må på et eller annet tidspunkt ta verdien i et register og legge ut en ramm. Alt dette brytes ned i mange små mikrooperasjoner. Som tippes for Intel kan det være 14 sånne operasjoner.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0008", "start": 1261.2, "end": 1442.44, "token_count": 585, "text": "Først hentes den inn, så deles den opp i små deler og utføres. For det er flere ting som skal gjøres. Man må hente inn verdien fra RAM inn i et temporært register. Så må man legge til, og så må det resultatet legges ut igjen. Vi må på et eller annet tidspunkt ta verdien i et register og legge ut en ramm. Alt dette brytes ned i mange små mikrooperasjoner. Som tippes for Intel kan det være 14 sånne operasjoner. Pipelining er at vi, når vi starter på en institusjon som har 14 deler, så venter vi ikke med å få gjort alle de 14 delene ferdig. Vi begynner på. Med en gang den første instruksjonen er gjort, så begynner vi på første instruksjon for den instruksjonen som kommer etter i pipelinen. Sånn at i praksis så kjøres ting delvis parallelt. I tillegg så har man superskalærarkitektur. Faktisk virkelig går parallelt. Og da kan det være flere samtidige institusjoner som kommer i en pipeline delt opp i 14 biter. Men så vil da hver av de små bitene, de kan kjøres helt samtidig. Altså institusjonen som er fem institusjoner etter den første, den kan kjøres samtidig. Og dette går veldig fint hvis institusjonene er avhengige. ... uavhengig av hverandre. Hvis det ikke er direkte sammenheng. Men i noen tilfeller er det en sammenheng. Det viktigste tilfellet er en if-test, som du har i Fawlucker og Viole og hele tiden. Hele tiden har man branching. Typiskvis av en if-test, så er det en branch. Hvis svaret er true, så går det den ene veien. Hvis det er få, så går det den andre veien. Det vet man ikke før man kommer dit. Det blir da plutselig et problem med en sånn bransjing når systemet allerede er i gang med å utføre neste institusjon. Det største problemet er at man kunne løst det ved å... Hvis man kom til branch, så bare stoppet man helt. Pipelining og superskalærere... Altså å kjøre mikroinstitusjoner. I reell parallellitet. Med parallellitet. Altså kjører de helt samtidig.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0009", "start": 1404.1, "end": 1623.8, "token_count": 590, "text": "Det vet man ikke før man kommer dit. Det blir da plutselig et problem med en sånn bransjing når systemet allerede er i gang med å utføre neste institusjon. Det største problemet er at man kunne løst det ved å... Hvis man kom til branch, så bare stoppet man helt. Pipelining og superskalærere... Altså å kjøre mikroinstitusjoner. I reell parallellitet. Med parallellitet. Altså kjører de helt samtidig. Man kunne skru det helt av. Men da ville ting gå mye saktere. Så det man prøver på da, er å gjette. Man gjetter hvilken bransje som skal kjøres, og så bare sier man sånn... Tidligere så har det ofte... Har disse testene blitt true? Så hiver man alle institusjonene i den bransjen som om den testen skulle slå til. Hvis da testen ikke slår til, og man har gjettet feil, hva skjer da? Jo, det er ikke katastrofe, for da må man rett og slett bare glemme hva som skjedde, og hoppe tilbake. Og så må man kjøre opp. Om igjen den andre bransjen. Det er klart, dette gir en masse ekstra logikk og overhead å få til dette her. Men igjen - alt er gjort for at ting skal gå raskere. Vi skal se på det i praksis, men vi kan ta med ett eksempel som gjorde at dette med pipeline i bransjen Og ikke minst parallellitet i mikroinstruksjoner, altså superskalærarkitektur, som alle moderne CPU-er etter 2000 har. Det var Melton og Specter som var to sikkerhetshull som ble funnet i 2018. Det var noe så spesielt som et hardware-sikkerhetshull. Og Meltov utnyttet nettopp dette her, at kode blir utført i parallell. Så... Men det var virkelig et hack. Men det utnyttet det at når man kommer til en bransje, så går man inn og... Og man kan også gjøre tester, f.eks.: Er det lov å lese data fra den andre prosessen? Dette systemet fungerer helt fint hvis systemet er sikkert på at CPU utfører én og én institusjon. Men med parallellitet... Med pipelining og med at institusjoner faktisk utføres i parallell.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0010", "start": 1572.4, "end": 1796.32, "token_count": 594, "text": "Så... Men det var virkelig et hack. Men det utnyttet det at når man kommer til en bransje, så går man inn og... Og man kan også gjøre tester, f.eks.: Er det lov å lese data fra den andre prosessen? Dette systemet fungerer helt fint hvis systemet er sikkert på at CPU utfører én og én institusjon. Men med parallellitet... Med pipelining og med at institusjoner faktisk utføres i parallell. Så begynner man noen ganger å utføre en institusjon som å sjekke om man har lov til å lese ram, samtidig som en annen prosess legger noen av sine data i ram. Og det dette sikkerhetsrullet utnyttet, var at en prosess da kunne ved en feil lese ram for en annen prosess. F.eks. kunne det brukes til at en prosess kunne lese passord som en annen prosess skrev inn. Det som var spesielt, var at dette brukte de hardware-effektene. Sånn at for å rette opp i denne feilen, så måtte både CPU-ene endres for å sikre seg mot denne feilen, og operativsystemet. Det er nyttig å vite litt om hva som foregår enda lenger ned. Stort sett når det gjelder sikkerhetssøl, så skjer det på operativsystemnivå. Altså med kode. Men i dette tilfellet så skjedde det altså med hardware. Vi skal nå se på et konkret eksempel på dette med branch prediction. En kode som... ser ganske vanlig ut, men som har en veldig spesiell oppførsel. Og det er et C++-program. Vi kan ta det først. Vi ser det heter b.cpp. Og det er et C++-program. Det kopieres da ikke med GCC, men med B.cpp på den måten her. Det kjøres med.a.. akkurat som for GCC. Så veldig forskjellig er det ikke. Men... Dette kunne også vært kjørt i C, men jeg gjør det i C++. Det er litt enklere å operere med Array. Så et C++-program ligner veldig på C. Den store forskjellen på C++ og C er at C++ er objektorientert, mens C ikke er objektorientert. Men det er ikke det som er fokus her. Fokus her er dette litt enkle, ikke så veldig smarte programmet, men det er lagd for å...", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0011", "start": 1743.6, "end": 1945.28, "token_count": 598, "text": "Det kjøres med.a.. akkurat som for GCC. Så veldig forskjellig er det ikke. Men... Dette kunne også vært kjørt i C, men jeg gjør det i C++. Det er litt enklere å operere med Array. Så et C++-program ligner veldig på C. Den store forskjellen på C++ og C er at C++ er objektorientert, mens C ikke er objektorientert. Men det er ikke det som er fokus her. Fokus her er dette litt enkle, ikke så veldig smarte programmet, men det er lagd for å... Illustrere dette med branch prediction. Og... Det er et ganske enkelt program. Vi ser vi har et stort ra som har 32 000 elementer. Ra-sizen er her. Man deklarerer dette som et ra med 32 768 elementer. Og så er det i første omgang bare... En enkel forløkker som initialiserer alle disse 32 000 r-elementene. Variabelen c løper gjennom alle tall opp til 32 000. Og så er det kode her... Her står det RAND. Det er en funksjon som trekker ut et tilfeldig tall. Og så ser vi at det prosent, det er... Det er en heltallsdivisjon. Så... Og den prosent, den gir da resten. Sånn at... Det eneste du trenger å vite, er at resultatet av denne her, det er et tilfeldig tall mellom 0 og 255. Det er da resten. Hvis du tar et tall og deler på 256, så får du... Så går det opp. Du får rest 0, eller så får du 1 i rest. Da blir tallet 1, eller så får du helt opp til 255 i rest. Hvis tallet er ett større, så går det opp igjen. Så rad gir et tilfeldig svært heltall. Og dette gir da tilfeldige tall mellom 0 og 255. Så det er utgangspunktet. Vi har et sånt r-ei. Så går vi litt lenger ned i programmet, så ser vi liksom... Hovedprogrammet hva det utfører. Og det er her som det skjer rare ting. For det første så skriver vi bare ut de ti første verdiene for å se om R-øyet er sortert eller ikke. I utgangspunktet er det ikke sortert, men etterpå skal vi skru på sortering. Og det er da rare ting skjer. Så det dette litt naive programmet gjør,", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0012", "start": 1907.72, "end": 2086.44, "token_count": 594, "text": "Så det er utgangspunktet. Vi har et sånt r-ei. Så går vi litt lenger ned i programmet, så ser vi liksom... Hovedprogrammet hva det utfører. Og det er her som det skjer rare ting. For det første så skriver vi bare ut de ti første verdiene for å se om R-øyet er sortert eller ikke. I utgangspunktet er det ikke sortert, men etterpå skal vi skru på sortering. Og det er da rare ting skjer. Så det dette litt naive programmet gjør, Vi legger sammen alle tall større enn 127. Og det gjør vi inni den indre løkka her. Så ser vi at jeg har lagt på en ytre løkke. Ikke tenk så mye på den. Det er bare lagt til for at dette skal ta litt tid. CPU-er er utrolig kjappe, så hvis vi bare hadde gjort én kjøring, så ville det å bare starte opp programmet tatt så mye tid. For vi skal se på forskjell i tiden. Det er den som er spesiell. Så vi gjør dette 50 000 ganger. Men hovedpoenget er hva vi gjør inni løkka her. Der sier vi at hvis dette tilfeldige tallet mellom 0 og 255 er større enn 127, så skal det summeres. Så det betyr bare... Vi tar alle tall større enn 127 og legger sammen. Så skriver vi ut summen. Så har det jo ikke noe merkelig skjedd med det... Vi kan ta det ut og... kompilere det. Og så kan vi kjøre det, men vi må da ta tiden på det når vi kjører. Og så ser vi... Dette er starten av æreiet. Så jeg har skrevet ut de ti første elementene. Det kommer helt tilfeldig. Og vi ser at dette programmet tok noe 20 sekunder. RIL her, det er hvor lang totaltid det tok. User, det er hvor mye CPU som ble brukt i use mode. Det skal vi snakke om i neste uke. Men kort sagt er det vanlige kommandoer som brukerprogrammet utfører. ... er hvor mye tid som ble brukt av dette programmet i current modes. Typisk for et regneprogram som dette her, så bruker man veldig lite operativstemkjernen. Stort sett er det bare programmet selv som står og kjører. Men så skal vi se på det som er litt mystisk...", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0013", "start": 2052.24, "end": 2256.72, "token_count": 599, "text": "User, det er hvor mye CPU som ble brukt i use mode. Det skal vi snakke om i neste uke. Men kort sagt er det vanlige kommandoer som brukerprogrammet utfører. ... er hvor mye tid som ble brukt av dette programmet i current modes. Typisk for et regneprogram som dette her, så bruker man veldig lite operativstemkjernen. Stort sett er det bare programmet selv som står og kjører. Men så skal vi se på det som er litt mystisk... Vi går nå inn i programmet igjen og så gjør jeg én liten endring. Det er en sånn sort-metode som har den syntaksen der. Det eneste dere trenger å vite, er at dette funksjonsskallet sorterer RE-data. Det er den eneste forskjellen jeg gjør. Ellers så skjer nøyaktig det samme her nede. Går gjennom like mange løkker. Det er klart, det ville ikke være noen forskjell på... Summen bør bli den samme. Det er bare at her ligger tallene i rekkefølge i dataeiere. Så kompilerer jeg på nytt. Og så tar tiden på hvor lang tid det tar. Og nå ser vi at nå er de første elementene sortert, med null først. Alle elementene med null i kommer først. Og så kommer... Men da ser vi... Her gikk plutselig programmet veldig mye fortere. Du brukte 17 sekunder her oppe og 11 sekunder her nede. Og det er... Det er det som er det store spørsmålet. Er det noen som kan se hva dette kan komme av? Hvorfor i all verden går plutselig programmet fortere bare fordi man sorterte RA? For... Nå må vi begynne å se på hva i all verden som skjer her. Random array er det samme i begge tilfeller. Så sorterer man det. Og så hopper man hit. Her skriver du ut de ti første. I det andre tilfellet var det bare nuller. Men den indre løkken her... Her skjer jo akkurat det samme. Den eneste forskjellen er at data-r-et er sortert. Og hva vil det si i praksis? Jo, det... I praksis så vil... ... vil man først gå gjennom en masse elementer hvor denne testen ikke står til. Og så går man gjennom en masse elementer, altså ca. 15 000, hvor dette slår til. Det kommer noen forslag...", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0014", "start": 2203.44, "end": 2406.66, "token_count": 589, "text": "I det andre tilfellet var det bare nuller. Men den indre løkken her... Her skjer jo akkurat det samme. Den eneste forskjellen er at data-r-et er sortert. Og hva vil det si i praksis? Jo, det... I praksis så vil... ... vil man først gå gjennom en masse elementer hvor denne testen ikke står til. Og så går man gjennom en masse elementer, altså ca. 15 000, hvor dette slår til. Det kommer noen forslag... Mer effektiv pipelining. Ja, det... Det k... Absolutt det kan man si. At pipeliningen er mer effektiv. Men på hvilken måte? Går inn i flere ganger, den som foreslår. Men det gjør man. Dette vil slå til akkurat like mange ganger. Så antall institusjoner som utføres, er faktisk den samme. Kanskje den bare sjekker if-testen én gang? Nei, den vil måtte sjekke if-testen hver eneste gang. For selv om r-er er sortert, så vet ikke operativsystemet eller noen andre... Så det må sjekkes hver gang. Er ikke dette speculative execution? Jo, nettopp! Dette er speculative execution. For når programmet kjøres, så... Så lærer... CPU-en lærer da hva som har skjedd ved forrige gang. Føre statistikk over hva som skjer, når man kommer til denne IF-testen i maskinkoden. Og når RAI-et er sortert, så vil systemet da lære at... Ja, denne testen her, den slår ikke til. Så her er det bare å... Her satser vi på at den ikke slår til. Og da bruker man speculative execution, så man begynner å utføre den insesjonen man tror det er. Og da går det mye fortere, for da har man... Når det ikke er større enn 127, så hopper man over. Og etterpå så kommer det masse RAI-data som er større enn 127. Og da vil hver gang så gjetter da systemet, eller CPU-en, gjetter da på at nå skal vi legge sammen. Og da utføres den addisjonen hver gang. Og den gjetter riktig hver gang. Og det er ganske mange ganger. 32 000 elementer. Så hver eneste gang den kommer til gift-testen, så gjetter den riktig.", "source": "lecture"}
{"lecture_id": "os6time1", "chunk_id": "os6time1_0015", "start": 2370.68, "end": 2612.66, "token_count": 565, "text": "Når det ikke er større enn 127, så hopper man over. Og etterpå så kommer det masse RAI-data som er større enn 127. Og da vil hver gang så gjetter da systemet, eller CPU-en, gjetter da på at nå skal vi legge sammen. Og da utføres den addisjonen hver gang. Og den gjetter riktig hver gang. Og det er ganske mange ganger. 32 000 elementer. Så hver eneste gang den kommer til gift-testen, så gjetter den riktig. Så blir det en bom, kanskje noen bommer, helt til den skjønner... OK. Her. Herfra og ut. Så gjetter den riktig. Og dermed går det mye fortere. Derimot, når r1 er hulter til bulter, så ville omtrent annenhver gang så ville dette her skifte. Det er typisk at branch prediction bare bommer hele tiden. Så det er riktig som oppsummert her. Branch prediction gjetter da veldig ofte korrekt, og systemet går mye raskere. Det er spørsmål om hvorfor det går så fort å sortere R-øyet. Ja, dette kommer jo egentlig i tillegg. Det er et godt spørsmål. Denne operasjonen er veldig rask. I tillegg ser vi at den utføres før løkkene. Så jeg sorterer ikke 50 000 ganger. Hvis jeg hadde lagt inn sorteringen der, så hadde det ikke vært så stor effekt. Men i forhold til å kjøre den løkka 50 000 ganger, hvor man går gjennom 32 000 rA i biter, så er denne operasjonen veldig rask. Det tar litt tid, men det har ikke noe særlig effekt for totaltiden. Ok. Da ser jeg at klokka har blitt mye, så vi tar et kvarters pause der. ... i pausen og komme med spørsmål. Etter pausen skal vi starte på multitasking. Men da tar vi en kort pause der. Ikke en kort pause... Vi tar en kvarters pause til... Hva blir det? 10.33 kan vi starte. ......... Det er veldig vanskelig å forstå hva som skjer i denne situasjonen. Det er veldig vanskelig å forstå hva som er sant og hva som er sant.", "source": "lecture"}
