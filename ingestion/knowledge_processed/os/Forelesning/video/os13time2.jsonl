{"lecture_id": "os13time2", "chunk_id": "os13time2_0000", "start": 0.0, "end": 207.12, "token_count": 585, "text": "Så fra nå blir forlesningen tatt opp. Vi snakket om ram og registre for å lagre adresser før pause. Og det var et godt spørsmål om å presisere disse registrene. Og da tenker jeg vi kan gå tilbake til det bildet... Det er viktig å huske på det bildet vi har av en CPU. Og det bildet her viser her nede hvordan RAM er koblet til CPU-en. Så her er det data out, adresse out. Så dette utgjør totalt sett adressebussen. I vår veldig enkle CPU så hadde vi... Men dette er det samme om du har... La oss si 64-bit. Da vil det være 64-bits-registre med 64 sånne koblinger mellom CPU-en. Datapath er en del av CPU-en, mens RAM er det vi snakker om nå - internmine. Og da ser vi uansett hvordan vi... Når vi skal snakke med RAM, Så må vi spesifisere adressen. Her er det fire bits som spesifiserer adressen. Det typiske man gjør da, er at man kobler et register inn i bussen på adresselinjene. Og hvis man da kobler rn, hvor det står tallet 1, inn i Address Out, så betyr det skriv til byte nummer 1 i ram. Står det 80rn, så skriver man til. Så på den måten så trenger man både et register som kobles til adressen, og et som kobles til dataene. Og de trenger ikke nødvendigvis være like store. 64 bit kan være litt overkill på rammeadresse, fordi ramme ikke er så stort. Så da kan man f.eks. velge å bruke... Et 48-bits-register til akkurat disse adressene. Og så kan man sende 64-bits med data. Altså man kan sende det registeret. Ja, altså... Så hvis man skal... Hvis man f.eks. skal sende tallet 8 til adresse 4... Så på denne CPU-en her så må du da ha ett register med tallet 8. Og så må det kobles til data out. Og så må du ha et annet register med tallet 4. Og så kobles det til adresse out. Og så trykker du på skriveknappen, og så skrives det til ramm. Så alle tall som kommer fra CPU-en på en eller annen måte, det må lagres i registeret.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0001", "start": 174.16, "end": 368.16, "token_count": 587, "text": "Hvis man f.eks. skal sende tallet 8 til adresse 4... Så på denne CPU-en her så må du da ha ett register med tallet 8. Og så må det kobles til data out. Og så må du ha et annet register med tallet 4. Og så kobles det til adresse out. Og så trykker du på skriveknappen, og så skrives det til ramm. Så alle tall som kommer fra CPU-en på en eller annen måte, det må lagres i registeret. Og når vi skulle programmere dette her, så måtte vi f.eks. da ta Skrive kode som inneholdt tallet 3, og så la vi det et register. Og så pekte det på en adresse. Sånn fungerte det hele veien. Ok. Vi så til sist før pausen at vi trengte MMU. Vi trengte en veldig hurtig hardware-bit som oversetter virtuelle adresser. Alle programmer bruker virtuelle adresser. De oversettes da til fysiske adresser. Så hvis vi skulle lagd det i... Det kunne vært nyttig å se til også. Hvis vi skulle lagd det her, så betyr det at da... Hvis vi skulle brukt et virtuelt adresserom, så betyr det at de adressene som vi sender ut her på AddressOut, de er da virtuelle. Så da kunne det være sånn at når vi sender ut adresse nr. 8, så har vi et system som sier at OK, egentlig så... Det er det virtuelle adresserommet. Egentlig skal den peke til adresse nummer 108 fysisk ramme. Og her, imellom address out og ram, så måtte man ha en egen enhet. Og det er det som er MMU-en, en egen enhet som da lynraskt oversetter... Akkurat som resten av CPU-en, med tilsvarende logikk, oversetter denne adressen fra 8 til 108. Så det vil måtte være en boks inni her. Denne CPU-en har fysisk adressering, så her kan du ikke bruke virtuelt. Men alle moderne CPU-er bruker et virtuelt adresserom. Så da har man en MMU i denne biten av databussen. Så det er det vi kommer til nå. Men først skal vi se på noen andre... Ja, se litt på mer praktisk bruk. Vi skal se på hvordan vi kan kompilere hva som skjer, når vi kompilerer programmer, og lowder dem.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0002", "start": 321.48, "end": 503.08, "token_count": 586, "text": "Så det vil måtte være en boks inni her. Denne CPU-en har fysisk adressering, så her kan du ikke bruke virtuelt. Men alle moderne CPU-er bruker et virtuelt adresserom. Så da har man en MMU i denne biten av databussen. Så det er det vi kommer til nå. Men først skal vi se på noen andre... Ja, se litt på mer praktisk bruk. Vi skal se på hvordan vi kan kompilere hva som skjer, når vi kompilerer programmer, og lowder dem. For det er jo det som i prinsippet skjer hele tiden. Man har kode som kompileres, og så får vi kjørbar kode. Og så må det legges inn i en termine og kjøres. Og det er det vi ser på denne sliden her. Så vi starter her oppe med... Kildekode. Og så kompilerer vi. Og det er da typisk, når vi har gjort det med C-programmet, så har vi skrevet GCC minus C, og så kode.c. Og da har vi ofte lagt på en minus O, og så kalt det noe. Rønn, for eksempel. Og den... Den rønn vil da være maskinkode. Og da har vi... Kompilatoren har oversatt kildekoden til maskinkode. Og her er det da maskinkode med null og enere. Vi har sett at vi kan se på den maskinkoden ved å be om å få assembly-kode. Men det er da en én-til-én mellom assembly-koden og maskinkoden. Dette er maskinkode som sier nøyaktig hvilke instruksjoner som skal utføres. Men det vi ikke har sett på tidligere, er at inni her så er det relative adresse. Ethvert program som dette her starter med et minnerom fra null til 4G. Fra null til maks. Og de adressene vil da være relative. For de vil ikke være de fysiske adressene som ligger her ute i rom. Men så før vi får ferdig maskinkoden som kan kjøres... Så har vi sett tidligere at vi har lagt til én linje. Med linking. Vi kan gjøre hele dette i en operasjon, men det vi typisk tatt har gjort, er at vi f.eks. har kompilert to biter. Vi har kompilert én main og én... Vi hadde en sånn sum-funksjon. Den kompilerte vi i to forskjellige programmer.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0003", "start": 464.3, "end": 629.98, "token_count": 596, "text": "For de vil ikke være de fysiske adressene som ligger her ute i rom. Men så før vi får ferdig maskinkoden som kan kjøres... Så har vi sett tidligere at vi har lagt til én linje. Med linking. Vi kan gjøre hele dette i en operasjon, men det vi typisk tatt har gjort, er at vi f.eks. har kompilert to biter. Vi har kompilert én main og én... Vi hadde en sånn sum-funksjon. Den kompilerte vi i to forskjellige programmer. Og da er det i linkingen så limes de to programmene til ett virkende system. Var at her i kildekoden så hadde vi f.eks. sånn Include STDIO... Altså for å kunne skrive print. Og det var da et systembibliotek som da linkes inn... Da er det kode her fra systembiblioteket for å printe ut. Det linkes sammen med maskinkoden som er lagd av kildekoden av programmet. Så alt dette limes sammen til én stor maskinkode. Og så, når programmet... Skal kjøres, så må det lastes inn i ram. Og det ser vi. Her er denne koden tatt og lastet inn i ram. Og det er maskinkode som da kan kjøres. CPU-en setter i gang hjørnes her på adresse 0, og så kjører den nedover. Så ser vi at vi har en sinus og x her. Og det er typisk et sånt systembibliotek. Man ønsker i kildekoden å regne ut sinus og x. I stedet for å skrive kode som regner ut det fra scratch, så bruker man et eller annet mattebibliotek som man linker inn herfra. Så kan man kjøre SiensaX. Og det kan man statisk linke inn. Man kan ta den SiensaX-koden og hive rett inn i maskinkoden. Men så kan man også ha såkalt dynamisk bibliotek. Og da vil man ha kode som ikke engang er utgangspunktet. Hvis man begynner å kjøre denne maskinkoden, så kan det være at man akkurat i dette tilfellet ikke regner ut SinusAX. Hvis det viser seg når du kjører dette programmet, så ønsker man å regne ut SinusAX. Da har man en dynamisk link. Og da laster operativsystemet inn dette biblioteket her med maskinkode som regner ut SinusAX og andre funksjoner.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0004", "start": 591.68, "end": 765.36, "token_count": 600, "text": "såkalt dynamisk bibliotek. Og da vil man ha kode som ikke engang er utgangspunktet. Hvis man begynner å kjøre denne maskinkoden, så kan det være at man akkurat i dette tilfellet ikke regner ut SinusAX. Hvis det viser seg når du kjører dette programmet, så ønsker man å regne ut SinusAX. Da har man en dynamisk link. Og da laster operativsystemet inn dette biblioteket her med maskinkode som regner ut SinusAX og andre funksjoner. Laster inn den, og så hopper koden til riktig sted her. Regner ut SinusX og returnerer. Og fordelen med dette med å ha et sånt dynamisk bibliotek, er at da kan jo flere programmer bruke den samme dynamiske koden. Dette er der shared memory. Vi ser her program 2. Det ønsker også å regne ut SinusX. Og da i stedet for at Koden er kopiert, Både i maskinkoden her oppe og i program 2 så peker begge til denne delen, til dette dynamiske biblioteket. Og på den måten så kan det da regne ut sinus 6. Men vi ser med en gang... Vi begynner å se på dette her. Jo, vi skal løfte inn maskinkode inn i ramm. Så begynner vi å tenke sånn... Hvordan disse adressene her... De begynner på null. Jo, vi kunne hatt sånn at... La oss si at dette er adresse 1000. Så kunne vi hatt sånn at da legger vi til 1000 på alle disse her. Da må alle adressene som er her inne, oversettes. Da må man legge til 1000, og så limer de fast her. Men problemet med det er at da må denne maskinkoden her forever ligge akkurat der. Og den dynamiske her må forever ligge akkurat der. Men hva om vi ønsker å legge inn nye programmer? Jo, da må de legges ut i resten av ramm. Men til slutt går ramm full, og man har ikke plass til flere. Og da må man begynne å ta programmer ut. Og da ville det vært veldig tungvint hvis alle programmer til enhver tid skulle vite hvor de lå, og alle måtte vite de... De fysiske adressene. Og denne oversettelsen her er veldig tungvint og veldig lite dynamisk. Så det man har kommet opp med da, er en metode med virtuelt minne.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0005", "start": 727.92, "end": 934.78, "token_count": 598, "text": "Jo, da må de legges ut i resten av ramm. Men til slutt går ramm full, og man har ikke plass til flere. Og da må man begynne å ta programmer ut. Og da ville det vært veldig tungvint hvis alle programmer til enhver tid skulle vite hvor de lå, og alle måtte vite de... De fysiske adressene. Og denne oversettelsen her er veldig tungvint og veldig lite dynamisk. Så det man har kommet opp med da, er en metode med virtuelt minne. Hvor alle adressene her, null til maks, de... Etter at det er lagt inn, så har man en tabell som viser hvor alle de forskjellige programmene. Sånn at når det er kode her som spør om rammeadresse 48, så vet det systemet, MMM-en, hvor rammeadresse 48 for akkurat denne kodebiten her ligger. Hvilken fysisk adresse det er. På denne måten så er det veldig enkelt å flytte programmer inn og ut. MMU, pagetabellene, de blir oppdatert når man flytter programmer inn og ut, og det muliggjør å ha en veldig dynamisk organisering av prosessene som ligger i rammen. Men før vi ser på det MMU i detalj, så skal vi se på et eksempel på hvordan man kan gjøre dette her i praksis. Jeg skal ikke vise det i praksis, men bare først skissere... Hva som skjer her. Dette er en simulering jeg lagde en gang. Så det er et C++-prosjekt. Og da lagde jeg et bibliotek som gjorde noen beregninger. Og regnet ut standard og vik osv. Det jeg gjorde da, var at jeg lagde et C++-library. Altså mitt eget bibliotek. Og det G++ er en C++-kompilator. Så det jeg gjorde da først, var å kompilere kildekoden til biblioteket. Og da lages det kalktools.o og roundtools.o. Og så er ar en kommando for å lage et bibliotek. Og det biblioteket jeg lagde, er livtools.a. Og så hadde jeg en simulering som jeg kompilerte. Akkurat tilsvarende som vi gjorde tidligere. Lage maskinkode. Og så til slutt... Så denne operasjonen her nede... Den lager en eksekverbar fil-sim ved å lime sammen alle programmene.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0006", "start": 897.0, "end": 1142.6, "token_count": 590, "text": "Og da lages det kalktools.o og roundtools.o. Og så er ar en kommando for å lage et bibliotek. Og det biblioteket jeg lagde, er livtools.a. Og så hadde jeg en simulering som jeg kompilerte. Akkurat tilsvarende som vi gjorde tidligere. Lage maskinkode. Og så til slutt... Så denne operasjonen her nede... Den lager en eksekverbar fil-sim ved å lime sammen alle programmene. Og her er det også noen kommandoer som gjør at man limer inn det biblioteket her oppe. Så i praksis det jeg gjorde, var at jeg laget mitt eget lille bibliotek her. Og så, den siste operasjonen, linket det sammen. Og all koden var det her inne. Og så kan den lastes inn og kjøres. Så vi kan... Vi kan se på hvordan det ser ut i praksis. Så her under 'Tools' så har jeg da de verktøyene. For eksempel 'Calc Tools'. Det er da en metode som regner ut varianse. Og så har jeg en... Bare et lite program som... Skal vi se... Sånn, kanskje. Dette er et lite skript som kompilerer. Så først kompileres de to programmene, og så lager jeg et bibliotek. Ved å eksplisitt kjøre det. Sånn. Nå har jeg lagd en bibliotekfil. Og den... Ta den her. Libtools.a. Det er selve bibliotekfilen som jeg nå skal bruke når jeg skal kjøre. Så... da kan jeg gå til selve simuleringen. Her har jeg også et lite program som kompilerer. Den komplerer selve simuleringen og noen andre hjelpeprogram. Og så her linkes det sammen til en simulering. Så jeg skal gjøre det her. Jeg skriver bæsj minus x, for da får jeg se eksplisitt hva som skjer. Nå er jeg lagd av en simulering. 27 000 bites. Og så kan den simuleringen kjøre. Så det som skjer når jeg kjører, Lastes den inn i minnet, inkludert biblioteksfilene? Så skal jeg prøve å gjøre det samme på en litt annen måte. Det jeg skal gjøre da, er... Nå har jeg en S-Tools. Men her skal jeg vise hvordan man lager et dynamisk bibliotek.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0007", "start": 1084.68, "end": 1314.08, "token_count": 594, "text": "Jeg skriver bæsj minus x, for da får jeg se eksplisitt hva som skjer. Nå er jeg lagd av en simulering. 27 000 bites. Og så kan den simuleringen kjøre. Så det som skjer når jeg kjører, Lastes den inn i minnet, inkludert biblioteksfilene? Så skal jeg prøve å gjøre det samme på en litt annen måte. Det jeg skal gjøre da, er... Nå har jeg en S-Tools. Men her skal jeg vise hvordan man lager et dynamisk bibliotek. Det er veldig mye av det samme. Det ligner veldig. Men du ser dynamiske bibliotek. Under Linux heter de.so. I Windows heter det DLL. Dynamical Linkable... DLL... Dynamical Linked Library heter det. Så hvis jeg kjører dette, så lager jeg da et dynamisk bibliotek. libstools.so. Så... da kan jeg... gå hit, hvor jeg bruker det dynamiske. Så kan jeg compilere med det dynamiske biblioteket. Og da ser det veldig likt ut. Jeg legger på en minus-L-tools der. Og så er det nå klart til at jeg kan kjøre den simuleringen i stedet. Det er akkurat den som går litt fortere. Det er ikke noen forskjell i koden egentlig. Det er bare en løkke som er mindre her. Så... Det ser jo veldig likt ut når jeg kjører, men det som er en viktig forskjell her, er at når... I det andre tilfellet her, når jeg starter denne her, som bruker et dynamisk bibliotek, så lastes det biblioteket inn når jeg kjører det. Og da kunne jeg også lage andre programmer som bruker det samme biblioteket. Vi kan se at det er en liten forskjell. Hvis jeg nå tar LS minus L på SIM, så ser vi at den er på 26,68. Mens den første simuleringen, den er på 27,880. Så du ser her, det er en forskjell på én kilobite. Og den kilobiten er rett og slett at i dette tilfellet, Så da er all koden fra biblioteket ligger fysisk inne i den kjørbare filen. Mens her så lastes den kjørbare... Det dynamiske biblioteket lastes dynamisk, og dermed ser vi at koden er litt mindre. Så hvis vi går tilbake til slidene, så...", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0008", "start": 1270.96, "end": 1479.04, "token_count": 595, "text": "Mens den første simuleringen, den er på 27,880. Så du ser her, det er en forskjell på én kilobite. Og den kilobiten er rett og slett at i dette tilfellet, Så da er all koden fra biblioteket ligger fysisk inne i den kjørbare filen. Mens her så lastes den kjørbare... Det dynamiske biblioteket lastes dynamisk, og dermed ser vi at koden er litt mindre. Så hvis vi går tilbake til slidene, så... I det andre tilfellet så hadde jeg da et dynamisk bibliotek, Som ble lastet inn når jeg kjørte koden. I det første tilfellet så lå alt inni her. Og dermed så var den 1K større enn den koden jeg brukte. Ja. Da skal vi se veldig kort på Linux prosess segmentation. Dette er da... Dette er da slik Linux... Det er bare noen begreper her som er nyttige å ha med seg. Vi ser... Stack har vi sett på tidligere. Det brukes til lokale variabler. Og så har vi her nede tekst, eller koden. Og det er da typen... Den maskinkoden som programmet bruker når det kjører. Og så har vi også noe som kalles HEAP. Og her lagres det globale variabler og data som... Som genereres dynamisk mens programmet kjører. Det ligger på heapen. Vi ser at den kan vokse oppover, sånn at vi kan... Og legge til dynamisk mer og mer variabler, f.eks., eller RA, som vi skal se på senere. Også MMApp. Det er en sånn minneavbilding av filer rett inn på ram, igjen sånn at ting skal gå raskere. Men nå skal vi se på minneadressering og MMU. Ja, som jeg har argumentert for tidligere, så må alle de... Virtuelle adressene må kunne knyttes til fysiske adresser. Som jeg nevnte, så kunne det skjedd ved loading, men det er både tidkrevende og tungvint, og lite dynamisk. Så i alle moderne OS så gjøres dette dynamisk mens programmet kjører. Og det gjør at man kan flytte inn og ut programmer og biblioteker og alt som operativstemme ønsker, når det vil. For å kunne kjøre alle programmer mest. Vi kunne hatt sånn at operativsystemet oversatte mellom fysiske adresser og de logiske eller virtuelle.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0009", "start": 1443.76, "end": 1616.76, "token_count": 587, "text": "Som jeg nevnte, så kunne det skjedd ved loading, men det er både tidkrevende og tungvint, og lite dynamisk. Så i alle moderne OS så gjøres dette dynamisk mens programmet kjører. Og det gjør at man kan flytte inn og ut programmer og biblioteker og alt som operativstemme ønsker, når det vil. For å kunne kjøre alle programmer mest. Vi kunne hatt sånn at operativsystemet oversatte mellom fysiske adresser og de logiske eller virtuelle. Men det ville gått altfor sakte. Man kan ikke ha kode som gjør det. Fordi disse operasjonene foregår hele tiden. Så dette må skje i brøkdelen av et sekund. Og da trenger vi hjelp fra hardware. Vi trenger en egen enhet, MMU. Og dette er skissert et bilde av MMU-en. Vi så på den simulerte CPU-en at vi har en databuss. Og det er da linjer med bits som går fra CPU-en og ut i RAM. Og den adressebiten, den oversettes av MMU. CPU-en sender ut en logisk adresse. Så oversettes MMU-en til fysisk adresse. Så kobles den på databussen. Det er da linjer som går herfra og inn hit. Så trykker de linjene på... La oss si jeg har sendt med adresse... MMU har oversett... La oss si logisk adresse 8 til fysisk adresse 1008. Så går 1008 ut hit. Så kobler man på RAM. 1008 med bits. Bang, bang, bang inn her. Så leses det som ligger i Byte nr. 1008, og så sendes det tilbake til CPUN. Og det skjer hver eneste gang man henter noe i RAN. Ja... Vi skal se på et lite eksempel, litt sånn fiktivt eksempel, med program 1 og program 2 som skal kjøres. Bare for å se hvordan det kan se ut i praksis. Etter at man har kompilert programmene, så er adressene logiske. Og da må man ha en MMU, eller en eller annen slags MMU-tabell, som oversetter de logiske eller virtuelle adressene til det fysiske. Da kan det f.eks. se sånn ut. Program 1, vi har kompilert det, og da står det i program 1... F.eks. på linje 24 står det LOW32. Det betyr da...", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0010", "start": 1582.08, "end": 1753.0, "token_count": 594, "text": "Bare for å se hvordan det kan se ut i praksis. Etter at man har kompilert programmene, så er adressene logiske. Og da må man ha en MMU, eller en eller annen slags MMU-tabell, som oversetter de logiske eller virtuelle adressene til det fysiske. Da kan det f.eks. se sånn ut. Program 1, vi har kompilert det, og da står det i program 1... F.eks. på linje 24 står det LOW32. Det betyr da... Last inn i CPU-en det som ligger på linje 32 i ram. Som i dette tilfellet er tallet 671. Så har vi noe tilsvarende i program 2. På linje 28 i program 2 så står det kanskje LOW 36. Og det betyr last inn denne 712, som ligger på linje 36 i ram. Når disse skal kjøres, så... Legges program 1 og program 2, de loads inn i ramm. Her har de fått en plassering. Men da ser vi at ingen av disse virtuelle adressene vil være de riktig fysiske. F.eks. program 1 har tilfeldigvis havnet der på 100. Program 2 har havnet på 150. Og da er det klart... Når program 1 sier \".load 32\", så mener det egentlig load 132. Og der da 132 må sendes ut på minnebussen... Sånn at programmet får denne verdien. Men husk at load 32, når den skal kjøres... Først må det lasses inn i CPU-en. Så utføres load 32. Og da vil CPU-en ved hjelp av MMU-en oversette 32 til 132, og så sendes tilbake hit. Så da kunne man jo tenke seg at man hadde en tabell... Som ordner dette her. Spørsmål i chatten... Logiske adresser, og er de samme som virtuelle? Ja, jeg bruker det litt om hverandre. Logiske eller virtuelle adresser. Hovedpoenget er at de må oversettes til fysiske adresser. Vi kunne hatt den tabellen som så ut som på dette. For program 1 så kunne vi si... OK, adresse 24, den mappes over til 100. Program 2, adresse 28, mappes av til 178. Men da hadde vi plutselig en tabell som var like stor som hele Ram. Så dette er helt umulig og altfor minnekrevende.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0011", "start": 1716.6, "end": 1902.08, "token_count": 591, "text": "Ja, jeg bruker det litt om hverandre. Logiske eller virtuelle adresser. Hovedpoenget er at de må oversettes til fysiske adresser. Vi kunne hatt den tabellen som så ut som på dette. For program 1 så kunne vi si... OK, adresse 24, den mappes over til 100. Program 2, adresse 28, mappes av til 178. Men da hadde vi plutselig en tabell som var like stor som hele Ram. Så dette er helt umulig og altfor minnekrevende. Men vi kunne i stedet dele opp det logiske minnet i pages. Sånn som dette eksempelet her, så kunne vi ha en side med 50 adresser. Og dermed har vi bare én faktor som må legges til. For da sier vi at program 1 ligger på denne siden, og alle adresser må da bare legge på 100. Og det er i praksis omtrent sånn MMU virker. Og dette med å bruke et virtuelt minnerom, det kalles generelt paging. Det er fordi man deler inn hver sin prosess, sitt virtuelle minnerom, i et antall sider. Så la oss si den forrige prosessen, da. De hadde 50 bite per side. Så hvis den besto av 500 bites, så ville de fått ti sider. Og så ville... I MMU så ville det bare stå hvor disse ti sidene ligger.  Og da... Når vi organiserer Ramm, det virtuelle Ramm, i sider, eller pages på denne måten, så kan operativsystemet da dynamisk laste inn og ut disse sidene fra Ramm. Og det kan da types å være sånne enheter på 4K, f.eks. En vanlig sidestørrelse er 4K, og da deles alle programmer inn. Og så laster operativstemme inn og ut disse bitene. På den måten har jeg operativstemme full kontroll over minibruken og kan dynamisk endre tildelingen av ramm til alle prosesser. Ja... Her er det et lite fiktivt eksempel på hvordan dette kan se ut. Har størrelse 2 jentebites. Skal se senere hvorfor det må være akkurat 2 i jente. Typiske verdier er 1 lik 12 eller 13, sånn at du får en sidestørrelse på 4 eller 8 kBite. 4 kBite er vanlig for X86-prosessorer. Det er ganske standard.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0012", "start": 1864.44, "end": 2062.12, "token_count": 581, "text": "og kan dynamisk endre tildelingen av ramm til alle prosesser. Ja... Her er det et lite fiktivt eksempel på hvordan dette kan se ut. Har størrelse 2 jentebites. Skal se senere hvorfor det må være akkurat 2 i jente. Typiske verdier er 1 lik 12 eller 13, sånn at du får en sidestørrelse på 4 eller 8 kBite. 4 kBite er vanlig for X86-prosessorer. Det er ganske standard. Så dette gjelder per prosess. Så vi har da en tabell... Hver prosess har en egen tabell. Hvis du har én CPU, så er det bare én prosess som kjører av gangen. Så i MMU trenger vi bare å ha den ene tabellen for prosessen som kjøres. Når en prosess switches ut, så lagres da MMU-tabellen i PCB. Men vi kan tenke oss... Her har vi en prosess med logisk minne. Og MMU vil da være en tabell som sier hvor i det fysiske minnet disse sidene ligger. Så f.eks. her står det frame nummer... Eller virtuell side nummer 0 ligger i page nummer 1. Eller ligger i frame nummer 1. Det logiske minnet kaller pages. Og så er dette i fysisk minne, det er frames. Og i MMU så står det her... Page nr. 0 ligger i frame 1. Og page nr. 1 ligger i frame 4 osv. Enkelt og greit. Bare en tabell som viser denne oversettelsen. Men det er veldig viktig at denne oversettelsen må være veldig hurtig. Så vi skal se litt i detalj på etter hvert hvordan oversettelsen foregår. I en sånn pagetabell så har vi da en pagetable-entry for hver eneste side. Og det viktigste da er sidenummeret. Det er altså... Det er det nummeret her. Hvilken frame er det som denne siden... Denne virtuelle siden, i hvilken fysisk frame ligger den? Noen andre bits. F.eks. sånn at man kan sette skrive- og leserettigheter på minnet også, per prosess og per page. Og så har man present-absent-bit. Det sier om... Det sier om denne siden faktisk ligger i det fysiske minnet.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0013", "start": 2012.64, "end": 2207.24, "token_count": 590, "text": "Og det viktigste da er sidenummeret. Det er altså... Det er det nummeret her. Hvilken frame er det som denne siden... Denne virtuelle siden, i hvilken fysisk frame ligger den? Noen andre bits. F.eks. sånn at man kan sette skrive- og leserettigheter på minnet også, per prosess og per page. Og så har man present-absent-bit. Det sier om... Det sier om denne siden faktisk ligger i det fysiske minnet. Hvis du ser null her, så betyr det at den ligger bare på disken. Og da... Hvis programmet ønsker å hente noe fra denne siden, så må den ut på disken og hente den. Og det er en såkalt page fault. Siden mangler, og må ut på disken og hente. Og det tar veldig lang tid. Endret bytte, det er også null eller én. Hvis den er én, så betyr det at siden er dirty, eller har blitt endret. At hvis... Hvis den siden skal ut av ramm, så må verdien skrives til disk. Hvis den ikke har blitt endret og den skal ut av ramm, så kan du bare droppe den. Men hvis endret-bittet er én, så er siden dirty, og den må skrives til disk før den kan fjernes fra ramm. Så er det reference. Det brukes av... Pagingaloritmer som velger hvilke sider som til enhver tid skal ha plass i rammen. TelB, Translation Look-Aside Buffer, det er en viktig bit. Og det vi har sett på i CPU-en, så har vi L1 og L2 Cash for ramm. Men da snakker vi hele tiden om... Om kode og variabler. Men vi har det samme for MMU, fordi MMU må gå så raskt. Så har man TLB, som er en cashbit spesielt for MMU-adressene. Og som et eksempel, da... Hvis man har en prosess som bruker 100 MB, så vil de gi 4 KB... Med sider... Nei, så vil det med 4 kB sider... Altså med 1 lik 12, så har vi 4 kB størrelse på sidene... Så vil det bety omtrent 25 000 sider. Så vi ser det blir fort veldig mange. En sånn topp-L blir fort veldig stor. En 4 GB prosess har 1 million sider i MMW.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0014", "start": 2162.88, "end": 2335.58, "token_count": 582, "text": "Så har man TLB, som er en cashbit spesielt for MMU-adressene. Og som et eksempel, da... Hvis man har en prosess som bruker 100 MB, så vil de gi 4 KB... Med sider... Nei, så vil det med 4 kB sider... Altså med 1 lik 12, så har vi 4 kB størrelse på sidene... Så vil det bety omtrent 25 000 sider. Så vi ser det blir fort veldig mange. En sånn topp-L blir fort veldig stor. En 4 GB prosess har 1 million sider i MMW. Og da får man ikke plass til å lagre dette inne i CPU-en. Der er det bare et begrenset antall registre. Så dermed så vil MMU være med også da... Den vil i utgangspunktet ligge i ramm, men så vil du ha noe i cash. Og TLB-en er da den innerste delen av cashen som de... som er raskest å treffe. Så TLB er... er da hurtigcash for... Og den vil da bare inneholde en bitte liten del av pagetabellen, men heldigvis er det ofte den som treffes på. Akkurat som med annen type cash, så bruker man ofte de samme sidene om og om igjen, sånn at da treffer man ofte på den oversettelsen. Hvis man ber om en adresse som ikke ligger i TLB, så får man en såkalt TLB-miss, eller en soft-miss. Og det tar vesentlig lengre tid enn om den ligger i TLB, for da må man lenger ut i cash, eventuelt helt ut i ram for å hente denne siden. Dette er bare noen eksempler på sånn typisk TLB-ytelse. Størrelse... En cash-linje, det er da en bit av cash... Altså den minste biten av cash er typisk på 64 bytes. Og til B-er kan være sånn mellom 16 000 og 4000 linjer. Eller mellom 1 og 256 kB. Så det er relativt... Det er en relativt liten tabell. Men det som er viktig, oppslagstiden er ekstremt hurtig. Dere kan gå i underkant av en klokkesykkel og slå opp. Det er hardware-kablet. Så man gjør ikke noen instruksjoner og regner noe. Adressene direkte.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0015", "start": 2296.84, "end": 2463.0, "token_count": 582, "text": "Altså den minste biten av cash er typisk på 64 bytes. Og til B-er kan være sånn mellom 16 000 og 4000 linjer. Eller mellom 1 og 256 kB. Så det er relativt... Det er en relativt liten tabell. Men det som er viktig, oppslagstiden er ekstremt hurtig. Dere kan gå i underkant av en klokkesykkel og slå opp. Det er hardware-kablet. Så man gjør ikke noen instruksjoner og regner noe. Adressene direkte. Hvis det er en TLB miss, så kan det forgå mange klokkesykler for å hente den, avhengig av om den er i cash eller i ram. Men det som er veldig fint med dette, er at TLB miss-frekvensen sånn statistisk så er den veldig liten. Stort sett så bruker man de samme adressene om og om igjen, og de ligger da i TLB. Så noe sånt som dette her kan det se ut. Tidligere at vi har level 2-cash, også level 3-cash, inne på prosessoren. Og så har vi RAM her ute. Så tidligere har vi sett at vi har LN-cash for data og for instruksjoner. Sånn at når... Ofte så henter man de samme instruksjonene, de samme dataene, om og om igjen. Og det ligger veldig nære CPU-en. Og dermed går det ti ganger så raskt som om man skulle hente det ut til RAM. Det samme er det for MMU, og da har vi en TLB-L1-cash her inne. Og dette er TLB-en som vi snakker om. Her ligger hurtigoppslagene for minneadressering. Så 99 % av tilfellene så treffer man på et LB, og da går oversettelsen fra virtuelt minne til fysisk minne veldig raskt. Vi kan... Ja... Vi kommer ikke så veldig lenger i dag, men vi skal i hvert fall ta med akkurat denne oversettelsen her. Det er en figur fra Tallbaum, og det viser en oversettelse fra det virtuelle adresserommet til det fysiske adresserommet. Her er det veldig små størrelser. 64K fysisk minne. 64K virtuelt minne. På moderne maskiner så har man opplevd mye større", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0016", "start": 2422.16, "end": 2620.2, "token_count": 600, "text": "Vi kan... Ja... Vi kommer ikke så veldig lenger i dag, men vi skal i hvert fall ta med akkurat denne oversettelsen her. Det er en figur fra Tallbaum, og det viser en oversettelse fra det virtuelle adresserommet til det fysiske adresserommet. Her er det veldig små størrelser. 64K fysisk minne. 64K virtuelt minne. På moderne maskiner så har man opplevd mye større både fysisk og virtuelt minne, men prinsippene er akkurat det samme. Så her ser vi at... Hvor mange er det? Åtte av disse virtuelle sidene er mappet til fysisk minne. Det er akkurat det samme. Her nederst her er page nummer null. Vi ser at den ligger i physical frame nummer to. Så det går en pil herfra og så opp hit. Og da må man, når det kommer en mineadresse herfra, inn til MMU-en, så må MMU-en lynraskt oversette den mineadressen til den riktige i den fysiske. Og det er det neste slide viser hvordan man gjør. Det er på en måte den fysiske kablingen i MMU som gjør at et MMU-oppslag går på faktisk brøkdelen av en klokkesykkel. Fordi det er ikke en... Det regnes ikke ut ved hjelp av CPU-instruksjoner. Det er direkte kabling. Og måten man får det til på, er at man har en innkommende adresse. Vi kan se konkret på dette eksempelet her. Har vi en innkommende adresse 8196... Og vi ser vi har... Vi har tolv bytt her. Det betyr at vi har en... Hver side har to i tolvte adresser. Og to i tolvte er... To i tiende er 1024, så to i tolvte er 4096. Så disse tolvbitene utgjør 4096 adresser. Og det er liksom... Det er internt på siden hvilken adresse det er. Men så... I det virtuelle adresserommet har vi da i tillegg fire bit. Og de bitene sier hvilken side i det virtuelle adresserommet det er. Og 0100, det er da dette... Det vil da være null, nei, enere. Og dette er Tore, så dette er tallet to. Så vi ser at den peker her. Er det virtuelle side nummer to. Og det betyr at...", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0017", "start": 2581.48, "end": 2782.34, "token_count": 582, "text": "Og det er liksom... Det er internt på siden hvilken adresse det er. Men så... I det virtuelle adresserommet har vi da i tillegg fire bit. Og de bitene sier hvilken side i det virtuelle adresserommet det er. Og 0100, det er da dette... Det vil da være null, nei, enere. Og dette er Tore, så dette er tallet to. Så vi ser at den peker her. Er det virtuelle side nummer to. Og det betyr at... Ja, dette vil da bli to ganger 4000... Det er da 8192. Dere kan se på de tallene. Jeg har skrevet det i detalj i forelesningsresultatene, hvordan man oversetter det. Så prøv å gå gjennom det. Og forstå nøyaktig hvordan vi kommer fra 8196 til 24580 her oppe. Det er en sånn typisk liten eksamensoppgave. Men dette er for at dere virkelig skal se mekanismen i hvordan dette oversettes. Her har vi side to. De neste tolvbitene er bare hvor i adresserommet det er. Her står det fire. Så dette er internt i adresserommet. Adresse nummer fire. Men så ser vi at her er MMU-tabellen. Den peker til... Nei, 2. Den peker til 110. Her står det 110. Så da tar man de bitene her som er... I page nummer to så står det 110, og det er da... Det er da tallet seks. Og så ser vi om man limer da bare det tallet seks som sier hvilken frame det er. Det er akkurat det som vi så her nede. Her er page nummer to. Page nummer 012... Page nummer to peker på fysisk adresse nummer seks. Det gjøres ved at man limer den... Kabler, da. 110. Sånn at den kommer først, og så sendes da bare hele denne her... Sendes videre til databussen. Og det er på magisk vis... Men vi har bare lint på et på en måte seks ganger 4096... Og det ble 24 576. Og så kommer det firetallet i tillegg. Firetallet er bare offset hvor i denne siden som denne adressen vi skal ha tak i, ligger. Så dette viser hvordan man... Ved å bare kable dette helt riktig med... Så får man en hardware-bit, altså MMU,", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0018", "start": 2737.8, "end": 2940.48, "token_count": 584, "text": "Sånn at den kommer først, og så sendes da bare hele denne her... Sendes videre til databussen. Og det er på magisk vis... Men vi har bare lint på et på en måte seks ganger 4096... Og det ble 24 576. Og så kommer det firetallet i tillegg. Firetallet er bare offset hvor i denne siden som denne adressen vi skal ha tak i, ligger. Så dette viser hvordan man... Ved å bare kable dette helt riktig med... Så får man en hardware-bit, altså MMU, som gjør denne oversettelsen i løpet av brøkdelen av et skudd. Ok... Ja. Så dette er bare å oppsummere hvordan dette her virker. Paging gjør da at man deler inn programmer, prog1 og prog2, i sider på denne måten her. Og så har man... Og så har man fysisk ram som ligger imellom her. Og da kan det være at ikke alle sidene i disse to programmene ligger i ram. Det kan kanskje bare være page 3 fra program 1. Og page 0 fra program 1 og page 4 fra program 2. De andre vil da ligge på disken. Disse sidene ligger da på swap-området på disken. Det er typisk noe tilfelle hvor man får problemer hvor det ikke er plass til alle programmene i RAM samtidig. Da sliter man, hvor da begynner... Da kaller man det... Swapping... Hvis du har en fysisk disk, vil du kunne høre at den disken driver og kjører og kjører, for hele tiden flyttes ting inn og ut av minnet fra disken. Og det går ekstremt tregt. Og det er da ting virkelig går sakte på en maskin. Ja... Oi, jeg ser mye tid for å avslutte det der. Bare veldig kjapt - persingalrytmer. Det er da algoritmer som bestemmer hvilke sider som skal ligge i ramm, og det er da en del av operativsystemet som gjør paging. Det tippet som skjer at du får en pagefault, det er da man adresserer noe... En adresse som ikke ligger i ramm, men som ligger ute på disk. Og det tar veldig lang tid, for da må man fysisk ut. Hente det inn i RAM, og så varsle alt. Så typisk vil en prosess scheduleres ut mens man venter på denne siden.", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0019", "start": 2898.4, "end": 3132.3, "token_count": 590, "text": "Det er da algoritmer som bestemmer hvilke sider som skal ligge i ramm, og det er da en del av operativsystemet som gjør paging. Det tippet som skjer at du får en pagefault, det er da man adresserer noe... En adresse som ikke ligger i ramm, men som ligger ute på disk. Og det tar veldig lang tid, for da må man fysisk ut. Hente det inn i RAM, og så varsle alt. Så typisk vil en prosess scheduleres ut mens man venter på denne siden. Men de algoritmene som bestemmer hvilke sider skal ligge inne, og hvilke skal ligge på disk, det er pitching allerede. Så fortsetter vi der med dynamisk allokering neste gang. Ja... Vi skal se. Det var noen gode spørsmål her i chatten. Først er det spørsmål om R32 fra starten av den designerte startadressen. Ja... Jeg antar du spørsmålet gjelder denne her. Lov 32, det vil være når... Helt konkret når man kompilerer, så vil kompilatoren lage minneadresser. Og den bruker det logiske adresserommet, og det logiske adresserommet starter på null. Altså Love 32, det er en logisk eller virtuell adresse innen det adresserommet som program 1 tror han er ene hersker over. Og programmet vet ikke da om når det blir loved ut, om dette blir da fysiske adresser eller ikke. Men det betyr ikke noe at programmet gjør det, for det er dette sørger MMU for at 32 alltid blir oversatt til i dette tilfellet. Ja... Men hva om prosessen bruker mer enn Pagent sin adresse? Det hender man får segmentation fault, og det er typisk hvis et program her inne snakker om en adresse som ikke er sin. Så hvis den er utenfor sine sider, så vil du typisk få en page fault. Så en av de delene som operativsystemet må gjøre, er å sørge for at ingen programmer kan skrive over i andres minner. Men med paging så kan operativsystemet styre dette totalt, sånn at det sikrer at ingen overskriver for hverandre. Til slutt er det spørsmål om... Hvorfor legger man ikke mer lagringsplass i LNC1GB? Og det er et godt spørsmål, men... Kunne du ikke bare hatt enormt mye lagringsplass her?", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0020", "start": 3090.78, "end": 3267.46, "token_count": 584, "text": "Så en av de delene som operativsystemet må gjøre, er å sørge for at ingen programmer kan skrive over i andres minner. Men med paging så kan operativsystemet styre dette totalt, sånn at det sikrer at ingen overskriver for hverandre. Til slutt er det spørsmål om... Hvorfor legger man ikke mer lagringsplass i LNC1GB? Og det er et godt spørsmål, men... Kunne du ikke bare hatt enormt mye lagringsplass her? Og dette er da et fysisk spørsmål... Man lager dette så effektivt som mulig, men hvis du har én GB her inne, så... Eller la oss si du hadde én GB her og ikke hadde noe L1, så... Da ville du straks hatt det problemet at det tok lengre tid, fordi det er så mange. 1 GB er enormt... Mange transistorer. Og det er jo fysiske systemer, dette her. Det er derfor vi har L1-cash, L2-cash, L3-cash osv. Man skulle jo ønske at så mye som mulig var nær CPU-en, men der er det fysiske begrensninger, så alt kan ikke være nær CPU-en. Og de størrelsene man har på L1, L2 og L3-cash, de har liksom blitt tilpasset og lagd sånn ut fra hardt... Hvordan kan man få det mest mulig effektivt? En grunn til at man da ikke lager LN-cash på én gigabyte, er at... ... er at det... Stort sett så er det ikke én gigabyte med data som brukes hele tiden om og om igjen. Ut fra statistikk av hvordan programmet kjører, har man funnet ut at... Sånn som med TLB, at det er 1 %... 99 % av tilfellene så treffer man med den TLB-en som ligger her, med kanskje bare 500K med data. Helt tett opp. Og da er det bedre å ha disse 500K med data veldig tett i CPU-en, sånn at det går lynraskt når de skal inn til registrene. Og så heller å ha én GB her ute med neste ledd. Men kanskje ikke så mye som 1 GB... Men appetitt-megabyte, i hvert fall. Og igjen så er det en sånn avveining. Hvis du skulle hatt 1 GB her,", "source": "lecture"}
{"lecture_id": "os13time2", "chunk_id": "os13time2_0021", "start": 3232.5, "end": 3345.78, "token_count": 365, "text": "med kanskje bare 500K med data. Helt tett opp. Og da er det bedre å ha disse 500K med data veldig tett i CPU-en, sånn at det går lynraskt når de skal inn til registrene. Og så heller å ha én GB her ute med neste ledd. Men kanskje ikke så mye som 1 GB... Men appetitt-megabyte, i hvert fall. Og igjen så er det en sånn avveining. Hvis du skulle hatt 1 GB her, så måtte det være plass til alle, og da ville det tatt lengre tid å få et vilkårlig bite herfra inn til CPU. Så dette med størrelsen på L1, L2, L3 Cash, de er nøye avveiet for å få det til å gå... Man kunne kjøre alt i cash. Ja, man prøver å lage cash større og større, men det er mye dyrere og krever mer strøm. Så det er begrensninger på det òg. Men utviklingen av CPU-er har hele tiden vært sånn at man legger inn mer og mer cash. Det er sånn Wars Law har funket de siste årene. Enda raskere. OK. Da tenker jeg at dere sikkert også trenger en pause. Det kan jeg holde på i noen timer til. Men vi stopper der. Og så tar vi heller og jobber med oppgaver. Det er oppgaver som går på akkurat dette her i denne uken. I neste uke.", "source": "lecture"}
