{"lecture_id": "os7time2", "chunk_id": "os7time2_0000", "start": 0.0, "end": 209.98, "token_count": 596, "text": "Ja... Da starter vi igjen. Aller først så var det et godt spørsmål i pausen om Output fra Time. Om... Så vidt jeg forstår spørsmålet, så var det hvorfor det er en liten forskjell på totaltiden. Og user og system, hvis du legger sammen. At det kan være større forskjell, men her ser du 4 pluss 12... Det blir ikke 5. 18. Og her er det også enda litt mer forskjell. Og svaret på det er at så skal ikke de nødvendigvis bli de samme. Og det kan vi også se av den prosenten bak her. Hvis den er 100 %, så skal de to være samme. For det betyr at da har CPU-en vært 100 % i bruk, og da vil du kunne se at de er like. Men i utgangspunktet så er denne kolonnen... Det er hvor mye CPU-tid som er brukt i såkalt jus. User mode er en modus av CPU-en hvor brukerprogrammet selv styrer alt og kjører CPU-en. Og det brukes stort sett hele tiden når man f.eks. regner, for da må brukerprosessen få tilgang til CPU-en og står og regner om og om igjen inni aluen. Og det er hvor mye tid operativsystemkjernen bruker på denne prosessen. Og hvis det er mye kall til disk og andre... områder... Eller mange kall til prosedyrer i operativsystemkjernen, så vil du se at... Skal vi se senere? Da kan man bruke mye tid her. Og sammenlagt så er dette hvor mye tid som... Som brukes da av CPU-en på denne prosessen. Men realtime, det er faktisk realtime, det er hvor lang tid det tar. Så realtime kan være dobbelt så lenge hvis det er to prosesser som... Hvis det er to prosesser som kjører, for eksempel... Ja, dette blir kanskje et dårlig eksempel. Hvis vi kjører de to sånne... Samtidig så... ja, så vil vel de kjøre på... De vil kjøre på samme CPU... Nei, de vil kjøre på hver sin. Sånn at de vil vel få en... Ja, de vil få en tilsvarende... Jo, vi kan se på et annet eksempel, men da passer det bra å ta en poll for akkurat det eksempelet vi skal se på. Det kan vi teste ut etter pollen.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0001", "start": 173.52, "end": 412.68, "token_count": 590, "text": "Ja, dette blir kanskje et dårlig eksempel. Hvis vi kjører de to sånne... Samtidig så... ja, så vil vel de kjøre på... De vil kjøre på samme CPU... Nei, de vil kjøre på hver sin. Sånn at de vil vel få en... Ja, de vil få en tilsvarende... Jo, vi kan se på et annet eksempel, men da passer det bra å ta en poll for akkurat det eksempelet vi skal se på. Det kan vi teste ut etter pollen. Så et lite spørsmål til alle... Man må jo til og med regne litt med papir og blyant hvis man ikke har en kalkulator eller er god i hoderegning. Spørsmålet e.r.: Hvis en 100 % CPU-avhengig prosess bruker 18 sekunder på én enkelt CPU, hvor lang tid bruker da fem slike prosesser på en server med fire CPU-er? Dette vil da være tilsvarende... 18 var kanskje ikke helt riktig, men jeg tenkte å teste ut med denne prosessen her, som tar omtrent 18 sekunder. Så problemstillingen er... Jeg kjører én enkelt prosess, og den bruker 18 sekunder. Men hvor lang tid tar det når jeg nå kjører... Hvis jeg da starter opp med en forløkke... Starter opp og kjører... Ja, jeg ser vi har fått inn en del svar allerede. Det er i hvert fall veldig mange riktige svar her, så dette ser bra ut. Ja... begynner det å se ut som de flere... Nei, det er fortsatt... Bruk gjerne litt mer tid på det, så kan vi etterpå både... Prøve å kjøre og se hvordan det ser ut i praksis, og så kan vi prøve å regne det ut. Ja, skal vi se. Nå tror jeg 75 % av dere her har svart. Ja, vi kan stoppe der. Så kan jeg prøve å dele resultatene, men da ser dere kanskje ikke... Jo, det ser dere der. Sånn. Dere ser Polly-resultatene nå? Rune er med oss også. Rune, hører du meg? Ja, det kan jeg. Du hører meg. Flott. Supert. Da er du med i denne andre timen, og så svarer du på spørsmål hvis det er noe jeg ikke får med meg. Eller hvis et eller annet galt skjer.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0002", "start": 360.0, "end": 577.88, "token_count": 598, "text": "Ja, vi kan stoppe der. Så kan jeg prøve å dele resultatene, men da ser dere kanskje ikke... Jo, det ser dere der. Sånn. Dere ser Polly-resultatene nå? Rune er med oss også. Rune, hører du meg? Ja, det kan jeg. Du hører meg. Flott. Supert. Da er du med i denne andre timen, og så svarer du på spørsmål hvis det er noe jeg ikke får med meg. Eller hvis et eller annet galt skjer. Supert. Ja. Rune, du ser Polla-resultatene nå? Ja. Flott. Ja, som vi ser... 75 % av dere har gått for 22,5 sekunder. Og det er veldig bra. For det... Det er i hvert fall det jeg trodde svaret skulle bli. Så vi kan gjøre to ting. Vi kan kjøre det her. Og mens det står og kjører, så kan vi prøve å regne på det. Så... Utgangspunktet var at vi hadde fem prosesser. Prosesser... Og hver av de bruker 18 sekunder. Og så har vi da fire CPU-er som de fem prosessene skal fordeles på. Så da er det typisk at 0, 1, 2, 3 kjører sånn. De vil jo da kjøre parallell, men så må nummer 4 settes på en av de andre CPU-ene. Og da, som vi så tidligere, så er dette bare et øyeblikksbilde. Man bytter da på hvilke CPU-er som har to prosesser av gangen. Sånn at totalt sett så fordeles tiden likt. Og da... Ja, det kan være litt sånn... Det kan være flere måter å regne det ut på. Men det som jeg tenker kanskje er den enkleste måten, og gjerne bruke andre måter, det er at hvis du har fem prosesser som skal kjøre i 18 sekunder, så trenger de... Hver av de trenger 18 CPU-sekunder. Så vi kan regne oss i 5 CPU ganger 18... Så mange CPU-sekunder trenger man for å utføre de jobbene ferdig. Og 5 ganger 18... 548... Det skulle bli 90 CPU-sekk. Og da... Når du har 90 CPU-sekunder, og så skal du dele det på... De må jo fordeles på fire sepuuer. For hvis alle de fire sepuuene kjører så mye de kan", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0003", "start": 529.02, "end": 744.32, "token_count": 587, "text": "så trenger de... Hver av de trenger 18 CPU-sekunder. Så vi kan regne oss i 5 CPU ganger 18... Så mange CPU-sekunder trenger man for å utføre de jobbene ferdig. Og 5 ganger 18... 548... Det skulle bli 90 CPU-sekk. Og da... Når du har 90 CPU-sekunder, og så skal du dele det på... De må jo fordeles på fire sepuuer. For hvis alle de fire sepuuene kjører så mye de kan av de 90 sepuu-sekundene hele tiden, så vil det bli fordelt på den måten der. Og dermed får man 90 fjerdedelssekund. Og 90 fjerdedeler er 45,5... Og det blir da 22,5 sekunder. Så det er derfor... Veldig bra at tre fjerdedeler av dere har kommet fram til at dette bør ta 22,5 sekunder. Og så kan vi også se på fasiten. Jeg tror ikke den er helt 22,5 sekunder, men vi kan se... Her var det faktisk ikke så veldig fair. Den stoppa, ser du det sultne... Vi ser her... Her var det litt forskjell i CPU-bruken. Det burde jo vært 80 %, men vi ser at den her faktisk fikk 88 %. Så den var nede i 21 sekunder, mens denne fikk bare 76 og var oppe i 24. Så her var ikke schedulerne helt feil. Varierer litt også om det er mye annen trafikk på serveren. Men vi ser røft i snitt så ville det blitt 22,5 hvis operativstemma hadde klart å fordele dette helt likt. Men her kan vi også se et eksempel på det spørsmålet som kom tidligere. Her ser vi at hvis man legger sammen user og system, Og i hvert fall ikke her. Og det er fordi at dette er liksom... Totalen her er hvor mye CPU-tid den prosessen her trenger. Og dette tallet her kommer da rett og slett fram for at... Dette er i hvor mange prosent den faktisk hadde. Og dermed så tar realtiden... er blitt realtiden mye lengre. Den blir av 24 sekunder. Ok. Da skal vi fortsette der vi slapp. Og hvor var det vi slapp? Her, ja. Med multitasking og multiprosessing.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0004", "start": 693.56, "end": 904.8, "token_count": 589, "text": "Og det er fordi at dette er liksom... Totalen her er hvor mye CPU-tid den prosessen her trenger. Og dette tallet her kommer da rett og slett fram for at... Dette er i hvor mange prosent den faktisk hadde. Og dermed så tar realtiden... er blitt realtiden mye lengre. Den blir av 24 sekunder. Ok. Da skal vi fortsette der vi slapp. Og hvor var det vi slapp? Her, ja. Med multitasking og multiprosessing. Og multiprosessing. Det er mange begreper som man må forholde seg til. Her er en liten oppsummering av noen av begrepene. Multitasking, eller multiprogramming, det er det som vi har sett på når operativsystemet fordeler tid på samme CPU. Den lar da flere prosesser dele på CPU-en. Og så dele ut tid til hver prosess. Det er multitasking. Multiprosessing er når to eller flere CPU-er samtidig kjører flere prosesser. I samme datamaskin kan du f.eks. ha fire CPU-er. Og hver av de kan da jobbe på én prosess helt samtidig, og det er multiprosessing. Og så har du det som kalles symmetrik multiprosessing. Da er det... Jo, den vesentlige forskjellen her er at da deler du på samme internmine. I multiprosessing så trenger du ikke å dele på samme internmine engang. SMP er det som er vanlig når du kjører i en server, sånn som de eksemplene vi har sett på tidligere. Da er... Alle prosessorene er da koblet til samme internminer. Og så kjører de helt samtidig i virkeligheten, i sanntid samtidig. Men det vi har sett på eksempler på hele tiden, er at vi har SMP samtidig som vi har multitasking. For operativstemme fordeler da mange prosesser på samme CPU, men samtidig så er det mange som kjører i parallell. En liten forskjell der er at da... Når du sier multicore, så sitter da flere prosessorer på samme brikke. Altså multicore. Core er en kjerne eller en regneenhet. De sitter da på samme brikke og deler også cash. Og kjører prosesser samtidig. Og det regnes også som SMP. Og her er det heller ikke så veldig store forskjeller.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0005", "start": 863.08, "end": 1049.8, "token_count": 587, "text": "men samtidig så er det mange som kjører i parallell. En liten forskjell der er at da... Når du sier multicore, så sitter da flere prosessorer på samme brikke. Altså multicore. Core er en kjerne eller en regneenhet. De sitter da på samme brikke og deler også cash. Og kjører prosesser samtidig. Og det regnes også som SMP. Og her er det heller ikke så veldig store forskjeller. I praksis så vil du ikke merke noen forskjell om det er SMP eller Multicore. Og du kan også ha en kobling av dette her. Altså at du har... En CPU-brikke med fire kjerner. Og så er det to sånne CPU-brikker inne i den samme maskinen. På det samme motherboardet. Og jeg vil dele interne mine. Så det var noen begreper. Skal vi se på noen eksempler på disse begrepene? Ja. Her ser vi fra venstre mot høyre... For det første singelprosessor, sånn som det var i gamle dager. Nå er det nesten umulig å oppdrive noen som helst prosessor som ser sånn ut. Dette er en duel-prosessor. Da ser vi at det er to separate brikker. Som sagt, man merker ikke så veldig stor førsel på det og den ved siden av, som er duel-core. Men her er det to separate fysiske brikker som du kan ta inn og ut av maskinen. Men begge er da koblet til samme ramm, men de har hver sin cash. Og så har vi to eksempler på multicore-prosessorer. Dette er en dual-core AMD-prosessor. Her ser vi CPU, eller da regneenheten, ALU, registeren og alt dette her, sitter inne i CPU. Og så har vi to atskilte L1- og L2-cash. Og så har du en dual-core Intel-prosessor som er litt annerledes. Her har du CPU med L1-cash, men så ser vi at L2-cash er felles. Og hva som er best av disse arkitekturene, det varierer litt. Som sagt så er det vanlig at man legger på en L3-cash her også, som f.eks. kan være felles. Men hva som er best, det kan variere litt med hva slags load du har på prosessoren. Hva den skal kjøre, altså på den serveren.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0006", "start": 1013.68, "end": 1237.56, "token_count": 600, "text": "Og så har du en dual-core Intel-prosessor som er litt annerledes. Her har du CPU med L1-cash, men så ser vi at L2-cash er felles. Og hva som er best av disse arkitekturene, det varierer litt. Som sagt så er det vanlig at man legger på en L3-cash her også, som f.eks. kan være felles. Men hva som er best, det kan variere litt med hva slags load du har på prosessoren. Hva den skal kjøre, altså på den serveren. Noen ganger, så... Hvis det er veldig mange like prosesser som deler veldig mye, så kan det være en fordel å ha mye felles cash. Men hvis de hele tiden gjør helt forskjellige ting, så kan det være en fordel å ha hvert sitt cash på denne måten her. Så der er det ikke noen fasit på hva som er best av det. Intel Core AMD K10. Dette er noen ikke helt nye CPU-er. De fleste CPU-er ser ganske like ut som disse her i dag. Dette her ser vi er en fire-core CPU. Så Intel Core E7, den har denne arkitekturen her. Så her ser vi... Det er fire CPU-er. Hver har L1-cash og L2-cash separat. Og så har de en felle. AMD-K10 er ganske lik. Den har litt mer L2-cash. Ellers er de ganske like. Neste punkt vi skal se på, er hypertrening, men vi kan se på... Et eksempel til før vi går inn på det. For... Skal vi se... Skal jeg finne riktig vindu? Linux-VM-ene deres kjører. Eller det vil si... Egentlig er det dokkercontainere. Dokker PC-er, så får jeg opp 100 forskjellige dokkercontainere. Som er de dere kjører. Men det jeg egentlig skulle se på, var... LSCPU, den sier litt om... Gir litt informasjon om CPU-en.  Og her så ser vi... Her står modellnavnet AMD Epic. Epic er en... Eller Epic 7552. Det er da modellnavnet på denne prosessoren. Og den bruker Zen Z1-mikroarkitekturen, som er en mikroarkitektur som AMD har designet. Og mikroarkitektur, det er... Og litt om det i notatene i dag. Det er på en måte hvordan instruksjonssettet er implementert av AMD.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0007", "start": 1197.26, "end": 1400.0, "token_count": 580, "text": " Og her så ser vi... Her står modellnavnet AMD Epic. Epic er en... Eller Epic 7552. Det er da modellnavnet på denne prosessoren. Og den bruker Zen Z1-mikroarkitekturen, som er en mikroarkitektur som AMD har designet. Og mikroarkitektur, det er... Og litt om det i notatene i dag. Det er på en måte hvordan instruksjonssettet er implementert av AMD. For instruksjonssettet, det er X86. Og Intel lager også CPU-er som implementerer dette institusjonssettet. Dvs. Move og Ad og alle disse institusjonene er helt like. Sånn at kode som kjører på AMD, den kan også kjøre Men hvordan dette her er implementert med LN-cash og med mikrooperasjoner og med pipelining osv., det er forskjellig fra prosessor til prosessor. Og AMD og Intel har hatt helt forskjellige approaches i mange tilfeller. Vi ser dette er en 48-corer-prosessor, men den har SMT, simultaneous multi-tredding. Og det er noe av det vi skal se på nå. Det er en helt annen tippemultetrening som foregår helt på prosessornivå. Men vi ser at den har 48 courses per socket. Og så har den... Et eller annet sted her så står det... Threads per core er 2 her, ja. Så totalt sett så har den hatt 96... Uavhengige treads. Vi skal se litt nøyere hva det egentlig betyr. Men så kan vi også se på cash. Her ser vi det er ganske mye cash. LND er datacash. LNI er instruksjonscash. Og... Så LNCash er på 3 MB. L2 er på 24... Og eldre på hele 192. Og det er ganske mye mer enn det vi så på AMD K10. OK. Så det var AMDoc, som er serveren som dere kjører på. Så når dere er inne på VM-ene og kjører LSPU, så er det... Dockercontainere deler på den underliggende operativsystemet, og da selvfølgelig også den underliggende serveren med serverservene. Til forskjell fra virtuelle maskiner, så kan du med dockercontainere... Når du lister, så vil du se den virkelige, fysiske serveren.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0008", "start": 1347.24, "end": 1554.32, "token_count": 588, "text": "Og eldre på hele 192. Og det er ganske mye mer enn det vi så på AMD K10. OK. Så det var AMDoc, som er serveren som dere kjører på. Så når dere er inne på VM-ene og kjører LSPU, så er det... Dockercontainere deler på den underliggende operativsystemet, og da selvfølgelig også den underliggende serveren med serverservene. Til forskjell fra virtuelle maskiner, så kan du med dockercontainere... Når du lister, så vil du se den virkelige, fysiske serveren. For containere sitter tettere på operativstemme enn det virtuelle maskiner gjør. Vi ses inntil senere. Da skal vi gå videre og se på hypertrading. Ja, hypertrading er opprinnelig en markedsføringsterminologi som Intel innførte. Det er altså Intels varemerke hypertrading. Som vi ser her nede, så er... Den generelle betegnelsen er SMT. Simultaneous Multitreading. Så når AMD bruker det samme prinsippet, så kaller de det for SMT. Men vi ser først på Intel og hyperthreading. Hyperthreading består i at én single core CPU, dvs. én CPU som har én enkelt alu, én regneenhet, én kjerne, Litt av innholdet i CPU-en er da duplisert. Spesielt registre. Man må ha egne registre for hver av de to prosessene. For det kan ikke lastes ut. Men dette foregår da på hardware-nivå. Så operativsystemet opplever dette som to selvstendige prosessorer. Men det som skjer i virkeligheten, er at når OS fordeler prosesser til denne prosessoren som er hypertraining, så settes det i gang to prosesser på samme CPU. Men de to prosessene deler da alønn som er på denne CPU-en. Da er det hardware som switcher kjøpt imellom de to prosessene. Dette skjer i løpet av nanosekunder. Altså ekstremt hurtig. Og dette er ikke i nærheten av det som skjer når man gjør contex-switch med OS. Det tar veldig mye lengre tid. Og denne teknologien er da lagd fordi man har sett at selv om man har pipelining og mikrooperasjoner som utføres i parallell på superskalare CPU-er,", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0009", "start": 1514.26, "end": 1745.6, "token_count": 594, "text": "Men de to prosessene deler da alønn som er på denne CPU-en. Da er det hardware som switcher kjøpt imellom de to prosessene. Dette skjer i løpet av nanosekunder. Altså ekstremt hurtig. Og dette er ikke i nærheten av det som skjer når man gjør contex-switch med OS. Det tar veldig mye lengre tid. Og denne teknologien er da lagd fordi man har sett at selv om man har pipelining og mikrooperasjoner som utføres i parallell på superskalare CPU-er, Det må hele tiden være litt hardware-ressurser som ikke blir brukt. F.eks. at alun ikke blir utnyttet fullstendig. Det er typisk fordi at selv med cash må man noen ganger vente på resultater, eller vente på noe fra RAM eller fra andre devices. Og denne ventetiden utnyttes av å lynhurtig switche frem og tilbake mellom de to prosessene som kjører. Og det er dette som er hypertrening. Det typiske er at de har egne registre for hver prosess, men deler felles alder. Etterpå skal vi kjøre noen tester, og da vil vi se at det går saktere når man har hypertrening, fordi de må dele på alderen. Og som jeg nevnte - hypertrening styrer, så har du vel. Så OS vet egentlig ikke noe om dette her. Jeg vet litt om det, men den er ikke med og styrer. Den bare gir prosesser til CPU-en, og så utfører CPU-en disse lynhurtige switchene mellom de to prosessene vi kjører. Ok. Da skal vi se på noen eksempler på hypertrening. Så da skal vi se... Da må jeg skifte om på å gå litt... Ja, da skal vi ta et eksempel fra den maskinen vi var på. Rex, for det er en... en desktop som har åtte sepur. Men så må jeg jobbe litt i bakgrunnen her. Og så må jeg... Hvis dere husker, så skrudde jeg av noen av sepurene hennes. Jeg lovte jeg skulle vise hvordan jeg gjorde det. Her er jeg nå på den Rex, en desktop. Den ser vi her når jeg taster én i topp, så får jeg opp at den har fire supper. Men her ser vi at jeg har en løkke som endrer på noe... Og den kan sette de forskjellige CPU-ene online.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0010", "start": 1690.96, "end": 1905.12, "token_count": 598, "text": "Men så må jeg jobbe litt i bakgrunnen her. Og så må jeg... Hvis dere husker, så skrudde jeg av noen av sepurene hennes. Jeg lovte jeg skulle vise hvordan jeg gjorde det. Her er jeg nå på den Rex, en desktop. Den ser vi her når jeg taster én i topp, så får jeg opp at den har fire supper. Men her ser vi at jeg har en løkke som endrer på noe... Og den kan sette de forskjellige CPU-ene online. Så det er åtte CPU-er her. Så det jeg gjør nå, er at jeg setter de resterende fire online. Sånn at hvis jeg nå taster topp og én, så ser vi - vips, så kom det fire CPU-er til. Så nå er denne en server. Eller en desktop med fire... Nei, med åtte CPU-er. Og hvis jeg gjør LSCPU, så ser vi også at dette her er... One-line CPU-list. Null til syv. Åtte CPU-er. Men så ser vi at det står to threads per core og core per sockets. Og vi ser også at dette er en Intel Core E7. Slår man opp på det, så vil man finne ut at denne her bruker hypertrening. Og min påstand nå er at dette er hypertrening. Den er faktisk... Det er egentlig ikke åtte helt uavhengige course, sånn som operativsystemet fremstiller det. Og sånn som det ser ut når man kjører topp eller hope-topp, så ser man at her er det åtte suppeur. Men vi skal nå se på hva... Hvordan ser det ut når vi kjører prosesser på disse åtte CPU-ene? Eller er det egentlig fire? Det er problemstillingen her nå. Er dette åtte helt selvstendige CPU-er? Eller er det fire CPU-er som kjører hypertraining og på en måte lurer OS til å... Til å tro at det er åtte? Så det første vi kan gjøre da, det er jo også å prøve å kjøre mange prosesser. Og så se hvordan det ser ut. Og vi hadde en fåløkke med reine... Ja, det ble det veldig mange. Én, to, tre, fire, fem. Det man kan gjøre litt enklere, er å si noe sånt. Da sier jeg har én til... Åtte prosesser. Så kjører jeg topp her samtidig. Oi. Nå ser jeg at jeg har feil vindu. Rop ut.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0011", "start": 1861.9, "end": 2082.64, "token_count": 600, "text": "det er jo også å prøve å kjøre mange prosesser. Og så se hvordan det ser ut. Og vi hadde en fåløkke med reine... Ja, det ble det veldig mange. Én, to, tre, fire, fem. Det man kan gjøre litt enklere, er å si noe sånt. Da sier jeg har én til... Åtte prosesser. Så kjører jeg topp her samtidig. Oi. Nå ser jeg at jeg har feil vindu. Rop ut. Ja vel. Jeg kan gjøre det på nytt. Det jeg gjorde, var at jeg startet... Nå er det åtte CPU-er som står og kjører her. Bare for å få det veldig eksplisitt, så kan vi sette på den last used CPU her nede. Da må jeg få utvide topp lite grann. Der, ja. Der har vi Las Jusipu. Så kjører jeg nå åtte prosesser. Og vi ser da 016728 osv. De kjører i parallell på disse åtte Sipuene. Sånn sett så ser det jo vel og bra ut. Men da er spørsmålet... Hvordan kan jeg finne ut nå? Er dette 100 %? Kjører de 100 % på helt uavhengige regneenheter? Eller er det hypertraining, som man kan lese at det faktisk er?  Og hvordan ser man i så fall forskjell på det? Jo, for å gjøre en lang historie kort, så kan man jo... Hvis det er hypertrening, så betyr det at da er det fire A-lur. Og hvis det da er åtte jobber som står og jobber, så er det klart... Da har operativsteamet satt inn to stykker på hver av CPU-ene. Og de må da bytte på. Og de må da dele på den aluen. Og det vil jo ikke da gå like fort å kjøre fire som å kjøre åtte. Så det vi kan gjøre, er å prøve å ta noen eksperimenter. Først så kan jeg prøve å kjøre fire jobber. Nå er de på hver sine CPU. Og kjører fulle ruller på dem. Og så kan vi se hvor lang tid tar egentlig det. Så dette er på en måte litt sånn som... Ja, altså, i notatene så har jeg et eksempel på... Hvis man har potetskrellere, altså personer som skreller poteter, som står inne i hver sin bod, så kan man jo teste...", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0012", "start": 2046.92, "end": 2234.5, "token_count": 590, "text": "Først så kan jeg prøve å kjøre fire jobber. Nå er de på hver sine CPU. Og kjører fulle ruller på dem. Og så kan vi se hvor lang tid tar egentlig det. Så dette er på en måte litt sånn som... Ja, altså, i notatene så har jeg et eksempel på... Hvis man har potetskrellere, altså personer som skreller poteter, som står inne i hver sin bod, så kan man jo teste... Hvis det er to personer som står inne der og deler en potetskreller. Så vil det måtte gå dobbelt så lang tid å skrelle poteter. Så det er potetskrelling jeg egentlig holder på med her. Vi ser når jeg kjørte åtte... Nei, når jeg kjørte fire... Så tok dette her realtime 18,5 sekunder. Usertime 18,5... Jo, det betyr at disse prosessene fikk tilgang til 100 % av CPU. Og da skulle også realtiden... Den totale realtiden skulle da være 18,5. Så dette er riktig. Sånn... Sånn bør det være. Men vi kan begynne å ane nå at dette tar mye lengre tid. Og vi ser faktisk... Jo... Dette tok nesten dobbelt så lang tid. Vi ser... 18 sekunder tok det for én CPU. Én prosess på én enkel CPU. Men når vi delte inn i åtte prosesser, så tok det 35,7 sekunder. Altså... 37 ville vært det dobbelte. Så vi kan se at vi har hatt en ørliten effekt av hyperthreading. Men stort sett så ser vi disse to prosessene her... De måtte faktisk dele på samme alu, og det er derfor det tok mye lengre. Nesten dobbelt så lang tid å regne ut. Det er også litt forvirrende, for det står fortsatt 99 %, men dette er sånn som operativsystemet ser det på. Men i virkeligheten så switcher de lynhastig frem og tilbake. Og da kan man jo lure på hvorfor er dette... Hvorfor er dette hypertrening så viktig i det hele tatt? Men da har vi et... Skal vi se... Et program som heter RAM2. Det er et program som bruker et RA. Og så gjør den en masse RA-operasjoner. Den leser masse inn og ut fra RAM.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0013", "start": 2186.66, "end": 2393.04, "token_count": 600, "text": "men dette er sånn som operativsystemet ser det på. Men i virkeligheten så switcher de lynhastig frem og tilbake. Og da kan man jo lure på hvorfor er dette... Hvorfor er dette hypertrening så viktig i det hele tatt? Men da har vi et... Skal vi se... Et program som heter RAM2. Det er et program som bruker et RA. Og så gjør den en masse RA-operasjoner. Den leser masse inn og ut fra RAM. Og da vil sånn som hypertraining kunne ha en effekt. Ramm2-programmet. Og så kjører det i stedet. Vi kan gjøre den samme testen. Vi kan kjøre én til fire. Nei... Det var... Det var feil. Sorry. Vi skulle ikke kjøre regn nå. Nå skulle vi kjøre Adopt-Alt. Sånn. Nå kjører jeg fire av de Ramm-programmene samtidig. Vi lar kjøre på hver sin CPU, og de bruker det fire sekunder. Og så setter jeg i gang åtte av dem. Hvis hypertraining ikke er noe effektivt nå, så ville dette tatt åtte sekunder. Men vi ser... Her hadde hypertraining plutselig en veldig stor effekt. For nå brukte vi realtid 4,3 sekunder. Mens her så brukte vi bare fire. Og dette viser hypertreading med sitt største potensial. Her så klarte Operativstemme da setter inn to prosesser på én og samme CPU med samme alu. Men siden her er det mye snakk med minnet, man må hele tiden vente for å... Her oppe så klarer ikke én prosess å utnytte CPU-en fullstendig. Derfor er hypertrening veldig effektivt, for da kan disse to stå og bytte på og gjøre de institusjonene de trenger på CPU-en. Og så får de gjort jobben veldig mye raskere. Men dette var de to ekstreme tilfellene. En regnejobb kan ikke utnytte hypertrening, men en rammejobb kan utnytte det veldig godt. Ofte så er det litt imellom, men i snitt så kan du kanskje få en sånn 30-40 % forbedring. Med hypertrening. Ok. Da skal... Ja, jeg ser vi har brukt ganske mye tid her. Jeg lurer på om vi skal utsette den biten med... Med hvorfor man ikke kan kjøre to prosesser samtidig. Vi kan se i stedet...", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0014", "start": 2348.2, "end": 2594.94, "token_count": 585, "text": "Men dette var de to ekstreme tilfellene. En regnejobb kan ikke utnytte hypertrening, men en rammejobb kan utnytte det veldig godt. Ofte så er det litt imellom, men i snitt så kan du kanskje få en sånn 30-40 % forbedring. Med hypertrening. Ok. Da skal... Ja, jeg ser vi har brukt ganske mye tid her. Jeg lurer på om vi skal utsette den biten med... Med hvorfor man ikke kan kjøre to prosesser samtidig. Vi kan se i stedet... Litt mer på hypertraining. Og spesielt så kan vi se på task-sett. For det er en interessant metode hvis vi... Jo, vi har sett at operativsystemet fordeler prosesser på CPU. Men nå skal vi se på en metode vi kan bruke for å selv spesifisere hvilken CPU en oppgave skal kjøres på. Og det kan vi gjøre med TaskSet. Og da kan vi time dette også. Men programmet TaskSet er et verktøy som gjør at vi kan se... Tasset minus C null sier plasser den følgende jobben på CPU0. Så når jeg kjører denne regnejobben her nå, så sier jeg at den skal så på CPU0. Da kunne jo kanskje... Hvis vi kjører AgeStop... Jeg kan kjøre Toppe. Skrur på Last Used CPU. For å se hvor den kjører. Der har vi med Last Used CPU. Så sier jeg start den på... Kjør den på prosessor 0, og da ser vi. Den kommer på. Hvis jeg i stedet sier kjør den på prosessor 1... Så ser vi. Da starter den å kjøre på 1. Det gjør at vi kan gjøre noen interessante eksperimenter, for da kan vi eksplisitt se nå vil jeg kjøre begge regnejobbene på prosessor 1. La oss bruke Adatat, som er litt raskere. La oss si nå... Jeg skal starte to regnejobber. Men så vil jeg da time task-sett, og så vil jeg sette begge på null. Sånn. Og nå vil begge de to regnejobbene kjøre på samme prosessor. Da får de bare 50 % CPU. Fordi da har jeg eksplisitt satt de på den samme CPU-en. Hvis jeg i stedet hadde satt de på CPU1 og -2 på den måten,", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0015", "start": 2536.24, "end": 2750.72, "token_count": 597, "text": "La oss bruke Adatat, som er litt raskere. La oss si nå... Jeg skal starte to regnejobber. Men så vil jeg da time task-sett, og så vil jeg sette begge på null. Sånn. Og nå vil begge de to regnejobbene kjøre på samme prosessor. Da får de bare 50 % CPU. Fordi da har jeg eksplisitt satt de på den samme CPU-en. Hvis jeg i stedet hadde satt de på CPU1 og -2 på den måten, da ville de to regnejobbene kjørt på hver sin CPU. Da gjør vi sånn som operativsystemet ville ha gjort det. Og det går da dobbelt så fort. Helt til slutt så kan vi se litt på... Se litt på hvordan man kan... Finne ut hvilke CPU-er som tilhører hvilken... Nei... Hvilke par det er av CPU-er som er hyperthrødding. Denne Thrød-siblings-list som jeg lister her, er en liste over hvilke CPU-er som hører sammen. Da kan vi se på denne her. I dette tilfellet så er det CPU-110 og -4 som egentlig er Thrød-siblings, som er de to som da deler på aluen. Helt til slutt så kan vi... Prøve å se om det er tilfellet. For jeg kan... Først kan jeg kjøre regnejobber på denne måten. Da sier je... Sett nå regnejobben på CPU1. Den første settes på CPU1, og den andre settes på CPU2. Hvor lang tid tar det nå å kjøre den regnejobben? Jo, det tar 18 sekunder. Men så kan jeg i stedet si... OK, nå vil jeg eksplisitt sette de to jobbene på 0 og 4. Dette betyr nå kjør den ene på 0 og kjør den andre på 4. Og det var ikke tilfeldig valg, for nå har jeg bedt dem om å kjøre regnejobbene på den samme hyperthreading-CPU-en. Så nå er det 0-4. De er siblings. Det betyr... De deler på en del av hardwaren, inkludert Sippuen. Så nå ser vi straks at dette tar lengre tid. De står på 0-4. Kunne si at de står på 0-4 her. Men tiden det tok, den var nå... Den ble da plutselig så godt som doblet. Det er fordi 0-4...", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0016", "start": 2712.14, "end": 2895.04, "token_count": 589, "text": "om å kjøre regnejobbene på den samme hyperthreading-CPU-en. Så nå er det 0-4. De er siblings. Det betyr... De deler på en del av hardwaren, inkludert Sippuen. Så nå ser vi straks at dette tar lengre tid. De står på 0-4. Kunne si at de står på 0-4 her. Men tiden det tok, den var nå... Den ble da plutselig så godt som doblet. Det er fordi 0-4... Det er akkurat samme kommandoen her. 1 og 2. I stedet her kjører vi på 0 og 4, og da er det på samme hypertrening CPU. Og da må du bytte på å dele aluen, og dermed går det dobbelt så lang tid å få det feil. OK... Jeg ser det er noen spørsmål i chatten her. Hadde også tatt fire sekunder om du kun kjørte ett, ja. Ja. Det var litt tilbake her. Men hvis jeg bare kjører én, så tar det også fire sekunder. Så om man kjører... Så. Det var vel den her. Hvis jeg bare kjører én prosess, sånn som dette, så tar det fire sekunder. Og hvis jeg da kjører fire uten noe task-sett eller noe som helst... Hvis jeg ikke bruker Tastset... Og kjører fire prosesser, så er dette fire helt uavhengige CPU-er. Og de bruker da like lang tid som om jeg kjører igjen. Vi kan se noen ganger at det tar litt mer tid. Og det er fordi at da kjører du 100 % på alle fire CPU-ene på en server. Og det er alltid noe prosesseringskraft som trengs på en server for å styre alle andre prosesser. Sånn at ofte så vil du se at det går litt mer tid. Men generelt sett så tar det omtrent fire sekunder. Om du kjører på én, eller om du kjører på fire. Men som vi har sett når vi da kjører på alle åtte, så... Og så tar det nesten dobbelt så lang tid fordi det egentlig er hypertrening. AMD har det samme, som på din IMDoc-serveren som dere har konteinere. Den har også hypertrening, eller AMDs hypertrening, som er SMT. Simultaneous Multitredding. Det er det også på den serveren.", "source": "lecture"}
{"lecture_id": "os7time2", "chunk_id": "os7time2_0017", "start": 2860.68, "end": 2967.7, "token_count": 335, "text": "Men generelt sett så tar det omtrent fire sekunder. Om du kjører på én, eller om du kjører på fire. Men som vi har sett når vi da kjører på alle åtte, så... Og så tar det nesten dobbelt så lang tid fordi det egentlig er hypertrening. AMD har det samme, som på din IMDoc-serveren som dere har konteinere. Den har også hypertrening, eller AMDs hypertrening, som er SMT. Simultaneous Multitredding. Det er det også på den serveren. OK. Men da stopper vi der, og så... Er vi nå... Jeg tror vi faktisk er tre studentassistenter. Så jeg skal sette opp break-out-rooms. Så der er det masse hjelp å få i dag. Og så må dere huske at det er oblig-innlevering, men det er først etter... etter konteuken. Så når dere er ferdig med oppgaven denne uken, så er det først etter... etter... etter... konteuken. Og så må dere også huske å ta MC1. Ta den så snart som mulig. Og så spør studentassistenten om hjelp hvis dere får mindre enn syv og må gjøre den om igjen. Da får dere kanskje noen gode tips også om hva dere bør se på før dere tar den en gang til. Da tar jeg en liten pause der og bygger opp Break Old Rooms.", "source": "lecture"}
