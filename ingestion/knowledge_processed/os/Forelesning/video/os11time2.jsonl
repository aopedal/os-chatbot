{"lecture_id": "os11time2", "chunk_id": "os11time2_0000", "start": 0.0, "end": 219.28, "token_count": 582, "text": "Før pause så vi på et prioriteringseksempel med Java på Linux. Og så lovte jeg at jeg skulle prøve å kjøre på Windows. Og det er det jeg prøver å gjøre nå. Aller først var det et spørsmål om hvordan å kopiere filer fra... Fra Windows til Studie-SSO. Da fins et par måter å gjøre det på. Det beste som vi kommer tilbake til etter påske når vi skal se på Windows, er å installere Open SSO på Windows, for da kan man kopiere med SEP. Sånn som dette. Bare sp.prio.java. Eller tilsvarende over på Studiesocial. Og så skrive passord. Så kopierer man... Så blir filen kopiert over direkte. Det er mulig å sette opp passordnøkler også. Da kan man få enda mer direkte over. Et alternativ er å installere... VIN-SEP. Hvis man søker på VIN-SEP, så er det den første siten man kommer til. Så kan man installere derfra. Og det er... et guieprogram som ser ut noe sånt som dette her. Så man da kan... Hvor jeg da har logget meg inn på denne serveren. Studio SSO i deres tilfelle. Og så kan man ta bare filer og kopiere. Frem og tilbake, sånn som dette er. Ved å peke og klikke. Men fra kommandolinja så kan man gjøre dem, som sagt, med SFP, hvis man installerer OpenSSO på Windows. Installere... Jeg tror man faktisk bare kan aktivere det, at det er en modul som kan aktiveres. Ok. Da skal vi se på Java-tråder på windows. Jeg har kopiert over den samme mappa. Det er prio.java. Så jeg kan kjøre den. Eneste forskjellen var at jeg... Ba den første tråden om å sove i 3000 millisekunder. Altså i tre sekunder. Men vi kan se av kjøringen hva slags prioriteter vi har. Tråd nummer to starter med prioritet 10, så den har høyest prioritet. Etter tre sekunder starter tråd nummer én med prioritet 5. Windows tar virkelig hensyn til prioriteten. Den kjører bare tråd nummer to fordi den har høyest prioritet. Men så ser vi... Nå endrer vi prioritet for tråd nummer to. Og så endres den til fire.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0001", "start": 180.0, "end": 405.44, "token_count": 595, "text": "Men vi kan se av kjøringen hva slags prioriteter vi har. Tråd nummer to starter med prioritet 10, så den har høyest prioritet. Etter tre sekunder starter tråd nummer én med prioritet 5. Windows tar virkelig hensyn til prioriteten. Den kjører bare tråd nummer to fordi den har høyest prioritet. Men så ser vi... Nå endrer vi prioritet for tråd nummer to. Og så endres den til fire. Og da er det tråd nummer én som har prioritet fem. Den kjører hele tiden. Så vi ser det er en enorm forskjell i prioriteter. Hvis en tråd har høyere prioritet enn en annen, så tar den omtrent alt som er av CPUT-tid. Så mens Linux default ikke bryr seg om Java-prioritet, så tar Windows ekstremt stor hensyn til det. Det er altså... Hvis man ser på prioritet i Windows, så er den veldig sterk. Altså hvis man endrer prioritetsklasser, så får man en veldig stor effekt. Og det ser vi tydelig her. Hadde prioritet fire. Den var enerådende i praksis hele veien. Mens tråden som hadde prioritet nummer fem, den måtte i praksis vente til den andre var ferdig. Og så fullførte den sin jobb. Så vi kan konkludere at implementasjonen av prioritet på Java den er plattformavhengig. Men også, som sagt, så skredulerer operativstemme, altså både Windows og Linux, veldig bra med default prioritet. Sånn at dette her er ikke opplevd som noe veldig stort problem. Man kan jo da også individuelt omprioritere med nice, f.eks. Eller på andre måter prioritere. Men stort sett så er operativsystemet... Moderne operativsystemer er så gode på å gi respons til de som trenger det interaktivt, og gi da en litt saktere respons til prosesser som bruker mye CPU. Og dette gjør da operativsystemene dynamisk på en så bra måte at det som regel ikke er noe stort behov for programmereren å gi Gi egne prioriteringer til prosesser. Ok, da skal vi gå videre med serialisering. Med mindre det er noen andre spørsmål? Skal vi se... Skal prøve å finne den sliden her. Der er vi. Ja, så...", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0002", "start": 338.6, "end": 560.24, "token_count": 589, "text": "til de som trenger det interaktivt, og gi da en litt saktere respons til prosesser som bruker mye CPU. Og dette gjør da operativsystemene dynamisk på en så bra måte at det som regel ikke er noe stort behov for programmereren å gi Gi egne prioriteringer til prosesser. Ok, da skal vi gå videre med serialisering. Med mindre det er noen andre spørsmål? Skal vi se... Skal prøve å finne den sliden her. Der er vi. Ja, så... Problemstillingen er at... Hvis man jobber med fellesdata, så må man serialisere. Hvis ikke, så skal vi... Som vi skal se... Da kan man slåss om å bruke en felles variabel og ødelegge hele datagrunnlaget. Resultatene kan bli helt feil. Et enkelt eksempel på dette er... Hvis vi tenker oss at vi har en webside som skriver ut billetter. En database som holder på antallet billetter. Så det ville jo kanskje gjøre dette enda mer komplisert, at du må koble deg opp mot databasen osv. Men da vil jeg alltid tenke på at vi må ha en trådsikker database. Det er da en database som er serialisert, hvor dette er tatt hensyn til. Men vi kan også tenke oss at vi bare har én webserver... Hvor det er to prosesser som står og kjører. Og begge må da ha tilgang til antall billetter. Ellers kan de ikke dele ut billetter i det hele tatt. Så i dette tilfellet tenker vi oss at vi har én variabel, ledige billetter, som sier hvor mange ledige billetter som finnes. Så kan vi tenke at koden for webserveren er noe sånt som dette her. Hvis ledige billetter er større enn null... Jo, da trekker vi fra lederbilletten med én, og så skriver vi ut en billett. Det ser jo enkelt og greit ut, men vi kan da få et mulig problem. Og det problemet er... Hva skjer hvis man er litt uheldig, og Prosess1 står og kjører og sjekker at det er lederbilletter? Men så vet vi at en sånn if-test utføres ikke i én instruksjon. Det er først en if. Først vil det være en compare av ledigbilletter med null, og se om den er større enn null.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0003", "start": 510.0, "end": 695.7, "token_count": 590, "text": "Jo, da trekker vi fra lederbilletten med én, og så skriver vi ut en billett. Det ser jo enkelt og greit ut, men vi kan da få et mulig problem. Og det problemet er... Hva skjer hvis man er litt uheldig, og Prosess1 står og kjører og sjekker at det er lederbilletter? Men så vet vi at en sånn if-test utføres ikke i én instruksjon. Det er først en if. Først vil det være en compare av ledigbilletter med null, og se om den er større enn null. Og i dette tilfellet så vil dette slå til. Men før Prosess1 har rukket å minske ledigbilletter, Så skjer det en contact switch. Så hopper jeg over til prosess 2. Og så utfører den den samme. Den sjekker at ledigbilletter er større enn null. Ja, ledigbilletter er større enn null. Og så trekker den fra. Og så skriver den ut en billett. Og så ser vi... Så gjør... Kommer vi etter den contact switchen, så kommer den tilbake. Ledigbillett til minus, minus. Den blir ned i minus én, og så skriver den ut. Enda en billett. Og det er klart det er to stykker som har fått billetter. Og her er det noe som går helt galt. Så på denne måten kan man ikke ha det. Så man må serialisere. Og man må sørge for at noe sånt som dette her ikke kan skje. Lett å forestille seg at dette kan skje, siden det er flere kodeoperasjoner involvert, at man først sjekker LED-billetter, og så trekke dem fram. Her er det en context match. Det tilfellet man også har, er at P1 og P2 kjører på hver sin CPU. Da vil det være enda mer problematisk, for da vil ikke de kunne... Sjekke seg imellom. Da vil de hente ned lederbilletter til sin CPU uten å sjekke om den andre da har gjort det. Så da er det enda vanskeligere å serialisere. Men vi skal også se at vi kan ha en race condition selv om det bare er én enkelt kodelinje.  Og en problemstilling for dette er at én linje høynivåkode... Selv om man bare ser koden, så ser man at dette er bare én linje.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0004", "start": 654.64, "end": 826.16, "token_count": 600, "text": "Da vil det være enda mer problematisk, for da vil ikke de kunne... Sjekke seg imellom. Da vil de hente ned lederbilletter til sin CPU uten å sjekke om den andre da har gjort det. Så da er det enda vanskeligere å serialisere. Men vi skal også se at vi kan ha en race condition selv om det bare er én enkelt kodelinje.  Og en problemstilling for dette er at én linje høynivåkode... Selv om man bare ser koden, så ser man at dette er bare én linje. Så her kan det ikke skje noe galt med race condition. Men som vi har sett tidligere, så kan ofte én linje med høynivåkode oversettes til flere linjer med maskinkode. Og i noen tilfeller så er det helt nødvendig, og det vil faktisk skje. Og en context switch kan oppstå når som helst mellom to maskininstitusjoner. For vi har sett mange ganger at operativsystemet aner ikke noe egentlig om hva de forskjellige... Om hva de forskjellige institusjonene betyr, og hva de gjør. Så operativsystemet bare sier ok, kjør. Institusjon, institusjon, institusjon. Sånn. Når som helst kan det komme en kontekstveksling. Og hvis prosessen opererer på to forskjellige CPU-er, har man operativstedet med enda mindre kontroll. Da skal vi se på et eksempel med to prosesser som oppdaterer én felles variabel. Og da er det en saldo de oppdaterer. Og her ser vi koden for P1. Så gjør den et eller annet sted saldo alik saldo minus mill. Så den trekker fra en million kroner på saldo. Tilsvarende gjør P2. Gjør noen operasjoner, og så øker den saldo med én. Og da er det lett å tenke sånn at ja, dette her er bare én operasjon. Så om disse to kjører samtidig, så vil ikke det noe ha noe å si. For først trekker den fra 1 mill., og så ligger den til 1 mill. Man skulle tro at dette, spesielt hvis man kjører på samme CPU, burde gå fint. Men hva skjer egentlig hvis det på et uheldig sted kommer en Context Switch fra P1 til P2? Jo, da må vi tenke på maskinarkitektur.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0005", "start": 789.8, "end": 959.68, "token_count": 582, "text": "Og da er det lett å tenke sånn at ja, dette her er bare én operasjon. Så om disse to kjører samtidig, så vil ikke det noe ha noe å si. For først trekker den fra 1 mill., og så ligger den til 1 mill. Man skulle tro at dette, spesielt hvis man kjører på samme CPU, burde gå fint. Men hva skjer egentlig hvis det på et uheldig sted kommer en Context Switch fra P1 til P2? Jo, da må vi tenke på maskinarkitektur. Og at det faktisk... ... prosesser gjør, er å utføre maskinkode. I dette tilfellet er det maskinkode for X86, altså rett på hardware. Men vi skal se senere at vi har det tilsvarende når vi kjører i Java. JVM utfører bite-kode. Så... Og da vil disse operasjonene, sånn som saldo..... Denne operasjonen kan ikke utføres av én enkelt maskininstitusjon. Det har vi sett tidligere. X86 tillater ikke to referanser til minnet samtidig. Så på en eller annen måte, uansett hvordan man kompilerer dette, eller om man skriver assembly-kode selv, så må man gjøre noe tilsvarende dette her. Man kunne gjort det kanskje et step videre, men noe tilsvarende som dette må skje. Og flytte saldo inn i et register. Og så har vi mill. Det ligger også ute i minnet. Så vi flytter det inn i BX. Og så legger vi BX til AX. Da har vi lagt til saldo liks saldo pluss mill. Og så legger vi resultatet ut i saldo. Og så er det tilsvarende for subtraksjon. Og da får vi et problem. Da kan vi risikere at en million forsvinner. Og... da tenker vi oss at saldo er 5 først. Og så begynner vi med prosess 1, som trekker ifra. Den flytter saldo og mill inn i registrene sine. Og så skjer en context switch. Og da er det viktig å huske på at ved en context switch må alt lagres. Så alle registerverdier lagres da for den prosessen. Og så kommer prosess 2 inn. Det gjør det samme, men flytte saldo og mill inn i AXLX. Allerede her aner vi at her kan ting gå galt.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0006", "start": 920.28, "end": 1124.14, "token_count": 590, "text": "Og... da tenker vi oss at saldo er 5 først. Og så begynner vi med prosess 1, som trekker ifra. Den flytter saldo og mill inn i registrene sine. Og så skjer en context switch. Og da er det viktig å huske på at ved en context switch må alt lagres. Så alle registerverdier lagres da for den prosessen. Og så kommer prosess 2 inn. Det gjør det samme, men flytte saldo og mill inn i AXLX. Allerede her aner vi at her kan ting gå galt. Denne P2 vil da ta og legge én mill til de fem eksisterende, sånn at den får AXLX. Så flytter den verdien ut, sånn at det blir seks millioner her ute. Så, før eller senere, skjer det en context switch tilbake til Prosess1. Prosess1sub Bx minus Ax. Men den bruker jo de gamle verdiene. Altså, den tar og trekker fra saldoen. Fem minus én, og da får den fire. Og så flytter den resultatet ut i saldo, og saldoen har blitt fire. Opplagt i dette tilfellet så burde jo saldoen ha blitt fem. Og én million er borte. Alltid kjedelig fra en saldo. Så konklusjonen her er at dette må opplagt serialiseres. Og det man må gjøre, er å serialisere aksess til felles data. Å serialisere betyr at først gjør P1 seg ferdig med sine operasjoner med saldo, og så gjør P2 seg ferdig. Eller motsatt. Men de må ikke kunne gjøre det samtidig. Akkurat dette kalles et kritisk avsnitt. Når en prosess gjør en operasjon på en felles variabel, da er det et såkalt kritisk avsnitt. Og ideen med å serialisere er at kritisk avsnitt må fullføres i sin helhet før den andre prosessen slippes til. For å få til dette fins det en rekke forskjellige metoder. Men det skal vi se på neste gang, hva slags metoder man kan bruke for å fikse dette. Nå skal vi se på noen eksempler på hvordan dette ser ut i praksis med Java og med Petrads for tiden. Ja, da... Skal vi se. Da har vi... Et ja-program her som heter saldo. Og det skal vi studere nå.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0007", "start": 1059.68, "end": 1290.16, "token_count": 593, "text": "må fullføres i sin helhet før den andre prosessen slippes til. For å få til dette fins det en rekke forskjellige metoder. Men det skal vi se på neste gang, hva slags metoder man kan bruke for å fikse dette. Nå skal vi se på noen eksempler på hvordan dette ser ut i praksis med Java og med Petrads for tiden. Ja, da... Skal vi se. Da har vi... Et ja-program her som heter saldo. Og det skal vi studere nå. Det gjør litt av det samme som det saldoprogrammet. Vi så på jordet, men i vårt tilfelle så er det to saldotretts. Det er da to tråder, S1 og S2. Ja, saldo av 1000. Den bare sover 1000 millisekunder. Det spiller ingen rolle i dette tilfellet. Men det som er viktig, er at vi har en public static int-saldo. Det er en static in saldo, så det betyr at den er felles. Og så har vi to tråder som oppdaterer denne saldoen. Og det som vi ser, skjer, er hvis ID er lik 1, så økes saldoen med én maks antall ganger. Hvis ID er to, så minskes saldoen med én. Og da er det klart. Ja... Maks er et svært tall. Det er én million. Så det er klart, hvis du øker en saldo én million ganger med én, og så minsker den... Eller samtidig minsker den én million ganger med én, så burde det ende opp med null til slutt. Men... Da skal vi se hvordan det ser ut. Og vi kjører den. Den jobba. Ja. Da starter to tråder, begge med samme prioritet. Det spiller ikke så stor rolle. Men så ser vi et eller annet galt her... skjer. Den endelige, totale saldoen er 38 000. Og hvis vi prøver å kjøre på ny... Så ser vi at det ble 92 000. Og her... Det er 27 642. Så vi ser at hver gang vi kjører, så får vi en helt annen verdi. Og her ble det minus 32 000. Og dette ser jo veldig merkelig ut. Men det er akkurat den effekten vi så i eksempelet. Med saldo og 1 mill. som blir borte. Det er ikke noen serialisering mellom trådene.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0008", "start": 1242.7, "end": 1447.48, "token_count": 600, "text": "Den endelige, totale saldoen er 38 000. Og hvis vi prøver å kjøre på ny... Så ser vi at det ble 92 000. Og her... Det er 27 642. Så vi ser at hver gang vi kjører, så får vi en helt annen verdi. Og her ble det minus 32 000. Og dette ser jo veldig merkelig ut. Men det er akkurat den effekten vi så i eksempelet. Med saldo og 1 mill. som blir borte. Det er ikke noen serialisering mellom trådene. Sånn at de vil hente inn den samme saldoverdien, og så vil de endre den. Og her ser vi at vi får en veldig stor effekt, fordi at... De vil gjøre mange operasjoner. Øke saldoen med 30 000, kanskje. Og så kommer den andre inn, og den har da allerede lest inn den samme verdien. Og så fortsetter de å jobbe med den. Så her blir... Forskjellene blir veldig store. Og det som kan være interessant da, er altså å se på... Hvordan er det egentlig Javakoden som... Hvordan ser Javakoden som... Kjører dette her. Hvordan ser den ut? Og da er det en egen... Det er en egen applikasjon, JavaP, som kan vise Java Byte-kode. Men hvis vi tar på minus private, så får man se akkurat den koden som kjører saldotråden. Kjøre den kommandoen... Så det jeg gjorde, var Java Payments Private på saldotredd. Og det vi ser her, det er Java Byte-kode. Så jeg ser... Ja, det kan jo minne litt om Assembler-kode. Den eneste forskjellen er at Assembler-kode er for X86 fysiske maskiner. Javabyte-koden er for en Java-virtuell maskin. Og... da kan vi prøve oss å finne ut... Jo, her er det en update-saldo. Det er den metoden som oppdaterer saldoen. Da kan vi se at det er to områder her. Her er det en e-ad, og her er det en e-sub. Og dette er de to områdene som saldoen blir oppdatert i. Og hvis vi konsentrerer oss om den delen som gjør... Dette er da tråd 1, som gjør saldo pluss, pluss. Og da skal jeg ikke gå så veldig inn på dette i detalj,", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0009", "start": 1412.16, "end": 1583.32, "token_count": 595, "text": "Jo, her er det en update-saldo. Det er den metoden som oppdaterer saldoen. Da kan vi se at det er to områder her. Her er det en e-ad, og her er det en e-sub. Og dette er de to områdene som saldoen blir oppdatert i. Og hvis vi konsentrerer oss om den delen som gjør... Dette er da tråd 1, som gjør saldo pluss, pluss. Og da skal jeg ikke gå så veldig inn på dette i detalj, men JVM er en såkalt stackmaskin. Det vil si at den legger variabler på stacken, og så opererer den på stacken. Det som faktisk foregår her, er... Her er det get static. Det betyr hent inn saldoen. Så hvis saldoen er 50, så legges tallet 50 på stacken. Og så icons 1. Den legger tallet 1 på stacken. Og eAdd, den legger sammen de to tallene. Så da tar den 50 pluss 1 får 51. Puts Attic... og legger verdien ut. Og helt tilsvarende skjer med Sub her nede. Og da er det klart. Da ser vi med en gang at dette tar litt tid. Først så hentes verdien inn og legges på sacken. Og da... Dette implementeres jo da igjen av JVM, som så kjører maskinkode som gjør dette her. Så det som er tydelig, er at saldo blir... Og så legges det i registeret, som bare denne prosessen eier. Og den aner da ikke noe om hva som skjer her nede. Så når dette kjøres samtidig, så er det helt kaos. Saldo hentes inn, men det er ikke noe kontroll på hvor mange ganger det gjøres. Det er ingen kontroll på at det ikke kan bli et avbrudd akkurat her. Og så overføres CPU-en til... Den andre tråden, og så trekker den fra. Og på en måte enda verre blir det når disse trådene opererer på hver sin CPU, for da jobber de helt uavhengig av hverandre. Og henter inn og ut saldo hele tiden. Uten å kontrollere hva den andre gjør i mellomtiden. Så det er helt klart at for at dette skal virke, så må man serialisere. Nøyaktig hvordan det gjøres, skal vi se på i... Vi ser på det neste gang, etter påske.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0010", "start": 1550.28, "end": 1724.92, "token_count": 586, "text": "Den andre tråden, og så trekker den fra. Og på en måte enda verre blir det når disse trådene opererer på hver sin CPU, for da jobber de helt uavhengig av hverandre. Og henter inn og ut saldo hele tiden. Uten å kontrollere hva den andre gjør i mellomtiden. Så det er helt klart at for at dette skal virke, så må man serialisere. Nøyaktig hvordan det gjøres, skal vi se på i... Vi ser på det neste gang, etter påske. Men det er en metode som heter'syncronized', som man kan bruke. Som da synkroniserer trådene i forhold til hverandre. Det som uansett er sikkert, er at hvis man ikke tar hensyn til dette her, hvis man ikke gjør programmene trådsikre, ikke tenker på race conditions, så kan ting som dette her oppstå. At man kjører samme programmet to ganger. Så er det helt vilkårlig hva man får ut som resultat. Ok. Da skal vi se på... Da skal vi se på et annet eksempel. Som på en måte er ligner, men denne gangen så er det... Så skal vi se på maskinkode. Og da skal vi se på faktisk... Helt enkeltinstitusjoner som likevel kan ha problemer med synkronisering. Så utgangspunktet her er... Dette programmet, tredd.c, det er da... Dette er da en implementasjon av p-tredds i c. Det er et bibliotek som gjør det mulig å kjøre tråder i et C-program. Vi skal ikke se så veldig mye på implementasjonen av det. Det er ikke kjempeviktig, men det er litt sånn som Yawa. Her skaper vi en tråd - tråd 1 og tråd 2. Og de skapes, og så sendes det med en metode - ink. Det er den metoden her oppe. Den sendes med, så det som skjer, er at trådene kjører den metoden. Så ser vi at de har en join her nede. Det betyr at de venter på hverandre, sånn at begge er ferdige før main avslutter og skriver ut svaret. Og det metoden gjør, det ligner jo litt på saldo, men det er at den veldig mange ganger, skal vi se... 100 millioner ganger", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0011", "start": 1693.64, "end": 1888.72, "token_count": 593, "text": "Og de skapes, og så sendes det med en metode - ink. Det er den metoden her oppe. Den sendes med, så det som skjer, er at trådene kjører den metoden. Så ser vi at de har en join her nede. Det betyr at de venter på hverandre, sånn at begge er ferdige før main avslutter og skriver ut svaret. Og det metoden gjør, det ligner jo litt på saldo, men det er at den veldig mange ganger, skal vi se... 100 millioner ganger så kaller den på programmet, eller på metoden, én linje. Kalte én linje den metoden for å eksplisitt se at dette er én linje. Også for å kunne implementere den metoden direkte i Assembly. Og da må vi se hva én linje gjør. Og den... Én dot c, den er ganske enkel. Den bare... Den tar en eksternint svar. Og så øker den den med 1. Enkelt og greit, sånn som saldo. Så her så ser vi... Denne variabelen her er deklarert globalt. Så når vi kompilerer den, når vi kompilerer dette programmet sammen med 1.c, så vil dette være en global variabel som da denne én-linje får tak i. Så... Alt i alt... Det som da bør skje, er at... Nå er det ikke en som trekker fra en som legger til, men begge disse her legger til. Sånn at vi har 100 mill. ganger så kaller vi svart pluss-pluss for den ene tråden og 100 mill. for den andre. Så resultatet til slutt bør bli 200 millioner. Så da kan vi prøve å kopilere TredoC. Kommer noen oppgaver også om dette etter påske, så da kan det være greit å se på en typisk feil. Hvis du bare kompilerer sånn, så ser du at den... Den gir en feilmelding om P3d. Og det er fordi man må ha på en opsjon minus P3d. Den linker inn et bibliotek. Så må jeg skrive det riktig. Sånn. Da er jeg klar til å kjøre. Oi, se. Nå kjører Adatat. Så kjører den. Men vi ser... Akkurat som med Javatrådene, så blir svaret forskjellig fra gang til gang.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0012", "start": 1830.92, "end": 2058.96, "token_count": 589, "text": "Hvis du bare kompilerer sånn, så ser du at den... Den gir en feilmelding om P3d. Og det er fordi man må ha på en opsjon minus P3d. Den linker inn et bibliotek. Så må jeg skrive det riktig. Sånn. Da er jeg klar til å kjøre. Oi, se. Nå kjører Adatat. Så kjører den. Men vi ser... Akkurat som med Javatrådene, så blir svaret forskjellig fra gang til gang. Her får jeg noe sånt som 114 millioner. Det jeg burde fått, var 200 millioner. Så igjen ser vi...  Her er det et eller annet som går galt. Så da kan vi... Ja, vi... Det vi ikke vet her, er... Kan dette være fordi at den institusjonen, altså én linje... Det kunne jo være... At når den kompileres, at kompilatoren lager da flere linjer. Når den kompileres. Og for å sjekke ut det, for å være sikker på at den ikke gjør det, så kan vi da lage... I stedet for én linje, så kan vi lage en liten minimal... Assemblyfile. Et lite assemblyprogram som implementerer én linje. Og den implementerer vi veldig eksplisitt med én enkel instruksjon. Så dette er nå bare... Her er det liksom svart på hvitt at dette er bare én enkel assemblyinstruksjon. Og jeg skal ikke gå inn på det... RIP er et spesielt... Register som brukes til å overføre variabler. Så det som skjer når jeg kjører denne her, er at den felles variabelen øker med igjen. Så den gjør i praksis akkurat det som 1.c gjør. Men 1.c ble komplert, så da var jeg ikke sikker på om dette faktisk ga én enkeltinstitusjon. Men dette her gir én enkeltinstitusjon. Så jeg kan da prøve... Og komplere på nytt, men i stedet for 1.c, så tar jeg med minimal. Sånn som det. Og så prøver jeg igjen. Og vi ser at... Jo, fortsatt så... Får jeg altså forskjellige svar. Og det... Det virker jo veldig rart. Her er det jo bare én institusjon. Så det kan ikke være noen context switch...", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0013", "start": 2016.44, "end": 2222.16, "token_count": 580, "text": "om dette faktisk ga én enkeltinstitusjon. Men dette her gir én enkeltinstitusjon. Så jeg kan da prøve... Og komplere på nytt, men i stedet for 1.c, så tar jeg med minimal. Sånn som det. Og så prøver jeg igjen. Og vi ser at... Jo, fortsatt så... Får jeg altså forskjellige svar. Og det... Det virker jo veldig rart. Her er det jo bare én institusjon. Så det kan ikke være noen context switch... Eller kan det være det? En context switch som gjør at den ene... Ja... At de får den samme effekten? At man henter inn variabelen og så endrer på context switchen? Og så kommer context switchen, og så lagres den? Det virker rart, fordi at... Det virker rart fordi... Her er det bare én institusjon. Så vi har ikke noe sånn mellomlagring, sånn som vi hadde i Java. Og da er det jo én ting som er nærliggende å tenke deg. Hva om vi prøver med Task-sett her? Fordi at disse to programmene... skeduleres på hver sin CPU. Og da har vi plutselig ikke noe kontroll på det som skjer. Så et naturlig forsøk å gjøre her er å se - hva skjer... Hvis vi tvinger disse til å kjøre på samme CPU, får vi da den samme effekten? Nei, det får vi ikke. Da ser vi. Hvis jeg tvinger de... Til å kjøre på samme CPU. Så... Takket være at dette bare er én institusjon, så... Dette er bare én institusjon, så da kan vi ikke få noen kontekst-switch som hopper fra prosess A til prosess B. For du har ikke den mellomlagringen. Så her klarer operativs- og CPU-en og den ene... Men det er klart... Vanligvis kjører man ikke med Tacet. Så med en gang man kjører det i to CPU-er, så får man problemer. Ja... Spørsmålet er hvorfor det har noe å si at de kjører på hver sin CPU? Ja, det er fordi at... Vi har sett at det som egentlig skjer når man utfører en kodelinje, selv om det bare er svar pluss, pluss...", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0014", "start": 2167.66, "end": 2388.76, "token_count": 582, "text": "Så her klarer operativs- og CPU-en og den ene... Men det er klart... Vanligvis kjører man ikke med Tacet. Så med en gang man kjører det i to CPU-er, så får man problemer. Ja... Spørsmålet er hvorfor det har noe å si at de kjører på hver sin CPU? Ja, det er fordi at... Vi har sett at det som egentlig skjer når man utfører en kodelinje, selv om det bare er svar pluss, pluss... Som i praksis så må den verdien, den må hentes fra RAM og inn i et register. Og selv om det gjøres som én operasjon, så har vi også sett at... Den er delt opp i mange sånne små mini-operasjoner, så ting skjer ikke sånn atomisk. Det skjer ikke som én operasjon hvor ingen andre ting utenom skjer. Og da må vi huske på at dette er to forskjellige CPU-er, så hver av de CPU-ene henter da inn denne variabelen. Den svarvariabelen ligger i ett spesielt sted. Begge er koblet inn med databussen, og begge henter ut den verdien når de skal gjøre svar pluss, pluss. Men da er det klart... Da vil det avhenge av hvem som blir først ferdig med svaret før den sender, og før den henter ut neste, og trafikken på databussen. Og når man gjør dette 200 millioner ganger, så ser vi at hele tiden så... Kan det gå galt? Men det man kan gjøre... Jeg har en lock-minimål her. Og der har jeg fortsatt den ene institusjonen. Men så har jeg en institusjon som heter lock. Det er den første metoden vi skal se på som kan løse dette problemet. Den må jo da videreformidle til alle de andre CPU-ene at nå må ingen bruke databussen. Nå må vi låse av databussen. Neste institusjon, fra og med lokk, som jeg sender, som jeg gjør nå... Den låser databussen, så ingen andre kan... Etter at jeg har satt lokk, så kan ingen bruke databussen. Og dermed, hvis jeg nå kompilerer den... Og ikke bruker minimal, men lokk minimal i stedet... Så skal vi se at selv om jeg nå kjører adopt-out... Så ser vi at svaret blir riktig hver gang.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0015", "start": 2330.56, "end": 2558.32, "token_count": 594, "text": "at nå må ingen bruke databussen. Nå må vi låse av databussen. Neste institusjon, fra og med lokk, som jeg sender, som jeg gjør nå... Den låser databussen, så ingen andre kan... Etter at jeg har satt lokk, så kan ingen bruke databussen. Og dermed, hvis jeg nå kompilerer den... Og ikke bruker minimal, men lokk minimal i stedet... Så skal vi se at selv om jeg nå kjører adopt-out... Så ser vi at svaret blir riktig hver gang. Men så så vi, la kanskje merke til også, at dette tar lengre tid. Og det er ikke så rart, for nå må databussen låses ut hele tiden, sånn at de to trådene som kjører på hver sin CPU, de nå må koordineres. De opererer samtidig, men de må vente på hverandre. Det tar noe sånn som 4,3 sekunder hvis jeg... Hvis jeg kjører med den opprinnelig, minimal... Old timer, så tar det... Det går nesten fire ganger så fort. Og dette er noe som generelt gjelder for koordinering. Det vil opplagt ta lengre tid, for da må... Da låses bussen med jevn og mellomrom. Og dermed så tar det rett og slett lengre tid. Men opplagt ikke minsten er at da unngår man race condition. Man får serialisert de to trådene, og resultatene blir riktige. Ja... Vi skal avslutte det, men det er ett spørsmål til. Hva er forskjellen på dette med plassering i RAM når man kjører to tråder på samme CPU og hver sin CPU? Ja, det er ikke noen direkte forskjell. Altså, én CPU er koblet med databussen til RAM. Men når disse to institusjonene kjører på samme CPU... Når man utfører svar pluss-pluss, eller når man utfører... ... man utfører denne institusjonen her, så... Hvis vi tenker oss at vi har to tråder, og den ene tråden utfører denne her, så vil hele den institusjonen fullføre. Denne institusjonen henter ut fra ram variabelen svar... La oss si den er 50. Så øker den med 1 til 51 og legger ut svar igjen. Og dette foregår på én atomisk operasjon. Det er bare én operasjon i CPU-en.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0016", "start": 2512.96, "end": 2700.72, "token_count": 588, "text": "... man utfører denne institusjonen her, så... Hvis vi tenker oss at vi har to tråder, og den ene tråden utfører denne her, så vil hele den institusjonen fullføre. Denne institusjonen henter ut fra ram variabelen svar... La oss si den er 50. Så øker den med 1 til 51 og legger ut svar igjen. Og dette foregår på én atomisk operasjon. Det er bare én operasjon i CPU-en. Og CPU-en ble aldri avbrutt midt inni den operasjonen. Da kan det skje en kontekst-switch, og da kan den andre tråden komme inn. Men på den måten ser vi at når de jobber på samme CPU, så vil først tråd 1 gjøre ferdig den. Og så kommer tråd 2 inn, og så vil den gjøre sin addisjon. Og da går det helt fint. Men når de er på to forskjellige CPU-er... Hver CPU henter da ut med denne institusjonen... Så sender den en beskjed ut på databussen - \".Hent inn variabelens svar.\" Og de er ikke koordinerte i det hele tatt. Så den trafikken går frem og tilbake totalt uten koordinasjon. Og da kan man risikere at Prosess1, som er på CPU1, kan hente svar i et tilfelle. Så kommer prosess 2, som er på CPU2. Den henter ut den samme, og de kan sende meldingen helt likt. Og da får begge svaret tilbake samtidig. Og begge vil da øke med én og sende svaret tilbake. Og da får vi akkurat det samme problemet tidligere. Hvis den opprinnelig var 50, så sender begge to tilbake svaret 51. Og 51 lagres to ganger. Men ett tall har da blitt borte. Og dermed så ser vi at det totale antallet ofte blir mindre enn det det skal. Ok. Men da... Da stopper vi der. Og så... ... tar jeg iallfall en liten pause, og så åpner jeg... ... noen... hva heter det... break-out-rooms. Og så kan dere... Få hjelp der til oppgaver og andre ting. Husk også å gjøre MC2 og få hjelp til den hvis dere står fast. Da stopper jeg rekordingen der.", "source": "lecture"}
{"lecture_id": "os11time2", "chunk_id": "os11time2_0017", "start": 2648.0, "end": 2709.68, "token_count": 164, "text": "Og 51 lagres to ganger. Men ett tall har da blitt borte. Og dermed så ser vi at det totale antallet ofte blir mindre enn det det skal. Ok. Men da... Da stopper vi der. Og så... ... tar jeg iallfall en liten pause, og så åpner jeg... ... noen... hva heter det... break-out-rooms. Og så kan dere... Få hjelp der til oppgaver og andre ting. Husk også å gjøre MC2 og få hjelp til den hvis dere står fast. Da stopper jeg rekordingen der. Husk også å gjøre MC2 og få hjelp til den hvis dere står fast. Da stopper jeg rekordingen der.", "source": "lecture"}
