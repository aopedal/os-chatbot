{"lecture_id": "os7del8", "chunk_id": "os7del8_0000", "start": 0.0, "end": 170.84, "token_count": 595, "text": "Ellen og L2Cash. Denne figuren viser prinsippene for Cash og hvorfor man kan få til å kjøre programmet fortere ved å bruke Cash. Helt til venstre på figuren her så ser vi CPU-en. Og så her står det R0R1R2 etter det. Det kunne stått AXBXXX også. Det er da registrene inni CPU-en. Disse brukes hele tiden til å mate oss inn i aluen. Problemstillingen er at denne CPU-en kan kverne veldig fort institusjoner. Den kan kverne institusjoner fortere enn RAM kan levere det. Og dermed så legger vi til dette L1- og L2-cash. Som sagt, mange har L3-cash også inne på skipen, av moderne prosessorer. Prinsippet er det samme. Så LN-cash er litt mindre. Men vi ser her i stedet for de fire... Her er det ikke bite engang, men det er fire bit. La oss si det er bite som skal inn i registrene. De fire bitene, de får plass i registrene. Og da kunne det være at CPU-en gjør en instruksjon som sier hent bite nummer 2. Opprinnelig var CPU-en sånn at OK, bite nummer to. Da går vi ut i ram, og så henter vi bite nummer to, som er den 1101 som ligger her oppe, og så sender vi den inn igjen. Men på den tiden så var det ikke noe forskjell på CPU og ram av betydning, sånn at det fungerte greit. Men etter hvert så har CPU-en løpt ifra og blitt raskere enn ram. Og da, i stedet for å bare hente den ene, Den biten der ute i ram, så når man da henter noe i ram, så tar man like godt med et stort område i nærheten av den biten man skal hente. Og så legger man... Så legger man det i L2-cash, hele den, så mye man får plass til, og det varierer. Og cashing, det styres på Hardner-nivå. Så dette er ikke noe som operativsystemet... Så vi kommer ikke til å se på i detalj nøyaktig hvordan algoritmene for dette er. Men det styres på hardware-nivå. Så som operativstem får du ikke gjort så mye med hvordan cash virker. Men iallfall i prinsippet så virker det sånn at du tar med en stor bit av gangen.", "source": "lecture"}
{"lecture_id": "os7del8", "chunk_id": "os7del8_0001", "start": 136.16, "end": 285.12, "token_count": 595, "text": "Så legger man det i L2-cash, hele den, så mye man får plass til, og det varierer. Og cashing, det styres på Hardner-nivå. Så dette er ikke noe som operativsystemet... Så vi kommer ikke til å se på i detalj nøyaktig hvordan algoritmene for dette er. Men det styres på hardware-nivå. Så som operativstem får du ikke gjort så mye med hvordan cash virker. Men iallfall i prinsippet så virker det sånn at du tar med en stor bit av gangen. Og så tar du med en litt mindre bit, som får plass i LN-cash. Og så, inntil sepund, så tar du de nærmeste bitene. Men statistisk sett så er det veldig ofte at man trenger bite, eller data som ligger i nærheten av hverandre. Dette kan f.eks. være institusjoner som ligger rett etter hverandre. Og da er det ofte at man hopper fra institusjon 1 til 2 til 3 til 4 osv. Og da, hvis man gjør det, så vil jo alle de institusjonene ligge her i LN Cash. Og da går det veldig kjapt å hente de over til SPU. andre gang. Noen ganger er det kanskje et stort RAI som ligger i RAM, de dataene du jobber med, og da er det den samme fordelen. Jo, da ofte så skal du ha neste RAI-element. Og når du henter ut det, så går det raskt fordi du har hentet det inn i LNCash. Og det skal vi teste ut senere når vi skal se på RAM. Hvordan er forskjellen på f.eks. hvordan man indekserer en matrise? For i noen tilfeller så hopper man rundt i RAM og henter. Man rammer data som ligger rett etter hverandre i ramm. Og det går alltid mye raskere. Så dette er hovedprinsippet for cash. Dette viser det man kan kalle mikroarkitekturen for L1- og L2-cash. Igjen så er det som sagt vanlig å ha en eldre cash, men i prinsippet så er den tilsvarende som level 2-cash. Her ser vi at LN-Cash har en litt spesiell arkitektur. Her står det LN-dato og LN-instruksjoner. Det betyr at her er det to forskjellige veier inn til CPU-en.", "source": "lecture"}
{"lecture_id": "os7del8", "chunk_id": "os7del8_0002", "start": 243.64, "end": 359.8, "token_count": 403, "text": "Og det går alltid mye raskere. Så dette er hovedprinsippet for cash. Dette viser det man kan kalle mikroarkitekturen for L1- og L2-cash. Igjen så er det som sagt vanlig å ha en eldre cash, men i prinsippet så er den tilsvarende som level 2-cash. Her ser vi at LN-Cash har en litt spesiell arkitektur. Her står det LN-dato og LN-instruksjoner. Det betyr at her er det to forskjellige veier inn til CPU-en. Det er dette som gjør at man kan si... Dette er egentlig ikke noen van Neumann-arkitektur, hvor både datainstruksjoner går på den samme bussen. Det er van Neumann-arkitektur inn hit. Den siste biten er Harvard-arkitekturen, hvor man deler opp. Institusjoner kommer inn på én buss eller rute til CPU-en, og data kommer inn på en annen. Så ser vi altså at vi har en tredje bit. TLB Transplation Look-Aside Buffer. Og det er... Nå skal vi komme tilbake til senere. Det er minneadressering. Det er en... Det bruker MMU. Og MMU, den virtualiserer minneadressene, sånn at CPU-en ikke trenger å vite nøyaktig hvor i ram enhver bite ligger. Men det kommer vi tilbake til senere, men det er også veldig viktig for effektivitet at det er hurtig. Så derfor så er det en egen bit av LNCash som er satt av til TLB, eller minneadressering.", "source": "lecture"}
