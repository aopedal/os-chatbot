{"lecture_id": "os13del11", "chunk_id": "os13del11_0000", "start": 0.0, "end": 196.72, "token_count": 589, "text": "Vi så til sist før pausen at vi trengte MMU. Vi trengte en veldig hurtig hardware bit som oversetter virtuelle adresser. Alle programmer bruker virtuelle adresser. De oversettes da til fysiske adresser. Det kunne vært nyttig å se til også. Hvis vi skulle lagd det her, så betyr det at da... Hvis vi skulle brukt et virtuelt adresserom, så betyr det at de adressene som vi sender ut her på AddressOuts, de er da virtuelle. Så da kunne det være sånn at når vi sender ut adresse nummer 8, så har vi system som sier at OK, egentlig så... Egentlig skal den peke til adresse nummer 108 i fysisk ramme. Og da måtte man her, imellom adresse out og ramme, så måtte man ha en egen enhet. Og det er det som er MMU-en. En egen enhet som da lynraskt oversetter... Akkurat som resten av CPU-en med tilsvarende logikk oversetter denne adressen fra 8 til 108. Det vil måtte være en boks inni her. Denne CPU-en har fysisk adressering, så her kan du ikke bruke virtuelt adresserom. Men alle moderne CPU-er bruker et virtuelt adresserom. Så da har man en MMU i denne biten av databussen. Så det er det vi kommer til nå, men først skal vi se på noen andre... Ja, vi ser litt på mer praktisk bruk. Og vi skal se på hvordan vi kan kompilere hva som skjer når vi kompilerer programmer, og lovder dem. For det er jo det som i prinsippet skjer hele tiden. Man har kode som kompileres, og så får vi kjørbar kode.  Og så må det legges inn i interminet og kjøres. Og det er det vi ser på denne sliden her. Så vi starter her oppe med kildekode, og så kompilerer vi. Og det er da typisk når vi har gjort det med C-programmer, så har vi skrevet GCC minus C, og så kode.c. Og da har vi ofte lagt på en minus O, og så kalt det noe. RUN, f.eks. Og den røde vil da være maskinkode. Og da har vi gjort den oversettelsen. Kompilatoren har oversatt kildekoden til maskinkode. Og her er det da maskinkode med nulldøgnere.", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0001", "start": 155.44, "end": 320.68, "token_count": 596, "text": "Og det er det vi ser på denne sliden her. Så vi starter her oppe med kildekode, og så kompilerer vi. Og det er da typisk når vi har gjort det med C-programmer, så har vi skrevet GCC minus C, og så kode.c. Og da har vi ofte lagt på en minus O, og så kalt det noe. RUN, f.eks. Og den røde vil da være maskinkode. Og da har vi gjort den oversettelsen. Kompilatoren har oversatt kildekoden til maskinkode. Og her er det da maskinkode med nulldøgnere. Vi har sett at vi kan se på den maskinkoden ved å be om å få assembly-kode. Men det er da en én-til-én mellom assembly-koden og maskinkoden. Dette er maskinkode som sier nøyaktig hvilke instruksjoner som skal utføres. Men det vi ikke har sett på tidligere, er at inni her så er det relative adresser. Ethvert program sånn som dette her starter med et minnerom fra 0 til 4G. Fra 0 til maks. Og de adressene vil da være relative, for de vil ikke være de fysiske adressene som ligger her ute i rommet. Men så før vi får ferdig maskinkoden som kan kjøres, så har vi sett tidligere at vi har lagt til én linje med linking. Vi kan gjøre hele dette her i en operasjon, men det vi typisk da har gjort, er at vi f.eks. så har vi kompliert to biter. Vi har kompliert én main og én... Vi hadde en sånn sum-funksjon. Den kompilerte vi i to forskjellige programmer. I linkingen så limes de to programmene til ett virkende system. Det som vi ikke så på, var at her i kildekoden så hadde vi f.eks. sånn Include STDIO. Altså for å kunne skrive print. Og det var da et systembibliotek som da linkes inn... Da er det kode her fra systembiblioteket for å printe ut. Det linkes sammen med... Maskinkoden som er lagd av kildekoden av programmet. Så alt dette limes sammen til én stor maskinkode. Og så, når programmet skal kjøres, så må det lastes inn i ram. Og det ser vi. Her er denne koden tatt og lastet inn i ram. Og det er en maskinkode som da kan kjøres.", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0002", "start": 288.48, "end": 456.4, "token_count": 595, "text": "Og det var da et systembibliotek som da linkes inn... Da er det kode her fra systembiblioteket for å printe ut. Det linkes sammen med... Maskinkoden som er lagd av kildekoden av programmet. Så alt dette limes sammen til én stor maskinkode. Og så, når programmet skal kjøres, så må det lastes inn i ram. Og det ser vi. Her er denne koden tatt og lastet inn i ram. Og det er en maskinkode som da kan kjøres. CPU-en setter i gang her på adresse 0, og så kjører den nedover. En sinus AX her, og det er typisk et sånt systembibliotek... Man ønsker i kildekoden å regne ut sinus AX, og i stedet for å skrive kode som regner ut det fra scratch, så bruker man et eller annet mattebibliotek som man linker inn herfra. Så kan man kjøre sinus AX. Og det kan man statisk linke inn. Man kan ta den sinus AX-koden og hive rett inn i maskinkoden. Men også ha såkalt dynamisk bibliotek. Og da vil man ha kode som ikke engang i utgangspunktet lastes inn. Så når man begynner å kjøre denne maskinkoden, så kan det være at man akkurat i dette tilfellet ikke regner ut SinusX. Og da trenger man ikke den koden. Hvis det viser seg når du kjører dette programmet, så ønsker man å regne ut SinusX. Da har man en dynamisk link. Da laster operativsystemet inn dette biblioteket her med maskinkode som regner ut CNS og X og andre funksjoner. Laster inn den, og så hopper koden til riktig sted her. Regner ut CNS og X og returnerer. Og fordelen med dette med å ha et sånt dynamisk bibliotek er at da kan jo flere programmer bruke den samme dynamiske koden. Dette er der shared memory. Vi ser det er program 2. Det ønsker også å regne ut sinus X. Og da, i stedet for at sinus X-koden er kopiert både i maskinkoden her oppe og i program 2, så peker begge til denne del L-en, til dette dynamiske biblioteket. Og på den måten så kan det da regne ut sinus X. Men vi ser med en gang. Vi begynner å se på dette her... Jo, vi skal løfte inn maskinkode inn i ramm.", "source": "lecture"}
{"lecture_id": "os13del11", "chunk_id": "os13del11_0003", "start": 417.6, "end": 592.0, "token_count": 571, "text": "Dette er der shared memory. Vi ser det er program 2. Det ønsker også å regne ut sinus X. Og da, i stedet for at sinus X-koden er kopiert både i maskinkoden her oppe og i program 2, så peker begge til denne del L-en, til dette dynamiske biblioteket. Og på den måten så kan det da regne ut sinus X. Men vi ser med en gang. Vi begynner å se på dette her... Jo, vi skal løfte inn maskinkode inn i ramm. Så begynner vi å tenke sånn... Disse adressene her... Jo, vi kunne jo hatt sånn at... La oss si dette er adresse 1000. Så kunne vi hatt sånn at... Ok, da legger vi til 1000 på alle disse her. Da må alle adressene som er her inne, oversettes. Da må vi legge til 1000. Lime de fast her. Men problemet med det er at da må denne maskinkoden her forever ligge akkurat der. Og den dynamiske her må forever ligge akkurat der. Men hva om vi ønsker å legge inn nye programmer? Jo, da må de legges ut i resten av RAM. Men til slutt går RAM full, og man har ikke plass til flere. Og da må man begynne å ta programmer ut. Og da ville det vært tungvint. Alle programmer til enhver tid skulle vite hvor de lå, og alle måtte vite de fysiske adressene. Og denne oversettelsen her er veldig tungvint og veldig lite dynamisk. Så det man har kommet opp med da, er en metode med virtuelt minne. Hvor alle adressene her... Etter at det er lagt inn, så har man en tabell som viser hvor alle de forskjellige programmene ligger. Sånn at når det er kode her som spør om ram-adresse 48, så vet det systemet, MMU-en, vet hvor ram-adresse 48 for akkurat denne kodebiten her ligger. Hvilken fysisk adresse det er. Den må alltid kunne oversettes. På denne måten så er det veldig enkelt å flytte programmer inn og ut, for da bare oppdaterer MMU. Pagetabellene blir oppdatert når man flytter programmer inn og ut, og det muliggjør å ha en veldig dynamisk organisering av prosessene som ligger i rammen.", "source": "lecture"}
