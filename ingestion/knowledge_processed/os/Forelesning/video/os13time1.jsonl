{"lecture_id": "os13time1", "chunk_id": "os13time1_0000", "start": 0.0, "end": 214.08, "token_count": 600, "text": "Der har jeg startet å ta opp. Som sagt - er det spørsmål, så inn i chatten. Så bare spør. Det er lov å skru på lyden og spørre også. Ingen gjør det, men det er lov. Men etter forelesning i hvert fall så vil det som vanlig være break-out rooms, Og studentassistentene. OK. Da skal vi se litt på dagens planer. Ja. For det første så kan dere se at jeg har endret litt på opplegget. Så... Nå er vi her. Så i forrige uke, uke tolv, så var det da den... Siste runden med digitale forelesninger. Så jeg fant ut at det pensumet vi har, er stort nok. Det har vært mange tilbakemeldinger på det. Så jeg har tenkt å ikke legge inn noe mer stoff rundt dokker. Og rundt det praktiske. Så i stedet tenkte jeg å bruke litt mer tid på... De siste delene om internminne og disker og filsystemer. Og da vil det tilsvarende være oppgaver, men da vil det bare være oppgaver om disse temaene her. Og ikke i tillegg, da, om Linux og PowerShell, sånn som det er pride å være. Så de siste tre ukene blir da litt roligere. De siste to ukene blir litt roligere sånn sett. Så det kommer til å være veldig god tid til å jobbe med dette fram til eksamen, som er lenge til. Det er vel 11.6, eller noe sånt, hvis jeg ikke husker helt feil. Og da tenker jeg også å prøve å få til en prøveeksamen en eller annen dag. Hvor mange uker med forelesning er det igjen? Jo, sånn... Som du ser her, så er vi nå her på tirsdag 13. april. Så tirsdag 27. blir siste forelesning. Mulig den ikke blir så lang heller. Men i hvert fall denne uken er den siste. Mens... Jo, mens eksamen er juni her, så jeg tenkte på et eller annet tidspunkt i morgen... Og da i form av en... en inspera-prøveeksamen. Sånn at dere får testet ut nøyaktig hvordan denne typen eksamen er. Og det... skal vi se... det jeg pleier å gjøre, er å bruke konteeksamen fra året før. Så jeg kommer nok til å gjøre det. Kanskje med noen tillegg.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0001", "start": 165.3, "end": 367.76, "token_count": 581, "text": "Men i hvert fall denne uken er den siste. Mens... Jo, mens eksamen er juni her, så jeg tenkte på et eller annet tidspunkt i morgen... Og da i form av en... en inspera-prøveeksamen. Sånn at dere får testet ut nøyaktig hvordan denne typen eksamen er. Og det... skal vi se... det jeg pleier å gjøre, er å bruke konteeksamen fra året før. Så jeg kommer nok til å gjøre det. Kanskje med noen tillegg. Ja... Det får vi se på. Hvis det er noen som... Har noen gode ideer om når det passer best med prøveeksamen. Typisk i forhold til andre fag osv. Det er akkurat samme obligatoriske innleveringer, prosjektinnleveringer osv. Kolliderer med mange andre. Så kom gjerne med forslag til det. Hvis ikke så kommer jeg med et forslag etter hvert. Ja... Så... Forrige gang så holdt vi på med mutex og semaforer og synkronisering. Så... Et siste tema som er relatert til det, er deadlock. Det fikk vi ikke snakket om forrige gang, så vi skal starte med... Og snakka om det i dag. Så litt om deadlock i starten. Men så etter hvert så er... Vi får se hvor langt vi kommer. Men fullt fokus er da fra på internminne, eller ramm. Og det er et veldig viktig tema. Kanskje spesielt viktig for... Når man kjører programmer og ting går sakte, da er det... Men hvis ting virkelig går sakte og henger, og man har problemer, da er det stort sett ramm som er problemet. Rett og slett at man har for lite ramm. Så det er helt nødvendig. Og vi skal se en del på dette teoretisk først. Men som atter så kommer vi til å ha en del praktiske demoer. Og forskjellige systemer. Men det kommer jo enda mer tilbake til neste gang, hvor vi skal se på en del veldig spesielle effekter med minnebruk. Hvor ting plutselig går mye saktere, hvor man gjør små endringer. Og det er da typisk pga. cash og andre rammerelaterte grunner. Og det... Vi skal starte litt generelt om ramme og adresserom osv.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0002", "start": 319.84, "end": 538.96, "token_count": 593, "text": "Men som atter så kommer vi til å ha en del praktiske demoer. Og forskjellige systemer. Men det kommer jo enda mer tilbake til neste gang, hvor vi skal se på en del veldig spesielle effekter med minnebruk. Hvor ting plutselig går mye saktere, hvor man gjør små endringer. Og det er da typisk pga. cash og andre rammerelaterte grunner. Og det... Vi skal starte litt generelt om ramme og adresserom osv. Og så skal vi se på MMU og paging, som er en veldig viktig bit av alt som har med interne min å gjøre. Og etter hvert noen praktiske eksempler. Ja, så da tenker jeg vi hopper... Til deadlock. Vi skal først på synkronisering. Vi har hele tiden... Det vil si, aller først så så vi på det å multitasking, å parallellisere. Få ting til å gå fort i parallell. Og stort sett så går det veldig fint. Det er bare å kjøre på i parallell så sant det er mulig å parallellisere koden. Men så kom vi til noen tilfeller hvor man må serialisere koden. Rett og slett ødeleggende at kode kjører i parallell. Og det er da typisk hvis man har en felles ressurs som to eller flere tråder jobber opp mot. Da kan de ødelegge for hverandre. Så et system må være tread safe. Det betyr at man ikke må ha tråder som ødelegger for hverandre. Og da må man serialisere og synkronisere. Og vi så forrige gang på forskjellige typer... Serialisering og forskjellige metoder for å gjøre det, bl.a. Mutex og semaforer, monitorer... Dette er teknologier og egentlig tilbud fra operativsystemet til programmereren for å hjelpe til å serialisere. De er bare litt forskjellige, hverandre. I prinsippet så er det samme ting de oppnår. Monitorer, sånn som vi så på i Java, de er enklere å forholde seg til. Det var én enkel metode som man kunne legge rundt en hel blokk, som den synkroniserte metoden. Så den ville da synkronisere hele systemet på en veldig enkel måte. Mens med å bruke mutexer direkte og også semaforer er litt mer komplisert.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0003", "start": 502.44, "end": 705.3, "token_count": 600, "text": "De er bare litt forskjellige, hverandre. I prinsippet så er det samme ting de oppnår. Monitorer, sånn som vi så på i Java, de er enklere å forholde seg til. Det var én enkel metode som man kunne legge rundt en hel blokk, som den synkroniserte metoden. Så den ville da synkronisere hele systemet på en veldig enkel måte. Mens med å bruke mutexer direkte og også semaforer er litt mer komplisert. Så dette er på en måte forskjellige tilbud fra prioritetsstemme til programmerere for å kunne serialisere. Men når man serialiserer på denne måten med mutexer og tvinger prosesser til å vente på hverandre, så får man et problem med at deadlock kan oppstå. Klare kriterier må være tilfredsstilt for at deadlock skal oppstå. Hvis man klarer å unngå alle disse tre kriteriene, kan man si at ok, da unngår jeg deadlock. Men samtidig så er dette gjerne noe man ønsker å få til i et program. Og da må man kode sånn at deadlock ikke oppstår. Det første kriteriet er at man må ha en eller annen form for mutex. Altså, man må ha ressurser som ikke kan deles. Hvis alle ressurser kan deles hele tiden, uten noe problem, så vil ikke deadlock også. Så må man også ha et kriterium at en prosess kan beholde sin ressurs mens den venter på andre. Og også at en prosess ikke kan tvinges til å gi opp sin ressurs. Hvis disse kriteriene er oppfylt, så kan deadlock oppstå. Og vi kan få deadlock ved sirkulær venting. Vi skal se hva det betyr. Ja... Her er et enkelt eksempel på deadlock.  Hvor man generelt kan få deadlock hvis to eller flere prosesser venter på hverandre. Og i det eksempelet her så ser vi at vi kjører prosess A og prosess B. Og de gjør sånn at de skal vente S1 for å vente på en ressurs, og single S1 her nede for å avgi den ressursen. Men da kan vi få et... Et dødlagt problem. Hvis både prosess A og prosess B ønsker å få tak i ressurs S1 og S2, og prosess A sånn tilfeldigvis, så gjør prosess A først en wait på S1, mens prosess B gjør wait på S2.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0004", "start": 671.06, "end": 823.04, "token_count": 583, "text": "så ser vi at vi kjører prosess A og prosess B. Og de gjør sånn at de skal vente S1 for å vente på en ressurs, og single S1 her nede for å avgi den ressursen. Men da kan vi få et... Et dødlagt problem. Hvis både prosess A og prosess B ønsker å få tak i ressurs S1 og S2, og prosess A sånn tilfeldigvis, så gjør prosess A først en wait på S1, mens prosess B gjør wait på S2. Og så, mens den venter på S1, så ønsker den også å vente på S2. Den vil også ha den ressursen. Og samtidig gjør... Prosess B, det samme, wait på S-en. Og da vil vi få en låst situasjon. Da ser vi gjerne på eksempel 2 her. Da vil vi få en låst situasjon, hvor prosess A venter på at prosess B skal release S2. For den har vi fått tak i SO. Den har nøkkelen her til SO. Og så venter den på den. Og tilsvarende venter Prosess B på at Prosess A skal release essay. Kanskje de står her med en sånn... Med busy waiting. Står og spinner og venter og venter. Og dette kalte seg en deadlock. Den vil aldri løse seg opp. Eksempel igjen er jo kanskje enklere. Prosess 1 venter på P2. P2 venter på P3, og P3 venter på P1. De bare venter på hverandre. Det kan være en semafor som dette her, men det kunne også være sånn som vi så på forrige gang, at prosess 2 skal være ferdig med noe i koden før prosess 3 går videre, osv. Og dette er sånt som kan oppstå i den virkelige verden også. Jeg husker veldig godt at jeg var ute og kjørte bil, og så kom jeg i et kryss hvor man har vikeplikt fra høyre. Og da hadde jeg tidligere snakket om dette på forelesning, at jo, hvis kommer det et kryss med fire biler som skal inn, og det var vanlig vikerplikt, så... Og da var det sånn at jeg ventet på den som sto ved siden av fra høyre. Den ventet på den som sto ved siden av fra høyre igjen, osv.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0005", "start": 793.56, "end": 959.62, "token_count": 583, "text": "Jeg husker veldig godt at jeg var ute og kjørte bil, og så kom jeg i et kryss hvor man har vikeplikt fra høyre. Og da hadde jeg tidligere snakket om dette på forelesning, at jo, hvis kommer det et kryss med fire biler som skal inn, og det var vanlig vikerplikt, så... Og da var det sånn at jeg ventet på den som sto ved siden av fra høyre. Den ventet på den som sto ved siden av fra høyre igjen, osv. Rundt hele krysset. Så alle sto og ventet på hverandre. Og jeg var den eneste, kanskje av bilistene, som jublet... Yes! Deadlock! Og løp hjem og fortalte om det til kona. De andre tenkte kanskje ikke så nøye over det, men akkurat denne situasjonen er det som skjer i programmer. Hvor de venter på hverandre, og så kan en deadlock-situasjon som det oppstå. Dining philosophers problem, det er et veldig kjent problem. Hvor deadlock da kan oppstå. Og dette er kjent fordi at det blir ofte brukt som et eksempelproblem. Så man trenger da... Eller man bruker semaforer og mutex osv. Og så skal man programmere disse filosofene til å siste å spise spagetti. Og tenke. Men så må man gjøre det på en sånn måte at man skal programmere Og man unngår deadlock. Problemet, hvis dere kan se her, så er det... Den tegningen skal forestille et bord med fem porsjoner med spagetti. Og så ligger det mellom hver tallerken en gaffel. Og da tenker vi oss at det er fem filosofer som sitter rundt her og skal spise. Og dette må da programmeres som filosofprosesser. Og de oppførte seg sånn at noen ganger så sitter de og tenker... Typisk bare står og spinner uten gafler. Men så er det noen ressurser de deler på, og det er gaflene. Hvis det sitter en øverst her ved bordet, så har han da to gafler som han kan ta. Og systemet er sånn at for å spise så må man ha to gafler. Og da er det typisk sånn... Jo, det er programmer, dette her, så de må da ta opp gafler én av gangen.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0006", "start": 929.98, "end": 1094.7, "token_count": 594, "text": "Typisk bare står og spinner uten gafler. Men så er det noen ressurser de deler på, og det er gaflene. Hvis det sitter en øverst her ved bordet, så har han da to gafler som han kan ta. Og systemet er sånn at for å spise så må man ha to gafler. Og da er det typisk sånn... Jo, det er programmer, dette her, så de må da ta opp gafler én av gangen. Og da må de med mutexer og så videre sjekke at gaflene er ledige. Så må de plukke opp først én gaffel, og så en til. Og så, når de kommer i gang, så kan de starte med å spise. Og da må de programmere sånn at det er random tidsbruk. Altså de kan sitte og tenke en stund. Og så bestemmer de seg om å begynne å spise. Og så begynner de å spise. Problemstillingen er da å programmere dette sånn at alle sitter og spiser. Alle sitter sånn og spiser. Og så... Jo, programmet må være sånn at de når som helst kan ta en gaffel  At de når som helst kan ta en gaffel og spise, og så må dette flyte. Og dette må gjelde i alle situasjoner. Og da kan det være sånn at dette fungerer veldig fint lenge, og så plutselig kommer du til deadlock. Og et eksempel på deadlock da, det vil typisk være at... Jo, tenk om... Hvis vi tenker oss disse fem trådene, kjører på én CPU, så vil du gjøre én ting av gangen. I og for seg så kan akkurat det samme skje hvis vi kjører på fem forskjellige CPU-er. Men i hvert fall hvis man tenker seg at alle samtidig kommer til det steget at de har tatt én gaffel opp. Og så sitter de og holder på den ressursen. Og så gjør alle de andre det samme. For alle tar opp høyre gaffel, og så venter de på at venstre gaffel skal bli ledig. Men hvis man ikke programmerer med høyre, Ja. Det er kommentar her med selvkjørende biler. Ja, og da vil du virkelig få en deadlock. Ja, det er kommentar her med selvkjørende biler. Ja, og da vil du virkelig få en deadlock.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0007", "start": 1051.08, "end": 1251.66, "token_count": 594, "text": "at de har tatt én gaffel opp. Og så sitter de og holder på den ressursen. Og så gjør alle de andre det samme. For alle tar opp høyre gaffel, og så venter de på at venstre gaffel skal bli ledig. Men hvis man ikke programmerer med høyre, Ja. Det er kommentar her med selvkjørende biler. Ja, og da vil du virkelig få en deadlock. Ja, det er kommentar her med selvkjørende biler. Ja, og da vil du virkelig få en deadlock. Når selvkjørende biler blir så avanserte at de kjører ut i trafikken, så er absolutt det noe man må ta hensyn til og få til en deadlock-løsning. Og ja, en mulig løsning kan kanskje være at man... Ja, nei, det er ikke noe... Hvis du tenker på det med selvkjørende biler... Det er et godt eksempel. Det er ikke så enkelt å finne ut hvem som skal kjøre. Det må kanskje være noe sånn at en starter å begynne å kjøre, og så detekterer, men da vil den andre si at... ja. Rangerer man prioritet? Jo, det kunne være en mulighet. Alle biler har en prioritet, så må de snakke sammen... Eller da må de vite hvem som skal kjøre først. Men det var et veldig godt eksempel på en virkelig deadlock som kan oppstå, Rent praktisk må kunne løses. Ja. Men kunstig intelligens... Jo, det blir jo en kunstig intelligens, men det er ikke så lett å lære det heller. Kunstig intelligens lærer ofte av tidligere data. Men det er klart. Dette er virkelig... Det er jo kunstig intelligens. Men hovedpoenget her er at dette er noe som... Med en gang man deler på ressurser og prøver å synkronisere seg imellom. Og det er ikke så lett å unngå deadlock, men det er usedvanlig viktig å unngå det. Jeg har kommet med mange gode forslag her. Trafikklys? Jo, det er jo en dag. Men at man har... Man legger inn det i alle kryss. Man kan jo på en måte lage software-trafikklys som alle indirekte vet om. OK, men... Ja, så dette er jo deadlock-problemstillingen. Mulige løsninger for deadlock. Ja...", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0008", "start": 1200.14, "end": 1405.82, "token_count": 596, "text": "Og det er ikke så lett å unngå deadlock, men det er usedvanlig viktig å unngå det. Jeg har kommet med mange gode forslag her. Trafikklys? Jo, det er jo en dag. Men at man har... Man legger inn det i alle kryss. Man kan jo på en måte lage software-trafikklys som alle indirekte vet om. OK, men... Ja, så dette er jo deadlock-problemstillingen. Mulige løsninger for deadlock. Ja... Den første og viktigste løsningen er å prøve å forhindre det. F.eks. internt i operativstemkjernen er det utrolig viktig at deadlock forhindres, sånn at prosesser ikke står og venter på hverandre. Og da må man skrive kode som gjør da at det aldri oppstår deadlock. Og det kan være litt vanskelig å programmere, Du må ofte teste det ut, men da kan det være sånn at deadlock oppstår bare i ekstremt sjeldne tilfeller. Og så oppdager man ikke før det skjer i kjørende kode. For vanlige brukerprosesser så er det vanskelig for operativsystemet å garantere at det ikke skjer en deadlock.  La oss si at operativsystemet tilbyr semaforer med mate and signal. Men hvis to programmer bruker det på denne måten her, så skjer det en deadlock. Og da er det vanskelig for operativsystemet å gjøre noe med det. Så metode to er altså å løse opp en deadlock, men det er generelt vanskelig, for ofte så holder en prosess på en ressurs av en eller annen... Av en grunn. Det er ikke bare tilfeldig at den har tatt den gaffelen. Den skal ha den. Så det er generelt vanskelig å løse opp deadlocker etter at det har skjedd. Så en vanlig måte å håndtere deadlockproblemer på er å stikke hodet i sanden, som strutser gjør. Og det er ofte sånn operativsystemet gjør. Hvis det er brukerdeadlock, så ignorerer operativsystemet det problemet. OK. Da var vi ferdige med deadlock og skedulering og synkronisering og hele den biten. Så nå skal vi starte å se på internmin. Internmin og cash. Vi har vært borti både internmin og cash tidligere. Men vi skal nå se spesifikt på det som spesielt har med ramme å gjøre.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0009", "start": 1358.66, "end": 1559.78, "token_count": 598, "text": "Og det er ofte sånn operativsystemet gjør. Hvis det er brukerdeadlock, så ignorerer operativsystemet det problemet. OK. Da var vi ferdige med deadlock og skedulering og synkronisering og hele den biten. Så nå skal vi starte å se på internmin. Internmin og cash. Vi har vært borti både internmin og cash tidligere. Men vi skal nå se spesifikt på det som spesielt har med ramme å gjøre. Ikke så mye på cash, men vi skal se hvordan ram oppfører seg, og hva som skjer når programmer lager store r-er og bruker store mengder ramm. Og hvordan organiseringen av ramm, ikke minst... hva som skjer når programmer lager store r-er og bruker store mengder ramm.  Hvordan organiseringen av ramm, ikke minst hvordan det skjer i operativsystem. Og jevnt så skjer det i nært samarbeid med hardware. Det er mange hardware-spesifikke instruksjoner og konstruksjoner, ikke minst MMU, som er lagd i hardware for at... Det å bruke ramm skal gå fort. Og veldig mye av dette skyldes at ramm i utgangspunktet er relativt tregt. Cash er mye raskere, eller S-ram er mye raskere enn D-ram. Kanskje noen faktorer ti ganger. Så det har vi sett på tidligere... For at man skal hurtigere kunne snakke med Ra. Men utgangspunktet RAM - Random Access Memory... Det høres ut som et litt rart begrep. Random Access. Men hovedpoenget med begrepet Random Access er at det er minnet hvor det går like fort å hente et hvert bite. Uavhengig av hvor det ligger. Hvis du skal hente byte nr. 1000 med ram eller random access, så betyr det at det går like fort å hente byte nr. 1000 som det går å hente byte nr. 1000-1000. Uansett hvor det ligger i ram, så går det like fort å hente det. Og det er i og for seg riktig for en standard konstruksjon av ram, I praksis så vil det ta forskjellig tid å hente en gitt bite. F.eks. en variabel svar som man har i et C-program. Hvis man skal gå ut i RAM og hente den, så vil det være forskjellig hvor lang tid det tar.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0010", "start": 1525.46, "end": 1685.38, "token_count": 592, "text": "som det går å hente byte nr. 1000-1000. Uansett hvor det ligger i ram, så går det like fort å hente det. Og det er i og for seg riktig for en standard konstruksjon av ram, I praksis så vil det ta forskjellig tid å hente en gitt bite. F.eks. en variabel svar som man har i et C-program. Hvis man skal gå ut i RAM og hente den, så vil det være forskjellig hvor lang tid det tar. Og det er først og fremst da pga. cash. For hvis du nylig har hentet den verdien, så vil den ligge i cash. Og cash er hurtigminne, og da går det hurtigere å hente. Sånn sett er det ikke random access i forhold til om du henter en variable eller en bite som ikke har vært i minnet på lang tid. Da vil det gå raskt å hente det. Et annet tilfelle vi har hvor det er forskjell på tiden, det er med såkalt nummanoder. Eller så er det servere som har mange CPU-er. Altså sånn titalls CPU-er. Sånn som noen av de vi har sett på, med 48 CPU-er. Eller sånn som den serveren som dokkecontainerne kjører i, Linux-VM-ene, som vi kaller dem, den har 60 CPU-er eller noe sånt. Den, den er da... Den har da et system av numa-noder. Og det betyr at det er en slags cluster av CPU-er, kanskje seks eller åtte av gangen, som tilhører spesielle noder. Som ligger nærmere de nodene. Rent og slett fysisk nærmere, sånn at de har raskere aksess. De har en egen minibuss ut dit. Så NVE Superbude kan hente da bites fra hele ramm, men i noen tilfeller vil det ta lengre tid, fordi de ikke sitter på den nummadoden som de selv hører til. Og da vil heller ikke RAN være helt random aksess. Det går like lang tid å hente hver bite. Og dette er veldig forskjellig fra harddisker, som vi skal se på senere. Iallfall spinnende, tradisjonelle harddisker. Der er det avhengig av hvor lesehodet til harddisken står, osv. På hvor lang tid det tar å hente en gitt del av minnet.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0011", "start": 1648.56, "end": 1830.04, "token_count": 596, "text": "fordi de ikke sitter på den nummadoden som de selv hører til. Og da vil heller ikke RAN være helt random aksess. Det går like lang tid å hente hver bite. Og dette er veldig forskjellig fra harddisker, som vi skal se på senere. Iallfall spinnende, tradisjonelle harddisker. Der er det avhengig av hvor lesehodet til harddisken står, osv. På hvor lang tid det tar å hente en gitt del av minnet. Ok. Men som vi har sett tidligere... Register og cash er laget av S-ram, static-ram. Det består av seks temas historier. Jeg har sett på konstruksjonen av det tidligere. Det er ekstremt hurtig, og det er statisk. Det trenger ikke å oppfriskes. Ram eller internmine, derimot, det er laget av D-ram, dynamic-ram. Og det er en mye enklere konstruksjon. Det består bare av én transistor, og så er det én kondensator. En kondensator er da et lite element som kan holde på ladning. Så det holder på statisk ladning. Litt sånn som en ballong som du gnir på, så får du statisk ladning. En kondensator kan da holde en liten ladning, og det vil da være en én eller null. Men denne ladningen må oppfriskes ca. ti ganger i sekundet. Så da må man ha en liten loop som går og oppfrisker alle verdiene i RAM hele tiden. Så det betyr jo opplagt at hvis man skrur av en maskin, så forsvinner alt som er i RAM. Ingenting av det som er i RAM. Selvfølgelig ikke det i registeret heller. Men... Så det betyr at alt som skal lagres permanent, det må lagres på disk. På harddisker, der ligger det permanent. Ja... Tidligere så var det ikke vanlig å synkronisere deRam. Men... Ja, for kanskje sånn 15-20 år siden, så... Så ble det vanlig å synkronisere det ram, sånn at lesing og skriving var synkronisert med en ekstern klokke. Sånn som det alltid har vært i CPU-en. Der har vi en klokke. Men det er også en klokke ut mot databussen, sånn at man synkroniserer lesing og skriving.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0012", "start": 1797.86, "end": 1969.54, "token_count": 588, "text": "Ja... Tidligere så var det ikke vanlig å synkronisere deRam. Men... Ja, for kanskje sånn 15-20 år siden, så... Så ble det vanlig å synkronisere det ram, sånn at lesing og skriving var synkronisert med en ekstern klokke. Sånn som det alltid har vært i CPU-en. Der har vi en klokke. Men det er også en klokke ut mot databussen, sånn at man synkroniserer lesing og skriving. Og da finnes det forskjellige versjoner av ram. Alle nyeste er DDR5. DDR4 var den forrige. DDR står for Double Data Rate. Så alt dette er hesteram, men det har vært versjoner som har kommet, som har vært mer og mer effektive. Og den typiske forskjellen er at de har høyere klokkefrekvens på databussen, sånn at de raskere kan overføre data. Den har vi også sett på videre. Dette er det veldig viktig å ha med seg. Vi starter helt innerst her med registeret. Og her inne... Registrene er ekstremt hurtige. Og så er det altså med avstanden. Registrene ligger inne i CPU-en, og man kan kopiere mellom registrene. På mindre enn et nanosekund, altså typisk på én eller to klokkesykler, så kan man kopiere mellom registrene. Mens LNCash, det er da fortsatt SRAM. Det er på en måte samme teknologi, men det ligger litt lenger ut, så det tar litt lengre tid. Og så kommer du enda lenger ut til L2Cash. Eltre Cash er gjerne hakke utenfor der igjen også, men noen flere nanosekunder. Og der ser vi at det er en faktum på minst ti inn til registrene. Det er denne forskjevnen som gjør at cash er så viktig. Man klarer rett og slett ikke å få inn data fort nok til CPU-en uten å bruke cash. Så kommer et hakk ut til disker. Solid State-disker. Skal se mer på det senere. De har Random Access på samme måte som RAM. At du kan ta like lang tid å hente en hvilken som helst bite. Men det går mye saktere. Det er en fakta på i hvert fall 1000 i forhold til RAM.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0013", "start": 1936.02, "end": 2162.66, "token_count": 600, "text": "Det er denne forskjevnen som gjør at cash er så viktig. Man klarer rett og slett ikke å få inn data fort nok til CPU-en uten å bruke cash. Så kommer et hakk ut til disker. Solid State-disker. Skal se mer på det senere. De har Random Access på samme måte som RAM. At du kan ta like lang tid å hente en hvilken som helst bite. Men det går mye saktere. Det er en fakta på i hvert fall 1000 i forhold til RAM. Og så har du kanskje grovt sett en fakta på 1000 til igjen ut til fysiske harddisker som spinner rundt. Så der går det veldig mye saktere. Her nede. Adresse 0. Her er det 8-bit som utgjør én bite. Og så er det adresse 1 osv. oppover. Og her ser du 42. Dette er 2 i 32. Så dette er 4 giga med adresser. Og dermed har du 4 gigabyte med... Med ram i dette R-øyet. Så det er viktig å huske. Det er bare ett stort R-øy som programmerer, så kan vi tenke på det. Ett stort R-øy med bites som ligger etter hverandre. Så har vi sett tidligere hvordan f.eks. vi har lagret en 64-bit... Som trenger fire bite. Og da setter man typisk av de fire bitene etter hverandre til en variabel. Det er en litt sånn teknikalitet. Men i virkeligheten så er det bare bite som ligger etter hverandre i et svært ærøy. Adresserommet... Vi trenger da å kunne adressere alle bitene som ligger der. Og disse adressene må da kunne lagres i registeret. Og det har vi sett på tidligere, at vi har brukt move f.eks. for å flytte noe fra ram og inn i de interne registrene i CPU-en. Og da har vi brukt registeret sånn som prosent-rsp, som er da en peker... Prosent-rsp peker til toppen av stacken. Det er et tilspørsmål i chatten her. GDDR... Ja, det er vel sånn GPU-ram... Det er jeg ikke sikker på. Men det er det. Det høres veldig sånn ut at det er grafikkram. Jeg kan sjekke ut det i pausen. Jo, et annet eksempel på adresserom, det er sånn som IP-adresser.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0014", "start": 2094.8, "end": 2328.34, "token_count": 597, "text": "Og da har vi brukt registeret sånn som prosent-rsp, som er da en peker... Prosent-rsp peker til toppen av stacken. Det er et tilspørsmål i chatten her. GDDR... Ja, det er vel sånn GPU-ram... Det er jeg ikke sikker på. Men det er det. Det høres veldig sånn ut at det er grafikkram. Jeg kan sjekke ut det i pausen. Jo, et annet eksempel på adresserom, det er sånn som IP-adresser. Da har vi alle adresser fra 00 til 255, 255, 255, 255. Alle IP4-adresser må ligge innenfor dette adresserommet. Det var derfor man måtte begynne med IPv6, fordi det var til slutt ikke nok adresser i adresserommet. Samme problemstillingene har man i internminet. Generelt så er det veldig enkelt adresserom for internminet. Det går bare fra null til maks. Men så trenger man å... Så trenger man å ha et register for å lagre en adresse. Til å begynne med hadde man 16-bits CPU-er. Og da hadde du en registerstørrelse på 16 bit. Hvis du da skulle lagre alle adressene, så er det bare plass til to i 16-adresser. Og det er 64K. Og derfor er det mange sånne gamle computere... Kommodorer, 64, osv. For da hadde de et adresserom som var på 64 000. Og der kunne man lagre 64 kilobyte, og det var punktet. Etter hvert så fikk man 32-bitsregisteret. Og da hadde man to i 32. Det er 4G. Det var også et sånt problem... Det var med 32-bits CPU-er. Hvis man kjørte Linux og hadde mer enn 4 GB ram, så fikk man straks et problem. Mange av de CPU-ene støttet ikke det å bruke 4G-ram. Så etter hvert kom det 64-bits-registeret, og da har man mer enn nok. Størrelse på adresserommet. Selv to opphøyde 48 gir 256 terabyte. Så det er mer enn nok for rammedelen. Så da er det ikke noe problem med antall bit i registrene. Men generelt så må du da kunne ha et register som kan lagre alle adressene i IRA. Ja... Virtuelt adresserom... Vi deler da...", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0015", "start": 2280.44, "end": 2481.9, "token_count": 587, "text": "Mange av de CPU-ene støttet ikke det å bruke 4G-ram. Så etter hvert kom det 64-bits-registeret, og da har man mer enn nok. Størrelse på adresserommet. Selv to opphøyde 48 gir 256 terabyte. Så det er mer enn nok for rammedelen. Så da er det ikke noe problem med antall bit i registrene. Men generelt så må du da kunne ha et register som kan lagre alle adressene i IRA. Ja... Virtuelt adresserom... Vi deler da... Vi har et fysisk adresserom. Det er liksom alle adressene fra null til maks. Men generelt så er det ikke plass i alle programmer i internminnet på en gang. Hvis du har veldig mange programmer, så må de til en viss grad lastes. Og i tillegg, som vi skal se, så er det veldig nyttig å kunne ha et virtuelt adresserom, for at man da dynamisk kan velge hvilke biter av et program som er med. Sånn man organiserer det, er at hvert enkelt program får et adresserom fra null til maks, f.eks. til 4G hvis det er Og hver prosess lokalt tror at den har tilgang til alt dette minnet. Den har et kjempesvært adresserom. Men i virkeligheten så ligger noe av dette minnet i ramm, og andre ligger på disken. Eller andre deler er ikke i bruk i det hele tatt. Så disse logiske adressene... De brukes overalt hvor programmet refererer til nå. F.eks. en sånn institusjon som dette er - move1023 til AL. Det sier move det som ligger i minneadresse 1023, inn i registeret AL. Men 1023 er da den virtuelle adressen. Det er ikke den faktisk fysiske adressen. Opprinnelig, i de aller første datamaskinene, så var det... Så brukte man ikke et virtuelt adresserom, og da var 1023 Byte nummer 1023 i RAM. Men nå har vi et system hvor alle disse adressene hele tiden oversettes til fysiske adresser. Og dette gjøres da av MMU, som vi skal se på i detalj. Memory Management Unit. Og... Siden dette gjøres om ikke ved hver institusjon, så hver eneste gang man adresserer RAM i det hele tatt, så må denne oversettelsen gjennomføres.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0016", "start": 2439.58, "end": 2637.66, "token_count": 571, "text": "Så brukte man ikke et virtuelt adresserom, og da var 1023 Byte nummer 1023 i RAM. Men nå har vi et system hvor alle disse adressene hele tiden oversettes til fysiske adresser. Og dette gjøres da av MMU, som vi skal se på i detalj. Memory Management Unit. Og... Siden dette gjøres om ikke ved hver institusjon, så hver eneste gang man adresserer RAM i det hele tatt, så må denne oversettelsen gjennomføres. Og det betyr at det må gå ekstremt raskt, for dette skjer hele tiden. Så alle programmer som snakker med minnet, de må få sin virtuelle adresse oversatt til den fysiske. Og det skjer om og om igjen, og da har man ikke... Da har man ikke noe tid til å bruke CPU-sykler på å få dette til, så dette må nærmest lagres i... Eller, det må lages i hardware. Og det er nettopp det MMU er. Det er hardware som oversetter fra virtuelle adresser til fysiske adresser. Men jeg ser vi trenger en pause nå, så da skal vi se på... Nøyaktig hvordan det gjøres etter pause. Vi skal ha et par... Et par eksempler på minnebruk også. Men så skal vi... Så skal vi se på nøyaktig hvordan MMU virker. Ja... Jeg ser Ina har kommet opp med et godt svar her. Det er typisk sånt som brukes i GPU-er, som er da prosessoren som prosesserer grafikk. Og GPU-er har typisk veldig mange uavhengige kjerner. De har små kjerner med relativt lite ramte hver, men de kan kanskje ha 4096 uavhengige kjerner som kan jobbe i parallell. Og det er opplagt nyttig når man jobber på grafikkenheter. Hvis man skal vri om på et 3D-bilde med enormt mange bits, så kan de operasjonene da gjøres i parallell. 4096 operasjoner gjøres helt samtidig. Det tilsvarer parallelle CPU-er, men de er mindre, og så gjør de akkurat denne operasjonen. Som er spesifisert for dem. Og GDDR er da den type ramme som GPU-ene bruker. Altså de grafiske prosessorenhetene.", "source": "lecture"}
{"lecture_id": "os13time1", "chunk_id": "os13time1_0017", "start": 2589.58, "end": 2661.54, "token_count": 203, "text": "Og det er opplagt nyttig når man jobber på grafikkenheter. Hvis man skal vri om på et 3D-bilde med enormt mange bits, så kan de operasjonene da gjøres i parallell. 4096 operasjoner gjøres helt samtidig. Det tilsvarer parallelle CPU-er, men de er mindre, og så gjør de akkurat denne operasjonen. Som er spesifisert for dem. Og GDDR er da den type ramme som GPU-ene bruker. Altså de grafiske prosessorenhetene. Ok. Men da tar vi en pause der. 9.19. Vi kan starte igjen... Hva blir det? 9.35. Så starter vi igjen. Da skal vi se på... Ja, det viktigste etter pause ble å se på hvordan MMU fungerer.", "source": "lecture"}
