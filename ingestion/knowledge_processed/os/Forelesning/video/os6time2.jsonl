{"lecture_id": "os6time2", "chunk_id": "os6time2_0000", "start": 0.0, "end": 220.44, "token_count": 591, "text": "Ja, aller først så var det et spørsmål i pausen om innlogging på Linux-VM. Om jeg kunne gjenta det? Og det kan jeg gjøre. Det gikk kanskje litt fort. Nå har jeg også begynt å legge ut videoer fra før pause. Sånn som dere ser nå, så går det an å gå inn på den og så se... Se f.eks. sånn som det. Det ligger åtte minutter ut i første time. Hvordan logger man på på Linux-VM-ene? Men jeg tar det uansett en gang til. Så... Det var også spørsmål om grupper. Så vi kan ta det også hvis vi går inn på... Studentgruppene her. Så ser dere at det er OS-grupper. Og nå er det 96 grupper. Så for å få en... For å få tilgang til en Linux-VM, så må du melde deg inn i en gruppe. Her ser vi noen som allerede har kommet inn i 81 og 83. Så hvis du ennå ikke har fått tilgang, f.eks. ikke har levert obliger, så meld deg inn i OS84. Det du da får som OS84, det er da bare et passord. Så du får kun passordet, og da er tanken... At hvis du har passord 84, sånn som det, så skal du da logge deg inn som brukeren group 84. Og i tillegg så skal... Så er hosten som du skal inn på, det er OS84. Så sånn logger du deg inn til denne adressen. Vi kan ta først før vi logger oss inn, så kan vi f.eks. bruke ping. Da ser vi at den svarer på ping. Dette er en typisk måte man sjekker om en server er oppe på. Ved å pinge. Men så er det da viktig at du går inn på group.at.os84. Hvordan vi finner passordet? Jo, gå på OS-gruppen. Og så klikk på... annonsement. Jeg trodde kanskje man fikk det annonsementet i Apos også. Altså alt på gruppen. Hvis ikke, så gå inn på... Gå inn på gruppen, og så klikk på annonsement der. Det skal jeg ikke gjøre, for der ligger da passordet til OS28. Det kom altså på Apos, ja. Så da... Hvis dere har slettet den e-posten, så gå inn i Gruppen og se på Announcements. Der ligger det bare en streng.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0001", "start": 186.72, "end": 366.92, "token_count": 594, "text": "Jeg trodde kanskje man fikk det annonsementet i Apos også. Altså alt på gruppen. Hvis ikke, så gå inn på... Gå inn på gruppen, og så klikk på annonsement der. Det skal jeg ikke gjøre, for der ligger da passordet til OS28. Det kom altså på Apos, ja. Så da... Hvis dere har slettet den e-posten, så gå inn i Gruppen og se på Announcements. Der ligger det bare en streng. Det er vel fire tegn og et tall og så fire nye tegn. Et lite ord og så et tall og så et annet ord. Så da logger dere inn som Group84. At Ords84. Og så er det... Hvis dere får opp noe sånt som dette her, så svar yes. Det er sånn typisk du får første gang du logger inn på en server. Og etterpå så lagrer den da Mac-adressen til den serveren. Så hvis du senere logger inn på den samme adressen, og Mac-adressen er endret, altså adressen til nettverkskortet på nivå 2, på la-nivå, eternettadressen... Hvis den har blitt endret, så... Så kan det tyde på at det er en sånn man in the middle attack. Altså at noen prøver å gjøre noe lureri med IP-adressen og sende deg til et annet sted enn du skal, osv. Så derfor må man første gang svare bare yes på den, så kommer man inn. Du ser, nå kommer jeg direkte inn. Du må taste passord. Men jeg har lagt opp SSO-nøkler, sånn at jeg kommer inn på alle disse VM-ene. Sånn at jeg kan hjelpe til. Er du på gruppe 1, så logger du inn på denne måten. Ok. Vi så på Branch Prediction, og så vidt jeg husker, så er det vel en oppgave uansett. Det kan være veldig nyttig å gå inn. Prøve å kjøre denne branch prediction og se hva som skjer. Men den effekten vi så i programmet, at det gikk fortere når man sorterte RE, det skyldtes altså at branch prediction traff oftere enn... Eller det traff egentlig hele tiden. Mens i andre tilfeller så måtte man veldig ofte gå tilbake, fordi man hadde bommet på branch prediction. Så måtte man gå tilbake. Og det tar opplagt ekstra tid.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0002", "start": 324.06, "end": 516.44, "token_count": 591, "text": "så er det vel en oppgave uansett. Det kan være veldig nyttig å gå inn. Prøve å kjøre denne branch prediction og se hva som skjer. Men den effekten vi så i programmet, at det gikk fortere når man sorterte RE, det skyldtes altså at branch prediction traff oftere enn... Eller det traff egentlig hele tiden. Mens i andre tilfeller så måtte man veldig ofte gå tilbake, fordi man hadde bommet på branch prediction. Så måtte man gå tilbake. Og det tar opplagt ekstra tid. Da skal vi over på et annet tema. Vi skal ikke slippe... Vi skal ikke slippe... datamaskinarkitektur helt fullstendig ennå. Oppsummere kort datamaskinarkitektur. Så jeg finner riktige slides... Sånn. Følgene er veldig viktig å huske fra datamaskinarkitektur. CPU-en har ikke noe annet som hva maskininstitusjonene gjør, hva slags logikk det er inni der. Den bare følger institusjonene én for én. Som vi skal se senere, så vet heller ikke operativsystemet om den indre logikken i maskininstitusjonene. Men det viktige er at NCPU utfører bare én og én institusjon. Og så er det ingen én-til-én-forbindelse mellom institusjoner i høynivåkode og maskinkode. Vi har sett at en kompulator kan lage forskjellige typer maskinkode, så det er ingen garanti for hvordan maskinkoden ser ut. Og i enkelte tilfeller så er det umulig å lage én linje maskinkode som gjør hele høynivåkoden. Så én linje kode i høynivåspråk fører ofte til mange maskininstitusjoner. I det ferdigkompliserte programmet. Så har vi også denne CPU-løkken. Den viser bare at CPU-en er en evig løkke. Wild not halved. Så lenge maskinen står på, så står den og kjører instruksjoner. Hvis den ikke har noen instruksjoner å gjøre, så gjør den en såkalt NOP. No operation. Altså at den bare står og slår i lufta. Etter hvert som det har kommet servere med veldig mange sippuer,", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0003", "start": 483.28, "end": 685.64, "token_count": 600, "text": "Så har vi også denne CPU-løkken. Den viser bare at CPU-en er en evig løkke. Wild not halved. Så lenge maskinen står på, så står den og kjører instruksjoner. Hvis den ikke har noen instruksjoner å gjøre, så gjør den en såkalt NOP. No operation. Altså at den bare står og slår i lufta. Etter hvert som det har kommet servere med veldig mange sippuer, så ville det tatt mye energi at alle står sånn og spinner og bruker energi på det. Da er det kommet nye features hvor du kan legge sippuer i dvale. Men i utgangspunktet så er det i hvert fall én som står og kontrollerer og slår i lufta helt til noe skjer. Enten det er kode som skal kjøres, eller at det kommer et interrupt. Det er viktig å ha med seg videre at når som helst så kan det komme et interrupt. F.eks. hvis man taster bokstaven A, så vil det da sendes en interrupt til CPU-en som sier at her har det kommet input fra en bruker. Eller kanskje det har kommet en pakke fra nettverket, eller annen input fra. Når som helst kan det skje et såkalt interrupt. Da må CPUN stoppe med å gjøre disse institusjonene. Så må den ta seg av interruptet. Men dette styres da i samarbeid med operativsystemet. Operativsystemet må ha et opplegg for å kunne behandle interrupter. Så jeg tenkte jeg bare tok en veldig kort introduksjon om operativsystemer og operativsystemhistorie. I operativsystemhistorien så... Den er ikke fullstendig. Men jeg bare tenkte å se litt på tidligere Microsoft og Unix' operativstemmer. Som kanskje har vært de mest sentrale. Operativsystemene, i hvert fall de siste 30 årene. Mac er også et sentralt operativsystem. Vi kommer innom det også. Men først en veldig kort oversikt over Microsoft Destop-OS og Server-OS. Og så tilsvarende for Unix og Linux. Dette er faktisk 40 år siden MS-DOS kom ut. Det var et 16-bit-operativsystem. Etter hvert så ser vi at det kom 32-bits. Sånn rundt 2000 er vel kanskje enda en litt, nei... Vinos 95 var det noe 32-bits, og her omtrent så var det", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0004", "start": 636.36, "end": 843.96, "token_count": 591, "text": "Mac er også et sentralt operativsystem. Vi kommer innom det også. Men først en veldig kort oversikt over Microsoft Destop-OS og Server-OS. Og så tilsvarende for Unix og Linux. Dette er faktisk 40 år siden MS-DOS kom ut. Det var et 16-bit-operativsystem. Etter hvert så ser vi at det kom 32-bits. Sånn rundt 2000 er vel kanskje enda en litt, nei... Vinos 95 var det noe 32-bits, og her omtrent så var det en sånn overgang fra Zipper med 16 til 32-bit. Etter hvert rundt år 2000 ble 64-bits vanlig. Det er det aller vanligste nå med 64-bits PU-er. Operativsystemet må da tilpasse seg, sånn at det kan løse alt med 64-bit. Det som gjorde Windows til en ekstrem suksess på 90-tallet, det var først og fremst at jeg hadde en veldig intuitivt og enkelt... Det gjorde at det etter hvert ble allemannseie å ha en PC. Til å begynne med var operativsystemene ganske ustabile, mye mer enn Unix-serverne, som styrte alt på serversiden på denne tiden. Det var vel først rundt 2000 med XB at det virkelig fikk et bra og stabilt... Det som gjorde det, var at det kombinerte... Det hadde samme kjerne som endte 5-1. Man skrev rett og slett hele Operativstemme om helt fra scratch. Så det var et helt annet Operativstemme enn en DOS-operativstemme som kom 20 år senere. Så er Vindow 7 altså en veldig stabil versjon. Nå er det Windows 10 som gjelder, som kom for fem-seks år siden, 2015. Tidligere ser vi at det kom hele tiden nye versjoner med XB, Vista 7, Windows 8 osv. Og Windows 10. Men nå ser det ut som man bare har mindre endringer på Windows 10. Opprinnelig så hadde det med året å gjøre. Altså sånn... Windows 2000 kom i år 2000. Windows 10 var en god stund etter 2010. Men det som kanskje er viktigere, er at tidligere så lagde man, når man lagde software generelt, så hadde man sånne store releaser med store endringer. Nå kommer det en ny release av Windows.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0005", "start": 789.48, "end": 988.9, "token_count": 593, "text": "Tidligere ser vi at det kom hele tiden nye versjoner med XB, Vista 7, Windows 8 osv. Og Windows 10. Men nå ser det ut som man bare har mindre endringer på Windows 10. Opprinnelig så hadde det med året å gjøre. Altså sånn... Windows 2000 kom i år 2000. Windows 10 var en god stund etter 2010. Men det som kanskje er viktigere, er at tidligere så lagde man, når man lagde software generelt, så hadde man sånne store releaser med store endringer. Nå kommer det en ny release av Windows. Dette programmet testet man og holdt på i et par år, og så fikk man en release. Nå er det mye mindre endringer i operativsystemene. Man tester ut endringene og releaser hele tiden. Eller mye oftere enn tidligere. Det samme gjelder Linux-distribusjoner og Linux-kjernen også. Man kommer helt inn med mange... Små endringer som kontinuerlig blir testet. Det er også en generell utvikling i software development. Her er det diverse av Windows ti versjoner. Jeg har ikke fått med den siste. Den kom i siste halvdel av 2020. Det er mulig det har kommet noen enda nyere der. ... og sjekke ut. Spørsmål i chatten om du anbefaler Linux eller Windows. Jeg har rett person til å spørre. Jeg anbefaler Linux. En av de få som alltid har kjørt Linux. Eller iallfall så lenge Linux har eksistert. Jeg kjører jo Windows også, og jeg har en gammel Mac. Men jeg anbefaler Linux fordi man... Har veldig stor frihet. Man kan mekke og hacke og legge inn hva som helst. Det har jo sine ulemper også. Det er klart, hvis man gjør for mye krumspring, så kan ting også gå galt. Men man har en veldig stor frihet, og så er alt åpen kildekode. Det har også endret seg når det gjelder... Tidligere var Windows helt lukket, men nå er det åpen kildekode. Hvilken Linux-distry du liker best... Der har jeg ikke så veldig sterke preferanser. Stort sett alltid brukt Ubuntu, for det er enkelt og greit. Og det er mye brukt. Debian har jeg brukt også, som er litt renere, på en måte.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0006", "start": 948.48, "end": 1148.08, "token_count": 590, "text": "Men man har en veldig stor frihet, og så er alt åpen kildekode. Det har også endret seg når det gjelder... Tidligere var Windows helt lukket, men nå er det åpen kildekode. Hvilken Linux-distry du liker best... Der har jeg ikke så veldig sterke preferanser. Stort sett alltid brukt Ubuntu, for det er enkelt og greit. Og det er mye brukt. Debian har jeg brukt også, som er litt renere, på en måte. Ikke har så mye kommersiell og ekstern programvare. Men ellers har jeg tror Red Hat et veldig stabilt operativsystem. Det har jeg ikke brukt veldig mye. Vi brukte noe på serveren her. Når det gjelder Windows eller Linux, så er det klart det har hver sine bruksområder. Stort sett ikke så veldig mange som kjører Linux. Men det fungerer veldig greit å kjøre det i dag. Det var mye verre sånn rundt 95, over 2000. Når du da kjørte Linux, så fungerte det veldig dårlig i samarbeid med Windows, f.eks. Men nå så går det ganske greit med alt, liksom... Man kan oppnå stort sett det samme med en Linux desktop som en Windows. Kanskje spill er fortsatt litt forskjellig, fordi Gui i Linux kjører i use of space. Mer om det senere. Men på den annen side så er det ikke så stor forskjell lenger på hva slags destop man har. Fordi i større og større grad så bruker man jo nettapplikasjoner som er nettbaserte. For å kunne kjøre alle applikasjoner som e-post og dokumentbehandling osv. Sånn rundt 2000 så var det virkelig sånn religionskrig mellom Windows og Linux osv. Men det har nok glattet seg litt ut etter hvert, fordi det ikke har så stor betydning når alt kjøres på nett. Ja... Microsoft har også en serverside. Når de første kom i 1993, så var de en veldig liten minoritet blant serverne. De aller fleste kjørte Unix-servere på den tiden, og etter hvert Linux. Men nå, særlig siden 2010, så har Windows-server blitt mer og mer brukt. Så nå kjører du Windows-server i mange serverrom. Ofte i kombinasjon med Linux-servere. Men fortsatt er nok Linux enda større.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0007", "start": 1104.34, "end": 1330.12, "token_count": 598, "text": "Ja... Microsoft har også en serverside. Når de første kom i 1993, så var de en veldig liten minoritet blant serverne. De aller fleste kjørte Unix-servere på den tiden, og etter hvert Linux. Men nå, særlig siden 2010, så har Windows-server blitt mer og mer brukt. Så nå kjører du Windows-server i mange serverrom. Ofte i kombinasjon med Linux-servere. Men fortsatt er nok Linux enda større. Vi skal se på noen tall senere, altså på serversiden, når det gjelder servere som drifter webservere over hele verden f.eks. Så er antallet Linux-servere litt større. Noe som er viktig både på Linux- og Microsoft-siden, er virtualisering. Azure kjører Windows-servere i storskala virtuelt. Unix operativstemmer. Det er på en måte en helt annen verden. Det... Ja, men opprinnelig, sånn på 80-tallet, så var Unix på en måte der Linux var for ti år siden. Nytt og spennende og åpen kildekode og brukt på universiteter osv. Så utviklet det seg til kommersielle 64-bit-OS. Da var det filmer som IBM, Sun, HP, Silicon Graphics og andre som bygde egne Unix operativsystemer. De hadde egen hardware med helt egne institusjoner osv. Og så hadde de et eget operativsystem. Så hadde Sun spark-prosessorer og også sitt eget operativsystem. Så det var mange forskjellige operativsystem, og de konkurrerte med hverandre. Det endte etter hvert med at Linux tok over rollen til alle disse her, og nå er det veldig få av den type Unix-operativsystem som eksisterer. De som kjører ute i serverom, er Linux- eller Windows-servere. Det var disse frie Unix-kronene som etter hvert tok over. Som da var åpen kildekode-varianter av de store kommersielle Unix-systemene som var lukket. Og der var også lukket kildekode. Spesielt Linux er åpen kildekode og har tatt over veldig mye av... Det som er i selve verden. Spesielt sånn HP, high performance computing, så er alle de tusen raskeste high performance computerne bygd på Linux. Ja, Macoa er også delvis bygd på Linux. Mac-kjernen Darwin, den bygger delvis på friBSD. Så sånn sett kan du si at Mac har noe av Unix i seg.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0008", "start": 1275.24, "end": 1481.04, "token_count": 599, "text": "av de store kommersielle Unix-systemene som var lukket. Og der var også lukket kildekode. Spesielt Linux er åpen kildekode og har tatt over veldig mye av... Det som er i selve verden. Spesielt sånn HP, high performance computing, så er alle de tusen raskeste high performance computerne bygd på Linux. Ja, Macoa er også delvis bygd på Linux. Mac-kjernen Darwin, den bygger delvis på friBSD. Så sånn sett kan du si at Mac har noe av Unix i seg. Og vi kan også se at f.eks. hvis du har en Mac, så kan du bare kjøre et vanlig skjell, et bærskjell. Så det er ganske tett integrert med Linux. Ikke så veldig stort forsøk. En liten gjennomgang av Linux-historie. Nå skal vi gå inn på et helt nytt tema, nemlig multitasking. Aller først skal vi for tredje gang se på CPU-løkken. Det er dette vi må ha med videre. CPU-en står da bare og om og om igjen kjører instruksjoner. Det vi skal se litt nærmere på nå, er interrupt request. For en gang iblant så kan det komme et fysisk interruptororkest, f.eks. ved at jeg taster på tastaturet sånn. Maskinen må da reagere på den inntastingen veldig hurtig. Og det som da skjer, er at CPU-en avbrytes i sin evige løkke. Og så håndterer den da det signalet. Ofte bruker sepunden noen mikrosekunder på å fullføre det den er i gang med. Og så hopper den til en interrupt-rutine, som da sørger for at den piltasten som jeg trykket på, at den har en effekt. Men sepunden må avbrytes for å håndtere det signalet. Og da må man... Lagre adressen til neste institusjon og så hoppe til en interrupt-rutine. Det blir litt sånn som å gjøre et kall på en rutine, men her er det en fysisk interrupt som sendes inn, og så gjøres det da kall på rutinen. Og hvert interrupt, eller IRQ, har sin egen rutine som man da hopper til. Så det er én rutine hvis det kommer noe fra tastaturet, en annen hvis det kommer fra nettverket. Hvis det kommer fra mikrofonen osv. Vi skal se på multitasking.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0009", "start": 1440.0, "end": 1640.32, "token_count": 594, "text": "Lagre adressen til neste institusjon og så hoppe til en interrupt-rutine. Det blir litt sånn som å gjøre et kall på en rutine, men her er det en fysisk interrupt som sendes inn, og så gjøres det da kall på rutinen. Og hvert interrupt, eller IRQ, har sin egen rutine som man da hopper til. Så det er én rutine hvis det kommer noe fra tastaturet, en annen hvis det kommer fra nettverket. Hvis det kommer fra mikrofonen osv. Vi skal se på multitasking. For å forstå multitasking er det viktig å vite hvordan minne eller ramm er koblet sammen med prosesser. Vi skal senere fokusere på ramm... Det vi trenger å vite nå, er at det finnes flere deler i ramm som er tildelt en prosess. Dette som vi viser bildet her nå, det er én bit av ramm som er tilordnet én prosess. Operativsystemet er også en egen prosess, og vil også ha en egen del av rammen. Den viktigste biten er kanskje koden, eller teksten, som vi ser her nede. Unnskyld. Koden, det er da maskininstruksjonene som prosessen skal kjøre. Som ligger etter hverandre. Institusjon for institusjon. Så det typiske som skjer når en prosess kjører, er at man starter på første institusjon til prosessen, og så løper den nedover. Men så har vi sett at vi hele tiden har variabler i programmet, som brukes og skrives til ram. Og da i heapen, som går fra koden her og oppover... Det er satt av masse plass til heapen, sånn at den kan utvide seg. For her kan man dynamisk legge inn nye variabler, nye RA f.eks. Det legges da på heapen. Stacken er et område hvor lokale variabler legges. F.eks. hvis du gjør et funksjonskall, så legger du på stacken returverdien fra det funksjonskallet, som at man vet hvor man skal tilbake. Så da er det enkelt å bare gå inn der, så plukker du opp returverdien, I tillegg er det vanlig å ha en MM-mapp, som er en avbildning av filer og devices inn i ramm. Men dette er igjen for at ting skal gå fortere. Så er det en kopi av noe av det som ligger på disk,", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0010", "start": 1601.36, "end": 1798.92, "token_count": 577, "text": "F.eks. hvis du gjør et funksjonskall, så legger du på stacken returverdien fra det funksjonskallet, som at man vet hvor man skal tilbake. Så da er det enkelt å bare gå inn der, så plukker du opp returverdien, I tillegg er det vanlig å ha en MM-mapp, som er en avbildning av filer og devices inn i ramm. Men dette er igjen for at ting skal gå fortere. Så er det en kopi av noe av det som ligger på disk, sånn at man skal ha raskere aksess. Men først og fremst så er det kode, og heap er det vi snakker om. Her ligger alle variabler, og her ligger instruksjoner. Singeltasking.os. Tidligere så var det dette som var måten datamaskiner kjørte på. Man hadde bare... Man kjørte bare én oppgave av gangen. Enten var det brukerprogrammet som kjørte den, eller OS. Og da ser vi... For selv om det var singeltasking... Singeltasking betyr at det da er bare én prosess som kan kjøre av gangen. Det typiske som skjedde når man kjørte singeltasking OS... For at operativsystemet startet opp først. Og så hadde man da ett brukerprogram. Og når dette skulle kjøre, så satte OS i gang brukerprogrammet og kjøre. Og så hadde da Device-minne, Skjerm-minne osv., Brukerdata eller Keep og Stack. Det var da bare én prosess som kunne kjøre av gangen. Et sånt batch-computing... Du hadde kanskje en rein operasjon som kunne ta en halvtime, og da satte operativstemmet i gang denne operasjonen. Og så kjørte den til den var ferdig, og så kunne neste program starte. Men alle moderne systemer har multitasking, og det er da et system som kan... Den får N, et antall programmer, til å kjøre samtidig. Så sånn som her, så har vi et operativsystem som har to prosesser som kjører samtidig. Og det måten operativsystemet får til det på, det er at den deler opp tiden. Altså gir den litt tid til hver prosess, sånn at det ser ut som de kjører samtidig. Men egentlig så kjører de annenhver gang.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0011", "start": 1761.6, "end": 1969.76, "token_count": 586, "text": "Men alle moderne systemer har multitasking, og det er da et system som kan... Den får N, et antall programmer, til å kjøre samtidig. Så sånn som her, så har vi et operativsystem som har to prosesser som kjører samtidig. Og det måten operativsystemet får til det på, det er at den deler opp tiden. Altså gir den litt tid til hver prosess, sånn at det ser ut som de kjører samtidig. Men egentlig så kjører de annenhver gang. Så ser det ut som de kjører samtidig, og det er rett og slett multitasking. Men vi ser... Hver prosess vil ha sitt eget område med heap og stack og program eller tekst eller kode. Og også IO-områder, altså for å snakke med disk, ta imot fra tastatur osv. Så hver prosess har da et sånt område på ramm. Multitasking er det systemet som operativsystemet bruker for å kjøre prosesser samtidig. Hovedideen her er at CPU-tiden blir delt opp i små biter. Og en liten bit av tiden man kan kjøre, er et hundredels sekund. Og da har man en såkalt round robin queue. Og så har man en hardware-timer. Skal se på dette i detalj. Hvert hundredels sekund så sender et interrupt-signal til Sippu. Og så starter man opp den første... Den første OS-institusjonen. Den legges da i... Og så lar OS hver prosess etter tur bruke CPU-en. CPU-en går da på rundgang mellom alle prosesser som ønsker å kjøre. Så det kan se ut noe sånt som dette her. Her har vi tre prosesser, P1, P2, P3, som kjører etter hverandre. Millisekunder er ett tusendels sekund. En typisk tid P1 kjører, er i ti millisekunder. Altså ett hundredels sekund. Men på ett hundredels sekund kan én prosess som står og kjører, gjøre millioner, for ikke å si milliarder, av institusjoner. Millioner av institusjoner kan den gjøre. Og da får operativstemme, får dette til å se ut som om alle disse tre prosessene kjører samtidig. Men i virkeligheten, når du bare har én CPU, så er det bare én prosess som kjører av gangen.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0012", "start": 1928.36, "end": 2118.04, "token_count": 590, "text": "En typisk tid P1 kjører, er i ti millisekunder. Altså ett hundredels sekund. Men på ett hundredels sekund kan én prosess som står og kjører, gjøre millioner, for ikke å si milliarder, av institusjoner. Millioner av institusjoner kan den gjøre. Og da får operativstemme, får dette til å se ut som om alle disse tre prosessene kjører samtidig. Men i virkeligheten, når du bare har én CPU, så er det bare én prosess som kjører av gangen. Så P1 kjører i 10 mil eller sekunder, så kommer det en Context Switch. Det er ganske omfattende. Da må OS lagre alt om denne prosessen her. Husker det er et levende liv som leves. Så alt som eksisterer om Prosess 1, det må lagres. Alle verdier i registeret, f.eks. Alt den har i ramm, er allerede lagret i ramm. Men all kontekst, all info om den prosessen, det må lagres. Og så må all konteksten til P2, den må lastres inn. F.eks. hvilke verdier registerene hadde når P2 stoppet sist. Sånn fortsetter det. Man bytter med Context Switcher hele veien, og så kommer P1 inn igjen. Og så bytter de om å kjøre på denne nå. PCB er prosesskontrollblokk. Det er da en blokk i ramm som inneholder all den informasjonen som trengs om en... CPU-registeret f.eks. peker etter stack-prosess-tilstand. Om den venter på noe, f.eks. Alle prosesser har en payday. Eier, prioritet osv. Masse informasjon som må lagres om hver enkelt prosess. Den operasjonen som operativsteamet gjør for å bytte om på prosesser, CPU-skjeduling er å fordele CPU-tid mellom prosessene. Det kalles ofte også timesharing. Ved hvert timer interrupt så vurderer operativsteamet om scheduleren skal kalles. For at ting skal gå fortere, så er det ikke alltid at man gjør et bytte. Som vi ser hvis vi går tilbake her. Hvis verken P1 eller P3 ønsker å bruke CPU-en, så kan det være at P2 bare fortsetter. For å få kontekstswitch-tiden til å gjøres så raskt som mulig,", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0013", "start": 2075.92, "end": 2264.74, "token_count": 583, "text": "Det kalles ofte også timesharing. Ved hvert timer interrupt så vurderer operativsteamet om scheduleren skal kalles. For at ting skal gå fortere, så er det ikke alltid at man gjør et bytte. Som vi ser hvis vi går tilbake her. Hvis verken P1 eller P3 ønsker å bruke CPU-en, så kan det være at P2 bare fortsetter. For å få kontekstswitch-tiden til å gjøres så raskt som mulig, så er det noen ganger man bare sjekker. Nei, ok, ingen andre ønsker å kjøre. Da bare fortsetter P2. Men det er da scheduleren, som er en del av operativsystemet. Den avgjør hvilken prosess som skal velges, når den blir kalt. Det å switche fra én prosess til en annen, kalles en context switch. All informasjonen må da først lagres for P1 og så hentes inn for P2. Så dette tar tid, og det er litt overhead å gjøre denne context switchen. Her ser vi alt som skjer i en kontekst-switch. Hvis vi tenker oss at prosess 1 kjører, og så switcher vi til prosess 2. Da vil jo prosess 1 bruke CPU-en. Og midt inni en operasjon, så kan det være at AX er lik 5. Neste institusjon som skal utføres, kan kanskje være at AX skal legges ut igjen. Verdien på AX må da lagres for prosessen. Så det er en ganske komplisert prosess, en context stetch. Det er jo en masse andre register og informasjon som må lagres av prosessen. Men all denne informasjonen for prosess 1 lages da i ramm i PCB1. Neste prosess som skjer, er at PCB2 må lastes inn. All informasjon fra PCB2 må da lastes inn i alle områder som beskriver den kjørende prosessen. Operativstemme ordner ikke alt dette her. For vi ser noe sånt som å laste inn alle verdier av institusjoner. Det blir litt vanskelig, for du må jo bruke registrene... for å kjøre programmet. Hvis operativstemme skulle gjøre det, så ville operativstemme også endre registerverdiene. Så der er det hardwareoperasjoner som kommer inn, som på én smell bare legger inn alle verdiene fra et lager. Sånn at dette blir én operasjon.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0014", "start": 2227.92, "end": 2418.26, "token_count": 589, "text": "Operativstemme ordner ikke alt dette her. For vi ser noe sånt som å laste inn alle verdier av institusjoner. Det blir litt vanskelig, for du må jo bruke registrene... for å kjøre programmet. Hvis operativstemme skulle gjøre det, så ville operativstemme også endre registerverdiene. Så der er det hardwareoperasjoner som kommer inn, som på én smell bare legger inn alle verdiene fra et lager. Sånn at dette blir én operasjon. Så kan man hoppe til neste institusjon. Da står det lagret PC et eller annet sted. Det siste som skjer etter at all informasjon er lagt til, er at da hopper man til programkontoren som kjører neste instruksjon. Ja... Multitasking i praksis... Vi skal se veldig kort på hvordan vi kan kjøre programmer, og hvordan det ser ut når vi kjører såkalt CPU. Veldig mange vanlige programmer bruker ikke noe særlig CPU. Det er ikke så mye de gjør. Ofte så venter de på noe input fra brukeren. En teksteditor f.eks. den venter hele tiden på klikk fra brukeren. Så finnes det andre CPU-avhengige prosesser. F.eks.... Et regneprogram. Det vil bruke CPU-en hele tiden. Så noe som man utnytter i en multitasking, er at veldig mange prosesser står egentlig bare og venter på CPU. Det gjør ikke så veldig mye. Men vi skal først se på såkalte CPU-avhengige prosesser. Det er prosesser som da hele tiden står og regner. Her er et enkelt cellscript. Som egentlig bare er en løkke som står og legger sammen tall. Sum pluss er like i. Det gjør dette skriptet om og om igjen. Det er en typisk CPU-avhengig prosess. Som hele tiden vil prøve å bruke så mye CPU-en bare kan. For å bli fortest mulig ferdig. Hvis du har flere sånne prosesser på en enkelt CPU, så må de hele tiden bytte opp. Vi skal straks se på det. Men aller først, så har man også i tillegg prosesser som er IO-bound. Eller som er som hele tiden venter på og bruker input og output. Det er sånn som webbroser og teksteditorer og regneark og sånn som stort sett ikke gjør så veldig mye.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0015", "start": 2383.16, "end": 2617.88, "token_count": 594, "text": "For å bli fortest mulig ferdig. Hvis du har flere sånne prosesser på en enkelt CPU, så må de hele tiden bytte opp. Vi skal straks se på det. Men aller først, så har man også i tillegg prosesser som er IO-bound. Eller som er som hele tiden venter på og bruker input og output. Det er sånn som webbroser og teksteditorer og regneark og sånn som stort sett ikke gjør så veldig mye. Det fine med multitasking er at da kan man hele tiden kombinere... Den type programmer. For hvis man bare hadde en sekvensiell CPU, som hele tiden måtte gjøre først A og så B... Hvis man hadde to prosesser, så ville hele de oppgavene... Her er det én prosess A, som først gjør CPU, så bruker den IO, og så CPU. Hvis vi skal gjøre det etter hverandre, så måtte det pent vente på. Men her kan operativstem utnytte det at Prosess A trenger CPU. Men så gjør den noe i henne, kanskje den skriver til RAM eller leser fra disk. Og da kan jo Prosess B bruke CPU-en. Da blir den prosessa kastet ut. Og så hives Prosess B inn i CPU-en, og så bytter de på sånn. Og dette er multitasking, og det gjør at man... Selv på én CPU kan man ha en rekke prosesser som står og kjører samtidig, uten at den blir overbelastet. Jeg har brukt mye tid her, men hvis dere holder ut, så skal jeg veldig kort kjøre en demo av multitasking på en server. Skal vi se. Så da... Hopper vi hit... Oi. Nei, det fungerte ikke så bra. Da får vi... Et lite øyeblikk. Der, kanskje. Der var vi inne. Ok, nå... Vi kan rydde opp litt her. Nå er jeg inne på én server. Og så skal jeg bare kjøre en... Jeg har en liten regnejobb. Har et program som heter Adopt-Alt. Som er CPU-avhengig. Og som bare står og bruker CPU. Da kan jeg samtidig kjøre Topp. Da ser vi... Topp viser nå øverst en linje med det programmet som kjører. Vi kan også ta tiden på programmet med time. Jeg starter på nytt, og da ser vi øverst der... Så er det en prosess som står og kjører.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0016", "start": 2573.28, "end": 2775.82, "token_count": 590, "text": "Jeg har en liten regnejobb. Har et program som heter Adopt-Alt. Som er CPU-avhengig. Og som bare står og bruker CPU. Da kan jeg samtidig kjøre Topp. Da ser vi... Topp viser nå øverst en linje med det programmet som kjører. Vi kan også ta tiden på programmet med time. Jeg starter på nytt, og da ser vi øverst der... Så er det en prosess som står og kjører. Og den ser vi bruker 100 % CPU. Hvis jeg taster tallet én i topp, så ser vi at det kommer fram én CPU her oppe. Og her er det bare CPU0. Så dette er en server som bare har én enkelt CPU. Det er det nesten umulig å få tak i. Altså alle dagens servere eller CPU-er har minst to CPU-er. Denne her har egentlig åtte CPU-er, men jeg har bare skrudd av de andre for å vise denne demoen her. Så det man kan gjøre, det er å kjøre... Prøv se hva som skjer. Jeg kjører nå to regneoppgaver samtidig. Da legger jeg henne i bakgrunnen sånn... To stykker. Og da ser vi... Her er det nå to prosesser som heter adopt out. Og vi ser de deler nå likt på CPU-en. Disse to her... Her er det en rad som sier CPU. Her ser vi hver av de for 50 %. Hvis jeg nå starter en til, så ser vi... Da kommer den inn også. Men da får hver av de 33 %. Da deler de likt på den ene CPU-en. Sånn fungerer multitasking når man bare har én CPU. De deler da på CPU-en. De kjører halvparten hver, men de kjører ca. ett hundredels sekund hver. Og så bytter de på hvem som kjører. Hele tiden bytter operativstemme frem og tilbake mellom de to prosessene. Så skal vi veldig kort se på hva som skjer hvis jeg nå starter opp én CPU til på denne serveren. Jeg kan gjøre det. Men nå startet jeg opp en server til. Nei, en CPU til. Hvis jeg nå taster én, så ser vi at jo, her dukker det opp to CPU-er. Så nå har denne serveren tilgang til to CPU-er. Og hva skjer da hvis jeg starter to programmer samtidig?", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0017", "start": 2728.74, "end": 2926.32, "token_count": 600, "text": "Hele tiden bytter operativstemme frem og tilbake mellom de to prosessene. Så skal vi veldig kort se på hva som skjer hvis jeg nå starter opp én CPU til på denne serveren. Jeg kan gjøre det. Men nå startet jeg opp en server til. Nei, en CPU til. Hvis jeg nå taster én, så ser vi at jo, her dukker det opp to CPU-er. Så nå har denne serveren tilgang til to CPU-er. Og hva skjer da hvis jeg starter to programmer samtidig? Jo, da ser vi her oppe... Så ser vi at... Nå jobber disse prosessene på hver sin CPU. Den får 100 % på den ene CPU-en, og den får 100 % på den andre. Men da vil det bli sånn at hvis jeg nå starter tre prosesser av den typen, så får de ca. 67 % hver. Da fordeler de CPU-tiden seg imellom på den måten. Og det går også an å se nøyaktig hvordan det skjer. Skal vi se om jeg er rask nok til å få til det. La oss si jeg starter tre prosesser her. Så ved å taste F så kan jeg gå inn i Topp. Jeg tastet nå F. Og så kan jeg gå ned og finne Last Use CPU. Så ser vi helt ytterst her, så har vi fått et nytt felt hvor det står 1.0.0. Nå var jeg litt sein, jeg kan starte på nytt. Starter nå tre A.8.-prosesser. Helt til høyre her så ser vi en null og en ener. Og da ser vi at de bytter på. Noen ganger så kjører begge på CPU1 og én på CPU0. Og så andre ganger så kjører begge på CPU0. Typisk så kjøres da én prosess på hver av CPU-ene, og så vil den tredje prosessen bytte mellom. Nei, det er ikke helt riktig. Fordi operativstemme har en scheduler som kalles fair scheduler. Så når tre prosesser kjøres på denne måten her... Det som i praksis skjer, er at alle tre bytter likt. Hver prosess får ca. to tredjedeler CPU-tid, hvor den har tilgang til CPU-tid. Og på den måten får de i snitt 67 % CPU-tid. OK. Da tenker jeg dere er passe slitne, så da skal vi slutte der. Men det er noen oppgaver denne uken som går ut på dette her.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0018", "start": 2891.04, "end": 3092.02, "token_count": 590, "text": "Så når tre prosesser kjøres på denne måten her... Det som i praksis skjer, er at alle tre bytter likt. Hver prosess får ca. to tredjedeler CPU-tid, hvor den har tilgang til CPU-tid. Og på den måten får de i snitt 67 % CPU-tid. OK. Da tenker jeg dere er passe slitne, så da skal vi slutte der. Men det er noen oppgaver denne uken som går ut på dette her. Nå kjørte jeg et CPU-program, men man kan også kjøre regn her. Det er det regneprogrammet jeg viste. Det vil oppføre seg på samme måte. Hvis jeg kjører et par regneprogram, så får de hver sin CPU. I snitt 67 % CPU hver. Fordi operativsystemene da bytter om på hvilken CPU de bruker. Sånn teoretisk så vi i dag mest på operativsystemer hvordan de kjører på én CPU. Men det er klart operativsystemet også da kunne gå inn og fordele prosesser på de forskjellige CPU-ene, som vi så vidt så på her. Så i oppgaven denne uken så skal dere teste ut dette her. Både på studio SSO og kjøre regnejobber. Men også på... Også på de Linux-VM-ene. Og der er det litt annerledes, for hvis på Linux-VM-ene... Hvis dere gjør topp der og taster én, så vil dere se at dere har noe sånt som 96 CPU-er. Men de konteinerne dere har, er satt opp sånn at de bare får tilgang på to CPU-er. Eller i snitt så får de så mye CPU-tilgang. Det er da begrenset på en annen måte. Ikke sånn som med fysiske servere, hvor du har fire CPU-er, og de er de du har. Men med virtuelle maskiner og med konteinere så kan man... Da kan man tildele et antall sepur. Med dockercontainere blir man tildelt en prosentdel. De dere har, er tildelt sånn at de får i snitt to sepur å kjøre på. Mens på studiesesong har hver VM fire sepur som man kan kjøre på. I oppgavene denne uken. Da er spørsmålet om dette var en CPU-avhengig prosess. Kunne gjentatt noen prosesser som ikke er så avhengige av CPU-er.", "source": "lecture"}
{"lecture_id": "os6time2", "chunk_id": "os6time2_0019", "start": 3047.88, "end": 3242.6, "token_count": 535, "text": "Da kan man tildele et antall sepur. Med dockercontainere blir man tildelt en prosentdel. De dere har, er tildelt sånn at de får i snitt to sepur å kjøre på. Mens på studiesesong har hver VM fire sepur som man kan kjøre på. I oppgavene denne uken. Da er spørsmålet om dette var en CPU-avhengig prosess. Kunne gjentatt noen prosesser som ikke er så avhengige av CPU-er. Ja, det er det. Egentlig de fleste prosesser er ikke avhengige av CPU-er. De står bare og venter på at noe skal skje, sånn som en teksteditor. Hvis du skriver veldig fort, så får den kanskje hvert ti tegne sekunde. At det skjer hvert tiendedels sekund... Da kan man gjøre en million instruksjoner i mellomtid. F.eks. en webbroser også. Selv om det er en del prosessering den må gjøre, så bruker den ikke 100 % CPU. Det kan man se på topp her. På den Linux-maskinen som kjører. Sånne som R-server. Bruker nesten ikke noe CPU. Så en gang iblant kommer det opp noen programmer som bruker litt CPU. Men hvis du ser på sånne som OBS Studio... Vi kan se på den maskinen jeg sitter på. Ja... Nå får jeg ikke opp det. Vi kan se på det neste gang. Litt mer i det... Vi skal fortsette å kjøre prosesser og se på multitasking. Men det ser vi at vi har brukt et kvarter over tiden. Så nå trenger vi en pause. Så da stopper vi der, og så ser vi mer på multitasking neste uke. Jo, jeg fikk i pausen beskjed av... At Ine er sykemeldt... Så hun er ikke her i dag, men det vil... Likevel så har vi to studentassistenter. Jeg håper Berrecutt er her i dag. Kan du høre meg, Berrecutt? Nei, vi får se. Han dukker opp. Jeg skal i hvert fall lage breakout rooms. Meg og to studenter, så gå inn der og spør om hjelp hvis dere står fast. Men da stopper vi der.", "source": "lecture"}
