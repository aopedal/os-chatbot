{"identifier": "linux5.2", "section_id": "5.2", "section_title": "Passord-kryptering", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00062000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.2 Passord-kryptering\n\nAlle brukere på en Linux server har en linje i /etc/passwd. For eksempel:\n\n```\nrex:~$ grep haugerud /etc/passwd\nhaugerud:x:285:1001:Hårek Haugerud,,,:/home/haugerud:/bin/bash\n```\n\nTidligere stod det en hash av passordet der istedet for x i andre kolonne. Denne hashen er en kryptert versjon av passordet og ligger nå i `/etc/shadow` og kan bare leses av root. Det er kun hashen som lagres og dette gjør at man kan logge inn på en datamaskin uten at passordet er lagret i klartekst noe sted. Om en slik liste med passord i klartekst blir lekket, ville det vært katastrofe. Men det er også alvorlig om en liste med passord-hasher blir fritt tilgjengelig.\n\n```\nrex:~$ sudo grep haugerud /etc/shadow\n[sudo] passord for haugerud: \nhaugerud:$6$WXQf3H3AUREz8y$IRYwxMcpK/aTX4oF.xEJrol.Va7cjGY4V.93wkKCc3Tcd9JV0mPIPjyqBuljB3UPw6.VPJx/ymiCJlxsk5lBv.:17835:0:99999:7:::\n```\n\nHashen kan (med rett 'salt') genereres med kommandoen `mkpasswd` :\n\n```\nrex:~$ mkpasswd -m sha-512 -S WXQf3H3AUREz8y\nPassord: \n$6$WXQf3H3AUREz8y$IRYwxMcpK/aTX4oF.xEJrol.Va7cjGY4V.93wkKCc3Tcd9JV0mPIPjyqBuljB3UPw6.VPJx/ymiCJlxsk5lBv.\n```\n\nHvilken kryptografisk hashing-metode som er brukt kan sees av de første tegnene i hashen:\n\n| Første tegn | Algoritme |\n|-----------|---------|\n| To tegn | DES (13 totalt) |\n| $1$ | md5 |\n| $5$ | sha256 |\n| $6$ | sha512 |\n\nSaltet er de etterfølgende tegnene frem til $-tegnet. Dette saltet gjør det vanskeligere å bruke enkelte brute force metoder som rainbow tables for å cracke passord om man kjenner en hash for et passord. Ved login skjer følgende:\n\n* Man taster passord\n* Login-shellet krypterer passordet\n* Sjekker mot /etc/shadow\n* Hvis likt login\n\nIllustrasjon:\nPassordkryptering\n\nFor 4 år siden lå alle bruker-hashene i `/etc/shadow` , men nå autentiseres den som logger seg inn på studssh ved hjelp av PAM (pluggable authentication module) mot AD (Active Directory) sentralt på OsloMet."}
{"identifier": "linux5.2.1", "section_id": "5.2.1", "section_title": "Hashing-algoritmer", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00062100000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.2.1 Hashing-algoritmer\n\nMed `mkpasswd` kan man velge hvilken hashing-metode man vil bruke:\n\n```\n$ mkpasswd -m help\nAvailable methods:\ndes\tstandard 56 bit DES-based crypt(3)\nmd5\tMD5\nsha-256\tSHA-256\nsha-512\tSHA-512\n```\n\nDette er enveisalgoritmer som for et gitt passord generere en entydig lengre streng av tegn. DES var tidligere standard, men ble så avløst av MD5 som er noe bedre, og nå er sha-512 standard metode for Linux. De samme prinsippene gjelder for Windows-innlogging, der lagres hash-strengene i SAM-databasen på en lokal Windows-maskin eller på en sentral server i Active Directory. Tidligere var LM-hash(DES) standard, men den ble etterhvert avløst av NTLM-hash(MD5) og etterhvert av kraftigere algoritmer som AES(Advanced Encryption Standard)."}
{"identifier": "linux5.2.2", "section_id": "5.2.2", "section_title": "Passord-cracking", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00062200000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.2.2 Passord-cracking\n\nHvis man har tilgang til shadowfilen på Linux eller SAM-databasen på Windows, kan et crack-program kryptere alle ord og kombinasjoner av ord i en ordbok og sammenligne med de krypterte passordene. Hvis ett av de riktige passordene velges, vil det avsløres ved at det gir en av hashene. Slike program kan teste hundretusner av passord per sekund, slik at passord fra ordbøker veldig raskt kan knekkes. Jo lengre passordene er og jo flere tegn som brukes i passordene, desto mer tidkrevende er det for passord-cracker program å teste ut alle mulige kombinasjoner.\n\nHvis man går ut ifra 52 tegn (a-z og A-Z), 10 tall og 32 spesialtegn, har man totalt 94 mulige tegn i et passord. Og om man har en kraftig GPU-server kan man regne ut en million hasher i sekundet for algortimer som sha512, mange flere for enklere algortimer. For åtte tegn i passordet er det eller 218 billioner mulige kombinasjoner. For å finne hash'ene for alle mulige kombinasjoner, tar det da i underkant av 7 år om man regner ut en million hash i sekundet. Tid for forskjellige lengder av passord er vist i følgende tabell:\n\n| Lengde | tid (36 tegn) | tid (62 tegn) | tid (94 tegn) |\n|------|-------------|-------------|-------------|\n| 4 | 1.7 sekunder | 15 sekunder | 78 sekunder |\n| 6 | 36 minutter | 16 timer | 192 timer |\n| 8 | 32 dager | 6.9 år | 193 år |\n| 10 | 116 år | 26.6 tusen år | 1.7 millioner år |\n\nTil sammenligning er det ca en million ord i en norsk ordbok som tar med alle varianter av norske ord, slik at det kun tar ett sekund å finne et passord som er med i en ordbok om man kjenner hashen for passordet.\n\nMan ser at lengden på passordet er veldig viktig for hvor raskt det kan være å gjette ved hjelp av et brute force angrep på en hash. I tillegg hjelper det at store bokstaver og spesialtegn tas med."}
{"identifier": "linux5.3", "section_id": "5.3", "section_title": "find", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00063000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.3 find\n\nDenne kommandoen kan brukes til å finne filer på systemet. Det er mulig å spesifisere en rekke kriterier. Ønsker man å finne alle filer (og mapper) i hjemmekatalogen som har filendelse c, kan man bruke\n\n```\nhaugerud@studssh:~$ find ~ -name \"*.c\"\n/iu/nexus/ua/haugerud/os/funk.c\n/iu/nexus/ua/haugerud/os/old/main.c\n/iu/nexus/ua/haugerud/os/old/sum.c\n```\n\nFor å finne alle filer og mapper som ble endret mer nylig enn 4 februar 2019 kl 19:55, kan man gjøre\n\n```\nhaugerud@studssh:~$ find . -newermt \"4 Feb 2019 19:55\"  -ls \n     9714      4 drwxr-xr-x  20 haugerud drift        4096 feb.  5 10:28 .\n    29479      4 -rw-------   1 haugerud drift         318 feb.  5 10:28 ./.Xauthority\n    29374      4 -rw-r--r--   1 haugerud drift          10 feb.  5 20:07 ./fil\n```\n\nder `-ls` gir en mer detaljert listing. Tilsvarende kan man finne alle filer som har blitt endret mellom to tidspunkt med\n\n```\nhaugerud@studssh:~$ find . -type f -newermt \"29 Jan 2019 19:55\" ! -newermt \"29 Jan 2019 22:55\" -ls \n    29422      4 -rwx------   1 haugerud drift          56 jan. 29 22:40 ./mappe/arg.sh~\n    29423      4 -rwx------   1 haugerud drift          58 jan. 29 22:42 ./mappe/arg.sh\n```\n\nhvor `-type f` gir kun filer."}
{"identifier": "linux5.4", "section_id": "5.4", "section_title": "sed", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00064000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.4 sed\n\nKommandoen sed kan brukes til å bytte ut forekomster av ord i setninger:\n\n```\necho dette er en test | sed s/test/fisk/\necho test og test | sed s/test/fisk/\necho test og test | sed s/test/fisk/g\n```"}
{"identifier": "linux5.5", "section_id": "5.5", "section_title": "sort", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00065000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.5 sort\n\nI tillegg til at man kan sende output fra en Linux-kommando inn til input for en annen, kan man også legge til en rekke opsjoner. På denne måten kan man få til veldig mye med enlinjers sammensatte kommandoer. Manualsiden til sort avslører at opsjonen -k gjør at man kan velge hvilken kolonne man vil sortere med hensyn på, mens -n gjør at man sorterer numerisk slik følgende eksempel viser. Utgangspunktet er filen `biler` som ser slik ut:\n\n```\n$ cat biler\nstudent bmw 500000\nhaugerud berlingo 150000\nkyrre elbil 90000\n```\n\nDenne filen kan man nå sortere som man ønsker med de rette opsjoner."}
{"identifier": "linux5.5.1", "section_id": "5.5.1", "section_title": "Sortert alfabetisk", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00065100000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.5.1 Sortert alfabetisk\n\n```\n$ sort biler\nhaugerud berlingo 150000\nkyrre elbil 90000\nstudent bmw 500000\n```"}
{"identifier": "linux5.5.2", "section_id": "5.5.2", "section_title": "Sortert alfabetisk etter andre kolonne", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00065200000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.5.2 Sortert alfabetisk etter andre kolonne\n\n```\n$ sort -k 2 biler\nhaugerud berlingo 150000\nstudent bmw 500000\nkyrre elbil 90000\n```"}
{"identifier": "linux5.5.3", "section_id": "5.5.3", "section_title": "Sortert numerisk etter tredje kolonne", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00065300000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.5.3 Sortert numerisk etter tredje kolonne\n\n```\n$ sort -n -k 3 biler\nkyrre elbil 90000\nhaugerud berlingo 150000\nstudent bmw 500000\n```\n\nDefault sender sort output til shellet, hvis man ønsker at reaultatet skal lagres i en fil må man be om det\n\n```\nsort -n -k 3 biler > sortertFil\n```"}
{"identifier": "linux5.6", "section_id": "5.6", "section_title": "head og tail", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00066000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.6 head og tail\n\nHvis man ønsker å se kun de 6 første linjene av en utgave av passordfilen på studssh sortert etter femte kolonne kan man bruke `head` for å få til det:\n\n```\nstudssh:~$  sort -t: -k 5 /etc/passwd | head -n 6\naasej:x:2748:1001:Aase Jenssen:/iu/nexus/uc/aasej:/bin/bash\ns137153:x:2603:100:Aasmund Solberg:/iu/cube/u2/s137153:/bin/bash\ns103726:x:1089:100:Abdi Farah Ahmad:/iu/cube/u3/s103726:/bin/false\ns133988:x:1695:100:Abdi Hassan Abdulle:/iu/cube/u2/s133988:/bin/bash\ns123860:x:1090:100:Abdinasir Omar Kahiye:/iu/cube/u2/s123860:/bin/bash\ns141546:x:3449:100:Abdiqadir Said Jama:/iu/cube/u3/s141546:/bin/false\n```\n\nLegg merke til at `-t:` gjør at tegnet : betraktes som skilleledd mellom kolonnene. Evalueringen av en slik pipeline går fra venstre til høyre så hvis man istedet ønsker å se en sortert utgave av de 6 første linjene, får man det med:\n\n```\nstudssh:~$ head -n 6 /etc/passwd | sort -t: -k 5 \nbin:x:2:2:bin:/bin:/bin/sh\ndaemon:x:1:1:daemon:/usr/sbin:/bin/sh\ngames:x:5:60:games:/usr/games:/bin/sh\nroot:x:0:0:root:/root:/bin/bash\nsync:x:4:65534:sync:/bin:/bin/sync\nsys:x:3:3:sys:/dev:/bin/sh\n```\n\nKommandoen `tail` gir i motsetning til `head` de siste linjene. En spesielt nyttig bruk av `tail` er for å se på slutten av log-filer. Hvis man i tillegg tilføyer opsjonen -f vil man kontinuerlig følge med på om det kommer nye linjer til logfilen, for eksempel slik:\n\n```\nsudo tail -f /var/log/auth.log\n```"}
{"identifier": "linux5.7", "section_id": "5.7", "section_title": "cut", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00067000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.7 cut\n\nCut brukes til å klippe ut deler av linjer. Cut leser fra standard input. En vanlig anvendelse er å klippe ut enkelte kolonner fra en tabell.\n\n```\n$cat /etc/passwd | cut -d: -f2 | tail -n 4\ngroup16\nmroot\nnoob\nmunin\n```\n\nHer \"pipes\" innholdet i /etc/passwd til cut, som bruker : som kolonneskille (gitt ved -d:) og som klipper ut kolonne 2 (gitt ved -f2). Dette pipes videre til head, som viser de fire nederst linjene.\n\n```\n$cat /etc/passwd | cut -c -3 | tail -n 4\ngro\nmro\nnoo\nmun\n```\n\nMed switchen -c angir vi at vi ønsker å klippe ut \"`characters\"'. Med - , der er et tall, klipper vi ut bare de første tallene. - tar tegnene fra tegn og ut linja, - tar alle tegnene mellom tegn og ."}
{"identifier": "linux5.8", "section_id": "5.8", "section_title": "Input fra bruker", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00068000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.8 Input fra bruker\n\n```\n#!/bin/bash \n\necho -en \"svar: \\a\" # -n dropper linjeskift\nread answer\necho \"Du svarte $answer\"\n```\n\nopsjonen `-e` muligjør bruk av kontrolltegn som `\\a` , som gir ett pip."}
{"identifier": "linux5.9", "section_id": "5.9", "section_title": "Lese filer og output med while og read", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION00069000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.9 Lese filer og output med while og read\n\nVeldig ofte ønsker man å gå igjennom og prosessere en fil eller tekstoutput fra en kommando linje for linje. Da kan while brukes til å lese input og read til å behandle linje for linje, som i skriptet read.sh:\n\n```\n#! /bin/bash\n\ni=0\nwhile read LINE \ndo\n   (( i++ ))\n   echo \"Linje nr $i: $LINE\"\ndone\n```\n\nread leser linje for linje fra STDIN slik at\n\n```\n$ read.sh < /etc/passwd\n```\n\nvil lese passordfilen. `read LINE` returnerer 0 (alt OK) helt til EOF og da stopper while.\n\nIFS kan endre hvordan `read` leser inn dataene og filen kan også sendes til `read` inne i scriptet::\n\n```\n#! /bin/bash\n\n#haugerud:x:285:102:Hårek Haugerud:/iu/nexus/ud/haugerud:/bin/bash\nIFS=:\nwhile read brnavn x ID GR NAVN HOME SHELL \ndo\n   echo \"$brnavn: $NAVN\"\ndone < /etc/passwd\n```\n\n`read` leser fra STDIN og dit kan linjene også sendes med en pipe:\n\n```\n#! /bin/bash\n\n#haugerud 16662  0.0  0.1  2256 1280 pts/2    S    12:52   0:00 /bin/bash\n\n# Sender all output fra ps aux til \\verb+read+:\nps aux |  \n   while read bruker PID x x x x x x x x prog\n   do\n      if [ \"$bruker\" = \"haugerud\" ]\n      then\n         echo \"ProsessID = $PID $prog\"\n      fi\n   done\n```"}
{"identifier": "linux5.10", "section_id": "5.10", "section_title": "Arrays", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION000610000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.10 Arrays\n\nEt array kan i bash fylles inn med elementer uten å deklarere arrayet først:\n\n```\nlinux:~$ tall[0]=null\nlinux:~$ tall[1]=en\nlinux:~$ tall[2]=to\nlinux:~$ tall[3]=tre\n```\n\nDen mest naturlige måten å skrive ut et array-element på fungerer ikke:\n\n```\nlinux:~$ echo $tall[1]\nnull[1]\nlinux:~$ echo $tall[2]\nnull[2]\nlinux:~$ echo ${tall[2]}\nto\n```\n\nMen man må legge inn et sett med krøll-parenteser rundt elementnanvnet for å få skrevet ut. Man kan også definere et array ved å skrive inn strenger innenfor en parentes adskilt av mellomrom:\n\n```\n$ tall=(null en to tre)\n$ echo ${tall[to]}\nnull\n$ echo ${tall[2]}\nto\n$ tall[4]=fire\n$ echo ${#tall[@]} # Antall elementer\n5\n$ echo ${tall[@]} # Alle verdier\nnull en to tre fire\n$ echo ${!tall[@]} # Index\n0 1 2 3 4\n$ for t in ${!tall[@]}\n> do\n> echo \"Tall nr $t er ${tall[$t]}\"\n> done\nTall nr 0 er null\nTall nr 1 er en\nTall nr 2 er to\nTall nr 3 er tre\nTall nr 4 er fire\n```"}
{"identifier": "linux5.11", "section_id": "5.11", "section_title": "Et vanlig problem med pipe til while og read", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION000611000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.11 Et vanlig problem med pipe til while og read\n\nEt naturlig forsøk på å sende output til en while-read løkke er følgende(se avsnittet nedenfor om hvordan man lager et array):\n\n```\n#! /bin/bash\ni=0\nps aux | awk '{print $2}' |\nwhile read pid\ndo\n   (( i++ ))\n   pidArr[$i]=$pid\ndone \necho Antall elementer: ${#pidArr[@]}\n```\n\nmen om man kjører dette, får man følgende resultat:\n\n```\n$ ./pipe.sh\nAntall elementer: 0\n```\n\nDette skyldes at når den kommer etter en pipe vil while-konsturksjonen startes i en annen prosess og variabler som blir laget i denne prosessen (arrayet i eksempelet over) vil forsvinne når while-prosessen avsluttes. Dette kan løses ved å sende en fil direkte til konstruksjonen eller mellomlagre output fra pipe'n i en fil:\n\n```\n#! /bin/bash\nps aux | awk '{print $2}' > tmp.txt\ni=0\nwhile read pid\ndo\n   (( i++ ))\n   pidArr[$i]=$pid\ndone < tmp.txt\necho Antall elementer: ${#pidArr[@]}\n```\n\nDa vil ønsket resultat oppnås:\n\n```\n$ ./pipe.sh\nAntall elementer: 742\n```\n\nMed den spesielle konstruksjon `<(kommando)` er det også mulig å direkte sende output fra `kommando` til while-read løkken som om det var en fil:\n\n```\n#! /bin/bash\ni=0\nwhile read pid\ndo\n   (( i++ ))\n   pidArr[$i]=$pid\ndone < <(ps aux | awk '{print $2}')\necho Antall elementer: ${#pidArr[@]}\n```\n\nDet gir samme ønskede resultat, dataene blir lagret i arrayet og kan brukes etter at løkken er fullført. Konstruksjon `<(kommando)` kalles \"Process Substitution\"."}
{"identifier": "linux5.12", "section_id": "5.12", "section_title": "Assosiative array", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION000612000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.12 Assosiative array\n\nAssosiative array har, istedet for tall, tekst-strenger som indeks. Et assosiativ array må deklareres før bruk i bash:\n\n```\n$ declare -A mann\n$ mann[eva]=adam\n$ mann[kari]=per\n$ mann[\"Gunn Kari\"]=\"Per Olav\"\n$ echo ${#mann[@]}\n3\n$ echo ${mann[@]}\nadam Per Olav per\n$ echo ${!mann[@]}\neva Gunn Kari kari\n$ for k in \"${!mann[@]}\"\n> do\n> echo \"$k sin mann er ${mann[\"$k\"]}\"\n> done\neva sin mann er adam\nGunn Kari sin mann er Per Olav\nkari sin mann er per\n```"}
{"identifier": "linux5.13", "section_id": "5.13", "section_title": "funksjoner", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION000613000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.13 funksjoner\n\nEn funksjon (function) brukes nesten på samme måte som et selvstendig script. Må inkluderes først i scriptet.\n\n```\n#!/bin/bash \n\n users()         #deklarasjon av funksjon \n { \n         date    #skriver ut dagens dato \n         who  # Må ha linjeskift før }\n } \n\n users  # kall paa en funksjon; ETTER deklarasjon\n```"}
{"identifier": "linux5.14", "section_id": "5.14", "section_title": "funksjoner og parametre", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION000614000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.14 funksjoner og parametre\n\nParametre overføres som til bash-script. Og som for script kan kun exit-verdier (tall) returneres, men med return og ikke exit.\n\n```\n#!/bin/bash \n\n findUser()         #deklarasjon av funksjon\n {\n    echo \"funk-arg: $*\"\n    local bruker # Lokal variabel\n    bruker=$1    # 1.u argument, dette er en lokal $1, uavhengig av den $1\n                 # som er 1. argument til hovedscriptet\n    funn=$(grep ^$bruker /etc/passwd)\n    if [ \"$funn\" ]\n    then\n        return 0 # Alt ok\n    fi\n    return 1\n }\n\n# Hovedprog 'user.sh', syntaks: $ user.sh bruker1 bruker 2 .....\necho \"Script-arg: $*\"\nfor user in $*\ndo\n   echo -e \"\\nLeter etter $user\" # -e tillater \\n\n   findUser $user    # $user blir $1 i prosedyren\n   if [ $? = 0 ]     # Returnverdi fra findUser i $?\n   then\n      echo \"$user finnes\"\n      echo $funn          # $funn er global\n   else\n      echo \"$user finnes ikke\"\n   fi\ndone\n\necho -e \"\\nScript-arg: $*\"\n\n#BUG: $ user.sh haug -> slår til på linjen haugerud i /etc/passwd\n# Kan bruke 'while read'-konstruksjon for å trekke ut brukernavn fra linjene\n```\n\n*Funksjoner kan også defineres direkte i et terminalvindu, men forsvinner når shellet avsluttes. \nMan kan lagre egne funskjoner i en fil, f. eks. funk.bash og inkludere funskjonene i flere script \nved å starte scriptene med som følger:*\n\n```\n#! /bin/bash\n\n. funk.bash  # Alternativt 'source funk.bash' I begge tilfeller tilsvarer \n             # det å taste inn all koden i filen funk.bash inn i \n             # begynnelsen av dette scriptet\n```"}
{"identifier": "linux5.15", "section_id": "5.15", "section_title": "Signaler og trap", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION000615000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.15 Signaler og trap\n\nEn prosess kan stoppes av andre prosesser og av kjernen. Det gjøres ved å sende et signal. Alle signaler bortsett fra SIGKILL ( `kill -9` ) kan stoppes og behandles av bash-script med kommandoen `trap` . Følgende script kan bare stoppes ved å sende ( `kill -9` ) fra et annent shell.\n\n```\n#! /bin/bash\n\n# Definisjoner fra \n# /usr/src/linux-headers-3.13.0-106/arch/x86/include/uapi/asm/signal.h\n\n#define SIGHUP          1       /* Hangup (POSIX).  */\n#define SIGINT          2       /* Interrupt (ANSI).  */\n#define SIGKILL         9       /* Kill, unblockable (POSIX).  */\n#define SIGTERM         15      /* Termination (ANSI).  */\n#define SIGTSTP         20      /* Keyboard stop (POSIX).  */\n\ntrap 'echo -e \"\\rSorry; ignores kill -1 (HUP)\\r\"' 1\ntrap 'echo -e \"\\rSorry; ignores kill -15 (TERM)\\r\"' 15\ntrap 'echo -e \"\\rSorry; ignores CTRL-C\\r\"' 2\ntrap 'echo -e \"\\rSorry; ignores CTRL-Z\\r\"' 20\ntrap 'echo -e \"\\rSorry; ignores kill - 3 4 5\\r\"' 3 4 5\ntrap 'echo -e \"\\rCannot stop kill -9\\r\"' 9\n\nwhile [ true ]\ndo\n   echo -en \"\\a quit? Answer y or n: \"\n   read answer\n   if [ \"$answer\" = \"y\" ]\n        then break\n   fi\ndone\n```"}
{"identifier": "linux5.16", "section_id": "5.16", "section_title": "Oversikt over shell-typer", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION000616000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.16 Oversikt over shell-typer\n\n*Det finnes mange forskjellige typer shell og det shellet som nå er mest brukt i\n             Linux-distribusjoner og som brukes her ved OsloMet  \ner bash (vi skiftet fra tcsh i 2001). \nDet er en forbedring og utvidelse av det originale Linux-shellet Bourne Shell (sh)*\n\n| Bourne-shell type | C-shell type |   |   |\n|-----------------|------------|---|---|\n| sh | Bourne-shell, Det opprinnelige Linux-shell | csh | C-shell, C-syntaks |\n| bash | Bourne-again-shell, forbedret sh | tcsh | forbedret csh, bedre interaktivt |\n| ksh | Korn-shell, utvidet sh, mye fra csh |  |  |\n\n* De fleste Linux/Linux system-script er skrevet i Bourne-shell, `/bin/sh`\n* Bourne-again-shell (bash), er default Linux-shell\n* bash kan kjøre alle Bourne-shell script\n* bash er Free Software Foundation's (FSF) Linux-shell\n\nUnder Linux:\n\n```\nhaugerud@studssh:~$ ls -l /bin/sh\nlrwxrwxrwx 1 root root 4 feb.  19  2014 /bin/sh -> dash\n```\n\nDebian Almquist shell (dash) er et mindre og hurtigere shell enn bash. Det ligger nærmere det originale Bourne-shell og har for Ubuntu blitt brukt som Bourne-substitutt siden 2006."}
{"identifier": "linux5.17", "section_id": "5.17", "section_title": "Oppstartsfiler", "source_category": "linux", "source_id": "5", "source_title": "Bash-scripting", "anchor": "SECTION000617000000000000000", "source": "os/Forelesning/linux/node6.html", "text": "## 5.17 Oppstartsfiler\n\nHver gang et nytt terminalvindu (f. eks. xterm) startes, startes bash og du får et prompt som du kan taste inn kommandoer ved. Hver gang bash startes leses en konfigurasjonsfil som ligger øverst i brukerens hjemmemappe og heter `.bashrc` . Alle kommandoer som står der blir utført. Hver gang du logger inn, utføres kommandoene i `/etc/profile` og `~/.bash_profile` .\n\nEt nytt shell startes hver gang\n\n* man logger inn på en maskin (ssh, telnet)\n* et nytt terminalvindu åpnes (xterm)\n* et nytt shell startes eksplisitt($ bash)\n\nShellet utfører først kommandoer i noen oppstartsfiler:\n\n* `/etc/profile` ved hver innlogging, systemfil\n* `~/.bash_profile` ved hver innlogging\n* `/etc/bash.bashrc` for hvert nytt shell, men ikke ved innlogging, systemfil\n* `~/.bashrc` for hvert nytt shell, men ikke ved innlogging\n\n*I disse filene kan f. eks. definisjoner av shell-variabler og alias'er legges.*\n\nEksempel på innhold:\n\n```\nPS1=\"\\h:\\w$ \"\nalias move=mv\nalias cp=\"cp -i\"\n```\n\nLegges dette i `~/.bashrc` vil `move` alltid bety `mv` og promptet blir:\n\n```\n$ bash                 \nstudssh:~/www/os$ exit    \nexit                   \n$ source ~/.bashrc     \nstudssh:~/www/os$\n```\n\n`source` starter **ikke** et nytt shell, men utfører alt i det eksisterende shellet."}
{"identifier": "linux10.1", "section_id": "10.1", "section_title": "Docker Compose og docker-compose.yaml", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION000111000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.1 Docker Compose og docker-compose.yaml\n\nVi har tidligere sett at det er en ryddigere og mer systematisk måte å bygge containere på ved å bruke en Dockerfile. Da kan man definere alt man ønsker skal være med når man starter containeren, som vilken programvare som skal være installert, hvilke filer som skal kopieres inn og så videre. Dette er et bedre alternativ enn å starte en container, installere det som trengs av programvare og innhold og så lagre denne containeren som et image og senere bruke denne. Da er det vanskligere å gjøre endringer, vanskligere å huske hva containeren egentlig inneholder og generelt vanskligere å gjenskape det samme imaget med noen endringer til å bruke i andre sammenhenger.\n\nDocker compose med den tilhørende docker-compose.yaml filen er en metode som gjør noe av den samme forenklingen for å kjøre containere som Dockerfile gjør for å bygge containere. Ofte trenger man å legge til mange flagg og opsjoner når man starter en container og dette kan gi lange og uoversiktlige docker container run-kommandoer. Man kan gjøre dette på en mye mer ryddig og systematisk måte ved å definere alt som skal skje når man starter en container i en docker-compose.yaml fil. Man kan i en slik fil også velge å starte flere samtidige containere som skal samarbeide om å gi den tjenesten man ønsker. For eksempel kan man med Docker compose samtidig starte både en webserver og en database-server som webserveren henter dataene sine fra. Generelt kan man bruke dette til å sette opp mange forskjellig typer oppsett av samtidige containere på en ryddig og oversiktlig måte. Dermed er det også enkelt å endre på konfigurasjonen og stoppe og starte hele clusteret av containere for å få alt til å virke som man ønsker.\n\nYAML sto opprinnelig for \"Yet Another Markup Language\" og er som XML et maskinlesbart format som også er inspirert av Python i den forstand at riktig innrykk i teksten er viktig og det fører til feilmeldinger om dette ikke er riktig definert. Derfor må man være svært nøye med innrykk/antall mellomrom og også med å ha mellomrom på riktige steder. Dette gir noe av de samme syntaks-problemene som ved bash-scripting, derfor er det også her en god strategi å sakte bygge opp en docker-compose.yaml fil og teste hver gang man gjør endringer."}
{"identifier": "linux10.2", "section_id": "10.2", "section_title": "Docker Compose hello-world", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION000112000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.2 Docker Compose hello-world\n\nDet gir kanskje ikke så mye mening å bruke Docker compose for å kjøre en hello-world container, men det kan være nyttig å teste ut for å gjøre seg kjent med konseptene. En docker-compose.yaml som starter en hello-world container kan se slik ut:\n\n```\nservices:\n  hello:\n    image: hello-world:latest\n```\n\nTidligere var det vanlig å starte med en linje av typen `version: '3.0'` som forteller hvilken Yaml-versjon som skal brukes, men det er ikke lenger nødvendig. Filen viser alle services som skal være med. I dette er det kun en som vi gir navnet 'hello'. Deretter følger hvilket image som skal brukes. Dermed er man klar til å kjøre hello-world containeren med:\n\n```\nroot@os180:~/compose# docker compose up\n[+] Running 1/1\n ✔ Container compose-hallo-1  Created\nAttaching to hallo-1\nhallo-1  | \nhallo-1  | Hello from Docker!\n```\n\nTidligere var kommandoen `docker-compose up` og hvis man prøver det får man nå en feilmelding.\n\nHvis man her ikke markerer at 'hello' er en av tjenestene og skriver filen slik:\n\n```\nservices:\n  hello:\n  image: hello-world:latest\n```\n\nfår man med en gang en feilmelding:\n\n```\nroot@os180:~/compose# docker compose up\nservices.image must be a mapping\n```"}
{"identifier": "linux10.3", "section_id": "10.3", "section_title": "Docker Compose nginx", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION000113000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.3 Docker Compose nginx\n\nHvis man ønsker å starte en nginx-container kan man bruke følgende yaml-fil:\n\n```\nservices:\n  nginx:\n    image: nginx:latest\n```\n\nog starte tjenesten med\n\n```\nroot@os180:~/compose# docker compose up -d\n[+] Running 1/1\n ✔ Container compose-ng1-1  Started\nroot@os180:~/compose# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS\t       PORTS     NAMES\n14d123a939af   nginx:latest   “/docker-entrypoint.…” 8 seconds ago Up 7 seconds    80/tcp    compose-ng1-1\n```\n\nHvis dette er første gang man laster ned nginx-imaget, vil det først lastes ned på samme måte som når man kjører `docker run nginx` . Deretter kan man stoppe det hele med:\n\n```\nroot@os180:~/compose# docker compose down\n[+] Running 2/2\n ✔ Container compose-ng1-1  Removed\n ✔ Network compose_default  Removed\n```\n\nDocker compose rydder opp etter seg ved å fjerne containeren som ble kjørt.\n\nHvis man ønsker at port 80 som nginx default bruker som source port skal vises som port 8080 på host'en som kjører containeren, kan man gjøre det ved å definere følgende i yaml-filen:\n\n```\nservices:\n  nginx:\n    image: nginx:latest\n    ports:\n      - 8080:80\n```\n\nGenerelt kan alle parametre og opsjoner man kan gi til `docker container run` defineres i yaml-filen. Deretter kan man starte nginx:\n\n```\nroot@os180:~/compose# docker compose up -d\n[+] Running 0/1\n ⠙ Network compose_default  Creating\n[+] Running 2/2d \n✔ Network compose_default  Created\n✔ Container compose-ng1-1  Started\nroot@os180:~/compose# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED        STATUS          PORTS                  NAMES\n6ba1338871fa   nginx:latest   “/docker-entrypoint.…” 34 seconds ago Up 33 seconds   0.0.0.0:8080->80/tcp   compose-ng1-1\n```\n\nog man vil kunne få en hilsen fra nginx:\n\n```\n# curl localhost:8080\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n```\n\nVidere kan man på en enkel måte definere en mappe på host'en som nginx skal hente sine web-sider fra ved å legge til følgende rett under ports: i yaml-filen:\n\n```\nvolumes:\n        - ./innhold:/usr/share/nginx/html:ro\n```\n\nDette gjør at man nå vil få opp innhold/index.html filen på host'en når man starter nginx."}
{"identifier": "linux10.4", "section_id": "10.4", "section_title": "Tjenester med flere samtidige containere", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION000114000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.4 Tjenester med flere samtidige containere\n\nDet er først og fremst med tanke på å sette opp flere samtidige containere som jobber sammen om å tilby en gitt tjeneste at docker compose virkelig er et kraftig verktøy. Hvis man definerer flere services innen samme docker.compose.yaml fil, vil docker compose også sette opp et lokalt privat nettverk som containerene kan kommunisere på. Dermed kan man for eksempel sette opp et lite nettverk med en database og en web-server som kommuniserer med hverandre.\n\nFølgende yaml-fil definerer to containere som leverer forskjellig innhold på henholdsvis port 8080 og 8081:\n\n```\nservices:\n  nginx:\n    image: nginx:latest\n      ports:\n        - 8080:80\n      volumes:\n        - ./innhold:/usr/share/nginx/html:ro\n  nginx2:\n    image: nginx:latest\n      ports:\n        - 8081:80\n      volumes:\n        - ./innhold2:/usr/share/nginx/html:ro\n```\n\nDermed kan man starte begge containerene samtidig og se at de virker som de skal. Og stoppe begge etterpå.\n\n```\nroot@os180:~/compose# docker compose up -d --remove-orphans\n[+] Running 3/3\n ✔ Network compose_default  Created                   0.4s \n ✔ Container compose-ng1-1  Started                   0.9s \n ✔ Container compose-ng2-1  Started                   0.8s \nroot@os180:~/compose# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED       STATUS       PORTS                NAMES\nf0343357eb3a   nginx:latest   “/docker-entrypoint.…” 6 seconds ago Up 6 seconds 0.0.0.0:8081->80/tcp compose-ng2-1\ncc1dfa99cf5c   nginx:latest   “/docker-entrypoint.…” 6 seconds ago Up 6 seconds 0.0.0.0:8080->80/tcp compose-ng1-1\n\nroot@os180:~/compose# curl localhost:8080\nhei \nroot@os180:~/compose# curl localhost:8081\nhei fra 2\nroot@os180:~/compose# docker compose down\n[+] Running 3/3\n ✔ Container compose-ng2-1  Removed                  0.8s \n ✔ Container compose-ng1-1  Removed                  0.9s \n ✔ Network compose_default  Removed\n```\n\nOm man går inn i den ene nginx og installerer ping og ifconfig (med apt install iputils-ping net-tools) vil man kunne se at man kan kommunisere over det lokale private nettverket med den andre containeren ved å bruke navnet som er definert i yaml-filen:\n\n```\n# docker exec -it f2 bash\nroot@f2d45f6e9bf5:/# ping nginx2\nPING nginx2 (192.168.32.3) 56(84) bytes of data.\n64 bytes from test_nginx2_1.test_default (192.168.32.3): icmp_seq=1 ttl=64 time=0.137 ms\n```\n\nDe to containerene har IPer 192.168.32.3 og 192.168.32.2 og kan kommunisere med hverandre som på andre nettverk. Dette gjør det mulig å sette opp relistiske systemer, ikke minst for å teste kode som man utvikler for dette service-scenariet.\n\nHvis man for eksempel ønsker å gi containeren et eget navn, kan man bruke variabelen container_name."}
{"identifier": "linux10.5", "section_id": "10.5", "section_title": "docker-compose build", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION000115000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.5 docker-compose build\n\nMan kan kombinere docker-compose med en eller flere Dockerfiles ved å spesifisere en mappe der den tilhørende Dockerfile ligger ved å angi 'build' istedet for image i yaml-filen:\n\n```\nservices:\n  nginx:\n    build: ./nginx\n    ports:\n      - 8080:80\n```\n\nDermed vil docker-compose prøve å bygge et image fra Dockerfile i mappen ./nginx og starte en container med det image't som er resultatet av denne byggingen. Og man kan sette opp en oversiktlig mappestruktur som definerer alle containerene som er med i et compose-prosjekt."}
{"identifier": "linux10.6", "section_id": "10.6", "section_title": "Virtuelle maskiner", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION000116000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.6 Virtuelle maskiner\n\n[Slides brukt i forelesningen](https://www.cs.oslomet.no/~haugerud/vm.pdf)"}
{"identifier": "linux10.8", "section_id": "10.8", "section_title": "Virtualisering", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION000118000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.8 Virtualisering\n\n* Virtualisering av server/desktop hardware\n* En hypervisor simulerer hardware ved å gi samme grensesnitt som virkelig hardware gir\n* Operativsystemene som kjører på en virtuell maskin, tror de kjører på ekte hardware\n\nIllustrasjon:\n."}
{"identifier": "linux10.9", "section_id": "10.9", "section_title": "Hvorfor virtualisering?", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION000119000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.9 Hvorfor virtualisering?\n\n* Isolasjon\n* Ressurssparing\n* Fleksibilitet\n* Programvare-utvikling\n* Skytjenester\n\nAlle disse fordelene gjelder også for containere og Docker, bortsett fra den første, isolasjon og sikkerhet. Men fleksibiliteten blir enda større med containere."}
{"identifier": "linux10.10", "section_id": "10.10", "section_title": "Isolasjon", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001110000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.10 Isolasjon\n\n* Tjenester og programmer kan kjøre på hver sin dedikerte server\n* Unngår at de forskjellige tjenestene ødelegger for hverandre og gir ryddigere drift\n* Men hva om den fysiske serveren eller hypervisor feiler?\n* Det meste av nedetid og feil skyldes ikke hardware men software. Og software for en hypervisor er generelt mindre kompleks enn all programvaren på en hel maskin\n* Sikkerhet: hvis en tjeneste blir hacket, vil det ikke påvirke de andre tjenestene\n* Dette er fordi Operativsystemet og applikasjonene kun kommuniserer mot det virtuelle hardware-API'et som hypervisor gir dem tilgang til. De har ingen mulighet til å kommunisere med andre deler av en hypervisor eller andre VMer."}
{"identifier": "linux10.11", "section_id": "10.11", "section_title": "Ressurssparing", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001111000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.11 Ressurssparing\n\n* Man kan oppnå isolasjon ved å ha en fysisk server for hver tjeneste, men det gir store driftskostnader\n* Med virtualisering kan det samme oppnås på en enkelt server\n* Virtuelle maskiner (VMer) som for eksempel bruker lite CPU kan settes på samme fysiske server\n* VMer kan enkelt flyttes til og fra fysiske servere og man kan dermed spare hardware og strøm\n* Hage, Thomas: *The CERES project - A Cloud Energy Reduction System*, Veileder: Kyrre Begnum (Masteroppgave i Nettverk og Systemadministrasjon, oslomet/UiO)\n* `https://www.cs.oslomet.no/teaching/materials/MS100A/html/NSA.html`"}
{"identifier": "linux10.12", "section_id": "10.12", "section_title": "Fleksibilitet", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001112000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.12 Fleksibilitet\n\n* Kapasiteten kan enkelt økes ved å legge til flere VMer, lastbalansering blir enklere\n* Elastisitet: Man kan dynamisk tildele CPUer og internminne til VMer\n* Har en VM blitt ødelagt eller kompromittert kan man enkelt starte opp en ny kopi\n* Tradisjonelt er det arbeidskrevende å flytte en tjeneste eller et softwareprosjekt til en ny server på grunn av avhengighet av operativsystemet og annen programvare: når noe er utviklet på en VM så kan hele VMen flyttes eller kopieres\n* Live migration: Hele VM flyttes til annen fysisk server uten nedetid på tjenestene\n* Ung, Fredrik: *Towards efficient and cost-effective live migrations of virtual machines*, NSA masteroppgave\n* Ahmad, Bilal: *Coordinating vertical and horizontal scaling for achieving differentiated QoS*, NSA masteroppgave, Veiledere: Anis Yazidi og Hårek Haugerud"}
{"identifier": "linux10.13", "section_id": "10.13", "section_title": "Skalering av ressurser", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001113000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.13 Skalering av ressurser\n\nIllustrasjon:\n."}
{"identifier": "linux10.14", "section_id": "10.14", "section_title": "Programvare-utvikling", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001114000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.14 Programvare-utvikling\n\n* Man kan raskt teste ut programvare på forskjellige operativsystemer, Window, Linux, Mac, etc. ved å kjøre VMer med en rekke forskjellige OS\n* Det er enklere å automatisere tester på flere plattformer (Test Driven Development)\n* Ønsker man å teste ut nye ideer, kan man raskt sette opp miljøer for å teste dem ut"}
{"identifier": "linux10.15", "section_id": "10.15", "section_title": "Skytjenester", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001115000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.15 Skytjenester\n\n* Virtualisering er grunnlaget for fleksible skytjenester\n* Kunder kan gis egne VMer med et antall CPUer, disk og minne\n* Disse kundene kan dele fysiske servere, noe som gir store besparelser av hardware\n* Nettbokhandelen Amazon startet med skytjenester fordi de bare hadde bruk for store mengder hardware til webserverene sine før jul og tenkte at de kunne leie ut hardware-ressursene resten av året"}
{"identifier": "linux10.16", "section_id": "10.16", "section_title": "Historie", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001116000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.16 Historie\n\n* IBM startet med virtualisering av stormaskiner på 1960-tallet\n* En VMM (Virtual Machine Monitor) styrte flere virtuelle maskiner på samme fysiske maskin\n* Første virtualiseringsløsning for x86: VMware i 1999\n* Deretter fulgte Xen, VirtualBox, KVM og mange andre\n* Hardware-støtte for x86 virtualisering kom først i 2005"}
{"identifier": "linux10.17", "section_id": "10.17", "section_title": "Krav til virtualisering", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001117000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.17 Krav til virtualisering\n\n* Popek og Goldberg, 1974: En maskin kan bare virtualiseres hvis alle **sensitive instruksjonene** også er **priviligerte instruksjoner**\n* En **Sensitiv instruksjon** kan bare utføres i kernel mode\n* En **Priviligert instruksjon** forårsaker en trap til kernel mode hvis den gjøres i user mode\n\nEksempel:\n\n* X86 instruksjonen POPF (skrur av og på interrupts) er en sensitiv instruksjon\n* Hvis den utføres i user mode vil ingenting skje, som for NOP (No Operation)\n* Instruksjonen CLI (CLear Interupt flag) er en sensitiv instruksjon, men den er også priviligert. Hvis den utføres i user mode, gjøres en trap til kernel mode\n* Vanlige instruksjoner som ADD, CMP og MOV er hverken sensitive eller priviligerte."}
{"identifier": "linux10.18", "section_id": "10.18", "section_title": "Hardware støttet virtualisering", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001118000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.18 Hardware støttet virtualisering\n\n* Hardware-støtte for x86 virtualisering kom først i 2005\n* Inntil da fantes det sensitive instruksjoner (som POPF) som bare ble droppet\n* Gjeste-OS kjører i user mode og vil ikke fungere som på vanlig hardware om en slik instruksjon droppes. Det vil føre til uforutsigbar oppførsel og kan føre til at OS crasher i verste fall.\n* Med Intel VT-x og AMD-V vil alle sensitive instruksjoner trap'e til kernel mode når de utføres i user mode\n\nIllustrasjon:\nHardware støttet virtualisering."}
{"identifier": "linux10.19", "section_id": "10.19", "section_title": "Type 1 hypervisor", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001119000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.19 Type 1 hypervisor\n\n* En type 1 hypervisor kjører direkte på hardware som et OS\n* Alle sensitive instuksjoner som utføres i user mode av gjeste-OS må trap'e til kernel mode og fanges opp av hypervisor\n* Eksempler: VMware ESX og vSphere, Xen, Hyper-V(Microsoft)\n\nIllustrasjon:\nType 1 Hypervisor."}
{"identifier": "linux10.20", "section_id": "10.20", "section_title": "Type 2 hypervisor", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001120000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.20 Type 2 hypervisor\n\n* En type 2 hypervisor kjører oppå et eksisternede OS\n* Deler av hypervisor kan inngå i det underliggende OS'et i form av kjernemoduler\n* Det kan være litt flytende grenser mellom type 1 og type 2\n* KVM/Qemu(Linux), VirtualBox, VMware Fusion (Mac)\n\nIllustrasjon:\nType 2 hypervisor."}
{"identifier": "linux10.21", "section_id": "10.21", "section_title": "Binær oversettelse", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001121000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.21 Binær oversettelse\n\n* Før 2005 måtte alternative metoder brukes, uten hardware-støtte\n* VMware lagde en hypervisor som mens et program kjører scanner koden etter sensitive instruksjoner\n* Dette gjøres for hver kodeblokk som ender i jump, call, trap eller lignende\n* Sensitive instruksjoner oversettes til kall til VMware-prosedyrer i hypervisor\n* De oversatte kodeblokkene cashes og dette gjør kjøringen effektiv\n* Hardware med VT-støtte genererer mange traps og dette tar lang tid\n* Noe binær oversettelse finnes også i VirtualBox"}
{"identifier": "linux10.22", "section_id": "10.22", "section_title": "Paravirtualisering", "source_category": "linux", "source_id": "10", "source_title": "Docker Compose, virtuelle maskiner", "anchor": "SECTION0001122000000000000000", "source": "os/Forelesning/linux/node11.html", "text": "## 10.22 Paravirtualisering\n\n* Paravirtualisering krever at Gjeste-OS endres\n* Alle sensitive instruksjoner erstattes med kall til hypervisor\n* Gjeste-OS kan optimaliseres for virtualisering\n* Ved å installere drivere laget for paravirtualisering, kan denne metoden bli meget effektiv"}
{"identifier": "linux2.3", "section_id": "2.3", "section_title": "Manualsider og apropos", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION00033000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.3 Manualsider og apropos\n\nFor å finne ut hvordan en viss kommando (f. eks. date) virker, kan man slå opp i manualsiden med\n\n```\n$ man date\n```\n\nManualsiden er vanligvis for lang til å vises på en side. Du kan manøvrere deg nedover en side av gangen ved å taste space. Man søker ved å taste `/søkeord` og så taste \"n\" fortløpende for flere forekomster. Tast \"q\" for å avslutte.\n\nApropos: finner kommandoer relatert til et emne.\n\n```\nhaugerud@studssh:~$ apropos compare\n[ (1)                - check file types and compare values\nbcmp (3)             - compare byte sequences\nbzcmp (1)            - compare bzip2 compressed files\nbzdiff (1)           - compare bzip2 compressed files\ncg_diff (1)          - compares two Cachegrind output files\ncmp (1)              - compare two files byte by byte\ncomm (1)             - compare two sorted files line by line\ndiff (1)             - compare files line by line\n\nhaugerud@studssh:~$ man diff\nDIFF(1)                                                User Commands                                                DIFF(1)\n\nNAME\n       diff - compare files line by line\n\nSYNOPSIS\n       diff [OPTION]... FILES\n\nDESCRIPTION\n       Compare FILES line by line.\n\n       Mandatory arguments to long options are mandatory for short options too.\n\n       --normal\n              output a normal diff (the default)\n      -i, --ignore-case\n              ignore case differences in file contents\n```\n\n*Alt som er listet i [] er opsjoner som kan men ikke må tas med. Tast \"q\" for å avslutte.*\n\n```\nstudssh$ diff -i fil1 fil2\n```\n\nOg et google-søk med 'linux command line' eller 'linux bash' og det du ønsker å finne gir ofte raskt det du leter etter."}
{"identifier": "linux2.4", "section_id": "2.4", "section_title": "Tidsbesparende triks i et Linux-shell", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION00034000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.4 Tidsbesparende triks i et Linux-shell\n\nDet finnes mange smarte knep som gjør inntasting av shell-kommandoer enklere. Bla tilbake i tidligere kommandoer og rediger dem med piltastene og trykk TAB-tasten for å finne mulige forlengelser av det du har skrevet inn.\n\n* Tidligere kommandoer kan gjentas og endres med piltaster og vanlig editering\n* , editere en tidligere kommando, og utføre den på nytt med Enter\n* `$ exit` og CTRL-d avslutter et shell.\n* Bruk Ctrl-C Hvis du skal stoppe et program som går i et shell\n\nMan kan søke bakover i tidligere kommandoer ved å taste CTRL-r og så fortløpende det man søker etter, \"mitt\" i eksempelet under:\n\n```\n(reverse-i-search)`': \n(reverse-i-search)`mitt': mv mitt.sh new\n```\n\nGenerelt kan man få skallet til å komplettere filnavn og kommandoer ved å trykke på TAB-tasten. Skal man f.eks. flytte til mappen kjempelangtnavn:\n\n```\n$ cd kj [TAB]\n$ cd kjempelangtnavn\n```\n\n*Hvis du også har en mappe der du står som heter kjiipt, piper det etter TAB*\n\n```\n$ cd kj [TAB] [TAB]\nkjempelangtnavn/ kjiipt/   \n$ cd kje [TAB]\n$ cd kjempelangtnavn\n$ loc [TAB]\nlocal      locale     localedef  locate     lockfile\n```\n\nDu kan også bruke TAB-tasten til å komplettere kommandoer du skal utføre. Skriver du\n\n```\n$ net\n```\n\nog så trykker TAB-tasten to ganger vil du få alle kommandoer som begynner på \"net\".\n\n```\n$ net\nnet         netcat      netkit-ftp  netstat\n```\n\ntast en \"s\" og TAB igjen og \"netstat\" fullføres av shellet.\n\nSe mer om dette og andre tips under 'Nyttige tips om bruk av Linux' under Linux-help ikonet på kurs-siden.\n\nHvis du kjører Linux med grafisk brukergrensesnitt vil i noen tilfeller kopiering og lignende være litt anderledes enn i andre systemer:\n\n* Copy = Merk område med venstre musetast\n* Paste = høyre musetast (putty) eller midtre musetast(linux)\n* Windows varianten: cut=CTRL-x copy=CTRL-c og paste=CTRL-v virker i de fleste nyere GUI-applikasjoner"}
{"identifier": "linux2.5", "section_id": "2.5", "section_title": "Linux-shellscript", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION00035000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.5 Linux-shellscript\n\n* Samling av kommandolinjer\n* program som utføres linje for linje\n* Kompileres ikke\n\n|   |   |\n|---|---|\n| + | Raskt å lage. |\n| + | Fint for små oppgaver. |\n| - | Langsomt i forhold til kompilert kode. |\n| - | Mangler avanserte datastrukturer. |\n| - | Kryptisk syntaks |\n| - | Vanskelig å feilsøke/debugge |\n\nEn meget nyttig måte å teste ut bash-script på er å bruke -x parameteren. Kjør scriptet ditt, som heter f. eks. mittscript, slik:\n\n```\n$ bash -x mittscript\n$ bash -x mittscript\n+ '[' -f /etc/passwd ']'\n+ echo Bra\nBra\nog hver kommando som utføres blir skrevet til skjermen.\n```"}
{"identifier": "linux2.6", "section_id": "2.6", "section_title": "Absolutt og relativ path", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION00036000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.6 Absolutt og relativ path\n\nEn path (bane) til en mappe eller en fil angis alltid absolutt eller relativt til posisjonen man er i filtreet. Absolutt path begynner alltid med / som er rot-mappen som alle de andre henger på.\n\n```\n$ pwd\n   /\n$ cd home\n$ pwd\n   /home\n$ cd etc               <----- Relativ path\nbash: cd: etc: No such file or directory\n$ cd /etc              <----- Absolutt path\n```\n\n| Alt I: Relativ path | AltII: Absolutt path |\n|-------------------|--------------------|\n| Fra / | Fra hvor som helst |\n| $ cd usr | $ cd /usr/bin |\n| $ cd bin | $ pwd |\n| $ pwd | /usr/bin |\n| /usr/bin |  |\n| Begynner ikke med / | Begynner med / |\n\nIllustrasjon:\nMappen /usr/bin i filtreet."}
{"identifier": "linux2.7", "section_id": "2.7", "section_title": "Mer filbehandling", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION00037000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.7 Mer filbehandling\n\n| Linux-kommando | resultat |\n|--------------|--------|\n| $ tree | viser den underliggende mappe-strukturen |\n| $ sudo apt-get install tree | Installerer programmet tree om det ikke finnes fra før |\n| $ mv dir1 dir2 | flytter mappen dir1 til mappen dir2 |\n| $ cp /bin/c* /tmp | Kopier alt som begynner på c i /bin til /tmp |\n| $ cp -R dir1 dir2 | Kopier dir1 med undermapper til dir2 |\n\nIllustrasjon:\nmv av hele mapper\n\nIllustrasjon:\ncp -R av hele mapper"}
{"identifier": "linux2.8", "section_id": "2.8", "section_title": "Sletting av filer og mapper", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION00038000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.8 Sletting av filer og mapper\n\nNB! Fjernes for godt (ingen undelete)\n\n| Linux-kommando | resultat |\n|--------------|--------|\n| $ rm fil1 | sletter fil1 (umulig å få tilbake) |\n| $ rmdir Mappe | kun tom mappe |\n| $ rm -R Mappe | sletter mappe og alle undermapper. Farlig |\n| $ rm -i fil2 | ber om bekreftelse først |"}
{"identifier": "linux2.9", "section_id": "2.9", "section_title": "Enda mer filbehandling", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION00039000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.9 Enda mer filbehandling\n\n| Linux-kommando | resultat |\n|--------------|--------|\n| $ locate noe | finner alle filer og mapper med navn som inneholder tekststrengen “noe” |\n| $ find tmp -name fil.txt | finner alt under tmp med navn som inneholder fil.txt |\n| $ find . -name \"*fil*\" | finner alt under mappen du står som inneholder strengen \"fil\" i navnet |\n| $ more fil1 | skriv til skjerm; en side av gangen |\n| $ grep group /etc/passwd | skriv til skjerm alle linjer som inneholder strengen group |\n| $ wc -l /etc/passwd | tell antall linjer i /etc/passwd |\n| $ grep group /etc/passwd | wc -l | tell antall linjer som inneholder strengen group |"}
{"identifier": "linux2.10", "section_id": "2.10", "section_title": "Lovlige filnavn", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION000310000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.10 Lovlige filnavn\n\nAlle tegn untatt / er lov// unngå spesielle tegn som æ,ø,å og mellomrom *for de \nmå spesialbehandles (som \"en fin fil\")* Bruk A-Z a-z 0-9 _ .\n\n* fil1\n* fil1.txt\n* Index.html\n* VeldigLangeFilnavn.help\n* fil2.ver3.tekst\n\nLinux er case-sensitiv. **fil1 er IKKE den samme filen som FIL1** ."}
{"identifier": "linux2.11", "section_id": "2.11", "section_title": "Prosesser", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION000311000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.11 Prosesser\n\n* `ps`\n* `ps aux`\n* `ps aux | grep root`\n* `man ps`\n* `top`"}
{"identifier": "linux2.12", "section_id": "2.12", "section_title": "Linux-maskiner", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION000312000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.12 Linux-maskiner\n\n* Hver Linux-maskin kalles en \"host\" (vert)\n* Flere brukere kan logge inn og bruke samme host samtidig.\n* Hver host har et navn: studssh (Linux, fil og www-server), rex (desktop), etc.\n* Entydig adresse som kan nås fra hele verden krever domenenavn i tillegg: studssh.cs.oslomet.no, login.uio.no\n\nMan kan logge inn fra hvorsomhelst i verden til en annen maskin:\n\n```\nssh os@studssh.cs.oslomet.no\nos@studssh.cs.oslomet.no's password:\n[os]studssh:~$\n```\n\nNår man logger inn med ssh (Secure Shell) krypteres alt som sendes."}
{"identifier": "linux2.13", "section_id": "2.13", "section_title": "Orientering: Hvem, hva, hvor", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION000313000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.13 Orientering: Hvem, hva, hvor\n\n| Linux-kommando | Gir deg |\n|--------------|-------|\n| $ whoami | brukernavn |\n| $ hostname | maskin-navn |\n| $ uname | Operativsystem (Linux, Solaris,.....) |\n| $ uname -a | OS, versjon, etc. |\n| $ who | hvem som er logget inn |\n| $ type chmod | hviklet program kjøres med chmod? |\n| $ history | tidligere kommandoer |"}
{"identifier": "linux2.14", "section_id": "2.14", "section_title": "Symbolske linker til filer (symbolic links)", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION000314000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.14 Symbolske linker til filer (symbolic links)\n\n```\n$ ln -s fil1 fil2\n$ ls -l\n-rw-------   1 haugerud drift             20 Sep  4 18:44 fil1\nlrwxrwxrwx   1 haugerud drift              4 Sep  4 18:43 fil2 -> fil1\n$ cat fil2\nDenne teksten står i fil1\n```"}
{"identifier": "linux2.15", "section_id": "2.15", "section_title": "Symbolske linker til mapper", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION000315000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.15 Symbolske linker til mapper\n\nVed å lage en link til en mappe kan man lage en snarvei i filtreet.\n\n```\n$ pwd\n/home/min/dir1\n$ ln -s /usr/bin mbin\n$ ls -l\nlrwxrwxrwx   1 haugerud drift              8 Sep  4 19:02 mbin -> /usr/bin\n```\n\nIllustrasjon:\nSymbolsk link fra mbin til /usr/bin\n\n```\n$ cd mbin\n$ ls\n822-date                giftopnm                    nawk                  rcsmerge\nEsetroot                giftrans                    ncftp                 rdist\n.......etc.......            # alle filene i /usr/bin\n$\n$ pwd\n/home/min/dir1/mbin          # /bin/pwd gir path relativt til linken\n$ type pwd\npwd is a shell builtin       # kommandoen pwd er bygd inn i bash\n$ /bin/pwd                   # /bin/pwd gir absolutt path til der du er\n/usr/bin\n$ cd ..\n$ pwd\n/home/min/dir1               # ikke /usr\n```"}
{"identifier": "linux2.16", "section_id": "2.16", "section_title": "Filrettigheter", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION000316000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.16 Filrettigheter\n\nAlle filer tilhører en bruker og en gruppe av brukere. For hver mappe og fil kan eieren sette rettighetene for\n\n* brukeren filen tilhører (seg selv)\n* gruppen filen tilhører\n* alle andre\n\n```\n$ ls -l\n-rwxrw-r--   1 haugerud drift           7512 Aug 30 14:20 fil.exe\n```\n\n|   |   |\n|---|---|\n| - | fil (d = mappe, l = link) |\n| rwx | fileier sine rettigheter (r = read, w = write, x = executable) |\n| rw- | gruppens rettigheter (kan lese og skrive) |\n| r- - | alle andre sine rettigheter (kan bare lese filen) |\n| 1 | antall hard links |\n| haugerud | eiers brukernavn |\n| drift | gruppen som filen tilhører (definert i /etc/group) |\n| 7512 | antall byte |\n| Aug 30 14:20 | tidspunkt filen sist ble endret |\n| fil.exe | filnavn |\n\nFor mapper betyr x at man har tilgang til mappen. Er ikke x satt, kan man ikke gå dit. Og da kan man heller ikke liste filer der eller kopiere noe dit."}
{"identifier": "linux2.17", "section_id": "2.17", "section_title": "Hvordan forstå filrettigheter", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION000317000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.17 Hvordan forstå filrettigheter\n\nRettighetene til eier, gruppe og andre er representert med kun tre bit. Dette begrenser hvor mange forskjellige rettigheter man kan ha, samtidig gjør det det enkelt å representere rettighetene som tall og å regne ut rettigheter i hodet. Dette gjør man på følgende måte:\n\n* kjørerettigheter = 1\n* skriverettigheter = 2\n* leserettigheter = 4\n\nVed hjelp av disse tallene (og tallet 0) kan vi telle fra 0 til 7 ved å kombinere dem på forskjellige måter. F.eks:\n\n* Kjørerettigheter + leserettigheter = 5\n* Kjøre + lese + skrive = 7 (maks)\n* skrive og kjøre, men ikke lese = 3"}
{"identifier": "linux2.18", "section_id": "2.18", "section_title": "Endre filrettigheter", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION000318000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.18 Endre filrettigheter\n\nNumerisk endring av filrettigheter:\n\n```\n$ chmod 644 fil.txt <- gir rw-r--r--\n$ chmod -R 755 dir  <- gir rwxr-xr-x til dir og alle filer og mapper under dir\n```\n\nTallene betyr:\n\n| rwx | octal | tekst |\n|---|-----|-----|\n| 000 | 0 | - - - |\n| 001 | 1 | - - x |\n| 010 | 2 | - w - |\n| 011 | 3 | - w x |\n| 100 | 4 | r - - |\n| 101 | 5 | r - x |\n| 110 | 6 | r w - |\n| 111 | 7 | r w x |\n\nFor mapper: Rettighet x (execute) gir tilgang til mappen.\n\nIllustrasjon:\nMan må ha tilgangsrettighet (x) til alle\n  mappene i path for å kunne lese en fil (her: se et web-bilde i /home/www/bilder). Alternativt:\n\n```\n$ chmod a+xr fil.txt <- gir read og execute til alle (a)\n$ chmod g-w fil.exe  <- fratar gruppen skriverettigheter\n```\n\nu = user, g = group, o = other, a = all (både u, g og o)"}
{"identifier": "linux2.19", "section_id": "2.19", "section_title": "umask", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION000319000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.19 umask\n\nKommandoen `umask` setter hva som skal være standard rettigheter for nye filer og mapper.\n\n```\n$ umask\n0022\n$ mkdir dir\n$ touch fil\n$ ls -l\ntotal 1\ndrwxr-xr-x  2 haugerud drift 512 Aug 30 23:52 dir\n-rw-r--r--  1 haugerud drift   0 Aug 30  2006 fil\n```\n\n`umask` er en 'maskering'. For hver brukergruppe settes rettighet '111 minus mask' for mapper og '110 minus mask' for filer. Bit som er satt i mask, settes alltid til null.\n\n```\n$ umask 027\n$ mkdir dir2\n$ touch fil2\n$ ls -l\ntotal 2\ndrwxr-x---  2 haugerud drift 512 Aug 30 23:53 dir2\n-rw-r-----  1 haugerud drift   0 Aug 30  2006 fil2\n```\n\nDet er ikke så viktig å vite detaljene i hvordan umask virker, for man kan raskt teste ut hva resultatet blir om man har en viss forståelse. Slik beregnes rettighetene:\n\n| For mappe | 7 = 111 | 7 = 111 | 7 = 111 |\n|---------|-------|-------|-------|\n| minus mask | 0 = 000 | 2 = 010 | 7 = 111 |\n| resultat | 7 = 111 | 5 = 101 | 0 = 000 |\n| rettighet | 7 = r w x | 5 = r - x | 0 = - - - |\n\nog for filer\n\n| For fil | 6 = 110 | 6 = 110 | 6 = 110 |\n|-------|-------|-------|-------|\n| minus mask | 0 = 000 | 2 = 010 | 7 = 111 |\n| resultat | 6 = 110 | 4 = 100 | 0 = 000 |\n| rettighet | 6 = r w - | 4 = r - - | 0 = - - - |"}
{"identifier": "linux2.QA", "section_id": "2.QA", "section_title": "Spørsmål", "source_category": "linux", "source_id": "2", "source_title": "Linux-filsystem, Linux-kommandoer", "anchor": "SECTION000320000000000000000", "source": "os/Forelesning/linux/node3.html", "text": "## 2.QA Spørsmål\n\n**Gir skriverettighet leserettighet?**\n\nHar man automatisk leserettigheter hvis man har skriverettighet? Svar: Nei, r, w og x settes uavhengig av hverandre. Men `-w-` (kun skriverettigheter) brukes i praksis aldri.\n\n**Kan man sette bare skriverettigheter på en fil?**\n\nJa. chmod 200 fil Da kan man skrive til filen, men ikke lese den.\n\n**Hvilke rettigheter trenger man for å kunne slette en fil?**\n\nw, skriverettigheter.\n\n**Kan man slette en fil man selv ikke har skriverettigheter til?**\n\nJa, om man har skriverettigheter til mappen den ligger i, men man får en advarsel og blir spurt først. Det samme gjelder en fil med ingen rettigheter, 000.\n\n**Hva skjer med eierskapet om man kopierer en annens fil?**\n\nDa blir man selv eier til den kopierte filen."}
{"identifier": "linux4.3", "section_id": "4.3", "section_title": "Shell-programmering", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION00053000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.3 Shell-programmering\n\nVi kan lage script som er\n\n* nye kommandoer\n* oppstartsprogrammer/program som gjør systemarbeid\n* innstallasjonsprogrammer\n* daemons; prosesser som alltid går i bakgrunnen og utfører tjenester.\n\n`$mittprog&` vil fortsette å kjøre etter logout.\n\nNår du skriver script:\n\n* begynn med et skjelett (som f. eks. kun behandler argumentene) og få det til å virke\n* utvid med en detalj av gangen; test for hver gang\n* test små deler med copy&paste til et kommandovindu\n\nDebugging:\n\n* `bash -x mittscript` viser hva som skjer\n* Legg inn linjer som `echo \"Har nå kommet hit\"`\n\nFeilmeldinger fra bash er ofte kryptiske og misvisende, så det er vanskelig å finne feil i et stort script."}
{"identifier": "linux4.4", "section_id": "4.4", "section_title": "if-test", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION00054000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.4 if-test\n\n```\nif test1\nthen\n   kommando1\nelif test2\nthen \n   kommando2\nelse\n   kommando3\nfi\n```"}
{"identifier": "linux4.5", "section_id": "4.5", "section_title": "if-eksempel; fil-testing", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION00055000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.5 if-eksempel; fil-testing\n\n```\n#! /bin/bash\n\nfil=$1\nif [ -f \"$fil\" ]\n then\n   echo $fil er en fil\nelif [ -d \"$fil\" ]; then\n   echo $fil er en mappe\nelse\n   echo $fil er hverken fil eller mappe\nfi\n```\n\n*Man må ha mellomrom før og etter [ og før ] i \nif-testene. Semikolon adskiller generelt to kommandoer på samme måte som et linjeskift.*\n\nFølgende script prøver å teste om det ikke er gitt noe argument:\n\n```\n#! /bin/bash\n\nargument1=$1\nif [ $argument1 = \"\" ]\nthen\n        echo \"Ingen argumenter\"\nfi\n```\n\nMen det gir en feilmelding når det kjøres uten argumenter\n\n```\n$ ./script\n./script: line 5: [: =: unary operator expected\n```\n\nfordi det ikke er anførselstegn rundt $argument1 og da ser bash en linje som ser ut som `if [  = \"\" ]` og gir feilmelding. Analogt vil testen `if [ -f ]` alltid slå til. Bruk derfor alttid anførselstegn rundt det som skal testes, slik at det blir en tom streng og dermed syntaktisk riktig om variabelen du tester ikke eksisterer eller er tom."}
{"identifier": "linux4.6", "section_id": "4.6", "section_title": "Flere filtester og sammenligning", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION00056000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.6 Flere filtester og sammenligning\n\n| Filtest | Sann hvis |\n|-------|---------|\n| -L fil | fil er en link |\n| -r fil | fil er lesbar |\n| -w fil | fil er skrivbar |\n| -e fil | fil eksisterer |\n| -x fil | fil er eksekverbar |\n| s1 = s2 | strengene s1 og s2 er like |\n| s1 != s2 | strengen s1 og s2 er forskjellige |\n| x -eq y | heltallene x og y er like |\n| x -lt y | x er mindre enn y 2 |\n| x -gt y | x er større enn y |\n| t1 -a t2 | Logisk og - sann hvis t1 OG t2 er sanne |\n| t1 -o t2 | Logisk eller - sann hvis t1 ELLER t2 er sanne |"}
{"identifier": "linux4.7", "section_id": "4.7", "section_title": "Logiske operatorer", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION00057000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.7 Logiske operatorer\n\n| Operator | betydning |\n|--------|---------|\n| ! | logisk NOT |\n| -a | logisk AND |\n| -o | logisk OR |"}
{"identifier": "linux4.8", "section_id": "4.8", "section_title": "for-løkke", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION00058000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.8 for-løkke\n\n```\nfor variable in list\ndo\n  kommandoer\ndone\n```\n\n*hvor  list er en liste av ord adskilt av mellomrom. F. eks. gir*\n\n```\nfor var in h1 h2 h3\ndo\n   echo $var\ndone\n```\n\ntil output\n\n```\nh1\nh2\nh3\n```\n\nInfo om nøkkelord som `for`\n\n```\nhaugerud@studssh:~$ type for\nfor is a shell keyword\n```\n\nkan man få med\n\n```\nhaugerud@studssh:~$ help for\nfor: for NAME [in WORDS ... ] ; do COMMANDS; done\n    Execute commands for each member in a list.\n```\n\nEksempler på `list` eller WORDS:\n\n* `$(ls)`\n* `$(cat fil)`\n* `*`\n* `dir/*.txt`\n* `$filer # ( filer=\"fil1 fil2 fil3\")`\n\n*En liste splittes med mellomrom. Variabelen IFS (Internal Field Separator)  kan\nsettes om man ønsker å splitte på et annet tegn. Det skjer ved at \nIFS-tegnet byttes ut med mellomrom når verdien av en shellvaribael \nbenyttes.\nDen må fjernes med unset \nom man ønsker å splitte på mellomrom igjen.*\n\n```\n$ var=fil1:fil2:fil3\n$ echo $var\nfil1:fil2:fil3\n$ IFS=:\n$ echo $var\nfil1 fil2 fil3\n$ for fil in $var\n> do\n> echo $fil\n> done\nfil1\nfil2\nfil3\n```\n\nÅ bruke kolon til å splitte er nyttig om man ønsker å løpe igjennom PATH eller en linje i passordfilen. Med noen opsjoner til cat, kan man se hva som skjuler seg bak $IFS:\n\n```\nhaugerud@studssh:~$ echo \"$IFS\" | cat -vet\n ^I$\n$\n```\n\nDette betyr at IFS splitter på de tre tegnene <space><tab><newline>, noe man kan se i bash sin manual-side om man søker på IFS.\n\nFra og med bash versjon 2.0 kan man også skrive vanlige for-løkker med en syntaks som ligner mer på Java:\n\n```\nfor (( i=1;i < 30;i++ ))\ndo \n   echo $i\ndone\n```"}
{"identifier": "linux4.9", "section_id": "4.9", "section_title": "Break og Continue", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION00059000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.9 Break og Continue\n\nBreak og Continue kan brukes mellom do og done til å avbryte for og while løkker:\n\n**continue**: Fortsett med neste runde i for/while løkke.\n\n**break**: Avslutt for/while løkke; hopp til etter done\n\n**break n**: Hopp ut n nivåer"}
{"identifier": "linux4.10", "section_id": "4.10", "section_title": "Numerikk", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION000510000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.10 Numerikk\n\nTungt å bruke `expr` som er eneste alternativ i Bourne-shell:\n\n```\na=`expr $a + 1`               # increment a\na=`expr 4 + 10 \\* 5`          # 4+10*5\n```\n\nEnklere innenfor (( )) for da kan Java-syntaks for numerikk brukes(men bare i bash 2.x).\n\n```\n$ (( x = 1 ))\n$ echo $x\n1\n$ (( x += 1))\n$ echo $x\n2\n$ (( total = 4*$x + x )) # Virker med x uten $ foran!\n$ echo $total\n10\n```\n\nDen numeriske testen\n\n```\nif ((x < y))\n```\n\ner et Bash 2.x alternativ til\n\n```\nif [ $x -lt $y ]\n```\n\nDen beste løsningen er å bruke syntaksen med doble paranteser, (( )), selvom syntaksen (for å være bakoverkompatibel) er litt uvanlig."}
{"identifier": "linux4.11", "section_id": "4.11", "section_title": "Script og argumenter", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION000511000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.11 Script og argumenter\n\nArgumenter blir lagret i spesielle variabler. Kjøres scriptet argscript.bash med tre argumenter: $ argscript.sh fil1 fil2 fil3 vil følgende variabler bli satt:\n\n| variabel | innhold | verdi i eksempelet |\n|--------|-------|------------------|\n| $* | hele argumentstrengen | fil1 fil2 fil3 |\n| $# | antall argumenter | 3 |\n| $1 | arg nr 1 | fil1 |\n| $2 | arg nr 2 | fil2 |\n| $3 | arg nr 3 | fil3 |"}
{"identifier": "linux4.12", "section_id": "4.12", "section_title": "Argumenter i for-løkke og exit-verdier.", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION000512000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.12 Argumenter i for-løkke og exit-verdier.\n\n```\n$ cat forarg\n#!/bin/bash \n\nif [ $# -lt 1 ]\nthen\n   echo No arguments\n   exit 1             # Avsluttet scriptet\nfi\n\nfor arg in $*\ndo\n  echo $arg was an argument\ndone\n\necho total number: $#\n\n$ forarg hei du\nhei was an argument\ndu was an argument\ntotal number: 2\n$ echo $?\n0\n$ forarg \nNo arguments\n$ echo $?\n1\n```\n\nVariabelen `$?` inneholder exit-verdien til programmet/kommandoen som sist ble utført. Det finnes andre variabler som er definert, som de to følgende:\n\n```\necho \"PID = $$, navn: $0\"\n```"}
{"identifier": "linux4.13", "section_id": "4.13", "section_title": "while", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION000513000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.13 while\n\nsyntaks:\n\n```\nwhile test\ndo\n     kommandoer\ndone\n```\n\nEksempel; alternativ måte å behandle argumenter: *bedre hvis \"strenger med mellomrom\" er blant argumentene*\n\n```\n#! /bin/bash\n\nwhile [ $# -gt 0 ]  # Så lenge det er noe i $*\ndo\n        echo \"arg: $1\"\n        shift          # skyver ut $1 og legger neste argument i $1\ndone\n```\n\nDeamon-eksempel\n\n```\n#! /bin/bash\n\nwhile [ \"true\" ]  # evig løkke; en streng er alltid 'sann'\ndo\n        echo \"Running $0, a process with PID $$\"\n        sleep 5   # sover i 5 sekunder\ndone\n```"}
{"identifier": "linux4.14", "section_id": "4.14", "section_title": "/proc - et vindu til kjernen", "source_category": "linux", "source_id": "4", "source_title": "Bash-scripting", "anchor": "SECTION000514000000000000000", "source": "os/Forelesning/linux/node5.html", "text": "## 4.14 /proc - et vindu til kjernen\n\nLinux tilbyr oss en enkel måte å undersøke tilstanden til operativsystemet på. Det finnes nemlig en mappe /proc som egentlig ikke finnes på harddisken, men som likevel inneholder “filer” som vi kan lese innholdet fra. Hver gang vi åpner en av filene i /proc, kjøres en metode i kjernen som skriver ut innholdet der og da. Man får altså et øyeblikksbildet av hva som skjer. Her er en liste over interessante filer og mapper i /proc:\n\n* cpuinfo\n* meminfo\n* interrupts\n* Hver prosess har en egen mappe som har samme navnsom prosessens PID. Spennende filer i en slik mappe kan være:\n  * status - Navn og status på prosessen\n  * stat - Teller prosessorbruk, minnebruk osv. se `man proc'\n* uptime\n* version\n* net/"}
{"identifier": "linux6.3", "section_id": "6.3", "section_title": "root og sudo", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION00073000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.3 root og sudo\n\nPå den virtuelle Linux-serveren, som egentlig er en ekstra isolert Docker container, dere har blitt tildelt i os-gruppene har dere rettigheter til å gjøre alt dere måtte ønske, som å installere programmer og lage nye brukere. Husk at Linux-VMene har offentlig IP og dermed kan bli utsatt for hacker-angrep fra hele verden.\n\nRoot er administratorbrukeren på Linux, som har alle rettigheter på systemet. For å bli root kan man logge inn direkte med root-passordet. Alternativt kan man logge inn med en vanlig bruker-konto og så bli root ved hjelp av kommonadoen `sudo su` hvis man er tildelt rettigheter for å gjøre dette.\n\nPå Linux-VM vil du som den vanlige group-brukeren for eksempel ikke få lov til å se på shadowfilen:\n\n```\n$ whoami\ngroup50\n$ cat /etc/shadow\ncat: /etc/shadow: Permission denied\n```\n\nMen fordi group-brukeren er en såkalt sudo-user som har root-rettigheter om han ønsker det, kan han likevel se shadow-filen med kommandoen\n\n```\nsudo cat /etc/shadow\n[sudo] password for group50:\n```\n\netter å ha skrevet inn sitt vanlige passord. Det er også mulig for en sudo-user å få opp et root-shell ved å gjøre\n\n```\nsudo su\n```\n\nMan bør være forsiktig med å jobbe fra et root-shell, siden man da lettere glemmer at man har de allmektige root-rettighetene som potensielt kan føre til store feilgrep.\n\nOm man jobber i et miljø med virtuelle maskiner og kontainere, noe som blir mer og mer vanlig, er ikke det å unngå å være logget på som root like viktig som før. Om man gjør et stort feilgrep, kan man raskt bygge en ny VM eller bare starte en ny kontainer. Ihvertfall så lenge man har backup av alle data som man hadde på serveren. Og det er viktig: ta alltid backup av script og lignende filer som dere har på Linux-VM."}
{"identifier": "linux6.4", "section_id": "6.4", "section_title": "Brukere", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION00074000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.4 Brukere\n\nEn bruker på et UNIX/Linux system består av følgende:\n\n* En linje i filen /etc/passwd som inneholder bl.a\n  * Bruker id - UID. Må være unik.\n  * Brukernavn\n  * Hjemmekatalog\n* En linje i filen /etc/shadow som inneholder en hash av passordet\n* En hjemmekatalog (vanligvis i /home)\n* Eventuelle gruppemedlemskap i filen\n* /etc/group\n\nMan kan lage nye bruker med kommandoen adduser eller useradd . Sistnevnte er kun anbefalt dersom man skal legge til en bruker via et script eller lignende. Kommandoen adduser fungerer mer interaktivt og passer best for å legge til en og en bruker. Den kan brukes slik\n\n```\ngroup60@os60:~$ sudo adduser s123456\n```\n\nfor å legge til brukeren `s123456` .\n\nFor å legge denne brukeren til sudo-gruppen slik at den blir en sudo-bruker, kan gjøres med\n\n```\ngroup60@os60:~$ sudo addgroup s123456 sudo\n```\n\nEt UNIX/Linux system har vanligvis en del brukere i tillegg til de \"menneskelige\" brukerne. Den mest kjente av dem er root, som har UID 0. De øvrige brukerne representerer tjenester som ikke bør kjøre som brukeren root av risikohensyn. Eksempler på slike brukere er nobody, sshd og sys. Dersom man installerer flere tjenester på et system, f.eks en webserver, vil man sansynligvis få opprettet de tilsvarende brukerne automatisk."}
{"identifier": "linux6.5", "section_id": "6.5", "section_title": "Grupper", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION00075000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.5 Grupper\n\n* gruppe av brukere\n* Definert i /etc/group\n* må defineres av root\n\n```\n$ groups haugerud                   # lister gruppene haugerud er med i\n $ chgrp studgruppe fil.txt      # fil.txt tilhører nå studgruppe\n $ chmod 770 fil.txt             # alle rettigheter til alle i studgruppe\n $ sudo adduser s123456 studgruppe # Gjør s123456 til medlem av studgruppe\n```\n\nMan kan lage en ny gruppe med `addgroup` :\n\n```\nmroot@os50:~$ sudo addgroup newgroup\n[sudo] password for mroot: \nAdding group `newgroup' (GID 1003) ...\nDone.\nmroot@os50:~$ grep newgroup /etc/group\nnewgroup:x:1003:\n```"}
{"identifier": "linux6.6", "section_id": "6.6", "section_title": "Rettighetsprinsipper i Linux/UNIX miljøer", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION00076000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.6 Rettighetsprinsipper i Linux/UNIX miljøer\n\nFølgende regler gjelder mellom brukere:\n\n* Alle prosesser/programmer som startes av en bruker vil være eid av den brukeren og filrettigheter vil være i forhold til eierskapet. Unntaket er kommandoen su som forandrer bruker og tjenester som forandrer status på seg selv, f.eks sshd (startes som root, men blir til sshd kort tid etter).\n* Brukere kan kun sende signaler til sine egne prosesser (f.eks med kommandoen kill). Unntak er root.\n* Brukere kan kun forandre på rettighetene til filer som de eier selv. Unntak er root.\n* Brukere kan ikke \"gi\" filer til andre brukere ved å forandre hvem som er eier av filen med kommandoen chown. Root kan.\n* Brukere KAN forandre hvilken gruppe som eier en fil med kommandoen chgrp, men KUN til grupper som den selv er medlem av. Root kan uansett.\n* Brukere kan ikke lage nye brukere. Bare root kan det.\n\nDet finnes to måter å bli root på. Den ene er å bruke kommandoen su , som ber deg om root sitt EGET passord. Denne metoden er mest kjent. I de nyeste versjonene av Linux er det blitt mer vanlig å bruke sudo, som gir rettigheter til vanlige brukere dersom de kan autentisere seg. Man må vanligvis være medlem av en spesiell gruppe for å få lov til å kjøre kommandoen sudo su , som ber brukeren om sitt eget passord istedefor root sitt passord.\n\nDet er også mulig å logge seg rett på systemet som root dersom man har root passordet. Det er derimot ikke anbefalt av følgende årsaker:\n\n* Alt den brukeren gjør vil bli gjort med root-rettigheter.\n* Ved å bruke su eller sudo su kan vi se i logfilene HVEM som ble root. Denne typen informasjon kan være veldig viktig når man vil finne ut hva som har skjedd (og hvem som skal få skylden).\n* Root skal kun brukes når man har behov for det, og ikke behandles som en normal bruker/person."}
{"identifier": "linux6.7", "section_id": "6.7", "section_title": "ssh-copy-id", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION00077000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.7 ssh-copy-id\n\nDet kan være nyttig å kunne logge inn med ssh på andre servere uten å måtte skrive passord hver gang. Sikkerhetsmessig kan dette også være en fordel, da man kan velge å kun tillate innlogging ved hjelp av ssh-nøkler og dermed unngå alle brute-force ssh-angrep. Først må man lage ssh-keys:\n\n```\ngroup1@os1:~$ ssh-keygen \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/home/group1/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /home/group1/.ssh/id_rsa.\nYour public key has been saved in /home/group1/.ssh/id_rsa.pub.\ngroup1@os1:~$\n```\n\nDeretter kan man med ssh-copy-id (som kopierer over id_rsa.pub) sørge for at man senere kan logge inn uten passord:\n\n```\ngroup1@os1:~$ ssh-copy-id group49@os49.vlab.cs.oslomet.no\ngroup49@os49.vlab.cs.oslomet.no's password: \n\ngroup1@os1:~$ ssh group49@os49.vlab.cs.oslomet.no\nLinux os49 2.6.32-5-xen-amd64 #1 SMP Fri Feb 5 17:48:36 UTC 2016 x86_64\ngroup49@os49:~$\n```\n\nMan kan deretter også utføre kommandoer direkte på andre servere:\n\n```\ngroup1@os1:~$ ssh group49@os49.vlab.cs.oslomet.no whoami;hostname\ngroup49\nos1\ngroup1@os1:~$ ssh group49@os49.vlab.cs.oslomet.no \"whoami;hostname\"\ngroup49\nos49\n```"}
{"identifier": "linux6.8", "section_id": "6.8", "section_title": "Root aksess til server med sudo-rettigheter", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION00078000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.8 Root aksess til server med sudo-rettigheter\n\nHvis man har en bruker på en server som har sudo-rettigheter, har man vanligvis ikke mulighet til å logge seg inn med ssh direkte til root-brukeren på serveren. Det er mulig å sette det opp, men det er sikrere og vanlig å skru av muligheten for å logge inn som root med passord. Man kan derfor heller ikke overføre ssh-nøkler med ssh-copy, men det er likevel mulig å sette opp ssh-key innlogging for root. Det som behøves er at nøkkelen også legges i root sin `.ssh` -mappe. Det er viktig å forsikre seg om at root faktisk har en mappe `/root/.ssh` og en enkel måte å sørge for at den blir opprettet (om den ikke har blitt opprettet tidligere) med riktige rettigheter er å kjøre `ssh-keygen` som root:\n\n```\n# ssh-keygen\n```\n\nog taste return på alle spørsmål.\n\nHvis du allerede har satt opp innlogging til din vanlige bruker på serveren, i dette eksempelet til group60@os60, kan du nå overføre nøkkelen derfra slik som dette:\n\n```\ngroup60@os60:~$ sudo cp .ssh/authorized_keys /root/.ssh\n```\n\nHvis mappen `/root/.ssh` ikke eksisterer fra før blir den laget som en fil og da vil innlogging ikke virke. Dermed skal du kunne logge inn også som root fra den serveren, f.eks. studssh, som du satte opp ssh-key innlogging fra til group60 i utgangspunktet. Når man overfører sin offentlige nøkkel til en annen server på denne måten, er det en enveis-innlogging. Det vil ikke være mulig å gå tilbake til serveren man kom fra med denne nøkkelen. Men man må passe godt på sin private nøkkel ( `id_rsa` ) for om andre får tilgang til den, kan de logge seg inn til de serverene som du har overført den offentlige nøkkelen til ( `id_rsa.pub` ). Når du logger deg på en server med ssh-key, er det din private nøkkel ( `id_rsa` ) som brukes til å autentisere deg (bevise at det er deg)."}
{"identifier": "linux6.9", "section_id": "6.9", "section_title": "Bakgrunnsjobber og screen", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION00079000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.9 Bakgrunnsjobber og screen\n\nHvis man ønsker å sette igang en jobb i et terminalvindu og la det stå og jobbe selvom man selv logger ut, kan man bruke screen. Da kan man senere logge seg inn på nytt til samme host og så koble seg opp til terminalvinduet som ligger i bakgrunnen. Man installerer screen og starter en ny screen-session med\n\n```\n$ sudo apt update -y \n$ sudo apt install screen\n$ screen\nScreen version 4.03.01 (GNU) 28-Jun-15\n\n$ uname\nLinux\n$ ./loop.sh\nloop nr 1\nloop nr 2\nloop nr 3\nloop nr 4\n```\n\nog dermed får man et terminalvindu som ser ut som et helt vanlig terminalvindu. Her kan man kjøre kommandoer og for eksempel sette igang en jobb som loop-jobben over. Når man så kobler seg fra dette screen-vinduet med CTRL-a CTRL-d, kommer man tilbake til shellet hvor man kjørte kommandoen screen.\n\n```\n$ screen\n[detached from 9833.pts-0.os1]\n$\n```\n\nSå kan man logge ut og inn igjen(eventuelt fra et helt annent sted) og liste alle screen-sessions med\n\n```\n$ screen -ls\nThere are screens on:\n\t9833.pts-0.os1\t(14. feb. 2017 kl. 18.15 +0100)\t(Detached)\n\t2216.compile\t(13. feb. 2017 kl. 09.01 +0100)\t(Detached)\n\t923.pts-1.os1\t(13. feb. 2017 kl. 08.57 +0100)\t(Detached)\n3 Sockets in /var/run/screen/S-group1.\n\n$\n```\n\nSå kan man koble seg til den screen man ønsker seg med\n\n```\n$ screen -r pts-0.os1\n```\n\nog man vil se at jobben har fortsatt å kjøre i terminalvinduet når man var logget ut.\n\n```\ngroup1@os1:~$ ./loop.sh\nloop nr 1\nloop nr 2\nloop nr 3\nloop nr 4\nloop nr 5\nloop nr 6\nloop nr 7\nloop nr 8\nloop nr 9\nloop nr 10\n```\n\nOm man ønsker å se om man er inne i en screen og vise hvilken det er, kan man oppnå det med\n\n```\n$ echo $STY\n9833.pts-0.os1\n```\n\nFor å gi navn til en screen kan man starte den med\n\n```\n$ screen -S compile\n```\n\nog den listes med navn som vist over i eksempelet med `screen -ls` . Om man fra screen-vinduet taster CTRL-d (uten CTRL-a foran) vil screen-prosessen drepes. På samme måte som om man drepte den med kill. For å scrolle opp og ned må man bruke kommandoen `CTRL-a ESC` og så opp og ned piltaster. `ESC` igjen for å avslutte scrolling.\n\nOm man leser manual-siden for screen, finner man kommandoer man trenger i litt mer spesielle tilfeller, men dette er alt man behøver for enkel bruk."}
{"identifier": "linux6.9.1", "section_id": "6.9.1", "section_title": "Å dele en screen med samme bruker", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION00079100000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.9.1 Å dele en screen med samme bruker\n\nHvis to personer er logget inn på samme Linux-server med samme bruker, kan de enkelt dele en felles screen der begge kan utføre kommandoer og dermed jobbe sammen. Først må en av dem lage en ny screen med opsjonene `-d -m` som gjør at man lager en screen men ikke kobler seg til den:\n\n```\nscreen -d -m -S felles\n```\n\nDeretter kan begge koble seg til med\n\n```\nscreen -x felles\n```\n\nog de vil begge kunne utføre kommandoer og se hva den andre gjør."}
{"identifier": "linux6.9.2", "section_id": "6.9.2", "section_title": "Bakgrunnsjobber og screen", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION00079200000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.9.2 Bakgrunnsjobber og screen\n\nScreen er også et fint verktøy å bruke for å sette igang batch-jobber som potensielt kan bruke lang tid på å bli ferdig og som kan finne på å skrive til både stderr og stdout. Det siste kan være problematisk om man har koblet seg opp med ssh for å starte jobbene, uten å sørge for å redirigere stderr og stdout. Default skriver de da tilbake til terminalen ssh-tilkoblingen kom fra og da kan hele jobben crashe om disse tilkoblingene ikke lenger finnes fordi du har logget ut. Forøvrig er følgende en sikker metode å sette igang en bakgrunnsjobb på en annen maskin med ssh:\n\n```\nssh haugerud@studssh.cs.oslomet.no '/home/haugerud/back.sh </dev/null >/home/haugerud/backup.log 2>&1 &'\n```\n\nLegg merke til at både stdin, stdout og stderr er tatt hånd om, slik at alle koblinger til ssh-kanalen er brutt. I tillegg er jobben (back.sh) avsluttet med &, slik at den legges i bakgrunnen. I tillegg brukes full path for å sikre at det ikke er noen avhengighet av PATH. Dermed vil denne fortsette å kjøre i bakgrunnen etter at man logger seg ut fra shellet som startet jobben med ssh. Alternativt kunne man startet jobben fra en screen-session, som ville stått og tatt i mot eventuell output. Men da kunne man potensielt fått problemer om serveren som kjører screen hadde gått ned."}
{"identifier": "linux6.10", "section_id": "6.10", "section_title": "scp", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION000710000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.10 scp\n\n`scp` (secure copy) kopierer filer mellom maskiner og sender alt kryptert:\n\n```\nmroot@os50:~$ scp haugerud@rex.cs.oslomet.no:~/www/regn .\nhaugerud@rex.cs.oslomet.no's password: \nregn                                                       100%  194   123.7KB/s   00:00    \nmroot@os50:~$\n```\n\nMeget nyttig og mye brukt for sikker filoverføring. Hvis man er på studssh og vil overføre en fil r.sh derfra, kan man gjøre det med\n\n```\nhaugerud@studssh:~$ scp r.sh mroot@os50.vlab.cs.oslomet.no:\nmroot@os50.vlab.cs.oslomet.no's password: \nr.sh                                                        100%   39     0.0KB/s   00:00\n```\n\nMed opsjonen -r kan man overføre mapper(inkludert undermapper):\n\n```\nhaugerud@studssh:~$ ls -l nymappe/\ntotal 16\n-rwxr-xr-x 1 haugerud drift 34 jan.   8 10:17 mitt.sh\n-rwxr-xr-x 1 haugerud drift 39 jan.   8 10:10 r.sh\n-rw-r--r-- 1 haugerud drift 24 jan.   8 10:09 tomfil\nhaugerud@studssh:~$ scp -r nymappe mroot@os50.vlab.cs.oslomet.no:\nmroot@os50.vlab.cs.oslomet.no's password: \ntomfil                                                     100%   24     0.0KB/s   00:00    \nr.sh                                                       100%   39     0.0KB/s   00:00    \nmitt.sh                                                    100%   34     0.0KB/s   00:00\n```"}
{"identifier": "linux6.11", "section_id": "6.11", "section_title": "Backup med rsync og cron-tab", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION000711000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.11 Backup med rsync og cron-tab\n\nNår man har satt opp passord-løs innlogging med ssh-keys som vist over, er det enkelt å sette opp systematisk backup. Anta man ønsker å ta backup av /home/group1 på en os-VM. Det kan man nå gjøre med\n\n```\nscp -r /home/group1/ haugerud@studssh.cs.oslomet.no:/home/haugerud/kopiavos1\n```\n\nog hele mappen og alle undermapper blir kopiert over. Men når man gjør det på nytt en gang til, vil alle filer kopieres over enda en gang. Linux-kommandoen `rsync` gjør det samme, men den kopierer bare over filer som har endret seg fra gang til gang:(Gjør først `$ sudo apt install rsync` )\n\n```\nrsync -a /home/group1/ haugerud@studssh.cs.oslomet.no:/home/haugerud/rsynckopiavos1\n```\n\nNår man lager en ny fil eller gjør en endring, er det bare dette som kopieres over neste gang. Den enkleste måten å få dette til å bli en daglig rutine(eventuelt hver time) er å bruke `cron` . På Linux-VM må cron først insatlleres med\n\n```\ngroup100@os100:~$ sudo apt install cron\n```\n\nOm man kjører\n\n```\ncrontab -e\n```\n\nfår man opp en fil som man kan bruke til å kjøre jobber til visse tider på døgnet. Følgende linje i crontab\n\n```\n# Edit this file to introduce tasks to be run by cron.\n#\n# m h  dom mon dow   command\n\n30 1 * * * /home/group1/bin/rsyncStudssh.sh\n```\n\nfører til at scriptet kjører hver natt kl 01.30. Hvis man bytter ut tallet 1 med *, vil scriptet `rsyncStudssh.sh` kjøres 30 minutter etter hver hele time. Forkortelsene i linjen over forklarer syntaksen i crontab:\n\n|   |   |\n|---|---|\n| m | minute |\n| h | hour |\n| dom | day of month |\n| mon | month |\n| dow | day of week |\n\nPå siden [crontab.guru](https://crontab.guru) er det enkelt å teste ut hva forskjellige crontab-koder gir.\n\nOm man har root aksess kan man også legge script i mappene definert i `/etc/crontab` :\n\n```\ngroup1@os1:~$ cat /etc/crontab \n# /etc/crontab: system-wide crontab\n# Unlike any other crontab you don't have to run the `crontab'\n# command to install the new version when you edit this file\n# and files in /etc/cron.d. These files also have username fields,\n# that none of the other crontabs do.\n\nSHELL=/bin/sh\nPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin\n\n# m h dom mon dow user\tcommand\n17 *\t* * *\troot    cd / && run-parts --report /etc/cron.hourly\n25 6\t* * *\troot\ttest -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )\n47 6\t* * 7\troot\ttest -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )\n52 6\t1 * *\troot\ttest -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )\n```\n\nScript som for eksempel legges i `/etc/cron.hourly` vil kjøres 17 minutter over hver hele time."}
{"identifier": "linux6.12", "section_id": "6.12", "section_title": "wget", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION000712000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.12 wget\n\n`wget` henter web (og ftp) sider fra kommandolinjen.\n\n```\nmroot@os50:~$ wget https://www.cs.oslomet.no/~haugerud/regn\n--2018-02-25 22:29:42--  https://www.cs.oslomet.no/~haugerud/regn\n```\n\nPå denne måten kan store nedlastninger kjøres i bakgrunnen. Opsjonen `-O -` sender output til STDOUT, slik at det kan brukes i en pipe.\n\n```\nwget -r https://www.gnu.org -o log.txt\n```\n\nOpsjonen `-r` henter hele web-stedet rekursivt (default dybde er 5). Med opsjonen `--mirror` og kjørt regelmessig, kan man opprettholde en mirror-site."}
{"identifier": "linux6.13", "section_id": "6.13", "section_title": "gzip,bzip2, tar og zip", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION000713000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.13 gzip,bzip2, tar og zip\n\n`gzip` komprimerer en fil mens `gunzip` dekomprimerer den.\n\n```\n$ ll\n-rw-r--r--    1 haugerud drift      130680 Oct  5 20:11 passwd\n$ gzip passwd\n$ ll\n-rw-r--r--    1 haugerud drift       39093 Oct  5 20:11 passwd.gz\n$ gunzip passwd.gz\n$ ll\n-rw-r--r--    1 haugerud drift      130680 Oct  5 20:11 passwd\n```\n\nDe nyere `bzip2` og `bunzip2` gjør det samme, er ikke like raskt, men komprimerer bedre.\n\n```\n$ bzip2 passwd\n$ ll\n-rw-r--r--    1 haugerud drift       29246 Oct  5 20:11 passwd.bz2\n$ bunzip2 passwd.bz2\n```\n\nKommandoen `tar` pakker en hel mappestruktur til en enkelt fil.\n\n```\n$ tar cf dir.tar dir  # Pakker alt ned i dir.tar, c = create\n$ tar xf dir.tar      # Pakker alt opp, lager dir, x = extract\n```\n\nMan kan kjøre `gzip` på en tar fil, men det er enklere å gjøre alt på en gang:\n\n```\n$ tar cfz dir.tgz dir  # Pakker alt ned i dir.tar, c = create, z = gzip\n$ tar xfz dir.tgz      # Pakker alt opp, lager dir, x = extract, z = gzip\n$ tar cfz ob1.tgz snort.bash info.bash # Pakker de to filene i ob1.tgz\n$ tar cfj dir.tbz dir  # j = bzip2\n```\n\nMan kan gjøre det samme med kommandoen `zip` som kan kjøre på mange plattformer og er kompatibel med windows sin `PKZIP` .\n\n```\n$ zip -r dir.zip dir  # -r = rekursivt i mappen dir\n$ unzip dir.zip\n```\n\n*tar cfz komprimerer noe mer:*\n\n```\n-rw-------    1 haugerud drift      728780 Sep 27 00:58 forelesning.tgz\n-rw-------    1 haugerud drift     1086314 Sep 27 01:00 forelesning.zip\n```"}
{"identifier": "linux6.14", "section_id": "6.14", "section_title": "awk (ward)", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION000714000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.14 awk (ward)\n\nSyntaks: awk 'awk program' fil\n\n```\n$ ps u\nhaugerud 23419  0.0  0.1  2032 1268 pts/1    S    09:07   0:00 -bash\n\n$  ps aux | awk '/haugerud/ {print $2}'\n23419\n4396\n4397\n$  ps aux | awk '/haugerud/ {print $2,$11}'\n23419 -bash\n4403 ps\n4404 awk\n$  ps aux | awk '{if ($1 == user) {print $2}}' user=`whoami`\n23419\n4416\n4417\n$ awk -F: '{ if ($1 == \"haugerud\") {print $NF}}' /etc/passwd\n/bin/bash\n```"}
{"identifier": "linux6.QA", "section_id": "6.QA", "section_title": "Spørsmål", "source_category": "linux", "source_id": "6", "source_title": "Linux-VMer, Screen, ssh-keys, cron", "anchor": "SECTION000715000000000000000", "source": "os/Forelesning/linux/node7.html", "text": "## 6.QA Spørsmål\n\n**Hvordan fjerne et alias?**\n\nSvar: med unalias: `unalias move`"}
{"identifier": "linux3.3", "section_id": "3.3", "section_title": "Dagens faktum: UNIX' opprinnelse", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION00043000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.3 Dagens faktum: UNIX' opprinnelse\n\nLinux er en åpen kildekode variant av operativsystemet UNIX som opprinnelig ble skrevet i PDP-7 assembler av Ken Thompson i 1969 ved AT&T Bell Laboratories. Han gjorde det for å kunne kjøre spillet \"space travel\" på minicomputeren PDP-7 (9 Kbyte internminne). Thompson lagde senere programmeringsspråket B og var også med å lage språket Go mens han jobbet hos Google. Progrmmeringsspråket C ble laget av Dennis Ritchie rundt 1970 for å kunne skrive UNIX i et plattformuavhengig språk; noe som ble gjort i 1973. UNIX og C hadde stor betydning for utviklingen av dataindustrien.\n\nIllustrasjon:\nKen Thompson(foran) og Dennis Ritchie ved en PDP-11."}
{"identifier": "linux3.4", "section_id": "3.4", "section_title": "Shell-variabler", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION00044000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.4 Shell-variabler\n\n*I et Linux-shell finnes det systemvariabler som $HOME, $PATH, $PS1, $CLASSPATH og mange\nandre som systemet og mange applikasjoner som f. eks. Jbuilder bruker. En bruker kan også definere\nsine egne lokale variabler med selvlagde variabelnavn.\nDet er vanlig, men ikke påkrevet å bruke små bokstaver i\nvariabelnavnet til lokale variable.*\n\n```\n$ os=Linux\n$ dato='Thu Jan 25'\n```\n\nDet må *ikke* være mellomrom før og etter =. Variabler refereres til med et $-tegn foran navnet:\n\n```\n$ echo $os\nLinux\n$ echo $dato\nThu Jan 25\n```\n\nNavnet kan avgrenses med\n\n```\n$ echo $osfrelst\n\n$ echo ${os}frelst\nLinuxfrelst\n```\n\n*Kommandoer for å liste og fjerne variabler:*\n\n```\n$ set         # Lister alle definerte variabler og funksjoner\n$ unset os    # Fjerner definisjonen av os\n```"}
{"identifier": "linux3.5", "section_id": "3.5", "section_title": "Globale shell-variabler", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION00045000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.5 Globale shell-variabler\n\nI utgangspunktet er shell-variabler lokale og bare kjent i det shellet de har blitt definert. Man kan gjøre variabler globale med kommandoen `export` :\n\n```\n$ date='30. januar'\n$ os=Linux\n$ export os\n$ export nyglobal='ny global verdi'\n```\n\nVariabelene `$os` og `nyglobal` er nå globale og vil arves av nye shell som startes, men det vil ikke `$date` :\n\n```\n$ bash\n$ echo $os\nLinux\n$ echo $nyglobal\nny global verdi\n$ echo $date\n```\n\nmen som vi ser kjenner det nye shellet ikke til variabelen `$date` , den er lokal og bare kjent i shellet den ble definert i.\n\n* vanlig å skrive globale variabler med store bokstaver\n* kalles ofte ENVIRONMENT varibler ($HOME, $PATH, $EDITOR, $CLASSPATH)\n* leses av programmer som ønsker å vite default editor, classpath, etc\n* Globale variabler kan listes med `export`\n* Variabler kan defineres direkte som globale i bash: `$ export os=Linux`\n* Kommandoen `$ env` lister alle definerte globale variabler"}
{"identifier": "linux3.6", "section_id": "3.6", "section_title": "Hvor ligger alle kommandoene egentlig? Svar: PATH", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION00046000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.6 Hvor ligger alle kommandoene egentlig? Svar: PATH\n\n*$PATH er en global variabel som inneholder en streng med alle mapper \n(separert med kolon) som shellet leter i for å finne kjørbare filer når et \n  kommandonavn tastes inn til shellet*\n\n```\nstudssh$ echo $PATH\n/opt/bin:/local/iu/bin:/local/gnu/bin:/local/bin:/usr/X11R6/bin:/usr/bin:/bin:.:\nstudssh$ type ls              # type gir hvilket program shellet starter\nls is /bin/ls\n```\n\n*Når du taster inn*\n\n```\n$ ls\n```\n\n*leter bash igjennom alle mappene i $PATH etter en fil med navn ls helt til \ndet finner en i den nest siste (/bin) og kjører den.* Hvis du gjør PATH tom:\n\n```\n$ PATH=\"\"\n```\n\nvil shellet ikke finne vanlige kommandoer som `mv` og `ls` fordi mappen `/bin` ikke er med i `$PATH` ."}
{"identifier": "linux3.7", "section_id": "3.7", "section_title": "Prosesser", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION00047000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.7 Prosesser\n\nHver gang vi starter et program lager Linux en uavhengig prosess: $ emacs Starter vi fra et shell, venter shellet på at programmet skal bli ferdig. $emacs& $ Dette starter emacs som en bakgrunnsprosess\n\n| kommando | virkning |\n|--------|--------|\n| $ ps | Lister shellets prosesser |\n| $ ps aux (eller -Al) | Alle prosesser |\n| $ top | Dynamisk ps -aux |\n| $ kill 1872 | Drep prosess med PID 1872 |\n| $ kill -9 1872 | Forsert drap av 1872 |\n| $ time mittScript.bash | Måler tidsforbruket |"}
{"identifier": "linux3.8", "section_id": "3.8", "section_title": "Apostrofer", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION00048000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.8 Apostrofer\n\n*I bash brukes 3 forskjellige typer apostrofer ', ` og \" som alle \n  har forskjellig betydning:*\n\n```\n$ dir=mappe\n\n$ echo 'ls $dir'      ' -> Gir eksakt tekststreng\nls $dir\n\n$ echo \"ls $dir\"      \" -> Variabler substitueres; verdien av $dir skrives ut.\nls mappe\n\n$ echo `ls $dir`      ` -> utfører kommando!\nfil1 fil2 fil.txt\n```\n\nHuskeregel\n\n```\n'  ->  /  -> Linux    -> vet hva man får\n`  ->  \\  -> Windows -> aner ikke hva man får\n```\n\nEt mer robust alternativ når en kommando skal utføres:\n\n```\necho $(ls $dir)\n```\n\nDette gir også mer lesbar kode. I tillegg kan man ikke ha uttrykk med apostrofer inni hverandre:\n\n```\nrex$ line=`grep `whoami` /etc/passwd`\nUsage: grep [OPTION]... PATTERN [FILE]...\nTry 'grep --help' for more information.\nbash: /etc/passwd: Permission denied\n```\n\nMen dette går fint med `$()` syntaksen:\n\n```\nrex$ line=$(grep $(whoami) /etc/passwd)\nrex$ echo $line\nhaugerud:x:5999:9002:Hårek Haugerud,,,:/home/haugerud:/bin/bash\n```\n\nSå generelt anbefales det å bruke denne. Om man prøver følgende uttrykk med apostrofer inni hverandre:\n\n```\nhaugerud@studssh:~/mappe$ var=`/bin/ls `pwd` `\n```\n\nDet vil si, det ga ingen feilmeldinger. Men om man ser nøyere på hva resultatet ble\n\n```\nhaugerud@studssh:~/mappe$ echo $var\nfil.txtpwd\nhaugerud@studssh:~/mappe$ pwd\n/iu/nexus/ua/haugerud/mappe\nhaugerud@studssh:~/mappe$ ls\nfil.txt\n```\n\nså ser vi at de ikke fungerte som ønsket. Igjen er det bedre å bruke `$()` konstruksjonen:\n\n```\nhaugerud@studssh:~/mappe$ var=$(/bin/ls $(pwd))\nhaugerud@studssh:~/mappe$ echo $var\nfil.txt\n```"}
{"identifier": "linux3.9", "section_id": "3.9", "section_title": "Tilordne output fra kommando til en variabel", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION00049000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.9 Tilordne output fra kommando til en variabel\n\n```\n$ mappe=`pwd`\n$echo $mappe\n/iu/nexus/ud/haugerud\n$ tall=`seq 5 10`\n$ echo $tall\n5 6 7 8 9 10\n```\n\nAnbefalt alternativt:\n\n```\n$ mappe=$(pwd)\n$ tall=$(seq 5 10)\n$ echo $tall\n5 6 7 8 9 10\n$ tall=$(echo {5..10})\n$ echo $tall\n5 6 7 8 9 10\n```"}
{"identifier": "linux3.10", "section_id": "3.10", "section_title": "Omdirigering (viktig!)", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION000410000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.10 Omdirigering (viktig!)\n\n*Den store fleksibiliteten det gir å kunne dirigere datastrømmer til og \nfra filer og programmer har alltid vært en sentral og nyttig egenskap ved Linux* .\n\nDe fleste Linux programmer og kommandoer har alltid tre åpne kanaler:\n\n| nummer | navn | fullt navn | funksjon | default |\n|------|----|----------|--------|-------|\n| 0 | stdin | standard in | input kanal | fra tastatur |\n| 1 | stdout | standard out | output kanal | til skjerm |\n| 2 | stderr | standard error | kanal for feilmelding | til skjerm |\n\nDataene som strømmer inn og ut av disse kanalene (streams) kan omdirigeres til og fra filer og programmer.\n\nIllustrasjon:\nLinux datakanaler"}
{"identifier": "linux3.10.1", "section_id": "3.10.1", "section_title": "Omdirigering til og fra filer", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION000410100000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.10.1 Omdirigering til og fra filer\n\nEks: stdout for echo er terminal.\n\n```\n$ echo hei\nhei\n$ echo hei > fil1\n$ cat fil1\nhei\n$ echo hei2 >> fil1\n$ cat fil1\nhei\nhei2\n```\n\n| omdirigering | virkning |\n|------------|--------|\n| > fil.txt | omdirigerer stdout til fil.txt. Overskriver |\n| >> fil.txt | legger stdout etter siste linje i fil.txt |\n| >& fil.txt | sender også stderr til fil.txt |\n| 2> err.txt | sender stderr til err.txt |\n| 2> /dev/null | stderr sendes til et 'sort hull' og forsvinner |\n| > fil.txt 2> err.txt | stdout -> fil.txt stderr -> err.txt |\n| find / -name passwd 2>&1 | grep -v Permission | sender stderr til samme kanal som stdout |\n| prog < fil.txt | sender fil til stdin for program |\n\nFlere eks:\n\n```\n$ ehco hei\nehco: Command not found\n$ ehco hei >& fil1\n$ cat fil1\nehco: Command not found\n$ echo hei > fil1 2> err.txt   # Sender error til err.txt\n$ mail haugerud < fil1\n```\n\nKonstruksjonen `2>&1` betyr: send stderr til samme kanal som stdout. Man limer da stderr-kanalen til kommandoen på samme linje inn i stdout-kanalen. I eksempelet over vil det føre til at man kan grep'e på både stdout og stdin fra find. Uten `2>&1` ville man bare kunne grep'e på stdout. Denne konstruksjonen kan også brukes som alternativ til `>&` , kommandoen\n\n```\nls /tmp/finnesikke > fil.txt 2&>1\n```\n\nvil sende stderr til fil.txt (men må stå etter `>` ).\n\nKonstruksjonen `1>&2` betyr: send stdout til samme kanal som stderr. Inne i et script vil\n\n```\necho \"Error!\" 1>&2\n```\n\nsende feilmeldinger til stderr, slik programmer vanligvis gjør. Vanligvis sender echo output til stdin, men `1>&2` gjør at stdout istedet sendes til stderr."}
{"identifier": "linux3.11", "section_id": "3.11", "section_title": "Omdirigering til og fra kommandoer; pipes", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION000411000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.11 Omdirigering til og fra kommandoer; pipes\n\n*En pipe  er et data-rør som leder et programs stdout til et annent programs stdin.* Uten pipe:\n\n```\n$ ps aux > fil\n$ more fil\n```\n\nMed pipe:\n\n```\n$ ps aux | more\n```\n\n*Dette gjør at man kan kombinere alle Linux-kommandoene på en rekke måter. Noen eksempler:*\n\n```\n$ ps aux | grep haugerud | more\n$ cat /etc/passwd | sort > fil.txt\n$ sort /etc/passwd > fil.txt \n$ ps aux | awk '{print $1}' | sort | uniq | wc -l\n$ ps -eo user | sort | uniq | wc -l\n```\n\n*Forklaring til det siste eksempelet: ps -eo user gir bare brukernavnet i ps-listingen. sort sorterer listen med brukernavn alfabetisk. uniq fjerner \nidentiske linjer, men kun de som kommer etter hverandre, derfor sort først. \nwc -l returnerer antall linjer. En slik \n'pipeline' gir dermed antall brukere som kjører prosesser på maskinen.*\n\nIllustrasjon:\nØverst: ps -aux | more. Nederst:  cat /etc/passwd | sort > fil.txt."}
{"identifier": "linux3.12", "section_id": "3.12", "section_title": "Piping standard error", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION000412000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.12 Piping standard error\n\nNår man setter en pipe etter en kommando, er det bare stdout som sendes dit. Men ved hjelp av konstruksjonen `|&` sender man også stderr videre:\n\n```\n$ ehco hei | grep found\nNo command 'ehco' found, did you mean:\n Command 'echo' from package 'coreutils' (main)\nehco: command not found\n$ ehco hei |& grep found\nNo command 'ehco' found, did you mean:\nehco: command not found\n```\n\nFinnes det en annen måte å gjøre det samme på?"}
{"identifier": "linux3.13", "section_id": "3.13", "section_title": "Sub-shell", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION000413000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.13 Sub-shell\n\nKonstruksjonen `(kommando;kommando)` gir et såkalt subshell. Da startes et nytt shell og man mottar den samlede output til stdout og stderr i shellet som kjører kommandoen. Det kan f.eks. brukes til å slå sammen output fra to filer:\n\n```\n$ cat > fil1\nen\nto\ntre\n$ cat > fil2\ntre\nto\nfire\n$ sort fil2\nfire\nto\ntre\n```\n\nHvis man ønsker å skrive ut de to filene med en kommando, kan man gjøre\n\n```\n$ cat fil2;cat fil1\ntre\nto\nfire\nen\nto\ntre\n```\n\nMen anta at man ønsker å sortere output fra de to filene; da kan man prøve følgende:\n\n```\ncat fil1;cat fil2 | sort\nen\nto\ntre\nfire\nto\ntre\n```\n\nMen det som skjer er at bare fil2 blir sortert. Om man lager et sub-shell\n\n```\n$ (cat fil1;cat fil2)\nen\nto\ntre\ntre\nto\nfire\n```\n\nvil output fra dette subshellet samlet sendes til sort:\n\n```\n$ (cat fil1;cat fil2) | sort\nen\nfire\nto\nto\ntre\ntre\n```\n\nog man oppnår det man ønsket."}
{"identifier": "linux3.14", "section_id": "3.14", "section_title": "source", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION000414000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.14 source\n\n| $ emacs change |\n|--------------|\n| #! /bin/bash |\n| cd /usr/bin |\n| pwd |\n\n```\n$ pwd\n/\n$ change\n/usr/bin\n$ pwd\n/\n```\n\nNår scriptet change kjøres, starter en ny prosess; et nytt shell som utfører\n\n```\ncd /usr/bin\n```\n\nog avsluttes. All shell-info blir da borte (variabler og posisjon i filtreet).\n\nIllustrasjon:\nNår et script kjøres startes et helt nytt shell. Alt som \nhar skjedd i dette shellet blir borte når scriptet avsluttes (exit utføres selvom det ikke \nstår eksplisitt på slutten av scriptet).\n\nKommandoen `source` utfører linje for linje i argumentfilen uten å starte noe annent shell.\n\n```\n$ pwd\n/\n$ source change\n/usr/bin\n$ pwd\n/usr/bin\n```\n\nI Bash er `.` og `source` ekvivalent:\n\n```\n$ . change   # samme som $ source change\n```"}
{"identifier": "linux3.15", "section_id": "3.15", "section_title": "Kommandoer brukt under forelesningen", "source_category": "linux", "source_id": "3", "source_title": "Variabler, omdirigering og pipes", "anchor": "SECTION000415000000000000000", "source": "os/Forelesning/linux/node4.html", "text": "## 3.15 Kommandoer brukt under forelesningen\n\n[Kommandoer](https://www.cs.oslomet.no/~haugerud/os/Forelesning/forelesningsKommandoer/Fri07.02.2020.html)"}
{"identifier": "linux9.2", "section_id": "9.2", "section_title": "Dockerhub", "source_category": "linux", "source_id": "9", "source_title": "Docker og Dockerhub, shell script ytelse", "anchor": "SECTION000102000000000000000", "source": "os/Forelesning/linux/node10.html", "text": "## 9.2 Dockerhub\n\nVanligvis laster man ned docker image fra [Dockerhub](https://hub.docker.com) hvor det ligger tusensvis av ferdilagde image som man kan laste ned og bruke, som ubuntu og nginx. Men man kan også lage sitt eget repository og laste opp egne ferdiglagde image dit som andre så kan laste ned og bruke. Anta man vil lage en ubuntu container som har jed installert og bruker følgende Dockerfile:\n\n```\nroot@os110:~/osbuntu# cat Dockerfile\nfrom ubuntu\nRUN apt-get -y update\nRUN apt install -y jed\n```\n\nDeretter bygger man den og lager et image som man kaller for eksempel osbuntu:\n\n```\nroot@os110:~/osbuntu# docker build -t osbuntu .\n```\n\nI dette tilfellet har jeg en bruker på dockerhub som heter haugerud og jeg må derfor tagge imaget på riktig måte for å laste det opp dit:\n\n```\nroot@os110:~/osbuntu# docker tag osbuntu haugerud/osbuntu:latest\n```\n\nDette kan også gjøres direkte når man bygger. Default versjon er 'latest', men man kan også lage flere versjoner med egendefinerte versjonsnummer som 1.0, 2.0, etc.\n\nFor å kunne pushe et image til Docker Hub må man først logge inn:\n\n```\nroot@os110:~# docker login\nLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.\nUsername: haugerud\nPassword: \nWARNING! Your password will be stored unencrypted in /root/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\n```\n\nog så kan man pushe et image:\n\n```\nroot@os110:~# docker push haugerud/osubuntu:latest\nThe push refers to repository [docker.io/haugerud/osubuntu]\n58657d799cb5: Pushed \nd0729e7aec69: Pushed \n8aaae71fccde: Pushed \n03cb13a80250: Pushed \nb93c1bd012ab: Mounted from library/ubuntu \n1.0: digest: sha256:5d9e384a97484e2af982d940833102b14638b057a286b0ca950906903e4b0220 size: 1368\nroot@os110:~#\n```\n\nDeretter kan hvem som helst laste ned dette imaget fra hvor som helst og sikre seg en fin Ubuntu-container med jed ferdig installert:\n\n```\nroot@os800:~# docker pull haugerud/osbuntu\nUsing default tag: latest\nlatest: Pulling from haugerud/osbuntu\nDigest: sha256:55bd19eebe21a365b789dbf7930df2027e3c860f87b31d161f8b143be361bbab\nStatus: Image is up to date for haugerud/osbuntu:latest\ndocker.io/haugerud/osbuntu:latest\n\nroot@os800:~# docker run -it haugerud/osbuntu /bin/bash\nroot@601858e8cd75:/# type jed\njed is /usr/bin/jed\n```\n\nHvis man ønsker å laste ned en annen versjon enn latest, for eksempel versjon 1.0, kan man gjøre det på følgende måte:\n\n```\nroot@os800:~# docker pull haugerud/osbuntu:1.0\n```"}
{"identifier": "linux9.3", "section_id": "9.3", "section_title": "Shell-programmering, oppsummering", "source_category": "linux", "source_id": "9", "source_title": "Docker og Dockerhub, shell script ytelse", "anchor": "SECTION000103000000000000000", "source": "os/Forelesning/linux/node10.html", "text": "## 9.3 Shell-programmering, oppsummering\n\n|   |   |\n|---|---|\n| + | Fint til enkle oppgaver der Linux-kommandoer gjør jobben |\n| + | Slipper å kompilere |\n| + | Pipes, omdirigering: Kraftige verktøy |\n| + | bra til enkle systemscript |\n| - | dårlig programstruktur (variabel-typer, parameter-overføring, klasser, etc.) |\n| - | dårlige feilmeldinger/debugging vanskelig |\n| - | kryptisk syntaks |\n| - | Veldig langsom sammenlignet med kompilert kode |"}
{"identifier": "linux9.4", "section_id": "9.4", "section_title": "Hastighet til programmer skrevet i  bash, python, perl, Java og C", "source_category": "linux", "source_id": "9", "source_title": "Docker og Dockerhub, shell script ytelse", "anchor": "SECTION000104000000000000000", "source": "os/Forelesning/linux/node10.html", "text": "## 9.4 Hastighet til programmer skrevet i  bash, python, perl, Java og C\n\nVi skal nå sammenligne hastigheten til programmer skrevet i bash, python, perl, Java og C som utfører følgende kode:\n\n```\nfor(j=0;j < TIMES;j++)\n       {\n       sum = 0;\n       for(i=0;i < 40000;i++)\n          {\n          tall = (i + 1)*(i + 1) - i*i;\n          sum = sum + tall;\n          }\n       }\n```\n\nI 2010 ble hastigheten til disse programmen testet på to av serverene ved oslomet og resultatene så da slik ut på cube (Linux) og nexus (Solaris):\n\n| Språk | CPU-tid i sekunder på cube | CPU-tid i sekunder på nexus | TIMES |\n|-----|--------------------------|---------------------------|-----|\n| sh | 248 | - | 1 |\n| bash | 5.7 | 11.8 | 1 |\n| php | 5.6 | 13.3 | 21 |\n| perl | 5.6 | 16.4 | 75 |\n| Java | 5.6 | - | 13500 |\n| C/C++ | 5.6 | 4.3 | 63000 |\n\nDet viste altså at C-programmet var 63000 ganger raskere enn et bash-script.\n\nPå forelesningen i 2019 ble dette resultatene med 500.000 runder i innerste løkke (12 ganger mer enn i 2010):\n\n```\nsum.bash:  TIMES = 1;\nsum.perl:  TIMES = 36;\nsum.py:    TIMES = 44\nsum.php:   TIMES = 400;\nsum.c:     TIMES = 4100;\nSum.java:  TIMES = 20000;\nsumO.c:    TIMES = 28000;\n```\n\npå en Linux PC med en Intel Core i7-3770 CPU med klokkefrekvens på 3.40GHz. Det er overraskende at forskjellene er så store. Og at Java er så nær C i effektivitet. Det siste skyldes at java bruker en såkalt JIT(Just-In-Time) kompilator, som kan kompilere hele eller deler av bytekoden om til maskinkode, tilsvarende som når C kompileres, rett før programmet kjøres. Forøvrig bruker java for å gjøre dette delvis to CPUer. Om java-programmet tvinges til å kjøre på en CPU, reduseres TIMES til 17000.\n\nForøvrig er resultatet for sum.c om man kompilerer med gcc uten å bruke opsjonen `-O` . Da kompileres programmet hurtig, men ikke med fokus på at det skal kjøre raskt. Programmet sumO.c er kompilert med `-O` og da går C-programmet mye raskere.\n\nÅ finne ut om forskjellen på Linux-VM'ene er den samme er en av ukens øvingsoppgaver.\n\nMen det er viktig å teste på nøyaktig det man er ute etter. Følgende kode leser en fil og skriver den til en annen fil med linjenummer:\n\n```\n#! /bin/bash\n\necho \"\" > /tmp/ny.fil\nnr=0\nwhile read line\ndo\n    (( nr++ ))\n    echo \"$nr: $line\" >> /tmp/ny.fil\ndone < /tmp/stor\necho \"Read $nr lines\"\n```\n\nTestes dette på å lese en 13 Mbyte tekstfil på studssh gir det:\n\n| Språk | CPU-tid i sekunder |\n|-----|------------------|\n| bash | 68.57 |\n| Java | 17.04 |\n| php | 9.3 |\n| perl | 2.18 |\n| C++ | 2.00 |\n\nOg som man ser er forskjellene mye mindre.\n\nFølgende avsnitt om regulære uttrykk betegnes i dette kurset som \"referansestoff\". Dette er stoff som det er interessant og viktig å vite om og som kan være nyttig å bruke i praksis, men dette stoffet vil det ikke bli spurt om til eksamen og er slik sett ikke en del av pensum."}
{"identifier": "linux1.2", "section_id": "1.2", "section_title": "Hva er Linux?", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION00022000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.2 Hva er Linux?\n\n* Linux er et operativsystem = et stort og komplisert program som styrer en datamaskin\n* Linux-kjernen laget av Linus Torvalds i 1991\n* GNU/Linux er et mer korrekt navn\n* Mest brukt som server OS\n* Linux er et Unix-OS, andre er Mac OS X, FreeBSD, BSD, Solaris, AIX\n* Unix ble laget av Ken Thompson og Dennis Ritchie i 1969\n* Viktig del av Unix-filosofien: Sette sammen mange små programmer på mange måter"}
{"identifier": "linux1.3", "section_id": "1.3", "section_title": "Linux", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION00023000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.3 Linux\n\n* Åpen kildekode, Linux-kjernen er GPL\n* Det finnes mange distribusjoner av Linux, i alle størrelser.\n* Små: i IP-kameraer, Mobiltelefoner(Android), Routere, switcher\n* Store: Ubuntu/Debian, Red Hat/Fedora/Centos, SUSE/openSUSE\n* GUI med vinduer og pek-og-klikk (for de som trenger det)"}
{"identifier": "linux1.4", "section_id": "1.4", "section_title": "Linux-fordeler", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION00024000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.4 Linux-fordeler\n\n* Gratis og åpen kildekode\n* Naturlig del av åpen kildekode-prosjekter\n* Sikkerhet\n* Stabilitet"}
{"identifier": "linux1.5", "section_id": "1.5", "section_title": "Hvor brukes Linux?", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION00025000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.5 Hvor brukes Linux?\n\n* Desktop/laptop: 1.5%\n* Web servere: 70%\n* Public Cloud: Amazon EC2 92% (Totalt: AWS 41%, Microsoft Azure 29%)\n* Smartphone/nettbrett: Android 70%, iOS 24% (Unix basert)\n* Supercomputere: 100% av de 500 største"}
{"identifier": "linux1.6", "section_id": "1.6", "section_title": "Hva er et shell?", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION00026000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.6 Hva er et shell?\n\n* kommandobasert verktøy\n* tar imot kommandoer fra tastatur\n* *Grensesnitt mot Linux-kjernen*\n\nIllustrasjon:\nLinux-kommandoene sendes til shellet som er et skall rundt Linux-kjernen. Shellet \nsørger for at oppdraget det får blir utført ved å gjøre et sett av systemkall til kjernen."}
{"identifier": "linux1.7", "section_id": "1.7", "section_title": "Hvorfor shell/kommandolinje?", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION00027000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.7 Hvorfor shell/kommandolinje?\n\n*Tidligere gikk all kommunikasjon med et Linux-system gjennom et shell.* [1](footnode.html#foot98)\n\n* Stor frihetsgrad; \"Alt\" er mulig å gjøre\n* **Kompliserte oppgaver kan løses effektivt, ved å sette sammen mange små Linux-program; sort, grep, sed, cp, mv**\n* *et programmeringsspråk: shell-script som kombinerer Linux-kommandoer; systemprogrammering*\n* Vanskelig å automatisere og replikere en lang sekvens av pek og klikk\n* Mye brukt i Linux automatisering, Cloud, Docker, Kubernetes, Git, osv"}
{"identifier": "linux1.8", "section_id": "1.8", "section_title": "Innlogging", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION00028000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.8 Innlogging\n\nHver bruker på et Linux-system har\n\n* entydig brukernavn\n* passord\n\nOversikt over alle brukere på systemet ligger i filen\n\n* /etc/passwd\n\nog de krypterte passordene ligger i filen\n\n* /etc/shadow\n\nKan ikke leses av vanlige brukere, kun av *root* (superuser)\n\nPassordet settes/endres på OsloMet via web."}
{"identifier": "linux1.9", "section_id": "1.9", "section_title": "Linux filsystem", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION00029000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.9 Linux filsystem\n\nFiler er et helt sentralt Linux-begrep. *Alle data lagres som filer og strømmer av \ndata fra tastatur og andre devicer blir behandlet som om de var filer.*\n\nIllustrasjon:\nEt typisk Linux-filtre"}
{"identifier": "linux1.10", "section_id": "1.10", "section_title": "Hvordan man flytter seg i et Linux-filtre", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION000210000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.10 Hvordan man flytter seg i et Linux-filtre\n\n| Linux-kommando | Virkning |\n|--------------|--------|\n| $ pwd | gir mappen/katalogen man står i (Print Working Directory) |\n| $ cd home | change directory til “home” (kun fra /) |\n| $ cd /etc | flytter til /etc |\n| $ cd .. | flytter en mappe opp |\n| $ cd ../.. | flytter to mapper opp |\n| $ cd | går til hjemmemappen |\n| $ ls -l | viser alt som finnes i mappen |"}
{"identifier": "linux1.11", "section_id": "1.11", "section_title": "Å lage et shell-script", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION000211000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.11 Å lage et shell-script\n\n```\n$ jed script.sh\n```\n\nIllustrasjon:\nscript.sh i jed\n\n* `#! --> nå kommer et script`\n* `/bin/bash --> skal tolkes av /bin/bash`\n* Rettigheter må settes slik at filen er kjørbar (x)\n\n```\n[os]studssh:~$ script.sh\n-bash: ./script.sh: Permission denied\n\n[os]studssh:~$ ls -l script.sh\n-rw-r--r-- 1 os student 37 2010-01-06 20:23 script.sh\n\n [os]studssh:~$ chmod 700 script.sh\n\n[os]studssh:~$ ls -l script.sh\n-rwx------ 1 os student 37 2010-01-06 20:23 script.sh\n\n [os]studssh:~$ script.sh\n Linux studssh 2.6.24-26-generic #1 SMP Tue Dec 1 18:37:31 UTC 2009 i686 GNU/Linux\ntmp\n/iu/cube/u4/os/mappe\ntotal 4\ndrwxr-xr-x 2 os student 4096 2010-01-04 12:11 tmp\n\n [os]studssh:~$\n```"}
{"identifier": "linux1.12", "section_id": "1.12", "section_title": "Filbehandling (Viktig!)", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION000212000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.12 Filbehandling (Viktig!)\n\n\"Alt\" i Linux er filer; *vanligvis ASCII-filer.*\n\n| Linux-kommando | resultat |\n|--------------|--------|\n| $ ls | lister filer/mapper i mappen der du står |\n| $ ls -l | ekstra info |\n| $ ls -a | lister “skjulte” filer (.fil) |\n| $ ls /etc | lister alt i /etc |\n| $ mkdir mappe | lager en mappe |\n| $ cat fil1 | skriv innhold til skjermen |\n| $ touch fil2 | lag en tom fil med navn “fil2”/oppdaterer tidsstempel hvis den fins |\n| $ jed fil3.txt | editer en fil med navn fil3.txt. Rask og effektiv editor som også kan brukes fra putty. |\n| $ emacs fil4.txt | editer en fil med navn fil4.txt. Mer omfattende GUI-editor. |\n| $ cp fil1 fil2 | kopierer fil1 til fil2 |\n| $ cp -i fil1 fil2 | Spørr om fil2 skal overskrives |\n| $ mv fil1 fil2 | Endrer navn fra fil1 til fil2 |\n| $ mv fil2 /tmp | Flytter fil2 til /tmp |"}
{"identifier": "linux1.13", "section_id": "1.13", "section_title": "Spesielle mapper", "source_category": "linux", "source_id": "1", "source_title": "Linux-shell, Linux-filsystem", "anchor": "SECTION000213000000000000000", "source": "os/Forelesning/linux/node2.html", "text": "## 1.13 Spesielle mapper\n\n| betegnelse | Mappe |\n|----------|-----|\n| . | den du står i |\n| .. | den over |\n| ../.. | den over den igjen |\n| ~ | Din hjemmemappe |\n\nBruk av ~:\n\n```\n$ echo ~\n/iu/nexus/ud/haugerud\n$ cat ~/.bashrc  (skriver din .bashrc til skjermen.)\n$ echo ~haugerud\n/iu/nexus/ud/haugerud\n$ cd ~/www       {# gå til din hjemmesidemappe.}\n```"}
{"identifier": "linux11.1", "section_id": "11.1", "section_title": "Windows PowerShell", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION000121000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.1 Windows PowerShell\n\nWindows PowerShell er, som bash for Linux, både kommandolinje og scriptspråk for Windows og ble innført av Microsoft i 2006. Fra og med Windows 2008 Server og Windows 7 har PowerShell vært installert som default. Det finnes en rekke aliaser som gjør at man kommer veldig langt med å skrive vanlige bash kommandoer.\n\nDet finnes fire kategorier kommandoer i PowerShell:\n\n|   |   |\n|---|---|\n| Cmdlets | Tilsvarer bash shell builtins som pwd og echo (og er en del av shellet). De fleste kommandoer er Cmdlets. |\n| Applications | Eksisterende Windowsprogrammer som ping og ipconfig. (tilsvarer /bin/mv) |\n| Scripts | Tekstfiler med endelse .ps1 (også for PS versjon 2 og høyere), tilsvarer bash-script |\n| Functions | Tilsvarer funksjoner i bash |\n\nOperativsystemet Windows er i utgangspunktet objektorientert og konfigurasjonen er ikke basert på tekstfiler som i Linux, men på binære filer og databaser. Derfor må et kraftig Windows shell også være objektorientert og det er PowerShell. Som bash er PowerShell bygd opp av mange små programmer eller Cmdlets som gir en fleksibel måte å løse oppgaver på. Under Linux har vi sett at disse kommandoene kan settes sammen med pipes og omdirigering og det er da tekst som streames mellom kommandoene. PowerShell tar dette ett steg videre og sender hele objekter mellom Cmdlets med pipes."}
{"identifier": "linux11.1.1", "section_id": "11.1.1", "section_title": "Verdens korteste Hello World program", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION000121100000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.1.1 Verdens korteste Hello World program\n\nHvis du har problemer med keyboard-tegn og norsk tastatur, kan du velge Settings Time & Language Region & Language norsk options og så legge til US keyboard. Så kan du switche mellom keyboard med Windows-tasten og space.\n\n```\n\"Hello World!\"\n```\n\nLagrer man dette som en fil med for eksempel navnet `hello.ps1` har man laget verdens korteste Hello World program. PowerShell script må ha filendelse `ps1` . Det gjelder også for versjon 2 av PowerShell. Med tanke på script som lastes ned av virus og ormer er det i utgangspunktet ikke lov å kjøre script i det hele tatt fra PowerShell. Men hvis du setter\n\n```\nPS> set-executionPolicy remoteSigned\n```\n\nvil du kunne kjøre egne script. Men dette får du bare lov til å gjøre hvis du kjører PowerShell med \"elevated privileges\", det vil si som administrator. Det kan du få til ved å trykke Windows-tasten, skrive \"PowerShell\" og så høyreklikke og velge \"Run as administrator\".\n\nHvis PowerShell scriptet åpner et nytt vindu som umiddelbart forsvinner, slik at du ikke ser \"Hello World!\"-teksten, kan du finne noen mulige løsninger her: [powershell-window-disappears](https://stackoverflow.com/questions/1337229/powershell-window-disappears-before-i-can-read-the-error-message) ."}
{"identifier": "linux11.2", "section_id": "11.2", "section_title": "To viktige kommandoer", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION000122000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.2 To viktige kommandoer\n\nDe kanskje to viktigste kommandoene i powershell er de som gir deg hjelp: \"Get-Command\" gir liste over alle kommandoer og \"Get-Help kommando\" gir informasjon om kommandoene. Disse kan sammenliknes med \"man\" og \"help\" i bash.\n\n```\nGet-Command\n\nCommandType     Name                                               Version    Source            \n-----------     ----                                               -------    ------            \nAlias           Add-ProvisionedAppxPackage                         3.0        Dism              \nAlias           Apply-WindowsUnattend                              3.0        Dism              \nAlias           Disable-PhysicalDiskIndication                     2.0.0.0    Storage           \nFunction        A:                                                                              \nFunction        Add-BCDataCacheExtension                           1.0.0.0    BranchCache       \nFunction        Add-BitLockerKeyProtector                          1.0.0.0    BitLocker         \nCmdlet          Read-Host                                          3.1.0.0    Microsoft.Power...\nCmdlet          Receive-DtcDiagnosticTransaction                   1.0.0.0    MsDtc             \n...\n```\n\nUten argument listes alle kommandoene\n\n```\nGet-Command ls\n\nCommandType     Name                                               Version    Sourc\n                                                                              e    \n-----------     ----                                               -------    -----\nAlias           ls -> Get-ChildItem                                                \n\nCommandType     Name                            Definition\n-----------     ----                            ----------\nAlias           ls                              Get-ChildItem\n```\n\nMed kommando som argument listes informasjon om kommandoen.\n\n```\nGet-Help Get-ChildItem\n\nNAME\n    Get-ChildItem\n\nSYNOPSIS\n    Gets the items and child items in one or more specified locations.\n\nSYNTAX\n    Get-ChildItem [[-Path] <string[]>] [[-Filter] <string>] [-Exclude <string[]\n...\n```\n\nFor å få informasjon om alle kommandoer, må du først kjøre Update-Help som Administrator."}
{"identifier": "linux11.3", "section_id": "11.3", "section_title": "Likheter med bash", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION000123000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.3 Likheter med bash\n\nDet er definert en rekke alias som gjør at mange av de kjente bash-kommandoene kan brukes direkte i powershell. Dette gjør at en del bash-script lett kan oversettes. Her er noen av de vanligste, kommandoen `alias` gir alle som er definert:\n\n```\nset-alias cat        get-content\nset-alias cd         set-location\nset-alias cp         copy-item\nset-alias history    get-history\nset-alias kill       stop-process\nset-alias ls         get-childitem\nset-alias mv         move-item\nset-alias ps         get-process\nset-alias pwd        get-location\nset-alias rm         remove-item\nset-alias rmdir      remove-item\nset-alias echo       write-output\n```"}
{"identifier": "linux11.3.1", "section_id": "11.3.1", "section_title": "Omdirigering", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION000123100000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.3.1 Omdirigering\n\nOmdirigering og pipes virker på samme måte som i bash. For eksempel er\n\n```\nPS> ls | sort > fil.txt\n```\n\nen gyldig powershell-kommando. Vanlig output og feilmeldinger er også delt på samme måte, slik at følgende virker som i bash:\n\n| omdirigering | virkning |\n|------------|--------|\n| > fil.txt | omdirigerer stdout til fil.txt. Overskriver |\n| >> fil.txt | legger stdout etter siste linje i fil.txt |\n| Write-Error \"oops\" 2> $null | sender stderr til \"/dev/null\" |\n| > fil.txt 2> err.txt | stdout -> fil.txt stderr -> err.txt |\n\nMen som vi skal se senere er det ikke tekst som streames mellom Cmdlets, men hele objekter!"}
{"identifier": "linux11.4", "section_id": "11.4", "section_title": "Variabler", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION000124000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.4 Variabler\n\nVariabler lages som i PHP ved å sette et $-tegn foran navnet:\n\n```\nPS > $var = \"min nye var\"\nPS > echo $var\nmin nye var\nPS > $var\nmin nye var\n```\n\nSlike variabler er lokale. PowerShell er ikke så nøye på mellorom som bash, men teksstrenger må skrives innenfor apostrofer. Legg merke til at echo er overfløding, en tekststreng blir skrevet ut selvom du ikke skriver echo først.\n\nCmdlet'en Get-Variable (kan forkortes til gv) viser hvilke variabler som er definert, følgende viser et utdrag:\n\n```\nPS > Get-Variable\n\nName                           Value\n----                           -----\nMaximumErrorCount              256\nMaximumVariableCount           4096\nMaximumFunctionCount           4096\nMaximumAliasCount              4096\nnull\nfalse                          False\ntrue                           True\nPWD                            C:\\Documents and Settings\\group10\\My Documents\\ps\nMaximumHistoryCount            4000\nHOME                           C:\\Documents and Settings\\group10\nPSVersionTable                 {CLRVersion, BuildVersion, PSVersion, PSCompatible...\nPID                            3976\nCulture                        nb-NO\nShellId                        Microsoft.PowerShell\nPSHOME                         C:\\WINDOWS\\system32\\WindowsPowerShell\\v1.0\\\nErrorView                      NormalView\nNestedPromptLevel              0\nOutputEncoding                 System.Text.ASCIIEncoding\nCommandLineParameters          {}\nargs                           {}\nPROFILE                        C:\\Documents and Settings\\group10\\My Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1\nvar                            min nye var\ndir                            mappe\n```"}
{"identifier": "linux11.5", "section_id": "11.5", "section_title": "Environmentvariabler", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION000125000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.5 Environmentvariabler\n\nI tillegg finnes det et sett med environmentvariabler i namespace'et env: som kan listes ut med ls:\n\n```\nPS > ls env:\nName                           Value\n----                           -----\nPath                           C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32...\nTEMP                           C:\\DOCUME~1\\group10\\LOCALS~1\\Temp\nPATHEXT                        .COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;....\nUSERDOMAIN                     IU-VM\nPROCESSOR_ARCHITECTURE         x86\nSystemDrive                    C:\nAPPDATA                        C:\\Documents and Settings\\group10\\Application Data\nwindir                         C:\\WINDOWS\nTMP                            C:\\DOCUME~1\\group10\\LOCALS~1\\Temp\nUSERPROFILE                    C:\\Documents and Settings\\group10\nProgramFiles                   C:\\Program Files\nHOMEPATH                       \\Documents and Settings\\group10\nCOMPUTERNAME                   IU-VM\nUSERNAME                       group10\nNUMBER_OF_PROCESSORS           1\nPROCESSOR_IDENTIFIER           x86 Family 16 Model 4 Stepping 2, AuthenticAMD\nSystemRoot                     C:\\WINDOWS\nComSpec                        C:\\WINDOWS\\system32\\cmd.exe\nLOGONSERVER                    \\\\IU-VM\nALLUSERSPROFILE                C:\\Documents and Settings\\All Users\nOS                             Windows_NT\nHOMEDRIVE                      C:\n```\n\nDette betyr at det for eksempel finnes en variabel $env:path\n\n```\nPS > $env:path\nC:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\system32\\WindowsP\nowerShell\\v1.0\\;C:\\Program Files\\OpenSSH\\bin;C:\\lcc\\bin\n```\n\nLegg merket til at variabler og cmdlets ikke er case-sensitive som de er i bash. Tilsvarende kan man liste funksjoner og aliaser med `ls function:` og `ls alias:`\n\n```\nPS > $alias:pwd\nMicrosoft.PowerShell.Management\\Get-Location\nPS > & $alias:pwd\n\nPath\n----\nC:\\Documents and Settings\\group10\\My Documents\\ps\n```\n\nHer ser vi at en & i starten av en linje gjør at innholdet av en streng kjøres. Nyttig om man må ha apostrofer rundt en path fordi den inneholder mellomrom."}
{"identifier": "linux11.6", "section_id": "11.6", "section_title": "Apostrofer", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION000126000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.6 Apostrofer\n\nApostrofer virker stort sett som i bash:\n\n```\nPS> $dir=\"mappe\"\n\nPS>  echo 'ls $dir'     #    ' -> Gir eksakt tekststreng\nls $dir\n\nPS>  echo \"ls $dir\"     #    \" -> Variabler substitueres; verdien av $dir skrives ut.\nls mappe\n\nPS> echo \"Filer: $(ls $dir)\"        #  utfører kommandoen \\verb+ls mappe+ inne i strengen\nfil fil2.txt\n```"}
{"identifier": "linux11.7", "section_id": "11.7", "section_title": "Objekter og Get-Member", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION000127000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.7 Objekter og Get-Member\n\nDet som virkelig gir ”Power” i PowerShell er at hele objekter sendes mellom Cmdlets. Dette gjør det veldig intuitivt og enkelt å trekke ut informasjon fra for eksempel lister av prosesser og filer. Og det geniale er at det kan gjøres på mer eller mindre samme måte uansett hvilke objekter vi ser på, objektene har bare litt andre egenskaper og metoder.\n\nFor eksempel returnerer en listing av filene i en mappe\n\n```\nPS > ls\nMode                LastWriteTime     Length Name\n----                -------------     ------ ----\nd----        02.03.2010     20:38            mappe\n-a---        01.03.2010     12:26         73 ps.ps1\n```\n\nikke bare tekst som viser filene i mappen slik som i bash. Egentlig returneres et array av objekter, ett for hver fil eller mappe. Om man ønsker kun et objekt for filen `ps.ps1` , kan man slik legge det i variabelen `$fil` :\n\n```\nPS > $fil = ls ps.ps1\n```\n\nHvis man på kommandolinjen nå skriver `$fil.` kan man tabbe seg gjennom alle metoder og properties for dette objektet. En måte å vise alle på en gang, er å sende objektet til cmdlet'en `Get-Member` :\n\n```\nPS > $fil | Get-Member\n\n   TypeName: System.IO.FileInfo\n\nName                      MemberType     Definition\n----                      ----------     ----------\nMode                   CodeProperty System.String Mode{get=Mode;}\nAppendText         Method          System.IO.StreamWriter AppendText()\nDelete                  Method          System.Void Delete()\nPSPath                NoteProperty System.String PSPath=Microsoft.PowerShel...\nCreationTime       Property        System.DateTime CreationTime {get;set;}\nDirectoryNam      Property        System.String DirectoryName {get;}\nExtension             Property        System.String Extension {get;}\nFullNa                 Property         System.String FullName {get;}\nIsReadOnly          Property         System.Boolean IsReadOnly {get;set;}\nLastAccessTime  Property         System.DateTime LastAccessTime {get;set;}\nLastWriteTime    Property         System.DateTime LastWriteTime {get;set;}\nLength                 Property         System.Int64 Length {get;}\nName                   Propertty        System.String Name {get;}\n```\n\nBare et lite utvalg er vist over. Dermed kan man for eksempel få tak i tidspunktet filen sist ble aksessert, lest eller sett på:\n\n```\nPS > $fil.LastAccessTime\n1. mars 2010 12:26:50\n```\n\nDette tidspunktet er også et objekt, et System.DateTime objekt. På samme måte kan dette objektet tilordnes en variabel\n\n```\nPS > $date = $fil.LastAccessTime\n```\n\nOg denne kan vi lese ut metoder og egenskaper fra med `Get-Member` :\n\n```\nPS > $date | Get-Member\n   TypeName: System.DateTime\n\nName                 MemberType     Definition\n----                 ----------     ----------\nAddHours             Method         System.DateTime AddHours(Double value)\nIsDaylightSavingTime Method         System.Boolean IsDaylightSavingTime()\nToLongDateString     Method         System.String ToLongDateString()\nToLongTimeString     Method         System.String ToLongTimeString()\nDayOfWeek            Property       System.DayOfWeek DayOfWeek {get;}\nDayOfYear            Property       System.Int32 DayOfYear {get;}\nHour                 Property       System.Int32 Hour {get;}\nMillisecond          Property       System.Int32 Millisecond {get;}\nMinute               Property       System.Int32 Minute {get;}\nMonth                Property       System.Int32 Month {get;}\nSecond               Property       System.Int32 Second {get;}\nTimeOfDay            Property       System.TimeSpan TimeOfDay {get;}\nYear                 Property       System.Int32 Year {get;}\n```\n\nIgjen er bare et lite utvalg vist. Dermed kan man trekke ut disse egenskapene, for eksempel året:\n\n```\nPS > $date.year\n2010\n```\n\nDet er også mulig å gjøre dette direkte uten å gå veien om et dato-objekt:\n\n```\nPS > $fil.LastAccessTime.year\n2010\n```\n\nMan kan til og med trekke det ut direkte fra kommandoen som listet filen:\n\n```\nPS > (ls ps.ps1).LastAccessTime.year\n2010\n```"}
{"identifier": "linux11.8", "section_id": "11.8", "section_title": "Undersøke typen til et objekt", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION000128000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.8 Undersøke typen til et objekt\n\nMed get-member vil vi få listet opp alle egenskaper (properties) og metoder som er tilgjengelige på det aktuelle objektet. Dette er viktig informasjon, fordi det forteller oss hva vi kan gjøre med objektene.\n\n```\nPS C:\\> ls | get-member\n\n   TypeName: System.IO.FileInfo\n\nName                      MemberType     Definition\n----                      ----------     ----------\n...\nLength                    Property       System.Int64 Length {get;}\nName                      Property       System.String Name {get;}\n...\n```\n\nØverst ser vi at typen til det som returneres fra ls er `System.IO.FileInfo` . Men vi ser bare typen til det siste elementet på denne måten. Kommandoen ls returnerer altså et array av FileInfo-objekter. Dette kan vi se ved å kalle metoden `GetType()` på returverdien slik:\n\n```\nPS C:\\> (ls).getType()\n\nIsPublic IsSerial Name                                     BaseType\n-------- -------- ----                                     --------\nTrue     True     Object[]                                 System.Array\n```\n\nFor mer informasjon om de ulike typene, kan man søke dem opp på Microsofts dokumentasjonssider, https://msdn.microsoft.com/. Søker man for eksempel etter `System.Array` får man som første treff `Array Class` . Her finner du definisjonen av klassen og kodeeksempler i flere språk.\n\nOm man kaller metoden getType for ett av elementene får man vite hva slags type dette er:\n\n```\nPS C:\\> (ls)[1].getType()\n\nIsPublic IsSerial Name                                     BaseType\n-------- -------- ----                                     --------\nTrue     True     FileInfo                                 System.IO.FileSystemInfo\n```"}
{"identifier": "linux11.9", "section_id": "11.9", "section_title": "ps", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION000129000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.9 ps\n\nNår man istedet for å liste filer med ls lister prosesser med ps, gir dette også objekter.\n\n```\nPS > ps\nHandles  NPM(K)    PM(K)      WS(K) VM(M)   CPU(s)     Id ProcessName\n-------  ------    -----      ----- -----   ------     -- -----------\n    194          6         3276           6012      49         1,20        4936  Adobe_Updater\n    102          5         1156            360      32          0,28       1264   alg\n    320          5         1528            908      22         1,28        696     csrss\n```\n\nDet som returneres fra ps er et array av prosessobjekter der første element er første prosess i listingen:\n\n```\nPS > $ps = ps\nPS > $ps[0].name\nAdobe_Updater\nPS > $ps[0].id\n4936\nPS > $ps[1].name\nalg\n```\n\nLengden av dette arrayet vil da gi antall prosesser på maskinen:\n\n```\nPS > $ps.length\n44\n```"}
{"identifier": "linux11.10", "section_id": "11.10", "section_title": "Foreach", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION0001210000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.10 Foreach\n\nDet er først når man bruker mulighetene objektorienteringen gir i script at PowerShell virkelig viser sin styrke:\n\n```\nforeach ($ls in ls *.ps1){\n    $sum += $ls.length\n}\n$sum\n```\n\neller i onelinere som dette:\n\n```\nls | ForEach-Object {$sum += $_.Length}\n```\n\nDisse mulighetene vil bli utdypet i senere avsnitt."}
{"identifier": "linux11.11", "section_id": "11.11", "section_title": "Installasjon av programmer fra PowerShell", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION0001211000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.11 Installasjon av programmer fra PowerShell\n\nPå samme måte som man installerer programmer i et Linux shell med apt-get, kan man installere programmer i PowerShell med Chocolatey; eller bare choco som kommandoen heter. Da må man først installere choco og det kan i PowerShell gjøres med:\n\n```\nwget -OutFile install.ps1 http://chocolatey.org/install.ps1\n```\n\nhvor `wget` er et alias for `Invoke-WebRequest` og virker på omtrent samme måte som i Linux. Etter å ha kjørt dette installasjons-scriptet, kan man installere annen programvare som ssh og scp med:\n\n```\nPS C:\\> choco install openssh\n```\n\nog deretter bruke det fra PowerShell på samme måte som man bruker det fra bash i Linux."}
{"identifier": "linux11.12", "section_id": "11.12", "section_title": "Select-String, PowerShells svar på grep", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION0001212000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.12 Select-String, PowerShells svar på grep\n\nFor å gå igjennom et array av objekter, som for eksemple alle prosessene som listes med ps, er foreach en meget nyttig konstruksjon. Allikevel er det viktig å sjekke hva mer man kan gjøre med kommandoen ps, før man overkompliserer oppgaven. I bash bruker vi kommandoen\n\n```\n$ ps | grep power\n```\n\nfor å finne alle prosesser med \"power\" i navnet. Vi har en funksjon i powershell som likner på grep, nemlig `select-string` eller kortversjonen `sls` . Men kommandoen `ps | select-string power` returnerer ikke helt det vi ønsker. Grunnen til dette er at kommandoen `ps` , i PowerShell, returnerer et array av objekter, og ikke en tekst. For å gjøre tilsvarende søk i PowerShell skriver man heller følgenede:\n\n```\n$ ps power*\n\nHandles  NPM(K)    PM(K)      WS(K) VM(M)   CPU(s)     Id ProcessName\n-------  ------    -----      ----- -----   ------     -- -----------\n     48       2      764       2696    28     0,05   2752 poweroff\n    257       5    28968      28196   135     0,47   5412 powershell\n```\n\nHer sender vi ordet power, med wildcardet *, til kommandoen ps, som er et alias for kommandoen get-process. Sjekk dette ved å skrive `get-command ps` . For detaljert informasjon om hva du kan gjøre med get-process, skriv `get-help get-process -detailed`\n\nFra Linux er vi vant til å velge ut linjer som inneholder et gitt ord med kommandoen `grep` . Det finnes ikke en helt tilsvarende PowerShell-kommando og ofte bruker man andre metoder for å oppnå det samme. Men det er mulig å bruke CmdLet'en `Select-String` som ligner:\n\n```\nls | Select-String fil\n```\n\ner et forsøk på å velge alle linjer som inneholder ordet `fil` i ls-listingen. Men Select-String virker på objekter og går derfor inn i mapper i listingen og det virker ikke helt som ønsket. Ved å pipe output fra ls til Out-String gjøres objekt-strømmen om til vanlige strenger og man får det til å virke som i bash:\n\n```\nls | Out-String -Stream | Select-String fil\n```\n\nMan må også ha med opsjonen `-Stream` til `Out-String` for at det skal virke."}
{"identifier": "linux11.13", "section_id": "11.13", "section_title": "Logiske operatorer", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION0001213000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.13 Logiske operatorer\n\n| Operator | Betydning |\n|--------|---------|\n| -lt | Less than |\n| -gt | Greater than |\n| -le | Less than or equal to |\n| -ge | Greater than or equal to |\n| -eq | Equal to |\n| -ne | Not equal to |\n\n| Operator | Betydning |\n|--------|---------|\n| -not | Not |\n| ! | Not |\n| -and | And |\n| -or | Or |\n\nMerk at i powershell kan vi bruke logiske operatorer rett i shellet. I bash vil `2 -lt 3` ikke returnere noen ting, fordi det er exit-verdien av denne kommandoen som indikerer om testen slo til eller ikke. I powershell er dette litt enklere:\n\n```\nPS > 2 -eq 3\nFalse\nPS > 2 -lt 3\nTrue\nPS > \"hei\" -eq \"hei\"\nTrue\nPS > -not (\"hei\" -eq \"heia\")\nTrue\n```"}
{"identifier": "linux11.14", "section_id": "11.14", "section_title": "Windows script editor", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION0001214000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.14 Windows script editor\n\nEn mulighet er å bruke Windows PowerShell ISE til å skrive PowerShell script. Da kan man få opp ett PowerShell vindu samtidig med et editor-vindu og kjøre scriptet ved å taste F5. Det finnes også mange generelle tekst-editorer for Windows som stort sett er GUI-baserte.\n\nEn annen mulighet er å installere `nano` med `choco install nano` og deretter bruke `nano` fra kommandolinjen slik som i et Linux shell."}
{"identifier": "linux11.15", "section_id": "11.15", "section_title": "Summere antall bytes i filer", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION0001215000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.15 Summere antall bytes i filer\n\nOutput fra PowerShell CmdLets er som vi har sett ikke bare tekst som i et bash-shell, men objekter. Dermed kan man ved hjelp av `foreach` gå igjennom alle objektene og trekke ut den informasjon man trenger:\n\n```\nforeach ($ls in ls *.ps1){\n    $sum += $ls.length\n}\n$sum\n```\n\nForeach er et alias for ForEach-Object, men når det står i starten av en setning, er det et PowerShell statement eller reservert ord, slik som if og for. Summasjon som inkluderer filer i alle undermapper får man med opsjonen -r til ls:\n\n```\nforeach ($ls in ls -r){\n    if($ls.Extension -eq \".ps1\"){\n\t$sum += $ls.length\n    }\n}\n```\n\nEgentlig er `ls -r` et alias for `Get-ChildItem -Recurse` ."}
{"identifier": "linux11.16", "section_id": "11.16", "section_title": "Stoppe prosesser med et gitt navn: nkill.ps1", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION0001216000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.16 Stoppe prosesser med et gitt navn: nkill.ps1\n\nEn stor fordel med at kommandoene gir objekter er at man kan bruke de samme metodene på mange forskjellige typer kommandoer, for eksempel på `ps` som er et alias for `Get-Process` :\n\n```\n$s = $args[0] # Første argument\n\nforeach ($p in ps ){\n   foreach ($name in $args){\n      if ($p.name -eq $name){\n         kill -whatif $p.id\n      }\n   }\n}\n```\n\nOpsjonen `-whatif` til `kill` er nyttig for å teste ut hva som kommer til å skje hvis man kjører scriptet. Når scriptet virker som det skal, kan man fjerne `-whatif` . En tilsvarende oneliner kan lages slik:\n\n```\nps | foreach {\tif($_.name -eq \"navn\"){kill $_.id -whatif}}\n```"}
{"identifier": "linux11.17", "section_id": "11.17", "section_title": "PowerShell oneliner", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION0001217000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.17 PowerShell oneliner\n\nOfte kan man lage tilsvarende kraftige konstruksjoner med bare en enkelt kommandolinje, såkalte oneliners. For å gjøre det bruker man konstruksjoner som `ForEach-Object` og `Where-Object` og lage en indre løkke hvor hvert objekt behandles. Inne i en slik løkke vil den spesielle variabelen `$_` være en peker til objektet som er under behandling. Hele scriptet ovenfor kan lages som en oneliner slik:\n\n```\nls | ForEach-Object {$sum += $_.Length}\n```\n\nMen man må på kommandolinjen passe på at variabelen nullstilles og hvis man i tillegg ønsker å skrive ut svaret kan man akkurat som i bash adskille kommandoer med semikolon:\n\n```\n$sum = 0; ls | ForEach-Object {$sum += $_.Length };$sum\n```\n\nMed Where-Object kan man velge ut objekter med spesielle egenskaper. For eksempel kan man plukke ut mapper fra en listing av filer og mapper på følgende måte:\n\n```\nls | Where-Object  {$_.PSIsCointainer}\n```\n\nfor `PSIsCointainer` er en TRUE/FALSE property som bare er sann for mapper. Where-Object kan kombineres med forEach-Object:\n\n```\n$sum = 0; ls | Where-Object  {$_.extension -eq \".txt\"} | ForEach-Object {$sum += $_.Length };$sum\n```\n\nsom legger sammen Length kun for filer med extension .txt."}
{"identifier": "linux11.18", "section_id": "11.18", "section_title": "Sort-Object og Select-Object", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION0001218000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.18 Sort-Object og Select-Object\n\nMed disse to CmdLets kan man sortere og velge ut objekter. For eksempel vil følgende oneliner sortere filer etter lengde, med de største først (descending) og deretter plukke ut de fire første:\n\n```\nls | Sort-Object Length -des | Select-Object -First 4\n```"}
{"identifier": "linux11.19", "section_id": "11.19", "section_title": "DateTime", "source_category": "linux", "source_id": "11", "source_title": "Windows PowerShell", "anchor": "SECTION0001219000000000000000", "source": "os/Forelesning/linux/node12.html", "text": "## 11.19 DateTime\n\n`DateTime` er en CmdLet som uten argumenter gir et objekt som inneholder dato og klokkeslett (DateTime) akkurat nå:\n\n```\nPS C:\\> Get-Date\nsøndag 19. mars 2017 19.41.59\n```\n\nMan kan også lage DateTime objekter for et vilkårlig tidspunkt:\n\n```\nPS C:\\> Get-Date -Year 2016 -Month 5 -Day 17  -Hour 17 -Minute 30 -Second 00\ntirsdag 17. mai 2016 17.30.00\n\nPS C:\\> Get-Date \"17/5 2007 17:30\"\ntorsdag 17. mai 2007 17.30.00\n\nPS C:\\> Get-Date \"17 May 2007 17:30\"\ntorsdag 17. mai 2007 17.30.00\n```\n\nMed utgangspunkt i en variabel som inneholder et DateTime-objekt, kan man med `Get-Member` finne egenskaper og metoder objektet har og for eksempel bruke det til å lage en ny variabel ett døgn tilbake i tid.\n\n```\nPS C:\\> $now = Get-Date\nPS C:\\> $now\n\nsøndag 19. mars 2017 19.44.26\n\nPS C:\\> $now | Get-Member\n\n   TypeName: System.DateTime\n\nName                 MemberType     Definition\n----                 ----------     ----------\nAdd                  Method         datetime Add(timespan value)\nAddDays              Method         datetime AddDays(double value)\nAddHours             Method         datetime AddHours(double value)\n\nPS C:\\> $yesterday = $now.AddDays(-1)\nPS C:\\> $yesterday\n\nlørdag 18. mars 2017 19.44.26\n```\n\nAnta at du husker at du har laget eller endret noen filer på mandag 13 mars, men ikke husker hvor de ligger. Da kan man først lage et par DateTime variabler tidlig på dagen og sent på kvelden:\n\n```\nPS C:\\> $mm = Get-Date \"13/3 2017 08:00\" # Mandag morgen\nPS C:\\> $mk = Get-Date \"13/3 2017 22:00\" # Mandag kveld\nPS C:\\> $mm.DayOfWeek\nMonday\n```\n\nDen siste kommandoen dobbeltsjekker at den 13 var en mandag. Deretter kan man lage en oneliner som lister alle filer som har `LastWriteTime` i dette tidsrommet:\n\n```\nPS C:\\Users\\haugerud> ls -r | Where-Object {$_.LastWriteTime -gt $mm -and $_.LastWriteTime -lt $mk}\n\n    Directory: C:\\Users\\haugerud\n\nMode                LastWriteTime         Length Name\n----                -------------         ------ ----\nd-----       13.03.2017     17.05                .ssh\nd-----       13.03.2017     18.28                mappe\n-a----       13.03.2017     19.00              0 file6.txt\n-a----       13.03.2017     10.38          13074 history13.03.2017\n\n    Directory: C:\\Users\\haugerud\\.ssh\n\nMode                LastWriteTime         Length Name\n----                -------------         ------ ----\n-a----       13.03.2017     17.05            189 known_hosts\n\n    Directory: C:\\Users\\haugerud\\mappe\n\nMode                LastWriteTime         Length Name\n----                -------------         ------ ----\n-a----       13.03.2017     09.05            146 hello.ps1\n-a----       13.03.2017     18.36             64 loop.ps1\n-a----       13.03.2017     18.25            307 nkill.ps1\n```\n\nHvis man sender output til `Format-Table` blir det litt ryddigere og man kan velge hvilke felt man ønsker å ha med:\n\n```\nls -r | Where-Object {$_.LastWriteTime -gt $mm -and $_.LastWriteTime -lt $mk} | Format-Table LastWriteTime,fullName\n\nLastWriteTime       FullName\n-------------       --------\n13.03.2017 17.05.18 C:\\Users\\haugerud\\.ssh\n13.03.2017 18.28.23 C:\\Users\\haugerud\\mappe\n13.03.2017 19.00.45 C:\\Users\\haugerud\\file6.txt\n13.03.2017 10.38.02 C:\\Users\\haugerud\\history13.03.2017\n13.03.2017 17.05.18 C:\\Users\\haugerud\\.ssh\\known_hosts\n13.03.2017 09.05.03 C:\\Users\\haugerud\\mappe\\hello.ps1\n13.03.2017 18.36.16 C:\\Users\\haugerud\\mappe\\loop.ps1\n13.03.2017 18.25.18 C:\\Users\\haugerud\\mappe\\nkill.ps1\n```\n\nHvis man ønsker en sortert liste på tidspunktet, må man sende objektene til sort (alias for Sort-Objekt) før man sender det til Format-Table:\n\n```\nls -r | Where-Object {$_.LastWriteTime -gt $mm -and $_.LastWriteTime -lt $mk} | sort LastWriteTime | Format-Table LastWriteTime,fullName\n\nLastWriteTime       FullName\n-------------       --------\n13.03.2017 09.05.03 C:\\Users\\haugerud\\mappe\\hello.ps1\n13.03.2017 10.38.02 C:\\Users\\haugerud\\history13.03.2017\n13.03.2017 17.05.18 C:\\Users\\haugerud\\.ssh\n13.03.2017 17.05.18 C:\\Users\\haugerud\\.ssh\\known_hosts\n13.03.2017 18.25.18 C:\\Users\\haugerud\\mappe\\nkill.ps1\n13.03.2017 18.28.23 C:\\Users\\haugerud\\mappe\n13.03.2017 18.36.16 C:\\Users\\haugerud\\mappe\\loop.ps1\n13.03.2017 19.00.45 C:\\Users\\haugerud\\file6.txt\n```"}
{"identifier": "os8.1.2", "section_id": "8.1.2", "section_title": "Vaffel-video", "source_category": "os", "source_id": "8", "source_title": "Systemkall, Scheduling og vaffelrøre", "anchor": "SECTION00091200000000000000", "source": "os/Forelesning/os/node9.html", "text": "## 8.1.2 Vaffel-video\n\n[Video som demonstrerer multitasking av forelesning og vaffelrørelaging](https://os.cs.oslomet.no/os/vaffel.mp4)"}
{"identifier": "os8.3", "section_id": "8.3", "section_title": "Hvorfor kan ikke en prosess bruke to CPU-er?", "source_category": "os", "source_id": "8", "source_title": "Systemkall, Scheduling og vaffelrøre", "anchor": "SECTION00093000000000000000", "source": "os/Forelesning/os/node9.html", "text": "## 8.3 Hvorfor kan ikke en prosess bruke to CPU-er?\n\nDet ville vært ønskelig om et vilkårlig program kjøres fire ganger så raskt på en maskin med en quadcore prosessor(4 CPU'er på en brikke) som på en maskin med en enkelt CPU av samme type. Men det gjør generelt et program ikke, det bruker like lang tid om det har fire prosessorer, for det klarer bare å utnytte en prosessor av gangen. Slik at man bare får en gevinst av de fire prosessorene om man har flere programmer som kjører samtidig.\n\nFor å undersøke hvorfor det er slik, ser vi på assemblerkoden for et program som regner ut Fibonacci-rekken, 1 1 2 3 5 8 13 21 34 55 ..... I denne rekken er neste tall summen av de to foregående. Assemblerkode ligger tett opp til maskinkode, det er en litt mer lesbar utgave av maskininstruksjoner og kan sees på som den koden som CPU-en utfører en for en:\n\n```\n1. mov 1, %ax    # %ax = 1\n2. mov 1, %bx    # %bx = 1\n3. add %ax, %bx  # %bx = %bx + %ax\n4. add %bx, %ax  # %ax = %ax + %bx\n5. jmp 3\n```\n\nEtter hver runde i denne evige løkken, vil ax og bx være siste og nest siste ledd i Fibonacci-rekken som er regnet ut. I instruksjon 3 settes bx lik summen av de to og i nummer 4 settes ax lik summen av de to og dermed har vi kommet to stepp videre i beregningen. Vi ser at det ikke er mulig for et operativsystem å fordele bergningene i en slik algoritme på flere CPU'er. Neste ledd i beregningen avhenger av det forrige og det tar uforholdsmessig lang tid å flytte verdier av registre fra en CPU til en annen. I dette tilfellet lar ikke algoritmen seg naturlig dele opp i separate bergningsdeler og da vil det også være vanskelig for en programmerer å dele opp beregningen i flere prosesser for å utnytte flere prosessorer. Følgende eksempel som regner ut summen er det i prinsippet letter å dele opp eller parallellisere som det kalles:\n\n```\n1. mov 2001, %ax\n2. mov 1, %bx\n3. mov 0, %cx\n3. add %bx, %cx   # %cx += %bx\n4. inc %bx        # %bx++\n5. cmp %bx %ax    \n6. jne 3          # Hopp til linje 3 hvis %bx ikke er lik 2001\n```\n\nEtter dette programmet er avsluttet vil registreret cx være lik . Det er lett å se at denne algoritmen i prinsippet kan deles i to. En CPU kan regne ut og en annen CPU kan regne ut og så legger man sammen svarene til slutt. Men poenget er at operativsystemet ikke har noen anelse om hva som foregår i et vilkårlig program. Det bare sørger for at prosessene får utført sine instruksjoner. Derfor er det programmereren som eksplisitt må skrive programmet slik at det kjøres som to uavhengige prosesser for at det skal kunne utnytte flere CPU'er. En annen løsning er at programmet inneholder flere tråder(threads) som kan kjøres på hver sin CPU, dette kommer vi tilbake til senere. Threads i denne sammenhengen har ikke noe med hyperthreads å gjøre, disse threads styres av OS og ikke av prosessoren. Det har også blitt utviklet kompilatorer som til en viss grad klarer å parallelisere kode. Men operativsystemet kan ikke gjette seg til hva programmet gjør og kan derfor ikke på egenhånd få en enkelt prosess til å utnytte flere prosessorer.\n\nModerne spillkonsoller inneholder ofte mange CPU'er, XBOX 360 har tre og Playstation 3 har åtte CPU'er. For å kunne utnytte disse må spill-programmen som kjøres på dem skrives slik at de kan utnytte alle prosessorene. Programmererne deler da opp oppgavene i uavhengige deler slik at de kan beregnes hver for seg. Dette kalles å parallellisere koden. Tidligere var dette bare viktig i såkalte clustere satt sammen av mange datamaskiner, men med dagens utvikling hvor etterhvert alle datamakiner har flere CPU'er er dette viktig for alle programmer."}
{"identifier": "os8.4", "section_id": "8.4", "section_title": "Samtidige prosesser", "source_category": "os", "source_id": "8", "source_title": "Systemkall, Scheduling og vaffelrøre", "anchor": "SECTION00094000000000000000", "source": "os/Forelesning/os/node9.html", "text": "## 8.4 Samtidige prosesser\n\nTo prosesser (tasks) må ikke ødelegge for hverandre:\n\n* skrive til samme minne\n* kapre for mye CPU-tid\n* få systemet til å henge\n\nBeste løsning:\n\nAll makt til OS = Preemptive multitasking\n\n**Linux, Windows, Mac**: Preemptive multitasking, *\"Preemptive\"= rettighetsfordelende. Opprinnelig betydning: Preemption = Myndighetene fordeler landområde.*\n\n**Windows 3.1**: Cooperative multitasking, prosessene samarbeider om å dele på CPU-en. *En prosess kan få hele systemet til å henge.*"}
{"identifier": "os8.5", "section_id": "8.5", "section_title": "Prosessor modus", "source_category": "os", "source_id": "8", "source_title": "Systemkall, Scheduling og vaffelrøre", "anchor": "SECTION00095000000000000000", "source": "os/Forelesning/os/node9.html", "text": "## 8.5 Prosessor modus\n\nAlle moderne prosessorer har et modusbit [5](footnode.html#foot1254) som kan begrense hva som er lov å gjøre. Modusbit switcher mellom bruker og priviligert modus. Dette kalles også protection hardware og er nødvendig for å kunne kjøre multitasking.\n\n* Bruker modus: User mode. begrenset aksess av minne og instruksjoner; må be OS om tjenester.\n* Priviligert modus: Kernel mode. Alle instruksjoner kan utføres. Alt minne og alle registre kan aksesseres.\n\nSe avsnittet Protection Hardware i 1.5.7 i Tanenbaum. Se også bruken av hjelm som hardware protection senere i forelesning."}
{"identifier": "os8.6", "section_id": "8.6", "section_title": "Hvordan kan OS effektivt kontrollere brukerprosesser?", "source_category": "os", "source_id": "8", "source_title": "Systemkall, Scheduling og vaffelrøre", "anchor": "SECTION00096000000000000000", "source": "os/Forelesning/os/node9.html", "text": "## 8.6 Hvordan kan OS effektivt kontrollere brukerprosesser?\n\n**Problem:**: OS kan ikke tillate en prosess/bruker å ta kontroll over maskinen. Men hvis OS skal kontrollere hver instruksjon en bruker-prosess utfører (emulering) gir det meget stor systemoverhead.\n\n**Effektiv løsning:**: OS bruker en hardware timer til å gi et begrenset tidsintervall til en brukerprosess og switcher til brukermodus og laster inn 1. brukerinstruksjon. Når tiden er ute, hopper CPU til OS-kode og OS overtar. Hver eneste CPU får sine individuelle timer-interrupt, slik at OS tar over kontrollen med jevne intervaller; typisk hvert hundredels skund."}
{"identifier": "os8.7", "section_id": "8.7", "section_title": "Bruker/Priviligert minne-kart", "source_category": "os", "source_id": "8", "source_title": "Systemkall, Scheduling og vaffelrøre", "anchor": "SECTION00097000000000000000", "source": "os/Forelesning/os/node9.html", "text": "## 8.7 Bruker/Priviligert minne-kart\n\nDet er helt vesentlig at operativsystemet har støtte fra hardware for å kunne kontrollere at vanlige programmer ikke skriver til vilkårlige deler av internminnet. Det varierer hvor stor del av de forskjellige operativsystemene som finnes som ligger i kjernen, det vil si, ligger i den priviligerte delen av minnet som kun kan nås i priviligert prosessormodus.\n\nIllustrasjon:\nModusbit må switches til priviligert modus for å kunne kjøre kode \nfra priviligert del av minne (OS-kjernen). Deler av OS ligger utenfor kjernen og kan \nkjøres fra brukermodus."}
{"identifier": "os8.8", "section_id": "8.8", "section_title": "Systemkall", "source_category": "os", "source_id": "8", "source_title": "Systemkall, Scheduling og vaffelrøre", "anchor": "SECTION00098000000000000000", "source": "os/Forelesning/os/node9.html", "text": "## 8.8 Systemkall\n\nAnta at en vanlig bruker utfører Linux-kommandoen `ls` . En slik kommando ber om å lese noe som ligger på harddisken og er da nødt til å få hjelp av OS-kjernen for brukerprogrammer har aldri direkte aksess til eksterne enheter. Programmet `ls` inneholder derfor bl. a. systemkallet `readdir()` som ber kjernen om å lese hva en katalog inneholder. Før kjernekoden kjøres, må modus-bit settes til kernel. Men hvis det fantes en instruksjon SWITCH_TO_KERNELMODE, ville et program i usermodus kunne gjøre denne instruksjonen og deretter få fri tilgang til systemet. Hvordan løses dette dilemmaet: sette modusbit til kernel og deretter være sikker på at det kun er kjernekode som kjøres?\n\nOS må igjen ha hjelp fra hardware i form av en spesiell instruksjon, trap, som i samme operasjon switcher modussbit til kernel og hopper til ett av flere predefinert steder i minnet hvor det ligger kode for systemkall, som vist i figur 56 . Det er da ikke mulig å switche til kernelmodus og kjøre vilkårlig kode etterpå for vanlige brukerprogrammer. Etter systemkallet er utført, switcher OS modusbit til brukermodus og returnerer til der i koden systemkallet ble utført.\n\nPå Linuxinstallasjoner der kildekoden er med, inneholder filen `syscall_table_32.S` (med path /usr/src/linux-source-3.2/arch/x86/kernel e.l.) som er en del av kildekoden for Linux som Linus Torvalds har skrevet, som definerer hver av de 348 Linux-systemkallene. Den tilsvarende filen for 4.4 kjernen heter\n\n```\nlinux-source-4.4.0/arch/x86/entry/syscalls/syscall_32.tbl\n```\n\nog har 376 systemkall. I tillegg finnes det noen spesifikke systemkall for 64 bits prosessorer.\n\nIllustrasjon:\nTrap-instruksjonen sørger for at en brukerprosess ikke kan oppnå full kontroll \nover en maskin ved å switche til kernelmodus.\n\nIllustrasjon:\nFig 1-17 fra Tanenbaum\n\nIllustrasjon:\nFig 1-18 fra Tanenbaum\n\nIllustrasjon:\nFig 1-23 fra Tanenbaum"}
{"identifier": "os8.9", "section_id": "8.9", "section_title": "Prioritet i Linux-scheduling", "source_category": "os", "source_id": "8", "source_title": "Systemkall, Scheduling og vaffelrøre", "anchor": "SECTION00099000000000000000", "source": "os/Forelesning/os/node9.html", "text": "## 8.9 Prioritet i Linux-scheduling\n\nAlle mulititasking operativsystem bruker en hardware timer til å dele opp tiden i små enheter. Med faste intervall vil denne timeren sende et interrupt til CPU-en som gjør at den hopper til operativsystemet-kode for dette intertuptet. Linux-kjernen deler tiden opp i ticks eller jiffies som vanligvis varer i 10 millisekunder eller ett hundredels sekund. Dette er tiden som går mellom hver gang hardwaretimeren sender et interrupt. Denne hardwaretimeren er faktisk programmerbar, slik at OS-kjernen kan sette verdien for denne når maskinen booter. Det har variert litt hva som har vært standard lengde på en Linux-jiffie, men i det siste har det vært 10 ms. I noen tidligere versjoner var det 2.5 ms. Det er mulig å konfigurere Linux kjerneversjon 2.6 til å bruke jiffie-lengde 10, 2.5 og 1 ms.\n\n* Tiden deles i epoker\n* Hver prosess tildeles et time-quantum målt i et helt antall jiffies som legges i variabelen counter. F. eks. 20 i enheter av ticks = 10 ms = timer-intervall\n* OS kjører Round Robin-scheduling. Prosessen som kjører mister ett tick (counter reduseres med en) for hvert timer-tick.\n* For hvert timer-tick sjekkes det om kjørende prosess har flere ticks, counter > 0\n* Hvis counter > 0 fortsetter prosessen, hvis ikke kalles schedule() som velger en ny\n* Epoken er over når alle prosesser har brukt opp sin tid (counter = 0)\n* Antall ticks som deles ut før hver epoke bestemmes av prioriteten og lagres i en variabel med navn 'priority'\n* En vanlig brukerprosess kan senke sin egen prioritet\n* Prioritet kan dermed endres dynamisk (har en prosess brukt mye CPU, kan den f. eks. få nedsatt prioritet)\n* Gjennomsnittlig time-quantum for 2.4 kjernen var ca 210 ms\n* Gjennomsnittlig time-quantum for 2.6 kjernen var ca 100 ms"}
{"identifier": "os8.10", "section_id": "8.10", "section_title": "need resched", "source_category": "os", "source_id": "8", "source_title": "Systemkall, Scheduling og vaffelrøre", "anchor": "SECTION000910000000000000000", "source": "os/Forelesning/os/node9.html", "text": "## 8.10 need resched\n\nLinux 2.6 kjernen deler dynamisk prosessene inn i 140 forkjellige prioritetsklasser. Hver prioritetsklasse tilsvarer et antall tildelte ticks i starten av en epoke. Hver gang scheduleren kalles, velges prosessen som har høyest prioritet og den kjører til den har brukt opp alle sine tildelte ticks. Deretter kalles scheduleren på nytt. Men hvis det i løpet av epoken kommer et interrupt, for eksempel fra tastaturet, vil et flagg `need_resched` bli satt og scheduler på grunn av dette kjøres etter neste timer-tick. En interaktiv prosess vil få mange ticks hver epoke og komme i en høy prioritetsklasse. Dermed vil den alltid velges før CPU-intensive prosesser etter en context switch. Men om ikke `need_resched` ble satt ved et interrupt fra for eksempel tastaturet, ville den interaktive prosessen som skulle hatt og prosessert dette tegnet måtte vente helt til en kjørende CPU-intensiv prosess var ferdig med alle sine tick i en epoke, før den slapp til etter en contex switch. At `need_resched` settes gjør at det skjer en context switch med en gang ved neste timer tick og interaktive prosesser får dermed en mye bedre responstid."}
{"identifier": "os8.11", "section_id": "8.11", "section_title": "Simulering av hvordan man ved hjelp av et operativsystem kan holde forelesning og lage vaffelrøre samtidig", "source_category": "os", "source_id": "8", "source_title": "Systemkall, Scheduling og vaffelrøre", "anchor": "SECTION000911000000000000000", "source": "os/Forelesning/os/node9.html", "text": "## 8.11 Simulering av hvordan man ved hjelp av et operativsystem kan holde forelesning og lage vaffelrøre samtidig\n\nI år (2025) vil denne simuleringen gjennomføres i levende live i PH170 onsdag 12. mars og ikke bare som videopptak slik som under pandemien.\n\n[Video som demonstrerer multitasking av forelesning og vaffelrørelaging](https://os.cs.oslomet.no/os/vaffel.mp4)\n\n*Når en datamaskin skal kjøre to prosesser samtidig, må den strengt skille mellom oppgavene \nde to gjør og fordele CPU-ressurser mellom de to. Et menneske er relativt dyktig til å gjøre \nto ting samtidig, men om man f. eks. skal forelese og lage vaffelrøre samtidig, kan det være nyttig (vel.....) \nå ha et program (operativsystem) som systematisk fordeler hjernebruken. Nedenfor følger instruksjoner for \nvaffelrøre, forelesning samt et styringsprogram som illustrerer hvordan et OS gjør scheduling.\nSidene nedenfor kan sammenlignes med internminnet på en maskin og hardware utfører \ninstruksjoner herfra i en evig løkke.*\n\n```\nOperativsystem, data \nmem[1] = OST1  # timer\nmem[2] = OSM1  # I/O melk\n\nOperativsystem, kode \nOSI1 stack = PC                      # I = Interrupt. Hjelm!\nOSI2 disableInterrupts\nOSI3 JMP mem[IRQ]\n\nOSM1 legg melk i buffer              # M = melk\nOSM2 set needResched\nOSM3 enableInterrupts\nOSM4 switch to user modus            # Ta av hjelm\nOSM5 PC = stack\n\nOST1 updateCounterCurrentProcess        # T = timer kall \nOST2 If(countersum == 0) \n        counter = priority;  JMP OSS1   # ny epoke\nOST3 If(counter == 0) \n        removeFromReadyList; JMP OSS1   # Call scheduler   \nOST4 if(! needResched)\n        switch to user modus            # Ta av hjelm\n        PC = stack\n\nOSS1 Les Ready List                     # S = scheduler\nOSS2 Velg prosess\nOSS3 if(ny prosess) \n            Context Switch  \n            OSS3a  stack -> OldPCB.PC   # Lagre gammel PCB\n            OSS3b  NyPCB.PC -> Stack    # Laste ny PCB\nOSS4 Sett på timer                      # ringer om ett minutt = tick/jiffie\nOSS5 enableInterrupts\nOSS6 switch to user modus               # Ta av hjelm\nOSS7 PC = stack\n\nOSmelk1 stack = PC    \nOSmelk2 disableInterrupts\nOSmelk3 hent melk                    # Be I/O melkemannen om melk\nOSmelk4 block prosess                # Fjern fra Readylist\nOSmelk5 JMP OSS1                     # Call scheduler\n\nOSegg1 stack = PC    \nOSegg2 disableInterrupts\nOSegg3 knus egg\nOSegg4 enableInterrupts\nOSegg5 switch to user modus          # Ta av hjelm\nOSegg6 PC = stack\n```\n\nVaffelprosess (V) med PCB (Process Control Block, process descriptor)\n\n```\nPCB\ncounter  0\npriority 3\nPC V1\n\nV1  100g sukker\nV2  100g mel\nV3  visp\nV4  blandet?\nV5  JMPNB V3  (Jump Not Blandet)\nV6  syscall trap OSmelk1\nV7  1 dl melk\nV8  Visp\nV9  blandet\nV10 JMPNB V8\nV11 syscall trap OSegg1 \nV12 Visp\nV13 blandet?\nV14 JMPNB V12\nV15 JMPNOK V6\n```\n\nForelesningsprosess. Siden den har prioritet 2, får den i snitt kjøre litt mindre enn vaffelprosessen.\n\n```\nPCB\ncounter  0\npriority 2\nPC F1\n\nF1 Utviklingen av Linux\nF2 Linux ble utviklet av datastudenten\nF3 Linus Torvalds på en hybel i Helsinki \nF4  år   Versjon brukere kodelinjer\nF5  1991  0.01   1       10K\nF6  1992  0.96   1000    40K\nF7  1994  1.0    100.000 170K\nF8  1996  2.0    1.5M    400K\nF9  1999  2.2    10M     1M\nF10 2001  2.4    20M     3.3M\nF11 2003  2.6    25M     5.9M \nF12 2009  2.6.32 ?       9.7M \nF13 2010  2.6.36 ?      10.9M \nF14 2011  3.0    ?      11.9M \nF15 2012  3.3    59M    12.3M \nF16 2015  4.0    ?      15.5M \nF17 2017  4.10   89M    17.0M\nF18 2019  4.19   ?      17.3M\n```\n\n```\nOperativsystem, data} \nready list: F, V\nneedResched\nstack:                               # Prosessen det ble hoppet fra\n\nCPU-registre} \nPC Program Counter\n(pekes på av kulepenn)\n\nIRQ:\n```\n\n*Operativsystemet opererer i priviligertmodus og bruker derfor sykkelhjelm. Når vaffelrøre \nprosessen stoppes må hvilken instruksjon den har kommet til lagres i PCB, slik at prosessen \nfortsetter fra der den slapp neste gang. Deretter leses ready-list. Hvis forelesningen ikke er \nferdig, står den der og adressen til neste instruksjon er lagret i denne prosessens PCB. \nOS oppdaterer Ready list, setter på timer, switcher til bruker modus og legger neste F-instruksjon \ni PC. Forelesningen fortsetter til timeren ringer og scheduler kalles på nytt. Ved ønske om å knuse egg \n(som er for risikofylt for at en vanlig bruker kan gjøre det) må vaffelprosessen gjøre et systemkall (OSegg). \nDa switches modus, systemkallet utføres, modus switches tilbake og vaffelprosessen kan fortsette.\ncounter minskes med en for hver gang timeren ringer for den prosessen som kjøres. Når alle countere er null er en epoke over \nog en ny innledes ved at alle countere blir satt lik prosessenes prioritet.*\n\n[Video som demonstrerer multitasking av forelesning og vaffelrørelaging](https://os.cs.oslomet.no/os/vaffel.mp4)"}
{"identifier": "os8.12", "section_id": "8.12", "section_title": "Dagens faktum: Linux", "source_category": "os", "source_id": "8", "source_title": "Systemkall, Scheduling og vaffelrøre", "anchor": "SECTION000912000000000000000", "source": "os/Forelesning/os/node9.html", "text": "## 8.12 Dagens faktum: Linux\n\n*Linux er nå snart 32 år gammelt:*\n\n```\n> From: torvalds@klaava.Helsinki.FI (Linus Benedict Torvalds)\n> Newsgroups: comp.os.minix\n> Summary: small poll for my new operating system\n> Date: 25 Aug 91 20:57:08 GMT\n> \n> Hello everybody out there using minix -\n> \n> I'm doing a (free) operating system (just a hobby, won't be big and\n> professional like gnu) for 386(486) AT clones.  This has been brewing\n> since april, and is starting to get ready.  I'd like any feedback on\n> things people like/dislike in minix, as my OS resembles it somewhat\n> (same physical layout of the file-system (due to practical reasons)\n> among other things). \n> \n> I've currently ported bash(1.08) and gcc(1.40), and things seem to work. \n> This implies that I'll get something practical within a few months, and\n> I'd like to know what features most people would want.  Any suggestions\n> are welcome, but I won't promise I'll implement them :-)\n> \n>               Linus (torvalds@kruuna.helsinki.fi)\n```\n\nLinux ble utviklet av Linus Torvalds (f. 1969) på en hybel i Helsinki.\n\n| år | Versjon | brukere | kodelinjer |\n|---|-------|-------|----------|\n| 1991 | 0.01 | 1 | 10K |\n| 1992 | 0.96 | 1000 | 40K |\n| 1994 | 1.0 | 100.000 | 176K |\n| 1995 | 1.2 | 500.000 | 311K |\n| 1996 | 2.0 | 1.5M | 400K |\n| 1999 | 2.2 | 10M | 1M |\n| 2001 | 2.4 | 20M | 3.3M |\n| 2003 | 2.6 | 25M | 5.9M |\n| 2009 | 2.6.32 | ? | 9.7M |\n| 2010 | 2.6.36 | ? | 10.9M |\n| 2011 | 3.0 | ? | 11.9M |\n| 2012 | 3.3 | 59M | 12.3M |\n| 2015 | 4.0 | ? | 15.5M |\n| 2017 | 4.10 | 89M | 17.0M |\n| 2019 | 4.19 | ? | 17.3M |\n| 2022 | 5.16 | ? | 22.6M |\n| 2024 | 6.7.8 | ? | ? |\n\nTorvalds leder fortsatt utviklingen av kjernen. Linux kildekode er fri, GNUs public licence, GPL. Tusenvis av programmerere fra hele verden har bidratt til prosjektet. En Eu-studie fra 2006 anslår at det ville koste 882M euro å utvikle 2.6.8-kjernen på nytt fra bunnen av."}
{"identifier": "os5.1", "section_id": "5.1", "section_title": "Maskinkode optimalisert for å kjøre hurtigst mulig", "source_category": "os", "source_id": "5", "source_title": "C, maskinkode og pipelining", "anchor": "SECTION00061000000000000000", "source": "os/Forelesning/os/node6.html", "text": "## 5.1 Maskinkode optimalisert for å kjøre hurtigst mulig\n\nFor gcc-kompilatoren er default virkemåte at den skal kompilere hurtigst mulig, det vil si at selve kompileringen skal gå så fort som mulig. Det er vanlgivis ønskelig når man utvikler et program, slik at man minimaliserer ventetiden før man kan prøvekjøre siste versjon. Når man derimot har et helt ferdig versjon, er det mest naturlig å be kompilatoren å lage kode som kjører raskest mulig og er mest mulig effektiv. Generelt vil man med opsjonen -O be gcc om å lage så hurtig kode som mulig; altså lage et program som utfører beregningen den skal gjøre som raskt som mulig.\n\nFølgende er en C-funksjon som regner ut tall nummer 'last' i Fibinacci-rekken:\n\n```\nint fibo(int last)\n{\n   int i;\n   int a=1,b=1,c;\n   /* Har allerede de første to */\n   for(i=3;i <= last;i++)\n       {\n\t  c = a;      /* b skal etterpå få denne */\n\t  a = a + b;  /* Neste tall */\n\t  b = c;      /* b fortsatt nest siste tall */\n       }\n   return(a);\n}\n```\n\nHvis man kompilerer denne koden med `gcc -S fibo.c` for å se hva slags maskinkode kompilatoren vil lage, får man følgende:\n\n```\nmovl\t%edi, -20(%rbp)\n\tmovl\t$1, -12(%rbp)\n\tmovl\t$1, -8(%rbp)\n\tmovl\t$3, -16(%rbp)\n\tjmp\t.L2\n.L3:\n\tmovl\t-12(%rbp), %eax\n\tmovl\t%eax, -4(%rbp)\n\tmovl\t-8(%rbp), %eax\n\taddl\t%eax, -12(%rbp)\n\tmovl\t-4(%rbp), %eax\n\tmovl\t%eax, -8(%rbp)\n\taddl\t$1, -16(%rbp)\n.L2:\n\tmovl\t-16(%rbp), %eax\n\tcmpl\t-20(%rbp), %eax\n\tjle\t.L3\n\tmovl\t-12(%rbp), %eax\n\tpopq\t%rbp\n\tret\n```\n\nHer kan man se at adderingsoperasjonene utføres direkte på variablene som ligger i RAM, de flyttes ikke først inn i registerne for så å utføre regneoperasjonene internt inne i CPU-en. Det finnes forøvrig ingen X86-instruksjon som direkte legger sammen to tall som ligger i RAM og så lagrer resultatet i RAM etterpå, derfor må minst ett av tallene i en addisjon ligge i RAM. Men hvis man istedet kompilerer denne koden med opsjonen -O: `gcc -O -S fibo.c` får man følgende resultat:\n\n```\nmovl\t$1, %esi\n\tmovl\t$1, %ecx\n\tmovl\t$3, %edx\n\tjmp\t.L3\n.L5:\n\tmovl\t%eax, %ecx\n.L3:\n\tleal\t(%rcx,%rsi), %eax\n\taddl\t$1, %edx\n\tmovl\t%ecx, %esi\n\tcmpl\t%edx, %edi\n\tjge\t.L5\n\trep ret\n```\n\nHer ser vi at alle beregningene skjer i registerne og dette gir kode som raskere leverer sluttresultatet.\n\nHvis man gjør dette med vår funksjon, sumFunksjon.c, får man en meget kort Assembly-kode som resultat:\n\n```\n$ gcc -O -S sumFunksjon.c\n$ cat sumFunksjon.s\n\t.file\t\"sumFunksjon.c\"\n\t.text\n\t.globl\tsum\n\t.type\tsum, @function\nsum:\n.LFB0:\n\t.cfi_startproc\n\tmovl\t$6, %eax\n\tret\n\t.cfi_endproc\n.LFE0:\n\t.size\tsum, .-sum\n\t.ident\t\"GCC: (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\"\n\t.section\t.note.GNU-stack,\"\",@progbits\n$\n```\n\nHvorfor er koden så kort og hva er den meget effektive beregningen kompilatoren har funnet frem til?"}
{"identifier": "os5.2", "section_id": "5.2", "section_title": "En linje høynivåkode kan gi flere linjer maskininstruksjoner", "source_category": "os", "source_id": "5", "source_title": "C, maskinkode og pipelining", "anchor": "SECTION00062000000000000000", "source": "os/Forelesning/os/node6.html", "text": "## 5.2 En linje høynivåkode kan gi flere linjer maskininstruksjoner\n\nVi tar utgangspunkt i følgende C-program `main.c` som kaller en ekstern funksjon `enlinje()` :\n\n```\n#include <stdio.h>\n\nextern int enlinje();\n\nint main (void) {\n\nint svar;\nprintf(\"Kaller enlinje()...\\n\");\nsvar = enlinje();\nprintf(\"Svar = %d\\n\", svar);\n}\n```\n\nDenne funksjonen, her lagret i filen `enlinje.c` , legger sammen to variabler som er lagret i RAM og som heter svar og memvar og returnerer svaret:\n\n```\nint enlinje()\n{\n   int svar = 32;\n   int memvar = 10;\n   \n   svar = svar + memvar;\n   \n   return(svar);\n}\n```\n\nVi skal nå se at en enkelt C-instruksjon som linjen\n\n```\nsvar = svar + memvar;\n```\n\nikke nødvendigvis fører til en enkelt linje med maskinkode. I dette tilfellet er det faktisk ikke mulig å gjøre denne operasjonen med en linje maskinkode, fordi det ikke finnes noen x86-instruksjon som kan utføre denne operasjonen.\n\nOm man prøver å legge sammen to variabler som ligger i internminnet(RAM), slik som dette\n\n```\nadd memvar, svar     # svar = svar + memvar\n```\n\nfår man følgende feilmelding\n\n```\nError: too many memory references for `add'\n```\n\nfordi det x86-instruksjonen add ikke kan operere på to referanser i minnet samtidig. Det ville tatt for lang tid og en slik instruksjon finnes derfor ikke. Man må først hente inn en av variablene fra minnet og det må også koden en kompilator lager gjøre.\n\nFølgende assembly-fil, en.s, inneholder assemblykode som gjøre det samme som enlinje.c:\n\n```\n.globl enlinje \n# C-signatur:int enlinje ()\n\nenlinje:        # Standard start av funksjon\n\nmov memvar, %rbx # Man trenger to linjer kode for å\nadd %rbx, svar   # gjøre en høynivålinje svar = svar + memvar\nmov svar, %rax   # Returnerer svar\n\nret  # Verdien i rax returneres\n\n# Følgende avsnitt av koden viser hvordan man definerer\n# variabler som lagres i minnet.\n# Andre linje tilsvarer linjen\n# int svar=32;\n# i et C-program\n# Dette avsnittet kunne også stått øverst i filen\n\n.data\nsvar:   .quad 32   # deklarerer variabelen svar i RAM\nmemvar: .quad 10   # 8 byte = 64 bit variable\n```\n\nC-koden main.c i starten av avsnittet kan brukes for å kalle assembly-funksjonen over med\n\n```\ngcc -no-pie main.c en.s\n```\n\nHvis man kompilerer enlinje med\n\n```\ngcc -S enlinje.c\n```\n\nFår man følgende kode:\n\n```\n.file\t\"enlinje.c\"\n\t.text\n\t.globl\tenlinje\n\t.type\tenlinje, @function\nenlinje:\n.LFB0:\n\t.cfi_startproc\n\tpushq\t%rbp\n\t.cfi_def_cfa_offset 16\n\t.cfi_offset 6, -16\n\tmovq\t%rsp, %rbp\n\t.cfi_def_cfa_register 6\n\tmovl\t$32, -8(%rbp)\n\tmovl\t$10, -4(%rbp)\n\tmovl\t-4(%rbp), %eax\n\taddl\t%eax, -8(%rbp)\n\tmovl\t-8(%rbp), %eax\n\tpopq\t%rbp\n\t.cfi_def_cfa 7, 8\n\tret\n\t.cfi_endproc\n.LFE0:\n\t.size\tenlinje, .-enlinje\n\t.ident\t\"GCC: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609\"\n\t.section\t.note.GNU-stack,\"\",@progbits\n```\n\nHvordan utføres addisjonen her?\n\nNB! Fra og med 2022 har default konfigurasjon av kompilatoren gcc endret seg, slik at man nå må legge på opsjonen -no-pie for å kompilerere assembly-kode som deklarere variabler i et data-segment. Derfor må man kompilere med\n\n```\ngcc -no-pie main.c en.s\n```\n\nog også bruke `gcc -no-pie` når man loader sammen en slik kompilert assembly-fil med en kompilert C-fil. Hvis ikke får du en feilmelding om relocation R_X86_64_32S against '.data' can not be used."}
{"identifier": "os5.3", "section_id": "5.3", "section_title": "If-test", "source_category": "os", "source_id": "5", "source_title": "C, maskinkode og pipelining", "anchor": "SECTION00063000000000000000", "source": "os/Forelesning/os/node6.html", "text": "## 5.3 If-test\n\nFølgende kode viser hvordan en if-test kan lages i assembly. Tilsvarende som for while- og for-løkker, må man ha en test som hopper til et annet sted i koden avhengig av resultatet av testen.\n\n```\n.globl iftest \n# C-signatur:int iftest ()\n\niftest:        # Standard start av funskjon\n\n# Returnerer 1 hvis svar > 42, ellers 0\n# if(svar > 42){\n#    return(1):\n# }\n# else{\n#    return(0);\n#}\n\nmov $42, %rbx\n\ncmp  %rbx, svar # compare\njg  greater     # Jump Greater, hvis svar > 42\n\nmov $0, %rax    # 42 eller mindre hvis her\njmp return\n\ngreater:\nmov $1, %rax\n\nreturn:\nret  # Verdien i rax returneres\n\n.data\nsvar:  .quad 40   # deklarerer variabelen svar i RAM\n```"}
{"identifier": "os5.4", "section_id": "5.4", "section_title": "Forenklinger ved CPU Simuleringen", "source_category": "os", "source_id": "5", "source_title": "C, maskinkode og pipelining", "anchor": "SECTION00064000000000000000", "source": "os/Forelesning/os/node6.html", "text": "## 5.4 Forenklinger ved CPU Simuleringen\n\nIforhold til vår forenklede simulering er de fleste CPUer som Intel og AMD mer komplekse:\n\n* Instruksjoner bruker mer tid enn en CPU-sykel på å utføres\n* Hver instruksjon hentes inn fra RAM før den utføres (ikke ROM)\n* En x86-instruksjon deles inn i flere små deler (mikro-operasjoner), uops"}
{"identifier": "os5.4.1", "section_id": "5.4.1", "section_title": "CPU-løkke (hardware-nivå)", "source_category": "os", "source_id": "5", "source_title": "C, maskinkode og pipelining", "anchor": "SECTION00064100000000000000", "source": "os/Forelesning/os/node6.html", "text": "## 5.4.1 CPU-løkke (hardware-nivå)\n\nEn datamaskin med en CPU gjennomfører en evigvarende løkke som utfører en maskininstruksjonen av gangen helt til maskinen skrus av. [En demo av en CPU-løkke (uten interrupts) kan sees her, men krever flash.](https://nexus.cs.oslomet.no/~haugerud/os/demoer/iecycle.swf) .\n\nPseudo-kode for den evige hardware-løkken som CPU-en kjører:\n\n```\nwhile(not HALT)\n{\n   IR = mem[PC];   # IR = Instruction Register\n   PC++;           # PC = Program counter\n   execute(IR);\n   if(InterruptRequest)\n   {\n      savePC();\n      loadPC(IRQ); # IRQ = Interrupt Request\n                   # Hopper til Interrupt-rutine\n   }\n}\n```"}
{"identifier": "os5.5", "section_id": "5.5", "section_title": "Pipelining", "source_category": "os", "source_id": "5", "source_title": "C, maskinkode og pipelining", "anchor": "SECTION00065000000000000000", "source": "os/Forelesning/os/node6.html", "text": "## 5.5 Pipelining\n\nEn instruksjon kan deles inn i flere deler, stages, 14 er vanlig i Intel-CPUer.\n\nEksempel med 4 stages:\n\n* Fetch (hent instruksjonen fra RAM)\n* Decode (hvilke knapper skal trykkes på i ALU og Datapath)\n* Execute (utfør instruksjonen)\n* Write (skriv resultater til RAM)\n\nTid spares ved at neste instruksjon starter før den første er ferdig."}
{"identifier": "os5.6", "section_id": "5.6", "section_title": "Pipelining", "source_category": "os", "source_id": "5", "source_title": "C, maskinkode og pipelining", "anchor": "SECTION00066000000000000000", "source": "os/Forelesning/os/node6.html", "text": "## 5.6 Pipelining"}
{"identifier": "os5.7", "section_id": "5.7", "section_title": "Intel mikroarkitekturer", "source_category": "os", "source_id": "5", "source_title": "C, maskinkode og pipelining", "anchor": "SECTION00067000000000000000", "source": "os/Forelesning/os/node6.html", "text": "## 5.7 Intel mikroarkitekturer\n\nEn mikroarkitektur er hvordan et instruksjonsett er implementert i en CPU.\n\n| År | arkitektur (CPU) | pipeline stages | Max MHz | nm |\n|---|----------------|---------------|-------|---|\n| 1978 | 8086 | 2 | 5 | 3000 |\n| 1985 | 486 | 5 | 33 | 1000 |\n| 1995 | P6 (Pentium Pro) | 14 | 450 | 250 |\n| 2000 | NetBurst (Pentium 4) | 20 | 2000 | 180 |\n| 2004 | NetBurst (Pentium 4) | 31 | 3800 | 90 |\n| 2011 | Sandy Bridge (core i7) | 14 | 4000 | 32 |\n| 2015 | Skylake (core i7) | 14 | 4200 | 14 |\n| 2019 | Cascade Lake (core i9) | 14 | 4400 | 14 |"}
{"identifier": "os5.8", "section_id": "5.8", "section_title": "Superscalar arkitektur", "source_category": "os", "source_id": "5", "source_title": "C, maskinkode og pipelining", "anchor": "SECTION00068000000000000000", "source": "os/Forelesning/os/node6.html", "text": "## 5.8 Superscalar arkitektur"}
{"identifier": "os5.9", "section_id": "5.9", "section_title": "Superscalar arkitektur", "source_category": "os", "source_id": "5", "source_title": "C, maskinkode og pipelining", "anchor": "SECTION00069000000000000000", "source": "os/Forelesning/os/node6.html", "text": "## 5.9 Superscalar arkitektur\n\n* En skalær prosessor utfører instruksjoner en for en (som simuleringen)\n* En superskalær prosessor har flere parallelle enheter som utfører mikro-operasjoner\n* For eksempel 2 ALU-er, 1 FPU, load, store\n* Utfører operasjoner samtidig\n* Operasjoner kan utføres out-of-order (i en annen rekkefølge enn det sekvensielle programmet tilsier)"}
{"identifier": "os5.10", "section_id": "5.10", "section_title": "Intel Core 2", "source_category": "os", "source_id": "5", "source_title": "C, maskinkode og pipelining", "anchor": "SECTION000610000000000000000", "source": "os/Forelesning/os/node6.html", "text": "## 5.10 Intel Core 2"}
{"identifier": "os10.3", "section_id": "10.3", "section_title": "Å kjøre Java, C og bash-programmer under forskjellige OS", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000113000000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.3 Å kjøre Java, C og bash-programmer under forskjellige OS\n\nUtgangspunktet er det samme \"Hello world!\" programmet skrevet i C, Java og Bash. Vi skal prøve å kjøre disse på tre systemer:\n\n* Operativsystemet Linux kjørt på en vanlig PC med Intel Pentium prosessor som kun forstår X86 maskin-instruksjoner\n* Operativsystemet Windows kjørt på den samme Intel-PC-en\n* Operativsystemet Solaris kjørt på en Sun Sparcstation 20 med en sparc-prosessor som kun forstår Sparc maskin-instruksjoner\n\nIdag er Sun og sparc-prosessor en utdøende rase og det finnes ikke så mange av dem lenger. Men det er et eksempel på en datamaskinarkitektur som er helt forskjellig fra x86 og Sparc CPUer var tidligere veldig mye i bruk i Unix-servere. Nå har dette markedet i stor grad blitt tatt over av Linux- og Windows-servere som stort sett kjører på Intel og AMD CPUer med x86-arkitektur."}
{"identifier": "os10.3.1", "section_id": "10.3.1", "section_title": "Hello.java", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000113100000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.3.1 Hello.java\n\nDette Java-programmet ser slik ut\n\n```\n$ cat Hello.java\nclass Hello\n{ \n    public static void main(String args[])\n    {\n        System.out.println(\"Java: Hello world!\");\n    }\n}\n```\n\nog som de to andre, skriver det bare ut en linje til skjermen. For å kjøre dette programmet må det kompileres og vi gjør det på Linux-maskinen:\n\n```\n$ javac Hello.java\n```\n\nda lages det en binær fil med navn `Hello.class` som inneholder såkalt bytekode. Denne koden er instruksjoner til en såkalt Java Virtual Machine (JVM) som er et program som kjører bytekoden og får det underliggende systemet til å utføre det denne koden sier skal gjøres. For hvert operativsystem er det en egen JVM som sørger for dette slik som vi ser i figuren:\n\nIllustrasjon:\nJava er plattformuavhengig og samme Hello.class fil kan kjøres på alle de tre plattformene.\n\nDermed kan `Hello.class` filen som ble kompilert på en Linux-maskinen faktisk kjøre på alle de tre plattformene. Enheten OS + Hardware blir ofte omtalt som en plattform. På grunn av dette sier vi at Java er plattformuavhengig. Det samme er også Perl og C#, deres kompilerte kode kjøres av virtuelle maskiner."}
{"identifier": "os10.3.2", "section_id": "10.3.2", "section_title": "hello.c", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000113200000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.3.2 hello.c\n\nDette programmet ser slik ut\n\n```\ncube$ cat hello.c\n#include <stdio.h>\nmain()\n{\n    printf(\"c: Hello world!\\n\");\n}\n```\n\nFor å kjøre dette programmet må det kompileres og vi gjør det på Linux-maskinen:\n\n```\n$ gcc hello.c\n```\n\nda lages det en binær fil med navn `a.out` som inneholder maskin-instruksjoner og deler av disse kan lastes inn og kjøres direkte på CPU-en til plattformen den er kompilert på. Nå har vi kompilert programmet på en X86-prosessor og da vil `a.out` inneholde X86-instruksjoner som på assembler-form kan se ut som f. eks. `mov %eax,%ebx` og henviser til registrene denne CPU-en har. Kompilatoren oversetter direkte fra kildekode til maskinkode. Assembly er et språk i mellom disse, men som ligger svært nær maskinkoden, og som gjør at vi enkelt kan se nøyaktig hva maskinkoden gjør. For å få kjørbar kode som er veldig kompakt og eller gjør nøyaktig det vi ønsker, er det mulig å skrive programmer direkte i assembly og så få en assembler til å oversette dette til maskinkode og dermed et kjørbart program.\n\nVed hjelp av reverse engineering kan man prøve å se hva binærkoden til et kompilert program (ofte kalt objekt-kode) inneholder. Programmet `objdump` er en disassembler som oversetter maskinkoden til en for mennesker mer leselig assembly-kode. Dette er det motsatte av hva en assembler gjør.\n\n```\nLinux$ objdump -d a.out \n\n8048278:       83 ec 04                     sub    $0x4,%esp\n 804827b:       e8 00 00 00 00          call   8048280 <_init+0xc>\n 8048280:       5b                      pop    %ebx\n 8048281:       81 c3 d8 12 00 00       add    $0x12d8,%ebx\n 8048287:       8b 93 fc ff ff ff       mov    -0x4(%ebx),%edx\n```\n\nDette er bare et lite utsnitt av koden og det sentrale i vår sammenheng er at dette er instruksjoner fra det såkalte X86-instruksjonssettet som alle vanlige Intel og AMD-prosessorer bruker.\n\nDermed kan det umulig gå bra å kjøre `a.out` på en Sparc-prosessor, for den forstår overhode ikke maskin-instruksjonene som blir gitt. Det er rett og slett helt gresk for Sparc-prosessoren. Den forstår bare Sparc-instruksjoner som er et helt annent instruksjonessett som vi kan se hvis vi kompilerer programmet og dumper objekt koden under Solaris:\n\n```\nSolaris$  gcc a.out\nSolaris$  objdump -d a.out\n   10440:       e0 03 a0 40     ld  [ %sp + 0x40 ], %l0\n   10444:       a2 03 a0 44     add  %sp, 0x44, %l1\n   10448:       9c 23 a0 20     sub  %sp, 0x20, %sp\n   1044c:       80 90 00 01     tst  %g1\n```\n\nDette ligner, men instruksjonene er delvis forskjellige og definsjonene av hvilke bit-strenger som betyr en bestemt instruksjon eller et bestemt register er helt forskjellige.\n\nI tillegg inneholder `a.out` kode som ber Linux-operativsystemet om å skrive ut til skjermen og dette er spesielle systemkall som er helt spesifikke for Linux og som andre OS ikke forstår. Dermed går det heller ikke å kjøre dette programmet på Windows-maskinen, selvom maskin-instruksjonene er de samme, alle er hentet fra X86-instruksjonssettet.\n\nIllustrasjon:\nC er ikke plattformuavhengig og samme a.out fil kan ikke kjøres på alle de tre plattformene. Som vi ser i figuren er det kun på plattformen programmet er kompilert at det kan kjøres og vi sier at C er plattformavhengig. Om vi skal kjøre dette programmet på de to andre plattformen, må det kompileres på nytt med en C-kompilator på både Windowsmaskinen og på Solaris-maskinen. På Windows kan det gjøres for eksempel med tinyCC (tcc), eller med en komersiell kompilator som Visual C++. På Solaris finnes det som regel en C-kompilator, det er vesentlig for Unix-maskiner. Da lages det instruksjoner som snakker med det rette OS'et og som inneholder de rette maskininstruksjonene, slik som i figuren.\n\nIllustrasjon:\nC-programmet må kompileres på hver av de tre plattformene, først da kan de kjøres."}
{"identifier": "os10.3.3", "section_id": "10.3.3", "section_title": "hello.bash", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000113300000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.3.3 hello.bash\n\nDette programmet ser slik ut\n\n```\ncube$ cat hello.bash\n#! /bin/bash\necho \"bash: Hello world!\"\n```\n\nog er avhengig av at shellet bash er installert på plattformen det skal kjøres. Dette programmet tolker da linje for linje og utfører den. Dette er delvis analogt til Java, bortsett fra at mellomleddet med å kompilere og lage bytekode er fjernet. Programmet bash erstatter JVM og kjører koden. Dermed er også bash-script plattformuavhengig. Tidligere var det ikke mulig å kjøre bash på Windows, men i de siste årene har Microsoft samarbeidet mye med Ubuntu og det er nå mulig å aktivere et fullverdig bash-shell i Windows. Men det er ikke aktivert som default."}
{"identifier": "os10.4", "section_id": "10.4", "section_title": "Test av C, Java, Python og bash på 5 plattformer", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000114000000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.4 Test av C, Java, Python og bash på 5 plattformer\n\nI forelesningen ble et Python 'Hello world' program testet i tillegg til de tre språkene beskrevet over. De fem forskjellige plattformene som var involvert i testen var de følgende.\n\n* Linux Ubuntu 18.04, Intel Xeon, Java 11 Python 3.6 (HP laptop)\n* MacOS X Darwin Kernel, Intel Core Duo, Java 6 (1.6) Python 2.6 (Gammel MacBook Pro)\n* Linux Ubuntu 16.04, AMD Opteron, Java 8 (1.8) Python 2.7 (Dell server med 48 CPUer)\n* Linux Ubuntu 20.04, ARM Neoverse-N1, Java 14 Python 3.8 (Amazon EC2, London)\n* Windows server 2019, Intel Xeon CPU, Java 8 (1.8) Python 3.9 (Amazon EC2, London)\n\nUtganspunktet varr at alle programmene ble kompilert og kjørt på den førstnevnte HP-laptopen som kjører Ubuntu 18.04. Kompileringen av programmene ble gjort med\n\n```\ngcc hello.c\njavac Hello.java\n```\n\nog kjøringen med\n\n```\n./a.out\njava Hello\npython hello.py\nbash hello.bash\n```"}
{"identifier": "os10.5", "section_id": "10.5", "section_title": "Threads (tråder)", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000115000000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.5 Threads (tråder)\n\n* prosess = At en kokk lager en porsjon middag i et kjøkken\n* CPU = kokk\n* ressurser = kjøkken, matvarer, oppskrift\n* thread/tråd = den sammenhengende serien av hendelser som skjer når kokken lager en porsjon\n\nNår porsjonen er ferdig er porsessen avsluttet. Alternativer:\n\n* To uavhengige prosesser = to kjøkken, kokken løper frem og tilbake og lager en porsjon i hvert kjøkken. Følger en oppskrift i hvert kjøkken(men oppskriften er den samme).\n* En prosess med to threads = Ett kjøkken, kokken bytter på å jobbe med de to porsjonene og lager to porsjoner fra samme oppskrift med felles ressurser for de to porsjonene.\n\nMed en tradisjonell prosess kan kun en kokk jobbe i et kjøkken og der lage kun en porsjon. Ønsker man å lage flere porsjoner, så må man lage flere kjøkken. Innfører man tråder kan flere kokker jobbe i samme kjøkken med flere porsjoner på en gang."}
{"identifier": "os10.6", "section_id": "10.6", "section_title": "Definisjoner av threads", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000116000000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.6 Definisjoner av threads\n\n* den sammenhengende rekken av hendelser/instruksjoner som utføres når et program kjøres\n* \"tråden\" som følges når et program utføres\n* Lettvekts prosess\n\nProgrammereren (og ikke OS) vet hva som skal gjøres. Han kan detaljstyre threads til å samarbeide om oppgaver som skal utføres.\n\nIllustrasjon:\nSingle og multithreading\n\nFigur 64 viser for en single threaded prosess hvordan programmet gjennom å utføre instruksjoner beveger seg igjennom koden og også frem og tilbake og til RAM. Om man tegner opp denne bevegelsen får man en enkelt \"tråd\" som beveger seg rundt og illustrerer hvordan programmet kjøres. Om man kjører et program flere ganger, kan det følge forskjellige tråder hvis for eksempel input er forskjellig fra gang til gang. Hvis man kjører en prosess som kan ha flere tråder kan man istedet for å kjøre et program tre ganger, kjøre tre tråder samtidig inne i den samme koden. Den høyre delen av figuren viser en multi threaded prosess hvor tre instanser av samme program kjører samtidig og følger hver sin tråd under utførelsen. Det meste av koden kan deles med de andre trådene, men alle data som er spesielle for den enkelte kjøringen må lagres hver for seg, slik som PCB for tråden. For eksempel vil disse tre trådene hele tiden ha forskjellige verdier i registerene og de vil kunne gjøre kall til forskjellige metoder. Dermed må de ha hver sin stack definert i RAM (hvor metode-kallene og metode-variabler lagres) og de må ha sine helt egne verdier i registerene som lagres i PCB når de ikke kjører. Den vanligste måten for operativsystemet å schedulere tråder er å betrakte dem som uavhengig enheter slik at tre tråder innen samme prosess kan kjøre på tre forskjellige CPUer."}
{"identifier": "os10.7", "section_id": "10.7", "section_title": "Fordeler med threads", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000117000000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.7 Fordeler med threads\n\n**Ressursdeling**: Flere tråder eksisterer innenfor samme prosess. Deler på kode, data og delvis PCB.\n\n**Respons**: Interaktive applikasjoner kan ha en tråd med høy prioritet som kommuniserer med brukere og lavprioritettråder som gjør grovarbeid.\n\n**Effiktivitet**: Tar mindre tid å lage nye threads og mindre tid å context-switche mellom threads. Kan typisk ta 30x så lang tid å lage en ny prosess som å lage en ny thread. Context switch kan ta 5x så lang tid.\n\n**Multiprosessor**: Hver tråd kan tildeles en egen CPU.\n\n**Felles variabler**: Ofte nyttig med felles minne for prosesser, men det er tungvint å sette opp. Dette er trivielt for threads."}
{"identifier": "os10.8", "section_id": "10.8", "section_title": "Java-threads", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000118000000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.8 Java-threads\n\nFor å lage Java-threads må man arve klassen Thread. Viktige Thread-metoder:\n\n**start()**: Allokerer minne, stack etc. og kaller run().\n\n**run()**: Her uføres jobben tråden skal gjøre.\n\n**yield()**: Tråden gir fra seg CPU-en.\n\n**setPriority()**: Setter thread-prioritet. Min = 1, Max = 10, default = 5.\n\n**sleep(ms)**: Tråden sover i ms millisekunder"}
{"identifier": "os10.8.1", "section_id": "10.8.1", "section_title": "Prioritet", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000118100000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.8.1 Prioritet\n\nVanligvis scheduleres to Java-tråder av OS, etter en-til-en modellen slik at de to trådene kjører uavhengig av hverandre og samtidig. Dette kalles native threads. Det finnes implementasjoner hvor Java kjører en prosess og schedulerer trådene selv, såkalte green-threads. jdk1.1 var implementert slik på Linux.\n\nDet går ikke klart frem av spesifikasjonene for JVM (Java Virtual Machine) hvordan prioritet skal implementeres og her kan det være forskjeller."}
{"identifier": "os10.8.2", "section_id": "10.8.2", "section_title": "Java på Linux", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000118200000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.8.2 Java på Linux\n\n```\n$ emacs Calc.java&\n$ javac Calc.java   # Calc.class lages; bytecode\n$ java Calc         # Starter JVM (Java Virtual Machine) som kjører byte-koden\n```"}
{"identifier": "os10.8.3", "section_id": "10.8.3", "section_title": "Variabler", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000118300000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.8.3 Variabler\n\nVariabler som blir definert som static vil være felles for alle trådene. Andre vil kun kunne brukes av den enkelte tråd.\n\n```\nstatic int count;\n   int id;\n```\n\nI eksempelet oppdateres `count` av begge trådene, mens det eksisterer en `id` for hver tråd.\n\nIllustrasjon:\nDeklareres en variabel som static blir den felles for alle tråder."}
{"identifier": "os10.9", "section_id": "10.9", "section_title": "Java thread eksempel: Calc.java", "source_category": "os", "source_id": "10", "source_title": "Plattformavhengighet og Threads", "anchor": "SECTION000119000000000000000", "source": "os/Forelesning/os/node11.html", "text": "## 10.9 Java thread eksempel: Calc.java\n\n```\nimport java.lang.Thread;\n\nclass CalcThread extends Thread\n{\n   static int count = 0;\n   int id;\n\n   CalcThread()\n        {\n         count++;\n         id = count;\n        }\n\n   public void run()\n        {\n         System.out.println(\"Thread nr.\" + id + \" is starting\");\n         System.out.println(\"Thread nr.\" + id + \" calculated \" + work());\n        }\n\n   private float work()\n        {\n         int i,j;\n           float res = 0;\n            System.out.println(\"Thread nr.\" + id + \" calculating\");\n            for(j = 1;j < 5;j++)\n                {\n                    for(i = 1;i < 30000000;i++)\n                        {\n                            res += 1.0/(1.0*i*i);\n                        }\n                     System.out.println(\"Thread nr.\" + id + \" calculating\" + j);\n                }\n         return(res);\n        }\n}\n\nclass Calc\n{\n   public static void main(String args[])\n   {\n    System.out.println(\"Starts two threads !\\n\");\n    CalcThread s = new CalcThread();\n    System.out.println(\"Thread s has id \" + s.id + \"\\n\");\n    s.start(); // Allokerer minne og kaller s.run()\n\n    CalcThread s2 = new CalcThread();\n    System.out.println(\"Thread s2 has id \" + s2.id + \"\\n\");\n    s2.start();\n    System.out.println(\"s2 started !\\n\");\n\n    }\n}\n```\n\nKjører man dette programmet på en maskin med to CPU'er, vil de to trådene kunne kjøre på hver sin CPU og dermed utnytte ressursene optimalt. Et java-program med en tråd vil kun kunne utnytte en av CPU-ene."}
{"identifier": "os2.3", "section_id": "2.3", "section_title": "Porter og transistorer", "source_category": "os", "source_id": "2", "source_title": "Transistorer, porter og krets som adderer tall", "anchor": "SECTION00033000000000000000", "source": "os/Forelesning/os/node3.html", "text": "## 2.3 Porter og transistorer\n\nVed hjelp av AND, OR og NOT-porter kan man helt generelt uttrykke alle mulige logiske sammenhenger. Fysisk sett er disse logiske portene bygd fra enda mindre byggestener, transistorer. Dette er selve grunn-byggestenen i en datamaskin på lignende måte som atomer er grunn-byggestenen i alle materialer. En transistor er egentlig bare en av/på bryter hvor en innkommende ledning er en bryter som avgjør om det ledes strøm eller ikke. Dette er omtrent som en vanlig elektrisk bryter på veggen, men i transistorens tilfelle styres bryteren av om det kommer strøm inn eller ikke. Slike transistorer kan man sette sammen i kretser og bygge logiske porter som igjen kan brukes til all den logikk en CPU trenger.\n\nI de aller første datamaskiner ble radiorør brukt som slike brytere. I 1948 ble halvleder-transistoren oppfunnet av Bardeen, Brattain og Shockley, noe de fikk nobelprisen i fysikk for i 1956. Man kan argumentere for at dette er den viktigste enkeltstående oppfinnelsen noen sinne. Den største forskjellen fra radiorør er at transistorene kan lages ekstremt små; i 2017 klarte Intel og pakke mer enn 100 millioner transistorer på en kvadratmillimeter. Dette var med såkalt 10 nanometer teknologi hvor størrelsen på komponenter er helt nede i 10 nanometer (en nanometer er meter). I 2020 begynte TSMC (Taiwan Semiconductor Manufacturing Company) produksjon av 5 nanometer silisium-brikker (chips). TSMC er verdens ledende halvleder-produsent og produserer for kunder som AMD og Apple og produserer også noe for Intel og andre firma som i hovedsak har egen produksjon.\n\nI CPU-en Intel 4004 fra 1971 var det 2.300 transistorer og en CPU klokkefrekvens på 500 KHz, mens det i en Intel Xeon fra 2016 var 7.2 milliarder transistorer og en klokkefrekvens på 3 GHz. Mindre avstander gjør det mulig å øke klokkefrekvensen, men etter 2005 har den ikke økt fordi det genreres for mye varme om man gjør det. Frem til 2005 kunne man løse dette problemet med å redusere størrelsen, men på denne tiden begynte man å nå de fysiske grensene for hvor lite noe kunne lages, siden bredden på ledningene bare utgjorde noen titalls atomers bredde. I følge Moores lov så dobler antall transistorer i integrerte kretser seg hvert andre år og den loven har blitt fulgt ganske nøyaktig siden 70-tallet. Riktignok har det meste av ekstra transistorer i moderne CPUer blitt brukt til cache, hurtigminne i CPUene. Fig. 8 [1](footnode.html#foot267) viser eksempler på mikroprosessorer som følger Moores lov.\n\nIllustrasjon:\nMoores lov: antall transistorer i integrerte kretser dobler seg hvert andre år. T\n\nOg snart når man de fysiske yttergrensene. Bohr-radius, avstand fra kjerne til elektron i hydrogen, er 0.05 nanometer. Radius til et Silisium-atom er 0.11 nanometer. Komponentene har nå blitt så små at man må ta hensyn til fenomener som kvante-tunnelering og man kan ikke gå særlig mye lenger ned i størrelse på transistor-teknologien."}
{"identifier": "os2.4", "section_id": "2.4", "section_title": "CMOS", "source_category": "os", "source_id": "2", "source_title": "Transistorer, porter og krets som adderer tall", "anchor": "SECTION00034000000000000000", "source": "os/Forelesning/os/node3.html", "text": "## 2.4 CMOS\n\nCMOS er en teknologi for å lage integrerte kretser som brukes i alle mikroprosessorer. At den er komplementær betyr at den setter sammen to motsatte typer transistorer, NMOS og PMOS. En NMOS-transistor er egentlig en n-type metal oxide semiconductor field effect transistor (MOSFET). Dette er egentlig en ekstremt liten bryter, noen tiltalls nanometer stor. Hvis det er null spenning inn på transistoren, er de to andre utgangene isolert fra hverandre, bryteren er av. Hvis man sender positiv spenning inn skrus bryteren på og de to andre utgangene vil lede strøm, akkurat som når man trykker på en lysbryter. En n-type transistor er vist i Fig. 9 .\n\nIllustrasjon:\nNMOS transistor. Når det ikke er spenning inn, er øvre og nedre del isolert, bryteren er av. Når X kobles til spenning går bryteren på og strøm ledes mellom nedre og øvre del. Det at man kan lage så ekstremt små transistorer har gjort det mulig å legge milliarder av dem på samme chip og lage enormt kraftige mikroprosessorer. En p-type transistor er veldig lik, men den virker helt motsatt, den er komplementær. En slik transistor er vist i Fig. 10 .\n\nIllustrasjon:\nPMOS transistor. Virker motsatt av NMOS, når det er spenning inn, er øvre og nedre del isolert, bryteren er av.\n\nVed å sette sammen NMOS og PMOS sammen viste det seg at man unngår unødvendig strømføring i kretsene og at man dermed reduserer varmeproduksjonen som er et vesentlig problem for integrerte kretser. Man kan lage den enkleste logiske porten, NOT, ved å sette sammen en p-type og en n-type transistor som vist i Fig. 11 .\n\nIllustrasjon:\nNOT-port. Når X kobles til positiv spenning, vil den øverste PMOS-transistoren isolere, mens den nederste NMOS-transistoren gir 0 spenning ved Y. Og det motsatte skjer når X kobles til jord.\n\nDermed har man en viktig byggestein. I figuren ser man også hvordan de forskjellig delene kobles sammen i en krets og kobles til spenning eller jord, null spenning. Hvis man kobler X-inngangen til NOT-porten til jord, null volt, vil man måle 5 volt ved utgangen Y. Så kan man bygge videre, ved for eksempel å sette en NOT-port til etter den første. Men hvis man ønsker å kunne lage alle mulige logiske binære funksjoner, trenger man også AND- og OR-porter. Det viser seg at man kan lage AND og OR-porter med 3 CMOS-par av transistorer og hvordan man kan lage OR er vist i Fig. 12 . Omtrent tilsvarende kan man lage en AND-port.\n\nIllustrasjon:\nEn OR-port kan lages av 6 transistorer. Vss er jord, null spenning, og Vdd er positiv spenning.\n\nDermed kan man lage alle mulige logiske operasjoner bygget på transistorer ved å sette sammen systemer av NOT, AND og OR-porter. For å bygge en CPU som kan gjøre operasjoner som å legge sammen tall, trenger man generelt å lage generelle binære funksjoner som vist i Fig. 14 .\n\nIllustrasjon:\nEn generell binær funksjon.\n\nGenerelt kan en boolsk funksjon defineres ved en sannhetstabell som definerer hva output av funksjonen skal være for alle mulige kombinasjoner av binær input."}
{"identifier": "os2.5", "section_id": "2.5", "section_title": "Boolsk algebra", "source_category": "os", "source_id": "2", "source_title": "Transistorer, porter og krets som adderer tall", "anchor": "SECTION00035000000000000000", "source": "os/Forelesning/os/node3.html", "text": "## 2.5 Boolsk algebra\n\nI boolsk algebra uttrykkes AND, OR og NOT på følgende måte\n\n* AND: A B (A B )\n* OR: A + B (A B)\n* NOT: ( A )\n\nDe boolske operatorene som står i parentes er slik de blir brukt i kurset Diskret matematikk. I digitalteknikk er det vanligst å bruke konvensjonen for boolske operatorer som brukes i dette kurset."}
{"identifier": "os2.6", "section_id": "2.6", "section_title": "Fra sannhetstabell til logisk krets.", "source_category": "os", "source_id": "2", "source_title": "Transistorer, porter og krets som adderer tall", "anchor": "SECTION00036000000000000000", "source": "os/Forelesning/os/node3.html", "text": "## 2.6 Fra sannhetstabell til logisk krets.\n\nNår man skal lage en komponent av en CPU, må man spesifisere nøyaktig hvordan denne kretsen skal virke. Og generelt vet man nøyaktig hva man ønsker. Hvis en krets for eksempel skal sammenligne to bit for å se om de er like, vil disse to bit være input til kretsen. Output vil være 1 (sann) hvis de to innkommende bit er like og 0 (usann) ellers. Tilsvarende kan man for mer komplekse kretser alltid kunne skrive ned hva som skal være output for hver eneste mulige input. På samme måte som for AND, OR og NOT-porter, kan ønsket om hvordan kretsen skal fungere formuleres som en såkalt sannhetstabell. Funksjonen F(A,B) til en krets som har som input A og B og som skal være 1 (sann) når A og B er like og 0 (usann) når A og B er forskjellige kan skrives slik:\n\n| A | B | F(A,B) |\n|---|---|------|\n| 0 | 0 | 1 |\n| 0 | 1 | 0 |\n| 1 | 0 | 0 |\n| 1 | 1 | 1 |\n\nUt ifra en slik sannhetstabell kan man alltid skrive ned et logisk uttrykk for funksjonen F(A,B). For å få til det, benytter man seg av egenskapene til AND og OR operatorene. Et produkt vil kun være lik 1 hvis både A og B er lik 1, i alle andre tilfeller vil produket være lik 0. Hvis en linje i sannhetstabellen viser at F skal være lik 1, kan man derfor skrive ned et produkt som gir 1 når man ganger sammen (AND'er) nøyaktig de to verdiene i denne linjen av sannhetstabellen. For første linje i sannhetstabellen over, må man derfor skrive ned uttrykket\n\n( 1 )\n\nsom første ledd av uttrykket F(A,B), siden dette gir 1 for verdiene A = 0 og B = 0 i første linje og 0 i alle andre tilfeller ( betyr ikke A eller NOT A og er lik 1 når A = 0). Hvis man skriver ned tilsvarende uttrykk for alle linjer som gir 1 i sannhetstabellen, kan man til slutt legge sammen alle leddene med OR-operatoren. Dette blir da tilsammen et korrekt uttrykk for funksjonen F, fordi om minst ett av leddene i et OR-uttrykk er 1 vil det totale uttrykket også bli 1. Dermed vil en slik sum av produkter alltid gi den riktige verdien for funksjonen F. I sannhetstabellen for sammenligningskretsen, gir også den siste linjen 1. Denne linjen gir derfor uttrykket som er 1 når A og B er 1 og ellers 0. Dermed kan det logiske uttrykket for funksjonen skrives ned som\n\n( 2 )\n\nFor å overbevise seg om at dette er riktig, kan man ganske enkelt teste at hvert ledd i sannhetstabellen er oppfylt. En stor fordel med logiske operatorer er at antall mulig input-verdier er begrenset, i motsetning til for kontinuerlige funksjoner.\n\nNår man har klart å skrive ned et logisk uttrykk for sannhetstabellen, kan man ganske enkelt tegne et diagram for kretsen ved å erstatte operatorene AND, OR og NOT med de tilsvarende logiske portene. Dermed kan man tegne følgende krets for ligning Eq. 2 :\n\nIllustrasjon:\nTegning av den logiske kretsen \n.\n\nSlike kretsdiagram kan brukes til å spesifisere enkeltdelene i en større krets som en CPU og til slutt kan tilsvarende deler lages i hardware. Først legges de logiske delene som skal med og så kobles de sammen; 'place and route' kalles generelt denne teknikken. Det finnes også programmeringsspråk som brukes til å definere kretser og verktøy som automatiserer deler av prosessen fra en logisk krets til en fysisk implementasjon som en integrert krets."}
{"identifier": "os2.7", "section_id": "2.7", "section_title": "Forenkling av logiske uttrykk.", "source_category": "os", "source_id": "2", "source_title": "Transistorer, porter og krets som adderer tall", "anchor": "SECTION00037000000000000000", "source": "os/Forelesning/os/node3.html", "text": "## 2.7 Forenkling av logiske uttrykk.\n\nMan kan generelt skrive ned logiske uttrykk som beskrevet over fra en sannhetstabell, også om den har 3, 4 eller enda flere input. Men da blir de resulterende logiske kretsene generelt svært omfattende. Men ved hjelp av Boolsk algebra og andre metoder er det mulig å redusere størrelsen før kretsene lages. Konstruksjonen av følgende krets er et eksempel på dette. Anta at man ønsker å lage en krets som tilfredsstiller følgende sannhetstabell:\n\n| A | B | F(A,B) |\n|---|---|------|\n| 0 | 0 | 0 |\n| 0 | 1 | 1 |\n| 1 | 0 | 0 |\n| 1 | 1 | 1 |\n\nVed å følge metoden forklart i forrige avsnitt, kan man da skrive ned den logiske funksjonen for kretsen som en sum av de to leddene som gir verdien 1 for andre og fjerde linje, slik at sannhetstabellen oppfylles:\n\n( 3 )\n\nDermed kan man tegne følgende krets for ligning Eq. 3 :\n\nIllustrasjon:\nTegning av den logiske kretsen \n.\n\nI motsetning til uttrykket i forrige avsnitt, kan dette uttrykket forenkles, slik at hele kretsen kan forenkles. Som i vanlig algebra, finnes det metoder for å faktorisere og forenkle uttrykk. Ved å bruke slike metoder kan dette uttrykket forenkles som følger:\n\n( 4 )\n\nHer har vi brukt at at som gjelder kun for Boolsk algebre. Som i vanlig algebra kan man faktorisere og som i vanlig algebra gjelder . I dette tilfellet er altså funksjonen F = B og kretsen blir ekstremt forenklet som vist i Fig. 16 .\n\nIllustrasjon:\nEkstrem forenkling av kretsen til .\n\nMan kan på samme måte lage boolske funksjoner og tegne kretser med utgangspunkt i en sannhetstabell når man har 3, 4 og også flere variabler. Med 3 og 4 variabler kan man bruke såkalte Karnaugh-diagram for systematisk forenkling, noe som er raskere og enklere enn å bruke Boolsk algebra direkte på utrykkene. Ofte er 4 variabler nok til å lage den enheten man ønsker og siden kan man bruke 'place and route' for å koble sammen alle enhetene til en fullstendig krets, slik som en CPU."}
{"identifier": "os2.8", "section_id": "2.8", "section_title": "Hvordan kan man få en logisk krets til å addere?", "source_category": "os", "source_id": "2", "source_title": "Transistorer, porter og krets som adderer tall", "anchor": "SECTION00038000000000000000", "source": "os/Forelesning/os/node3.html", "text": "## 2.8 Hvordan kan man få en logisk krets til å addere?\n\nI digital logikk er tall representert binært, som spenninger av og på. En måte å få en krets til å legge sammen binære tall på, er å la den gjennomføre operasjonene som man bruker når man legger sammen binære tall med penn og papir. Fig. 17 viser hvordan man legger sammen 1 + 3 = 4 binært. Det rød ett-tallet over nullen er mente fra første operasjon der man gjør 1 + 1 = 10 binært og får en i mente. Tilsvarende er det andre røde tallet mente fra neste operasjon.\n\nIllustrasjon:\nBinær addisjon som gir 1 + 3 = 4\n\nNå vil det være mulig å lage en digital krets som utfører en enkelt av disse repeterende operasjonene som man gjør for å legge sammen to tall. Man tar med mente fra høyre, legger sammen med de to tallen som står under hverandre og det resulterer i ett binært siffer som settes under brøkstreken og eventuelt mente til neste operasjon. Det betyr at input for kretsen er mente fra forrige operasjon (som vi kaller Z) og de to tallene som skal adderes, dem kaller vi X og Y. Output fra kretsen er ett tall S som skal under brøkstreken og resulterende mente som vi kaller C (engelsk: carry). Operasjonen som skal utføres er vist i Fig 18 .\n\nIllustrasjon:\nEn enkelt operasjon i binær addisjon som må repeteres for hvert siffer i de binære tallene.\n\nNår man forstår algoritmen for å legge sammen to tall, er det rett frem å skrive ned sannhetstabellen for en krets som skal gjøre akkurat denne operasjonen, med input X, Y og Z og output S og C. Den blir som følger:\n\n| X | Y | Z | S | C |\n|---|---|---|---|---|\n| 0 | 0 | 0 | 0 | 0 |\n| 0 | 0 | 1 | 1 | 0 |\n| 0 | 1 | 0 | 1 | 0 |\n| 0 | 1 | 1 | 0 | 1 |\n| 1 | 0 | 0 | 1 | 0 |\n| 1 | 0 | 1 | 0 | 1 |\n| 1 | 1 | 0 | 0 | 1 |\n| 1 | 1 | 1 | 1 | 1 |\n\nFor eksempel i den siste linjen, når alle tre input er 1, forplanter mente seg videre til C = 1 og også S blir 1. Gitt en slik sannhetstabell kan man med metodene vist i de forrige avsnittene konstruere en logisk krets ved å\n\n* Skrive ned boolske uttrykk for funksjonene S(X,Y,Z) og C(X,Y,Z).\n* Forenkle uttrykkene med Boolsk algebra (eller Karnaugh-diagram).\n* Tegne en krets basert på det Boolske uttrykket som utfører nøyaktig denne operasjonen.\n\nPunkt 1 vil være å ta utgangspunkt i de fire linjene i sannhetstabellen som gir 1 for funksjonene S og C. Dermed kan man skrive ned uttrykkene: deretter kan uttrykkene forenkles. Det er ved hjelp av boolsk algebra (eller Karnaugh-diagram) mulig å forenkle C til og dermed tegne kretsen som gir funksjonen C, som vist i Fig. 19 . Det er uten for dette kursets pensum å utføre denne type litt mer kompliserte forenklinger, men det er viktig å vite at man systematisk kan utføre denne type forenklinger ved hjelp av boolsk algebra eller enda mer effektivt ved hjelp av Karnaugh-diagram.\n\nIllustrasjon:\nKrets som lager funksjonen \n.\n\nUttrykket for S kan også forenkles noe. Deretter kan man tegne kretsene for disse uttrykkene sammen i en boks. I dette tilfellet kalles kretsen en Full Adder (FA) og en boks om gjør denne operasjonen (og hvor innholdet i kretsen med alle AND, OR og NOT-porter er skjult), kan se ut som i Fig. 20 .\n\nIllustrasjon:\nEn Full Adder krets som oppfyller sannhetstabellen vist over.\n\nVed å sette sammen to slike Full Adder kretser ved å koble carry fra den høyre boksen til mente i den venstre boksen, som vist i Fig. 21 , vil vi få en krets som legger sammen to binære tall og og som gir som resultat det binære tallet .\n\nIllustrasjon:\nTo Full Adder kretser skjøtet sammen slik at de regner ut det binære regnestykket \n korrekt for alle mulige verdier av X og Y.\n\nKretsen med de to FA'ene utfører regnestykket som er vist i Fig. 22\n\nIllustrasjon:\nDet binære regnestykket \n. Kretsen i Fig. 21 utfører dette.\n\nFor å addere tall med flere bit, kan man bare legge til flere slike bokser, en for hvert tall. Om man skjøter sammen 64 slike Full Adder bokser, får man en krets som legger sammen 64-bits tall. I Fig. 23 legger kretsen sammen to 3-bits tall.\n\nIllustrasjon:\nTre Full Adder kretser skjøtet sammen slik at de regner ut det binære regnestykket \n korrekt for alle mulige verdier av X og Y.\n\nHer har vi sett hvordan man kan lage en krets som legger sammen to binære tall. Tilsvarende kan man lage kretser som gjør alle andre operasjoner man trenger i en CPU, som å sammenligne, subtrahere, multiplisere, dividere og så videre. For x86 arkitekturen finnes det hundrevis av instruksjoner, noen krever kompliserte kretser andre er enklere. Ikke alle instruksjoner opererer på tall og data, noen gjør ikke annet enn å endre på verdien av ett enkelt bit. Og kretsene kan utnytte hverandre. Som et eksempel kan man klare å lage en instruksjon som subtraherer ved å kode negative tall med en metode som kalles toerkomplement, kan man bruke en addisjons-krets til å trekke fra hverandre tall også. Kretser for alle de logiske og matematiske instruksjonene legges inn i det som kalles ALU (Arithmetic Logic Unit) og ved å sende riktig styringsbit til ALU, får man utført den instruksjonen man ønsker."}
{"identifier": "os15.2", "section_id": "15.2", "section_title": "Disker", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000162000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.2 Disker\n\nEn harddisk består av et antall plater av et magnetisk materiale. For hver plate er det et lese/skrive-hode som kan lese/skrive bits ved å måle magnetisering/magnetisere platene. De fleste disker lagrer data på begge sider av platene og har derfor lese/skrive-hode over og under.\n\nIllustrasjon:\nOverflaten av en plate på innsiden av en harddisk. Lesehodet flyttet posisjon mens bildet ble tatt og kan derfor sees i to posisjoner.\n\n[Denne linken](\nhttps://commons.wikimedia.org/wiki/File:HardDisk1.ogv  \n) viser en video av en åpen harddisk mens den kjører.\n\nIllustrasjon:\nTversnitt av en harddisk. En typsik rotasjonshastighet er \n7200 rpm (rounds per minute)."}
{"identifier": "os15.2.1", "section_id": "15.2.1", "section_title": "Sektor", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000162100000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.2.1 Sektor\n\nDet området som lesehodet dekker under en rotasjon, kalles en track og en track er delt opp i sektorer. En sektor er\n\n* grunnenhet for disker\n* vanligvis på 512 bytes\n* minste enhet som kan leses/skrives til.\n\nIllustrasjon:\nHver plateoverflate er delt inn i tracks og sektorer. Den delen av en track som ligger \ninnenfor en sektor, er den minste enheten det lagres data på og den er vanligvis på 512 bytes. Noen ganger brukes begrepet sektor om alle tracks i en retning på disken."}
{"identifier": "os15.2.2", "section_id": "15.2.2", "section_title": "Sylinder", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000162200000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.2.2 Sylinder\n\nEn sylinder er samlingen av alle tracks fra alle platene i disken som ligger i samme avstand fra sentrum.\n\nIllustrasjon:\nEn sylinder defineres som samlingen av tracks på alle overflater i samme avstand fra sentrum. \nSylinder nummer 39 er derfor samlingen av alle track nr. 39 på begge sider av alle platene. Adressen til den minste lesbare enheteten, en sektor, er derfor gitt ved tre parametre [leshode, track, sektornummer]. Når OS vil lese noe fra disk, sendes en forespørsel med disse tre tallene."}
{"identifier": "os15.3", "section_id": "15.3", "section_title": "Partisjoner", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000163000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.3 Partisjoner\n\nEn disk-partisjon defineres som et antall sylindere som ligger fysisk samlet etter hverandre. For eksempel kan man bestemme at alle sylindere fra og med nummer 150 til og med 672 skal utgjøre en partisjon. Dette er den største enheten man deler inn en disk i. Under Windows er det vanlig ha en stor partisjon som utgjør hele disken, mens det under Linux er vanlig å dele inn disken i flere partisjoner. Monteringspunkter i filsystemet kan da tildeles bestemte partisjoner slik at for eksempel alt som ligger under `/home` legges på partisjon nummer 3 på disken.\n\nIllustrasjon:\nEn partisjon består av et antall sylindre som ligger etter hverandre. Noen av fordelene med partisjoner er:\n\n* Hvis man har en egen partisjon for brukeres filer og partisjonen som OS ligger på blir ødelagt eller OS av andre grunner må installeres på nytt, vil man kunne beholde partisjonen med brukerfiler.\n* Hvis man bare har en disk, kan man likevel ha forskjellige filsystemer og dermed forskjellige OS på den samme disken når den er delt i partisjoner.\n* Mindre partisjoner og dermed mindre filsystemer er noe hurtigere enn å ha alt på en partisjon.\n* Filsystemene på partisjoner kan tilpasses dataene som skal ligge der. For eksempel stor cluster-størrelse til videofilmer."}
{"identifier": "os15.4", "section_id": "15.4", "section_title": "SSD (Solid State Drive)", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000164000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.4 SSD (Solid State Drive)\n\n* Basert på flash-minne som i minnepinner og har ingen bevegelige deler\n* Tåler rystelser bedre og er lydløs\n* Rask random aksesstid, 0.1 ms mot 5-10 ms for roterende disker\n* Dyrere enn tradisjonelle disker og mindre kapasitet"}
{"identifier": "os15.5", "section_id": "15.5", "section_title": "Filsystemer", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000165000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.5 Filsystemer\n\nFør en ny disk kan tas i bruk må den formatteres. Dette er en lavnivå organisering av disken som vanligvis gjøres på fabrikken der den deles inn i sektorer, som for de fleste harddisker er på 512 byte. Når dette er gjort kan disk-controlleren lese og skrive til disse sektorene. Når man senere bruker software til å formattere en disk, er dette en høynivå formattering som setter disken tilbake til slik den var når den var ny, og i tillegg gjør operasjoner som å legge inn en boot-sektor. Før operativsystemet og applikasjoner kan ta disken i bruk må det så lages et filsystem på disken. Det finnes mange forskjellige filsystemer, NTFS er det vanligste på Windows, tidligere var FAT det vanligste. På Linux er filsystemet ext3 det vanligste. Hvis disken er inndelt i flere partisjoner, kan det lages forskjellige filsystemer på de forskjellige partisjonene. Fra Windows kan man ikke uten videre lese og skrive til partisjoner med ext3, men fra Linux kan man lese og skrive til parisjoner med FAT og NTFS.\n\nFilsystemet tar utganspunkt i den miste enheten som kan leses fra eller skrives til, sektoren som typisk er på 512 bytes. Den viktigste oppgaven til filsystemet er å fordele mapper og filer på diskens sektorer og holde orden på hvor alt ligger. I de fleste tilfeller er en sektor for liten til å være en optimal størrelse for inndelingen av en disk og filsystemet deler derfor disken inn i større blokker (Linux: blocks, Windows: clustere). Størrelsen på blokkene må bestemmes når filsystemet lages og fordeler og ulemper ved store/små blokker må da veies mot hverandre.\n\n* Store blokker\n  * Lese og skrive går hurtig, større sammenhengende områder\n  * En liten fil vil bruke unødvendig mye plass\n  * Bra til store filer, bilder og video\n* Små blokker\n  * Små filer bruker mindre diskplass\n  * Større filer kan risikere å bli spredt rundt på disken\n  * Lese og skrive store filer går da saktere\n  * Bra hvis filsystemet skal inneholde mange små filer"}
{"identifier": "os15.5.1", "section_id": "15.5.1", "section_title": "Tabell over filenes blokker", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000165100000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.5.1 Tabell over filenes blokker\n\nAlle filsystemer har en oversikt over hvilke blokker enhver fil på systemet består av. Når en fil lages, vil den om mulig lagres på sammenhengende blokker. Når filene øker vil den dynamisk tildeles flere blokker, men da kan det være at det ikke er plass ved siden av de opprinnelige blokkene og filen må spres på flere områder av disken.\n\nIllustrasjon:\nFilsystemet holder oversikt over hvilke blokker en fil består av. Blokkstørrelsen er 2KByte i dette \neksempelet. Bare hele blokker kan allokeres til en fil, slik at all plassen ikke utnyttes når filstørrelsen ikke eksakt går opp \nnår man deler på filstørrelsen."}
{"identifier": "os15.5.2", "section_id": "15.5.2", "section_title": "Fragmentering", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000165200000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.5.2 Fragmentering\n\nEn oppdeling av filer rundt om kring på disken som resultat av dynamisk allokering når filer vokser, kalles fragmentering og den blir ofte ganske omfattende på disker som er mye i bruk og hvor det meste av plassen blir brukt. Under Windows kan man defragmentere disken med Disk Defragmenter. Det må da være minst 15% ledig plass og prosessen kan ta lang tid. For Linux ext-filsystemer finnes det ikke noen innebygd defragmenterer, men det finnes slike verktøy som kan installeres.\n\nIllustrasjon:\nNår en fil slettes vil det oppstå huller på disken og dette vil føre til enda større grad av fragmentering."}
{"identifier": "os15.5.3", "section_id": "15.5.3", "section_title": "Sletting av filer", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000165300000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.5.3 Sletting av filer\n\nNår en fil slettes, vil de fleste filsystemer bare slette informasjonen om filene og hvilke blokker som tilhører filene og ikke slette innholdet av blokkene. Dermed kan man med applikasjoner som autopsy eller ved å se på et disk-image direkte med en hex-editor finne igjen hele eller deler av en slettet fil. Det finnes egne applikasjoner som brukes til å slette filer bedre ved å skrive over innholdet av filene med nuller eller tilfeldige bit. Selvom man gjør en slik operasjon flere ganger, kan man med måleinstrumenter som er enda mer nøyaktige enn standard lese/skrive-hoder finne ut hva som opprinnelig var skrevet. Et eksempel på dette kan sees i Fig. 86 .\n\nIllustrasjon:\nRester etter data som er overskrevet på en harddisk.\n\nBildet er hentet fra boken Forensic Discovery av Farmer og Venema som er tilgjengelig [online](https://www.porcupine.org/forensics/forensic-discovery/) ."}
{"identifier": "os15.6", "section_id": "15.6", "section_title": "Lage et Linux ext3 filsystem", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000166000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.6 Lage et Linux ext3 filsystem\n\nFørst må man lage en tom fil av den størrelse man ønsker på image't.\n\n```\nhaugerud@lap:~/disk/mount$ dd if=/dev/zero of=minfil bs=8M count=1\n1+0 records in\n1+0 records out\n8388608 bytes (8,4 MB, 8,0 MiB) copied, 0,00784602 s, 1,1 GB/s\n```\n\nDette lager en 8 MiB fil med null-tegn (ASCII tegn nummer null). Deretter kan man bygge et filsystem på denne filen:\n\n```\nhaugerud@lap:~/disk/mount$ mkfs -t ext3 minfil\nmke2fs 1.44.1 (24-Mar-2018)\nDiscarding device blocks: done                            \nCreating filesystem with 8192 1k blocks and 2048 inodes\n\nAllocating group tables: done                            \nWriting inode tables: done                            \nCreating journal (1024 blocks): done\nWriting superblocks and filesystem accounting information: done\n```\n\nDeretter kan dette image't monteres i filsystemet på helt samme måte som om det var en disk:\n\n```\nhaugerud@lap:~/disk/mount$ sudo mount minfil /mnt\n[sudo] password for haugerud: \nhaugerud@lap:~/disk/mount$ cd /mnt/\nhaugerud@lap:/mnt$ ls -l\ntotal 12\ndrwx------ 2 root root 12288 april 27 00:10 lost+found\n```\n\nTidligere måtte man eksplisitt bruke opsjonen -o loop for å montere en fil, men det fungerer nå uten å spesifisere det."}
{"identifier": "os15.7", "section_id": "15.7", "section_title": "NTFS", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000167000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.7 NTFS\n\nWindows NT File System er Windows NT/XP/7/8/10 sitt eget filsystem men også FAT16 og FAT32 støttes.\n\n* Deler inn disken i clustere\n* Clusterstørrelse på 512 bytes, 1 KiB, 2 KiB, 4 KiB og opp til maks 64 KiB\n* 4 KiB clustere er default for disker på 2GiB eller mer\n* Clusterne adresseres med 64 bits pekere\n* Komprimering\n* Cluster størrelse på mer enn 4 KiB kan ikke komprimeres og brukes vanligvis ikke\n* Kryptering\n* Alle endringer i filsystemet logges (men ikke endringer av data)\n* Raskt å rekonstruere filsystemet ved disk-crash"}
{"identifier": "os15.7.1", "section_id": "15.7.1", "section_title": "Volum", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000167100000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.7.1 Volum\n\n* Et volum består av en eller flere clustere\n* Kan omfatte deler(partisjoner) av en disk, en hel disk, eller flere disker\n* Filsystemet defineres for dette volumet\n* Maksimum antall clustere i et volum er , 16TiB med 4KiB clustere"}
{"identifier": "os15.7.2", "section_id": "15.7.2", "section_title": "Master File Table(MFT)", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000167200000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.7.2 Master File Table(MFT)\n\nDen viktigste filen i et NTFS-volum er MFT selv.\n\n* Filen MFT består av 16 records med metadata og deretter en record for hver fil og mappe\n* Hver fil har en 1KB record som inneholder all informasjon om filen som attributter\n* Eksempler på atributter: tidsstempler, filnavn, data eller peker til hvor clusterene med data ligger\n* Hvis plass lagres begynnelsen av dataene i MFT record'en\n* Små filer kan lagres i sin helhet i MFT record'en\n* Hvis det ikke er plass til pekere til alle clusterne, lages det en peker til en ny MFT-record\n* Rettigheter ble tidligere lagret i hver fil-record: hvem er eier, hvem kan lese, skrive, aksessere\n* Rettigheter lagres nå i en av de 16 MFT metatdatafilene, $Secure\n* OS-kjernen behandler en fil som et objekt\n\nIllustrasjon:\nFigure 11-41 i Tanenbaum.\n\nIllustrasjon:\nFigure 11-42 i Tanenbaum."}
{"identifier": "os15.7.3", "section_id": "15.7.3", "section_title": "Linux-partisjoner", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000167300000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.7.3 Linux-partisjoner\n\nEksempelet under er informasjon som gis når man velger p for print fra menyen etter at man som root har kjørt kommandoen `fdisk /dev/hda` på en linux PC:\n\n```\nDisk /dev/hda: 61.4 GB, 61492838400 bytes\n255 heads, 63 sectors/track, 7476 cylinders\nUnits = cylinders of 16065 * 512 = 8225280 bytes\n\n   Device Boot      Start         End      Blocks   Id  System\n/dev/hda1   *           1         608     4883728+  83  Linux\n/dev/hda2             609         624      128520   82  Linux swap / Solaris\n/dev/hda3             625        2537    15366172+  83  Linux\n/dev/hda4            2538        7476    39672517+   5  Extended\n/dev/hda5            2538        6500    31832766   83  Linux\n/dev/hda6            6501        7476     7839688+  83  Linux\n```\n\nDen første partisjonen tildeles navnet `/dev/hda1` og består av alle sylinderne fra 1 til og med sylinder nummer 608. Hver sylinder er på 8225280 bytes og denne partisjonen er derfor på bytes bytes = 4.66 GBytes. Alternativt sier output at denne partisjonen består av 4883728 blocks med størrelse 1024 bytes. Partisjon nr. 2 er en liten swap-partisjon på 16 sylindre og totalt 126 MByte. Den fjerde partisjonen er spesiell. Det kan bare lages fire såkalte primære partisjoner og om man skal ha flere enn fire må den fjerde lages som en extended partisjon som inneholder de resterende. `/dev/hda4` inneholder ikke data, men definerer området på disken som utgjør partisjon 5 og 6. Linux-kommandoen `df` viser hvordan filsystemet er montert på partisjonene.\n\nfor SATA og SCSI-disker heter disk-devicet vanligvis `/dev/sda` og kommandoen `fdisk /dev/sda` på en linux PC kan gi:\n\n```\nDisk /dev/sda: 298,1 GiB, 320072933376 bytes, 625142448 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: dos\nDisk identifier: 0xcb46d2fa\n\nDevice     Boot     Start       End   Sectors   Size Id Type\n/dev/sda1  *         2048 591679487 591677440 282,1G 83 Linux\n/dev/sda2       591681534 625141759  33460226    16G  5 Extended\n/dev/sda5       591681536 625141759  33460224    16G 82 Linux swap / Solaris\n```\n\nog heads, tracks og cylinders er ikke lenger nevnt.\n\n```\n[root]@rex$ df\nFilesystem           1K-blocks      Used Available Use% Mounted on\n/dev/hda1              4806904   4223584    339136  93% /\n/dev/hda3             15124900  13790960    565632  97% /lokal\n/dev/hda5             31333024  22349088   7392300  76% /mysql\n/dev/hda6              7716496   2785908   4538604  39% /mln\n```\n\nAlt som ligger under `/lokal` i filsystemet vil fysisk ligge på partisjon nummer 3. Tilsvarende for partisjon 5 og 6. Resten av filsystemet, alt annent under `/` ligger på 1. partisjon. Neste disk vil het `/dev/hdb` og på samme måte kan denne deles inn i partisjoner og andre deler av filsystemet kan monters på disse partisjonene."}
{"identifier": "os15.8", "section_id": "15.8", "section_title": "Windows-partisjoner", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000168000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.8 Windows-partisjoner\n\nOm man deler opp en disk under Windows, tildeles hver partisjon bokstaver, C, D, E etc. Bokstavene A og B er tradisjonelt satt av for to diskett-stasjoner. Om man har flere disker kan hele denne eller deler av den om man lager flere partisjoner, tildels andre bokstaver. På Windows XP kan man Ved å kjøre programmet `Diskpart` se på og endre partisjoneringen av diskene:\n\n```\nC:\\>Diskpart\n\nMicrosoft DiskPart version 1.0\nCopyright (C) 1999-2001 Microsoft Corporation.\nOn computer: DIRAC\n\nDISKPART> list disk\n\n  Disk ###  Status      Size     Free     Dyn  Gpt\n  --------  ----------  -------  -------  ---  ---\n  Disk 0    Online        75 GB      0 B\n  Disk 1    Online        75 GB    54 GB\n```\n\nDenne PC-en har to disker og ved å velge en av diskene kan man se hvilke partisjoner den inneholder:\n\n```\nDISKPART> select disk 0\n\nDisk 0 is now the selected disk.\n\nDISKPART> detail disk\n\nWDC WD800BB-32BSA0\nDisk ID: 3E423E41\nType   : IDE\nBus    : 0\nTarget : 0\nLUN ID : 0\n\n  Volume ###  Ltr  Label        Fs     Type        Size     Status     Info\n  ----------  ---  -----------  -----  ----------  -------  ---------  --------\n  Volume 2     C                NTFS   Partition     39 GB  Healthy    System\n  Volume 3     F                       Partition     35 GB  Healthy\n```\n\nVi ser at disken er delt i to omtrent like store partisjoner, at den første heter C, er systemdisken og har filsystemet NTFS. Den andre heter F og på denne er det ennå ikke lagd noe filsystem."}
{"identifier": "os15.9", "section_id": "15.9", "section_title": "Disk controller og DMA", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION000169000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.9 Disk controller og DMA\n\nEt multitasking OS vil fortløpende ha behov for å lese data fra mange forskjellige steder på en disk. Siden disken snurrer rundt er det ikke opplagt hva som er den hurtigste måten å lese for eksempel 20 forskjellige slike forespørsler. En forespørsel består typisk av tre tall; [leshode, track, sektornummer]. Å flytte lesehodet til nærmeste neste track som skal leses er en mulighet, å la leshodet flytte seg hele veien fra innerst til ytterst og plukke opp forespøsler underveis er en annen. OS må velge en slik algoritme for å hente inn data. På moderne disker utføres slike algoritmer av mikroprosessoren som sitter på diskens egen disk controller. Tidligere tok OS seg direkte av lesingen av data og administreringen av disken, men det ordner nå disk controlleren.\n\nFør var det også vanlig at OS detaljstyrte skrivingen av data fra disken til internminnet. Dette krevet veldig mange interrupts hver gang det komm inn data fra disken og derfor bruker moderne systemer DMA (Direct Memory Access) som avlaster denne jobben for CPU-en. Dette er vanligvis en egen chip knyttet til systembussen med en egen liten mikroprosessor og tillatelse fra CPU til å skrive direkte til minnet. CPU kan dermed be DMA om en større eller mindre lese eller skriveoperasjoner og DMA vil administrere kopieringen mellom disk og internminnet. Først når alle dataene er på plass sender DMA et interrupt til CPU som forteller at kopieringen er fullført. DMA brukes også for lesning av data fra andre enheter som CD-spiller, USB-devicer etc.\n\nOgså for I/O enheter som harddisker som er svært langsomme sammenlignet med internminnet, er det nyttig å bruke cache. I internminnet er det satt av plass til disk-cache, slik at mest mulig av det som er lest i det siste meelomlagres og kan hentes ut mye hurtigere om det kommer en ny forespørsel.\n\nIllustrasjon:\nDMA kommuniserer med disk-controlleren og sørger for at det OS ønsker blir kopiert mellom \nharddisken og internminnet."}
{"identifier": "os15.10", "section_id": "15.10", "section_title": "ATA/IDE, SATA og SCSI", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION0001610000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.10 ATA/IDE, SATA og SCSI\n\nDet finnes flere interface-standarer eller grensesnitt-typer for harddisker. De varierer i pris og ytelse. ATA/IDE er billigst og brukes til standard PC'er. SATA er ATA's arvtager, har høyere ytelse og brukes også noe av server. SCSI og SAS er dyrere og brukes av servere som krever høy ytelse."}
{"identifier": "os15.10.1", "section_id": "15.10.1", "section_title": "ATA/IDE", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION0001610100000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.10.1 ATA/IDE\n\nDen tidligste versjonen av denne grensessnitt-standaren ble på slutten av åttitallet kjent som IDE, Integrated Drive Electronics, fordi disk-controlleren ble plassert på selve disken. Etterhvert ble det offisielle navnet på standarden ATA (Advanced Technology Attachment).\n\n* Den billigste teknologien\n* Brukes i standard desktop PC'er og laptoper\n* Kalles ofte PATA (Parallell ATA) eter at SATA (Serial ATA) ble innført\n* Overføringshastigheter opp til 100 MB/s\n* Kan ha inntil 2 disker på samme kabel (master og slave)\n\nIllustrasjon:\nATA/IDE kabel"}
{"identifier": "os15.10.2", "section_id": "15.10.2", "section_title": "SATA", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION0001610200000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.10.2 SATA\n\n* Serial ATA, raskere og bedre enn ATA, men omtrent samme pris\n* Introdusert i 2003, har tatt over for ATA\n* Må ha SATA-kontroller på hovedkortet eller egen SATA-kontroller\n* Overføringshastigheter opp til 300 MB/S (SATA2/SATA-300)\n* Bruker samme metode (8B/10B encoding) som ethernet til å sende data\n* En disk per kabel\n\nIllustrasjon:\nSATA-kontakter på hovedkort\n\nIllustrasjon:\nSATA-kabel"}
{"identifier": "os15.10.3", "section_id": "15.10.3", "section_title": "SCSI", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION0001610300000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.10.3 SCSI\n\n* SCSI = Small Computer Systems Interface\n* Interface-standard fra 1986 for disker, CD-ROM etc.\n* Mer selvstendige disker enn ATA-disker, kan ha mange disker i serie på samme kabel\n* Generelt raskere, mer robuste og dyrere enn ATA\n* SCSI mest brukt i servere som krever høy disk-ytelse\n* Overføringshastigheter opp mot 640 MB/s (Ultra-640 SCSI)\n* SAS, Serial Attached SCSI, enda hutigere, bedre og dyrere enn parallell SCSI\n* SAS støtter SATA devicer\n\nIllustrasjon:\nSCSI-kabel"}
{"identifier": "os15.11", "section_id": "15.11", "section_title": "KiB, MiB og GiB", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION0001611000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.11 KiB, MiB og GiB\n\nBenenvninger som KB og MB er ikke alltid entydge, KB kan bety både bytes og 1000 bytes. Den opprinnelige SI [6](footnode.html#foot2357) -definisjonen av prefiksene er den helt korrekte og sier at K = 1000, M = 1000.000, G = 1000.000.000, etc. Vanlig praksis når det for eksempel gjelder RAM er at 128MB betyr 128 bytes. Men hvis en harddisk-produsent oppgir at en disk er på 300 GB, betyr det at den er bytes og et OS vil da typisk rapportere den som en disk med kapasitet på 279.4 GB. For å ordne opp i dette og flere lignende tilfeller av flertydighet definerte i 1999 International Electrotechnical Commission (IEC) nye binære prefikser kibi-, mebi-, gibi- og tilhørende symboler Ki, Mi, Gi. Disse prefiksene symboliserer potenser av 2 slik at Ki , Mi og Gi . I 2005 ble dette en IEEE [7](footnode.html#foot2361) -standard.\n\n| Navn | Symbol | Verdi | Eksempel |\n|----|------|-----|--------|\n| kilo | K |  |  |\n| mega | M |  |  |\n| giga | G |  |  |\n| tera | T |  |  |\n| kibi | Ki |  | 100 KB = 97.6 KiB |\n| mebi | Mi |  | 100 MB = 95.4 MiB |\n| gibi | Gi |  | 100 GB = 93.1 GiB |\n| tebi | Ti |  | 100 TB = 90.9 TiB |\n\nEt disk-eksempel viser at produsenten Seagate bruker SI-benvening og sier at en disk er på 160 GB. På første figur ser man at Linux fdisk bruker samme benevning og 1 GB = 1 milliard bytes.\n\nIllustrasjon:\nfdisk viser 160 GB Derimot viser XP's Disk Managment at disken er på 149.05 GB og bruker altså 1 GB = bytes = 1.08 milliarder bytes.\n\nIllustrasjon:\nXP viser 149.05 GB\n\nPartisjoneringsverktøyet GParted som brukes under Ubuntu-installasjon, rapporterer disk-størrelser i GiB, slik at det er helt entydig hva som menes. Men fortsatt er MiB og GiB relativt sjelden i bruk.\n\nIllustrasjon:\nGParted viser at en 160 GB disk er på 149.05 GiB."}
{"identifier": "os15.12", "section_id": "15.12", "section_title": "Sammenligning av overføringshastigheter på minne-enheter", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION0001612000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.12 Sammenligning av overføringshastigheter på minne-enheter\n\n| enhet | Hastighet (MBit/s) |\n|-----|------------------|\n| Serial Infrared (SIR) | 0.115 |\n| Bluetooth 1.1 | 0.7 |\n| Medium Infrared (MIR) | 0.5-1 |\n| CD-ROM, 1x | 1.2 |\n| Bluetooth 2.0 | 2.1 |\n| Fast IR | 4 |\n| Wireless IEEE 802.11b | 5.5-11 |\n| 10 MBit Ethernet | 10 |\n| DVD-ROM, 1x | 11.1 |\n| USB 1.0 | 12 |\n| Bluetooth 4.0 | 25 |\n| Bluetooth 5 | 50 |\n| Wireless IEEE 802.11g | 54 |\n| CD-ROM, 52x | 62.4 |\n| 100 MBit Ethernet | 100 |\n| Wireless IEEE 802.11n | 150 |\n| DVD-ROM, 16x | 177.3 |\n| FireWire IEEE 1394 400 | 400 |\n| Blu-ray Disk 12x | 432 |\n| USB 2.0 | 480 |\n| Wireless IEEE 802.11ac | 500 |\n| FireWire 800 | 800 |\n| Gigabit Ethernet | 1,000 |\n| PATA 133 | 1,064 |\n| SATA2 300 | 2,400 |\n| Ultra-320 SCSI | 2,560 |\n| FireWire 3,200 | 3,200 |\n| SATA3 | 4,800 |\n| USB 3.0 | 5,000 |\n| Ultra-640 SCSI | 5,120 |\n| Wireless IEEE 802.11ad | 6,750 |\n| 10 Gigabit Ethernet | 10,000 |\n| USB 3.1 | 10,000 |\n| Thunderbolt 1 | 10,000 |\n| SAS 3 | 12,000 |\n| SATA 3.2 | 16,000 |\n| Thunderbolt 1 | 20,000 |\n| Thunderbolt 3 | 40,000 |\n| 40 Gigabit Ethernet | 40,000 |\n| 100 Gigabit Ethernet | 100,000 |\n| InfiniBand | 100,000 |\n\nTil sammenligning noen typiske tall for krav til overføringshastigheter for film i forskjellige kvaliteter:\n\n| hastighet | kvalitet |\n|---------|--------|\n| 2-3 Mbit/s | VHS |\n| 8-12 Mbit/s | DVD |\n| 36 Mbit/s | Blueray |\n| 4-25 Mbit/s | HD-TV/4K |\n\nI motsetning til hva som er vanlig i mange andre sammenhenger, betyr her prefikset M en million. Altså betyr Mbit/s ikke bit/s = 1.048.576 bit/s. Bruken av slike prefiks er diskutert i forrige avsnitt."}
{"identifier": "os15.12.1", "section_id": "15.12.1", "section_title": "Sammenligning av disker", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION0001612100000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.12.1 Sammenligning av disker\n\nHer er et eksempel på hver av disktypene med priser hentet fra komplett.no. Men husk at ytelsestallene er hentet fra produsentene.\n\n| Type | Kapasitet | hastighet | Søketid | Rotasjon | Buffer | Produsent | pris |\n|----|---------|---------|-------|--------|------|---------|----|\n| SATA-600 | 1 TB | 600 MBps | 8.5 | 7200 rpm | 64MB | Seagate | 528 |\n| SAS | 2 TB | 1200 MBps | 4.16 | 7200 rpm | 128 MB | Seagate | 1,675 |\n| SSD | 120 GB | 600 MBps |  |  |  | Kingston | 578 |\n| SSD | 240 GB | 600 MBps |  |  |  | Corsair | 1,049 |\n| SSD | 2TB GB | 600 MBps |  |  | 2 GB | Samsung | 6,699 |\n\nI 2012 så det slik ut:\n\n| Type | Kapasitet | hastighet | Søketid | Rotasjon | Buffer | Produsent | pris |\n|----|---------|---------|-------|--------|------|---------|----|\n| SATA-600 | 1 TB | 600 MBps |  | 7200 rpm | 32MB | Seagate | 795 |\n| SAS | 1 TB | 600 MBps |  | 7200 rpm | 64 MB | Seagate | 1.395 |\n| SAS | 600 MB | 600 MBps |  | 15000 rpm | 16 MB | Seagate | 3.695 |\n| SSD | 60 GB | 300 MBps |  |  |  | Corsair | 799 |\n| SSD | 240 GB | 600 MBps |  |  |  | Corsair | 1,999 |\n\nOg for enda et par år tidligere så det slik ut:\n\n| Type | Kapasitet | hastighet | Søketid | Rotasjon | Buffer | Produsent | pris |\n|----|---------|---------|-------|--------|------|---------|----|\n| ATA-133 | 320 GB | 133 MBps | 8.5 ms | 7200 rpm | 8 MB | Hitachi | 795 |\n| SATA-300 | 320 GB | 300 MBps | 8.5 ms | 7200 rpm | 16 MB | Hitachi | 795 |\n| Ultra320 SCSI | 300 GB | 320 MBps | 4.7 ms | 10000 rpm | 8 MB | Seagate | 5.750 |\n| SAS | 300 GB | 300 MBps | 3.5 ms | 15000 rpm | 16 MB | Seagate | 8.995 |"}
{"identifier": "os15.13", "section_id": "15.13", "section_title": "RAID", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION0001613000000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.13 RAID\n\nMens utviklingen av hastigheten til prosessorer, cache og delvis RAM har gått raskt, har utviklingen av hastigheten til harddisker vært langsom. En måte å forbedre ytelsen på når det begynner å bli vanskelig å få hver enklet enhet til å gå raskere, er å bruke flere enheter i parallell. Utviklingen av multicore prosessorer er et eksempel på dette. For disker kalles teknologien som gjør dette RAID (Redundant Array of Independent Disks). Man bruker da flere like disker til å øke hastigheten man kan hente data og man kan også bruke et slikt oppsett til redundans; dobbel lagring av data slik at man ikke mister data om en disk blir ødelagt.\n\n**RAID 0**: Minst to disker. Striper diskene. Ingen redundans. Hurtigere å lese.\n\n**RAID 1**: Minst to disker. Dupliserer dataene. Hurtigere å lese. Kan fortsatt lese alt om en disk ryker.\n\n**RAID 3**: Minst tre disker. Parallell aksess, veldig små striper, ned til en byte. Paritet lagres på en ekstra disk. Om en disk ryker kan informasjonen hentes ut fra de som er igjen. Optimalt høy overføringshastighet, men kun en forespørsel kan behandles av gangen.\n\n**RAID 4**: Minst tre disker. Paritet lagres på en ekstra disk. Store striper, sektor eller blocks. Om en disk ryker kan informasjonen hentes ut fra de som er igjen. Kan behandle flere forespørsler samtidig. Bra for servere som får mange forespørsler.\n\n**RAID 5**: Minst tre disker. Paritet lagres fordelt på diskene. Store striper, sektor eller blocks. Om en disk ryker kan informasjonen hentes ut fra de som er igjen.\n\nRAID kan implementeres i software, det vil si av OS, eller i hardware ved en dedikert RAID-controller på hovedkortet. RAID 0, 1 og 5 er implementert i Windows 2003 server."}
{"identifier": "os15.13.1", "section_id": "15.13.1", "section_title": "Ytelse", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION0001613100000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.13.1 Ytelse\n\nVed såkalt striping av diskene økes ytelsen ved både lesing og skriving av filer. Dette fordi en stor fil deles i striper som fordeles på diskene. Innholdet av en stor fil vil være fordelt på alle diskene og data kan både leses fra og skrives til diskene i parallell og da går det mye raskere."}
{"identifier": "os15.13.2", "section_id": "15.13.2", "section_title": "Paritet", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION0001613200000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.13.2 Paritet\n\nHvis man har en samling bits (for eksempel en byte, 8 bit) som har verdi en eller null, kan man telle antall enere. Hvis antall enere er like (0, 2, 4, , har samlingen av bits like paritet. Hvis antall enere er odde (1, 3, 5, ), sier vi at samlingen av bits har odde paritet. Dette kan brukes til en meget enkel feilsjekking, hvis man sender et antall bit over et nettverk og pariteten har endret seg på veien, kan man konkludere med at minst ett bit må ha endret verdi. I et RAID kan man ta et bit fra hver data-disk i RAID'et, regne ut pariteten og skrive den til en egen paritetsdisk. Hvis en av diskene i RAID'et crasher og alle dataene for denne disken går tapt, kan man bruke dataene på paritetsdisken for å finne ut verdien på de tapte bit'ene. Hvis pariteten for de igjenværende diskene er den samme som den lagrede pariteten, har en null gått tapt. Hvis pariteten for de igjenværende diskene er forskjellig fra den lagrede pariteten, har en ener gått tapt. Dermed kan hver bit på den tapte disken gjenskapes. I RAID 3 er stripene små, ned til en byte. I RAID 4 og 5 er stripene et antall sektorer. I begge tilfeller er prinsippet for redundans det samme. Bergningen av paritet må gjøres når det skrives til diskene. Det kan gjøres hurtig, fordi XOR-porter kan regne ut paritet i paralell for 32 eller 64 bit av gangen, for henholdsvis 32 og 64 bits prosessorer. Det finnes også hardware-RAID, egne enheter som gjør disse paritetsberegningene og styrer RAID'et uavhengig av prosessoren."}
{"identifier": "os15.13.3", "section_id": "15.13.3", "section_title": "Eksempel på paritetsberegning", "source_category": "os", "source_id": "15", "source_title": "Disker og filsystemer", "anchor": "SECTION0001613300000000000000", "source": "os/Forelesning/os/node16.html", "text": "## 15.13.3 Eksempel på paritetsberegning\n\nAnta at vi i et RAID 3 striper disken bit for bit og bruker 5 disker. Disken med paritet lagrer da den samlede pariteten for bit'ene for de 4 andre diskene; en ener om antallet er odde og en null om antallet er like:\n\n| disk 1 | disk 2 | disk 3 | disk4 | paritets-disk |\n|------|------|------|-----|-------------|\n| 0 | 1 | 0 | 1 | 0 |\n| 1 | 0 | 1 | 1 | 1 |\n| 0 | 0 | 1 | 1 | 0 |\n| 1 | 1 | 0 | 0 | 0 |\n| 0 | 0 | 1 | 0 | 1 |\n| 1 | 1 | 1 | 1 | 0 |\n\nHvis nå for eksempel den 2. disken crasher og alle dataene fra den blir borte, vil RAID'et se slik ut:\n\n| disk 1 | disk 2 | disk 3 | disk4 | paritets-disk |\n|------|------|------|-----|-------------|\n| 0 |  | 0 | 1 | 0 |\n| 1 |  | 1 | 1 | 1 |\n| 0 |  | 1 | 1 | 0 |\n| 1 |  | 0 | 0 | 0 |\n| 0 |  | 1 | 0 | 1 |\n| 1 |  | 1 | 1 | 0 |\n\nHvordan kan man nå trylle frem igjen dataene på den ødelagte disk2 og legge dem inn på en ny disk? Vi ser da at dataene fra denne disken kan trylles frem igjen ved å bruke paritetsdisken og reglene nevnt over: Hvis pariteten for de igjenværende diskene er den samme som den lagrede pariteten, har en null gått tapt. Hvis pariteten for de igjenværende diskene er forskjellig fra den lagrede pariteten, har en ener gått tapt. Prøv selv!"}
{"identifier": "os14.2", "section_id": "14.2", "section_title": "Dynamisk allokering", "source_category": "os", "source_id": "14", "source_title": "Internminne i praksis", "anchor": "SECTION000152000000000000000", "source": "os/Forelesning/os/node15.html", "text": "## 14.2 Dynamisk allokering\n\nEt program kan be om at det settes av minnet til sine variabler før det starter, men det kan også be om at minne allokeres dynamisk. F. eks. vil et Java-statement\n\n```\nPCB = new process;\n```\n\ngjøre at denne plassen settes av i minnet først når programmet utfører det. Programmet tildeles page for page med minne. I C++ må man eksplisitt delete objekter som ikke er i bruk lenger for å frigjøre minne, JVM utfører dette automatisk (garbage collection). Den delen av et programs minne som inneholder variabler og data og som dynamisk kan øke og minke i størrelse, kalles ofte heap. Variabler i funskjoner/metoder som forsvinner og ikke kan brukes mer etter at kallet på funksjonen er ferdig, legges på stack."}
{"identifier": "os14.3", "section_id": "14.3", "section_title": "VIRT, RES og SHR i top", "source_category": "os", "source_id": "14", "source_title": "Internminne i praksis", "anchor": "SECTION000153000000000000000", "source": "os/Forelesning/os/node15.html", "text": "## 14.3 VIRT, RES og SHR i top\n\nHvis man kompilerer og kjører følgendeC- program på en Linux-maskin, vil man kunne observere hvordan størrelsene VIRT, RES og SHR endrer seg.\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n\n#define S 1024*1024\n\nint staticArr[S];\nint main()\n{\n   int i, size,d;\n\n   printf(\"\\nStørrelse: \");\n   scanf(\"%d\",&size);\n   printf(\"Lager int  array med %d elementer\\n\",size);\n\n   int *array = malloc(size * sizeof(int));\n   \n   printf(\"\\nKlar til å bruke arrayet:\");\n   scanf(\"%d\",&d);\n\n   for(i=0;i < size;i++)\n     {\n\tarray[i] = i;\n     }\n\n   printf(\"\\nVenter på å avslutte: \");\n   scanf(\"%d\",&size);\n}\n```\n\nProgrammet starter med å definere et statisk array med 1 M elementer som hver er på 4 byte, altså 4MiB. Både et slikt statisk array og et dynamisk array som lages med malloc() vil legges på heap.\n\nStørrelsen VIRT er beskrevet slik i manualsiden for top:\n\n```\nVIRT  --  Virtual Memory Size (KiB)\n          The total amount of virtual memory used by the task.  It includes all code, data and shared libraries\n          plus pages that have been swapped out and pages that have been mapped but not used.\n```\n\nVIRT er altså all det internminnet som prosessen kan tenkes å bruke, men som ikke nødvendigvis ligger i RAM. Det som ikke ligger i RAM, ligger i SWAP-området på disken.\n\nHvis vi kjører programmet med bare ett element i arrayet, får vi\n\n```\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                        \n19924 haugerud  20   0    4352    652    584 S   0,0  0,0   0:00.00 a.out\n```\n\nmens hvis vi øker størrelsen til 1024*1024 som vist i koden over, kompilerer og kjøre på nytt, viser top:\n\n```\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                        \n25448 haugerud  20   0    8448    640    572 S   0,0  0,0   0:00.00 a.out\n```\n\nOg endringen i VIRT er 8448 - 4352 = 4096 og altså nøyaktig 4MiB = 4*1024*1024. Denne størrelsen er definert når programmet starter, men man kan dynamisk legge til mer internminnet som vist i koden over med funksjonen malloc. Hvis vi dynamisk legger til et nytt array med 1 M elementer\n\n```\nrex:~/mem/a$ ./a.out \n\nStørrelse: 1048576\nLager int  array med 1048576 elementer\n```\n\nvil vi se på top at VIRT øker\n\n```\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                        \n25448 haugerud  20   0   12548    640    572 S   0,0  0,0   0:00.00 a.out\n```\n\nog økningen er 12548 - 8448 = 4100 KiB som er som forventet ganske nøyaktig 4MiB.\n\nMen som vi ser endres ikke RES i det hele tatt av dette og det er fordi disse array-elementene bare er allokert i det virtuelle minnerommet og ikke fysisk lastet inn i RAM. RES er definert på følgende måte:\n\n```\nRES  --  Resident Memory Size (KiB)\n          The non-swapped physical memory a task is using.\n```\n\nRES er altså den delen av prosessens internminnet som akkurat nå ligger fysisk inne i RAM. Når vi lar programmet fortsette å kjøre og tilordne verdier til alle elementene i det dynamiske arrayet, gir top dette:\n\n```\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                        \n25448 haugerud  20   0   12548   5256   1276 S   0,0  0,0   0:00.00 a.out\n```\n\nVi ser at RES øker med litt over 4MiB som først og fremst skyldes at hele arrayet nå lastes inn i RAM.\n\nStørrelsen SHR er i top definert som\n\n```\nSHR  --  Shared Memory Size (KiB)\n         The  amount  of shared memory available to a task, not all of which is typically resident.  It simply\n         reflects memory that could be potentially shared with other processes.\n```\n\nSHR er den mengden av internminnet som det kan være mulig å dele med andre prosesser; merk den ligger ikke nødvendigvis i RAM nå."}
{"identifier": "os14.4", "section_id": "14.4", "section_title": "Noen minne-begreper", "source_category": "os", "source_id": "14", "source_title": "Internminne i praksis", "anchor": "SECTION000154000000000000000", "source": "os/Forelesning/os/node15.html", "text": "## 14.4 Noen minne-begreper\n\n**Soft miss**: page-referanse er ikke i TLB; må hentes fra internminnet\n\n**Hard miss**: = page fault. En page mangler i minnet(og i TLB); må hentes fra disk\n\n**Major fault**: = page fault. En page mangler i minnet(og i TLB); må hentes fra disk\n\n**Minor fault**: = En page mangler i page-tabellen i RAM og må lages. Må IKKE hentes fra disk\n\n**Dirty page**: En side som har blitt endret slik at den må skrives til disk om den må ut av minnet\n\n**working set**: (Windows) Det sett av sider som en prosess har brukt nylig\n\n**RES**: (Linux) De sider som nå er lastet inn (RESident) i fysisk RAM.\n\n**Segment**: En logisk del av et programs minne, data, programtekst, stack-segmenter\n\n**buffer cache**: Del av minnet som brukes som filsystem-cache"}
{"identifier": "os14.5", "section_id": "14.5", "section_title": "RAM-test", "source_category": "os", "source_id": "14", "source_title": "Internminne i praksis", "anchor": "SECTION000155000000000000000", "source": "os/Forelesning/os/node15.html", "text": "## 14.5 RAM-test\n\n```\nrex:~/mem/ramsmp-3.5.0$ ./ramsmp -b 1\nRAMspeed/SMP (GENERIC) v3.5.0 by Rhett M. Hollander and Paul V. Bolotoff, 2002-09\n\n8Gb per pass mode, 2 processes\n\nINTEGER & WRITING         1 Kb block: 16376.46 MB/s\nINTEGER & WRITING         2 Kb block: 17503.79 MB/s\nINTEGER & WRITING         4 Kb block: 16018.84 MB/s\nINTEGER & WRITING         8 Kb block: 17191.61 MB/s\nINTEGER & WRITING        16 Kb block: 17629.32 MB/s\nINTEGER & WRITING        32 Kb block: 17232.47 MB/s\nINTEGER & WRITING        64 Kb block: 12087.30 MB/s\nINTEGER & WRITING       128 Kb block: 10896.62 MB/s\nINTEGER & WRITING       256 Kb block: 11532.74 MB/s\nINTEGER & WRITING       512 Kb block: 11663.74 MB/s\nINTEGER & WRITING      1024 Kb block: 12726.65 MB/s\nINTEGER & WRITING      2048 Kb block: 6481.25 MB/s\nINTEGER & WRITING      4096 Kb block: 2418.77 MB/s\nINTEGER & WRITING      8192 Kb block: 2152.39 MB/s\nINTEGER & WRITING     16384 Kb block: 2141.66 MB/s\nINTEGER & WRITING     32768 Kb block: 2137.81 MB/s\n```\n\n[Intel Core Duo 6600](https://www.cpu-world.com/CPUs/Core_2/Intel-Core%202%20Duo%20E6600%20HH80557PH0564M%20%28BX80557E6600%29.html)"}
{"identifier": "os14.6", "section_id": "14.6", "section_title": "free", "source_category": "os", "source_id": "14", "source_title": "Internminne i praksis", "anchor": "SECTION000156000000000000000", "source": "os/Forelesning/os/node15.html", "text": "## 14.6 free\n\n```\nrex:~/www$ free -m\n             total       used       free     shared    buffers     cached\nMem:          2011       1453        557          0         14        551\n-/+ buffers/cache:        887       1123\nSwap:         1937        683       1253\n```"}
{"identifier": "os14.7", "section_id": "14.7", "section_title": "top", "source_category": "os", "source_id": "14", "source_title": "Internminne i praksis", "anchor": "SECTION000157000000000000000", "source": "os/Forelesning/os/node15.html", "text": "## 14.7 top\n\n```\ntop - 01:50:33 up 78 days, 11:02, 35 users,  load average: 0.19, 0.51, 0.61\nTasks: 408 total,   1 running, 399 sleeping,   0 stopped,   8 zombie\nCpu(s):  0.8%us,  0.7%sy,  0.0%ni, 98.5%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st\nMem:   2059344k total,  1501056k used,   558288k free,    14572k buffers\nSwap:  1983988k total,   700372k used,  1283616k free,   565164k cached\n\n  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                  \n23123 haugerud  20   0  2676 1428  932 R    0  0.1   0:00.21 top                                                       \n    1 root      20   0  2932 1232  792 S    0  0.1   0:30.41 init                                                      \n    2 root      20   0     0    0    0 S    0  0.0   0:00.02 kthreadd                                                  \n    3 root      RT   0     0    0    0 S    0  0.0   0:32.07 migration/0                                               \n    4 root      20   0     0    0    0 S    0  0.0   0:35.21 ksoftirqd/0\n```"}
{"identifier": "os14.8", "section_id": "14.8", "section_title": "Eksempler på minnebruk", "source_category": "os", "source_id": "14", "source_title": "Internminne i praksis", "anchor": "SECTION000158000000000000000", "source": "os/Forelesning/os/node15.html", "text": "## 14.8 Eksempler på minnebruk\n\n```\n#include <stdio.h>    \n\nint array[200000000];\nmain(int argc, char *argv[]){\n   int i,j;\n   for(i = 0;i < 2000000;i++){\n      j = i*100;\n      array[i] = i;\n   }\n}\n```\n\n```\n#include <stdio.h>    \n\nint array[10000][10000];\nmain(int argc, char *argv[]){\n   int i,j;\n   for(i = 0;i < 10000;i++){\n      for(j = 0;j < 10000;j++){\n\t array[i][j] = 5;\n      }\n   }\n}\n```"}
{"identifier": "os4.2", "section_id": "4.2", "section_title": "Simulerings-CPU og RAM", "source_category": "os", "source_id": "4", "source_title": "C, maskinkode og assembly", "anchor": "SECTION00052000000000000000", "source": "os/Forelesning/os/node5.html", "text": "## 4.2 Simulerings-CPU og RAM\n\nI maskinkoden som summerer opp summen S = 1 + 2 + 3 ved hjelp av en løkke som er mulig å få til på grunn av branch-kontrollen, foregår alle beregninger inne i CPU-en. Det vil si at alle tallene først legges inn i registerne og at alle resultatene fra mellomregninger før man kommer frem til den endelige summen ligger i registerne lokalt i CPU. Slik er det for virkelige CPU-er laget av Intel og AMD også. Registerne er meget hurtige, men det er et begreneset antall man kan ha inne i en CPU. En alternativ lagringsplass for beregningsdata er internminne eller RAM. Her er det plass til Milliarder av bytes (8 bit) med data, men det tar omtrent ti ganger så lang tid å lagre noe i RAM. Det optimale er derfor å alltid bruke registre for å lagre midlertidige data, slik som den stadig økende summen i eksempelet vi ser på. Men hvordan høynivåkoden oversettes til maskinkode avgjøres av kompilatoren. Dette er et program som systematisk kan oversette alle mulige varianter av høynivåkode til maskinkode som utfører det som høynivåkoden ber om når det kompilerte programmet kjøres i en datamaskin. Detaljer som om beregningsdata skal lagres i registere eller i RAM, avgjøres av kompilatoren. Men som vi skal se senere er det mulig å be kompilatoren om å lage maskinkode som skal gå hurtigst mulig. Og hvis man gjør det når man kompilerer vil kompilatoren lage kode som lagrer alle mellomregninger i registerne og først skriver resultatene til variabler i RAM når beregningene er fullført.\n\nNår man deklarerer variabler som for eksempel i et C-program på følgende måte\n\n```\nint sum=0;\nint i;\n```\n\nvil det settes av 4 byte i RAM til denne variabelen og der initialiseres den til å ha verdien 0. RAM er ganske enkelt et enormt array av bytes som ligger etterhverandre. Den minste lagerenheten er en byte som består av 8 bit. At en integer skal være 32 bit er en konvensjon for programmeringsspråket C, men disse konvensjonene kan variere mellom forskjellige språk og også mellom forskjellige implementasjoner av C. Andre konvensjoner er at en long long int bruker 8 byte og at flytt-tall lagringsenhetene float og double er henholdsvis 32 og 64 bit lange."}
{"identifier": "os4.3", "section_id": "4.3", "section_title": "C-programmering", "source_category": "os", "source_id": "4", "source_title": "C, maskinkode og assembly", "anchor": "SECTION00053000000000000000", "source": "os/Forelesning/os/node5.html", "text": "## 4.3 C-programmering\n\nSiden Dennis Ritchie på starten av 70-tallet laget programmeringsspråket C, har det vært tett knyttet til Unix-operativsystemer. De fleste Unix-programmer er skrevet i C og de fleste systemkall har korresponderende C-funksjoner med samme navn. Vi skal her bruke C-program som eksempler på høynivåkode og se hvordan de må kompileres til maskinkode for å kunne kjøres av en datamaskin."}
{"identifier": "os4.3.1", "section_id": "4.3.1", "section_title": "hello.c", "source_category": "os", "source_id": "4", "source_title": "C, maskinkode og assembly", "anchor": "SECTION00053100000000000000", "source": "os/Forelesning/os/node5.html", "text": "## 4.3.1 hello.c\n\nEt `Hello World` C-program ser slik ut:\n\n```\n/* filnavn: hello.c */\n\n#include <stdio.h>\n\nint main()\n{\n   printf(\"Hello world!\\n\");\n}\n```\n\nDen første linjen inkluderer standard-biblioteket `stdio.h` som blant annet inneholder funksjoner for å kunne skrive til et terminal-vindu. Alle C-program har en main-funksjon. Den kan inneholde all koden eller inneholde kall til andre funksjoner. For å kunne kjøre et C-program, må det først kompileres til maskinkode og det kan man i et Linux-shell gjøre slik:\n\n```\n$ gcc hello.c\n```\n\nDet lages da maskinkode som lagres i en fil ved navn `a.out` . Den kan kjøres med\n\n```\n$ ./a.out\nHello world!\n```\n\nFilen `a.out` inneholder maskinkode i form av maskin-instruksjoner for en prosessor med såkalt x86-arkitektur som ble introdusert av Intel i 1978. Det finnes mange forskjellige CPU-arkitekturer, som ARM, SPARC og PowerPC, men x86 er den som nå brukes i nesten alle PCer og servere. Andre arkitekturer har andre maskin-instruksjoner og de kan derfor ikke kjøre maskinkode for x86, slik som innholdet i `a.out` . Maskinkode for Hello World er på mange tusen byte og den inneholder blant annet kode for å kommunisere med operativsystemet. Dette er nødvendig for eksempel for å kunne skrive ut noe. Man kan se på direkte på koden og følgende er deler av innholdet:\n\n```\n$ xxd a.out \n00000000: 7f45 4c46 0201 0100 0000 0000 0000 0000  .ELF............\n00000010: 0200 3e00 0100 0000 3004 4000 0000 0000  ..>.....0.@.....\n00000020: 4000 0000 0000 0000 d819 0000 0000 0000  @...............\n00000030: 0000 0000 4000 3800 0900 4000 1f00 1c00  ....@.8...@.....\n\n00000230: 0100 0000 0000 0000 2f6c 6962 3634 2f6c  ......../lib64/l\n00000240: 642d 6c69 6e75 782d 7838 362d 3634 2e73  d-linux-x86-64.s\n00000250: 6f2e 3200 0400 0000 1000 0000 0100 0000  o.2.............\n00000260: 474e 5500 0000 0000 0200 0000 0600 0000  GNU.............\n\n000005b0: f3c3 0000 4883 ec08 4883 c408 c300 0000  ....H...H.......\n000005c0: 0100 0200 4865 6c6c 6f20 776f 726c 6421  ....Hello world!\n000005d0: 0000 0000 011b 033b 3000 0000 0500 0000  .......;0.......\n```\n\nDeler av programmet inneholder data, som strengen `Hello world!` og andre deler inneholder maskin-instruksjoner. Disse tilsvarer på alle måter maskin-instruksjonene i den simulerte maskinen vi har sett på. Den hadde kun 8-bits instruksjoner, x86-instruksjoner er av variabel lengde mellom 8 og 48 bit. Etterhvert skal vi se på Assembly-kode og der korresponderer hver x86 assembly-instruksjon som ADD, MOV, CMP, JNE osv. til en bestem maskin-instruksjon. Dette er også helt tilsvarende som i CPU-simuleringen."}
{"identifier": "os4.3.2", "section_id": "4.3.2", "section_title": "Et C-program som summerer", "source_category": "os", "source_id": "4", "source_title": "C, maskinkode og assembly", "anchor": "SECTION00053200000000000000", "source": "os/Forelesning/os/node5.html", "text": "## 4.3.2 Et C-program som summerer\n\nTidligere oversatte vi høynivåkode, en for-løkke med summering, til maskinkode for den simulerte CPUen. Den prosessen vi da gjennomførte, er det samme som gcc-kompilatoren gjorde for C-programmet over. Følgende er et C-program vi kaller `sum.c` som utfører den samme beregningen. Vi kunne skrevet all koden i main-funksjonen, men lager en egen funksjon som vi kaller `sum()` for enklere å kunne analysere hva som skjer i denne spesielle kode-biten:\n\n```\n/* filnavn: sum.c */\n\n#include <stdio.h>\n\nint sum()\n{\n   int S=0,i;\n   for(i=0;i<4;i++)\n   {\n      S = S + i;\n   }\n   return(S);\n}\n\nint main()\n{\n   int Sum;\n   Sum = sum();\n   printf(\"Sum = %d \\n\",Sum);\n}\n```\n\nVariabler må deklareres i C. Hvis man ikke definerer funksjonen før main(), kan man få en warning fra gcc. Man kan kompilere og kjøre programmet med\n\n```\n$ gcc sum.c -o sum\n$ ./sum\nSum = 6\n```\n\nOpsjonen `-o` brukes til å gi det kjørbare programmet et annet navn enn default verdi `a.out` ."}
{"identifier": "os4.3.3", "section_id": "4.3.3", "section_title": "Kompilering av C-funksjoner", "source_category": "os", "source_id": "4", "source_title": "C, maskinkode og assembly", "anchor": "SECTION00053300000000000000", "source": "os/Forelesning/os/node5.html", "text": "## 4.3.3 Kompilering av C-funksjoner\n\nNår programmet over kompileres, lages det først maskinkode av C-koden i `sum.c` og så linkes denne koden sammen med kode fra standard-biblioteket `stdio.h` til ferdig maskinkode som er klar til å lastes inn i RAM og kjøres. Det er også mulig å legge en C-funksjon i en egen fil og så kompilere den til en egen maskinkode-fil. Hvis vi kaller følgende fil `sumFunksjon.c`\n\n```\n/* filnavn: sumFunksjon.c */\n\nint sum()\n{\n   int S=0,i;\n   for(i=0;i<4;i++)\n   {\n      S = S + i;\n   }\n   return(S);\n}\n```\n\nkan vi kompilere den med\n\n```\n$ gcc -c sumFunksjon.c -o funksjon\n```\n\nOpsjonen `-c` gir kompilatoren `gcc` beskjed om å ikke linke programmet, men bare kompilere det og legge maskinkoden i filen `funksjon` . Deretter kan vi lage en fil til som vi kan kalle `sumMain.c`\n\n```\n/* filnavn: sumMain.c */\n\n#include <stdio.h>\n\nextern int sum();\n\nint main(void)\n{\n   int summ;\n   summ = sum();\n   printf(\"Sum = %d \\n\",summ);\n   \n}\n```\n\nså kan vi kompilere den med\n\n```\n$ gcc -c sumMain.c -o main\n```\n\nog lage en maskinkode-fil med navn `main` . Til slutt kan vi skjøte sammen og be kompilatoren om å linke disse to filene sammen til et kjørbart sum-program og kjøre det:\n\n```\n$ gcc funksjon main -o sum\n$ ./sum\nSum = 6\n```\n\nVi kunne gjort disse tre operasjonene, kompilering av de to programmen og linking, i en operasjon med\n\n```\n$ gcc sumFunksjon.c sumMain.c -o sum\n```\n\nmen vi velger å gjøre det slik for å kunne erstatte beregningene i `funksjon` med Assembly-kode. Maskinkoden i `funksjon` tilsvarer den maskinkoden vi la inn i CPU-simuleringen, dermed kan vi i detalj sammenligne x86-Assembly med vårt eget assembly-språk for den simulerte CPUen."}
{"identifier": "os4.4", "section_id": "4.4", "section_title": "Assembly", "source_category": "os", "source_id": "4", "source_title": "C, maskinkode og assembly", "anchor": "SECTION00054000000000000000", "source": "os/Forelesning/os/node5.html", "text": "## 4.4 Assembly\n\n[Kompendiet i INF2270 datamaskinarkitektur på UiO](https://www.uio.no/studier/emner/matnat/ifi/INF2270/v16/pensumliste/kompendium-inf2270.pdf) inneholder nyttig informasjon, blan annet alle X86 instruksjonene. Forelesningsnotatene til Erik Hjelmås, OS-kompendium2018.pdf, som ligger under filer i Canvas, inneholder noen avsnitt om Assembly.\n\nDet finnes mange andre gode kilder på nettet, blant annet denne [introduksjonen til Assembly.](https://www.cs.oberlin.edu/~bob/cs331/Notes%20on%20x86-64%20Assembly%20Language.pdf)\n\nVi skal ikke gå veldig dypt inn i x86-assembly, men ved hjelp av noen få av de tilgjengelige Assembly-instruksjonene skrive kode som tilsvarer noen enkel eksempler på høynivåkode.\n\nIdag trenger vi bare å kjenne noen få assembly-instruksjoner som ligner på dem vi lagde for simulerings-CPU-en:\n\n| Instruksjon | source | destination | resultat |\n|-----------|------|-----------|--------|\n| mov | s | d | verdien av s legges i d |\n| add | s | d | d = d + s |\n| cmp | s | d | sammenlign (compare) s og d |\n| jne | label |  | Jump Not Equal, hvis s ulik d i forrige linje, hopp til label |\n\nHer kan s være en konstant (et tall skrevet som $34 for tallet 34), et register ( `%rax, %rbx, %rcx, %rdx` ) eller en referanse til et sted i RAM. Det siste kan være definert som et variabelnavn eller på formen `-4(%rbp)` , som betyr fire byte fra starten av stack for programmet. Stack er et område i RAM der variabler for metoder lagres og rbp står for Register Base Pointer og peker på starten av stacken."}
{"identifier": "os4.4.1", "section_id": "4.4.1", "section_title": "Summerings-funksjonen skrevet i Assembly", "source_category": "os", "source_id": "4", "source_title": "C, maskinkode og assembly", "anchor": "SECTION00054100000000000000", "source": "os/Forelesning/os/node5.html", "text": "## 4.4.1 Summerings-funksjonen skrevet i Assembly\n\nFølgende x86-Assembly kode utfører nøyaktig det samme som maskinkoden i filen `funksjon` i avsnittet over. Assemblerkode ligger svært tett opp til den maskinkoden som kjører i CPU-en man programmerer for og koden kan kun kjøre på CPUer som har nøyaktig den arkitekturen og dermed de maskininstruksjonene som koden inneholder. Nesten alle data som instruksjonene i maskinkode virker på er lagret i selve CPU-en og lagringsenhetene for disse dataene er registre. I vår simulerte CPU kalte vi registrene R0, R1, R2 og R3. I x86-arkitekturen finnes det fire generelle registre som er svært mye brukt i all Assembly-programmering og de kalles ax, bx, cx og dx. Opprinnelig ble disse betegnelsene brukt om 16-bits registre på den tiden dette var den vanlige størrelsen for en x86-CPU. Ganske snart økte størrelsen til 32-bit og disse registrene ble da betegnet eax, ebx, etc. En moderne 64-bits prosessor har 64-bits registre og de kalles rax, rbx, rcx og rdx og det er disse vi bruker i koden nedenfor. Når denne koden assembles til maskinkode, vil maskinkoden utføre den samme beregningen som maskinkoden i filen `funksjon` i forrige avsnitt som regner ut summen S.\n\nFølgende kode utgjør Assembly-programmet `as.s` :\n\n```\n# filnavn: as.s\n\n.globl sum \n# C-signatur:int sum ()\n\n# 64 bit assembly\n\n# b = byte (8 bit)\n# w = word (16 bit, 2 bytes)\n# l = long (32 bit, 4 bytes)\n# q = quad (64 bit, 8 bytes)\n\n# Opprinnelige 16bits registre: ax, bx, cx, dx\n# ah, al 8 bit\n# ax 16 bit\n# eax 32 bit\n# rax 64 bit\n\nsum:                 # Standard\n\nmov   $3, %rcx       # 3 -> rcx, maks i løkke\nmov   $1, %rdx       # 1 -> rdx, tallet i økes med for hver runde\nmov   $0, %rbx       # 0 -> rbx, variabelen i lagres i rbx\nmov   $0, %rax       # 0 -> rax, summen = S \n\n# løkke\nstart: # label\nadd  %rdx, %rbx # rbx = rbx + rdx (i++) \nadd  %rbx, %rax # rax = rax + rbx (S = S + i)\ncmp  %rcx, %rbx # compare, er i = 3?\njne  start      # Jump Not Equal til start:\n\nret  # Verdien i rax returneres\n```\n\nAssembly-programmet `as.s` utfører nøyaktig det samme som C-programmet `sumFunksjon.c` listet øverst i avsnitt 4.3.3 .\n\nOm vi sammenligner med summerings-koden for den simulerte CPU-en i avsnitt 3.7, vil man se at de åtte Assembly-linjene etter `sum:` tilsvarer linje for linje koden der (om man ser bort ifra linjen som inneholder `start:` . Registeret `%rcx` tilsvarer R0, `%rdx` tilsvarer R1, `%rbx` tilsvarer R2 og `%rax` tilsvarer R3. Vi har skrevet programmet slik at summen S lagres i nettopp registeret `%rax` fordi verdien som ligger i nettopp `%rax` er den verdien som returneres til main-funksjonen som utfører kallet på funksjonen `sum()` .\n\nFor å kunne kjøre funksjonen vi har skrevet i Assembly-programmet `as.s` må man be gcc-kompilatoren om å assemble den. Det kan man gjøre slik:\n\n```\n$ gcc -c as.s -o as\n```\n\nDette gjør at gcc oversetter Assembly-koden til maskinkode og lagrer denne maskinkoden i filen `as` . Prosessen med å assemble Assembly-kode til maskinkode er mye enklere enn kompilering fordi det er en ganske enkel oversettelse som stort sett skjer linje for linje. For eksempel vil en linje som inneholder instruksjonen ADD ganske enkelt oversettes til oppcode som inneholder hvilket nummer instruksjonen ADD har i x86-arkitekturen etterfulgt av rett rekkefølge på registrene som er involvert. Helt på samme måte som vi gjorde med koden for den simulerte CPUen.\n\nTil slutt kan man så linke maskinkoden i filen `as` sammen med main-maskinkoden for å få et kjørbart program:\n\n```\n$ gcc main as -o sum\n$ ./sum\nSum = 6\n```\n\npå samme måte som med C-programmene, kunne man også gjort disse tre operasjonene, kompilering av main, assembly av `as.s` og linking av de to, i en operasjon:\n\n```\n$ gcc sumMain.c as.s -o sum\n$ ./sum\nSum = 6\n```\n\nMan kunne også skrive hele hovedprogrammet i Assembly, men for å forenkle kodingen, har vi konsentrert oss om kun den koden som utføres av sum-funksjonen.\n\nEt viktig poeng er at maskinkoden `as` laget fra Assembly funksjonelt sett utfører den samme beregningen som maskinkoden `funksjon` som kompilatoren lagde. Men det finnes mange mulige varianter av både Assembly-kode og maskinkode som utfører nøyaktig det som høynivåkoden sier skal gjøres. Men hva som er den optimale maskinkoden som både er raskest og tar minst plass, er langt fra opplagt. Veldig mye forsking og utvikling er blitt brukt på å lage kompilatorer som genererer best mulig maskinkode. Likevel kan gode Assembly-programmerer i noen tilfeller lage enda bedre kode enn en kompilator, spesielt om de har innsikt i nøyaktig hva som er hensikten med programmet."}
{"identifier": "os4.5", "section_id": "4.5", "section_title": "Assembly-kode generert av en kompilator", "source_category": "os", "source_id": "4", "source_title": "C, maskinkode og assembly", "anchor": "SECTION00055000000000000000", "source": "os/Forelesning/os/node5.html", "text": "## 4.5 Assembly-kode generert av en kompilator\n\nMan kan også be en kompilator om å stoppe kompileringen før den assembler koden til maskinkode. Det kan man med gcc få til med opsjonen -S og den lager da en fil med filendelse s som innholder Assembly-kode som tilsvarer den maskinkoden den ville laget om man bare kompilerte med opsjonen -c.\n\n```\n$ gcc -S sumFunksjon.c\n$ cat sumFunksjon.s\n\t.file\t\"sumFunksjon.c\"\n\t.text\n\t.globl\tsum\n\t.type\tsum, @function\nsum:\n.LFB0:\n\t.cfi_startproc\n\tpushq\t%rbp\n\t.cfi_def_cfa_offset 16\n\t.cfi_offset 6, -16\n\tmovq\t%rsp, %rbp\n\t.cfi_def_cfa_register 6\n\tmovl\t$0, -8(%rbp)\n\tmovl\t$0, -4(%rbp)\n\tjmp\t.L2\n.L3:\n\tmovl\t-4(%rbp), %eax\n\taddl\t%eax, -8(%rbp)\n\taddl\t$1, -4(%rbp)\n.L2:\n\tcmpl\t$3, -4(%rbp)\n\tjle\t.L3\n\tmovl\t-8(%rbp), %eax\n\tpopq\t%rbp\n\t.cfi_def_cfa 7, 8\n\tret\n\t.cfi_endproc\n.LFE0:\n\t.size\tsum, .-sum\n\t.ident\t\"GCC: (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\"\n\t.section\t.note.GNU-stack,\"\",@progbits\n$\n```"}
{"identifier": "os12.3", "section_id": "12.3", "section_title": "Mulige måter å takle kritiske avsnitt", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION000133000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.3 Mulige måter å takle kritiske avsnitt\n\n|   |   |   |\n|---|---|---|\n| A | Skru av scheduler før kritisk avsnitt. P1 kode: disableInterupts(); saldo = saldo - mill; enableInterupts(); OK for en OS-kjerne, men for farlig for brukerprosesser; de kan ta over styringen. | disableInterupts(); saldo = saldo - mill; enableInterupts(); |\n| disableInterupts(); saldo = saldo - mill; enableInterupts(); |  |  |\n| B | Bruke en form for lås som gjør at bare en prosess av gangen har tilgang til felles data. MUTual EXclusion = MUTEX = gjensidig utelukkelse mest brukt mange implementasjoner |  |"}
{"identifier": "os12.3.1", "section_id": "12.3.1", "section_title": "Linux-eksempel", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION000133100000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.3.1 Linux-eksempel\n\nFile-lock for Linux-mail: hvis filen\n\n```\n/var/mail/haugerud.lock\n```\n\neksisterer, kan inbox ikke leses/skrives til. *Sendmail og andre mailprogram \nlager denne filen før de skriver/leser mail og fjerner den når de er ferdige.*"}
{"identifier": "os12.3.2", "section_id": "12.3.2", "section_title": "Windows-eksempel", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION000133200000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.3.2 Windows-eksempel\n\nWin 32 API'et har to funksjonskall\n\n* EnterCriticalSection\n* LeaveCriticalSection\n\nsom applikasjoner kan kalle før og etter et kritisk avsnitt."}
{"identifier": "os12.4", "section_id": "12.4", "section_title": "Softwareløsning for P1/P2 med MUTEX", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION000134000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.4 Softwareløsning for P1/P2 med MUTEX\n\nTrenger to funksjoner `GetMutex(lock)` og `ReleaseMutex(lock)` som gjør at en prosess av gangen kan sette en lock. Da kan problemet løses med:\n\n```\nGetMutex(lock);      // henter nøkkel\nKritiskAvsnitt();    // saldo -= mill;\nReleaseMutex(lock);  // gir fra seg nøkkel\n```"}
{"identifier": "os12.4.1", "section_id": "12.4.1", "section_title": "Software-mutex, forsøk 1", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION000134100000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.4.1 Software-mutex, forsøk 1\n\n```\nstatic boolean lock = false; // felles variabel\n\nGetMutex(lock)\n   {\n   while(lock){} // venter til lock blir false\n   lock = true;\n   }\nReleaseMutex(lock)\n   {\n   lock = false;\n   }\n```\n\nDette burde sikre at to prosesser ikke er i kritisk avsnitt samtidig? Men hva om det skjer en Context Switch rett etter `while(lock){}` når P1 kjører?\n\nDa rekker ikke P1 å sette lock til true og P2 kunne gå inn i kritisk avsnitt, switches ut og P1 kan gå inn i kritisk avsnitt samtidig! Altså er ikke denne metoden korrekt. Dette er vanskelig å løse med en algoritme, som forsøkene i ukens oppgaver viser. Men Peterson-algoritmen gir en elegant løsning."}
{"identifier": "os12.5", "section_id": "12.5", "section_title": "Hardware-støttet mutex", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION000135000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.5 Hardware-støttet mutex\n\nI praksis brukes som oftest hardwarestøttede løsninger, for alle softwareløsninger innebærer mange instruksjoner i tillegg til busy-waiting, som koster CPU-tid. Et unntak er synkronisering av fler-CPU maskiner, SMP, symmetric multiprocessing og flerkjerneprosessorer. . Kan lages med en egen instruksjon **testAndSet** også kalt TSL(Test and Set Lock). Tester og setter en verdi i samme maskininstruksjon. Låser minne-bussen slik at ikke andre CPUer kan endre eller lese verdien. GetMutex() kan da implementeres med:\n\n```\nGetMutex(lock)\n   {\n    while(testAndSet(lock)) {}\n   }\n```\n\nog en context switch kan ikke ødelegge siden testen og endringen av lock skjer i samme instruksjon."}
{"identifier": "os12.6", "section_id": "12.6", "section_title": "X86-instruksjonen lock", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION000136000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.6 X86-instruksjonen lock\n\nEn annen X86 maskininstruksjon er `lock` som vi så på i forrige uke og som hindret race condition når kritisk avsnitt kun består av en enkelt instruksjon . Den vil for neste instruksjon som utføres låse minnebussen slik at instruksjoner på andre CPUer ikke samtidig kan hente eller lagre noe i RAM. Dette sikrer at instruksjonen etter lock som utføres på en variabel i minne får avsluttet hele sin operasjon uten at RAM endres. Dermed avverges problemet ved at det kritiske avsnittet fullføres før noen andre tråder slipper til."}
{"identifier": "os12.7", "section_id": "12.7", "section_title": "Semaforer", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION000137000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.7 Semaforer\n\nEn semafor er en integer S som signaliserer om en ressurs er tilgjengelig. To operasjoner kan gjøres på en semafor:\n\n```\nSignal(S): S = S + 1;                 # Kalles ofte Up(), V()\nWait(S): while(S <= 0) {}; S = S - 1; # Kalles ofte Down(), P()\n```\n\nSignal og wait må være uninterruptible og implementeres med hardwarestøtte eller i kjernen for å være atomiske(umulige å avbryte).\n\n**Binær semafor**: S = 0 eller 1 (som lock) (initialiseres til 1)\n\n**Teller semafor**: S vilkårlig heltall (initialiseres til antall ressurser)\n\nEn semafor kan brukes slik til å takle et kritisk avsnitt(må da initialiseres til 1):\n\n```\nWait(S);\nKritiskAvsnitt();\nSignal(S);\n```\n\nEn semafor som er initialisert til S=1 og som ikke kan bli større enn 1, omtales ofte som en mutex."}
{"identifier": "os12.7.1", "section_id": "12.7.1", "section_title": "Implementasjon av semafor i OS", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION000137100000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.7.1 Implementasjon av semafor i OS\n\nHvis en semafor implementeres i OS kan prosesser som venter legges i en egen kø, slik at de ikke bruker CPU mens de venter. Skjematisk sett kan implementasjonen gjøres slik:\n\n```\nSignal(S){\n   S = S + 1;\n   if(S <= 0){\n      wakeup(prosess);\n      # Sett igang neste prosess fra venteliste\n   }\n}\n```\n\n```\nWait(S){\n   S = S - 1;\n   if(S < 0){\n      block(prosess);\n      # Legg prosess i venteliste\n   }\n}\n```\n\nEn mp4 demo kan sees på [denne web-siden](https://www.cs.oslomet.no/~haugerud/os/demoer/mutex.mp4) som viser hvordan en implementasjon semaforer kan brukes av operativsystemet.\n\nEn flash-demo det samme kan sees på [denne web-siden](https://www.cs.oslomet.no/~haugerud/os/demoer/swf/sema.swf) ."}
{"identifier": "os12.8", "section_id": "12.8", "section_title": "Bruk av semafor i kritisk avsnitt", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION000138000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.8 Bruk av semafor i kritisk avsnitt\n\nAnta at semaforen S brukes til å beskytte en felles ressurs (variabel eller lignende) i et kritisk avsnitt. Prosess A og B må da kall Wait() før og Signal() etter kritisk avsnitt.\n\n| PA | PB-kode |\n|---|-------|\n| A1 | B1 |\n| A2 | Wait(S) |\n| A3 | K1 |\n| Wait(S) | K2 |\n| K1 | K3 |\n| K2 | Signal(S) |\n| K3 | B2 |\n| Signal(S) | B3 |\n| A4 | B4 |\n\nSlik beskyttes da det kritiske avsnittet (pilene angir Context Switch)\n\n| A | B | S |\n|---|---|---|\n|  | B1 | 1 |\n|  | Wait(S) | 0 |\n|  | K1 | 0 |\n| A1 |  | 0 |\n| A2 |  | 0 |\n| A3 |  | 0 |\n| Wait(S) | OS legger A i kø | -1 |\n|  | K2 | -1 |\n|  | K3 | -1 |\n|  | Signal(S) | 0 (A ut av kø) |\n|  | B2 | 0 |\n|  | B3 | 0 |\n|  | B4 | 0 |\n| K1 |  | 0 |\n| K2 |  | 0 |\n| K3 |  | 0 |\n| Signal(S) |  | 1 |\n| A4 |  | 1 |"}
{"identifier": "os12.9", "section_id": "12.9", "section_title": "Bruk av semafor til å synkronisere to prosesser", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION000139000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.9 Bruk av semafor til å synkronisere to prosesser\n\nEn semafor kan brukes til å synkronisere to prosesser. Anta prosess B (PB) må vente til prosess A (PA) er ferdig med noe i sin kode (kodelinje A3 i eksempelet), før den kan gå videre (med kodelinje B2 i eksempelet). Med en semafor S initialisert til 0, kan de da synkroniseres som følger:\n\n| PA | PB-kode |\n|---|-------|\n| A1 | B1 |\n| A2 | Wait(S) |\n| A3 | B2 |\n| Signal(S) | B3 |\n| A4 | B4 |\n\nPB kan ikke gjøre B2 før PA har satt S til 1. Pilene angir Context Switch. To mulige forløp. B når først fram:\n\n| A | B | S |\n|---|---|---|\n| A1 |  | 0 |\n| A2 |  | 0 |\n|  | B1 | 0 |\n|  | Wait(S) | -1 |\n| A3 |  | -1 |\n| Signal(S) |  | 0 |\n| A4 |  | 0 |\n|  | B2 | 0 |\n|  | B3 | 0 |\n\nA når først fram:\n\n| A | B | S |\n|---|---|---|\n| A1 |  | 0 |\n| A2 |  | 0 |\n| A3 |  | 0 |\n| Signal(S) |  | 1 |\n| A4 |  | 1 |\n|  | B1 | 1 |\n|  | Wait(S) | 0 |\n|  | B2 | 0 |\n|  | B3 | 0 |"}
{"identifier": "os12.10", "section_id": "12.10", "section_title": "Tanenbaums bruk av semaforer", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION0001310000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.10 Tanenbaums bruk av semaforer\n\nSemaforene som er omtalt i læreboka er de samme som omtalt her men Tanenbaum bruker betegnelsene up og down istedet for signal og wait. I tillegg blir semaforen ikke mindre enn null, den beholder verdien null om en prosess kaller wait, men prosessen blir satt i kø. Men når en annen prosess gjør signal vil prosessen som lå i kø vekkes og de to kallene nulle ut verdien på semaforen. I praksis blir effekten den samme. Men vår bruk av semaforen viser tydligere hvor mange som ligger i kø."}
{"identifier": "os12.11", "section_id": "12.11", "section_title": "Låse-mekanismer brukt i Linux-kjernen", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION0001311000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.11 Låse-mekanismer brukt i Linux-kjernen\n\nLinux-kjernen kan selv skru av og på interrupts for å sikre at korte kode-biter ikke blir avbrutt. Flere CPUer kan samtidig kjøre kjerne-kode, derfor er låser mye i bruk for å unngå at datastrukturer aksesseres samtidig.\n\n**Atomiske operasjoner**: Operasjonen kan ikke interruptes, eksempel: `atomic_inc_and_test()`\n\n**Spinlocks**: Mest brukt. For korte avsnitt. Bruker busy waiting.\n\n**Semaforer**: Kjernen sover til semaforen blir ledig igjen om den er opptatt.\n\n**Reader/Writer locks**: Samtidige prosesser kan lese, men bare en CPU av gangen kan skrive"}
{"identifier": "os12.12", "section_id": "12.12", "section_title": "Monitorer og Java synkronisering", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION0001312000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.12 Monitorer og Java synkronisering\n\nDet viser seg at i praksis er det vanskelig å skrive korrekte programmer med semaforer. Programmeren er helt overlatt til seg selv og ett signal for mye vil ødelegge hele systemet. Derfor ble konseptet monitor laget. Dette er en del av et programmeringsspråk og kan sørge for at hele metoder eller deler av kode synkroniseres. Kun en monitor-metode kan kjøre av gangen og dermed sikres synkronisering på et høyere nivå.\n\nDette er implementert i Java som har et eget statement `synchronized` for å synkronisere bruken av felles variabler. Alle java-objekter har en egen monitor-lås, tilsvarende variabelen lock vi har brukt i tidligere eksempler.\n\nNår man bruker statementet `synchronized()` må man derfor knytte det opp mot ett objekt og dermed bruke dette objektets lås. En integer verdi som variabelen `saldo` er ikke et objekt, i motsetning til for eksempel et array, og derfor lager vi et objekt som vi kaller `lock` for så å knytte `synchronized()` opp mot dette objektet:\n\n```\npublic static int saldo;                  // Felles variable, gir race condition\n    public static Object lock = new Object(); // Argumentet til synchronized må være et objekt\n```\n\nDermed kan man gjøre `synchronized(lock)` rundt en kodeblokk\n\n```\nsynchronized(lock)\n                   {\n                      saldo++;\n                   }\n```\n\nhvor man synkronisere mot lock-objektets lås.\n\nI praksis betyr det at om en tråd kjører instruksjoner inne i denne kodeblokken, vil andre tråder settes på vent om de prøver å kjøre det samme kodeavsnittet. Dette avsnittet er da et kritisk avsnitt. Det tilsvarer helt å kalle wait før og signal etter et kritisk avsnitt. Gjør man det med eksempelet fra forrige forelesning, tar beregningene lenger tid, men saldo blir 0 til slutt.\n\nSer man på java bytekoden, kan man se at koden som oppdaterer saldo da blir beskyttet i en monitor:\n\n```\n$ javap -private -c SaldoThread\n \n      17: getstatic     #17                 // Field lock:Ljava/lang/Object;\n      20: dup\n      21: astore_2\n      22: monitorenter\n      23: getstatic     #18                 // Field saldo:I\n      26: iconst_1\n      27: iadd\n      28: putstatic     #18                 // Field saldo:I\n```\n\nMan kan også definere hele metoder som synchronized. I Figure 2-35 i læreboka defineres i et eksempel metoden\n\n```\npublic synchronized void insert(int val)\n```\n\nDette forsikrer programmereren om at kun en tråd av gangen kan kjøre denne metoden.\n\nEn løsning på vårt problem kunne være å gjøre følgende:\n\n```\nprivate static synchronized void upSaldo()\n     {\n\tsaldo++;\n     }\n\n   private static synchronized void downSaldo()\n     {\n\tsaldo--;\n     }\n```\n\nog bruke disse metodene istedet for å endre variabelen direkte. Da ville også koden bli threadsafe og alltid gi saldo lik null til slutt."}
{"identifier": "os12.13", "section_id": "12.13", "section_title": "Message passing", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION0001313000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.13 Message passing\n\nEn annen metode for å sikre serialisering som også virker i distribuerte systemer er message passing. Konkurrerende tråder eller prosesser synkroniseres da ved å sende signaler til hverandre. En ulempe ved dette er at det generelt ikke er like effektivt som semaforer og monitorer."}
{"identifier": "os12.14", "section_id": "12.14", "section_title": "Dining Philosophers Problem", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION0001314000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.14 Dining Philosophers Problem\n\nDette er et klassisk synkroniseringsproblem og som ofte har blitt brukt for å demonstrere synkroniseringsteknikker som semaforer og monitorer. Fem filosofer sitter rundt et bord og har fem gafler på deling. Når filosofene ikke tenker spiser de, men de trenger to gafler for å kunne spise. Hvordan kan man skrive fem filosof-prosesser som kjører samtidig og samtidig unngå en situasjon hvor alle griper en gaffel og blir sittende og vente? Dette er en såkalt deadlock-tilstand, vranglås, og det må unngås når man har samtidige tråder.\n\nFilosoftilstander:\n\n* tenker (uten gafler)\n* Spiser spaghetti med 2 gafler\n\nTar opp en gaffel av gangen.\n\n**Problem**: Programmer en filosofprosess slik at 5 prosesser kan spise og tenke i tidsrom av varierende lengde og dele ressursene (gaflene) uten at deadlock (vranglås) kan oppstå.\n\nIllustrasjon:\nFra Tanenbaum: Lunch time in the Philosophy Department."}
{"identifier": "os12.15", "section_id": "12.15", "section_title": "Deadlock", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION0001315000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.15 Deadlock\n\nTo eller fler prosesser venter på hverandre, ingen kommer videre. Eks. 1: P1 venter på P2, P2 venter på P3 og P3 venter på P1 (sirkulær venting)\n\nEks. 2: Deadlock med to semaforer S1 og S2, initialisert til 1:\n\n| PA | PB-kode |\n|---|-------|\n| Wait(S1) |  |\n|  | Wait(S2) |\n| Wait(S2) |  |\n|  | Wait(S1) |\n| . | . |\n| . | . |\n| . | . |\n| Signal(S1) | Signal(S2) |\n| Signal(S2) | Signal(S1) |"}
{"identifier": "os12.16", "section_id": "12.16", "section_title": "Kriterier for at deadlock kan oppstå", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION0001316000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.16 Kriterier for at deadlock kan oppstå\n\n* Mutex: ressurser som ikke kan deles\n* En prosess kan beholde sine ressurser mens den venter på andre.\n* En prosess kan ikke tvinges til å gi opp sin ressurs (felles minne, disk, etc.)\n\nMed 1, 2 og 3 oppfylt, kan deadlock oppstå ved sirkulær venting! Mulige løsninger:\n\n* Forhindre. Internt i OS-kjernen må deadlock forhindres. Umulig å forhindre bruker-deadlock.\n* Løse opp deadlock. Generelt vanskelig.\n* Ignorere problemet (mest vanlig metode for et OS)."}
{"identifier": "os12.17", "section_id": "12.17", "section_title": "Tråder i Python", "source_category": "os", "source_id": "12", "source_title": "Mutex, Semaforer, Deadlock", "anchor": "SECTION0001317000000000000000", "source": "os/Forelesning/os/node13.html", "text": "## 12.17 Tråder i Python\n\nGlobal Interpreter Lock (GIL) er en mekanisme som brukes av CPython, den mest populære implementeringen av Python, for å sikre at kun én tråd utfører bytekodeinstruksjoner om gangen. Dette låser hovedinterpreterløkken, slik at tråder ikke kan utføre Python-bytecode parallelt, selv på en flertrådet prosessor.\n\nimport multiprocessing, gir en løsning som lar deg opprette prosesser, som hver har sin egen Python-interpreter og minneplass. Dette omgår GIL og lar deg utnytte flere CPU-kjerner.\n\nNoen biblioteker som NumPy og Pandas er implementert i C og frigjør GIL under tunge beregninger. Dette kan tillate parallell utførelse av beregninger uten å være begrenset av GIL.\n\nHvis man kjører følgende kode på en server med flere CPUer, vil kun en av trådene kjøre av gangen:\n\n```\nimport threading\n\nclass SaldoThread(threading.Thread):\n    MAX = 200000000\n    count = 0\n    saldo = 0  # Felles variabel, gir race condition?\n\n    def __init__(self):\n        super().__init__()\n        SaldoThread.count += 1\n        self.id = SaldoThread.count\n\n    def run(self):\n        print(f\"Tråd nr. {self.id} starter\")\n        self.update_saldo()\n\n    def update_saldo(self):\n        if self.id == 1:\n            for _ in range(SaldoThread.MAX):\n                SaldoThread.saldo += 1\n        else:\n            for _ in range(SaldoThread.MAX):\n                SaldoThread.saldo -= 1\n        print(f\"Tråd nr. {self.id} ferdig. Saldo: {SaldoThread.saldo}\")\n\nclass NosynchThread:\n    @staticmethod\n    def main():\n        print(\"Starter to tråder!\")\n\n        s1 = SaldoThread()\n        s2 = SaldoThread()\n        s1.start()\n        s2.start()\n\n        s1.join()\n        s2.join()\n\n        print(f\"Endelig total saldo: {SaldoThread.saldo}\")\n\nif __name__ == \"__main__\":\n    NosynchThread.main()\n```"}
{"identifier": "os6.3", "section_id": "6.3", "section_title": "branch prediction", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00073000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.3 branch prediction\n\n* Ved en branch i programmet (if-test), vet man ikke hva neste instruksjon er\n* Stort problem for pipelining, må vente på resultatet fra forrige instruksjon\n* Gjetter, basert på erfaring, hvilken branch (gren) som følges i programmet og utfører den\n* Speculative execution, må gjøres om hvis feil\n* I et superskalær arkitektur kan begge grener delvis utføres på forhånd\n\nFølgende `C++` program inneholder kode som viser hva konsekvensene av branch prediction kan være. I starten av programmet lages et data-array med tilfeldig trukkede heltall mellom 0 og 255. De 10 første tallene blir skrevet ut og så gjentas en ytre løkke 100.000 ganger for at man skal få mer nøyaktige målinger av hvor lang tid den indre løkken tar. Den indre løkken består av at man går igjennom hvert element i det store arrayet og legger til verdien `data[c]` til en variable sum hvis verdien er større enn 127. I praksis vil dette skje omtrent halvparten av gangene.\n\n```\n#include <algorithm>\n#include <iostream>\n\nusing namespace std;\n\nint main()\n{\n   // Lager et data-array\n   int i,c;\n   int arraySize = 32768;\n   int data[arraySize];\n   \n   for (c = 0; c < arraySize; ++c)\n     {\n       data[c] = rand() % 256;\n     }\n   \n   // Gir tilfeldig tall mellom 0 og 255\n   // Gir samme array med tall for hver kjøring\n\t\n   // sort(data, data + arraySize);\n   // sorterter data-arrayet\n   \n   // Skriver ut de 10 første verdiene\n   for (c = 0; c < 10; c++)\n     cout << data[c] << \"\\n\";\n   \n   // Legger sammen alle tall større enn 127\n   long sum = 0;\n   \n   // Ytre løkke for at det skal ta litt tid...\n   for (i = 0; i < 100000; ++i)\n     {\n        // Indre løkke\n        for (c = 0; c < arraySize; ++c)\n           {\n             if (data[c] > 127)\n             sum += data[c];\n           }\n     }\n   \n   cout << \"sum = \" << sum << \"\\n\";\n}\n```\n\nDeretter kompileres `C++` programmet og kjøres på en Linux-maskin:\n\n```\n$ g++ b.cpp\n$ time ./a.out \n103\n198\n105\n115\n81\n255\n74\n236\n41\n205\nsum = 314931600000\nReal:17.095 User:17.096 System:0.000 100.00%\n```\n\nKommandoen `time` tar tiden på programmet som kjøres og gir som resultat at programmet har brukt 17.096 sekunder CPU-tid og at det har brukt CPU-en hele tiden (100%). Utskriften av de 10 første tallene viser at verdiene kommer i en tilfeldig rekkefølge og at de er over og under 127, slik at if-testen vil slå til en gang i blant og i gjennomsnitt ca halvparten av gangene.\n\nDeretter gjøres en enkelt endring på koden ved at kommentartegnet foran linjen\n\n```\nsort(data, data + arraySize);\n```\n\nfjernes, slik at data-arrayet blir sortert før programmet kjører de to løkkene. Dette vil endre rekkefølgen for når if-testen slår til og dataene adderes til sum-variabelen, men det vil skje nøyaktig like mange ganger og som vi ser blir også summen nøyaktig den samme:\n\n```\n0\n0\n0\n0\n0\n0\n0\n0\n0\nsum = 314931600000\nReal:6.285 User:6.280 System:0.000 99.91%\n```\n\nUtskriften av de første 10 elementene viser at data-arrayet er sortert og starter med alle 0-verdiene. Men det overraskende er at denne kjøringen går mer en dobbelt så fort og nesten bare tar en tredjedel av tiden til den første kjøringen. Og dette til tross for at nøyaktig de samme instruksjonene blir utført i begge tilfeller og det samme regnestykket gir samme resultat. Hva kan dette skyldes?"}
{"identifier": "os6.4", "section_id": "6.4", "section_title": "Meltdown", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00074000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.4 Meltdown\n\n* Et hardware-sikkerhetshull funnet i 2018\n* Rammet Intel, ARM og IBM-prosessorer\n* Meltdown utnytter at både koden som sjekker om prosessen kan lese fra RAM og lesingen fra RAM delvis utføres\n* Meltdown kan dermed lese data fra andre prosesser som er cache't men ennå ikke fjernet pga feil branch\n* Spectre brukte lignende metoder til å lese passord og sensitive data\n* Betegnet som sikkerhets-katastrofe\n* Både CPU design og operativsystemer ble endret for å hindre Meltdown og Spectre i å virke"}
{"identifier": "os6.5", "section_id": "6.5", "section_title": "Viktig å huske fra datamaskinarkitektur", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00075000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.5 Viktig å huske fra datamaskinarkitektur\n\nPå veien videre er det viktigste å huske fra datamaskinarkitektur at alt CPU-en gjør er å slavisk utføre maskininstruksjoner en for en i en evigvarende løkke; ihvertfall til maskinen skrus av. Legg også merke til at det ikke er noen en til en forbindelse mellom instruksjoner i høynivåkode og maskinkode. En linje kode i høynivåspråk fører ofte til mange maskininstruksjoner i det kompilerte programmet."}
{"identifier": "os6.6", "section_id": "6.6", "section_title": "OS historie", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00076000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.6 OS historie\n\nDet er nyttig å vite litt om historien til noen av de mest brukte operativsystemene."}
{"identifier": "os6.6.1", "section_id": "6.6.1", "section_title": "Microsoft Desktop-OS", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00076100000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.6.1 Microsoft Desktop-OS\n\n**MS-DOS**: 1981, 16-bit\n\n**Windows**: 1.0 i 1985, 3.0 i 1990, GUI på toppen av DOS\n\n**Windows 95**: Noe 32-bit kode, mye 16-bit Intel assembler,DOS-filsystem, bruker DOS til å boote\n\n**Windows 98**: essensielt som 95, desktop/Internett integrert\n\n**Windows Me**: essensielt som 98, mer multimedia og nettverk support\n\n**Windows 2000**: Første (ikke så vellykkede) forsøk med Desktop OS basert på NT (5.0).\n\n**Windows XP**: Oktober 2001, Desktop-OS som kombinerer NT 5.1 kode med Win 9x. Home edition: 1 CPU, XP Professional: 2CPU-er, logge inn utenfra, 32 og 64 bit\n\n**Windows Vista**: januar 2007. Kernel NT 6.0, Booter raskere, bedre filsøk, Ingen suksess.\n\n**Windows 7**: oktober 2009, kjernen er Windows NT 6.1, PowerShell 2.0 default, 7 editions, Service Pack 1\n\n**Windows 8**: oktober 2012, NT 6.2, Start Screen, touch screen, USB 3.0, Windows Store, Windows RT for ARM\n\n**Windows 8.1**: oktober 2013, NT 6.3\n\n**Windows 10**: July 2015, NT 10.0(!), Microsoft Edge, virtual desktops, native Ubuntu bash shell(samarbeid med Canonical) gjennom Windows Subsystem for Linux\n\n**Windows 11**: October 2021, NT 10.0(!), ikke lenger støtte for 32-bit x86 CPUs, Internet Explorer ikke inkludert\n\n*Intels første 32-bit maskin var 386 fra 1985. \nGenerelt problem før XP: Windows er bakover-kompatibelt til DOS, alle Win-prosesser kan ødelegge \nfor kjernen og ta ned OS.*"}
{"identifier": "os6.6.2", "section_id": "6.6.2", "section_title": "Microsoft Server-OS", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00076200000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.6.2 Microsoft Server-OS\n\n**NT 3.1**: 1993 32-bit, skrevet fra scratch i C (lite assembler), David Cutler (VAX-VMS designer), mye bedre sikkerhet og stabilitet enn Windows. 3.1 millioner linjer kode.\n\n**NT 4.0**: 1996, Samme GUI som Win-95, 16 millioner linjer, portabelt `->` alpha, PowerPC\n\n**Windows 2000**: NT 5.0, opp til 32 CPU'er, features fra Win-98, Plug and Play, `\\winnt\\system32\\ntoskrnl.exe`. 29 millioner linjer. *MS-DOS borte, men 32-bits kommando-interface med samme funksjonalitet.*\n\n**Windows Server 2003**: bygger på 2000 server, NT 5.2, design med tanke på .NET: web, XML, C#, 32 og 64 bit, SP1, SP2, R2 i 2006\n\n**Windows Server 2008**: februar 2008, felles basis med Vista, første OS med PowerShell, Kan installeres som **Server core** og styres fra CLI (Command Line Interface), Hyper-V virtualisering\n\n**Windows Server 2008 R2**: oktober 2009, NT 6.1 (som Win 7), PowerShell 2.0 default, kun 64 bit\n\n**Windows Server 2012**: september 2012, NT 6.2 (som Win 8), cloud computing, oppdatert Hyper-V, nytt filsystem: ReFS\n\n**Windows Server 2012 R2**: oktober 2013, NT 6.3 (som Win 8.1)\n\n**Windows Server 2016**: september 2016, NT 10.0, Windows Defender, nano server: uten gui, fjernstyres med PowerShell\n\n**Windows Server 2019**: oktober 2018, NT 10.0, Windows Admin Center\n\n**Windows Server 2022**: August 2021, NT 10.0.2"}
{"identifier": "os6.6.3", "section_id": "6.6.3", "section_title": "Unix operativsystemer", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00076300000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.6.3 Unix operativsystemer\n\nDagens Unix-versjoner har utviklet seg fra to som dominerte rundt 1980:\n\n* system V (AT&T Bell Labs)\n* BSD (University of California at Berkely )\n\nDe fleste av dagens varianter er bygd på SVR4 som er en blanding. Følgende er kommersielle 64 bit Unix-OS for RISC-prosessorer som var dominerende i server-markedet et stykke inn på 2000-tallet:\n\n| OS | Eier | hardware |\n|---|----|--------|\n| AIX | IBM | RS6000, Power |\n| Solaris | Sun | Sparc, intel-x86 |\n| HP-UX | Hewlett-Packard | PA-RISC, Itanium(IA-64) |\n| Tru64 UNIX(Digital Unix) | HP(Compaq(DEC)) | Alpha |\n| IRIX | Silicon Graphics | SGI |\n\nOracle stanset vidreutviklingen av Solaris, det største av Unix-operativsystemene, i 2017. Idag er det x86 servere som dominerer og de fleste med Linux. Frie Unix-kloner for mange plattformer:\n\n| OS | hardware |\n|---|--------|\n| FreeBSD | x86, Alpha, Sparc |\n| OpenBSD | (sikkerhet) x86, Alpha, Sparc, HP, PowerPC, mm |\n| NetBSD | x86, Alpha, Sparc, HP, PowerPC (Mac), PlayStation, mm |\n| Darwin | (basis for Mac OS X og iOS, kjernen, XNU, bygger på FreeBSD og Mach 3 microkernel) , intel x86, ARM, PowerPC |\n| Linux | x86, Alpha, Sparc, HP, PowerPC, PlayStation 3, Xbox, stormaskin, mm |"}
{"identifier": "os6.6.4", "section_id": "6.6.4", "section_title": "Interrupts (avbrytelser)", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00076400000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.6.4 Interrupts (avbrytelser)\n\n* Signal fra hardware\n* CPU-en avbrytes for å håndtere signalet\n* Lagrer adressen til neste instruksjon på stack og hopper til interrupt-rutinen\n* Hvert interrupt-nr (IRQ) har sin rutine"}
{"identifier": "os6.7", "section_id": "6.7", "section_title": "Singletasking OS", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00077000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.7 Singletasking OS\n\nBasis for flerprosess-systemer."}
{"identifier": "os6.7.1", "section_id": "6.7.1", "section_title": "Internminne-kart", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00077100000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.7.1 Internminne-kart\n\n*Stack: brukes bl. a. til å lagre adressen som skal returneres til ved subrutinekall.*"}
{"identifier": "os6.8", "section_id": "6.8", "section_title": "Multitasking-OS", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00078000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.8 Multitasking-OS\n\n*For å lage et system som kan kjøre n programmer samtidig, må vi få en enprosess maskin til \nå se ut som n maskiner.*\n\n*Bruker software til å fordele tid mellom n programmer og å dele ressurser; minne, disk, skjerm etc. \nOS-kjernen utfører denne oppgaven.*\n\nSamtidige prosesser må tildeles hver sin del av minne:\n\nIllustrasjon:\nMinnekart for et multitasking system"}
{"identifier": "os6.9", "section_id": "6.9", "section_title": "Multitasking", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION00079000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.9 Multitasking\n\nMultitasking gjør at man kan kjøre flere programmer samtidig selvom man bare har en CPU. I prinsippet er CPU-en meget enkel på den måten at den gjør en og en maskinistruksjon av gangen. Som for eksempel å legge sammen to tall, å sammenligne to bit-strenger (1010001101101110 = 1010001100101110?) eller å lagre en streng med binære tall i internminnet(RAM). Et multitasking operativsystem får det til å se ut som om mange programmer kan kjøre samtidig ved å dele opp tiden i små biter (timeslices) og la hver prosess som kjører få en bit CPU-tid (typisk et hundredels sekund) av gangen i et køsystem (såkalt Round Robin kø). Metoden som alle moderne OS bruker er Preemptive multitasking. Metoden består i at en hardware timer (klokke) jevnlig sender et interrupt-signal som gjør at første OS-instruksjon legges inn i CPU-en. Dermed unngås det at vanlige brukerprosesse tar over kontrollen. OS lar hver prosess etter tur bruke CPU-en i et kort tidsintervall. Alle prosesser ser da ut til å kjøre samtidig. Når OS switcher fra prosess P1 til prosess P2 utføres en såkalt Contex Switch (kontekst svitsj).\n\nIllustrasjon:\nProsessene P1, P2 og P3 kjører samtidig under et multitasking OS. En \nContext Switch utføres hver gang en prosess gis CPU-tid. Typisk tid for context-switch: 0.001 ms (ms = millisekunder = tusendels sekund). Timeslice = 10 ms for Linux på Intel."}
{"identifier": "os6.10", "section_id": "6.10", "section_title": "PCB -Process Control Block", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION000710000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.10 PCB -Process Control Block\n\nProcess Control Block (PCB) er Prosessens tilstandsbeskrivelse: prioritet, prosessormodus, minne, stack, åpne filer, I/O, etc. PCB inneholder bl. a. følgende:\n\n* CPU registre\n* pekere til stack\n* prosesstilstand (sleep, run, ready, wait, new, stopped)\n* navn (PID)\n* eier (bruker)\n* prioritet (styrer hvor mye CPU-tid den får)\n* parent prosess\n* ressurser (åpne filer, etc.)"}
{"identifier": "os6.11", "section_id": "6.11", "section_title": "Timesharing og Context Switch", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION000711000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.11 Timesharing og Context Switch\n\nCPU-scheduling = å fordele CPU-tid mellom prosessene = Time Sharing Metoden som alle moderne OS bruker er Preemptive multitasking med en Round Robin kø. OS lar hver prosess etter tur bruke CPU-en i et kort tidsintervall (timeslice). Alle prosesser ser da ut til å kjøre samtidig. Når OS switcher fra prosess P1 til prosess P2 utføres en Contex Switch.\n\nIllustrasjon:\nProsessene P1, P2 og P3 kjører samtidig under et multitasking OS. En \nContext Switch utføres hver gang en prosess gis CPU-tid. Typisk tid for context-switch: 0.001 ms. Timeslice = 10 ms for Linux på Intel.\n\n*All PCB-info må lagres i en Context Switch -> tar tid  -> systemoverhead*\n\nIllustrasjon:\nCPU info lagres i PCB ved en Context Switch"}
{"identifier": "os6.12", "section_id": "6.12", "section_title": "Multitasking i praksis, CPU-intensive programmer", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION000712000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.12 Multitasking i praksis, CPU-intensive programmer\n\nEt program som oversetter kildekode til maskinkode (kompilator) eller et program som hele tiden regner med tall, vil bruk så mye CPU-tid som det klarer å få tak i. Prosesser som kjører slike programmer kalles CPU-intensive. De fleste vanlige programmer som browsere, tekstbehandlingsprogrammer, tengeprogram etc. bruker lite CPU og det er dette som gjør at multitasking av hundretalls samtidige prosesser går helt greit uten at brukeren oppfatter datamaskinen som treg. Vi skal nå se hva som skjer når vi kjører flere instanser av et mulititasking program på systmer med en eller flere CPU'er.\n\nProgrammet vi bruker er et lite shell-script som står i en løkke og regner og regner. Da vil det hele tiden ha behov for CPU-en. Siden prosessen aldri har behov for å vente på data fra disk, tastatur eller andre prosesser, kan den regne uten stans. Programmet heter `regn` og ser slik ut:\n\n```\n#! /bin/bash\n\n# regn (bruker CPU hele tiden)\n\n(( max = 100000 ))\n(( i = 0  ))\n(( sum = 0  ))\n\necho $0 : regner....\nwhile (($i < $max))\ndo\n        (( i += 1 ))\n        (( sum += i  ))\ndone\necho $0, resultat: $sum\n```"}
{"identifier": "os6.13", "section_id": "6.13", "section_title": "Multitasking eksempel", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION000713000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.13 Multitasking eksempel\n\n*Bare rene regneprosesser bruker CPU hele tiden. Vanlige prosesser\n  venter mye på I/O (Input/Output fra disk, nettverk etc.) og\n  multitasking gir da mer effektiv utnyttelse av CPU.*\n\nIllustrasjon:\nProsessene A og B kjørt med single og multitasking"}
{"identifier": "os6.14", "section_id": "6.14", "section_title": "CPU-intensiv prosess på system med èn CPU", "source_category": "os", "source_id": "6", "source_title": "Branch prediction, Multitasking", "anchor": "SECTION000714000000000000000", "source": "os/Forelesning/os/node7.html", "text": "## 6.14 CPU-intensiv prosess på system med èn CPU\n\nMed kommandoen `lscpu` kan man hente ut mye nyttig informasjon om cpu og cache:\n\n```\nuser@chokeG7:~$ lscpu \nArchitecture:        x86_64\nCPU op-mode(s):      32-bit, 64-bit\nByte Order:          Little Endian\nAddress sizes:       40 bits physical, 48 bits virtual\nCPU(s):              1\nOn-line CPU(s) list: 0\nThread(s) per core:  1\nCore(s) per socket:  1\nSocket(s):           1\nNUMA node(s):        1\nVendor ID:           AuthenticAMD\nCPU family:          15\nModel:               65\nModel name:          Dual-Core AMD Opteron(tm) Processor 2216\nStepping:            3\nCPU MHz:             2400.114\nBogoMIPS:            4800.22\nHypervisor vendor:   Xen\nVirtualization type: full\nL1d cache:           64K\nL1i cache:           64K\nL2 cache:            1024K\nNUMA node0 CPU(s):   0\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt rdtscp lm 3dnowext 3dnow rep_good nopl cpuid extd_apicid pni cx16 x2apic hypervisor lahf_lm cr8_legacy 3dnowprefetch vmmcall\n```\n\nDette viser at denne Linux-maskinen har èn enkelt 64-bits CPU med en klokkefrekvens på 2.4 GHz. Utskriften viser også at dette er en virtuell maskin, man kan se at den er virtualisert med Xen utifra de to linjene\n\n```\nHypervisor vendor:   Xen\nVirtualization type: full\n```\n\nVidere kan man se størrelsen på L1 og L2 cache. En rask og tydelig oversikt kan man få med kommandoen `lstopo` :\n\n```\nlstopo --no-io\n```\n\nsom gir følgende figur\n\nIllustrasjon:\nCPU-topologi generert av lstopo den virtuelle maksinen chokeG7.\n\nVi starter en instans av programmet `regn` som er CPU-intensivt og bruker så mye CPU det kan få:\n\n```\nmroot@chokeG7:~$ ./regn \n./regn, resultat: 3125001250000\n```\n\nSamtidig startes `top` og man kan se at prosessen med PID (Process ID) 18908 forsyner seg grovt av CPU-en og klarer å karre til seg 99.3% av CPU-tiden. Verdien som vises er gjennomsnittsverdien for de siste 3 sekunder.\n\n```\ntop - 14:32:39 up 10 days, 23:56,  2 users,  load average: 0,09, 0,12, 0,05\nTasks:  74 total,   1 running,  73 sleeping,   0 stopped,   0 zombie\n%Cpu(s):  0,0 us,  0,7 sy,  0,0 ni, 99,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,3 st\n\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                    \n18908 mroot     20   0    9504   3244   3008 R  99,3   0,7   0:07.16 regn                                       \n18903 mroot     20   0   16668   4668   3536 S   0,3   1,0   0:00.04 sshd\n```\n\nVi starter så en instans til av programmet som regner i vei, uavhengig av den første. Da ser vi at OS fordeler CPU-en likt mellom de to prosessene og de får i underkant av 50% hver av CPU-tiden.\n\n```\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                    \n18912 mroot     20   0    9504   3224   2988 R  49,8   0,7   0:13.14 regn                                       \n18913 mroot     20   0    9504   3312   3080 R  49,8   0,7   0:12.84 regn\n```\n\nDette betyr at reelt sett er det til enhver tid bare en prosess som kjører, men det oppleves som om de kjører samtidig fordi OS deler opp tiden i små biter(1-10 hundredels sekunder) og lar dem bruke CPU-en annenhver gang. Husk at for en prosess er ett hundredels sekund lang tid, den kan rekke å utføre millioner av maskininstruksjoner på den tiden."}
{"identifier": "os3.3", "section_id": "3.3", "section_title": "ALU", "source_category": "os", "source_id": "3", "source_title": "Vipper og registre, CPU-arkitektur", "anchor": "SECTION00043000000000000000", "source": "os/Forelesning/os/node4.html", "text": "## 3.3 ALU\n\nVi har vist at ved å sette sammen flere bokser som adderer enkelt-siffer med mente, kan man lage en adderer som ser omtrent ut som i Fig. 24 .\n\nIllustrasjon:\nC = A + B (12 =  6 +6). Logiske kretser med AND, OR og NOT er konstruert inne i boksen på en slik måte at de alltid regner ut riktig resultat. Kretsen leser fra og skriver til 4-bits registre.\n\nEn slik løsning kan systematisk utvikles til å legge sammen 32 og 64 bits tall. Når det gjelder addisjon, gjøres det noen forbedringer på metoden vi brukte for at det ikke skal ta for lang tid for mente å bevege seg fra siste til første siffer. Men det vil bruke mye plass om man må ha en slik enhet for enhver matematisk eller logisk operasjon som man ønsker å utføre. Det viser seg at man kan konstruere en krets som ved hjelp av små endringer både kan addere, subtrahere, øke med en, sammenligne, gange med 2, og så videre. Man styrer hvilken av disse operasjonene enheten skal utføre ved hjelp av kontroll-bits. I Fig. 25 ser vi en tilsvarende krets med to ekstra kontroll-bit.\n\nIllustrasjon:\nEn ALU med fire funksjoner. C = A + 1 (7 = 6 + 1). Her styrer kontroll-bitene S0 og S1 kretsen til å øke A med en og legge resultatet i C. Dette kan for eksempel skje ved S0 = 0 og S1 = 0, mens ved S0 = 0 og S1 = 1 ville ALU-en legge sammen tallene.\n\nDette gjør det mulig å kode inn flere lignende operasjoner inn i kretsen, og den blir til en liten ALU (Arithmetic Logic Unit). Eksakt hvilken funksjon som utføres bestemmes av kontroll-bitene. En ALU er selve hjernen i en CPU hvor alle beregninger blir gjort. I tillegg inneholder CPU registre (4-bits registre i figuren) for å lagre data og en kontrollenhet som oversetter maskininstruksjoner til styringsbit for registre og ALU slik at riktig instruksjon blir utført. Konseptet ALU ble innført av matematikeren John von Neumann i forbindelse med konstruksjonen av en av verdens første datamaskiner, EDVAC i 1945. Det følgende er operasjoner som alle ALU-er kan utføre:\n\n* Adder\n* Subtraher\n* Inkrement (++)\n* Dekrement ()\n* Multipliser\n* Divider\n* Shift (flytt alle bit i en retning)\n* Sammenligne\n* AND, OR, NOT, XOR\n\nIllustrasjon:\nALU-en til EDSAC 2 fra 1958 hadde radiorør, som senere ble erstattet av transistorer. Neste steg er å forstå hvordan man kan bruke AND, OR og NOT-porter til å lage registre som kan lagre data inne i CPUen."}
{"identifier": "os3.4", "section_id": "3.4", "section_title": "Lagring av data: vipper og registre", "source_category": "os", "source_id": "3", "source_title": "Vipper og registre, CPU-arkitektur", "anchor": "SECTION00044000000000000000", "source": "os/Forelesning/os/node4.html", "text": "## 3.4 Lagring av data: vipper og registre\n\nMan kan lagre og representere nuller og enere ved å bruke små kondensatorer som lagrer elektrisk ladning. Men dette er ikke like raskt som om man bruker logiske porter lagd av transistorer. I tillegg må kondensator-lagerenheten jevnlig oppfriskes, typisk 10 ganger i sekundet. Men det er denne teknologien som brukes i RAM og dette skal vi se på senere. Hovedproblemet er at denne teknologien gjøer RAM tregere. For å lage en lagerplass som hurtig kan leses å endres må vi bruke logiske porter. Av slike porter kan man lage en lagerenhet som kan lagre nuller og enere og disse kalles vipper(engelsk: flip-flops). Dette er den siste byggestenen vi trenger for å kunne lagre dataene i beregningene som kretsene gjør. Det er mulig å lage en slik lagerenhet ved hjelp av porter. Denne vil da bli ekstremt hurtig, like hurtig som resten av CPU-en og langt hurtigere en lagringsenhetene i RAM. En vippe er den grunnleggende lagringsenheten i CPU-en og brukes til all lagring av data internt, inkludert cache (mellomlagring) i CPU-en og cache mellom CPU og RAM. I de neste avsnittene skal vi se på hvordan en slik lagringsenhet kan konstrueres. Først lager vi en enhet som kan lagre en bit, slike kan settes sammen til store registre med 32 og 64 bit."}
{"identifier": "os3.4.1", "section_id": "3.4.1", "section_title": "Lagringsenhet for en bit, D-lås(D-latch)", "source_category": "os", "source_id": "3", "source_title": "Vipper og registre, CPU-arkitektur", "anchor": "SECTION00044100000000000000", "source": "os/Forelesning/os/node4.html", "text": "## 3.4.1 Lagringsenhet for en bit, D-lås(D-latch)\n\nFor å lagre noe med porter, må vi lage en lukket krets slik at bit-verdiene bevares. Et første forsøk er vist i Fig. 27 .\n\nIllustrasjon:\nLagring av verdien Q = 1\n\nMen et opplagt problem med denne lagringen er at verdien ikke kan endres. Ved å legge inn en OR-port foran NOT-porten [2](footnode.html#foot541) får man en mulighet til å legge inn en verdi D, som vist i Fig. 28 .\n\nIllustrasjon:\nEndring av verdien Q til 0\n\nFor denne lagringsenheten kan man endre verdien. Hvis man sender inn D=0 som på figuren vil den etterfølgende NOT-porten sende en ener inn i den øverste OR-porten. Hvis det kommer en ener inn i en av inngangene til en OR-port vil det alltid gå en ener ut, og dermed vil kretsen lagre 0 etter at eneren har gått igjennom den siste øverste NOT-porten. Hvis vi prøver å lagre D=1, kan man se at den nederste OR-porten alltid vil gi en ener ut. Dermed sendes en null opp til den øverste OR-porten som sammen med en null fra NOT-porten rett etter D gir en null og dermed en ener ved Q [3](footnode.html#foot550) .\n\nDermed kan vi legge inn verdire i lagringsenheten, men problemet nå er at vi alltid vil legge inn det som kommer inn i D. Noen ganger ønsker vi å bevare det vi har lagret til senere og for å få til den muligheten legger vi inn et kontroll signal C som er slik at\n\n* C = 1 verdien inn fra D lagres\n* C = 0 den lagrede verdien beholdes, uavhengig av verdien inn fra D\n\nDet kan gjøres som vist i Fig. 29 .\n\nIllustrasjon:\nD-lås(latch). D står for data. Dette er en lagringskrets som kan skru lagring av og på. Den nederste boksen symboliserer hele kretsen.\n\nHvis C = 1 så vil kretsen fungere nøyaktig som kretsen over i Fig. 28 , fordi en ener inn i en AND-port alltid vil gi verdien til den andre inngangen ut og dermed er alt nøyaktig som i kretsen over. Hvis C = 0 vil kretsen fungere nøyaktig som den første kretsen i Fig. 27 . Dette er fordi en null inn i en AND-port alltid gir 0 ut, og dermed kommer det en null inn i begge OR-portene. Men en null inn i en OR-port gir alltid verdien til den andre inngangen og dermed fungerer kretsen som den aller første og enkleste, kretsen beholder bare den verdien den har lagret."}
{"identifier": "os3.4.2", "section_id": "3.4.2", "section_title": "Simulering av shift-register med studenter", "source_category": "os", "source_id": "3", "source_title": "Vipper og registre, CPU-arkitektur", "anchor": "SECTION00044200000000000000", "source": "os/Forelesning/os/node4.html", "text": "## 3.4.2 Simulering av shift-register med studenter\n\nEt problem med å bruke en D-lås til å lagre data i en CPU er at man trenger kontroll på når data lagres av en D-lås og når data leses av neste D-lås. Om data i tillegg går igjennom kretser som endrer data blir problemet større, for da vil det være ulik tid som går med til å fullføre beregninger av ulik type. For eksempel tar en multiplikasjon av to tall lenger tid enn en addisjon. Under forelesningen skulle hver av de åtte deltagerne fungere som en D-lås. Det vil si, de skulle kun se på D-låsen foran seg og endre sin verdi til dens verdi når input fra C er 1. Når foreleser løftet hånden, betydde det C = 1 og at alle D-låser skulle virke ved å endre sin verdi til den samme verdien som nærmeste D-lås hadde. På samme måte som i Fig. 32 der hver av D-låsene hele tiden leser av verdien Q til den D-låsen som står til venstre for seg og dette blir til input D for den selv. Når C = 1 vil den derfor endre sin Q-verdi til samme Q-verdi som D-låsen til venstre for seg. På samme måte stilte åtte studenter, dobbelt så mange som i figuren, opp etterhverandre som vist i Fig. 31 .\n\nIllustrasjon:\nÅtte menneskelige D-låser på rad. Armen opp betyr 1, ned betyr 0. Hver D-lås leser verdien til D-låsen til høyre for seg (motsatt retning som for D-låsene i  i  Fig. 32).\n\nNår foreleser hever armen og alle begynner å virke, er problemet at det kan være litt ulikheter mellom hvor fort de menneskelige D-låsene reagerer på endringer til D-låsen foran dem. Dermed kan for eksempel en endring fra figuren over bli til resultatet i Fig. , at en ekstra verdi 1 dukker opp. Det kan skje hvis den kvinnelige vippen nummer 4 fra venstre leser av sin verdi raskere enn kvinnelig vippe nr 6. Og mannlig vippe nr 5 i mellom dem er raskere enn mannlig vippe nr 7. En slik måte å propagere data på vil være ustabil i forhold til selv svært små forskjeller i tidsbruk og vil også være helt ubrukelig som metode i en CPU.\n\nIllustrasjon:\nDe menneskelige D-låsene reagerer ikke nøyaktig like fort og dermed kan dette bli neste tilstand for arrayet av bits, der en ener for mye har dukket opp.\n\nFor å kunne kontrollere nøyaktig når dataene blir overført og gjøre overføringen uavhengig av små svingninger i tempo på de involverte kretsene, innfører man en klokke som med jevne av og på singnaler styrer dette. I forelesningen ble dette gjort ved at foreleser svinger armen opp og ned i et jevnt tempo med en frekvens på omtrent en halv Hertz, altså hvert andre sekund. Når dette gjøres og alle studentene virker som de skal, kan man se at de to bit'ene beveger seg bortover uten at noe informasjon blir borte. Svingningene opp og ned med armen tilsvarer den berømte CPU-klokken, som typisk svinger med en frekvens på 2-4 GHz, noe som betyr flere milliarder svingninger av og på i løpet av et sekund."}
{"identifier": "os3.4.3", "section_id": "3.4.3", "section_title": "Vipper(flip flops)", "source_category": "os", "source_id": "3", "source_title": "Vipper og registre, CPU-arkitektur", "anchor": "SECTION00044300000000000000", "source": "os/Forelesning/os/node4.html", "text": "## 3.4.3 Vipper(flip flops)\n\nNå er vi nesten fremme; vi har sett hvordan en krets kan gjøre operasjoner som å legge sammen to tall og vi har nå en lagringsenhet som input kan tas fra og resultatet lagres i. Men det er et problem som gjenstår. Hvis vi bare kobler sammen disse enhetene, har man ikke kontroll på den logiske flyten av data. Selvom signalene går med nesten lysets hastighet, tar det litt tid fra signalene kommer inn på den ene siden av en regnekrets til det rette svaret kommer ut i den andre enden. Et eksempel på hvordan flyten blir ukontrollert får man om man kobler sammen fire D-låser i hensikt å lage et shift-register som vist i Fig. 32 .\n\nIllustrasjon:\nD-latch(lås). Fire D-låser settes sammen til et shift-register. Vi ønsker å kunne utføre en operasjon som 1010 -> 0101 som med binære tall er det samme som å dele på 2. Men om vi sender en 1'er inn i C (som betyr at D-låsen skal lese inn en ny verdi) som i figuren, har vi ikke kontroll på hvor lang tid det tar for den nye verdien å bli lest, og med en gang den blir lest, vil neste D-lås lese den nye verdien og så videre [4](footnode.html#foot590) . Dermed har man ikke kontroll på hvor langt informasjonen går før man eventuelt skal sende inn en 0'er inn i C for å stoppe innlesningen og lagre resultatet. I mer kompliserte kretser vil det også være et problem at det kan variere mye hvor lang tid det tar før beregningen er ferdig og neste bit klar for lesing. Dette problemet løser man i en CPU ved å sette sammen D-låser to og to og å ha en klokke som sender et av og på signal med en viss frekvens, for eksempel 1 GHz, eller en milliard endringer mellom null og en i sekundet. Hvordan dette kan gjøres er vist i Fig. 33 .\n\nIllustrasjon:\nTo master og slave D-låser blir til en D-vippe. Klokken går av og på og styrer når de endelige dataene lagres av slaven. Dette er selve CPU-klokken, som typisk har en frekvens på 1-3 GHz. Når klokken sender en 1'er, vil en slave lese inn og lagre det som master lagret når klokken rett før sendte en 0. Dermed vil data kunne bevege seg fra D-vippe til D-vippe på en kontrollert måte. Det er slaven som holder den gjeldene verdien for vippen som den leser fra master i starten av en klokkesyklus. Dette er verdien til bit'en i denne klokkesyklusen. Et shift til høyre vil forflytte alle slave-verdiene synkronisert, slik at de flytter seg hver gang klokken går over fra å sende 0 til å sende 1. Til en viss grad kunne man se at det fungerte under student-simuleringen.\n\nOppsummert vil tiden deles inn i små klokke-tikk og innenfor et slikt tikk må\n\n* Når klokken sender en 0: alle beregninger ferdigstilles ved å strømme igjennom kretsene som adderer eller gjør annen logikk, sluttresultatet lagres hos master. Det må være ferdig før klokken switcher til 1.\n* Når klokken sender en 1: slaven leser verdien fra master og lagrer den. Den begynner straks å sende dette resultatet, som er det gjeldende resultatet, ut i kretsene som er koblet til utgangen for nye beregninger.\n\nCPU-klokken er helt essensiell for å synkronisere dataene, for hvert tikk av klokken kan et nytt sett av beregninger gjøres, for eksempel å utføre en maskin-instruksjon.\n\nData lagres i CPU-en med slike vipper og slike samlinger av vipper som vi lar representere tall kalles registre. En 32bits CPU har registre som består av 32 vipper og dermed kan lagre 32bits tall. En 64bits CPU har 64bits registre. Vi skal nå se på en simulering av en virkelig CPU laget med verktøyet Digital Works. Denne CPU-en er svært liten, det er en 4bits CPU og den har altså 4bits registre. Men bortsett fra størrelsen, kan den i prinsippet gjøre alle beregninger som en moderne CPU kan gjøre og den virker på helt samme måte. Grunnen til at en moderne CPU er mye mer komplisert er i tillegg til at de er større, er at arkitekturen er endret for at beregningene skal gå rasker. Registrene sitter i begge ender av beregningene. Hvis to tall skal legges sammen, kobles output for to registre til ALU-en som inneholder addisjons-logikken. Utgangen av ALU kobles så til registeret som skal lagre resultatet. I denne simulerte maskinen gjøres en ny operasjon eller instruksjon hvert klokke-tikk."}
{"identifier": "os3.5", "section_id": "3.5", "section_title": "Tellere", "source_category": "os", "source_id": "3", "source_title": "Vipper og registre, CPU-arkitektur", "anchor": "SECTION00045000000000000000", "source": "os/Forelesning/os/node4.html", "text": "## 3.5 Tellere\n\nFor å kunne løpe gjennom instruksjoner i et program, trenger man en teller som kan telle oppover for hvert klokke-tikk. Et program som kjøres av en CPU består av en rekke instruksjoner som skal gjøres etterhverandre. Den starter med instruksjon nummer en som ligger i RAM og så teller den seg oppover til instruksjon nummer 2 og så videre ved hjelp av telleren. Noen ganger er det behov for å hoppe i koden, som ved en If-test, og da settes telleren til det instruksjonsnummeret det skal hoppes til og teller videre derfra. I Fig. 34 ser vi en 2-bits teller som kan telle fra 0 til 3. Ved å la verdien disse vippene har, D-vipper i dette tilfellet, representere hvert sitt siffer i et binært tall, kan de tilsammen representere tallene 0-3. For å lage større tall, trenger vi bare flere vipper.\n\nIllustrasjon:\nEn 2-bits teller"}
{"identifier": "os3.6", "section_id": "3.6", "section_title": "CPU-arkitektur", "source_category": "os", "source_id": "3", "source_title": "Vipper og registre, CPU-arkitektur", "anchor": "SECTION00046000000000000000", "source": "os/Forelesning/os/node4.html", "text": "## 3.6 CPU-arkitektur\n\nDen vanligste datamaskinarkitekturen som brukes, i hvertfall i hovedtrekk, av de fleste av dagens datamaskiner, er von Neumann-arkitekturen. Den ble definert i rapporten \"First Draft of a Report on the EDVAC\" av matematikk-professoren John von Neumann i 1945. Fig. 35 viser en skisse av denne arkitekturen.\n\nIllustrasjon:\nVon Neumann arkitektur De viktigste delene av von Neumann arkitekturen er\n\n* Et arbeidsminne (internminnet/RAM) som inneholder både instruksjoner og kode.\n* En aritmetisk/logisk enhet (ALU - Arithmetic Logic Unit) som kan utføre matematiske og logiske operasjoner.\n* En kontrollenhet som henter inn instruksjoner fra RAM, dekoder dem og sender signaler som gjør at instruksjonen blir utført.\n* Registre, internlager for både instruksjoner og data inne i CPU-en.\n* Enheter for input og output som gjør at CPU kan kommunisere med harddisk, tastatur, nettverk, etc.\n\nCPU(Central Processing Unit) inneholder kontrollenheten, ALU og registre (de to siste utgjør tilsammen datapath). Et problem med denne arkitekturen blir omtalt som 'the Von Neumann bottlenck'. Det kommer av at instruksjoner og data deler samme data-buss. I Hardvard arkitekturen er strømmen av instruksjoner og data inn til CPU fysisk adskilt. I de fleste moderne løsninger er en Modified Harvard architecture tatt i bruk som løser flaskehalsen ved å ha forskjellige cache-kanaler for instruksjoner og data."}
{"identifier": "os3.7", "section_id": "3.7", "section_title": "Beregningsenheter", "source_category": "os", "source_id": "3", "source_title": "Vipper og registre, CPU-arkitektur", "anchor": "SECTION00047000000000000000", "source": "os/Forelesning/os/node4.html", "text": "## 3.7 Beregningsenheter\n\nFølgende er noen typer beregningsenheter med økende grad av kapasitet. En CPU er meget anvendelig ved at den er så generell at den kan programmeres til å gjøre alle mulige beregninger. De etterfølgende enhetene er i økende grad spesialiserte og dermed raskere til å utføre de spesielle beregningene de er lagd for å gjøre.\n\n* ALU (Arithmetic Logic Unit) CPU-ens hjerne\n* CPU (Central Processing Unit)\n* FPU (Floating-Point Unit) vanligvis integrert i CPU\n* GPU (Graphics Processing Unit) tusenvis av cores\n* FPGA (Field-programmable Gate Array) programmerbar logikk\n* ASIC (Application-Specific Integrated Circuit)"}
{"identifier": "os3.8", "section_id": "3.8", "section_title": "En simulering av en datamaskin", "source_category": "os", "source_id": "3", "source_title": "Vipper og registre, CPU-arkitektur", "anchor": "SECTION00048000000000000000", "source": "os/Forelesning/os/node4.html", "text": "## 3.8 En simulering av en datamaskin\n\nFig. 36 viser arkitekturen til en komplett CPU som kan utføre programmer skrevet i såkalt maskinkode. Det er gjort visse endringer i forhold til von Neumann arkitekturen, den vesentligste er at maskininstruksjonene er lagret i en ROM (Read Only Memory) inne i CPUen. Vanligvis hentes de fra RAM fortløpende og lagres i instruksjonsregisteret i CPU-en før de kjøres.\n\nI en reell CPU består portene av fysiske halvledere og ledningene av fysiske elektriske ledninger brent inn i kretskort i ekstremt liten skala. Alt denne maskinen forstår er nuller og enere og for å gi den beskjed om hva den skal gjøre, må disse beskjedene gis i form av en binær kode. I denne maskinen består instruksjonene av 8 bit og for eksempel betyr maskininstruksjonen 01001011 at den skal legge sammen tallet som er lagret i register R2 og tallet som er lagret i register R3 og lagre resultatet i R2. Instruksjonen er delt opp slik at de 4 første bit'ene 0100 betyr ADD og at operasjonen 'legg sammen' skal utføres. De to neste bitene 10 betyr R2 og de to siste 11 betyr R3. Det eneste CPU-en gjør er å utføre denne type instruksjoner om og om igjen.\n\nIllustrasjon:\nEn komplett CPU tilkoblet RAM\n\nEn samling slike instruksjoner utgjør et program og i denne maskinen er de lagret i boksen merket ROM. Vanligvis ligger maskinkoden som skal utføres sammen med programmets data i RAM, boksen nede i høyre hjørnet. I denne datamaskinarkitekturen ligger bare programmets data i RAM og det finnes instruksjoner som flytter data mellom RAM og registrene, men vi skal i første omgang ikke bruke dem her. Kanalene som går mellom datapath og RAM er data-bussen. I en von Neuman-arkitektur sendes både data og instruksjoner over denne bussen. Men i vårt tilfelle ligger ikke instruksjonene i RAM men i en spesiallaget ROM, dette er ikke så vanlig i CPU-arkitekturer. Men totalt sett minner denne arkitekturen derfor mer om Harvard-arkitekturen hvor instruksjoner og data sendes inn til CPU-en på to forskjellige busser. Det finnes typisk noen hundre registre i en standard CPU, men disse blir bare brukt til mellomlager, mer permanente verdier som variabler i et program, lagres i RAM som har mye større kapasitet. Enda større datamengder som man ønsker å lagre når maskinen skrus av, lagres på disk.\n\nIllustrasjon:\nDatapath med fire 4-bits registre og ALU. En ofte brukt operasjon består i at data føres inn i ALU fra registrene via A og B og at resultatet etter beregningen lagres i et register.\n\nMen hvor er selve hjernen til CPU-en som kan legge sammen tall, trekke dem fra hverandre, sammeligne dem og så videre? Den sitter inne i Datapath der inngangen til to valgte registre kan kobles til ALU-en (Arithmetic Logic Unit). Og inne i denne skjer selve operasjonen. Verdien på input-ledningene S0 og S1 avgjør hvilke operasjoner som utføres, ADD, SUB, SHIFT, etc. Andre input-ledninger avgjør hvilke registre som ledes inn i ALU og i hvilket register resultatet lagres. Disse input'ene kommer fra instruksjonsdekoderen som for hver instruksjon trykker på de rette knappene for å få den utført. For eksempel sørger instruksjonsdekoderen for at maskininstruksjonen 01001011 nevnt ovenfor virkelig fører til at ALU legger sammen tallet som er lagret i register R2 med tallet som er lagret i register R3 og lagrer resultatet i R2."}
{"identifier": "os3.9", "section_id": "3.9", "section_title": "Fra høynivåkode til CPU-beregning", "source_category": "os", "source_id": "3", "source_title": "Vipper og registre, CPU-arkitektur", "anchor": "SECTION00049000000000000000", "source": "os/Forelesning/os/node4.html", "text": "## 3.9 Fra høynivåkode til CPU-beregning\n\nSå godt som all programvare blir skrevet i et høynivåspråk som Java eller C. Dette er språk som vanlige CPU-er ikke forstår og høynivåkode må derfor oversettes til maskinkode for at den skal kunne utføres. Oppgaven med å oversette fra høynivåkode til maskinkode utføres vanligvis av et program, en kompilator. Vi skal se på et enkelt eksempel og vise hvordan en liten bit høynivåkode kan oversettes til et kjørbart program i vår virtuelle Digital Works prosessor. Vi starter med følgende kodesnutt:\n\n```\nS = 0;\nfor(i=1;i < 4;i++)\n{\n   S = S + i;\n}\n```\n\nDet en programmerer ønsker CPU-en skal utføre er følgende:\n\n```\ni = 1: S = 0 + 1 = 1\ni = 2: S = 1 + 2 = 3\ni = 3: S = 3 + 3 = 6\n```\n\nog så avslutte. Om dette var et C-program, ville variablene S og i lagres i RAM og lastes inn i registrene under beregningene. Nå skal vi skrive en optimalisert maskinkode for vår maskin, hvor S og i lagres i registrene Dette gjør at beregningen går hurtigere, fordi det tar relativt lang tid å lese og skrive til RAM. Følgende er et såkalt Assembly-program som utfører denne beregningen. Assembly er et språk som ligger svært nær maskinspråk, det bruker symboler for maskininstruksjoner slik at det er lettere å lese for et menneske. Det har i motsetning til høynivåspråk en enkel en-til-en oversettelse til maskinspråk.\n\n```\n0 MOVI R0 <- 3            (MOV Integer. maksverdien i for-løkken legges i R0)\n1 MOVI R1 <- 1            (tallet som i økes med for hver runde i løkken)\n2 MOVI R2 <- 0            (variabelen i lagres i R2)\n3 MOVI R3 <- 0            (S = 0)\n4 ADD R2 <- R2 + R1       (i++)  \n5 ADD R3 <- R3 + R2       (S = S + i)\n6 CMP R2 R0               (COMPARE, er i = 3 ? ) \n7 JNE 4                   (Jump Not Equal 4, hopp til linje 4 hvis i != 3)\n```\n\nDette er slik programmet kan gjennomføres med maskin-instruksjoner og for å kunne programmer vår maskin, må nå dette programmet skrives binært med enere og nuller. Da trenger vi å vite litt av instruksjonssettet for maskinen. Vår CPU er konstruert slik at instruksjonene består av 8 bit. De fire første bit'ene definerer hvilket nummer instruksjonen er i rekken av instruksjoner. Bit nummer 5 og 6 er første operand og nr 7 og 8 er andre operand. Vanligvis bestemmer det to-bits tallet i operanden hvilket register som er involvert. Instruksjonene vi trenger til vårt program er:\n\n| binært Nr | operand1 | operand2 | Nr | Navn |\n|---------|--------|--------|---|----|\n| 0010 | DR | tall | 2 | MOVI |\n| 0100 | DR | SR | 4 | ADD |\n| 1100 | DR | SR | 12 | CMP |\n| 1111 | nr | nr | 15 | JNE |\n\nDen første linjen betyr at MOVI er instruksjon nummer 2 og at den gjør at tallet gitt ved de to siste bit'ene i instruksjonen legges i register nr DR (Destination Register). Instruksjonen ADD er nummer 4 og den legger sammen DR og SR(Source Register) og legger svaret i DR. Instruksjon nr 12 er CMP og den sammenligner DR og SR. Til slutt er instruksjon nummer 15 JNE(Jump Not Equal) som hopper til linjenummeret definert av de fire siste bit'ene i instruksjonen, hvis registrene sammenlignet i forrige instruksjon var ulike. Når vi vet dette kan vi oversette Assembly-programmet vi skrev til maskinkode som kan lastes inn i maskinens ROM:\n\n| Linje Nr | I Nr | DR | SR |\n|--------|----|---|---|\n| 0 | 0010 | 00 | 11 |\n| 1 | 0010 | 01 | 01 |\n| 2 | 0010 | 10 | 00 |\n| 3 | 0010 | 11 | 00 |\n| 4 | 0100 | 10 | 01 |\n| 5 | 0100 | 11 | 10 |\n| 6 | 1100 | 10 | 00 |\n| 7 | 1111 | 01 | 00 |\n\nFørste instruksjon er MOVI (0010) og den legger tallet 3 (11) i register nummer 0 (00, det vil si R0 Og tilsvarende for de andre instruksjonene. En kompilator oversetter direkte fra høynivåkode til tilsvarende maskinkode som kan kjøres direkte av datamaskinene. Ved å laste maskinkoden inn i Digital Works-simuleringen, kan man se hvordan dette programmet kjøres instruksjon for instruksjon og til slutt produserer resultatet S = 6.\n\nI prinsippet fungerer moderne CPUer på samme måte som i denne simuleringen. En vesentlig forskjell er at også maskininstruksjonene hentes fra RAM. Da dette tar litt tid og da noen instruksjoner er litt mer omfattende en andre, kan det i noen tilfeller ta mer enn en klokkesyklus å få utført en instruksjon."}
{"identifier": "os3.10", "section_id": "3.10", "section_title": "Løkker og branch control", "source_category": "os", "source_id": "3", "source_title": "Vipper og registre, CPU-arkitektur", "anchor": "SECTION000410000000000000000", "source": "os/Forelesning/os/node4.html", "text": "## 3.10 Løkker og branch control\n\nLegg merke til at siste instruksjon hopper til linje 4, basert på sammenligningen av to registre i forrige instruksjon. Denne muligheten er svært viktig, for den gjør det mulig å utføre alle slags løkker, som for og while-løkker og i tilleg if-tester. I alle disse tilfellen må utførelsen kunne velge å hoppe til et annet sted i programmet basert på et resultat. JNE-instruksjonen (Jump Not Equal) gjør at man hopper til en adresse hvis sammenligningen av to registre i forrige instruksjon viste at de er forskjellige.\n\nHvis man ikke kunne hoppe i koden, ville man bare kunne utføre instruksjoner etterhverandre fra første til siste instruksjon og programmene måtte være enormt lange. Et program med en milliard linjer ville kunne utføres på omtrent ett sekund. Fig. 36 ser vi at det er to bit i DATAPATH, Z og co, som leder til en liten del av CPU-en som kalles branch controll. Disse styrer sammen med to bit fra instruksjonsdekoderen om programkontrollen bare skal oppe til neste instruksjon som den vanligvis gjør når program counter teller oppover, eller om PC istedet skal hoppe til det 4-bits tallet som kommer inn fra de 4 siste bit i ROM der instruksjonen inneholder adressen det eventuelt skal hoppes til.\n\nBranch control gjør at denne enkle CPU-en kan utføre if, for og while og med det i prinsippet kan utføre alle mulige dataprogrammer. Begrensningen en firebits registerstørrelse utgjør er det lett å fjerne ved å bare øke registerstørrelsen til for eksempel 64 bit som de fleste vanlige Intel og AMD CPUer bruker. Logikken er den samme, det blir bare veldig mange flere ledinger å holde styr på.\n\nTotalt kan denne maskinen forøvrig gjøre åtte instruksjoner(men store og load som laster inn og ut fra RAM har bugs):\n\n| binært Nr | operand1 | operand2 | Nr | Navn | Funksjon |\n|---------|--------|--------|---|----|--------|\n| 0000 | DR | SR | 0 | MOV | R[DR] R[SR] |\n| 0010 | DR | tall | 2 | MOVI | R[DR] tall |\n| 0100 | DR | SR | 4 | ADD | R[DR] R[DR] + R[SR] |\n| 0110 | DR | SR | 6 | SUB | R[DR] R[DR] - R[SR] |\n| 1000 | DR | SR | 8 | LOAD | R[DR] M[R[SR]] |\n| 1010 | DR | SR | 10 | STORE | M[R[DR]] R[SR] |\n| 1100 | DR | SR | 12 | CMP | R[DR] - R[SR] = 0? |\n| 1111 | nr | nr | 15 | JNE | PC = nr nr hvis like |\n\nHvilke instruksjoner som kan utføres, hvordan de er nummerert, hva operandene betyr og hvordan de skal tolkes, utgjør tilsammen maskinarkitekturen. Den vanligste arkitekturen i våre dager i PCer og servere er X86-arkitekturen som ble innført av Intel i 1978 og som også brukes av AMD. Men den aller mest produserte prosessoren er basert på ARM (Advanced RISC Machine) som brukes i mobiler. Det var i 2017 produsert mer enn 100 milliarder ARM-prosessorer og 200 milliarder ble passert i 2021."}
{"identifier": "os19.1", "section_id": "19.1", "section_title": "Prøveeksamen 2025", "source_category": "os", "source_id": "19", "source_title": "Prøveeksamen 2025 (og 20 og 21)", "anchor": "SECTION000201000000000000000", "source": "os/Forelesning/os/node20.html", "text": "## 19.1 Prøveeksamen 2025\n\nPrøveeksamen er identisk med konte-eksamen fra høsten 2024.\n\n[Prøveeksamen 2025](https://os.cs.oslomet.no/os/eksamen/eksamenH2024.pdf)\n\n[Løsningsforslag prøveeksamen 2025](https://os.cs.oslomet.no/os/eksamen/fasitH2024.pdf)"}
{"identifier": "os19.2", "section_id": "19.2", "section_title": "Prøveeksamen 2020", "source_category": "os", "source_id": "19", "source_title": "Prøveeksamen 2025 (og 20 og 21)", "anchor": "SECTION000202000000000000000", "source": "os/Forelesning/os/node20.html", "text": "## 19.2 Prøveeksamen 2020\n\nPrøveeksamen er identisk med konte-eksamen fra høsten 2019.\n\n[Prøveeksamen 2020](https://os.cs.oslomet.no/os/eksamen/eksamenH2019.pdf)\n\n[Løsningsforslag prøveeksamen 2020](https://os.cs.oslomet.no/os/eksamen/fasitH2019.pdf)"}
{"identifier": "os19.3", "section_id": "19.3", "section_title": "Prøveeksamen 2021", "source_category": "os", "source_id": "19", "source_title": "Prøveeksamen 2025 (og 20 og 21)", "anchor": "SECTION000203000000000000000", "source": "os/Forelesning/os/node20.html", "text": "## 19.3 Prøveeksamen 2021\n\nPrøveeksamen er identisk med konte-eksamen fra høsten 2020, bortsett fra de 4 siste oppgavene som kom i tillegg.\n\n[Prøveeksamen 2021](https://os.cs.oslomet.no/os/eksamen/eksamenH2020.pdf)\n\n[Løsningsforslag prøveeksamen 2021](https://os.cs.oslomet.no/os/eksamen/fasitH2020.pdf)"}
{"identifier": "os9.3", "section_id": "9.3", "section_title": "Systemkall og timer ticks", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000103000000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.3 Systemkall og timer ticks\n\nEt eksempel på et systemkall er getppid som returnerer PID for prosessens parent, foreldre-prosessen som startet prosessen.\n\n```\nrex:~$ grep getppid /usr/src/linux-source-4.4.0/arch/x86/entry/syscalls/syscall_64.tbl \n110\tcommon\tgetppid\t\t\tsys_getppid\n```\n\nSom vi ser er getppid systemkall nummer 110 for Linux sin 4.4 kjerne. Programmeringsspråket C ble laget samtidig som operativsystemet Unix og er dermed også tett beslektet med Linux. Mange av systemkallene i Linux er egne funksjoner i C. Det er tilfellet for getppid og følgende er et C-program som gjør dette systemkallet 10 millioner ganger.\n\n```\n#include<unistd.h>\n\nint main(void) {\n   int i;\n   for (i=0; i<10000000; i++) {\n      getppid();\n   }\n   return(0);\n}\n```\n\nHvis vi ser på timer-ticks før og etter dette programmet, vil vi se at de fleste av tickene finner sted i kernel eller system mode. Vi tester dette med følgende script `sys.sh` :\n\n```\n#! /bin/bash\n\ngrep cpu3 /proc/stat\ntaskset -c 3 ./getppid\ngrep cpu3 /proc/stat\n```\n\nDette scriptet starter getppid-programmet på CPU 3 og leser ticks fra den CPUen før og etter. Ett tick (også kalt jiffie) varer i 10 millisekunder (ett hundredels sekund) og om for eksempel en CPU bruker all tid i user mode når en prosess kjøres på den, vil denne kolonnen øke med 100 ticks i løpet av ett sekund. De fire første kolonnene i `/proc/stat` er som følger:\n\n* user (1) Time spent in user mode.\n* nice (2) Time spent in user mode with low priority (nice).\n* system (3) Time spent in system mode.\n* idle (4) Time spent in the idle task.\n\nog resultatet av kjøringen er:\n\n```\nrex:~$ ./sys.sh \ncpu3 6354414 5212787 2789939 218067966 804787 0 198336 0 0 0\ncpu3 6354490 5212787 2790067 218067966 804787 0 198336 0 0 0\n```\n\nVi ser at det kun er kolonnene user (1) og system (3) som har endret seg. Av differansen mellom de to første kolonnene ser vi at ved 76 av tickene som ble foretatt mens programmet kjørte, ble programmet kjørt i user-mode. Av differansen i tredje kolonne, ser vi at 128 av tickene skjedde mens programmet var i system elle kernel-mode. Det siste betyr at operativsystemet utførte et systemkall, getppid, på vegne av programmet som ble startet opp i user-mode. Totalt antall ticks adderer opp til 204 og det betyr at programmet totalt brukte 2.04 sekunder CPU-tid på CPU nr 3.\n\nOmtrent det samme kan vi konkludere om vi bruker time-kommandoen til å ta tiden på prosessen:\n\n```\nrex:~/undervisning/OSogUNIX/unixnotater/virt$ time ./getppid\nReal:2.068 User:0.772 System:1.292 99.83%\n```\n\nsom viser at programmet bruker 0.77 sekunder i user-mode og 1.29 sekunder i kernel-mode. Hvis man tar tiden på sys.sh scriptet ser man at det stemmer meget godt overens.\n\n```\nrex:~$ time ./sys.sh \ncpu3 6355584 5212992 2790765 218120204 804824 0 198434 0 0 0\ncpu3 6355662 5212992 2790894 218120205 804824 0 198434 0 0 0\nReal:2.072 User:0.780 System:1.284 99.59%\n```"}
{"identifier": "os9.4", "section_id": "9.4", "section_title": "Prioritet", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000104000000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.4 Prioritet\n\nDet er vanlig å kategorisere prosesser og gi dem prioritet etter hvilken kategori de tilhører.\n\nHvis en prosess i en høyere prioritetsklasse ønsker å kjøre, for eksempel en kjerne-prosess, overtar den med en gang for prosesser fra en lavere prioritetsklasse og kjører til den er ferdig. Innen samme prioritetsklasse tildeles flere timeslices til prosesser med høyere prioritet, slik at de innen samme Round Robin-kø får mer CPU-tid men kjøres samtidig. FCFS (First Come First Served) er en annen scheduler algoritme som brukes for kjerne-tråder (kthreads) som må bli helt ferdige med det de skal gjøre før de avsluttes."}
{"identifier": "os9.4.1", "section_id": "9.4.1", "section_title": "Scheduling-algoritmer", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000104100000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.4.1 Scheduling-algoritmer\n\nScheduling (skedulering) betegner organiseringen av hvordan man tildeler ressurser til en arbeidsoppgave som skal gjennomføres. I mange sammenhenger trenger man algoritmer som sørger for at en arbeidsoppgave blir effektivt fullført og som fordeler tid eller andre ressurser, organiserer jobbflyt og hvordan prosesser utføres og det trenger ikke nødvendigvis å være prosesser i en datamaskin. Noen vanlige algoritmer er:\n\n* RR (Round Robin) Prosesser kjører på omgang, litt tid hver runde\n* FCFS (First Come First Served) Den første prosessen blir først prosessert\n* FIFO (First In Firs Out) Samme som FCFS\n* SJF (Shortest Job First) Den prosessen som tar kortest tid er den neste som kjøres"}
{"identifier": "os9.4.2", "section_id": "9.4.2", "section_title": "Linux-eksempel: nice", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000104200000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.4.2 Linux-eksempel: nice\n\n```\n$ nice -n 9 regn     # Setter nice-verdi til 9 for prosess regn\n$ renice +19 25567   # Endrer nice-verdi til 19\n```\n\n* nice vær snill med andre prosesser\n* Høyere niceverdi gir mindre CPU-tid til prosessen\n* default niceverdi er 0\n* top viser niceverdier"}
{"identifier": "os9.5", "section_id": "9.5", "section_title": "Prosess-prioritet i Windows", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000105000000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.5 Prosess-prioritet i Windows\n\nWindows scheduling har store likeheter med Linux. Prosesser får i utgangspunktet en prioritet som kan endres dynamisk. CPU-prosesser gis gradvis mindre, I/O prosesser gradvis mer. Det finnes 4 forhåndsdefinerte prioritetsklasser:\n\n* IDLE PRIORITY CLASS (prioritet 4)\n* NORMAL PRIORITY CLASS (8)\n* HIGH PRIORITY CLASS (13)\n* REALTIME PRIORITY CLASS (24)\n\nPrioritet for en prosess settes til verdier mellom 1 og 31. Prioritet endres dynamisk og prosessen som kjører et aktivt vindu, gis økt prioritet. Dette kan endres fra task-manager hvis man har admin-rettigheter og først velger 'go to details'. Men det er svært stor forskjell på prioritestnivåene som blir satt i task-manager."}
{"identifier": "os9.6", "section_id": "9.6", "section_title": "Prosessforløp", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000106000000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.6 Prosessforløp\n\nDenne figuren viser de viktigste tilstandene i et prosessforløp. Prosesser som ligger i ready-list ønsker så snart som mulig å bli tildelt tid i prosessoren og dermed komme over i tilstand running. Prosesser som venter av fri vilje eller som for eksempel må vente på Input/Output (I/O) settes i waiting-tilstand."}
{"identifier": "os9.6.1", "section_id": "9.6.1", "section_title": "Sentrale schedulingbegreper", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000106100000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.6.1 Sentrale schedulingbegreper\n\n**Enqueuer**: \n  * Legger i kø\n  * Beregner prioritet\n\n**Dispatcher**: \n  * Velger prosess fra READY LIST; liste med prosesser som er klare til å kjøre"}
{"identifier": "os9.6.2", "section_id": "9.6.2", "section_title": "Prosessforløp-demo", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000106200000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.6.2 Prosessforløp-demo\n\n[En mp4-demo av dette prosessforløpet kan sees her](https://os.cs.oslomet.no/os/demoer/prosess.mp4)"}
{"identifier": "os9.7", "section_id": "9.7", "section_title": "Lage en ny prosess", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000107000000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.7 Lage en ny prosess\n\nDet mest sentrale konseptet for et operativsystem er prosessen. De følgende avsnitt viser hvordan prosesser fødes, lever og dør på Linux og Windows. Alle moderne OS har en mekanisme for å lage nye prosesser. Prosesser lages ved\n\n* System oppstart (Linux: init-prosessen)\n* En kjørende prosess utfører et systemkall som staret en ny prosess\n* En bruker ber om at en prosess startes\n\nBortsett fra ved systemoppstart er det alttid en prosess som lager en annen og den prosessen kalles en forelder-prosess. I prosessverdenen er det bare en forelder til ett eller flere barn. En parent-prosess lager en child-prosess."}
{"identifier": "os9.7.1", "section_id": "9.7.1", "section_title": "Linux: fork()", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000107100000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.7.1 Linux: fork()\n\nfork() er et Linux-systemkall for å lage en child-prosess. fork() lager en kloning, identisk prosess med kopi av program, data og PCB (bortsett fra PID, PPID og noen andre).\n\nVanligvis starter child med å laste inn koden for det programmet det skal kjøre, slik at child-prosessen likevel blir forskjellig fra parent-prosessen.\n\nLinux-prosesser lager på denne måten et hierarki av prosesser med barn og barnebarn. Det kan da være mulig å sende signaler til alle prosessene i et hierarki."}
{"identifier": "os9.7.2", "section_id": "9.7.2", "section_title": "Windows: CreateProcess", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000107200000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.7.2 Windows: CreateProcess\n\nWin 32 API'et har også støtte for fork(), men standardmetoden for å lage en ny prosess er å gjøre et kall til `CreateProcess` med 10 parametre. Da lages et nytt prosess-objekt; hvilket program som skal kjøres, vinduer som skal åpnes, prioritet mm overføres med parameterene til kallet. Bindingen mellom parent og child er ikke like sterk som under Linux. Windowsprosesser kan gjøre sine barn arveløse."}
{"identifier": "os9.8", "section_id": "9.8", "section_title": "Avslutte prosesser", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000108000000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.8 Avslutte prosesser\n\nVanligvis avsluttes prosesser når jobben er ferdig. Noen prosesser, såkalte daemons, kjører hele tiden mens systemet er oppe. Prosesser avsluttes ved:\n\n* Normal avslutning. Frivillig. Linux: exit, Windows: ExitProcess\n* Avslutning ved feil. Frivillig. (f. eks. 'file not found')\n* Fatal feil. Ufrivillig. (division by zero, Segmentation fault, core dumped)\n* Drept av annen prosess. Ufrivillig. Linux: kill, Windows: TerminateProcess"}
{"identifier": "os9.8.1", "section_id": "9.8.1", "section_title": "Signaler", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000108100000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.8.1 Signaler\n\nProsesser kan kommunisere med hverandre ved hjelp av signaler. En bruker kan også sende et signal til en prosess, CTRL-C er et eksempel på et slikt signal som prøver å avslutte prosessen. Under Linux kan en prosess selv velge hva den skal gjøre når den mottar et signal. For eksempel er standard oppførsel for en prosess å avslutte når den mottar et CTRL-C signal, men den kan velge å ignorere det. Med kommandoen kill kan man sende mange forskjellige signaler og `kill -9` er et såkalt ustoppelig signal som dreper prosessen enten den vil eller ikke. For kill-signaler er det en forutsetning at den som sender signalet har riktig rettigheter, ellers vil signalet ikke ha noen effekt."}
{"identifier": "os9.8.2", "section_id": "9.8.2", "section_title": "Signaler og trap i bash-script", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000108200000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.8.2 Signaler og trap i bash-script\n\nEn prosess kan stoppes av andre prosesser og av kjernen. Det gjøres ved å sende et signal. Alle signaler bortsett fra SIGKILL ( `kill -9` ) kan stoppes og behandles av bash-script med kommandoen `trap` . Følgende script kan bare stoppes ved å sende ( `kill -9` ) fra et annent shell.\n\n```\n#! /bin/bash\n\n# definisjoner fra fra /usr/src/linux-2.2.18/include/asm-i386/signal.h:\n#define SIGHUP          1       /* Hangup (POSIX).  */\n#define SIGINT          2       /* Interrupt (ANSI).  */\n#define SIGKILL         9       /* Kill, unblockable (POSIX).  */\n#define SIGTERM         15      /* Termination (ANSI).  */\n#define SIGTSTP         20      /* Keyboard stop (POSIX).  */\n\ntrap 'echo -e \"\\rSorry; ignores kill -1 (HUP)\\r\"' 1\ntrap 'echo -e \"\\rSorry; ignores kill -15 (TERM)\\r\"' 15\ntrap 'echo -e \"\\rSorry; ignores CTRL-C\\r\"' 2\ntrap 'echo -e \"\\rSorry; ignores CTRL-Z\\r\"' 20\ntrap 'echo -e \"\\rSorry; ignores kill - 3 4 5\\r\"' 3 4 5\ntrap 'echo -e \"\\rCannot stop kill -9\\r\"' 9\n\nwhile [ true ]\ndo\n   echo -en \"\\a quit? Answer y or n: \"\n   read answer\n   if [ \"$answer\" = \"y\" ]\n        then break\n   fi\ndone\n```"}
{"identifier": "os9.9", "section_id": "9.9", "section_title": "OS arkitektur", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000109000000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.9 OS arkitektur\n\nDen vanligste om ikke den beste måten å designe et OS på er en såkalt monolittisk arkitektur. Linux er et typisk eksempel på dette. Alle metoder i koden har tilgang til alle datastrukturer i kjernen. Dette gjør at kjernen blir hurtig og effektiv, men åpner for flere bugs. Windows NT kjernen er objektorientert og skrevet i C++ og har gjennom dette en ryddigere struktur. En ulempe med Windows er at GUI delvis inngår i kjernen slik at den blir mye mer omfattende. En bedre arkitektur er en såkalt microkernel. Bare det helt essensielle utføres av kjernen, som multitasking og behandling av interrupts. Resten utføres utenfor kjernen av prosesser i usermode som kommuniserer med hverandre og mikrokjernen."}
{"identifier": "os9.9.1", "section_id": "9.9.1", "section_title": "Linux arkitektur", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000109100000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.9.1 Linux arkitektur\n\nIllustrasjon:\nLinux arkitektur"}
{"identifier": "os9.9.2", "section_id": "9.9.2", "section_title": "Windows arkitektur", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION000109200000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.9.2 Windows arkitektur\n\nIllustrasjon:\nWindows arkitektur"}
{"identifier": "os9.10", "section_id": "9.10", "section_title": "Design av systemkommandoer", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION0001010000000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.10 Design av systemkommandoer\n\nAnalogt med forholdet mellom privilegert modus og usermodus er forholdet mellom superuser og en vanlig bruker. Men et program som kjører som root har bare utvidede rettigheter i forhold til filsystemet og devicer, det kjøres ikke som en del av OS-kjernen. To muligheter (eksempler fra Linux) ved design av systemkommandoer.\n\n* Root-rettigheter (noen få: ping, mount, su, ...)\n  * tilgang på alle filer\n  * mye sikkerhets-overhead (alt må sjekkes)\n  * stor sikkerhetsrisiko (kan være sikkerhetshull)\n  * betrodd software\n* Vanlig bruker-rettigheter (de fleste: ls, ps, mv,...)\n  * Sikrere (*begrensede rettigheter*)\n  * Lite feilsjekking lite overhead"}
{"identifier": "os9.10.1", "section_id": "9.10.1", "section_title": "Linux-eksempel: setuid-bit", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION0001010100000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.10.1 Linux-eksempel: setuid-bit\n\n```\ngroup1@osG1:~$ ls -l /bin/ls\n-rwxr-xr-x 1 root root 114032 jan.  26  2013 /bin/ls\ngroup1@osG1:~$ ls -l /bin/ping\n-rwsr-xr-x 1 root root 36136 april 12  2011 /bin/ping\n```\n\n*Kommandoen /bin/ls kjører med vanlige brukerrettigheter, men for /bin/ping \nbetyr s'en på eierrettighetene at setuid-bit er satt. Dette betyr at en vanlig \nbruker kjører ping med root-rettigheter. Setuid-programmer er en stor sikkerhetsrisiko.* Setuid-bit settes med\n\n```\n$ chmod 4755 program  # Setter SETUID-bit\n$ chmod 0755 program  # Skrur av SETUID-bit\n```"}
{"identifier": "os9.11", "section_id": "9.11", "section_title": "Utbredelse av Operativsystemer", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION0001011000000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.11 Utbredelse av Operativsystemer\n\nDet finnes mange undersøkelser om utbredelsen av operativsystemer og det er vanskelig å få en eksakt oversikt fra åpne kilder."}
{"identifier": "os9.11.1", "section_id": "9.11.1", "section_title": "Desktop OS", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION0001011100000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.11.1 Desktop OS\n\nFølgende er statistikk for desktop-OS basert på hva slags OS de som er inne på web-sider bruker. Slik så tallene ut i 2007:\n\n```\nWindows XP      85.30% \nWindows 2000    5.00% \nMac OS          4.15% \nWindows 98      1.77% \nMacIntel        1.52% \nWindows ME      0.89% \nWindows NT      0.68% \nLinux \t        0.37% \nWindows Vista   0.16%\n```\n\nTallene er hentet fra [marketshare.hitslink.com.]( \nhttps://marketshare.hitslink.com\n) . De blir laget månedlig fra statistikk over hva slags OS som blir brukt av ca 160 millioner besøkende pr måned som er innom mer enn 40.000 forskjellige webservere verden over. En annen kilde med lignende statistikk er [https://gs.statcounter.com.]( \nhttps://gs.statcounter.com\n) .\n\nI 2009 så det slik ut:\n\n```\nWindows XP      63.76% \n Windows Vista \t 22.48% \n Mac OS X 10.5   5.28% \n Mac OS X 10.4   2.74% \n Windows 2000    1.37% \n Mac OS X        1.00% \n Linux           0.83%\n```\n\n2012:\n\n```\nDesktop Operating System Market Share February, 2012\nWindows XP     45.39%\nWindows 7      38.12%\nWindows Vista  8.10%\nMac OS X 10.6  3.00%\nMac OS X 10.7  2.69%\nLinux          1.16%\nMac OS X 10.5  0.95%\nMac OS X 10.4  0.23%\nWindows 2000   0.15%\nWindows NT     0.06%\nWindows 98     0.05%\n```\n\n2017\n\n```\nTOTAL MARKET SHARE\nWindows 7       48.41%\nWindows 10      25.19%\nWindows XP      8.45%\nWindows 8.1\t6.87%\nMac OS X 10.12  2.91%\nLinux           2.05%\nWindows 8       1.65%\nMac OS X 10.11  1.55%\nMac OS X 10.10  1.00%\nWindows Vista   0.78%\nWindows NT      0.39%\nMac OS X 10.9   0.35%\n```\n\n2019\n\n```\nWindows 7\t40.17%\nWindows 10\t37.35%\nWindows 8.1\t4.87%\nMac OS X 10.13\t4.36%\nWindows XP\t3.91%\nMac OS X 10.14\t1.88%\nMac OS X 10.12\t1.51%\nLinux\t        1.49%\nWindows 8\t0.99%\nMac OS X 10.11\t0.98%\n```\n\n2021\n\n```\nWindows 10\t55.17%\nWindows 7\t27.09%\nWindows 8.1\t3.41%\nMac OS X 10.14\t3.34%\nMac OS X 10.15\t2.96%\nMac OS X 10.13\t1.52%\nLinux\tLinux\t1.37%\nWindows XP\t1.35%\nLinux\tUbuntu\t0.81%\nMac OS X 10.12\t0.65%\n```\n\nIllustrasjon:\nSlik så trenden ut mellom 2018 og 2019, ikke så store endringer frem til 2021.\n\nTilsvarende tall for webbrowsere er som følger;\n\n```\n2007\nInternet Explorer  79.64% \nFirefox            14.00% \nSafari \t           4.24% \nOpera \t           0.87% \nNetscape           0.85% \nMozilla            0.22%\n```\n\n```\n2009\nInternet Explorer  67.55% \nFirefox            21.53% \nSafari             8.29% \nChrome             1.12% \nOpera              0.70%\n```\n\n```\n2012\nInternet Explorer  52.84%\nFirefox            20.92%\nChrome             18.90%\nSafari             5.24%\nOpera              1.71%\n```\n\n```\n2017\nChrome             58.22%\nInternet Explorer  19.45%\nFirefox            11.73%\nMicrosoft Edge     5.51%\nSafari             3.46%\nOpera              1.26%\n```\n\n```\n2019\nChrome\t          65.00%\nInternet Explorer 10.23%\nFirefox\t          9.72%\nEdge\t          4.33%\nSafari\t          3.74%\nOpera\t          1.57%\n```\n\n```\n2021\nChrome\t                68.75\nFirefox\t                7.91\nEdge\t                7.36\nInternet Explorer\t5.86\nSafari\t                3.64\nQQ\t                1.76\nSogou Explorer\t        1.67\nOpera\t                1.22\n```"}
{"identifier": "os9.11.2", "section_id": "9.11.2", "section_title": "Server OS", "source_category": "os", "source_id": "9", "source_title": "Prosesser, OS-arkitektur", "anchor": "SECTION0001011200000000000000", "source": "os/Forelesning/os/node10.html", "text": "## 9.11.2 Server OS\n\nServertall er vanskligere å finne fra åpne kilder. Netcrafts rapport fra Mars 2008 visete at av de 162 millioner webserverene de hadde mottatt respons fra i sin undersøkelse, kjørte ca 60% apache(typisk med Linux som OS), ca 30% Microsoft webserver og 10% på andre plattformer. Fire år etter så det litt anderledes ut, apache hadde økt andelen noe. ( [Se detaljer her.](\nhttp://news.netcraft.com/archives/2012/03/05/march-2012-web-server-survey.html\n) ) I 2019 hadde bildet endret seg med flere Microsoft webservere og ( [detaljene kan sees her.](\n\nhttps://news.netcraft.com/archives/2019/02/28/february-2019-web-server-survey.html\n  ) )\n\nI 2020 har bildet igjen endret seg og Nginx er den mest brukte webserveren. ( [detaljene kan sees her.](\nhttps://news.netcraft.com/archives/2020/\n  ) )\n\nDet mest korrekte bildet får man trolig av å se på 'active sites' som har reelle webservere som leverer innhold og ikke kun er reklame for f.eks. salg av domenenavn.\n\n[En wikipedia artikkel](\nhttps://en.wikipedia.org/wiki/Usage_share_of_operating_systems\n) prøver å gi en oversikt over utbredelse av server-OS."}
{"identifier": "os13.2", "section_id": "13.2", "section_title": "Internminne", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION000142000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.2 Internminne\n\nOm internminnet bruker man ofte betegnelsen RAM som er en forkortelse for Random Access Memory. Det kalles 'Random' fordi hvilken som helst byte kan leses ut eller aksesseres like raskt som enhver annen byte. Men som vi skal se vil det i praksis ikke alltid stemme at det tar like lang tid å laste inn to forskjellige byte fra RAM. En årsak til dette som gjelder for de aller fleste systemer er cache som mellomlagrer data. Hvis vi henter inn verdine på en variabel og denne ligger i cache, går inntil ti ganger raskere enn om den må hentes helt fra RAM. En annen årsak som gjelder større servere er at servere med flere titalls CPU-er ofte er delt inn i såkale numanodes som kommuniserer raskere med enkelte tilordnede deler av RAM. Dette kan utgjøre en hastighetsforskjell på inntil to tre ganger.\n\nVi så i avsnitt [7.3](node8.html#IogC) at både CPU-registre og cache er laget av SRAM (Static RAM), men det er ikke en del av internminnet. Aksess til SRAM er ekstremt hurtig og SRAM er statisk i den betydning at det ikke trenger å oppfriskes. Internminnet er laget av DRAM som står for Dynamic RAM. Mer en 10 ganger i sekundet må DRAM opplades, ellers forsvinner informasjonen. SRAM består av 6 transistorer for hver bit som lagres. Men DRAM trenger bare en transistor og en kapasitator(lagrer elektrisk ladning) for å lagre en bit. Derfor er DRAM billigere, mindre, bruker mindre effekt og kan lages i større enheter. Internminnet består derfor av DRAM eller forbedrede varianter av DRAM. DDR5 SDRAM (Double-Data Rate generation 5 Synchronus Dynamic RAM) er et av de foreløpig siste leddene av kjedene av forbedrede utgaver av DRAM.\n\nI samme avsnitt viste Fig. 78 noen typiske størrelser og aksesstider for de sentrale lagringsmedien som finnes i en datamaskin, fra registre til harddisk. Legg spesielt merke til den store forskjellen i aksesstid mellom internminnet og harddisk, selv moderne superraske SSD-disker er tusen ganger tregere.\n\nIllustrasjon:\nMinne-pyramiden. Størrelsen og tiden det tar å hente data øker nedover pyramiden.\n\nInternminnet (RAM, Random Access Memory/arbeidsminne) er et stort array av bytes: Alle disse adressene utgjør tilsammen det *fysiske minnet* siden det er adresser til fysisk DRAM enheter som lagrer bit.\n\nI følgende tabell kan man se hvor mange adresser det er plass til for forskjellige størrelser av registre. Det totalet antall adresser som finnes for en gitt størrelse av et register kalles et adresserom.\n\n| Registerstørrelse (i bit) | antall mulige adresser |\n|-------------------------|----------------------|\n| 16 | = 64 K, Kilo, |\n| 32 | 4 G, Giga, |\n| 48 | 256 T, Tera, |\n| 64 | 20 E,Exa, |"}
{"identifier": "os13.3", "section_id": "13.3", "section_title": "Virtuelt adresserom", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION000143000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.3 Virtuelt adresserom\n\nGenerelt er det ikke plass til alle programmer i internminnet på en gang. Derfor gir man hvert enkelt program sitt eget virtuelle adresserom fra 0 til det programmet måtte trenge. Er adresse-registeret 32 bit, er typisk det virtuelle adresserommet opp til 4Gbyte. Det vil da virke for prosessen som den har tilgang til alt dette minnet. Men i virkeligheten er ikke nødvendigvis alt i bruk og av det som er i bruk kan noe ligge i RAM og andre deler på disk.\n\nDisse virtuelle eller logiske adressene brukes overalt hvor programmet refererer til seg selv, for eksempel i en instruksjon som\n\n```\nmov (1023), %al\n```\n\nsom betyr last inn byte nummer 1023 i det 8 bit store registeret %al. 1023 er da den virtuelle adressen. Når programmet lastes inn i internminnet og kjøres vil det variere hvor i det fysiske minnet programmet legges. Det må derfor være mulig å oversette mellom virtuelle og fysiske adresser."}
{"identifier": "os13.4", "section_id": "13.4", "section_title": "Internminnet/RAM", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION000144000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.4 Internminnet/RAM\n\nEt kjørbart program ligger i utgangspunktet på harddisken, men må lastes inn i internminnet før det kan kjøres. Skjematisk må kildekode gjennom prosessen i Fig. 69 før den kan kjøres.\n\nIllustrasjon:\nLoading av et brukerprogram/en prosess"}
{"identifier": "os13.5", "section_id": "13.5", "section_title": "C++ library", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION000145000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.5 C++ library\n\nHvis man lager C++-prosjekter og har metoder man ofte bruker, kan man lage sin egen library-fil som man kobler sammen med hovedprogrammet når man skal bruke det. Kompileringen av biblioteksfilen kan se slik ut:\n\n```\ng++ -c calcTools.cpp                         # Lager maskinkode calcTools.o\ng++ -c randTools.cpp                         # Lager maskinkode randTools.o\nar rcv libTools.a  calcTools.o   randTools.o # Lager lib-filen libTools.a\n```\n\nSenere kan dette biblioteket brukes i et prosjekt:\n\n```\ng++ -c -I../Tools mainsim.cpp       # Lager maskinkode mainsim.o\ng++ -c -I../Tools simulation.cpp    # Lager maskinkode simulation.o\ng++ -c  -I../Tools user.cpp         # Lager maskinkode user.o\ng++ -o sim mainsim.o simulation.o user.o  -lm  -L../Tools -lTools\nsim  # Kjører programmet\n```\n\nDette linker (limer sammen) de 3 programmene med libTools.a (som loaderen finner pga -L../Tools) og andre biblioteker (-lm tar med et matte-bibliotek) og lager en kjørbar fil med navn sim. Man kan også lage et dynamisk (shared) library med filendelse so.\n\n```\ng++ -fpic -c randTools.cpp\ng++ -fpic -c calcTools.cpp\ng++ -shared -o libsTools.so randTools.o calcTools.o\n\ng++ -o sim mainsim.o simulation.o user.o  -lm  -L../sTools -lsTools\nexport LD_LIBRARY_PATH=\"../sTools\"\nsim  # Kjører programmet\n```"}
{"identifier": "os13.6", "section_id": "13.6", "section_title": "Layout av en prosess sitt adresserom/segmentation", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION000146000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.6 Layout av en prosess sitt adresserom/segmentation\n\nDet virtuelle adresserommet til en prosess er delt opp i regioner eller segmenter og de følgende er de viktigste:\n\n* Den statiske binære koden som prosessen kjører, text segmentet, ofte bare kalt text\n* Heap`en hvor globale variabler og data som dynamisk generers lagres\n* Stack`en hvor de lokale variablene lagres, brukes også til funksjonskall\n* MMAP, minneavbildninger av filer(og devicer) på disk direkte i det virtuelle minnet\n\nIllustrasjon:\nLayout for det virtuelle adresserommet for en Linux-prosess."}
{"identifier": "os13.7", "section_id": "13.7", "section_title": "Minneadressering og MMU", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION000147000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.7 Minneadressering og MMU\n\nEt programs virtuelle adressering til variabler, subrutiner, bibliotek, data og så videre må knyttes til fysiske adresser. Dette kunne skjedd ved loading, men ville vært svært tidkrevende og tungvint. I moderne OS gjøres dette dynamisk mens programmene kjører. Dette muligjør at programmer og biblioteker kan flyttes til og fra harddisk og bare loades når det er behov for dem. Om OS skulle oversette fysiske adresser til logiske/virtuelle, ville det belaste CPU-en for mye, så dette tar en egen enhet, MMU (Memory Managment Unit), seg av.\n\nIllustrasjon:\nMMU oversetter logiske adresser fra CPU til fysiske RAM-adresser i realtime"}
{"identifier": "os13.8", "section_id": "13.8", "section_title": "Eksempel på MMU-tabell", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION000148000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.8 Eksempel på MMU-tabell\n\nAnta at de to programmene Prog1 og Prog2 skal kjøre på en maskin. Som i Fig. 72 vil adressene i de kompilerte programmene være logiske og ikke til en fastlagt adresse i minne. Dette fordi man da bare trenger å oppdatere MMU-tabellene når programmene plasseres eller omplasseres i RAM.\n\nIllustrasjon:\nDen kompilerte Prog1 og Prog2 maskinkoden inneholder logiske adresser Når CPU utfører instruksjonen 'load 32' for Prog1 som refererer til minnet sendes den logiske adressen 32 til MMU som bruker sin tabell for Prog1-adresser til å oversette til den fysiske adressen 132, slik at riktig byte blir loadet. MMU trenger da tabeller som ser slik ut:\n\n| Prog1 | Prog2 |   |   |\n|-----|-----|---|---|\n| 0 | 100 | 0 | 150 |\n| . | . | . | . |\n| . | . | . | . |\n| 24 | 124 | 28 | 178 |\n| . | . | . | . |\n| . | . | . | . |\n| 32 | 132 | 36 | 186 |\n| . | . | . | . |\n| 40 | 140 | 40 | 190 |\n\nMen det vil være alt for minnekrevende å ha en linje i tabellen for hver adresse! Det logiske minnet deles derfor opp i pages som legges i det fysiske minnet hver for seg. I eksempelet over kunne en page f. eks. utgjøre 50 adresser. MMU trengte da bare å vite at Prog1 starte på adresse 100 og at Prog2 startet på adresse 150."}
{"identifier": "os13.9", "section_id": "13.9", "section_title": "Paging", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION000149000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.9 Paging\n\nVed å dele inn minnet i like store biter (pages/sider), vil man effektivt kunne laste disse sidene inn og ut av minnet og samtidig enkelt holde oversikt over hvor hver side er i en page-tabell. Dette gjør at det er enkelt og plassbesparende å dynamisk allokere (sette av) nytt minne til en prosess. Man unngår den fragmentering som ville oppstått om vilkårlig store biter av minnet ble tildelt en prosess. Når prosessen ble avluttet, ville det da blit et hull med tilgjengelig med akkurat denne størrelsen. Ved å bruke faste sidestørrelser, unngår man slike ujevnt store hull. Inndelingen i sider gjør at deler av programmer effektivt kan lastes inn og ut av minnet og dermed gjør det enkelt å implementere virtuelt minne. En viktig fordel for OS er at med full oversikt over en prosess sitt minnet i en page-tabell, er det lett å kontrollere at prosessen bare skriver til det minnet den er tildelt. Oppsummert har bruk av logiske eller virtuelle minneadresser og inndeling av disse i sider av samme størrelse har følgende fordeler:\n\n* Fast sidestørrelser hindrer fragmentering\n* Dynamisk flytting av deler av prosesser til og fra disk\n* Full kontroll for OS over prosessers minnebruk\n* Mulliggjør å bruke diskplass til å utvide minnet, virtuelt minne"}
{"identifier": "os13.10", "section_id": "13.10", "section_title": "Pages", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION0001410000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.10 Pages\n\nEn page har en størrelse bytes og typisk er n = 12 eller 13 og page-størrelsen er dermed 4 eller 8 Kbytes. Den konkrete størrelsen avhenger av prosessorens arkitektur. 4Kbytes er vanlig for X86-prosessorer. Figur 73 hviser et eksempel på hvordan pages kan fordeles i minnet og hvor enkel MMU-tabellen da blir. Ved en context switch lagres tabellen for den gamle prosessen i dens PCB og tabellen til den nye prosessen lastes inn i MMU.\n\nIllustrasjon:\nLogisk minne og paging\n\nEn prosess som bruker 100Mbyte minne vil med 4Kbyte page størrelse bestå av omtrent 25.000 sider men en prosess som bruker 4GByte RAM vil ha en million sider i MMU. Det er ikke plass til å lagre adressen til alle disse sidene i selve MMU og den fullstendige tabellen ligger selv i internminnet. Men MMU bruker en Translation Lookaside Buffer (TLB) som er hurtig cache minne som inneholder en del av page-tabellen. Ved oppslag på adresser til sider som ikke ligger her, hentes de fra minnet, men da tar det vesentlig lenger tid."}
{"identifier": "os13.11", "section_id": "13.11", "section_title": "MMU eksempel med 4k page-størrelse", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION0001411000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.11 MMU eksempel med 4k page-størrelse\n\nI Figur 74 som er hentet fra Tanenbaum, ser man et eksempel på en avbilding fra det virtuelle 64K store virtuelle adresserrommet til det 32K store fysiske adresserommet. Vanligvis er begge adresserom mye større. Og man må huske at hver prosess får tildelt sitt eget adresserom og dette peker på fysiske adresser i RAM. Andre prosesser vil da peke til andre steder i RAM. Hver gang det gjøres en context switch og en annen prosess starter å kjøre på en CPU, må denne prosessens MMU-tabell lastes inn før den kan begynne å kjøre. Dette er eksempel på en slik tabell etter at den er lastet inn. Vi ser at det er åtte (0-7) virtuelle pages som peker på åtte fysiske page-frames i RAM.\n\nIllustrasjon:\nFigure 3-9 i Tanenbaum. Forholdet mellom virtuelle og fysiske adresser\n\nNår MMU mottar en innkommende virtuell adresse, 8196 i eksempelet i Figur 75 , må denne adressen ekstremt hurtig oversettes til en fysisk adresse. I dette tilfellet er side-størrelsen 4K og 12 bit vil da kunne brukes til å adressere hele siden. Det virtuelle adresserommet er på 64k og man trenger da 16 bit for å adressere hele dette adresserommet.\n\nIllustrasjon:\nFigure 3-10 i Tanenbaum. Slik oversetter MMU virtuelle(logiske) adresser til fysiske.\n\nVi ser at de fire første bit'ene brukes til å angi hvilket nummer i rekken av 16 pages som en adresse hører til. I eksempelet er de fire første bit'ene 0010 = 2 og det betyr dermed virtuell page nr. 2. MMU-tabellen viser hvilken fysisk frame hver av de 16 virtuelle sidene peker på og vi ser at page 2 peker på fysisk frame nummer 110 = 6. Dette kan vi også se i Figur 73 , der en pil viser at page nummer 2 peker på fysisk frame nummer 6 (man starter å telle på null). Oversettelsen skjer lynraskt ved at de tre bit'ene i indeks 2 i MMU-tabellen, 110, hektes på foran de 12 bit'ene som forteller hvor i den 4K store framen byte'en som ønskes ligger. Dette gir dermed øyeblikkelig den utgående adressen 24580. Det fysiske adresserommet er på 32k og 15 bit er da nok til å dekke hele adresserommet.\n\nHver page har 2 `^` 12 = 4096 adresser. Page 0 begynner på 0, page 1 begynner på 4096, page 2 begynner på 8192 og så videre. Inkommende adresse er 8196, fordi den er 2x4096 (første byte page 2, 0010) + offset 4 (100) som tilsammen blir 8192 + 4 = 8196. Den utgående adressen til fysisk frame blir 24580, fordi den er 6*4096 (første byte page 6, 110) + offset 4 (100) som tilsammen blir 24576 + 4 = 24580."}
{"identifier": "os13.12", "section_id": "13.12", "section_title": "Paging og swapping", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION0001412000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.12 Paging og swapping\n\nÅ dele in det logiske minnet i pages gjør det mulig å dynamisk laste inn og ut deler av en prosess. Dermed kan minnet til det samlede antall prosesser på en maskin være større enn det fysiske minnet, resten lagres page for page på harddisk på swap-området. Det virtuelle minnet til en prosess kan da fysisk lagres både i RAM og på disk. I Fig. 77 har fysisk minne bare plass til 3 pages og resten må lagres på disk. Det å laste pages til og fra swap-området på disken kalles \"paging\".\n\nIllustrasjon:\nVirtuelt minne. Bare en page av Prog2 ligger i minne. Om data fra \npage 5 eller 6 blir spurt etter, må disse lastes inn.\n\nTidligere var swapping eneste måte å bruke disk til virtuelt minne; da blir hele prosessen lastet ut på disk. Med en disk med lesehastighet på 100MByte/s tar det 10 sekunder å swappe en prosess på 1 GByte. Swapping brukes i moderne OS oftest bare når det er ekstrem mangel på minne. Er det fysiske minnet altfor lite, vil OS bruke nesten all sin tid på å flytte sider til og fra disk; dette kalles trashing. Det er viktig å huske at det kan ta flere hundere tusen ganger så lang tid å hente pages fra en disk som å aksessere RAM, så virtuelt minne kan på ingen måte fullt ut erstatte RAM."}
{"identifier": "os13.13", "section_id": "13.13", "section_title": "Page Table entry", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION0001413000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.13 Page Table entry\n\nIllustrasjon:\nPage table entry.\n\n* Page Frame nummer: Fysisk frame-nummer i RAM\n* Present: Hvis 0 blir det en page-fault\n* Endret: Hvis 1 er siden dirty og må skrives til disk om den fjernes\n* Rettigheter: lese, skrive, kjøre\n* Referenced: settes hvis brukt, brukes av paging-algoritmer"}
{"identifier": "os13.14", "section_id": "13.14", "section_title": "TLB - Translation Lookaside Buffer", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION0001414000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.14 TLB - Translation Lookaside Buffer\n\n* En prosess som bruker 100Mbyte minne vil med 4Kbyte page størrelse bestå av omtrent 25.000 sider\n* 4GByte prosess gir en million sider i MMU\n* Ikke plass til å lagre adressen til alle disse sidene i MMU\n* Den fullstendige tabellen ligger selv i internminnet\n* MMU bruker en Translation Lookaside Buffer (TLB) som er hurtig cache minne\n* Inneholder en liten del av page-tabellen,\n* Ved oppslag på adresser til sider som ikke ligger i TLB, hentes de fra RAM\n* Kalles TLB-miss eller soft-miss. Tar vesentlig lenger tid enn om adressen er i TLB"}
{"identifier": "os13.15", "section_id": "13.15", "section_title": "Typisk TLB ytelse", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION0001415000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.15 Typisk TLB ytelse\n\n* størrelse: 16 - 4096 linjer (1 - 256 kBytes)\n* En cache linje er vanligvis 64 bytes\n* oppslagstid: 0.5 - 1 klokke-sykel\n* ekstra tid ved TLB-miss: 10-100 klokke-sykler\n* TLB-miss frekvens: 0.01 - 1%"}
{"identifier": "os13.16", "section_id": "13.16", "section_title": "Internminnet og Cache", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION0001416000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.16 Internminnet og Cache\n\nVi har tidligere sett at for å kunne fore en hurtig prosessor med instruksjoner og data raskt nok, bruker man flere nivåer av mellomlagring av data, såkalt cache-minne. Det går vesentlig raskere å hente minne fra cache-minnet enn fra internminnet. I Fig. [45](node8.html#Cache) så vi noen typiske størrelser og aksesstider for de sentrale lagringsmedien som finnes i en datamaskin, fra registre til harddisk. Spesielt bemerket vi den store forskjellen i aksesstid mellom internminnet og harddisk.\n\nCache inneholder både data, instruksjoner og deler av MMU page-tables i TLB (Translation Lookaside Buffer). I L1 cache er ofte disse egne enheter, mens L2 cache pleier å være en enhet. I de senere årene har man klart å få plass til L2 på selve prosessorchip'en (den lille brikken som utgjør mikroprosessoren, bare noen kvadratcentimeter stor). Arkitekturen til en moderne prosessor kan da i grove trekk se ut som i Fig. 78 .\n\nIllustrasjon:\nLevel 1 cache (L1) bestående av tre deler. I AMD Athlon 64 er TLB i tillegg delt i to deler, en for \nadresser til instruksjoner og en for adresser til data. Noen arkitekturer har i tillegg enda et lag i minnehierarkiet, en offchip L3 cache som sitter mellom mikroprosessoren og RAM. For Intel Core i7 og AMD Opteron K10 har også L3 cache fått plass på prosessor-chip'en."}
{"identifier": "os13.17", "section_id": "13.17", "section_title": "Paging-algoritmer", "source_category": "os", "source_id": "13", "source_title": "Internminne", "anchor": "SECTION0001417000000000000000", "source": "os/Forelesning/os/node14.html", "text": "## 13.17 Paging-algoritmer\n\n* Page-fault (En page mangler i minnet; ligger på swap på disk)\n* Ingen ledig frame i minnet\n* OS må velge hvilken page som skal legges på disk\n* Gjøres av paging-algoritme"}
{"identifier": "os7.1", "section_id": "7.1", "section_title": "CPU-intensiv prosess på Mac med to CPU'er", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION00081000000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.1 CPU-intensiv prosess på Mac med to CPU'er\n\nMac OS X sin operativsystemkjerne heter Darwin og bygger blant annent på FreeBSD-kjernen som er en Unix-kjerne bygd på den opprinnelig BSD Unix-versjonen. Dermed følger det som standard også med mye som er kjent fra Linux. For eksempel kan får man opp et bash-shell når man starter opp et Mac OS X-terminalvindu:\n\n```\nharek-haugeruds-macbook:~ hh$ uname -a\nDarwin dhcp-202-136.wlan.hio.no 9.5.1 Darwin Kernel Version 9.5.1: Fri Sep 19 16:19:24 PDT 2008; root:xnu-1228.8.30~1/RELEASE_I386 i386\n```\n\nSom vi ser er dette kjerneversjon 9.5.1 av Darwin og denne har en rettferdig måte å dele to CPU'er mellom tre prosesser på. Når man kjører det samme regn-scriptet, får man følgende resultat:\n\n```\n$ top -o cpu\nProcesses:  48 total, 5 running, 43 sleeping... 176 threads             21:43:01\nLoad Avg:  3.16,  1.85,  0.83    CPU usage: 89.27% user, 10.73% sys,  0.00% idle\n\n  PID COMMAND      %CPU   TIME   #TH #PRTS #MREGS RPRVT  RSHRD  RSIZE  VSIZE\n  170 bash        63.9%  2:33.80   1    13     19  192K   704K   692K    18M \n  168 bash        63.8%  2:56.34   1    13     19  192K   704K   692K    18M \n  169 bash        62.1%  2:35.43   1    13     19  192K   704K   692K    18M\n```\n\nMan ser at tiden deles praktisk talt likt mellom de tre prosessene. Dette gjøres ved at tre prosessene med jevne mellomrom bytter på hvilken CPU de kjører på. Til en hver tid vil det kjøre to prosesser på samme CPU, men OS-scheduler bytter likt mellom dem, slik at de skifter på hvilken av prosessene som kjører alene på den andre CPUen."}
{"identifier": "os7.2", "section_id": "7.2", "section_title": "Fem CPU-intensive prosesser på host med 4 CPUer", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION00082000000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.2 Fem CPU-intensive prosesser på host med 4 CPUer\n\nServeren studssh har fire CPUer som man kan se fra lscpu:\n\n```\nhaugerud@studssh:~$ lscpu \nArchitecture:          x86_64\nCPU op-mode(s):        32-bit, 64-bit\nByte Order:            Little Endian\nCPU(s):                4\nOn-line CPU(s) list:   0-3\nThread(s) per core:    1\nCore(s) per socket:    2\nSocket(s):             2\nNUMA node(s):          1\nVendor ID:             AuthenticAMD\nCPU family:            15\nModel:                 6\nModel name:            Common KVM processor\nStepping:              1\nCPU MHz:               2294.248\nBogoMIPS:              4588.49\nHypervisor vendor:     KVM\nVirtualization type:   full\nL1d cache:             64K\nL1i cache:             64K\nL2 cache:              512K\nL3 cache:              16384K\nNUMA node0 CPU(s):     0-3\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx lm rep_good nopl extd_apicid pni cx16 x2apic hypervisor cmp_legacy 3dnowprefetch vmmcall\n```\n\nDet vil si den har to sockets (to forskjellige brikker) med to Cores (CPUer) på hver. Men som man kan se av linjen hvor det står KVM, så er den egentlig en virtuell maskin (KVM står for Kernel-based Virtual Machine og er en type Linux virtualisering) og har derfor fått tildelt disse CPUene. Tidligere i semesteret var studssh konfigurert med bare to vCPUer (virtualCPU), dette kan konfigureres.\n\nIllustrasjon:\nCPU-topologi generert av lstopo på den virtuelle maksinen studssh.\n\nVed å kjøre en CPU-intensiv prosess, får man følgende resultat:\n\n```\nhaugerud@studssh:~$ time ./regn\nReal:9.962 User:9.940 System:0.004 99.82%\n```\n\nDen bruker ca 10 sekunder. Hvis man kjører fem slike prosesser samtidig,\n\n```\ntop - 13:04:52 up 27 days,  1:31, 19 users,  load average: 1,11, 0,86, 0,61\nTasks: 268 total,   6 running, 261 sleeping,   1 stopped,   0 zombie\n%Cpu0  : 98,3 us,  0,3 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  1,3 st\n%Cpu1  : 97,7 us,  0,3 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,3 si,  1,7 st\n%Cpu2  : 95,0 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  5,0 st\n%Cpu3  : 98,7 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,3 si,  1,0 st\nKiB Mem :  8174752 total,  4926648 free,   363368 used,  2884736 buff/cache\nKiB Swap:   950268 total,   846168 free,   104100 used.  7368460 avail Mem \n\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                    P \n 7495 haugerud  20   0   14648   3284   3092 R  85,1  0,0   0:04.47 regn                       1 \n 7493 haugerud  20   0   14648   3184   2980 R  81,8  0,0   0:04.38 regn                       0 \n 7497 haugerud  20   0   14648   1040    940 R  80,9  0,0   0:04.32 regn                       3 \n 7498 haugerud  20   0   14648   3228   3036 R  79,5  0,0   0:03.86 regn                       0 \n 7491 haugerud  20   0   14648   3280   3084 R  71,0  0,0   0:03.93 regn                       2\n```\n\nvil de fem prosessen kjøre samtidig på de fire CPUene, slik at det til en hver tid er to prosesser på en av CPUene. I top-utskriften over, kan man se av P-kolonnen helt til høyre at det er CPU nr 0 som har to prosesser. OS skifter fortløpende på hvilken CPU som har to prosesser, slik at alle de fem prosessene får omtrent like mye CPU-tid hver, ca 80%.\n\nNår en prosess tar 10 sekunder, vil det kreves 5x10 = 50 CPU-sekunder for å fullføre alle de fem jobbene. Arbeidsmengden blir fordelt likt på fire CPUer og det vil da ta 50/4 = 12.5 sekunder å fullføre hver jobb. Og dette resultatet får man om man kjører fem jobber samtidig.\n\n```\nhaugerud@studssh:~$ for i in {1..5}; do time ./regn& done\n\nReal:12.208 User:10.060 System:0.016 82.54%\nReal:12.241 User:10.060 System:0.020 82.34%\nReal:12.366 User:9.964 System:0.024 80.76%\nReal:12.869 User:10.200 System:0.008 79.32%\nReal:13.143 User:10.076 System:0.032 76.90%\n```\n\nSom forventet bruker jobbene ca 12.5 sekunder på å bli ferdig. Man kan også beregne at om man bruker 80% CPU i 12.5 sekunder vil man tilsammen bruke 10 CPU-sekunder. Det kan man også se av output, User: viser hvor mange CPU-sekunder hver prosess har brukt."}
{"identifier": "os7.3", "section_id": "7.3", "section_title": "Internminnet og Cache", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION00083000000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.3 Internminnet og Cache\n\nVi har sett at CPU-en kan lese og utføre maskininstruksjoner og disse blir hentet inn til registerne fra internminnet. Dette minnet blir også kalt RAM, en forkortelse for Random Access Memory.'Random' fordi hvilken som helst byte kan leses ut eller aksesseres like raskt som enhver annen byte. Maskinkoden for operativsystemet og andre programmer som skal kjøres må først lastes inn i internminnet fra disk. Andre deler av programmene kan hentes inn fra disk senere ved behov. Selvom det går omtrent hundre tusen ganger raskere å hente data fra internminnet enn å hente data fra harddisken, tar det alt for lang tid i forhold til hvor fort moderne CPU'er kan behandle data. De raskeste prosessorene yter mer enn 1000 MIPS (Million Instructions Per Second), det vil si mer enn en milliard ( ) instruksjoner i sekundet. Hvis CPU-en måtte vente på data fra RAM for hver instruksjon den skulle gjøre, ville mange prosesser gått ti ganger så sakte som de gjør nå. For å kunne mate en hurtig prosessor med instruksjoner og data raskt nok, bruker man flere nivåer av mellomlagring av data, såkalt cache-minne. Ordet cache kommer fra fransk og betyr et hemmelig lager. Det går vesentlig raskere å hente minne fra cache-minnet enn fra internminnet. I tillegg har det vist seg at de fleste programmer i 90% av tiden utfører instruksjoner innenfor 10% av det totale minnet. Når CPU ber om en instruksjon som ligger et bestemt sted i minnet, hentes derfor ikke bare denne instruksjonen, men for eksempel 32 KByte av minnet. Alt dette lagres i cache og når CPU ber om neste instruksjon, ligger den ofte i cache, slik at den ikke må hentes fra internminnet. Fig. 45 viser noen typiske størrelser og aksesstider for de sentrale lagringsmedien som finnes i en datamaskin, fra registre til harddisk. Legg spesielt merke til den store forskjellen i aksesstid mellom internminnet og harddisk.\n\nIllustrasjon:\nMinne-pyramiden. Størrelsen og tiden det tar å hente data øker nedover pyramiden.\n\nBåde CPU-registre og cache er laget av SRAM (Static RAM). Aksess er meget hurtig og SRAM er statisk i den betydning at det ikke trenger å oppfriskes, slik DRAM (Dynamic RAM) må. Mer en 10 ganger i sekundet må DRAM opplades, ellers forsvinner informasjonen. SRAM består av 6 transistorer for hver bit som lagres, til sammenligning består en NOT-port av to transistorer og AND og OR-porter av 4. Men DRAM trenger bare en transistor og en kapasitator(lagrer elektrisk ladning) for å lagre en bit. Derfor er DRAM billigere, mindre og bruker mindre effekt og kan derfor lages i større enheter. Internminnet består derfor av DRAM eller forbedrede varianter av DRAM. DDR4 SDRAM (Double-Data Rate generation 4 Synchronus Dynamic RAM) ble lansert i 2014 og i 2020 kom DDR5 som er det foreløpig siste av leddene i kjedene av forbedrede utgaver av DRAM.\n\nIllustrasjon:\nLevel 1 cache (L1) ligger nærmest CPU. L2 er større, men har lengre \naksesstid. Større deler av instruksjoner og data blir hentet av gangen fordi det ofte blir brukt for dette senere.\n\nCache inneholder både data og instruksjoner og deler av MMUs (Memory Management Unit) page-tables i TLB (Translation Lookaside Buffer). I L1 cache er ofte disse separert i egne enheter, mens L2 cache pleier å være en enhet. I de senere årene har man klart å få plass til L2 på selve prosessorchip'en (den lille brikken som utgjør mikroprosessoren, bare noen kvadratcentimeter stor).\n\nArkitekturen til en moderne prosessor kan da i grove trekk se ut som i Fig. [78](node14.html#Cache2) .\n\nIllustrasjon:\nLevel 1 cache (L1) bestående av tre deler. I AMD Athlon 64 er TLB i tillegg delt i to deler, en for \nadresser til instruksjoner og en for adresser til data.\n\nNoen arkitekturer har i tillegg enda et lag i minnehierarkiet, en offchip L3 cache som sitter mellom mikroprosessoren og RAM."}
{"identifier": "os7.4", "section_id": "7.4", "section_title": "Multitasking og Multiprocessing", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION00084000000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.4 Multitasking og Multiprocessing\n\n* **Multitasking/Multiprogramming** Software(OS) brukes til å fordele tid fra samme CPU mellom flere prosesser\n* **Multiprocessing** To eller flere CPU'er i samme computersystem kjører flere prosesser virkelig samtidig, på samme tidspunkt\n\n* **Symmetric Multiprocessing** SMP, to eller flere prosessorer deler samme internminnet og kjører flere prosesser virkelig samtidig, på samme tidspunkt\n* **Multi Core Multiprocessing** To eller flere prosessorer på samme brikke deler cache og databus og kjører flere prosesser samtidig. Regnes også som SMP.\n\nIllustrasjon:\nSingle og dual prosessor og dual core prosessorer. Den tykke linjen markerer grensen for brikken/chip'en"}
{"identifier": "os7.5", "section_id": "7.5", "section_title": "Intel Core og AMD K10", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION00085000000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.5 Intel Core og AMD K10\n\nVi skal se litt på Intel Core i7 og AMD Opteron K10. De har mange likheter, begge er quad core, det vil si har 4 kjerner og har opptil 3.2 GHz klokkefrekvens. Cache-arkitekturen ligner også på hverandre, begge ser ut som i figuren:\n\nIllustrasjon:\nIntel Core i7 og AMD Opteron K10. K10 kjernen har 512KB L2 cache og i7 kjernene har hyperthreading, ellers er de i store trekke relativt like.\n\nEn forskjell er at Intel Core i7 har hyperthreading i motsetning til de foregående Intel Core 2 prosessorene. Dermed kan den kjøre åtte prosesser samtidig. Men som vi skal se senere, for svært CPU-krevende prosesser har ikke dette så stor betydning, de må dele på beregnings-enheten, ALU.\n\nMerk forøvrig: 30 MHz var maks klokkefrekvens for Intel i 1992 og den ble mer enn tredvedoblet på åtte år fram til 2000 hvor de første GHz prosessorene kom. Men på de neste åtte årene ble frekvensen bare tredoblet. Det at det er vanskelig å øke klokkefrekvensen har gjort at man istedet har økt kapasiteten med multi core og hyperthreading."}
{"identifier": "os7.6", "section_id": "7.6", "section_title": "Mikroarkitektur", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION00086000000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.6 Mikroarkitektur\n\nVi har sett at hardware definerer et bestemt instruksjonssett og sett på noen av instruskjonene som er definert i X86-instruksjonssettet. Men i praksis finnes det mange måter å fysisk implementere et gitt instruksjonssett. Måten en produsent av CPU-er, som Intel eller AMD, implementerer et instruksjonssett kalles en mikroarkitektur. Forskjeller i for eksempel hvordan mikro-operasjoner utføres og hvordan pipelining eller chache-nivåer er lagt opp utgjør forskjeller i mikroarkitekturen. Man kan si at datamaskinarkitekturen utgjør kombinasjonen av instruksjonssettet og mikroarkitekturen.\n\nServeren amdock som er fysisk server for alle Linux-VMene (som egentlig er docker containere) har en AMD CPU modell som heter EPYC 7552 og det er en 64-bit 48-core x86 server-mikroprosesser designet av AMD i 2019. Hver core(kjerne) har SMT (Simultanious Multithreading) slik at OS ser 96 CPU-er. Den er basert på AMDs Zen 2 mikroarkitektur. Den har 3MB L1-cache, 24 MB L2 cache og 192 MB L3 cache. Videre har den 768 GB RAM."}
{"identifier": "os7.7", "section_id": "7.7", "section_title": "Hyperthreading", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION00087000000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.7 Hyperthreading\n\nFlere av Intels prosessorer som Pentium 4 og Xeon har såkalt hyperthreading teknologi (Hyper-Threading er slik Intel selv betegner teknologien). Det vil si at deler av CPU-en er duplisert, som alle registerne, men for eksempel ikke ALU-en. Det gjør at en CPU kan inneholde to prosesser samtidig, slik at hvis den ene prosessen for eksempel bruker tid på å hente noe fra minne, kan CPUen ekstremt raskt switche over og la den andre prosessen bruke ALU-en. En slik overgang styres av hardware og ikke av operativsystemeet og skjer i løpet av et nanosekund eller to. En normal context switch utført av OS tar flere tusen ganger så lang tid, flere mikrosekunder. Det å utføre instruksjoner for en prosess kalles en thread eller tråd. Det er basert på bildet av den linjen(tråden) som følges når et program utføres ved å hoppe i mellom instruksjonene som programmet består av. Mer om threads senere. I en CPU med hyperthreading er ikke fullstendig delt i to enheter, slik som kjernene i en dobbel core prosessorer hvor de er helt separate enheter. Et operativsystem oppfatter en hyperthreading CPU på samme måte som en duo core, som to CPU'er. Det kan derfor være vanskelig å se forskjellen, men det vil kunne sees av ytelsen.\n\nHyperthreading er Intels eget markedsføringsbegrep for denne teknologien. Den generelle betegnelse er SMT (Simultaneous multithreading) og AMD har implementert SMT i noen av sine mikroartkitekturer som i Zen.\n\nDesktop'en rex har en Intel i7 prosessor som har 4 kjerner(cores) som er hyperthreading og lscpu gir følgende:\n\n```\nrex:~$ lscpu \nArchitecture:          x86_64\nCPU op-mode(s):        32-bit, 64-bit\nByte Order:            Little Endian\nCPU(s):                8\nOn-line CPU(s) list:   0-7\nThread(s) per core:    2\nCore(s) per socket:    4\nSocket(s):             1\nNUMA node(s):          1\nVendor ID:             GenuineIntel\nCPU family:            6\nModel:                 58\nModel name:            Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz\nStepping:              9\nCPU MHz:               1711.156\nCPU max MHz:           3900,0000\nCPU min MHz:           1600,0000\nBogoMIPS:              6785.02\nVirtualization:        VT-x\nL1d cache:             32K\nL1i cache:             32K\nL2 cache:              256K\nL3 cache:              8192K\n```\n\nDette er ikke en VM men en fysisk node som har en socket med 4 cores og 2 threads per core. Det gir tilsammen 8 CPUer, output fra lscpu omtaler hver regneenhet som en CPU. Men 2 threads per core betyr i denne sammenhengen at hver core er hyperthreading som forklart over og egentlig er en regneenhet med en enkelt ALU men dobbelt sett av registre slik at en core kan kjøre to prosesser samtidig. Hvordan dette ser ut i praksis skal vi her teste.\n\nSom før bruker vi følgende CPU-slukende program:\n\n```\n#! /bin/bash\n\n(( max = 300000 ))\n(( i = 0  ))\n(( sum = 0  ))\n\nwhile (($i < $max))\ndo\n        (( i += 1 ))\n        (( sum += i  ))\ndone\necho $0, resultat: $sum\n```\n\nSlik ser det ut på rex om man starter 10 CPU-intensive regnejobber:\n\n```\nrex:~/regn$ for i in {1..10}; do time ./regn & done\n```\n\n```\ntop - 21:19:30 up 26 days,  9:10,  2 users,  load average: 3,72, 2,59, 2,12\nTasks: 395 total,  11 running, 384 sleeping,   0 stopped,   0 zombie\n%Cpu0  :100,0 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,0 st\n%Cpu1  :100,0 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,0 st\n%Cpu2  :100,0 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,0 st\n%Cpu3  :100,0 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,0 st\n%Cpu4  :100,0 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,0 st\n%Cpu5  :100,0 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,0 st\n%Cpu6  :100,0 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,0 st\n%Cpu7  :100,0 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,0 st\nKiB Mem : 16385632 total,  5192648 free,  5303528 used,  5889456 buff/cache\nKiB Swap: 16730108 total, 16698824 free,    31284 used. 10271192 avail Mem \n\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                   P \n32596 haugerud  20   0   14068    908    804 R  90,0  0,0   0:17.55 regn                      0 \n32599 haugerud  20   0   14068   3020   2808 R  83,7  0,0   0:16.54 regn                      4 \n32598 haugerud  20   0   14068    912    808 R  83,4  0,0   0:17.08 regn                      6 \n32584 haugerud  20   0   14068    940    836 R  82,7  0,0   0:16.71 regn                      1 \n32595 haugerud  20   0   14068   2872   2660 R  79,7  0,0   0:15.93 regn                      3 \n32587 haugerud  20   0   14068   2932   2720 R  79,4  0,0   0:17.39 regn                      1 \n32597 haugerud  20   0   14068   2944   2728 R  78,1  0,0   0:18.73 regn                      5 \n32600 haugerud  20   0   14068    900    800 R  78,1  0,0   0:15.61 regn                      3 \n32588 haugerud  20   0   14068   2956   2740 R  75,7  0,0   0:16.41 regn                      2 \n32592 haugerud  20   0   14068    904    800 R  68,8  0,0   0:15.54 regn                      7\n```\n\nLinux-kjernen betrakter dette som åtte uavhengige CPU'er og kjører prosesser på alle åtte. Av kolonnen P kan vi se at OS fordeler prosesser på alle CPUene og dermed må det være to prosesser på to av dem, i dette tilfellet på prosessor nummer 1 og 3. OS bytter med jevne mellomrom på hvilke CPUer som har to prosesser, slik at som man kan se av time-kolonnen, alle prosessene får omtrent like mye CPU-tid og avslutter samtidig. CPU-kolonnen viser andel CPU de siste 3 sekundene og her kan vi se at det er litt forskjell. Men i snitt får de omtrent 4/5 dels eller 80% CPU-tid. Det koster litt overhead å flytte en prosess fra en CPU til en annen, så det skjer ikke altfor ofte. (Når man kjører top må man taste 1 for å se de 8 øverste CPU-linjene og f fulgt av p og return for å se hvilke prosessorer som brukes)."}
{"identifier": "os7.7.1", "section_id": "7.7.1", "section_title": "Kjører en CPU med hyperthreading to prosesser reelt sett samtidig?", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION00087100000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.7.1 Kjører en CPU med hyperthreading to prosesser reelt sett samtidig?\n\nMen regner disse prosessene reelt sett samtidig? Hvis man setter igang åtte regnejobber viser `top` at de jobber på hver sin CPU og at de hver får 100% CPU-tid. Men hvordan kan man finne ut om de virkelig gjør det?\n\nPå samme måte som om man ønsker å finne ut om åtte arbeidere man har ansatt for å skrelle poteter virkelig jobber samtidig. Man tar tiden på dem. Åtte personer bør bruke like lang tid på å skrelle åtte sekker poteter som fire stykker bruker på fire sekker poteter. Ihvertfall hvis de har en potetskreller (ALU) hver. Men hvis to og to av arbeiderne må dele på samme potetskreller, tar det dobbelt så lang tid.\n\nSå vi setter igang fire regnejobber som skreller ivei på hver sin av de fire CPU-ene:\n\n```\nrex:~/regn$ for i in {1..4}; do time ./regn & done\n\nReal:18.152 User:18.144 System:0.000 99.96%\nReal:18.401 User:18.392 System:0.004 99.97%\nReal:18.417 User:18.412 System:0.000 99.97%\nReal:18.516 User:18.508 System:0.000 99.96%\n```\n\nJobben går unna på litt i overkant av 18 sekunder og det bør ikke ta lenger tid for åtte prosesser hvis de reelt sett jobber samtidig:\n\n```\nrex:~/regn$ for i in {1..8}; do time ./regn & done\nReal:35.048 User:35.008 System:0.000 99.88%\nReal:35.222 User:35.144 System:0.000 99.78%\nReal:35.246 User:35.104 System:0.000 99.59%\nReal:35.270 User:34.976 System:0.020 99.22%\nReal:35.500 User:34.888 System:0.008 98.29%\nReal:35.562 User:34.840 System:0.012 98.00%\nReal:35.606 User:35.448 System:0.000 99.55%\nReal:35.796 User:35.140 System:0.012 98.20%\n```\n\nMen det tar nesten dobbelt så lang tid. Som beskrevet tidligere, CPU-en har lastet inn to prosesser samtidig, men internt må de bytte på å bruke ALU-en og for slike prosesser som hele tiden bruker CPU har hyperthreading liten effekt. Det blir som om arbeiderne må bytte på å bruke samme potetskreller og da tar det dobbelt så lang tid å bli ferdig. Litt effekt har dog hyperthreading, det går litt mindre enn dobbelt så lang tid, som ville vært nærmere 37 sekunder."}
{"identifier": "os7.8", "section_id": "7.8", "section_title": "Hyperthreading med prosess som bruker mye RAM", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION00088000000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.8 Hyperthreading med prosess som bruker mye RAM\n\nHyperthreading har altså kun en liten positiv effekt for programmer som hele tiden bruker ALU siden de to prosessene da må bytte på å bruke ALUen og dermed bruker dobbelt så lang tid. Men for programmer som ofte venter noen klokkesykler på å få lest fra eller skrevet til RAM kan hyperthreading ha stor effekt. Det følgende programmet skriver om og om igjen tall til et array som ligger i RAM:\n\n```\nrex:~/regn$ cat ram.c \n#include <stdio.h> \n\nint array[102400];\n\nvoid main(){\n   int i,k;\n   for(k=0;k<2000000;k++){\n      for(i = 0;i < 1024;i++){\n          array[i] = i;\n     }\n  }\n}\n```\n\nHvis man kompilerer og kjører det, bruker det ca 4 sekunder på å kjøre ferdig.\n\n```\nrex:~/regn$ gcc ram.c\nrex:~/regn$ time ./a.out \nReal:4.021 User:4.016 System:0.004 99.97%\n```\n\nHvis man starter fire slike prosesser, sørger operativsystemet sin scheduler for at de kjører på hver sin ALU og alle bruker omtrent fire sekunder.\n\n```\nrex:~/regn$ for i in {1..4}; do time ./a.out& done\nrex:~/regn$\nReal:4.060 User:4.056 System:0.000 99.89%\nReal:4.103 User:4.100 System:0.000 99.91%\nReal:4.137 User:4.132 System:0.000 99.87%\nReal:4.141 User:4.136 System:0.000 99.88%\n```\n\nHvis man kjører åtte slike RAM-brukende prosesser samtidig, vil to og to av dem kjøre på samme core og dermed bytte på å bruke den samme ALU-en. Men i dette tilfellet vil det hele tiden være litt venting på RAM, slik at et lynhurtig bytte av hvem som bruker ALU kan gi en positiv effekt. Og det er hardware som utfører dette byttet, det blir i motsetning til for en vanlig prosess context switch ikke utført av operativsystemet.\n\n```\nrex:~/regn$ for i in {1..8}; do time ./a.out& done\nrex:~/regn$\nReal:4.345 User:4.336 System:0.000 99.80%\nReal:4.370 User:4.332 System:0.000 99.12%\nReal:4.371 User:4.364 System:0.000 99.85%\nReal:4.371 User:4.368 System:0.000 99.94%\nReal:4.425 User:4.420 System:0.000 99.89%\nReal:4.437 User:4.424 System:0.000 99.70%\nReal:4.479 User:4.328 System:0.000 96.62%\nReal:4.496 User:4.328 System:0.000 96.27%\n```\n\nOg nå ser vi at hyperthreading har en meget stor effekt, til tross for at de må dele ALU bruker prosessen bare omtrent 10 % mer CPU-tid på å fullføre sammenlignet med når en prosess kjører helt alene på en core."}
{"identifier": "os7.9", "section_id": "7.9", "section_title": "Deaktivering av hyperthreading", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION00089000000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.9 Deaktivering av hyperthreading\n\nFølgende informasjon er hentet fra samme Intel desktop med navn rex:\n\n```\nrex:~$ lscpu | grep name\nModel name:            Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz\n\nrex:~$ lscpu | grep Thread\nThread(s) per core:    2\n\nrex:~$ grep \"\" /sys/devices/system/cpu/cpu*/topology/thread_siblings_list \n/sys/devices/system/cpu/cpu0/topology/thread_siblings_list:0,4\n/sys/devices/system/cpu/cpu1/topology/thread_siblings_list:1,5\n/sys/devices/system/cpu/cpu2/topology/thread_siblings_list:2,6\n/sys/devices/system/cpu/cpu3/topology/thread_siblings_list:3,7\n/sys/devices/system/cpu/cpu4/topology/thread_siblings_list:0,4\n/sys/devices/system/cpu/cpu5/topology/thread_siblings_list:1,5\n/sys/devices/system/cpu/cpu6/topology/thread_siblings_list:2,6\n/sys/devices/system/cpu/cpu7/topology/thread_siblings_list:3,7\n```\n\nDette viser at CPUen har hyperthreading, siden den angir \"2 threads per core\". Når to prosess-enheter deler samme ALU, kalles de \"thread siblings\" og listen over viser hvilke som hører sammen og deler ALU. Den samme informasjonen kan man få grafisk med `lstopo` :\n\n```\nlstopo --no-io --no-caches\n```\n\ngir følgende figur\n\nIllustrasjon:\nCPU-topologi generert av lstopo for rex med hyperthreading aktivert\n\nFor å skru av hyperthreading, kan man fjerne en PU (Processing Unit) fra hver av de fire siblings-parene i listen. Alternativt en av PU'ene fra hver core i lstopo-figuren. Dette kan gjøres ved som root å overskrive en setting i `/sys/devices/system/cpu` :\n\n```\n# for i in 4 5 6 7; do echo 0 > /sys/devices/system/cpu/cpu$i/online ; done\n```\n\nEtter man har gjort dette, vil rex kun ha fire cores uten hyperthreadin og OS vil kun se disse fire og schedulere prosesser på disse fire.\n\nIllustrasjon:\nCPU-topologi generert av lstop for rex med hyperthreading deaktivert\n\nOm man nå starter 8 regn-jobber på rex, ser det slik ut:\n\n```\ntop - 12:10:49 up 27 days, 2 min,  1 user,  load average: 4,66, 1,71, 0,95\nTasks: 345 total,   9 running, 336 sleeping,   0 stopped,   0 zombie\n%Cpu0  : 99,7 us,  0,3 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,0 st\n%Cpu1  :100,0 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,0 st\n%Cpu2  :100,0 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,0 si,  0,0 st\n%Cpu3  : 99,3 us,  0,0 sy,  0,0 ni,  0,0 id,  0,0 wa,  0,0 hi,  0,7 si,  0,0 st\nKiB Mem : 16385632 total,  4838284 free,  5646572 used,  5900776 buff/cache\nKiB Swap: 16730108 total, 16725972 free,     4136 used.  9934028 avail Mem \n\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                 \n29234 haugerud  20   0   14068    884    780 R  50,2  0,0   0:07.19 regn                                    \n29232 haugerud  20   0   14068    940    836 R  49,8  0,0   0:07.10 regn                                    \n29237 haugerud  20   0   14068   2956   2740 R  49,8  0,0   0:07.16 regn                                    \n29239 haugerud  20   0   14068    940    836 R  49,8  0,0   0:07.33 regn                                    \n29241 haugerud  20   0   14068   1056    956 R  49,8  0,0   0:07.10 regn                                    \n29243 haugerud  20   0   14068    884    780 R  49,8  0,0   0:07.10 regn                                    \n29242 haugerud  20   0   14068    888    784 R  49,5  0,0   0:07.26 regn                                    \n29244 haugerud  20   0   14068    912    808 R  49,2  0,0   0:07.07 regn\n```\n\nDe åtte jobbene deler på fire CPUer, to kjører på hver og får 50% CPU-tid. Totaltiden blir naturlig nok ganske nøyaktig det dobbelte av når bare fire prosesser kjører:\n\n```\nReal:36.553 User:18.260 System:0.004 49.96%\nReal:36.679 User:18.340 System:0.012 50.03%\nReal:36.839 User:18.356 System:0.000 49.82%\nReal:36.842 User:18.232 System:0.000 49.48%\nReal:36.854 User:18.216 System:0.008 49.45%\nReal:36.915 User:18.232 System:0.000 49.39%\nReal:37.098 User:18.368 System:0.000 49.51%\nReal:37.112 User:18.272 System:0.000 49.23%\n```\n\nLitt overhead blir det av context-switching når to prosesser deler samme CPU, men ikke mye. Og vi ser at totaltiden blir litt over ett sekund lenger enn når hyperthreading var på, så en liten effekt har hyperthreading, selvom de to prosessene må dele ALU. For andre jobber kan hyperhtreading ha større effekt, spesielt hvis programmene ofte bruker RAM."}
{"identifier": "os7.10", "section_id": "7.10", "section_title": "RAM-prosess uten hyperthreading", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION000810000000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.10 RAM-prosess uten hyperthreading\n\nHvis vi nå kjører prosessen som hele tiden skriver til et array, så ser det helt likt ut når 4 prosesser kjører. De vil scheduleres av OS på hver sin core og bruker som før ca 4 sekunder:\n\n```\nrex:~/regn$ for i in {1..4}; do time ./a.out& done\nrex:~/regn$\nReal:4.063 User:4.036 System:0.000 99.34%\nReal:4.080 User:4.056 System:0.004 99.50%\nReal:4.171 User:4.036 System:0.000 96.76%\nReal:4.177 User:4.088 System:0.000 97.86%\n```\n\nMen når vi nå kjører 8 samtidige prosesser må operativsysteme schedulere to prosesser på hver CPU (core/kjerne/regnenhet/ALU) og la de to prosessene bytte på å bruke den ved konvensjonell multitasking styrt av OS. Da vil det totalt sett naturlig nok ta dobbelt så lang tid å fullføre alle prosessene:\n\n```\nrex:~/regn$ for i in {1..8}; do time ./a.out& done\nrex:~/regn$\nReal:8.034 User:3.988 System:0.000 49.64%\nReal:8.077 User:3.980 System:0.000 49.27%\nReal:8.083 User:4.040 System:0.000 49.98%\nReal:8.139 User:4.036 System:0.008 49.68%\nReal:8.137 User:3.988 System:0.000 49.00%\nReal:8.139 User:3.988 System:0.000 48.99%\nReal:8.163 User:3.996 System:0.004 49.00%\nReal:8.176 User:4.124 System:0.000 50.43%\n```\n\nDette er resultatet av OS-styrt multitasking og er helt forskjellig fra hva vi fikk når hyperthreading var skrudd på, da fikk vi følgende når nøyaktig samme program kjøres på samme maskin:\n\n```\nrex:~/regn$ for i in {1..8}; do time ./a.out& done\nrex:~/regn$\nReal:4.345 User:4.336 System:0.000 99.80%\nReal:4.370 User:4.332 System:0.000 99.12%\nReal:4.371 User:4.364 System:0.000 99.85%\nReal:4.371 User:4.368 System:0.000 99.94%\nReal:4.425 User:4.420 System:0.000 99.89%\nReal:4.437 User:4.424 System:0.000 99.70%\nReal:4.479 User:4.328 System:0.000 96.62%\nReal:4.496 User:4.328 System:0.000 96.27%\n```\n\nDet går nå nesten dobbelt så fort og viser at hardware hyperthreading er mye mer effektivt en OS multithreading med context switch. En hyperthreading switch bruker bare noen nanosekunder og kan utnytte at en thread venter på RAM. En OS-context switch tar minst tusen ganger så lang tid og kan derfor ikke brukes til å effektivisere bort svært korte pauser i prosesseringen på grunn av venting på RAM."}
{"identifier": "os7.11", "section_id": "7.11", "section_title": "Taskset", "source_category": "os", "source_id": "7", "source_title": "Multitasking, cache, hyperthreading", "anchor": "SECTION000811000000000000000", "source": "os/Forelesning/os/node8.html", "text": "## 7.11 Taskset\n\nMed kommandoen `taskset` kan man eksplisitt forlange at en prosess kjører på en bestemt CPU. Det vil da medføre at man overstyrer OS sin scheduling av prosesser; OS vil alltid prøve å fordele arbeidsmengden så jevnt som mulig. Taskset kan være nyttig i mange situasjoner og kan også brukes til å belyse forskjellen på multithreading og hyperthreading. OS nummererer CPU-ene fra 0 til 7 om man har åtte av dem. Man kan låse en regnejobb til CPU nummer 0 og kjøre og ta tiden på den med\n\n```\nrex:~/regn$ time taskset -c 0  ./regn\nReal:18.042 User:18.036 System:0.000 99.96%\n```\n\n(på forelesning ble rekkefølgen på time og taskset byttet og da blir tidsanvisningen anderledes) Hvis man tvinger to slike regnejobber til å kjøre på samme CPU vil de bruke dobbelt så lang tid:\n\n```\nrex:~/regn$ for i in 1 2; do time taskset -c 0  ./regn& done\nrex:~/regn$\nReal:36.088 User:18.036 System:0.000 49.97%\nReal:36.206 User:18.164 System:0.000 50.16%\n```\n\nAv prosenttallet ser vi at de får 50% CPU hver, likt fordelt fra OS som schedulerer under restriksjonen att begge alltid må kjøre på OS nr 0. Hvis man overlot scheduling til OS, ville de blitt plassert på hver sin core og fullført dobbelt så fort:\n\n```\nrex:~/regn$ for i in 1 2; do time  ./regn& done\nrex:~/regn$\nReal:18.431 User:18.428 System:0.000 99.98%\nReal:18.453 User:18.448 System:0.000 99.97%\n```\n\nFra før vet vi at CPU 0 og CPU 4 er siblings, det vil si sitter på samme core. Hvis vi med hyperthreading aktivert bruker taskset til å låse prosessene til disse to, vil det gå nesten like sakte som om de ble satt på samme CPU:\n\n```\nrex:~/regn$ for cpu in 0 4; do time taskset -c $cpu  ./regn& done\nrex:~/regn$\nReal:35.075 User:35.072 System:0.000 99.99%\nReal:35.080 User:35.072 System:0.004 99.99%\n```\n\nDet kommandoen over tekninsk sett gjør er å gi variabelen cpu verdien 0 og 4 og løkken setter igang to prosesser, en på CPU 0 og en på CPU 4, som er siblings og sitter på samme core med en felles ALU.\n\nMen hvis vi låser prosessene på nesten samme måte, men til CPU 1 og 4, vil det igjen gå nesten dobbelt så fort fordi vi nå eksplisitt har plassert dem på hver sin core, slik også OS gjør når to prosesser scheduleres:\n\n```\nrex:~/regn$ for cpu in 1 4; do time taskset -c $cpu  ./regn& done\nrex:~/regn$\nReal:18.470 User:18.468 System:0.000 99.98%\nReal:18.762 User:18.756 System:0.000 99.97%\n```"}
{"identifier": "os1.2", "section_id": "1.2", "section_title": "Om kurset", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION00022000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.2 Om kurset\n\n* Kurset består av to relativt uavhengige deler\n  * Operativsystemer(OS)\n  * Praktisk bruk av operativsystemer (Linux/Windows/Docker)\n* Foreleser: Hårek Haugerud, haugerud@oslomet.no, rom SG214, SG29\n* Hver onsdag fra 8:30: Flipped classroom-forelesninger\n* Videoer hvor alt fagstoff foreleses legges ut uken før\n* All kursinfo: `https://www.cs.oslomet.no/~haugerud/os` og Canvas\n* Viktig: Jobb med **oppgaver**!!\n* grunnlag for valgfaget Nettverks- og systemadministrasjon\n* grunnlag for OsloMet-mastergraden Cloud-based services and operations (tidligere Network and System administration)"}
{"identifier": "os1.3", "section_id": "1.3", "section_title": "Vesentlige mål for kurset", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION00023000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.3 Vesentlige mål for kurset\n\n* Lære å bruke kommandolinje, inkludert script (Mest Linux og Docker, noe Windows)\n* Lære hvordan en datamaskin virker på alle nivåer, fra transistorer og opp til operativsystemet"}
{"identifier": "os1.4", "section_id": "1.4", "section_title": "Pensumlitteratur", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION00024000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.4 Pensumlitteratur\n\n* To kompendier dekker pensum\n  * os.pdf\n  * linux.pdf\n  * Versjonene fra 2024 ligger under filer på Canvas og under Forelesninger på kurs-siden\n  * Kompendiene blir fortløpende oppdatert i løpet av semesteret med årets endringer\n* Anbefalt støtteliteratur: Tanenbaum, Andrew S.: Modern operating systems : Global edition, 4th edition, 2014\n* Omfattende og dyr, men en meget god bok"}
{"identifier": "os1.5", "section_id": "1.5", "section_title": "Eksamen", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION00025000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.5 Eksamen\n\n* 3 timers skriftlig Inspera eksamen (teller 100%)\n* Ingen hjelpemidler tillatt\n* Linux kommandolinje tilgjengelig under eksamen i Silurveien"}
{"identifier": "os1.6", "section_id": "1.6", "section_title": "Obligatoriske gruppe-innleveringer", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION00026000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.6 Obligatoriske gruppe-innleveringer\n\n* Uke-oppgavene som er markert som obligatoriske for hver uke samles opp og leveres ved hver innlevering.\n* Alle obliger MÅ være godkjent for å kunne melde seg opp til eksamen"}
{"identifier": "os1.7", "section_id": "1.7", "section_title": "Obligatoriske individuelle innleveringer", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION00027000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.7 Obligatoriske individuelle innleveringer\n\nIndividuelle Multiple Choice tester med tidsbegrensning\n\n* Utgår trolig i 2025\n* 3 korte Multiple Choice tester (7-10 minutter)\n* Trekkes tilfeldig fra en database av spørsmål\n* Må svare riktig på minst 7 av 10 for å få godkjenning\n* Hvis ikke MÅ studentassistent kontaktes. Hen går igjennom svarene og anbefaler hva som bør jobbes med og oppdaterer databasen slik at du får en ny sjanse"}
{"identifier": "os1.8", "section_id": "1.8", "section_title": "Nyttige personer", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION00028000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.8 Nyttige personer\n\n* Foreleser\n* Studentassistenter, i øvingstimene\n* Hedda Marie Westlin, heddamar@oslomet.no, Linux drift (data2500-server, etc)"}
{"identifier": "os1.9", "section_id": "1.9", "section_title": "Hva er et operativsystem (OS)?", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION00029000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.9 Hva er et operativsystem (OS)?\n\nEt OS er et software-grensesnitt mellom brukeren og en datamaskins hardware."}
{"identifier": "os1.10", "section_id": "1.10", "section_title": "Hvor stort er et operativsystem?", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000210000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.10 Hvor stort er et operativsystem?\n\nKildekoden til et moderne operativsystem som Linux eller Windows er på omtrent fem millioner linjer kode. Det tilsvarer omtrent 100 Tanenbaum-bøker som hver er på 1000 sider med 50 linjer pr side.\n\nSå stor er alene kildekoden for selve operativsystemkjernen. Hvis man tar med GUI, biblioteker og annen nødvendig system software (som Windows explorer), blir størrelsen ti til tyve ganger større."}
{"identifier": "os1.11", "section_id": "1.11", "section_title": "OS-definisjon", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000211000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.11 OS-definisjon\n\nForsøk på definisjon: OS er programvare hvis hensikt er:\n\n|   |   |\n|---|---|\n| A | Gi applikasjonsprogrammer og brukere enhetlig, enklere og mer abstrakt adgang til maskinens ressurser |\n| B | Administrere ressursene slik at prosesser og brukere ikke ødelegger for hverandre når de skal aksessere samme ressurser. |\n\nEksempler:\n\n|   |   |\n|---|---|\n| A | filsystemet som gir brukerne adgang til logiske filer slik at brukerne slipper å spesifisere disk, sektor, sylinder, lesehode osv. |\n| B | Et system som sørger for at brukerne ikke skriver over hverandres filer; fordeling av CPU-tid. |"}
{"identifier": "os1.12", "section_id": "1.12", "section_title": "Prinsippskisse av Linux", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000212000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.12 Prinsippskisse av Linux\n\nIllustrasjon:\nPrinsippskisse for et IT-system. GNU/Linux distribusjonen er \nmarkert med stiplede linjer. API = Application Programming Interface.\n\nGNU er en rekursiv forkortelse (høy nerdefaktor) og står for 'GNU's not Unix'. Bakgrunnen for begrepet GNU/Linux er at GNU-prosjektet som ble startet av Richard Stallmann i 1983. GNU sto bak mange av de veldig viktige delene som ligger utenfor kjernen, som shellet bash og kompilatoren gcc. Operativsystemkjernen kan for eksempel ikke gjøre så mye fornuftig hvis man ikke kan kompilere programmer slik at de kan kjøres. Det er fortsatt noen som bruker begrepet GNU/Linux når de omtaler operativsystemet Linux, men det vanligste er å bare si Linux. Og bruken av GNU/Linux kan sammenlignes med distribusjoner av Linux som Ubuntu og Red Hat. Disse distribusjonene gjør også en rekke tilpasninger og lager systemprogrammer som skal gjøre det enklere, bedre og sikrere å bruke Linux-kjernen."}
{"identifier": "os1.13", "section_id": "1.13", "section_title": "Sentralt begrep: prosess", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000213000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.13 Sentralt begrep: prosess\n\nProsess er et svært viktig Operativsystem-begrep."}
{"identifier": "os1.13.1", "section_id": "1.13.1", "section_title": "Linux prosesser", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000213100000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.13.1 Linux prosesser\n\n```\n21:49:07 up 7 days,  7:05,  2 users,  load average: 0.01, 0.02, 0.00\n66 processes: 64 sleeping, 2 running, 0 zombie, 0 stopped\nCPU states:   3.8% user,   2.4% system,   0.0% nice,  93.8% idle\nMem:    901440K total,   875496K used,    25944K free,    18884K buffers\nSwap:   128516K total,     2252K used,   126264K free,   681000K cached\n\n  PID USER     PRI  NI  SIZE  RSS SHARE STAT %CPU %MEM   TIME COMMAND\n17938 root      11 -10 93532  10M  2000 S <   2.3  1.2   0:31 XFree86\n18958 haugerud  17   0  8800 8800  7488 R     2.3  0.9   0:01 kdeinit\n18788 haugerud  11   0  3548 3548  2572 S     0.7  0.3   0:03 artsd\n19272 haugerud  12   0   956  956   748 R     0.3  0.1   0:00 top\n    1 root       8   0   484  456   424 S     0.0  0.0   0:00 init\n    2 root       9   0     0    0     0 SW    0.0  0.0   0:00 keventd\n    3 root      19  19     0    0     0 SWN   0.0  0.0   0:00 ksoftirqd_CPU0\n    4 root       9   0     0    0     0 SW    0.0  0.0   0:29 kswapd\n    5 root       9   0     0    0     0 SW    0.0  0.0   0:00 bdflush\n    6 root       9   0     0    0     0 SW    0.0  0.0   0:19 kupdated\n  123 daemon     9   0   432  428   356 S     0.0  0.0   0:00 portmap\n  130 root       9   0     0    0     0 SW    0.0  0.0   0:01 rpciod\n  131 root       9   0     0    0     0 SW    0.0  0.0   0:00 lockd\n  196 root       9   0   872  868   724 S     0.0  0.0   0:02 syslogd\n  199 root       9   0  1092 1088   420 S     0.0  0.1   0:00 klogd\n  204 root       9   0   700  700   604 S     0.0  0.0   0:00 rpc.statd\n  209 root       9   0   944  940   628 S     0.0  0.1   0:06 inetd\n  293 root       9   0  2076 1860  1608 S     0.0  0.2   0:02 sendmail\n  314 root       8   0  1280 1224  1068 S     0.0  0.1   0:00 sshd\n  319 root       9   0  3028 2208   596 S     0.0  0.2   0:00 xfs\n  321 root       9   0  1968 1968  1748 S     0.0  0.2   0:00 ntpd\n```"}
{"identifier": "os1.13.2", "section_id": "1.13.2", "section_title": "Windows XP prosesser", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000213200000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.13.2 Windows XP prosesser\n\n```\nPS C:\\Documents and Settings\\mroot> ps\n\nHandles  NPM(K)    PM(K)      WS(K) VM(M)   CPU(s)     Id ProcessName\n-------  ------    -----      ----- -----   ------     -- -----------\n    105       5     1176       3616    32     0,07   1212 alg\n    342       5     1512       3180    22    20,56    688 csrss\n    118       4     1056       2808    21     0,90    972 csrss\n    144       3     1812       3548    21     0,44   1132 csrss\n     76       4     1004       3684    30     0,05    376 ctfmon\n     72       4      964       3452    30     0,02    460 ctfmon\n     86       2     1420       2200   413     0,02   2032 cygrunsrv\n    157       4     1952       6180    44     0,07   1776 DW20\n    352      10     8772      14460    85     0,66    520 explorer\n    362      10     8036      14856    84     0,75   1864 explorer\n      0       0        0         28     0               0 Idle\n    164       6     3168       4724    38     2,65   1040 logonui\n    389       9     3908       2284    41     0,38    768 lsass\n    276       9    27568      25488   140     1,68   2132 powershell\n     79       3     1196       3576    34     0,02    232 rdpclip\n    106       4     1392       4384    35     0,03   1800 rdpclip\n    154       5     4348       5884    56     0,08   2080 rundll32\n    356       8     3328       5116    35     1,24    756 services\n     40       2      400       1504    11     0,01    248 shutdownmon\n     31       1      152        412     3     0,04    616 smss\n    120       5     3148       4780    41     1,23   1468 spoolsv\n     86      23     2092       3428   413     0,05    488 sshd\n    263       6     2908       5452    61     0,11    924 svchost\n    239      13     1724       4248    34     0,31   1080 svchost\n   1561      62    15192      25432   140     5,15   1168 svchost\n     76       3     1308       3584    29     1,11   1264 svchost\n    161       5     1492       3912    34     1,23   1372 svchost\n```"}
{"identifier": "os1.13.3", "section_id": "1.13.3", "section_title": "Definisjon av prosess", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000213300000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.13.3 Definisjon av prosess\n\nAlternative definisjoner:\n\n* Et program som kjører\n* Arbeidsoppgavene en prosessor gjør på et program\n* \n  * Et kjørbart program\n  * Programmets data (variabler, filer, etc.)\n  * OS-kontekst (tilstand, prioritet, prosessor-registre, etc.)\n* Et programs ånd/sjel\n    * I en analogi hvor programmet som kjører er et menneskes DNA, vil prosessen være hele livet et menneske lever:\n    * **Program**: = DNA\n    * **Prosess**: = livet\n    * **Hardware**: = Organer/Universet/hus/mat/bygninger\n    * **OS**: = staten/lovverket\n    * **kill, Ctrl-C**: = drap\n    * **root/Administrator**: = Gud\n    * **CPU**: =Hjerne\n    * **kriminalitet**: = Black hat hacking"}
{"identifier": "os1.14", "section_id": "1.14", "section_title": "Abstraksjon og hierarkier", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000214000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.14 Abstraksjon og hierarkier\n\n*Disse begrepene som er illustrert i Figur 2 er generelt sett blant de viktigste innen all databehandling, og spesielt innen OS.*\n\nIllustrasjon:\nAbstraksjoner i et hierarki"}
{"identifier": "os1.14.1", "section_id": "1.14.1", "section_title": "Linux-eksempel på hierarki", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000214100000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.14.1 Linux-eksempel på hierarki\n\n*Med verktøyet Bourne Again-shell (bash):*\n\n```\n$ cat /etc/motd\n```\n\nHjelpeprogrammet cat bruker flere systemkall for å skrive /etc/motd til skjermen. *Et C-program kan gjøre direkte kall til Linux-kjernen. \nF. eks. klargjør systemkallet open for å lese fra en fil:*\n\n```\nopen(\"/etc/motd\", O_RDONLY|O_LARGEFILE) = 3\n```\n\nKommandoen cat betstår av en serie systemkall:\n\n* open\n* read\n* close\n* etc.\n\nHvilke systemkall et Linux-program gjør, kan man se med kommandoen strace :\n\n```\n$ strace cat /etc/motd\nexecve(\"/bin/cat\", [\"cat\", \"/etc/motd\"], [/* 36 vars */]) = 0\nuname({sys=\"Linux\", node=\"rex\", ...})   = 0\nbrk(0)                                  = 0x804d000\nold_mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x40017000\naccess(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory)\nopen(\"/etc/ld.so.preload\", O_RDONLY)    = -1 ENOENT (No such file or directory)\nopen(\"/etc/ld.so.cache\", O_RDONLY)      = 3\nfstat64(3, {st_mode=S_IFREG|0644, st_size=67455, ...}) = 0\nold_mmap(NULL, 67455, PROT_READ, MAP_PRIVATE, 3, 0) = 0x40018000\nclose(3)                                = 0\naccess(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory)\nopen(\"/lib/libc.so.6\", O_RDONLY)        = 3\nread(3, \"\\177ELF\\1\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\\3\\0\\1\\0\\0\\0\\360^\\1\"..., 512) = 512\nfstat64(3, {st_mode=S_IFREG|0755, st_size=1244688, ...}) = 0\nold_mmap(NULL, 1254852, PROT_READ|PROT_EXEC, MAP_PRIVATE, 3, 0) = 0x40029000\nold_mmap(0x40151000, 32768, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED, 3, 0x127000) = 0x40151000\nold_mmap(0x40159000, 9668, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x40159000\nclose(3)                                = 0\nmunmap(0x40018000, 67455)               = 0\nbrk(0)                                  = 0x804d000\nbrk(0x806e000)                          = 0x806e000\nbrk(0)                                  = 0x806e000\nfstat64(1, {st_mode=S_IFCHR|0600, st_rdev=makedev(136, 25), ...}) = 0\nopen(\"/etc/motd\", O_RDONLY|O_LARGEFILE) = 3\nfstat64(3, {st_mode=S_IFREG|0644, st_size=712, ...}) = 0\nread(3, \"Linux rex 2.6.1skas #3 SMP Mon A\"..., 4096) = 712\nwrite(1, \"Linux rex 2.6.1skas #3 SMP Mon A\"..., 712) = 712\nread(3, \"\", 4096)                       = 0\nclose(3)                                = 0\nclose(1)                                = 0\nexit_group(0)                           = ?\n```"}
{"identifier": "os1.15", "section_id": "1.15", "section_title": "Datamaskinarkitektur", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000215000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.15 Datamaskinarkitektur\n\nOperativsystemkjernen styrer maskinens hardware slik at programmene som skal kjøres kan få utført det de ønsker uten at de ødelegger for hverandre. For å forstå hvordan et operativsystem virker, må man derfor også ha noe forståelse for de grunnleggende delene av en datamaskin og ikke minst forstå datamaskinens hjerne, CPU-en."}
{"identifier": "os1.16", "section_id": "1.16", "section_title": "Digitalteknikk og konstruksjon av kretser", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000216000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.16 Digitalteknikk og konstruksjon av kretser\n\nAlle tall i en datamaskin er representert i det binære tallsystem med nuller og enere og fysisk representeres det med ingen eller positiv elektrisk spenning i forhold til jord. Ved å sette slike bit med verdi null eller en ved siden av hverandre, kan man velge å la dem representere binære tall. For eksempel vil 32 bit ved siden av hverandre kunne representere alle heltall fra 0 til 4 294 967 295. Når man har en slik definisjon av tall, kan man definere alt man trenger i en datamaskin, desimaltall, bokstaver (for eksempel ASCIII, 80 = P), eller pixler og farger i grafikk. Alt representeres med tall som igjen representeres binært med bit som er av eller på, representert ved 0 Volts spenning elle 5 Volts spenning. Et tall kan representeres med 4 bits som vist i figur 1.16 .\n\nIllustrasjon:\nEt fire bits tall representer ved ulike spenningsforskjeller\n\nFor å kunne lage en datamaskin må man kunne utføre logiske og matematiske operasjoner på slike samlinger av bit. For eksempel må man kunne sammenligne, addere, subtrahere, multiplisere, dividere og gjøre shift-operasjoner. For å få til dette må man lage elektriske kretser som utfører denne type operasjoner. Det må for eksempel være mulig å få en CPU til å legge sammen to tall og gi et resultat. Dette kan man få til ved digitale kretser også kalt logiske kretser. La oss først se på hva man trenger for å kunne addere sammen to tall."}
{"identifier": "os1.17", "section_id": "1.17", "section_title": "Logiske porter og binær logikk", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000217000000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.17 Logiske porter og binær logikk\n\nAlt CPU-en eller prosessoren i en datamaskin gjør er å manipulere på nuller og enere og ved hjelp av dette kan all verdens tenkelige beregninger utføres. Det teoretiske grunnlaget for manipulasjon av nuller og enere, binær logikk, ble utviklet på 1800-tallet. Ved hjelp av tre logiske operatorer, AND, OR og NOT, kan alle logiske beregninger utføres. Så ved å bygge disse tre logiske operatorene i hardware og i tillegg ha en enhet som kan lagre verdien 1 eller 0, har man alt som skal til for å bygge en datamaskin. En 0 blir representert ved ingen spenning og 1 ved for eksempel 5 Volts spenning. Så kan man ved hjelp av matematisk logikk konstruere en datamaskin som kan legge sammen, trekke fra og sammenligne binære tall og det er stort sett alt man trenger.\n\nDen fysiske implementasjonen av AND, OR og NOT operatorene kalles porter, det kommer en eller to ledninger inn i den ene enden og går en ledning ut av den andre. Teoretisk fysikks store oppdagelse i det tyvende århundre, kvantemekanikken, la grunnen for halvlederteknologien og transistoren. I 1956 fikk Shockley, Bardeen og Brattain Nobelprisen i Fysikk for å konstruere transistoren som har gjort det mulig å lage slike porter ekstremt små. På en CPU-chip med noen få kvadratcentimeters overflate kan det være plass til 100 millioner slike porter og med ledninger mellom dem som er så tynne som 5 nanometer. Et hårstrå er til sammenligning 100 000 nm. De fysiske grenesene for hvor lite det er mulig å lage de integrert kretsene begynner å nærme seg og derfor klarer man ikke å øke klokkefrekvensen så hurtig som tidligere.\n\nI Fig. 4 ser vi de tre grunnleggende portene og hvordan man kan sette dem sammen til mer kompliserte kretser.\n\nIllustrasjon:\nDe tre grunnleggende logiske byggestenene i en prosessor, AND, OR og NOT-porter.\n\nLogikken til disse operatorene og tilsvarende porter kan beskrives ved såkalte sannhetstabeller, ved binær logikk og ved å tegne portene som vist i følgende avsnitt."}
{"identifier": "os1.17.1", "section_id": "1.17.1", "section_title": "AND", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000217100000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.17.1 AND\n\nSannhetstabell:\n\n| A | B | Ut = |\n|---|---|----|\n| 0 | 0 | 0 |\n| 0 | 1 | 0 |\n| 1 | 0 | 0 |\n| 1 | 1 | 1 |\n\nLogisk AND-operator:\n\nIllustrasjon:\nTegning av AND-port"}
{"identifier": "os1.17.2", "section_id": "1.17.2", "section_title": "OR", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000217200000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.17.2 OR\n\nSannhetstabell:\n\n| A | B | Ut = |\n|---|---|----|\n| 0 | 0 | 0 |\n| 0 | 1 | 1 |\n| 1 | 0 | 1 |\n| 1 | 1 | 1 |\n\nLogisk OR-operator:\n\nIllustrasjon:\nTegning av OR-port"}
{"identifier": "os1.17.3", "section_id": "1.17.3", "section_title": "NOT", "source_category": "os", "source_id": "1", "source_title": "Introduksjon til operativsystemer", "anchor": "SECTION000217300000000000000", "source": "os/Forelesning/os/node2.html", "text": "## 1.17.3 NOT\n\nSannhetstabell:\n\n| A | Ut = |\n|---|----|\n| 0 | 1 |\n| 1 | 0 |\n\nLogisk NOT-operator:\n\nIllustrasjon:\nTegning av NOT port\n\nI tegningen av OR-porten, betyr det for eksempel at hvis det kommer en spenning 0 inn på inngang A og en spenning 1 inn på inngang B, vil det gå en spenning 1 ut. Slike porter kan man så sette sammen til kompliserte kretser. Det er for eksempel ikke veldig mange porter som skal til for å bygge en krets som kan legge sammen to firebits tall, slik CPU-en omtalt nedenfor kan. Alle tall i en datamaskin er representert i det binære tallsystem med nuller og enere, eller som vi har sett, med ingen eller positiv elektrisk spenning.\n\nI figurene ser man hvordan det er vanlig å tegne AND, OR og NOT-porter i krets-diagram."}
{"identifier": "os11.3", "section_id": "11.3", "section_title": "Mange samtidige Java-tråder", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION000123000000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.3 Mange samtidige Java-tråder\n\nMan kan starte et gitt antall tråder med\n\n```\n.\n.\n.\n    static double saldo[] = new double[5000000]; // Felles array. 5M*8 byte = 40MByte\n.\n.\n.\n       int threads = 20;\n       CalcThread tr[] = new CalcThread[threads];\n       System.out.println(\"Starts \" +threads + \" threads !\\n\");\n\n       for(k = 0;k < threads;k++)\n           {\n               tr[k] = new CalcThread();\n               System.out.println(\"Thread has id \" + tr[k].id + \"\\n\");\n               tr[k].start();\n           }\n```\n\nDette vil lage en prosess med mange tråder. Med top på Linux så dette tidligere ut som 20 uavhengige prosesser, selvom de egentlig var tåder. På en Linux host med to CPU'er ser det idag slik ut:\n\n```\nPID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                              \n 4448 haugerud  20   0  246m  59m  15m S  199  2.9   0:16.19 java\n```\n\nLegg merke til at prosessen bruker 199% CPU, det skyldes at de 20 trådene tilsammen bruker så mye CPU ved at de av OS-kjernen scheduleres på begge CPU-ene. Om man taster H får man se alle trådene:\n\n```\nPID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                   \n 4458 haugerud  20   0  246m  59m  15m R 10.8  2.9   0:59.51 java                                      \n 4466 haugerud  20   0  246m  59m  15m R 10.8  2.9   0:59.38 java                                      \n 4450 haugerud  20   0  246m  59m  15m R 10.5  2.9   0:59.60 java                                      \n 4454 haugerud  20   0  246m  59m  15m R 10.5  2.9   0:59.54 java                                      \n 4465 haugerud  20   0  246m  59m  15m R 10.5  2.9   0:59.34 java                                      \n 4455 haugerud  20   0  246m  59m  15m R 10.2  2.9   0:59.53 java                                      \n 4459 haugerud  20   0  246m  59m  15m R 10.2  2.9   0:59.49 java                                      \n 4460 haugerud  20   0  246m  59m  15m R 10.2  2.9   0:59.49 java                                      \n 4451 haugerud  20   0  246m  59m  15m R  9.9  2.9   0:59.58 java                                      \n 4461 haugerud  20   0  246m  59m  15m R  9.6  2.9   0:52.16 java                                      \n 4467 haugerud  20   0  246m  59m  15m R  9.3  2.9   0:52.01 java                                      \n 4452 haugerud  20   0  246m  59m  15m R  9.0  2.9   0:52.18 java                                      \n 4456 haugerud  20   0  246m  59m  15m R  9.0  2.9   0:52.18 java                                      \n 4462 haugerud  20   0  246m  59m  15m R  9.0  2.9   0:52.14 java                                      \n 4463 haugerud  20   0  246m  59m  15m R  9.0  2.9   0:52.13 java                                      \n 4464 haugerud  20   0  246m  59m  15m R  9.0  2.9   0:52.13 java                                      \n 4468 haugerud  20   0  246m  59m  15m R  9.0  2.9   0:52.08 java                                      \n 4469 haugerud  20   0  246m  59m  15m R  9.0  2.9   0:52.01 java                                      \n 4453 haugerud  20   0  246m  59m  15m R  8.7  2.9   0:52.22 java                                      \n 4457 haugerud  20   0  246m  59m  15m R  8.7  2.9   0:52.15 java\n```\n\nDet ser ut som det er 20 prosesser som bruker 59MByte hver, men de deler i virkeligheten på et stort felles array, `saldo[]` . Legg merke til at hver tråd har sin egen PID. Det er slik OS-kjernen ser trådene, de scheduleres som selvstendige enheter og får like mye CPU hver. Hvis man i top taster f og velger\n\n```\nTPGID   = Tty Process Grp Id  \nnTH     = Number of Threads\n```\n\nvil man se at dette er PID for den opprinnelige prosessen som startet alle de andre trådene, tråd nummer 21 i listingen nedenfor:\n\n```\nPID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND          TPGID nTH \n 7617 haugerud  20   0 8241296  60408  16644 R 43,9  0,4   1:30.37 java              7586  40 \n 7623 haugerud  20   0 8241296  60408  16644 R 41,6  0,4   1:29.58 java              7586  40 \n 7624 haugerud  20   0 8241296  60408  16644 R 41,6  0,4   1:31.18 java              7586  40 \n 7607 haugerud  20   0 8241296  60408  16644 R 41,3  0,4   1:31.09 java              7586  40 \n 7622 haugerud  20   0 8241296  60408  16644 R 41,3  0,4   1:30.59 java              7586  40 \n 7619 haugerud  20   0 8241296  60408  16644 R 40,3  0,4   1:32.93 java              7586  40 \n 7625 haugerud  20   0 8241296  60408  16644 R 40,3  0,4   1:32.86 java              7586  40 \n 7606 haugerud  20   0 8241296  60408  16644 R 39,9  0,4   1:31.49 java              7586  40 \n 7614 haugerud  20   0 8241296  60408  16644 R 39,9  0,4   1:30.02 java              7586  40 \n 7615 haugerud  20   0 8241296  60408  16644 R 39,9  0,4   1:30.50 java              7586  40 \n 7620 haugerud  20   0 8241296  60408  16644 R 39,9  0,4   1:30.47 java              7586  40 \n 7609 haugerud  20   0 8241296  60408  16644 R 38,9  0,4   1:31.44 java              7586  40 \n 7610 haugerud  20   0 8241296  60408  16644 R 38,9  0,4   1:30.85 java              7586  40 \n 7611 haugerud  20   0 8241296  60408  16644 R 38,3  0,4   1:30.66 java              7586  40 \n 7613 haugerud  20   0 8241296  60408  16644 R 38,0  0,4   1:30.76 java              7586  40 \n 7616 haugerud  20   0 8241296  60408  16644 R 38,0  0,4   1:30.37 java              7586  40 \n 7608 haugerud  20   0 8241296  60408  16644 R 37,3  0,4   1:30.91 java              7586  40 \n 7618 haugerud  20   0 8241296  60408  16644 R 37,3  0,4   1:29.09 java              7586  40 \n 7621 haugerud  20   0 8241296  60408  16644 R 37,3  0,4   1:29.92 java              7586  40 \n 7612 haugerud  20   0 8241296  60408  16644 R 37,0  0,4   1:30.44 java              7586  40 \n 7586 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7587 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.06 java              7586  40 \n 7588 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7589 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7590 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7591 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7592 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7593 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7594 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7595 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7596 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:16.10 java              7586  40 \n 7597 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7598 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7599 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7600 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.02 java              7586  40 \n 7601 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.02 java              7586  40 \n 7602 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7603 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.02 java              7586  40 \n 7604 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.00 java              7586  40 \n 7605 haugerud  20   0 8241296  60408  16644 S  0,0  0,4   0:00.05 java              7586  40\n```\n\nOg hvis man taster H igjen, er det bare denne prosessen man ser som bruker nesten 800% CPU, siden serveren har 8 CPU'er i dette tilfellet.\n\n```\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     TPGID nTH \n 7586 haugerud  20   0 8241296  60548  16644 S 790,4  0,4  86:37.05 java       7586  40\n```"}
{"identifier": "os11.4", "section_id": "11.4", "section_title": "Java threads-eksempel: Prioritet", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION000124000000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.4 Java threads-eksempel: Prioritet\n\nEn Java-tråd kan tilordnes prioritet med `setPriority()` . Eksempelet under viser også at en tråd selv kan endre sin prioritet. Når en tråd med høyere prioritet starter er meningen at den skal ta over CPU fra tråder med lavere prioritet, eventuelt gis mer CPU-tid. Men dette er ikke et absolutt krav i spesifikasjonen og praksis viser at dette ikke er tilfelle for alle JVM'er.\n\nOm man hadde kjørt programmet i eksempelet med tråder implementert i user-space, ville OS ikke vært involvert i scheduleringen. Med Java green-threads (jdk1.1) startes først tråd 1 med prioritet 5 og tråd 2 med prioritet 10. Tråd 2 \"sover\" i 3 sekunder, så i starten kjører tråd 1 alene. Når tråd 2 våkner, tar den fullstendig over CPU-en og utfører `work()` helt til den setter sin egen prioritet til 1. Da tar tråd 1 over igjen til den er helt ferdig og til slutt fullføres tråd 2.\n\nKjøres det samme med native-threads, som er implementert i alle nyere JVM'er, vil trådene scheduleres av OS-kjernen og dermed timeslices og kjøre samtidig. På Linux vil prioriteten i praksis ikke ha noen innflytelse, trådene kjøres samtidig og deler likt på CPU, uansett hva prioriteten settes til. Dette skjer også om trådene tvinges til å kjøre på samme CPU med taskset. Det ville vært mulig å bruke `nice` til å implementere prioritet i en Linux JVM, men man har valgt å ikke gjøre det som default siden dette ikker er et absolutt krav i spesifikasjonen for JVM-implementasjonen. Se ukeoppgavene om hvordan man kan få prioritet til å virke under Linux.\n\nUnder Windows vil trådene både timeslice og resprektere prioriteten, men i så stor grad at threads med lavere prioritet nesten ikke slipper til. Og denne prioriteringen skjer kun hvis trådene deler samme CPU. Om det er flere CPUer tilgjengelig, kjører trådene på hver sin CPU og får like mye CPU-tid hver. Moralen er: Java Threads er ikke plattformuavhengig og avhengig av hvordan JVM i samarbeid med det underliggende OS schedulerer trådene.\n\n```\nimport java.lang.Thread;\n\nclass PriorThread extends Thread\n{\n   static int count = 0;\n   int id,mil;\n   int max = 400000000;\n   \n   PriorThread(int millisek)\n\t{\n\t count++;\n\t id = count;\n\t mil = millisek;\n\t}\n\n   public void run()\n\t{\n\t try {sleep (mil);} catch (Exception e) {}\t \t \n\t System.out.println(\"Thread nr.\" + id + \" med prioritet \" + getPriority() + \" starter\");\n\t System.out.println(\"Thread nr.\" + id + \" regnet ut \" + work()+ \"\\n\");\n\t if(id == 2)\n\t    {\n\t    setPriority(1);\n\t    System.out.println(\"\\nEndrer prioritet for Thread nr.\" + id + \". Prioritet er nå \"+getPriority()+\"\\n\");\n\t    }\n\t System.out.println(\"Thread nr.\" + id + \" regnet ut \" + work()+ \"\\n\");\n\t}\n\n   private float work()\n\t{\n\t int i,j;\n\t float res = 0;\n\t for(j=1;j<=8;j++)\n\t     {\n\t\t for(i = 1;i < max;i++)\n\t\t     {\n\t\t\t res += 1.0/(1.0*i*i);\n\t\t     }\n\t\t System.out.println(\"Thread nr.\" + id + \" avsluttet work(\" + j + \")\");\n\t     }\n\t return(res);\n\t}\n}\n\nclass Prior\n{\n   public static void main(String args[])\n   {\n    System.out.println(\"\\nStarter to threads!\\n\");\n    PriorThread s1 = new PriorThread(1);\n    s1.start();\n    s1.setPriority(5);\n    System.out.println(\"Default prioritet er \" + s1.NORM_PRIORITY + \" for en thread\");\n    System.out.println(\"Max er \" + s1.MAX_PRIORITY + \" og min er \" + s1.MIN_PRIORITY + \"\\n\");\n\n    PriorThread s2 = new PriorThread(0);\n    s2.setPriority(10);\n    s2.start();  \n   }\n}\n```"}
{"identifier": "os11.5", "section_id": "11.5", "section_title": "Prior.java kjørt på Linux", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION000125000000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.5 Prior.java kjørt på Linux\n\nMan ser av kjøringen under at selvom man tvinger trådene til å dele samme CPU, har ikke prioriteten noen effekt:\n\n```\nrex:~/threads$ taskset -c 0 java Prior\n\nStarter to threads!\n\nDefault prioritet er 5 for en thread\nMax er 10 og min er 1\n\nThread nr.2 med prioritet 10 starter\nThread nr.1 med prioritet 5 starter\nThread nr.1 avsluttet work(1)\nThread nr.2 avsluttet work(1)\nThread nr.1 avsluttet work(2)\nThread nr.2 avsluttet work(2)\nThread nr.1 avsluttet work(3)\nThread nr.2 avsluttet work(3)\nThread nr.1 avsluttet work(4)\nThread nr.2 avsluttet work(4)\nThread nr.1 avsluttet work(5)\nThread nr.2 avsluttet work(5)\nThread nr.1 avsluttet work(6)\nThread nr.2 avsluttet work(6)\nThread nr.1 avsluttet work(7)\nThread nr.2 avsluttet work(7)\nThread nr.2 avsluttet work(8)\nThread nr.1 avsluttet work(8)\nThread nr.1 regnet ut 13.15576\n\nThread nr.2 regnet ut 13.15576\n\nEndrer prioritet for Thread nr.2. Prioritet er nå 1\n\nThread nr.1 avsluttet work(1)\nThread nr.2 avsluttet work(1)\nThread nr.1 avsluttet work(2)\nThread nr.2 avsluttet work(2)\nThread nr.2 avsluttet work(3)\nThread nr.1 avsluttet work(3)\nThread nr.2 avsluttet work(4)\nThread nr.1 avsluttet work(4)\nThread nr.2 avsluttet work(5)\nThread nr.1 avsluttet work(5)\nThread nr.2 avsluttet work(6)\nThread nr.1 avsluttet work(6)\nThread nr.2 avsluttet work(7)\nThread nr.1 avsluttet work(7)\nThread nr.2 avsluttet work(8)\nThread nr.2 regnet ut 13.15576\n\nThread nr.1 avsluttet work(8)\nThread nr.1 regnet ut 13.15576\n```"}
{"identifier": "os11.6", "section_id": "11.6", "section_title": "Prior.java kjørt på Windows 10", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION000126000000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.6 Prior.java kjørt på Windows 10\n\nKjører man PriorThread-eksempelet under Windows, på en maskin med kun en CPU, vil prioriteten tas hensyn til, men tråd med høyere prioritet tar da over nesten all CPU-tiden og slipper ikke den andre tråden til:\n\n```\nPS C:\\Users\\os\\threads> java Prior\n\nStarter to threads!\n\nDefault prioritet er 5 for en thread\nMax er 10 og min er 1\n\nThread nr.2 med prioritet 10 starter\nThread nr.2 avsluttet work(1)\nThread nr.2 avsluttet work(2)\nThread nr.1 med prioritet 5 starter\nThread nr.2 avsluttet work(3)\nThread nr.2 avsluttet work(4)\nThread nr.2 avsluttet work(5)\nThread nr.2 avsluttet work(6)\nThread nr.2 avsluttet work(7)\nThread nr.2 avsluttet work(8)\nThread nr.2 regnet ut 13.15576\n\nThread nr.1 avsluttet work(1)\nThread nr.1 avsluttet work(2)\n\nEndrer prioritet for Thread nr.2. Prioritet er nå 1\n\nThread nr.1 avsluttet work(3)\nThread nr.1 avsluttet work(4)\nThread nr.1 avsluttet work(5)\nThread nr.1 avsluttet work(6)\nThread nr.1 avsluttet work(7)\nThread nr.1 avsluttet work(8)\nThread nr.1 regnet ut 13.15576\n\nThread nr.1 avsluttet work(1)\nThread nr.1 avsluttet work(2)\nThread nr.1 avsluttet work(3)\nThread nr.1 avsluttet work(4)\nThread nr.1 avsluttet work(5)\nThread nr.1 avsluttet work(6)\nThread nr.1 avsluttet work(7)\nThread nr.1 avsluttet work(8)\nThread nr.1 regnet ut 13.15576\n\nThread nr.2 avsluttet work(1)\nThread nr.2 avsluttet work(2)\nThread nr.2 avsluttet work(3)\nThread nr.2 avsluttet work(4)\nThread nr.2 avsluttet work(5)\nThread nr.2 avsluttet work(6)\nThread nr.2 avsluttet work(7)\nThread nr.2 avsluttet work(8)\nThread nr.2 regnet ut 13.15576\n```\n\nMan ser at når thread nr. 2 endrer prioritet, kjører thread nr. 1 to runder før thread nr 2 får tid til å skrive ut sin kommentar om at prioriteten er senket.\n\nKjører man eksemplet med mange tråder, kan man på Windows taskmanager se hvor mange tråder JVM bruker. For å få til det må man høyreklikke på en av kolonne-navnene og be om at thread-kolonnen vises. I utganspunktet bruker Windows JVM 10 tråder. Hvis man starter 20 egne tråder viser dermed Taskmanager 30 tråder."}
{"identifier": "os11.7", "section_id": "11.7", "section_title": "Blokkerende systemkall", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION000127000000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.7 Blokkerende systemkall\n\nDen viktigste årsaken til at man i det hele tatt begynte med threads var såkalte blokkerende I/O requests. Blokkerende betyr at applikasjonen som ber om I/O blir satt på vent av operativsystemet til resultatet fra I/O operasjonen returnerer. Blokkerende I/O forespørsler kan for eksempel være å lese fra en fil eller fra tastaturet. Programmet kan da ikke kjøre videre før det får resultatet. Generelt leder forespørsler om I/O til systemkall og disse er da blokkerende eller ikke-blokkerende systemkall. Eksempler på blokkerende systemkall:\n\n* read/write\n* wait\n* sleep\n\nDe to første er alltid blokkerende, mens read og write kan bli gjort til nonblocking ved å bruke buffere og ordninger som sender signaler når lesingen/skrivingen er ferdig. Ikke blokkerende systemkall:\n\n* getpid\n* gettimeofday\n* setuid\n\nDette er systemkall som ikke trenger å vente på I/O, andre prosesser eller noe annent for å fullføre. Uansett vil et systemkall føre til en trap til OS-kjernen."}
{"identifier": "os11.8", "section_id": "11.8", "section_title": "Thread-modeller", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION000128000000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.8 Thread-modeller\n\nDet finnes tre hovedmetoder for hvordan et operativsystem skedulerer threads. De tre metodene er forskjellige med hensyn på hvor uavhengig av hverandre trådene skeduleres.\n\nIllustrasjon:\nThread-modeller i OS-kjernen\n\n**en til mange**: Alle trådene skeduleres som en prosess, en enhet. Java: green-threads, JVM sørger selv for skedulering; ingen multitasking. Default på gamle versjoner av Linux(Debian) og Solaris.\n\n**en til en**: Den mest brukte modellen. Hver tråd skeduleres uavhengig av de andre. Windows Java-threads, Linux native Java-threads, Linux Posix-threads (pthreads)\n\n**mange til mange**: Tråder skeduleres uavhengig om de ikke er for mange. Kjernen kan begrense antall tråder i RR-køen. Solaris, Digital Unix, IRIX pthreads\n\nEt operativsystem som bruker en-til-mange metoden vil behandle en prosess som inneholder mange tråder akkurat som en prosess med bare en tråd. Den gir prosessen biter av CPU-tid som alle andre prosesser og bryr seg ikke om at prosessen egentlig består av flere tråder. Det gjør at tråd-programmet selv må sørge for skedulering. En måte å gjøre dette på er at trådene kaller på `yield()` for å signalisere til de andre trådene at den er ferdig med sin del av jobben. Alternativt kan tråd-programmet selv lag en round robin schedulering som fordeler tid mellom trådene. For Java green-threads, som var default metode i de første Java-versjonene, var det JVM som selv sørget for skedulering. Hvis man i en slik versjon av Java setter igang to tråder, vil de ikke jobbe annen hver gang som man ville forvente, men første tråd kjøre til den er ferdig og så vil trå nummer to ta over.\n\nDe aller fleste av dagens operativsystemer bruker en-til-en metoden hvor det er en kjerne-tråd for hver bruker-tråd. Det betyr ikke at det for hver bruker-prosess er en egen prosess eller tråd i kjernen, men at kjernen for hver tråd har lagret data som registerverdier, program counter, tilstand, tråd-ID, prioritet og så videre og skedulerer hver tråd uavhengig av de andre trådene. For prosesser med bare en tråd, har kjernen lagret disse dataene i en tabell som inneholder informasjon om alle prosessene som kjører. For prosesser som har flere tråder, har kjernen for hver av disse en tabell som inneholder data for de individuelle trådene. Når operativsystemets scheduler skal velge hvilken tråd den skal kjøre på en CPU, velger den mellom alle tilgjengelige tråder, uavhengig av hvilken prosess de tilhører og uavhengig av hvor mange tråder hver prosess har. OS-kjernen fordeler CPU-tid jevnt mellom alle trådene og ikke mellom prosessene. En prosess som har veldig mange tråder vil derfor få mer CPU-tid enn en prosess med få tråder."}
{"identifier": "os11.9", "section_id": "11.9", "section_title": "Synkronisering", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION000129000000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.9 Synkronisering\n\nSamtidige prosesser som deler felles ressurser/data må synkroniseres .\n\n* prosesser må ikke endre felles data samtidig\n* en prosess bør ikke lese felles data mens en annen endrer dem\n* en prosess må kunne vente på (f. eks. resultater fra) en annen prosess\n\nDistribuerte systemer mer og mer vanlig. Synkronisering er da essensielt."}
{"identifier": "os11.10", "section_id": "11.10", "section_title": "Serialisering", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION0001210000000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.10 Serialisering\n\nProsesser/tråder som aksesserer felles data må serialiseres; jobbe en av gangen på felles data. Problemstillingen kalles **Race Condition** (konkurranse om felles ressurser). *Brukeren må selv serialisere sine prosesser. OS legger mulighetene til rette.*"}
{"identifier": "os11.10.1", "section_id": "11.10.1", "section_title": "Eksempel: To web-prosesser som skriver ut billetter", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION0001210100000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.10.1 Eksempel: To web-prosesser som skriver ut billetter\n\nAnta at man kan kjøpe billetter på en web-side. På web-serveren starter det da opp en prosess for hver bruker som bestiller en billett. Disse prosessene er helt uavhengige, bortsett fra at de har en felles variabel `LedigeBilletter` som er antall ledige billetter. Koden prosessene kjører kan se omtrent slik ut:\n\n```\nif(LedigeBilletter > 0){\n   LedigeBilletter--;\n   SkrivUtBillett();\n}\n```\n\nDette fungerer greit når bare en slik prosess kjøres av gangen, men det kan oppstå problemer hvis de kjører samtidig(husk at `LedigeBilletter` er en felles variabel):\n\n| P1-kode | P2-kode | LedigeBilletter |\n|-------|-------|---------------|\n| if(LedigeBilletter > 0){ |  | 1 |\n| —Context Switch | if(LedigeBilletter > 0){ | 1 |\n|  | LedigeBilletter—; | 0 |\n|  | SkrivUtBillett(); | 0 |\n|  | } | 0 |\n| LedigeBilletter—; | Context Switch— | -1 |\n| SkrivUtBillett(); |  | -1 |\n| } |  | -1 |\n\nEn Context Switch kan forekomme når som helst og hvis den skjer rett etter at P1 har sjekket at `(LedigeBilletter > 0)` , men før den har senket verdien med en, vil P1 og P2 skrive ut den samme (og siste) billetten til to forskjellige kunder. Dette er opplagt galt. Prosessene må serialiseres, slik at denne kodebiten (som kalles et kritisk avsnitt) gjøres av en prosess av gangen."}
{"identifier": "os11.10.2", "section_id": "11.10.2", "section_title": "Eksempel: to prosesser som oppdaterer en felles variabel", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION0001210200000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.10.2 Eksempel: to prosesser som oppdaterer en felles variabel\n\nDet er viktig å huske at en linje høynivåkode ofte oversettes til mange linjer makinkode. Dermed kan en Race Condition oppstå selv inni en kodelinje, fordi en Context Switch kan oppstå mellom to hvilke som helst maskininstruksjoner. CPU-en ser kun maskininstruksjoner og aner ikke noe om høynivåkoden som ligger bak. Anta at to prosesser P1 og P2 kjører følgende høynivåkode som oppdaterer en konto:\n\n| P1-kode | P2-kode |\n|-------|-------|\n| static int saldo; | static int saldo; |\n| . | . |\n| . | . |\n| . | . |\n| saldo = saldo - mill; | saldo = saldo + mill; |\n\n*Variabelen saldo er da en felles variabel begge kan endre.*\n\n**Problem**: Hva skjer om OS switcher fra P1 til P2 mens P1 ufører `saldo = saldo - mill` ?\n\n**Hvorfor?**: Prosessen utfører maskinkode, linje for linje, og kan bli avbrutt etter en instruksjon.\n\n| P1 | P2 |\n|---|---|\n| saldo = saldo - mill; | saldo = saldo + mill; |\n| mov saldo,%ax | mov saldo,%ax |\n| mov mill,%bx | mov mill,%bx |\n| sub %bx,%ax | add %bx,%ax |\n| mov %ax,saldo | mov %ax,saldo |\n\nAnta at P1 blir Context switchet etter å ha utført `mov mill,\\%bx` og P2 overtar. Og videre at saldo er 5 til å begynne med og mill er 1. Følgende skjer, sett fra prosessoren:\n\n| Prosess som kjører | Instruksjon (IR) | %ax | %bx | saldo |\n|------------------|----------------|---|---|-----|\n| P1 | mov saldo,%ax | 5 | 0 | 5 |\n| P1 | mov mill,%bx | 5 | 1 | 5 |\n| OS | Context switch | 0 | 0 | 5 |\n| P2 | mov saldo, %ax | 5 | 0 | 5 |\n| P2 | mov mill,%bx | 5 | 1 | 5 |\n| P2 | add %bx,%ax | 6 | 1 | 5 |\n| P2 | mov %ax,saldo | 6 | 1 | 6 |\n| OS | Context switch | 5 | 1 | 6 |\n| P1 | sub %bx,%ax | 4 | 1 | 6 |\n| P1 | mov %ax,saldo | 4 | 1 | 4 |\n\nNår P2 er ferdig vil P1 bruke den gamle saldoverdien 5 og sluttresultatet blir saldo = 4. Det burde ha blitt saldo = 5 og en mill er borte!! Konklusjon: må serialisere aksess til felles data!"}
{"identifier": "os11.11", "section_id": "11.11", "section_title": "Kritisk avsnitt", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION0001211000000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.11 Kritisk avsnitt\n\nTo prosesser P1 og P2 kjører:\n\n| P1-kode | P2-kode |\n|-------|-------|\n| static int saldo; | static int saldo; |\n| . | . |\n| . | . |\n| . | . |\n| saldo = saldo - mill; | saldo = saldo + mill; |\n\nUtregningen av saldo er et kritisk avsnitt i koden til P1 og P2. Et kritisk avsnitt **må fullføres** av prosessen som utfører det uten at andre prosesser slipper til; prosessene må serialiseres."}
{"identifier": "os11.12", "section_id": "11.12", "section_title": "Kritisk avsnitt: Java-eksempel", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION0001212000000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.12 Kritisk avsnitt: Java-eksempel\n\nAnta at to tråder samarbeider om et felles int-variabel saldo. Den ene tråden øker en million ganger saldo med 1, mens tråd nummer to minker verdien av saldo med en million ganger. Koden kan se slik ut:\n\n```\n// Kompileres med  javac NosynchThread.java\n// Run: java NosynchThread\n\nimport java.lang.Thread;\n\nclass SaldoThread extends Thread\n{\n    static int MAX = 1000000; // En million\n    static int count = 0;\n    public static int saldo; // Felles variable, gir race condition\n    int id; \n    \n    SaldoThread()\n    {\n        count++;\n        id = count;\n    }\n    \n    public void run()\n    {\n\tSystem.out.println(\"Tråd nr. \"+ id +\", med prioritet \" + getPriority() + \" starter\");\n\tupdateSaldo();\n    }\n    \n    private void updateSaldo()\n    {\n\tint i;\n\tif(id == 1) \n\t{\n\t    for(i = 1;i < MAX;i++) \n\t    {\n\t\tsaldo++;\n\t    }\n\t}\n\telse      \n\t{\n\t    for(i = 1;i < MAX;i++)\n\t    {\n\t        saldo--;\n\t    }\n\t}\n\tSystem.out.println(\"Tråd nr. \" + id + \" ferdig. Saldo: \" + saldo);\n    }\n}\n\nclass NosynchThread extends Thread\n{\n   public static void main (String args[])\n   {\n       int i;\n       System.out.println(\"Starter to tråder!\");\n\n       SaldoThread s1 = new SaldoThread();\n       SaldoThread s2 = new SaldoThread();\n       s1.start();\n       s2.start();\n\n       try{s1.join();} catch (InterruptedException e){}\n       try{s2.join();} catch (InterruptedException e){}\n\n       System.out.println(\"Endelig total saldo: \" +SaldoThread.saldo);\n   }\n}\n```\n\n*Her stod det inntil 14 april 2024 i koden  public synchronized void updateSaldo() men det var trolig fra\nen test; det hjelper ikke å bruke synchronized slik, se mer om dette i neste forelesning. I videoen er koden korrekt\npresentert, uten synchronized.*\n\nMan skulle tro at saldo dermed ender opp som 0, men en kjøring kan gi noe slikt som:\n\n```\nrex:~/threads/nosync$ java NosynchThread \nStarter to tråder!\nTråd nr. 2, med prioritet 5 starter\nTråd nr. 1, med prioritet 5 starter\nTråd nr. 2 ferdig. Saldo: -7831\nTråd nr. 1 ferdig. Saldo: -4892\nEndelig total saldo: -4892\n```\n\neller\n\n```\nrex:~/threads/nosync$ java NosynchThread \nStarter to tråder!\nTråd nr. 1, med prioritet 5 starter\nTråd nr. 2, med prioritet 5 starter\nTråd nr. 1 ferdig. Saldo: 8055\nTråd nr. 2 ferdig. Saldo: 3727\nEndelig total saldo: 3727\n```\n\nAltså flere tusen feil og varierende resultat fra gang til gang. Dette skyldes at trådenes lesning og lagring av den felles variabelen ikke er synkronisert."}
{"identifier": "os11.12.1", "section_id": "11.12.1", "section_title": "Årsaken: race conditions", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION0001212100000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.12.1 Årsaken: race conditions\n\nSer man på bytekoden som kjøres vil den delen av updateSaldo() som legger til 1 se slik ut\n\n```\n\\normalsize\n$ javap -private -c SaldoThread\n -private for å vise alle metoder, ellers vises ikke updateSaldo()\n.\n.\n      17: getstatic     #17                 // Field saldo:I\n      20: iconst_1\n      21: iadd\n      22: putstatic     #17                 // Field saldo:I\n.\n.\n```\n\nog tilsvarende del av koden for subtraksjon ser slik ut\n\n```\n40: getstatic     #17                 // Field saldo:I\n      43: iconst_1\n      44: isub\n      45: putstatic     #17                 // Field saldo:I\n```\n\nJVM er en stack-maskin og getstatic laster verdien fra saldo på stacken før iadd øker verdien med en. Til slutt lagres verdien på stacken med putstatic. Årsaken til regnefeilene er at trådene når som helst kan context switches og om det skjer mellom getstatic og putstatic, vil regneoperasjonen bli usynkroniserte og trådene overser deler av hverandres regneoperasjoner."}
{"identifier": "os11.13", "section_id": "11.13", "section_title": "Race condition med C, to pthreads og én instruksjon", "source_category": "os", "source_id": "11", "source_title": "Java threads og synkronisering", "anchor": "SECTION0001213000000000000000", "source": "os/Forelesning/os/node12.html", "text": "## 11.13 Race condition med C, to pthreads og én instruksjon\n\nVi så i eksempelet med Java-tråder at instruksjonen\n\n```\nsaldo++;\n```\n\nfaktisk ikke utføres av en enkelt Java bytecode-instruksjon, men av flere. Dermed vil det selvom trådene kjører på samme CPU kunne skje en context switch rett etter at verdien på saldo er lastet inn og før verdien er lagret igjen. Når den andre tråen så går inn og leser verdien på saldo vil den bruke den ikke oppdaterte verdien og en race condition oppstår. Sluttresultatet vil avhenge av hvilken tråd som leser verdien først og vil dermed være forskjellig for hver gang programmet kjøres. Men hva om det faktisk bare var en enkelt instruksjon som blir utført i det kritiske avsnittet? Kan det også da oppstå en race condition?\n\nFor å undersøke det lager vi et ligenende program hvor vi bruker en enkelt assembly-instruksjon for å forsikre oss om at det kun er en enkelt instruksjon som utføres og at kompilatoren ikke lager maskinkode som involverer flere instruksjoner. Tråder er ikke inkludert som default i C, men man kan introdusere tråder ved hjelp av pthreads-biblioteket. Koden nedenfor viser et C-program som lager to tråder som begge oppdaterer en felles variabel med navn `svar` . I dette tilfellet øker begge tråder verdien til variabelen like mange ganger og dermed vet vi at verdien må bli det dobbelte av det hver tråd øker med hvis det ikke inntreffer en race condition.\n\n```\n#include <stdio.h>\n#include <stdlib.h>\n#include <pthread.h>\n\nint svar = 0;\n\nextern void enlinje();\n\nvoid *inc() \n{\n   printf(\"Starter; svar verdi: %d\\n\", svar);\n   \n   for (int i = 0; i < 10000000; i++) \n     {\n\tenlinje();\n     }\n   \n   printf(\"Avslutter; svar verdi: %d\\n\", svar);\n}\n\nint main()\n{\n           pthread_t thread1, thread2;\n      \n          /* Lager uavhengige threads som utfører inc-funksjonen */\n      \n           pthread_create( &thread1, NULL, inc,NULL);\n           pthread_create( &thread2, NULL, inc, NULL);\n      \n           /* Venter med join til begge tråder er ferdige */\n      \n           pthread_join( thread1, NULL);\n           pthread_join( thread2, NULL); \n      \n           printf(\"Main avslutter; svar verdi: %d\\n\", svar);\n           exit(0);\n}\n```\n\nI første omgang skriver vi enlinje-funksjonen med vanlig C-kode i en fil med navn `en.c` , alt den gjør er å øke verdien av den felles variabelen `svar` med en:\n\n```\nvoid enlinje()\n{\n   extern int svar;\n   svar++;\n}\n```\n\nNår vi så kompilerer og kjører programmet på følgende måte:\n\n```\nrex:~/threads/lock$ gcc -pthread thread.c en.c\nrex:~/threads/lock$ ./a.out \nStarter; svar verdi: 0\nStarter; svar verdi: 629979\nAvslutter; svar verdi: 10026464\nAvslutter; svar verdi: 12261597\nMain avslutter; svar verdi: 12261597\n\nrex:~/threads/lock$ ./a.out \nStarter; svar verdi: 0\nStarter; svar verdi: 204229\nAvslutter; svar verdi: 7132793\nAvslutter; svar verdi: 10668956\nMain avslutter; svar verdi: 10668956\n\nrex:~/threads/lock$ ./a.out \nStarter; svar verdi: 0\nStarter; svar verdi: 114562\nAvslutter; svar verdi: 9936660\nAvslutter; svar verdi: 10127784\nMain avslutter; svar verdi: 10127784\n```\n\nser vi at en race condition oppstår fordi svaret blir forskjellig for hver gang og avhenger av rekkefølgen de to trådene oppdaterer variabelen. At svaret er litt over 10 millioner er forenlig med det som skjer hvis begge henter ut verdien 1 omtrent samtidig og øker den til 2 og så skriver tilbake omtrent samtidig, vil den totale økningen være 1, mens den burde vært 2. Når trådene fortsetter slik uten å samarbeide, vil ca halvparten av økningene med 1 forsvinne. Men kan dette skyldes at kompilatoren lager maskinkode som involverer flere instruksjoner? Ja, det kan være årsaken (å undersøke om det virkelig er tilfelle at kompilatoren lager flere linjer, overlates til en av ukens oppgaver). For å være helt sikker på at enlinje-funksjonen kun utfører en enkelt insturksjon, erstatter vi `en.c` med assembly-filen `minimal.s` :\n\n```\n.globl\tenlinje\nenlinje:\n\tincl svar(%rip)\n\tret\n```\n\nNår vi nå kompilerer og kjører er vi sikker på at det kun er en enkelt instruksjon som oppdaterer variabelen `svar` , den blir ikke lagret i et register først. Likevel, når vi kompilerer og kjører oppstår det fortsatt en race condition:\n\n```\nrex:~/threads/lock$ gcc -pthread thread.c minimal.s \nrex:~/threads/lock$ ./a.out \nStarter; svar verdi: 0\nStarter; svar verdi: 748235\nAvslutter; svar verdi: 7065807\nAvslutter; svar verdi: 10768013\nMain avslutter; svar verdi: 10768013\n```\n\nDette skyldes at de to trådene kjører på hver sin CPU og at det ikke er noen koordinering CPUene imellom om å vente på hverandre når en variabel skal hentes fra RAM. Men hva om man tvinger begge trådene til å kjøre på samme kjerne eller CPU? Da bør vel en race condition avverges? Det kan testes ved å starte prosessen med taskset, den vil tvinge prosessen og alle dens tråder til å kjøre på samme CPU. Og ganske riktig, da løses problemet:\n\n```\nrex:~/threads/lock$ taskset -c 0 ./a.out \nStarter; svar verdi: 0\nStarter; svar verdi: 3258051\nAvslutter; svar verdi: 17614192\nAvslutter; svar verdi: 20000000\nMain avslutter; svar verdi: 20000000\n\nrex:~/threads/lock$ taskset -c 0 ./a.out \nStarter; svar verdi: 0\nStarter; svar verdi: 3348312\nAvslutter; svar verdi: 17502515\nAvslutter; svar verdi: 20000000\nMain avslutter; svar verdi: 20000000\n```\n\nUansett hvor mange ganger man kjører dette, vil det gi riktig resultat. Dette er fordi en enkelt maskininstruksjon fullføres før en context switch skjer, dermed vil et kritisk avsnitt alltid fullføres før neste tråd tar over.\n\nEn mer genrell løsning består i å legge til maskininstruksjonen `lock` rett før oppdateringen av `svar` :\n\n```\n.globl\tenlinje\nenlinje:\n        lock\n\tincl\tsvar(%rip)\n\tret\n```\n\nDenne instruksjonen låser minnebussen slik at ingen andre prosesser får bruke den før den selv har utført neste instruksjon. Dermed løses problemet:\n\n```\nrex:~/threads/lock$ ./a.out \nStarter; svar verdi: 0\nStarter; svar verdi: 116546\nAvslutter; svar verdi: 19886202\nAvslutter; svar verdi: 20000000\nMain avslutter; svar verdi: 20000000\n```\n\nDette er en metode å løse race condition problemer på, i neste forelesning ser vi på denne og andre metoder. Forøvrig bruker programmet tre ganger så lang tid på å kjøre når man bruker `lock` . Dette er fordi det tar mye ekstra tid å synkronisere prosessene, de må vente på hverandre når minnebussen låses."}
