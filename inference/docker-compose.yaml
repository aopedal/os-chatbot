services:
  vllm:
    build:
      context: .
      dockerfile: Dockerfile.vllm
    container_name: vllm
    ports:
      - "8000:8000"
    command: >
      python -m vllm.entrypoints.openai.api_server
      --host 0.0.0.0
      --port 8000
      --model /app/models/gpt-oss-20b
      --max_model_len 65536
      --gpu-memory-utilization 0.75
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]